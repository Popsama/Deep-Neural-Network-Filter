{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP神经网络的卡尔曼滤波器实现（基于Dual-optimized adaptive Kalman filtering algorithm based on BP neural network and variance compensation for laser absorption spectroscopy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所需要的一些modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Spectral_KF import SpectralKalmanFilter\n",
    "from torch.utils.data import random_split\n",
    "from FilterNet_utils import Data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tensor(array):\n",
    "    \"\"\"\n",
    "    因为numpy的ndarry和pytorch的tensor是两种不同的数据类型，将来在将读取的数据进行训练之前，\n",
    "    需要先将ndarry转变为tensor.\n",
    "    \"\"\"\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = tensor.type(torch.cuda.FloatTensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BpFilter(nn.Module):  # four hidden layer; seven hidden units in each layer (according to the original paper)\n",
    "    \"\"\"\n",
    "    神经网络滤波器\n",
    "    input -  layer 1 -  layer2 - layer3 - layer4 - output\n",
    "    (1, 1) - (1, 7) -  (1, 7) - (1, 7) - (1, 7) - (1, 1)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BpFilter, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=1, out_features=7)\n",
    "        self.fc2 = nn.Linear(in_features=7, out_features=7)\n",
    "        self.fc3 = nn.Linear(in_features=7, out_features=7)\n",
    "        self.fc4 = nn.Linear(in_features=7, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一下BpFilter,主要是查看输入输出的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "filter = BpFilter()\n",
    "a = torch.randn(10, 1)\n",
    "print(a.shape)\n",
    "a_hat = filter(a)\n",
    "print(a_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit(model, train_loader, device, optimizer, criterion, epochs):\n",
    "    \"\"\"\n",
    "    训练模型，输入模型，数据集，GPU设备，选择的优化器以及损失函数，在设置的epoch内进行模型优化。\n",
    "    :param model: 输入的训练模型, untrained model\n",
    "    :param train_loader: training data loader\n",
    "    :param validation_loader: validation data loader\n",
    "    :param device: GPU or  cpu\n",
    "    :param optimizer: the chosen optimizer\n",
    "    :param criterion: the loss function\n",
    "    :param epochs: iteration running on models\n",
    "    :return: trained loss & test loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    iteration_loss_list = []\n",
    "    validation_error_list = []\n",
    "    for e in range(epochs):\n",
    "        for index, (train_x, train_y) in enumerate(train_loader):\n",
    "            batch_x = train_x.to(device)\n",
    "            batch_y = train_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction1 = model(batch_x)\n",
    "            loss = criterion(prediction1, batch_y)\n",
    "            iteration_loss_list.append(float(loss))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"epoch: {} [{}/{} {:.2f}%] train loss: {} \".format(e, \n",
    "                                                                     index*len(batch_x),\n",
    "                                                                     len(train_loader.dataset),\n",
    "                                                                     100*index/len(train_loader),\n",
    "                                                                     loss.item())\n",
    "                  )\n",
    "    return iteration_loss_list, validation_error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 普通卡尔曼滤波器（无BP优化的），重点还是在process noise variance & measurement noise variance。可以根据具体实验计算出来。对于透射光谱（吸收光谱）系统，构建了state space equatoins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_kalman(index=500):\n",
    "    process_var = 0.009858427**2  # process noise variance\n",
    "    sensor_var = 0.009223176**2  # measurement noise variance\n",
    "    Z = CH4_noisy_spectral[index]\n",
    "    nk = np.arange(0, 1111)\n",
    "    Z = np.vstack((Z, nk))  # (2, 1111) measurement matrix\n",
    "    U = CH4_no_noise_spectral[index]\n",
    "    ones = np.ones((1111,))\n",
    "    U = np.vstack((U, ones))  # (2, 1111) control matrix\n",
    "    KF_Filter = SpectralKalmanFilter(U, Z, process_var, sensor_var)  # KF类的实例\n",
    "    CH4_KF = KF_Filter.filtering()\n",
    "    CH4_KF = CH4_KF[0]  # (1111,)\n",
    "    return CH4_KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigth_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight.data)\n",
    "        init.constant_(m.bias.data,0.1)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(0,0.01)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据。使用的是模拟的无噪声甲烷（0-1000ppm）的吸收谱，以及模拟的有噪声（高斯白噪声和干涉噪声叠加的噪声）甲烷（0-1000ppm）的吸收谱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"模拟数据 （透射谱）\"\"\"\n",
    "    no_noise_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\深度学习滤波器\\1000组模拟数据\\提供给模型的数据\\模拟数据\\CH_nonoise_spectral.npy\"\n",
    "    CH4_no_noise_spectral = np.load(no_noise_path)  # (1000, 1111) 透射谱（吸收谱）\n",
    "\n",
    "    noisy_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\深度学习滤波器\\1000组模拟数据\\提供给模型的数据\\模拟数据\\CH_noisy_spectral.npy\"\n",
    "    CH4_noisy_spectral = np.load(noisy_path)  # (1000, 1111) 透射谱（吸收谱）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据original paper,他们做的是先用kalman filter对噪声信号进行一次滤波，再次基础之上，使用BPNN对滤波后的信号进行二次优化（我阅读之后的理解，原文并没有对这个过程进行直接描述，因此可能有出入，在我们与作者进行邮件沟通之后，也没有得到明确的KF状态方程的表达，因此之后的BP-KF完全是基于我们对论文的理解进行构建的。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1111)\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"plain KF滤波1次\"\"\"\n",
    "    \"\"\"对所有的噪声信号进行KF滤波，滤波后的信号可以作为BP神经网络的输入，而无噪声的信号即为label（ground truth）\"\"\"\n",
    "    CH4_KF = np.zeros_like(CH4_no_noise_spectral)  # (1000, 1111)\n",
    "    for i in range(1000):\n",
    "        CH4_KF[i] = plain_kalman(index=i)\n",
    "    print(CH4_KF.shape)  # (1000, 1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 值得注意的是，根据原文，状态方程中描述吸收谱的state vector是有透射率和波数组成的，在这里我们简化为只有透射率的输入，因此原文中的BPNN是一个2维的输入和2维的输出，在这里我们简化为1维（only transmittance）输入和1维输出（optimized transmittance）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: torch.Size([1111000, 1])\n",
      "label shape: torch.Size([1111000, 1])\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"KF滤波之后用BP再优化一次\"\"\"\n",
    "    input_data = CH4_KF.reshape(-1, 1)  # (1111000, 1) 将它作为BpKF的input\n",
    "    label_data = CH4_no_noise_spectral.reshape(-1, 1)  # label (1111000, 1)\n",
    "    input_data = array_to_tensor(input_data)  # torch.cuda.FloatTensor size(1111, 1)\n",
    "    label_data = array_to_tensor(label_data)  # torch.cuda.FloatTensor size(1111, 1)\n",
    "    print(\"input data shape:\", input_data.shape)\n",
    "    print(\"label shape:\", label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"进行数据分割 train-validation-test split\"\"\"\n",
    "    train_data, test_data, train_label, test_label = train_test_split(input_data, label_data, test_size=0.2, random_state=2)\n",
    "    train_loader = Data_set(train_data, train_label, 1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [0/888800 0.00%] train loss: 0.44016897678375244 \n",
      "epoch: 0 [1111/888800 0.12%] train loss: 0.43416857719421387 \n",
      "epoch: 0 [2222/888800 0.25%] train loss: 0.4288434684276581 \n",
      "epoch: 0 [3333/888800 0.38%] train loss: 0.423783540725708 \n",
      "epoch: 0 [4444/888800 0.50%] train loss: 0.41786110401153564 \n",
      "epoch: 0 [5555/888800 0.62%] train loss: 0.4122677445411682 \n",
      "epoch: 0 [6666/888800 0.75%] train loss: 0.40661633014678955 \n",
      "epoch: 0 [7777/888800 0.88%] train loss: 0.40153074264526367 \n",
      "epoch: 0 [8888/888800 1.00%] train loss: 0.3953395485877991 \n",
      "epoch: 0 [9999/888800 1.12%] train loss: 0.39021486043930054 \n",
      "epoch: 0 [11110/888800 1.25%] train loss: 0.3851398527622223 \n",
      "epoch: 0 [12221/888800 1.38%] train loss: 0.3796140253543854 \n",
      "epoch: 0 [13332/888800 1.50%] train loss: 0.37402620911598206 \n",
      "epoch: 0 [14443/888800 1.62%] train loss: 0.36865803599357605 \n",
      "epoch: 0 [15554/888800 1.75%] train loss: 0.3628241717815399 \n",
      "epoch: 0 [16665/888800 1.88%] train loss: 0.35746392607688904 \n",
      "epoch: 0 [17776/888800 2.00%] train loss: 0.35229846835136414 \n",
      "epoch: 0 [18887/888800 2.12%] train loss: 0.34679362177848816 \n",
      "epoch: 0 [19998/888800 2.25%] train loss: 0.3416960835456848 \n",
      "epoch: 0 [21109/888800 2.38%] train loss: 0.3361808657646179 \n",
      "epoch: 0 [22220/888800 2.50%] train loss: 0.33036935329437256 \n",
      "epoch: 0 [23331/888800 2.62%] train loss: 0.3253497779369354 \n",
      "epoch: 0 [24442/888800 2.75%] train loss: 0.32057806849479675 \n",
      "epoch: 0 [25553/888800 2.88%] train loss: 0.31501486897468567 \n",
      "epoch: 0 [26664/888800 3.00%] train loss: 0.30969205498695374 \n",
      "epoch: 0 [27775/888800 3.12%] train loss: 0.3027724027633667 \n",
      "epoch: 0 [28886/888800 3.25%] train loss: 0.29476749897003174 \n",
      "epoch: 0 [29997/888800 3.38%] train loss: 0.2867759168148041 \n",
      "epoch: 0 [31108/888800 3.50%] train loss: 0.2787973880767822 \n",
      "epoch: 0 [32219/888800 3.62%] train loss: 0.2703551650047302 \n",
      "epoch: 0 [33330/888800 3.75%] train loss: 0.2623089551925659 \n",
      "epoch: 0 [34441/888800 3.88%] train loss: 0.25408318638801575 \n",
      "epoch: 0 [35552/888800 4.00%] train loss: 0.24582791328430176 \n",
      "epoch: 0 [36663/888800 4.12%] train loss: 0.23756597936153412 \n",
      "epoch: 0 [37774/888800 4.25%] train loss: 0.22908736765384674 \n",
      "epoch: 0 [38885/888800 4.38%] train loss: 0.22078418731689453 \n",
      "epoch: 0 [39996/888800 4.50%] train loss: 0.2130681276321411 \n",
      "epoch: 0 [41107/888800 4.62%] train loss: 0.20451734960079193 \n",
      "epoch: 0 [42218/888800 4.75%] train loss: 0.19680355489253998 \n",
      "epoch: 0 [43329/888800 4.88%] train loss: 0.18879011273384094 \n",
      "epoch: 0 [44440/888800 5.00%] train loss: 0.1808956414461136 \n",
      "epoch: 0 [45551/888800 5.12%] train loss: 0.1734580248594284 \n",
      "epoch: 0 [46662/888800 5.25%] train loss: 0.16572292149066925 \n",
      "epoch: 0 [47773/888800 5.38%] train loss: 0.15834294259548187 \n",
      "epoch: 0 [48884/888800 5.50%] train loss: 0.15111654996871948 \n",
      "epoch: 0 [49995/888800 5.62%] train loss: 0.143901064991951 \n",
      "epoch: 0 [51106/888800 5.75%] train loss: 0.13687875866889954 \n",
      "epoch: 0 [52217/888800 5.88%] train loss: 0.13025261461734772 \n",
      "epoch: 0 [53328/888800 6.00%] train loss: 0.12309062480926514 \n",
      "epoch: 0 [54439/888800 6.12%] train loss: 0.11690380424261093 \n",
      "epoch: 0 [55550/888800 6.25%] train loss: 0.11045227944850922 \n",
      "epoch: 0 [56661/888800 6.38%] train loss: 0.10443726927042007 \n",
      "epoch: 0 [57772/888800 6.50%] train loss: 0.09824186563491821 \n",
      "epoch: 0 [58883/888800 6.62%] train loss: 0.0926942527294159 \n",
      "epoch: 0 [59994/888800 6.75%] train loss: 0.08673714846372604 \n",
      "epoch: 0 [61105/888800 6.88%] train loss: 0.08111811429262161 \n",
      "epoch: 0 [62216/888800 7.00%] train loss: 0.07609014213085175 \n",
      "epoch: 0 [63327/888800 7.12%] train loss: 0.0709221363067627 \n",
      "epoch: 0 [64438/888800 7.25%] train loss: 0.06615567207336426 \n",
      "epoch: 0 [65549/888800 7.38%] train loss: 0.06152203306555748 \n",
      "epoch: 0 [66660/888800 7.50%] train loss: 0.057051315903663635 \n",
      "epoch: 0 [67771/888800 7.62%] train loss: 0.05271599814295769 \n",
      "epoch: 0 [68882/888800 7.75%] train loss: 0.048498187214136124 \n",
      "epoch: 0 [69993/888800 7.88%] train loss: 0.044611912220716476 \n",
      "epoch: 0 [71104/888800 8.00%] train loss: 0.04111706092953682 \n",
      "epoch: 0 [72215/888800 8.12%] train loss: 0.03746119141578674 \n",
      "epoch: 0 [73326/888800 8.25%] train loss: 0.03428962826728821 \n",
      "epoch: 0 [74437/888800 8.38%] train loss: 0.03095044568181038 \n",
      "epoch: 0 [75548/888800 8.50%] train loss: 0.0280938558280468 \n",
      "epoch: 0 [76659/888800 8.62%] train loss: 0.025382841005921364 \n",
      "epoch: 0 [77770/888800 8.75%] train loss: 0.022903110831975937 \n",
      "epoch: 0 [78881/888800 8.88%] train loss: 0.020429030060768127 \n",
      "epoch: 0 [79992/888800 9.00%] train loss: 0.018063535913825035 \n",
      "epoch: 0 [81103/888800 9.12%] train loss: 0.01605641283094883 \n",
      "epoch: 0 [82214/888800 9.25%] train loss: 0.014226958155632019 \n",
      "epoch: 0 [83325/888800 9.38%] train loss: 0.012494574300944805 \n",
      "epoch: 0 [84436/888800 9.50%] train loss: 0.010863354429602623 \n",
      "epoch: 0 [85547/888800 9.62%] train loss: 0.009411458857357502 \n",
      "epoch: 0 [86658/888800 9.75%] train loss: 0.008159191347658634 \n",
      "epoch: 0 [87769/888800 9.88%] train loss: 0.007015220820903778 \n",
      "epoch: 0 [88880/888800 10.00%] train loss: 0.005905355326831341 \n",
      "epoch: 0 [89991/888800 10.12%] train loss: 0.004997866228222847 \n",
      "epoch: 0 [91102/888800 10.25%] train loss: 0.004168232902884483 \n",
      "epoch: 0 [92213/888800 10.38%] train loss: 0.003446955932304263 \n",
      "epoch: 0 [93324/888800 10.50%] train loss: 0.002825739560648799 \n",
      "epoch: 0 [94435/888800 10.62%] train loss: 0.0022953993175178766 \n",
      "epoch: 0 [95546/888800 10.75%] train loss: 0.0018070540390908718 \n",
      "epoch: 0 [96657/888800 10.88%] train loss: 0.001418918021954596 \n",
      "epoch: 0 [97768/888800 11.00%] train loss: 0.0011234711855649948 \n",
      "epoch: 0 [98879/888800 11.12%] train loss: 0.0008343183435499668 \n",
      "epoch: 0 [99990/888800 11.25%] train loss: 0.0006196402246132493 \n",
      "epoch: 0 [101101/888800 11.38%] train loss: 0.00044048004201613367 \n",
      "epoch: 0 [102212/888800 11.50%] train loss: 0.00030514932586811483 \n",
      "epoch: 0 [103323/888800 11.62%] train loss: 0.0002138366107828915 \n",
      "epoch: 0 [104434/888800 11.75%] train loss: 0.00014031292812433094 \n",
      "epoch: 0 [105545/888800 11.88%] train loss: 9.08904621610418e-05 \n",
      "epoch: 0 [106656/888800 12.00%] train loss: 5.9146914281882346e-05 \n",
      "epoch: 0 [107767/888800 12.12%] train loss: 5.317108298186213e-05 \n",
      "epoch: 0 [108878/888800 12.25%] train loss: 4.675581294577569e-05 \n",
      "epoch: 0 [109989/888800 12.38%] train loss: 4.438650648808107e-05 \n",
      "epoch: 0 [111100/888800 12.50%] train loss: 7.17790171620436e-05 \n",
      "epoch: 0 [112211/888800 12.62%] train loss: 8.706960215931758e-05 \n",
      "epoch: 0 [113322/888800 12.75%] train loss: 8.849822916090488e-05 \n",
      "epoch: 0 [114433/888800 12.88%] train loss: 0.00013476048479788005 \n",
      "epoch: 0 [115544/888800 13.00%] train loss: 0.00016586302081122994 \n",
      "epoch: 0 [116655/888800 13.12%] train loss: 0.0001696029503364116 \n",
      "epoch: 0 [117766/888800 13.25%] train loss: 0.0001792093098629266 \n",
      "epoch: 0 [118877/888800 13.38%] train loss: 0.0002107069012708962 \n",
      "epoch: 0 [119988/888800 13.50%] train loss: 0.0002174926339648664 \n",
      "epoch: 0 [121099/888800 13.62%] train loss: 0.00023617190890945494 \n",
      "epoch: 0 [122210/888800 13.75%] train loss: 0.00024147704243659973 \n",
      "epoch: 0 [123321/888800 13.88%] train loss: 0.0002273550780955702 \n",
      "epoch: 0 [124432/888800 14.00%] train loss: 0.00023720506578683853 \n",
      "epoch: 0 [125543/888800 14.12%] train loss: 0.00023422048252541572 \n",
      "epoch: 0 [126654/888800 14.25%] train loss: 0.00021690734138246626 \n",
      "epoch: 0 [127765/888800 14.38%] train loss: 0.0002272108686156571 \n",
      "epoch: 0 [128876/888800 14.50%] train loss: 0.000228672128287144 \n",
      "epoch: 0 [129987/888800 14.62%] train loss: 0.00019730892381630838 \n",
      "epoch: 0 [131098/888800 14.75%] train loss: 0.0002006484428420663 \n",
      "epoch: 0 [132209/888800 14.88%] train loss: 0.00018684699898585677 \n",
      "epoch: 0 [133320/888800 15.00%] train loss: 0.000167560632689856 \n",
      "epoch: 0 [134431/888800 15.12%] train loss: 0.00015096738934516907 \n",
      "epoch: 0 [135542/888800 15.25%] train loss: 0.00014893508341629058 \n",
      "epoch: 0 [136653/888800 15.38%] train loss: 0.0001496681070420891 \n",
      "epoch: 0 [137764/888800 15.50%] train loss: 0.0001222347200382501 \n",
      "epoch: 0 [138875/888800 15.62%] train loss: 0.00011476018698886037 \n",
      "epoch: 0 [139986/888800 15.75%] train loss: 0.00010906574607361108 \n",
      "epoch: 0 [141097/888800 15.88%] train loss: 9.660304931458086e-05 \n",
      "epoch: 0 [142208/888800 16.00%] train loss: 8.158179116435349e-05 \n",
      "epoch: 0 [143319/888800 16.12%] train loss: 6.959954043850303e-05 \n",
      "epoch: 0 [144430/888800 16.25%] train loss: 7.612008630530909e-05 \n",
      "epoch: 0 [145541/888800 16.38%] train loss: 7.068601553328335e-05 \n",
      "epoch: 0 [146652/888800 16.50%] train loss: 6.6301719925832e-05 \n",
      "epoch: 0 [147763/888800 16.62%] train loss: 6.00978200964164e-05 \n",
      "epoch: 0 [148874/888800 16.75%] train loss: 7.20389507478103e-05 \n",
      "epoch: 0 [149985/888800 16.88%] train loss: 5.0185924919787794e-05 \n",
      "epoch: 0 [151096/888800 17.00%] train loss: 5.504942964762449e-05 \n",
      "epoch: 0 [152207/888800 17.12%] train loss: 5.839147706865333e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [153318/888800 17.25%] train loss: 5.384725227486342e-05 \n",
      "epoch: 0 [154429/888800 17.38%] train loss: 4.5004566345596686e-05 \n",
      "epoch: 0 [155540/888800 17.50%] train loss: 4.781592360814102e-05 \n",
      "epoch: 0 [156651/888800 17.62%] train loss: 5.497273741639219e-05 \n",
      "epoch: 0 [157762/888800 17.75%] train loss: 4.9521684559294954e-05 \n",
      "epoch: 0 [158873/888800 17.88%] train loss: 4.858481770497747e-05 \n",
      "epoch: 0 [159984/888800 18.00%] train loss: 4.667239045375027e-05 \n",
      "epoch: 0 [161095/888800 18.12%] train loss: 4.715123577625491e-05 \n",
      "epoch: 0 [162206/888800 18.25%] train loss: 4.4735763367498294e-05 \n",
      "epoch: 0 [163317/888800 18.38%] train loss: 4.8546808102400973e-05 \n",
      "epoch: 0 [164428/888800 18.50%] train loss: 4.4487922423286363e-05 \n",
      "epoch: 0 [165539/888800 18.62%] train loss: 5.32451958861202e-05 \n",
      "epoch: 0 [166650/888800 18.75%] train loss: 4.9722264520823956e-05 \n",
      "epoch: 0 [167761/888800 18.88%] train loss: 4.817529770662077e-05 \n",
      "epoch: 0 [168872/888800 19.00%] train loss: 4.54520049970597e-05 \n",
      "epoch: 0 [169983/888800 19.12%] train loss: 3.944595664506778e-05 \n",
      "epoch: 0 [171094/888800 19.25%] train loss: 5.290676199365407e-05 \n",
      "epoch: 0 [172205/888800 19.38%] train loss: 4.982752579962835e-05 \n",
      "epoch: 0 [173316/888800 19.50%] train loss: 5.252003757050261e-05 \n",
      "epoch: 0 [174427/888800 19.62%] train loss: 5.4368487326428294e-05 \n",
      "epoch: 0 [175538/888800 19.75%] train loss: 4.983560211258009e-05 \n",
      "epoch: 0 [176649/888800 19.88%] train loss: 4.840384644921869e-05 \n",
      "epoch: 0 [177760/888800 20.00%] train loss: 4.507686389843002e-05 \n",
      "epoch: 0 [178871/888800 20.12%] train loss: 4.161711331107654e-05 \n",
      "epoch: 0 [179982/888800 20.25%] train loss: 4.590196840581484e-05 \n",
      "epoch: 0 [181093/888800 20.38%] train loss: 4.576972423819825e-05 \n",
      "epoch: 0 [182204/888800 20.50%] train loss: 4.451860149856657e-05 \n",
      "epoch: 0 [183315/888800 20.62%] train loss: 4.8729649279266596e-05 \n",
      "epoch: 0 [184426/888800 20.75%] train loss: 4.580273889587261e-05 \n",
      "epoch: 0 [185537/888800 20.88%] train loss: 4.615544094122015e-05 \n",
      "epoch: 0 [186648/888800 21.00%] train loss: 5.219255399424583e-05 \n",
      "epoch: 0 [187759/888800 21.12%] train loss: 5.729424810851924e-05 \n",
      "epoch: 0 [188870/888800 21.25%] train loss: 5.061742922407575e-05 \n",
      "epoch: 0 [189981/888800 21.38%] train loss: 4.258929766365327e-05 \n",
      "epoch: 0 [191092/888800 21.50%] train loss: 4.388500747154467e-05 \n",
      "epoch: 0 [192203/888800 21.62%] train loss: 3.6236091546015814e-05 \n",
      "epoch: 0 [193314/888800 21.75%] train loss: 5.222682375460863e-05 \n",
      "epoch: 0 [194425/888800 21.88%] train loss: 5.14583989570383e-05 \n",
      "epoch: 0 [195536/888800 22.00%] train loss: 4.462098149815574e-05 \n",
      "epoch: 0 [196647/888800 22.12%] train loss: 3.771527190110646e-05 \n",
      "epoch: 0 [197758/888800 22.25%] train loss: 4.6860805014148355e-05 \n",
      "epoch: 0 [198869/888800 22.38%] train loss: 4.877344690612517e-05 \n",
      "epoch: 0 [199980/888800 22.50%] train loss: 4.7708166675874963e-05 \n",
      "epoch: 0 [201091/888800 22.62%] train loss: 5.463518755277619e-05 \n",
      "epoch: 0 [202202/888800 22.75%] train loss: 4.3834013922605664e-05 \n",
      "epoch: 0 [203313/888800 22.88%] train loss: 4.477688707993366e-05 \n",
      "epoch: 0 [204424/888800 23.00%] train loss: 4.9918569857254624e-05 \n",
      "epoch: 0 [205535/888800 23.12%] train loss: 4.5034550566924736e-05 \n",
      "epoch: 0 [206646/888800 23.25%] train loss: 4.404777064337395e-05 \n",
      "epoch: 0 [207757/888800 23.38%] train loss: 5.261185287963599e-05 \n",
      "epoch: 0 [208868/888800 23.50%] train loss: 5.341355426935479e-05 \n",
      "epoch: 0 [209979/888800 23.62%] train loss: 4.2166284401901066e-05 \n",
      "epoch: 0 [211090/888800 23.75%] train loss: 4.572965917759575e-05 \n",
      "epoch: 0 [212201/888800 23.88%] train loss: 5.70140837226063e-05 \n",
      "epoch: 0 [213312/888800 24.00%] train loss: 5.3069263231009245e-05 \n",
      "epoch: 0 [214423/888800 24.12%] train loss: 4.597123188432306e-05 \n",
      "epoch: 0 [215534/888800 24.25%] train loss: 4.319184517953545e-05 \n",
      "epoch: 0 [216645/888800 24.38%] train loss: 5.046487785875797e-05 \n",
      "epoch: 0 [217756/888800 24.50%] train loss: 4.205962613923475e-05 \n",
      "epoch: 0 [218867/888800 24.62%] train loss: 5.018519004806876e-05 \n",
      "epoch: 0 [219978/888800 24.75%] train loss: 4.8270245315507054e-05 \n",
      "epoch: 0 [221089/888800 24.88%] train loss: 4.518231435213238e-05 \n",
      "epoch: 0 [222200/888800 25.00%] train loss: 4.314140824135393e-05 \n",
      "epoch: 0 [223311/888800 25.12%] train loss: 4.7996047214837745e-05 \n",
      "epoch: 0 [224422/888800 25.25%] train loss: 4.32943161285948e-05 \n",
      "epoch: 0 [225533/888800 25.38%] train loss: 4.735824404633604e-05 \n",
      "epoch: 0 [226644/888800 25.50%] train loss: 3.816733442363329e-05 \n",
      "epoch: 0 [227755/888800 25.62%] train loss: 4.453876681509428e-05 \n",
      "epoch: 0 [228866/888800 25.75%] train loss: 4.278238702681847e-05 \n",
      "epoch: 0 [229977/888800 25.88%] train loss: 4.3904736230615526e-05 \n",
      "epoch: 0 [231088/888800 26.00%] train loss: 4.366007124190219e-05 \n",
      "epoch: 0 [232199/888800 26.12%] train loss: 5.344702731235884e-05 \n",
      "epoch: 0 [233310/888800 26.25%] train loss: 4.7015491873025894e-05 \n",
      "epoch: 0 [234421/888800 26.38%] train loss: 4.444184378371574e-05 \n",
      "epoch: 0 [235532/888800 26.50%] train loss: 5.3140553063713014e-05 \n",
      "epoch: 0 [236643/888800 26.62%] train loss: 4.385736974654719e-05 \n",
      "epoch: 0 [237754/888800 26.75%] train loss: 4.054728560731746e-05 \n",
      "epoch: 0 [238865/888800 26.88%] train loss: 4.937395715387538e-05 \n",
      "epoch: 0 [239976/888800 27.00%] train loss: 5.280065306578763e-05 \n",
      "epoch: 0 [241087/888800 27.12%] train loss: 4.115990668651648e-05 \n",
      "epoch: 0 [242198/888800 27.25%] train loss: 4.74303487862926e-05 \n",
      "epoch: 0 [243309/888800 27.38%] train loss: 4.410186011227779e-05 \n",
      "epoch: 0 [244420/888800 27.50%] train loss: 4.073034506291151e-05 \n",
      "epoch: 0 [245531/888800 27.62%] train loss: 5.097138273413293e-05 \n",
      "epoch: 0 [246642/888800 27.75%] train loss: 4.653045834857039e-05 \n",
      "epoch: 0 [247753/888800 27.88%] train loss: 5.290741319186054e-05 \n",
      "epoch: 0 [248864/888800 28.00%] train loss: 4.284450187697075e-05 \n",
      "epoch: 0 [249975/888800 28.12%] train loss: 4.509651262196712e-05 \n",
      "epoch: 0 [251086/888800 28.25%] train loss: 4.08237028750591e-05 \n",
      "epoch: 0 [252197/888800 28.38%] train loss: 4.717351112049073e-05 \n",
      "epoch: 0 [253308/888800 28.50%] train loss: 3.842868682113476e-05 \n",
      "epoch: 0 [254419/888800 28.62%] train loss: 4.780247763847001e-05 \n",
      "epoch: 0 [255530/888800 28.75%] train loss: 4.8181616875808686e-05 \n",
      "epoch: 0 [256641/888800 28.88%] train loss: 4.9459431465948e-05 \n",
      "epoch: 0 [257752/888800 29.00%] train loss: 4.864024231210351e-05 \n",
      "epoch: 0 [258863/888800 29.12%] train loss: 4.642767453333363e-05 \n",
      "epoch: 0 [259974/888800 29.25%] train loss: 4.733569949166849e-05 \n",
      "epoch: 0 [261085/888800 29.38%] train loss: 3.2324285712093115e-05 \n",
      "epoch: 0 [262196/888800 29.50%] train loss: 4.430658009368926e-05 \n",
      "epoch: 0 [263307/888800 29.62%] train loss: 4.841647751163691e-05 \n",
      "epoch: 0 [264418/888800 29.75%] train loss: 4.1717827116372064e-05 \n",
      "epoch: 0 [265529/888800 29.88%] train loss: 3.66493477486074e-05 \n",
      "epoch: 0 [266640/888800 30.00%] train loss: 5.4048581660026684e-05 \n",
      "epoch: 0 [267751/888800 30.12%] train loss: 4.4512438762467355e-05 \n",
      "epoch: 0 [268862/888800 30.25%] train loss: 4.556498970487155e-05 \n",
      "epoch: 0 [269973/888800 30.38%] train loss: 6.187297549331561e-05 \n",
      "epoch: 0 [271084/888800 30.50%] train loss: 5.0932012527482584e-05 \n",
      "epoch: 0 [272195/888800 30.62%] train loss: 3.777419260586612e-05 \n",
      "epoch: 0 [273306/888800 30.75%] train loss: 4.635743971448392e-05 \n",
      "epoch: 0 [274417/888800 30.88%] train loss: 4.306053597247228e-05 \n",
      "epoch: 0 [275528/888800 31.00%] train loss: 4.5482447603717446e-05 \n",
      "epoch: 0 [276639/888800 31.12%] train loss: 4.7473422455368564e-05 \n",
      "epoch: 0 [277750/888800 31.25%] train loss: 4.992404137738049e-05 \n",
      "epoch: 0 [278861/888800 31.38%] train loss: 4.1661071009002626e-05 \n",
      "epoch: 0 [279972/888800 31.50%] train loss: 4.1216564568458125e-05 \n",
      "epoch: 0 [281083/888800 31.62%] train loss: 4.495177563512698e-05 \n",
      "epoch: 0 [282194/888800 31.75%] train loss: 5.084648364572786e-05 \n",
      "epoch: 0 [283305/888800 31.88%] train loss: 5.732348654419184e-05 \n",
      "epoch: 0 [284416/888800 32.00%] train loss: 4.875811646343209e-05 \n",
      "epoch: 0 [285527/888800 32.12%] train loss: 4.5389395381789654e-05 \n",
      "epoch: 0 [286638/888800 32.25%] train loss: 4.229177284287289e-05 \n",
      "epoch: 0 [287749/888800 32.38%] train loss: 5.0487542466726154e-05 \n",
      "epoch: 0 [288860/888800 32.50%] train loss: 4.764131881529465e-05 \n",
      "epoch: 0 [289971/888800 32.62%] train loss: 4.3943342461716384e-05 \n",
      "epoch: 0 [291082/888800 32.75%] train loss: 3.855675458908081e-05 \n",
      "epoch: 0 [292193/888800 32.88%] train loss: 4.364494088804349e-05 \n",
      "epoch: 0 [293304/888800 33.00%] train loss: 4.726899351226166e-05 \n",
      "epoch: 0 [294415/888800 33.12%] train loss: 4.7741876187501475e-05 \n",
      "epoch: 0 [295526/888800 33.25%] train loss: 4.482519580051303e-05 \n",
      "epoch: 0 [296637/888800 33.38%] train loss: 4.211585837765597e-05 \n",
      "epoch: 0 [297748/888800 33.50%] train loss: 3.9859060052549466e-05 \n",
      "epoch: 0 [298859/888800 33.62%] train loss: 5.23866037838161e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [299970/888800 33.75%] train loss: 4.27638842666056e-05 \n",
      "epoch: 0 [301081/888800 33.88%] train loss: 4.7526689741062e-05 \n",
      "epoch: 0 [302192/888800 34.00%] train loss: 4.1963729017879814e-05 \n",
      "epoch: 0 [303303/888800 34.12%] train loss: 4.914661985822022e-05 \n",
      "epoch: 0 [304414/888800 34.25%] train loss: 5.352546941139735e-05 \n",
      "epoch: 0 [305525/888800 34.38%] train loss: 4.546366835711524e-05 \n",
      "epoch: 0 [306636/888800 34.50%] train loss: 4.3489515519468114e-05 \n",
      "epoch: 0 [307747/888800 34.62%] train loss: 4.4789510866394266e-05 \n",
      "epoch: 0 [308858/888800 34.75%] train loss: 3.967072188970633e-05 \n",
      "epoch: 0 [309969/888800 34.88%] train loss: 4.4972883188165724e-05 \n",
      "epoch: 0 [311080/888800 35.00%] train loss: 5.352882362785749e-05 \n",
      "epoch: 0 [312191/888800 35.12%] train loss: 3.881088923662901e-05 \n",
      "epoch: 0 [313302/888800 35.25%] train loss: 4.601743057719432e-05 \n",
      "epoch: 0 [314413/888800 35.38%] train loss: 3.815388117800467e-05 \n",
      "epoch: 0 [315524/888800 35.50%] train loss: 4.6172819565981627e-05 \n",
      "epoch: 0 [316635/888800 35.62%] train loss: 4.375940261525102e-05 \n",
      "epoch: 0 [317746/888800 35.75%] train loss: 4.805892240256071e-05 \n",
      "epoch: 0 [318857/888800 35.88%] train loss: 4.558909859042615e-05 \n",
      "epoch: 0 [319968/888800 36.00%] train loss: 4.9059563025366515e-05 \n",
      "epoch: 0 [321079/888800 36.12%] train loss: 5.0154787459177896e-05 \n",
      "epoch: 0 [322190/888800 36.25%] train loss: 4.502257070271298e-05 \n",
      "epoch: 0 [323301/888800 36.38%] train loss: 4.9787700845627114e-05 \n",
      "epoch: 0 [324412/888800 36.50%] train loss: 5.1500272093107924e-05 \n",
      "epoch: 0 [325523/888800 36.62%] train loss: 3.691055462695658e-05 \n",
      "epoch: 0 [326634/888800 36.75%] train loss: 5.462321132654324e-05 \n",
      "epoch: 0 [327745/888800 36.88%] train loss: 4.850898403674364e-05 \n",
      "epoch: 0 [328856/888800 37.00%] train loss: 5.078272079117596e-05 \n",
      "epoch: 0 [329967/888800 37.12%] train loss: 5.119196430314332e-05 \n",
      "epoch: 0 [331078/888800 37.25%] train loss: 4.6925513743190095e-05 \n",
      "epoch: 0 [332189/888800 37.38%] train loss: 4.333578181103803e-05 \n",
      "epoch: 0 [333300/888800 37.50%] train loss: 5.098168912809342e-05 \n",
      "epoch: 0 [334411/888800 37.62%] train loss: 4.3680265662260354e-05 \n",
      "epoch: 0 [335522/888800 37.75%] train loss: 4.596771759679541e-05 \n",
      "epoch: 0 [336633/888800 37.88%] train loss: 5.318767580320127e-05 \n",
      "epoch: 0 [337744/888800 38.00%] train loss: 3.5446071706246585e-05 \n",
      "epoch: 0 [338855/888800 38.12%] train loss: 5.180844891583547e-05 \n",
      "epoch: 0 [339966/888800 38.25%] train loss: 4.4207394239492714e-05 \n",
      "epoch: 0 [341077/888800 38.38%] train loss: 3.9450729673262686e-05 \n",
      "epoch: 0 [342188/888800 38.50%] train loss: 4.6824316086713225e-05 \n",
      "epoch: 0 [343299/888800 38.62%] train loss: 4.015957165393047e-05 \n",
      "epoch: 0 [344410/888800 38.75%] train loss: 4.9445101467426866e-05 \n",
      "epoch: 0 [345521/888800 38.88%] train loss: 4.559157241601497e-05 \n",
      "epoch: 0 [346632/888800 39.00%] train loss: 4.59781258541625e-05 \n",
      "epoch: 0 [347743/888800 39.12%] train loss: 5.347617843654007e-05 \n",
      "epoch: 0 [348854/888800 39.25%] train loss: 4.250315032550134e-05 \n",
      "epoch: 0 [349965/888800 39.38%] train loss: 3.916048081009649e-05 \n",
      "epoch: 0 [351076/888800 39.50%] train loss: 4.7096924390643835e-05 \n",
      "epoch: 0 [352187/888800 39.62%] train loss: 4.1225019231205806e-05 \n",
      "epoch: 0 [353298/888800 39.75%] train loss: 4.614576755557209e-05 \n",
      "epoch: 0 [354409/888800 39.88%] train loss: 5.533528747037053e-05 \n",
      "epoch: 0 [355520/888800 40.00%] train loss: 5.2590105042327195e-05 \n",
      "epoch: 0 [356631/888800 40.12%] train loss: 4.529020225163549e-05 \n",
      "epoch: 0 [357742/888800 40.25%] train loss: 4.630647526937537e-05 \n",
      "epoch: 0 [358853/888800 40.38%] train loss: 4.064860331709497e-05 \n",
      "epoch: 0 [359964/888800 40.50%] train loss: 4.09465137636289e-05 \n",
      "epoch: 0 [361075/888800 40.62%] train loss: 4.7446137614315376e-05 \n",
      "epoch: 0 [362186/888800 40.75%] train loss: 4.3777847167802975e-05 \n",
      "epoch: 0 [363297/888800 40.88%] train loss: 4.763658580486663e-05 \n",
      "epoch: 0 [364408/888800 41.00%] train loss: 5.19991954206489e-05 \n",
      "epoch: 0 [365519/888800 41.12%] train loss: 4.987230568076484e-05 \n",
      "epoch: 0 [366630/888800 41.25%] train loss: 4.9589132686378434e-05 \n",
      "epoch: 0 [367741/888800 41.38%] train loss: 3.969639146816917e-05 \n",
      "epoch: 0 [368852/888800 41.50%] train loss: 5.035774302086793e-05 \n",
      "epoch: 0 [369963/888800 41.62%] train loss: 5.0868064136011526e-05 \n",
      "epoch: 0 [371074/888800 41.75%] train loss: 4.0053128032013774e-05 \n",
      "epoch: 0 [372185/888800 41.88%] train loss: 4.336320489528589e-05 \n",
      "epoch: 0 [373296/888800 42.00%] train loss: 4.464267840376124e-05 \n",
      "epoch: 0 [374407/888800 42.12%] train loss: 5.0997459766222164e-05 \n",
      "epoch: 0 [375518/888800 42.25%] train loss: 5.30842698935885e-05 \n",
      "epoch: 0 [376629/888800 42.38%] train loss: 4.59393450000789e-05 \n",
      "epoch: 0 [377740/888800 42.50%] train loss: 4.5368167775450274e-05 \n",
      "epoch: 0 [378851/888800 42.62%] train loss: 3.83223632525187e-05 \n",
      "epoch: 0 [379962/888800 42.75%] train loss: 4.833208004129119e-05 \n",
      "epoch: 0 [381073/888800 42.88%] train loss: 4.61742929473985e-05 \n",
      "epoch: 0 [382184/888800 43.00%] train loss: 5.159705688129179e-05 \n",
      "epoch: 0 [383295/888800 43.12%] train loss: 5.085545853944495e-05 \n",
      "epoch: 0 [384406/888800 43.25%] train loss: 4.077651828993112e-05 \n",
      "epoch: 0 [385517/888800 43.38%] train loss: 4.706016989075579e-05 \n",
      "epoch: 0 [386628/888800 43.50%] train loss: 3.937688234145753e-05 \n",
      "epoch: 0 [387739/888800 43.62%] train loss: 4.687877299147658e-05 \n",
      "epoch: 0 [388850/888800 43.75%] train loss: 4.655167140299454e-05 \n",
      "epoch: 0 [389961/888800 43.88%] train loss: 4.7921119403326884e-05 \n",
      "epoch: 0 [391072/888800 44.00%] train loss: 4.017652099719271e-05 \n",
      "epoch: 0 [392183/888800 44.12%] train loss: 5.058048918726854e-05 \n",
      "epoch: 0 [393294/888800 44.25%] train loss: 5.866831270395778e-05 \n",
      "epoch: 0 [394405/888800 44.38%] train loss: 4.829111639992334e-05 \n",
      "epoch: 0 [395516/888800 44.50%] train loss: 5.570774374064058e-05 \n",
      "epoch: 0 [396627/888800 44.62%] train loss: 4.303062814869918e-05 \n",
      "epoch: 0 [397738/888800 44.75%] train loss: 4.3395622924435884e-05 \n",
      "epoch: 0 [398849/888800 44.88%] train loss: 6.433308590203524e-05 \n",
      "epoch: 0 [399960/888800 45.00%] train loss: 3.986490992247127e-05 \n",
      "epoch: 0 [401071/888800 45.12%] train loss: 5.533901276066899e-05 \n",
      "epoch: 0 [402182/888800 45.25%] train loss: 5.143077578395605e-05 \n",
      "epoch: 0 [403293/888800 45.38%] train loss: 4.8646677896613255e-05 \n",
      "epoch: 0 [404404/888800 45.50%] train loss: 4.2244580981787294e-05 \n",
      "epoch: 0 [405515/888800 45.62%] train loss: 4.86334138258826e-05 \n",
      "epoch: 0 [406626/888800 45.75%] train loss: 3.6080051359022036e-05 \n",
      "epoch: 0 [407737/888800 45.88%] train loss: 4.4343978515826166e-05 \n",
      "epoch: 0 [408848/888800 46.00%] train loss: 4.677461038227193e-05 \n",
      "epoch: 0 [409959/888800 46.12%] train loss: 4.1385963413631544e-05 \n",
      "epoch: 0 [411070/888800 46.25%] train loss: 4.797128349309787e-05 \n",
      "epoch: 0 [412181/888800 46.38%] train loss: 4.523801908362657e-05 \n",
      "epoch: 0 [413292/888800 46.50%] train loss: 4.5729626435786486e-05 \n",
      "epoch: 0 [414403/888800 46.62%] train loss: 4.895624806522392e-05 \n",
      "epoch: 0 [415514/888800 46.75%] train loss: 5.142741065355949e-05 \n",
      "epoch: 0 [416625/888800 46.88%] train loss: 4.9930415116250515e-05 \n",
      "epoch: 0 [417736/888800 47.00%] train loss: 4.4448766857385635e-05 \n",
      "epoch: 0 [418847/888800 47.12%] train loss: 5.314397640177049e-05 \n",
      "epoch: 0 [419958/888800 47.25%] train loss: 3.652716623037122e-05 \n",
      "epoch: 0 [421069/888800 47.38%] train loss: 4.493627784540877e-05 \n",
      "epoch: 0 [422180/888800 47.50%] train loss: 4.17497540183831e-05 \n",
      "epoch: 0 [423291/888800 47.62%] train loss: 3.9604678022442386e-05 \n",
      "epoch: 0 [424402/888800 47.75%] train loss: 5.237462028162554e-05 \n",
      "epoch: 0 [425513/888800 47.88%] train loss: 4.620312029146589e-05 \n",
      "epoch: 0 [426624/888800 48.00%] train loss: 3.679957808344625e-05 \n",
      "epoch: 0 [427735/888800 48.12%] train loss: 3.986283627455123e-05 \n",
      "epoch: 0 [428846/888800 48.25%] train loss: 4.152509063715115e-05 \n",
      "epoch: 0 [429957/888800 48.38%] train loss: 4.384354906505905e-05 \n",
      "epoch: 0 [431068/888800 48.50%] train loss: 3.796902092290111e-05 \n",
      "epoch: 0 [432179/888800 48.62%] train loss: 4.7395613364642486e-05 \n",
      "epoch: 0 [433290/888800 48.75%] train loss: 5.197515929467045e-05 \n",
      "epoch: 0 [434401/888800 48.88%] train loss: 4.873061698162928e-05 \n",
      "epoch: 0 [435512/888800 49.00%] train loss: 4.914798046229407e-05 \n",
      "epoch: 0 [436623/888800 49.12%] train loss: 5.72388235013932e-05 \n",
      "epoch: 0 [437734/888800 49.25%] train loss: 4.950333459419198e-05 \n",
      "epoch: 0 [438845/888800 49.38%] train loss: 4.364300184533931e-05 \n",
      "epoch: 0 [439956/888800 49.50%] train loss: 5.337878246791661e-05 \n",
      "epoch: 0 [441067/888800 49.62%] train loss: 4.138834628975019e-05 \n",
      "epoch: 0 [442178/888800 49.75%] train loss: 4.9670539738144726e-05 \n",
      "epoch: 0 [443289/888800 49.88%] train loss: 4.518113928497769e-05 \n",
      "epoch: 0 [444400/888800 50.00%] train loss: 4.826591248274781e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [445511/888800 50.12%] train loss: 5.266123480396345e-05 \n",
      "epoch: 0 [446622/888800 50.25%] train loss: 5.0952276069438085e-05 \n",
      "epoch: 0 [447733/888800 50.38%] train loss: 3.930352977477014e-05 \n",
      "epoch: 0 [448844/888800 50.50%] train loss: 5.7350385759491473e-05 \n",
      "epoch: 0 [449955/888800 50.62%] train loss: 4.0958464524010196e-05 \n",
      "epoch: 0 [451066/888800 50.75%] train loss: 4.876236926065758e-05 \n",
      "epoch: 0 [452177/888800 50.88%] train loss: 4.497465124586597e-05 \n",
      "epoch: 0 [453288/888800 51.00%] train loss: 4.370041278889403e-05 \n",
      "epoch: 0 [454399/888800 51.12%] train loss: 4.250213532941416e-05 \n",
      "epoch: 0 [455510/888800 51.25%] train loss: 4.2877349187619984e-05 \n",
      "epoch: 0 [456621/888800 51.38%] train loss: 4.531544982455671e-05 \n",
      "epoch: 0 [457732/888800 51.50%] train loss: 4.808177618542686e-05 \n",
      "epoch: 0 [458843/888800 51.62%] train loss: 4.5958953705849126e-05 \n",
      "epoch: 0 [459954/888800 51.75%] train loss: 5.270282053970732e-05 \n",
      "epoch: 0 [461065/888800 51.88%] train loss: 4.011987039120868e-05 \n",
      "epoch: 0 [462176/888800 52.00%] train loss: 4.135592462262139e-05 \n",
      "epoch: 0 [463287/888800 52.12%] train loss: 4.374705531517975e-05 \n",
      "epoch: 0 [464398/888800 52.25%] train loss: 4.485137469600886e-05 \n",
      "epoch: 0 [465509/888800 52.38%] train loss: 4.566399729810655e-05 \n",
      "epoch: 0 [466620/888800 52.50%] train loss: 4.818629895453341e-05 \n",
      "epoch: 0 [467731/888800 52.62%] train loss: 5.332810906111263e-05 \n",
      "epoch: 0 [468842/888800 52.75%] train loss: 4.813970372197218e-05 \n",
      "epoch: 0 [469953/888800 52.88%] train loss: 4.245312084094621e-05 \n",
      "epoch: 0 [471064/888800 53.00%] train loss: 3.621579162427224e-05 \n",
      "epoch: 0 [472175/888800 53.12%] train loss: 4.445774175110273e-05 \n",
      "epoch: 0 [473286/888800 53.25%] train loss: 4.867712777922861e-05 \n",
      "epoch: 0 [474397/888800 53.38%] train loss: 5.227196015766822e-05 \n",
      "epoch: 0 [475508/888800 53.50%] train loss: 4.532958337222226e-05 \n",
      "epoch: 0 [476619/888800 53.62%] train loss: 5.3184459829935804e-05 \n",
      "epoch: 0 [477730/888800 53.75%] train loss: 5.088284888188355e-05 \n",
      "epoch: 0 [478841/888800 53.88%] train loss: 4.225972224958241e-05 \n",
      "epoch: 0 [479952/888800 54.00%] train loss: 4.706992694991641e-05 \n",
      "epoch: 0 [481063/888800 54.12%] train loss: 5.231838804320432e-05 \n",
      "epoch: 0 [482174/888800 54.25%] train loss: 5.8550762332743034e-05 \n",
      "epoch: 0 [483285/888800 54.38%] train loss: 5.0012247811537236e-05 \n",
      "epoch: 0 [484396/888800 54.50%] train loss: 4.008551695733331e-05 \n",
      "epoch: 0 [485507/888800 54.62%] train loss: 4.535312473308295e-05 \n",
      "epoch: 0 [486618/888800 54.75%] train loss: 4.269577766535804e-05 \n",
      "epoch: 0 [487729/888800 54.88%] train loss: 4.747341154143214e-05 \n",
      "epoch: 0 [488840/888800 55.00%] train loss: 4.230591730447486e-05 \n",
      "epoch: 0 [489951/888800 55.12%] train loss: 4.7107969294302166e-05 \n",
      "epoch: 0 [491062/888800 55.25%] train loss: 5.248938759905286e-05 \n",
      "epoch: 0 [492173/888800 55.38%] train loss: 3.9940347051015124e-05 \n",
      "epoch: 0 [493284/888800 55.50%] train loss: 5.4191608796827495e-05 \n",
      "epoch: 0 [494395/888800 55.62%] train loss: 5.040262112743221e-05 \n",
      "epoch: 0 [495506/888800 55.75%] train loss: 4.3163643567822874e-05 \n",
      "epoch: 0 [496617/888800 55.88%] train loss: 5.11383441335056e-05 \n",
      "epoch: 0 [497728/888800 56.00%] train loss: 4.781535972142592e-05 \n",
      "epoch: 0 [498839/888800 56.12%] train loss: 4.632650961866602e-05 \n",
      "epoch: 0 [499950/888800 56.25%] train loss: 5.0020891649182886e-05 \n",
      "epoch: 0 [501061/888800 56.38%] train loss: 4.754176552523859e-05 \n",
      "epoch: 0 [502172/888800 56.50%] train loss: 4.611706390278414e-05 \n",
      "epoch: 0 [503283/888800 56.62%] train loss: 4.433401409187354e-05 \n",
      "epoch: 0 [504394/888800 56.75%] train loss: 4.5077333197696134e-05 \n",
      "epoch: 0 [505505/888800 56.88%] train loss: 5.255043652141467e-05 \n",
      "epoch: 0 [506616/888800 57.00%] train loss: 4.9808713811216876e-05 \n",
      "epoch: 0 [507727/888800 57.12%] train loss: 4.0274011553265154e-05 \n",
      "epoch: 0 [508838/888800 57.25%] train loss: 6.0544934967765585e-05 \n",
      "epoch: 0 [509949/888800 57.38%] train loss: 4.3563781218836084e-05 \n",
      "epoch: 0 [511060/888800 57.50%] train loss: 4.367516521597281e-05 \n",
      "epoch: 0 [512171/888800 57.62%] train loss: 3.69244153262116e-05 \n",
      "epoch: 0 [513282/888800 57.75%] train loss: 4.923318556393497e-05 \n",
      "epoch: 0 [514393/888800 57.88%] train loss: 4.59766888525337e-05 \n",
      "epoch: 0 [515504/888800 58.00%] train loss: 3.7921490729786456e-05 \n",
      "epoch: 0 [516615/888800 58.12%] train loss: 4.605982030625455e-05 \n",
      "epoch: 0 [517726/888800 58.25%] train loss: 4.5089691411703825e-05 \n",
      "epoch: 0 [518837/888800 58.38%] train loss: 4.692635775427334e-05 \n",
      "epoch: 0 [519948/888800 58.50%] train loss: 4.4371085095917806e-05 \n",
      "epoch: 0 [521059/888800 58.62%] train loss: 4.585206261253916e-05 \n",
      "epoch: 0 [522170/888800 58.75%] train loss: 4.882514622295275e-05 \n",
      "epoch: 0 [523281/888800 58.88%] train loss: 4.6873487008269876e-05 \n",
      "epoch: 0 [524392/888800 59.00%] train loss: 4.3474588892422616e-05 \n",
      "epoch: 0 [525503/888800 59.12%] train loss: 4.772862666868605e-05 \n",
      "epoch: 0 [526614/888800 59.25%] train loss: 3.9131700759753585e-05 \n",
      "epoch: 0 [527725/888800 59.38%] train loss: 4.7588477173121646e-05 \n",
      "epoch: 0 [528836/888800 59.50%] train loss: 4.519652429735288e-05 \n",
      "epoch: 0 [529947/888800 59.62%] train loss: 5.494239303516224e-05 \n",
      "epoch: 0 [531058/888800 59.75%] train loss: 5.223884363658726e-05 \n",
      "epoch: 0 [532169/888800 59.88%] train loss: 4.505483593675308e-05 \n",
      "epoch: 0 [533280/888800 60.00%] train loss: 4.4695807446260005e-05 \n",
      "epoch: 0 [534391/888800 60.12%] train loss: 4.8716778110247105e-05 \n",
      "epoch: 0 [535502/888800 60.25%] train loss: 4.5662040065508336e-05 \n",
      "epoch: 0 [536613/888800 60.38%] train loss: 4.352265750640072e-05 \n",
      "epoch: 0 [537724/888800 60.50%] train loss: 4.4514927139971405e-05 \n",
      "epoch: 0 [538835/888800 60.62%] train loss: 4.584304042509757e-05 \n",
      "epoch: 0 [539946/888800 60.75%] train loss: 4.895789243164472e-05 \n",
      "epoch: 0 [541057/888800 60.88%] train loss: 5.2966850489610806e-05 \n",
      "epoch: 0 [542168/888800 61.00%] train loss: 5.169258656678721e-05 \n",
      "epoch: 0 [543279/888800 61.12%] train loss: 4.653956784750335e-05 \n",
      "epoch: 0 [544390/888800 61.25%] train loss: 3.903074320987798e-05 \n",
      "epoch: 0 [545501/888800 61.38%] train loss: 4.957243436365388e-05 \n",
      "epoch: 0 [546612/888800 61.50%] train loss: 3.3443404390709475e-05 \n",
      "epoch: 0 [547723/888800 61.62%] train loss: 4.9449969083070755e-05 \n",
      "epoch: 0 [548834/888800 61.75%] train loss: 3.999753971584141e-05 \n",
      "epoch: 0 [549945/888800 61.88%] train loss: 4.731191074824892e-05 \n",
      "epoch: 0 [551056/888800 62.00%] train loss: 3.822939106612466e-05 \n",
      "epoch: 0 [552167/888800 62.12%] train loss: 5.0673061195993796e-05 \n",
      "epoch: 0 [553278/888800 62.25%] train loss: 5.110981874167919e-05 \n",
      "epoch: 0 [554389/888800 62.38%] train loss: 4.605014328262769e-05 \n",
      "epoch: 0 [555500/888800 62.50%] train loss: 4.592237382894382e-05 \n",
      "epoch: 0 [556611/888800 62.62%] train loss: 3.675815969472751e-05 \n",
      "epoch: 0 [557722/888800 62.75%] train loss: 4.667494067689404e-05 \n",
      "epoch: 0 [558833/888800 62.88%] train loss: 4.675917443819344e-05 \n",
      "epoch: 0 [559944/888800 63.00%] train loss: 4.5716744352830574e-05 \n",
      "epoch: 0 [561055/888800 63.12%] train loss: 5.0025020755128935e-05 \n",
      "epoch: 0 [562166/888800 63.25%] train loss: 4.7180797992041335e-05 \n",
      "epoch: 0 [563277/888800 63.38%] train loss: 4.141636600252241e-05 \n",
      "epoch: 0 [564388/888800 63.50%] train loss: 5.368047277443111e-05 \n",
      "epoch: 0 [565499/888800 63.62%] train loss: 4.0463259210810065e-05 \n",
      "epoch: 0 [566610/888800 63.75%] train loss: 4.946568515151739e-05 \n",
      "epoch: 0 [567721/888800 63.88%] train loss: 3.9647598896408454e-05 \n",
      "epoch: 0 [568832/888800 64.00%] train loss: 4.567439100355841e-05 \n",
      "epoch: 0 [569943/888800 64.12%] train loss: 4.837091182707809e-05 \n",
      "epoch: 0 [571054/888800 64.25%] train loss: 4.537338099908084e-05 \n",
      "epoch: 0 [572165/888800 64.38%] train loss: 4.2428673623362556e-05 \n",
      "epoch: 0 [573276/888800 64.50%] train loss: 5.189647345105186e-05 \n",
      "epoch: 0 [574387/888800 64.62%] train loss: 4.530237492872402e-05 \n",
      "epoch: 0 [575498/888800 64.75%] train loss: 4.614452336682007e-05 \n",
      "epoch: 0 [576609/888800 64.88%] train loss: 4.473205262911506e-05 \n",
      "epoch: 0 [577720/888800 65.00%] train loss: 4.150396489421837e-05 \n",
      "epoch: 0 [578831/888800 65.12%] train loss: 5.2205366955604404e-05 \n",
      "epoch: 0 [579942/888800 65.25%] train loss: 5.18074375577271e-05 \n",
      "epoch: 0 [581053/888800 65.38%] train loss: 4.0313512727152556e-05 \n",
      "epoch: 0 [582164/888800 65.50%] train loss: 4.256260581314564e-05 \n",
      "epoch: 0 [583275/888800 65.62%] train loss: 4.8909016186371446e-05 \n",
      "epoch: 0 [584386/888800 65.75%] train loss: 4.7456833272008225e-05 \n",
      "epoch: 0 [585497/888800 65.88%] train loss: 6.009066419210285e-05 \n",
      "epoch: 0 [586608/888800 66.00%] train loss: 4.603386696544476e-05 \n",
      "epoch: 0 [587719/888800 66.12%] train loss: 5.25964678672608e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [588830/888800 66.25%] train loss: 4.492102380027063e-05 \n",
      "epoch: 0 [589941/888800 66.38%] train loss: 4.346885179984383e-05 \n",
      "epoch: 0 [591052/888800 66.50%] train loss: 4.278205960872583e-05 \n",
      "epoch: 0 [592163/888800 66.62%] train loss: 4.413236820255406e-05 \n",
      "epoch: 0 [593274/888800 66.75%] train loss: 4.7715195250930265e-05 \n",
      "epoch: 0 [594385/888800 66.88%] train loss: 5.1496692321961746e-05 \n",
      "epoch: 0 [595496/888800 67.00%] train loss: 4.475075184018351e-05 \n",
      "epoch: 0 [596607/888800 67.12%] train loss: 4.463789809960872e-05 \n",
      "epoch: 0 [597718/888800 67.25%] train loss: 5.36293737241067e-05 \n",
      "epoch: 0 [598829/888800 67.38%] train loss: 4.354536213213578e-05 \n",
      "epoch: 0 [599940/888800 67.50%] train loss: 4.4474334572441876e-05 \n",
      "epoch: 0 [601051/888800 67.62%] train loss: 4.983128746971488e-05 \n",
      "epoch: 0 [602162/888800 67.75%] train loss: 3.602662400226109e-05 \n",
      "epoch: 0 [603273/888800 67.88%] train loss: 4.301243825466372e-05 \n",
      "epoch: 0 [604384/888800 68.00%] train loss: 4.1495088225929067e-05 \n",
      "epoch: 0 [605495/888800 68.12%] train loss: 4.655568045563996e-05 \n",
      "epoch: 0 [606606/888800 68.25%] train loss: 4.5686068915529177e-05 \n",
      "epoch: 0 [607717/888800 68.38%] train loss: 5.4617867135675624e-05 \n",
      "epoch: 0 [608828/888800 68.50%] train loss: 5.00253117934335e-05 \n",
      "epoch: 0 [609939/888800 68.62%] train loss: 4.463440563995391e-05 \n",
      "epoch: 0 [611050/888800 68.75%] train loss: 6.222945376066491e-05 \n",
      "epoch: 0 [612161/888800 68.88%] train loss: 5.211504321778193e-05 \n",
      "epoch: 0 [613272/888800 69.00%] train loss: 4.126405838178471e-05 \n",
      "epoch: 0 [614383/888800 69.12%] train loss: 4.289944263291545e-05 \n",
      "epoch: 0 [615494/888800 69.25%] train loss: 4.3625685066217557e-05 \n",
      "epoch: 0 [616605/888800 69.38%] train loss: 4.486020770855248e-05 \n",
      "epoch: 0 [617716/888800 69.50%] train loss: 4.1222017898689955e-05 \n",
      "epoch: 0 [618827/888800 69.62%] train loss: 4.127265128772706e-05 \n",
      "epoch: 0 [619938/888800 69.75%] train loss: 4.1630537452874705e-05 \n",
      "epoch: 0 [621049/888800 69.88%] train loss: 4.6701228711754084e-05 \n",
      "epoch: 0 [622160/888800 70.00%] train loss: 5.16544641868677e-05 \n",
      "epoch: 0 [623271/888800 70.12%] train loss: 3.829954584944062e-05 \n",
      "epoch: 0 [624382/888800 70.25%] train loss: 4.519907452049665e-05 \n",
      "epoch: 0 [625493/888800 70.38%] train loss: 4.4364343921188265e-05 \n",
      "epoch: 0 [626604/888800 70.50%] train loss: 4.569030716083944e-05 \n",
      "epoch: 0 [627715/888800 70.62%] train loss: 4.496434121392667e-05 \n",
      "epoch: 0 [628826/888800 70.75%] train loss: 4.89040685351938e-05 \n",
      "epoch: 0 [629937/888800 70.88%] train loss: 4.182464545010589e-05 \n",
      "epoch: 0 [631048/888800 71.00%] train loss: 4.829354656976648e-05 \n",
      "epoch: 0 [632159/888800 71.12%] train loss: 4.312681994633749e-05 \n",
      "epoch: 0 [633270/888800 71.25%] train loss: 5.073287684354e-05 \n",
      "epoch: 0 [634381/888800 71.38%] train loss: 4.835068102693185e-05 \n",
      "epoch: 0 [635492/888800 71.50%] train loss: 3.8590809708693996e-05 \n",
      "epoch: 0 [636603/888800 71.62%] train loss: 4.627152156899683e-05 \n",
      "epoch: 0 [637714/888800 71.75%] train loss: 3.8360471080522984e-05 \n",
      "epoch: 0 [638825/888800 71.88%] train loss: 4.179614916210994e-05 \n",
      "epoch: 0 [639936/888800 72.00%] train loss: 4.4532578613143414e-05 \n",
      "epoch: 0 [641047/888800 72.12%] train loss: 5.121087815496139e-05 \n",
      "epoch: 0 [642158/888800 72.25%] train loss: 4.724017344415188e-05 \n",
      "epoch: 0 [643269/888800 72.38%] train loss: 4.836448351852596e-05 \n",
      "epoch: 0 [644380/888800 72.50%] train loss: 4.575940329232253e-05 \n",
      "epoch: 0 [645491/888800 72.62%] train loss: 4.215854642097838e-05 \n",
      "epoch: 0 [646602/888800 72.75%] train loss: 5.285726365400478e-05 \n",
      "epoch: 0 [647713/888800 72.88%] train loss: 4.245451418682933e-05 \n",
      "epoch: 0 [648824/888800 73.00%] train loss: 4.922090738546103e-05 \n",
      "epoch: 0 [649935/888800 73.12%] train loss: 4.4875723688164726e-05 \n",
      "epoch: 0 [651046/888800 73.25%] train loss: 4.778655056725256e-05 \n",
      "epoch: 0 [652157/888800 73.38%] train loss: 5.398441862780601e-05 \n",
      "epoch: 0 [653268/888800 73.50%] train loss: 3.6907586036249995e-05 \n",
      "epoch: 0 [654379/888800 73.62%] train loss: 4.193677887087688e-05 \n",
      "epoch: 0 [655490/888800 73.75%] train loss: 4.571651152218692e-05 \n",
      "epoch: 0 [656601/888800 73.88%] train loss: 4.521461596596055e-05 \n",
      "epoch: 0 [657712/888800 74.00%] train loss: 4.422608981258236e-05 \n",
      "epoch: 0 [658823/888800 74.12%] train loss: 3.686682248371653e-05 \n",
      "epoch: 0 [659934/888800 74.25%] train loss: 4.4329895899863914e-05 \n",
      "epoch: 0 [661045/888800 74.38%] train loss: 4.0907354559749365e-05 \n",
      "epoch: 0 [662156/888800 74.50%] train loss: 4.7589655878255144e-05 \n",
      "epoch: 0 [663267/888800 74.62%] train loss: 4.3857915443368256e-05 \n",
      "epoch: 0 [664378/888800 74.75%] train loss: 4.196942609269172e-05 \n",
      "epoch: 0 [665489/888800 74.88%] train loss: 4.319503204897046e-05 \n",
      "epoch: 0 [666600/888800 75.00%] train loss: 4.3226438720012084e-05 \n",
      "epoch: 0 [667711/888800 75.12%] train loss: 4.9830181524157524e-05 \n",
      "epoch: 0 [668822/888800 75.25%] train loss: 4.225226439302787e-05 \n",
      "epoch: 0 [669933/888800 75.38%] train loss: 5.0219510740134865e-05 \n",
      "epoch: 0 [671044/888800 75.50%] train loss: 4.6533579734386876e-05 \n",
      "epoch: 0 [672155/888800 75.62%] train loss: 4.851900666835718e-05 \n",
      "epoch: 0 [673266/888800 75.75%] train loss: 5.036027869209647e-05 \n",
      "epoch: 0 [674377/888800 75.88%] train loss: 3.969053796026856e-05 \n",
      "epoch: 0 [675488/888800 76.00%] train loss: 4.620491381501779e-05 \n",
      "epoch: 0 [676599/888800 76.12%] train loss: 5.791543662780896e-05 \n",
      "epoch: 0 [677710/888800 76.25%] train loss: 3.6806814023293555e-05 \n",
      "epoch: 0 [678821/888800 76.38%] train loss: 5.439775486593135e-05 \n",
      "epoch: 0 [679932/888800 76.50%] train loss: 4.597743463818915e-05 \n",
      "epoch: 0 [681043/888800 76.62%] train loss: 5.425115887192078e-05 \n",
      "epoch: 0 [682154/888800 76.75%] train loss: 5.240816972218454e-05 \n",
      "epoch: 0 [683265/888800 76.88%] train loss: 4.811281178263016e-05 \n",
      "epoch: 0 [684376/888800 77.00%] train loss: 3.414510138100013e-05 \n",
      "epoch: 0 [685487/888800 77.12%] train loss: 4.2656964069465175e-05 \n",
      "epoch: 0 [686598/888800 77.25%] train loss: 5.0651447963900864e-05 \n",
      "epoch: 0 [687709/888800 77.38%] train loss: 4.688714034273289e-05 \n",
      "epoch: 0 [688820/888800 77.50%] train loss: 5.3247367759468034e-05 \n",
      "epoch: 0 [689931/888800 77.62%] train loss: 4.5442284317687154e-05 \n",
      "epoch: 0 [691042/888800 77.75%] train loss: 5.059496106696315e-05 \n",
      "epoch: 0 [692153/888800 77.88%] train loss: 4.2914085497613996e-05 \n",
      "epoch: 0 [693264/888800 78.00%] train loss: 5.147285992279649e-05 \n",
      "epoch: 0 [694375/888800 78.12%] train loss: 4.100837395526469e-05 \n",
      "epoch: 0 [695486/888800 78.25%] train loss: 5.0610167818376794e-05 \n",
      "epoch: 0 [696597/888800 78.38%] train loss: 4.6585006202803925e-05 \n",
      "epoch: 0 [697708/888800 78.50%] train loss: 5.162490197108127e-05 \n",
      "epoch: 0 [698819/888800 78.62%] train loss: 4.920546052744612e-05 \n",
      "epoch: 0 [699930/888800 78.75%] train loss: 3.727179500856437e-05 \n",
      "epoch: 0 [701041/888800 78.88%] train loss: 4.032003562315367e-05 \n",
      "epoch: 0 [702152/888800 79.00%] train loss: 5.119629713590257e-05 \n",
      "epoch: 0 [703263/888800 79.12%] train loss: 4.146538412896916e-05 \n",
      "epoch: 0 [704374/888800 79.25%] train loss: 4.22288867412135e-05 \n",
      "epoch: 0 [705485/888800 79.38%] train loss: 4.3161602661712095e-05 \n",
      "epoch: 0 [706596/888800 79.50%] train loss: 4.735420225188136e-05 \n",
      "epoch: 0 [707707/888800 79.62%] train loss: 4.933889431413263e-05 \n",
      "epoch: 0 [708818/888800 79.75%] train loss: 5.349556522560306e-05 \n",
      "epoch: 0 [709929/888800 79.88%] train loss: 4.647776222554967e-05 \n",
      "epoch: 0 [711040/888800 80.00%] train loss: 4.464888115762733e-05 \n",
      "epoch: 0 [712151/888800 80.12%] train loss: 3.953417399316095e-05 \n",
      "epoch: 0 [713262/888800 80.25%] train loss: 5.0255825044587255e-05 \n",
      "epoch: 0 [714373/888800 80.38%] train loss: 5.344225064618513e-05 \n",
      "epoch: 0 [715484/888800 80.50%] train loss: 5.291058914735913e-05 \n",
      "epoch: 0 [716595/888800 80.62%] train loss: 4.4272303057368845e-05 \n",
      "epoch: 0 [717706/888800 80.75%] train loss: 4.999146403861232e-05 \n",
      "epoch: 0 [718817/888800 80.88%] train loss: 4.865162918576971e-05 \n",
      "epoch: 0 [719928/888800 81.00%] train loss: 5.0171001930721104e-05 \n",
      "epoch: 0 [721039/888800 81.12%] train loss: 5.2065475756535307e-05 \n",
      "epoch: 0 [722150/888800 81.25%] train loss: 4.34808389400132e-05 \n",
      "epoch: 0 [723261/888800 81.38%] train loss: 4.8939262342173606e-05 \n",
      "epoch: 0 [724372/888800 81.50%] train loss: 5.265447907731868e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [725483/888800 81.62%] train loss: 4.081115184817463e-05 \n",
      "epoch: 0 [726594/888800 81.75%] train loss: 4.7353332774946466e-05 \n",
      "epoch: 0 [727705/888800 81.88%] train loss: 4.0403640014119446e-05 \n",
      "epoch: 0 [728816/888800 82.00%] train loss: 5.559494093176909e-05 \n",
      "epoch: 0 [729927/888800 82.12%] train loss: 4.82995601487346e-05 \n",
      "epoch: 0 [731038/888800 82.25%] train loss: 4.955697659170255e-05 \n",
      "epoch: 0 [732149/888800 82.38%] train loss: 3.7879999581491575e-05 \n",
      "epoch: 0 [733260/888800 82.50%] train loss: 5.05492789670825e-05 \n",
      "epoch: 0 [734371/888800 82.62%] train loss: 4.566220741253346e-05 \n",
      "epoch: 0 [735482/888800 82.75%] train loss: 4.784838165505789e-05 \n",
      "epoch: 0 [736593/888800 82.88%] train loss: 4.5360149670159444e-05 \n",
      "epoch: 0 [737704/888800 83.00%] train loss: 4.0623050153953955e-05 \n",
      "epoch: 0 [738815/888800 83.12%] train loss: 4.215613807900809e-05 \n",
      "epoch: 0 [739926/888800 83.25%] train loss: 4.205243749311194e-05 \n",
      "epoch: 0 [741037/888800 83.38%] train loss: 3.810002453974448e-05 \n",
      "epoch: 0 [742148/888800 83.50%] train loss: 3.989622200606391e-05 \n",
      "epoch: 0 [743259/888800 83.62%] train loss: 4.831182741327211e-05 \n",
      "epoch: 0 [744370/888800 83.75%] train loss: 4.728184285340831e-05 \n",
      "epoch: 0 [745481/888800 83.88%] train loss: 3.978394306614064e-05 \n",
      "epoch: 0 [746592/888800 84.00%] train loss: 4.303225432522595e-05 \n",
      "epoch: 0 [747703/888800 84.12%] train loss: 4.6519147872459143e-05 \n",
      "epoch: 0 [748814/888800 84.25%] train loss: 5.0382652261760086e-05 \n",
      "epoch: 0 [749925/888800 84.38%] train loss: 3.693223334266804e-05 \n",
      "epoch: 0 [751036/888800 84.50%] train loss: 4.1137045627692714e-05 \n",
      "epoch: 0 [752147/888800 84.62%] train loss: 5.485676592797972e-05 \n",
      "epoch: 0 [753258/888800 84.75%] train loss: 5.017074727220461e-05 \n",
      "epoch: 0 [754369/888800 84.88%] train loss: 4.991946116206236e-05 \n",
      "epoch: 0 [755480/888800 85.00%] train loss: 3.449158975854516e-05 \n",
      "epoch: 0 [756591/888800 85.12%] train loss: 5.312691064318642e-05 \n",
      "epoch: 0 [757702/888800 85.25%] train loss: 5.272300404612906e-05 \n",
      "epoch: 0 [758813/888800 85.38%] train loss: 5.488297392730601e-05 \n",
      "epoch: 0 [759924/888800 85.50%] train loss: 3.6184639611747116e-05 \n",
      "epoch: 0 [761035/888800 85.62%] train loss: 4.389142486616038e-05 \n",
      "epoch: 0 [762146/888800 85.75%] train loss: 3.6004934372613207e-05 \n",
      "epoch: 0 [763257/888800 85.88%] train loss: 4.339811493991874e-05 \n",
      "epoch: 0 [764368/888800 86.00%] train loss: 5.5153428547782823e-05 \n",
      "epoch: 0 [765479/888800 86.12%] train loss: 5.427880387287587e-05 \n",
      "epoch: 0 [766590/888800 86.25%] train loss: 5.1402326789684594e-05 \n",
      "epoch: 0 [767701/888800 86.38%] train loss: 4.455012458493002e-05 \n",
      "epoch: 0 [768812/888800 86.50%] train loss: 4.734612230095081e-05 \n",
      "epoch: 0 [769923/888800 86.62%] train loss: 4.730412911158055e-05 \n",
      "epoch: 0 [771034/888800 86.75%] train loss: 5.053748463978991e-05 \n",
      "epoch: 0 [772145/888800 86.88%] train loss: 4.775448178406805e-05 \n",
      "epoch: 0 [773256/888800 87.00%] train loss: 4.9731159379007295e-05 \n",
      "epoch: 0 [774367/888800 87.12%] train loss: 5.525028973352164e-05 \n",
      "epoch: 0 [775478/888800 87.25%] train loss: 5.3500574722420424e-05 \n",
      "epoch: 0 [776589/888800 87.38%] train loss: 4.255774547345936e-05 \n",
      "epoch: 0 [777700/888800 87.50%] train loss: 5.658643567585386e-05 \n",
      "epoch: 0 [778811/888800 87.62%] train loss: 3.698081127367914e-05 \n",
      "epoch: 0 [779922/888800 87.75%] train loss: 4.373030242277309e-05 \n",
      "epoch: 0 [781033/888800 87.88%] train loss: 6.319145177258179e-05 \n",
      "epoch: 0 [782144/888800 88.00%] train loss: 4.088140485691838e-05 \n",
      "epoch: 0 [783255/888800 88.12%] train loss: 4.159469244768843e-05 \n",
      "epoch: 0 [784366/888800 88.25%] train loss: 5.408807555795647e-05 \n",
      "epoch: 0 [785477/888800 88.38%] train loss: 4.264772724127397e-05 \n",
      "epoch: 0 [786588/888800 88.50%] train loss: 4.633343269233592e-05 \n",
      "epoch: 0 [787699/888800 88.62%] train loss: 3.9516238757641986e-05 \n",
      "epoch: 0 [788810/888800 88.75%] train loss: 4.270709177944809e-05 \n",
      "epoch: 0 [789921/888800 88.88%] train loss: 5.190295269130729e-05 \n",
      "epoch: 0 [791032/888800 89.00%] train loss: 4.5411048631649464e-05 \n",
      "epoch: 0 [792143/888800 89.12%] train loss: 4.594568599713966e-05 \n",
      "epoch: 0 [793254/888800 89.25%] train loss: 4.1749473894014955e-05 \n",
      "epoch: 0 [794365/888800 89.38%] train loss: 4.5302633225219324e-05 \n",
      "epoch: 0 [795476/888800 89.50%] train loss: 3.995643783127889e-05 \n",
      "epoch: 0 [796587/888800 89.62%] train loss: 4.894744779448956e-05 \n",
      "epoch: 0 [797698/888800 89.75%] train loss: 3.6588331568054855e-05 \n",
      "epoch: 0 [798809/888800 89.88%] train loss: 5.005209459341131e-05 \n",
      "epoch: 0 [799920/888800 90.00%] train loss: 5.2092571422690526e-05 \n",
      "epoch: 0 [801031/888800 90.12%] train loss: 4.4763692130800337e-05 \n",
      "epoch: 0 [802142/888800 90.25%] train loss: 4.994653500034474e-05 \n",
      "epoch: 0 [803253/888800 90.38%] train loss: 5.163904279470444e-05 \n",
      "epoch: 0 [804364/888800 90.50%] train loss: 4.658800025936216e-05 \n",
      "epoch: 0 [805475/888800 90.62%] train loss: 4.25717189500574e-05 \n",
      "epoch: 0 [806586/888800 90.75%] train loss: 3.4973094443557784e-05 \n",
      "epoch: 0 [807697/888800 90.88%] train loss: 4.5543554733740166e-05 \n",
      "epoch: 0 [808808/888800 91.00%] train loss: 4.674333831644617e-05 \n",
      "epoch: 0 [809919/888800 91.12%] train loss: 4.427495150594041e-05 \n",
      "epoch: 0 [811030/888800 91.25%] train loss: 4.647354217013344e-05 \n",
      "epoch: 0 [812141/888800 91.38%] train loss: 3.46167289535515e-05 \n",
      "epoch: 0 [813252/888800 91.50%] train loss: 4.780771632795222e-05 \n",
      "epoch: 0 [814363/888800 91.62%] train loss: 4.734157846542075e-05 \n",
      "epoch: 0 [815474/888800 91.75%] train loss: 4.363772677606903e-05 \n",
      "epoch: 0 [816585/888800 91.88%] train loss: 4.715111572295427e-05 \n",
      "epoch: 0 [817696/888800 92.00%] train loss: 4.6615139581263065e-05 \n",
      "epoch: 0 [818807/888800 92.12%] train loss: 3.946814831579104e-05 \n",
      "epoch: 0 [819918/888800 92.25%] train loss: 4.340694431448355e-05 \n",
      "epoch: 0 [821029/888800 92.38%] train loss: 4.9724465498002246e-05 \n",
      "epoch: 0 [822140/888800 92.50%] train loss: 4.7897465265123174e-05 \n",
      "epoch: 0 [823251/888800 92.62%] train loss: 4.3346284655854106e-05 \n",
      "epoch: 0 [824362/888800 92.75%] train loss: 5.416894055088051e-05 \n",
      "epoch: 0 [825473/888800 92.88%] train loss: 4.301451190258376e-05 \n",
      "epoch: 0 [826584/888800 93.00%] train loss: 4.43813914898783e-05 \n",
      "epoch: 0 [827695/888800 93.12%] train loss: 5.580287688644603e-05 \n",
      "epoch: 0 [828806/888800 93.25%] train loss: 4.6254092012532055e-05 \n",
      "epoch: 0 [829917/888800 93.38%] train loss: 5.572459485847503e-05 \n",
      "epoch: 0 [831028/888800 93.50%] train loss: 5.838917422806844e-05 \n",
      "epoch: 0 [832139/888800 93.62%] train loss: 4.19358657381963e-05 \n",
      "epoch: 0 [833250/888800 93.75%] train loss: 4.7077846829779446e-05 \n",
      "epoch: 0 [834361/888800 93.88%] train loss: 5.268900713417679e-05 \n",
      "epoch: 0 [835472/888800 94.00%] train loss: 4.293065285310149e-05 \n",
      "epoch: 0 [836583/888800 94.12%] train loss: 4.487315163714811e-05 \n",
      "epoch: 0 [837694/888800 94.25%] train loss: 4.7125795390456915e-05 \n",
      "epoch: 0 [838805/888800 94.38%] train loss: 4.687370892497711e-05 \n",
      "epoch: 0 [839916/888800 94.50%] train loss: 4.919900675304234e-05 \n",
      "epoch: 0 [841027/888800 94.62%] train loss: 4.783345139003359e-05 \n",
      "epoch: 0 [842138/888800 94.75%] train loss: 4.3232990719843656e-05 \n",
      "epoch: 0 [843249/888800 94.88%] train loss: 4.240662747179158e-05 \n",
      "epoch: 0 [844360/888800 95.00%] train loss: 4.297242412576452e-05 \n",
      "epoch: 0 [845471/888800 95.12%] train loss: 4.967216227669269e-05 \n",
      "epoch: 0 [846582/888800 95.25%] train loss: 4.2520754504948854e-05 \n",
      "epoch: 0 [847693/888800 95.38%] train loss: 3.72652975784149e-05 \n",
      "epoch: 0 [848804/888800 95.50%] train loss: 5.008499647374265e-05 \n",
      "epoch: 0 [849915/888800 95.62%] train loss: 4.834286664845422e-05 \n",
      "epoch: 0 [851026/888800 95.75%] train loss: 4.351138341007754e-05 \n",
      "epoch: 0 [852137/888800 95.88%] train loss: 3.778532118303701e-05 \n",
      "epoch: 0 [853248/888800 96.00%] train loss: 3.723248664755374e-05 \n",
      "epoch: 0 [854359/888800 96.12%] train loss: 5.382509698392823e-05 \n",
      "epoch: 0 [855470/888800 96.25%] train loss: 4.943954627378844e-05 \n",
      "epoch: 0 [856581/888800 96.38%] train loss: 4.226677629048936e-05 \n",
      "epoch: 0 [857692/888800 96.50%] train loss: 4.6137181925587356e-05 \n",
      "epoch: 0 [858803/888800 96.62%] train loss: 4.3084961362183094e-05 \n",
      "epoch: 0 [859914/888800 96.75%] train loss: 4.3451222154544666e-05 \n",
      "epoch: 0 [861025/888800 96.88%] train loss: 4.195230212644674e-05 \n",
      "epoch: 0 [862136/888800 97.00%] train loss: 4.3839540012413636e-05 \n",
      "epoch: 0 [863247/888800 97.12%] train loss: 4.551609163172543e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [864358/888800 97.25%] train loss: 4.423038990353234e-05 \n",
      "epoch: 0 [865469/888800 97.38%] train loss: 4.8222547775367275e-05 \n",
      "epoch: 0 [866580/888800 97.50%] train loss: 4.77964204037562e-05 \n",
      "epoch: 0 [867691/888800 97.62%] train loss: 4.178200470050797e-05 \n",
      "epoch: 0 [868802/888800 97.75%] train loss: 4.323145549278706e-05 \n",
      "epoch: 0 [869913/888800 97.88%] train loss: 4.165662539890036e-05 \n",
      "epoch: 0 [871024/888800 98.00%] train loss: 4.761098898597993e-05 \n",
      "epoch: 0 [872135/888800 98.12%] train loss: 4.1563140257494524e-05 \n",
      "epoch: 0 [873246/888800 98.25%] train loss: 4.085400723852217e-05 \n",
      "epoch: 0 [874357/888800 98.38%] train loss: 3.923535768990405e-05 \n",
      "epoch: 0 [875468/888800 98.50%] train loss: 3.8446396501967683e-05 \n",
      "epoch: 0 [876579/888800 98.62%] train loss: 4.4331409299047664e-05 \n",
      "epoch: 0 [877690/888800 98.75%] train loss: 4.428927059052512e-05 \n",
      "epoch: 0 [878801/888800 98.88%] train loss: 4.884695226792246e-05 \n",
      "epoch: 0 [879912/888800 99.00%] train loss: 5.240925747784786e-05 \n",
      "epoch: 0 [881023/888800 99.12%] train loss: 4.802930561709218e-05 \n",
      "epoch: 0 [882134/888800 99.25%] train loss: 4.843880014959723e-05 \n",
      "epoch: 0 [883245/888800 99.38%] train loss: 5.1208699005655944e-05 \n",
      "epoch: 0 [884356/888800 99.50%] train loss: 4.361923856777139e-05 \n",
      "epoch: 0 [885467/888800 99.62%] train loss: 5.167989002075046e-05 \n",
      "epoch: 0 [886578/888800 99.75%] train loss: 5.0693914090516046e-05 \n",
      "epoch: 0 [887689/888800 99.88%] train loss: 3.852475492749363e-05 \n",
      "epoch: 1 [0/888800 0.00%] train loss: 4.562341928249225e-05 \n",
      "epoch: 1 [1111/888800 0.12%] train loss: 4.440218617673963e-05 \n",
      "epoch: 1 [2222/888800 0.25%] train loss: 5.540887650568038e-05 \n",
      "epoch: 1 [3333/888800 0.38%] train loss: 4.837237065657973e-05 \n",
      "epoch: 1 [4444/888800 0.50%] train loss: 4.073195668752305e-05 \n",
      "epoch: 1 [5555/888800 0.62%] train loss: 4.667700704885647e-05 \n",
      "epoch: 1 [6666/888800 0.75%] train loss: 4.520657967077568e-05 \n",
      "epoch: 1 [7777/888800 0.88%] train loss: 4.5892982598161325e-05 \n",
      "epoch: 1 [8888/888800 1.00%] train loss: 4.621090192813426e-05 \n",
      "epoch: 1 [9999/888800 1.12%] train loss: 4.671533315558918e-05 \n",
      "epoch: 1 [11110/888800 1.25%] train loss: 4.306894334149547e-05 \n",
      "epoch: 1 [12221/888800 1.38%] train loss: 4.184186036582105e-05 \n",
      "epoch: 1 [13332/888800 1.50%] train loss: 5.004628837923519e-05 \n",
      "epoch: 1 [14443/888800 1.62%] train loss: 4.1369286918779835e-05 \n",
      "epoch: 1 [15554/888800 1.75%] train loss: 3.813824150711298e-05 \n",
      "epoch: 1 [16665/888800 1.88%] train loss: 4.250010897521861e-05 \n",
      "epoch: 1 [17776/888800 2.00%] train loss: 4.6797733375569806e-05 \n",
      "epoch: 1 [18887/888800 2.12%] train loss: 4.71329185529612e-05 \n",
      "epoch: 1 [19998/888800 2.25%] train loss: 5.294482616591267e-05 \n",
      "epoch: 1 [21109/888800 2.38%] train loss: 4.811920734937303e-05 \n",
      "epoch: 1 [22220/888800 2.50%] train loss: 4.5546446926891804e-05 \n",
      "epoch: 1 [23331/888800 2.62%] train loss: 4.3425068724900484e-05 \n",
      "epoch: 1 [24442/888800 2.75%] train loss: 4.345319393905811e-05 \n",
      "epoch: 1 [25553/888800 2.88%] train loss: 4.37890957982745e-05 \n",
      "epoch: 1 [26664/888800 3.00%] train loss: 5.032395347370766e-05 \n",
      "epoch: 1 [27775/888800 3.12%] train loss: 4.699705823441036e-05 \n",
      "epoch: 1 [28886/888800 3.25%] train loss: 4.868643736699596e-05 \n",
      "epoch: 1 [29997/888800 3.38%] train loss: 3.9108621422201395e-05 \n",
      "epoch: 1 [31108/888800 3.50%] train loss: 5.099322515889071e-05 \n",
      "epoch: 1 [32219/888800 3.62%] train loss: 4.126599014853127e-05 \n",
      "epoch: 1 [33330/888800 3.75%] train loss: 4.607791197486222e-05 \n",
      "epoch: 1 [34441/888800 3.88%] train loss: 4.546290801954456e-05 \n",
      "epoch: 1 [35552/888800 4.00%] train loss: 4.179919051239267e-05 \n",
      "epoch: 1 [36663/888800 4.12%] train loss: 4.7457397158723325e-05 \n",
      "epoch: 1 [37774/888800 4.25%] train loss: 4.4206881284480914e-05 \n",
      "epoch: 1 [38885/888800 4.38%] train loss: 3.8671631045872346e-05 \n",
      "epoch: 1 [39996/888800 4.50%] train loss: 4.88442528876476e-05 \n",
      "epoch: 1 [41107/888800 4.62%] train loss: 4.909225754090585e-05 \n",
      "epoch: 1 [42218/888800 4.75%] train loss: 4.749337676912546e-05 \n",
      "epoch: 1 [43329/888800 4.88%] train loss: 4.393115159473382e-05 \n",
      "epoch: 1 [44440/888800 5.00%] train loss: 4.7249082854250446e-05 \n",
      "epoch: 1 [45551/888800 5.12%] train loss: 4.913306111120619e-05 \n",
      "epoch: 1 [46662/888800 5.25%] train loss: 5.211570896790363e-05 \n",
      "epoch: 1 [47773/888800 5.38%] train loss: 4.080732833244838e-05 \n",
      "epoch: 1 [48884/888800 5.50%] train loss: 4.611599069903605e-05 \n",
      "epoch: 1 [49995/888800 5.62%] train loss: 4.773164619109593e-05 \n",
      "epoch: 1 [51106/888800 5.75%] train loss: 5.487975795404054e-05 \n",
      "epoch: 1 [52217/888800 5.88%] train loss: 4.779433220392093e-05 \n",
      "epoch: 1 [53328/888800 6.00%] train loss: 5.028417217545211e-05 \n",
      "epoch: 1 [54439/888800 6.12%] train loss: 4.286849434720352e-05 \n",
      "epoch: 1 [55550/888800 6.25%] train loss: 4.920988794765435e-05 \n",
      "epoch: 1 [56661/888800 6.38%] train loss: 4.0409482608083636e-05 \n",
      "epoch: 1 [57772/888800 6.50%] train loss: 4.3401149014243856e-05 \n",
      "epoch: 1 [58883/888800 6.62%] train loss: 4.3084361095679924e-05 \n",
      "epoch: 1 [59994/888800 6.75%] train loss: 3.934657797799446e-05 \n",
      "epoch: 1 [61105/888800 6.88%] train loss: 5.506894740392454e-05 \n",
      "epoch: 1 [62216/888800 7.00%] train loss: 4.7139430535025895e-05 \n",
      "epoch: 1 [63327/888800 7.12%] train loss: 3.896512498613447e-05 \n",
      "epoch: 1 [64438/888800 7.25%] train loss: 5.2528972446452826e-05 \n",
      "epoch: 1 [65549/888800 7.38%] train loss: 4.713862654170953e-05 \n",
      "epoch: 1 [66660/888800 7.50%] train loss: 5.4288251703837886e-05 \n",
      "epoch: 1 [67771/888800 7.62%] train loss: 4.3083633499918506e-05 \n",
      "epoch: 1 [68882/888800 7.75%] train loss: 4.4519103539641947e-05 \n",
      "epoch: 1 [69993/888800 7.88%] train loss: 5.262790000415407e-05 \n",
      "epoch: 1 [71104/888800 8.00%] train loss: 4.713982343673706e-05 \n",
      "epoch: 1 [72215/888800 8.12%] train loss: 4.9441638111602515e-05 \n",
      "epoch: 1 [73326/888800 8.25%] train loss: 3.758489401661791e-05 \n",
      "epoch: 1 [74437/888800 8.38%] train loss: 3.978188397013582e-05 \n",
      "epoch: 1 [75548/888800 8.50%] train loss: 4.917447586194612e-05 \n",
      "epoch: 1 [76659/888800 8.62%] train loss: 5.462107219500467e-05 \n",
      "epoch: 1 [77770/888800 8.75%] train loss: 3.942701005144045e-05 \n",
      "epoch: 1 [78881/888800 8.88%] train loss: 4.806326614925638e-05 \n",
      "epoch: 1 [79992/888800 9.00%] train loss: 5.2222341764718294e-05 \n",
      "epoch: 1 [81103/888800 9.12%] train loss: 4.1563365812180564e-05 \n",
      "epoch: 1 [82214/888800 9.25%] train loss: 5.549208071897738e-05 \n",
      "epoch: 1 [83325/888800 9.38%] train loss: 5.130498902872205e-05 \n",
      "epoch: 1 [84436/888800 9.50%] train loss: 4.504756725509651e-05 \n",
      "epoch: 1 [85547/888800 9.62%] train loss: 4.6226308768382296e-05 \n",
      "epoch: 1 [86658/888800 9.75%] train loss: 4.517546040005982e-05 \n",
      "epoch: 1 [87769/888800 9.88%] train loss: 3.833010487142019e-05 \n",
      "epoch: 1 [88880/888800 10.00%] train loss: 5.3575040510622784e-05 \n",
      "epoch: 1 [89991/888800 10.12%] train loss: 4.809061283594929e-05 \n",
      "epoch: 1 [91102/888800 10.25%] train loss: 4.557746433420107e-05 \n",
      "epoch: 1 [92213/888800 10.38%] train loss: 4.624067878467031e-05 \n",
      "epoch: 1 [93324/888800 10.50%] train loss: 4.602015178534202e-05 \n",
      "epoch: 1 [94435/888800 10.62%] train loss: 4.43269127572421e-05 \n",
      "epoch: 1 [95546/888800 10.75%] train loss: 3.674450272228569e-05 \n",
      "epoch: 1 [96657/888800 10.88%] train loss: 4.4339263695292175e-05 \n",
      "epoch: 1 [97768/888800 11.00%] train loss: 4.798498048330657e-05 \n",
      "epoch: 1 [98879/888800 11.12%] train loss: 4.428107422427274e-05 \n",
      "epoch: 1 [99990/888800 11.25%] train loss: 5.093666914035566e-05 \n",
      "epoch: 1 [101101/888800 11.38%] train loss: 4.1181625419994816e-05 \n",
      "epoch: 1 [102212/888800 11.50%] train loss: 4.457151590031572e-05 \n",
      "epoch: 1 [103323/888800 11.62%] train loss: 3.7976667954353616e-05 \n",
      "epoch: 1 [104434/888800 11.75%] train loss: 4.041616557515226e-05 \n",
      "epoch: 1 [105545/888800 11.88%] train loss: 4.372777038952336e-05 \n",
      "epoch: 1 [106656/888800 12.00%] train loss: 5.665400021825917e-05 \n",
      "epoch: 1 [107767/888800 12.12%] train loss: 3.93342888855841e-05 \n",
      "epoch: 1 [108878/888800 12.25%] train loss: 5.0886017561424524e-05 \n",
      "epoch: 1 [109989/888800 12.38%] train loss: 4.440743214217946e-05 \n",
      "epoch: 1 [111100/888800 12.50%] train loss: 5.006797073292546e-05 \n",
      "epoch: 1 [112211/888800 12.62%] train loss: 4.555060513666831e-05 \n",
      "epoch: 1 [113322/888800 12.75%] train loss: 4.237651592120528e-05 \n",
      "epoch: 1 [114433/888800 12.88%] train loss: 4.2958658013958484e-05 \n",
      "epoch: 1 [115544/888800 13.00%] train loss: 4.722305675386451e-05 \n",
      "epoch: 1 [116655/888800 13.12%] train loss: 4.641971827368252e-05 \n",
      "epoch: 1 [117766/888800 13.25%] train loss: 5.358244015951641e-05 \n",
      "epoch: 1 [118877/888800 13.38%] train loss: 4.0876508137444034e-05 \n",
      "epoch: 1 [119988/888800 13.50%] train loss: 4.879252446698956e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [121099/888800 13.62%] train loss: 4.6256969653768465e-05 \n",
      "epoch: 1 [122210/888800 13.75%] train loss: 4.9991558626061305e-05 \n",
      "epoch: 1 [123321/888800 13.88%] train loss: 6.172163557494059e-05 \n",
      "epoch: 1 [124432/888800 14.00%] train loss: 4.555845953291282e-05 \n",
      "epoch: 1 [125543/888800 14.12%] train loss: 4.215124135953374e-05 \n",
      "epoch: 1 [126654/888800 14.25%] train loss: 5.080825576442294e-05 \n",
      "epoch: 1 [127765/888800 14.38%] train loss: 4.909605559078045e-05 \n",
      "epoch: 1 [128876/888800 14.50%] train loss: 4.563223774312064e-05 \n",
      "epoch: 1 [129987/888800 14.62%] train loss: 3.876713162753731e-05 \n",
      "epoch: 1 [131098/888800 14.75%] train loss: 4.705888204625808e-05 \n",
      "epoch: 1 [132209/888800 14.88%] train loss: 4.062207881361246e-05 \n",
      "epoch: 1 [133320/888800 15.00%] train loss: 4.7773861297173426e-05 \n",
      "epoch: 1 [134431/888800 15.12%] train loss: 5.4859141528140754e-05 \n",
      "epoch: 1 [135542/888800 15.25%] train loss: 3.760338950087316e-05 \n",
      "epoch: 1 [136653/888800 15.38%] train loss: 5.3664240112993866e-05 \n",
      "epoch: 1 [137764/888800 15.50%] train loss: 4.739479481941089e-05 \n",
      "epoch: 1 [138875/888800 15.62%] train loss: 4.230049307807349e-05 \n",
      "epoch: 1 [139986/888800 15.75%] train loss: 5.086809323984198e-05 \n",
      "epoch: 1 [141097/888800 15.88%] train loss: 4.61357667518314e-05 \n",
      "epoch: 1 [142208/888800 16.00%] train loss: 5.09617239004001e-05 \n",
      "epoch: 1 [143319/888800 16.12%] train loss: 4.600831016432494e-05 \n",
      "epoch: 1 [144430/888800 16.25%] train loss: 4.0115370211424306e-05 \n",
      "epoch: 1 [145541/888800 16.38%] train loss: 4.198600072413683e-05 \n",
      "epoch: 1 [146652/888800 16.50%] train loss: 4.4600903493119404e-05 \n",
      "epoch: 1 [147763/888800 16.62%] train loss: 6.245903205126524e-05 \n",
      "epoch: 1 [148874/888800 16.75%] train loss: 4.978767901775427e-05 \n",
      "epoch: 1 [149985/888800 16.88%] train loss: 5.1184157200623304e-05 \n",
      "epoch: 1 [151096/888800 17.00%] train loss: 4.697290205513127e-05 \n",
      "epoch: 1 [152207/888800 17.12%] train loss: 4.846540468861349e-05 \n",
      "epoch: 1 [153318/888800 17.25%] train loss: 5.533162402571179e-05 \n",
      "epoch: 1 [154429/888800 17.38%] train loss: 4.725351755041629e-05 \n",
      "epoch: 1 [155540/888800 17.50%] train loss: 4.63079268229194e-05 \n",
      "epoch: 1 [156651/888800 17.62%] train loss: 4.917833211948164e-05 \n",
      "epoch: 1 [157762/888800 17.75%] train loss: 3.96053510485217e-05 \n",
      "epoch: 1 [158873/888800 17.88%] train loss: 4.488407648750581e-05 \n",
      "epoch: 1 [159984/888800 18.00%] train loss: 4.6511915570590645e-05 \n",
      "epoch: 1 [161095/888800 18.12%] train loss: 4.117657954338938e-05 \n",
      "epoch: 1 [162206/888800 18.25%] train loss: 4.5102289732312784e-05 \n",
      "epoch: 1 [163317/888800 18.38%] train loss: 4.5281267375685275e-05 \n",
      "epoch: 1 [164428/888800 18.50%] train loss: 5.073679858469404e-05 \n",
      "epoch: 1 [165539/888800 18.62%] train loss: 4.935245306114666e-05 \n",
      "epoch: 1 [166650/888800 18.75%] train loss: 4.9645921535557136e-05 \n",
      "epoch: 1 [167761/888800 18.88%] train loss: 4.362694380688481e-05 \n",
      "epoch: 1 [168872/888800 19.00%] train loss: 4.3237469071755186e-05 \n",
      "epoch: 1 [169983/888800 19.12%] train loss: 4.3883759644813836e-05 \n",
      "epoch: 1 [171094/888800 19.25%] train loss: 3.930350430891849e-05 \n",
      "epoch: 1 [172205/888800 19.38%] train loss: 4.647679816116579e-05 \n",
      "epoch: 1 [173316/888800 19.50%] train loss: 4.718666968983598e-05 \n",
      "epoch: 1 [174427/888800 19.62%] train loss: 4.339316001278348e-05 \n",
      "epoch: 1 [175538/888800 19.75%] train loss: 4.1700724977999926e-05 \n",
      "epoch: 1 [176649/888800 19.88%] train loss: 4.754466499434784e-05 \n",
      "epoch: 1 [177760/888800 20.00%] train loss: 4.67467398266308e-05 \n",
      "epoch: 1 [178871/888800 20.12%] train loss: 4.111393354833126e-05 \n",
      "epoch: 1 [179982/888800 20.25%] train loss: 3.570064654923044e-05 \n",
      "epoch: 1 [181093/888800 20.38%] train loss: 4.739846917800605e-05 \n",
      "epoch: 1 [182204/888800 20.50%] train loss: 4.6687880967510864e-05 \n",
      "epoch: 1 [183315/888800 20.62%] train loss: 4.375842763693072e-05 \n",
      "epoch: 1 [184426/888800 20.75%] train loss: 4.653341602534056e-05 \n",
      "epoch: 1 [185537/888800 20.88%] train loss: 5.036837683292106e-05 \n",
      "epoch: 1 [186648/888800 21.00%] train loss: 4.5185784983914346e-05 \n",
      "epoch: 1 [187759/888800 21.12%] train loss: 4.731443550554104e-05 \n",
      "epoch: 1 [188870/888800 21.25%] train loss: 4.440992051968351e-05 \n",
      "epoch: 1 [189981/888800 21.38%] train loss: 4.576095307129435e-05 \n",
      "epoch: 1 [191092/888800 21.50%] train loss: 3.4724875149549916e-05 \n",
      "epoch: 1 [192203/888800 21.62%] train loss: 4.75358719995711e-05 \n",
      "epoch: 1 [193314/888800 21.75%] train loss: 4.482145232032053e-05 \n",
      "epoch: 1 [194425/888800 21.88%] train loss: 5.1483471906976774e-05 \n",
      "epoch: 1 [195536/888800 22.00%] train loss: 3.928404476027936e-05 \n",
      "epoch: 1 [196647/888800 22.12%] train loss: 4.3028907384723425e-05 \n",
      "epoch: 1 [197758/888800 22.25%] train loss: 4.770673331222497e-05 \n",
      "epoch: 1 [198869/888800 22.38%] train loss: 5.388733552535996e-05 \n",
      "epoch: 1 [199980/888800 22.50%] train loss: 4.3714826460927725e-05 \n",
      "epoch: 1 [201091/888800 22.62%] train loss: 4.19361240346916e-05 \n",
      "epoch: 1 [202202/888800 22.75%] train loss: 4.366978464531712e-05 \n",
      "epoch: 1 [203313/888800 22.88%] train loss: 4.024752706754953e-05 \n",
      "epoch: 1 [204424/888800 23.00%] train loss: 4.12170120398514e-05 \n",
      "epoch: 1 [205535/888800 23.12%] train loss: 4.6597866457886994e-05 \n",
      "epoch: 1 [206646/888800 23.25%] train loss: 5.695203071809374e-05 \n",
      "epoch: 1 [207757/888800 23.38%] train loss: 4.303988680476323e-05 \n",
      "epoch: 1 [208868/888800 23.50%] train loss: 5.06500800838694e-05 \n",
      "epoch: 1 [209979/888800 23.62%] train loss: 4.6848646888975054e-05 \n",
      "epoch: 1 [211090/888800 23.75%] train loss: 4.4838361645815894e-05 \n",
      "epoch: 1 [212201/888800 23.88%] train loss: 5.260547550278716e-05 \n",
      "epoch: 1 [213312/888800 24.00%] train loss: 5.5077332945074886e-05 \n",
      "epoch: 1 [214423/888800 24.12%] train loss: 4.038890256197192e-05 \n",
      "epoch: 1 [215534/888800 24.25%] train loss: 5.366944969864562e-05 \n",
      "epoch: 1 [216645/888800 24.38%] train loss: 4.2954805394401774e-05 \n",
      "epoch: 1 [217756/888800 24.50%] train loss: 5.242773477220908e-05 \n",
      "epoch: 1 [218867/888800 24.62%] train loss: 4.530765727395192e-05 \n",
      "epoch: 1 [219978/888800 24.75%] train loss: 4.8743233492132276e-05 \n",
      "epoch: 1 [221089/888800 24.88%] train loss: 3.9667087548878044e-05 \n",
      "epoch: 1 [222200/888800 25.00%] train loss: 4.2271360143786296e-05 \n",
      "epoch: 1 [223311/888800 25.12%] train loss: 4.693540176958777e-05 \n",
      "epoch: 1 [224422/888800 25.25%] train loss: 4.0870578231988475e-05 \n",
      "epoch: 1 [225533/888800 25.38%] train loss: 4.6661985834361985e-05 \n",
      "epoch: 1 [226644/888800 25.50%] train loss: 4.689266279456206e-05 \n",
      "epoch: 1 [227755/888800 25.62%] train loss: 4.440414340933785e-05 \n",
      "epoch: 1 [228866/888800 25.75%] train loss: 5.7204364566132426e-05 \n",
      "epoch: 1 [229977/888800 25.88%] train loss: 4.981714300811291e-05 \n",
      "epoch: 1 [231088/888800 26.00%] train loss: 4.9380832933820784e-05 \n",
      "epoch: 1 [232199/888800 26.12%] train loss: 3.8191072235349566e-05 \n",
      "epoch: 1 [233310/888800 26.25%] train loss: 4.357862053439021e-05 \n",
      "epoch: 1 [234421/888800 26.38%] train loss: 5.5991040426306427e-05 \n",
      "epoch: 1 [235532/888800 26.50%] train loss: 4.708260894403793e-05 \n",
      "epoch: 1 [236643/888800 26.62%] train loss: 3.682259557535872e-05 \n",
      "epoch: 1 [237754/888800 26.75%] train loss: 4.639313920051791e-05 \n",
      "epoch: 1 [238865/888800 26.88%] train loss: 5.131359648657963e-05 \n",
      "epoch: 1 [239976/888800 27.00%] train loss: 3.7650257581844926e-05 \n",
      "epoch: 1 [241087/888800 27.12%] train loss: 4.2828774894587696e-05 \n",
      "epoch: 1 [242198/888800 27.25%] train loss: 4.092572271474637e-05 \n",
      "epoch: 1 [243309/888800 27.38%] train loss: 4.136625648243353e-05 \n",
      "epoch: 1 [244420/888800 27.50%] train loss: 4.498103589867242e-05 \n",
      "epoch: 1 [245531/888800 27.62%] train loss: 4.90727907163091e-05 \n",
      "epoch: 1 [246642/888800 27.75%] train loss: 4.8382851673522964e-05 \n",
      "epoch: 1 [247753/888800 27.88%] train loss: 4.8472113121533766e-05 \n",
      "epoch: 1 [248864/888800 28.00%] train loss: 4.55397748737596e-05 \n",
      "epoch: 1 [249975/888800 28.12%] train loss: 5.9543552197283134e-05 \n",
      "epoch: 1 [251086/888800 28.25%] train loss: 4.305595939513296e-05 \n",
      "epoch: 1 [252197/888800 28.38%] train loss: 5.0942693633260205e-05 \n",
      "epoch: 1 [253308/888800 28.50%] train loss: 3.566230952856131e-05 \n",
      "epoch: 1 [254419/888800 28.62%] train loss: 4.0495120629202574e-05 \n",
      "epoch: 1 [255530/888800 28.75%] train loss: 4.035096935695037e-05 \n",
      "epoch: 1 [256641/888800 28.88%] train loss: 3.981002373620868e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [257752/888800 29.00%] train loss: 6.086635767132975e-05 \n",
      "epoch: 1 [258863/888800 29.12%] train loss: 4.783663462148979e-05 \n",
      "epoch: 1 [259974/888800 29.25%] train loss: 5.1760922360699624e-05 \n",
      "epoch: 1 [261085/888800 29.38%] train loss: 4.509448990575038e-05 \n",
      "epoch: 1 [262196/888800 29.50%] train loss: 4.676516618928872e-05 \n",
      "epoch: 1 [263307/888800 29.62%] train loss: 4.089700451004319e-05 \n",
      "epoch: 1 [264418/888800 29.75%] train loss: 4.3987773096887395e-05 \n",
      "epoch: 1 [265529/888800 29.88%] train loss: 4.58249487564899e-05 \n",
      "epoch: 1 [266640/888800 30.00%] train loss: 4.154500857111998e-05 \n",
      "epoch: 1 [267751/888800 30.12%] train loss: 4.6349599870154634e-05 \n",
      "epoch: 1 [268862/888800 30.25%] train loss: 4.9145975935971364e-05 \n",
      "epoch: 1 [269973/888800 30.38%] train loss: 3.750235555344261e-05 \n",
      "epoch: 1 [271084/888800 30.50%] train loss: 5.287278690957464e-05 \n",
      "epoch: 1 [272195/888800 30.62%] train loss: 4.7836845624260604e-05 \n",
      "epoch: 1 [273306/888800 30.75%] train loss: 4.7743978939251974e-05 \n",
      "epoch: 1 [274417/888800 30.88%] train loss: 4.09751883125864e-05 \n",
      "epoch: 1 [275528/888800 31.00%] train loss: 5.8435889513930306e-05 \n",
      "epoch: 1 [276639/888800 31.12%] train loss: 5.15992142027244e-05 \n",
      "epoch: 1 [277750/888800 31.25%] train loss: 4.493433880270459e-05 \n",
      "epoch: 1 [278861/888800 31.38%] train loss: 4.851211633649655e-05 \n",
      "epoch: 1 [279972/888800 31.50%] train loss: 4.244320371071808e-05 \n",
      "epoch: 1 [281083/888800 31.62%] train loss: 4.565718336380087e-05 \n",
      "epoch: 1 [282194/888800 31.75%] train loss: 4.167764927842654e-05 \n",
      "epoch: 1 [283305/888800 31.88%] train loss: 4.388486559037119e-05 \n",
      "epoch: 1 [284416/888800 32.00%] train loss: 4.4399756006896496e-05 \n",
      "epoch: 1 [285527/888800 32.12%] train loss: 4.805439311894588e-05 \n",
      "epoch: 1 [286638/888800 32.25%] train loss: 4.550754965748638e-05 \n",
      "epoch: 1 [287749/888800 32.38%] train loss: 4.200520197628066e-05 \n",
      "epoch: 1 [288860/888800 32.50%] train loss: 4.146841820329428e-05 \n",
      "epoch: 1 [289971/888800 32.62%] train loss: 5.4534317314391956e-05 \n",
      "epoch: 1 [291082/888800 32.75%] train loss: 4.5163367758505046e-05 \n",
      "epoch: 1 [292193/888800 32.88%] train loss: 4.2342937376815826e-05 \n",
      "epoch: 1 [293304/888800 33.00%] train loss: 4.197164889774285e-05 \n",
      "epoch: 1 [294415/888800 33.12%] train loss: 4.905249079456553e-05 \n",
      "epoch: 1 [295526/888800 33.25%] train loss: 4.2456646042410284e-05 \n",
      "epoch: 1 [296637/888800 33.38%] train loss: 3.8360121834557503e-05 \n",
      "epoch: 1 [297748/888800 33.50%] train loss: 3.821887730737217e-05 \n",
      "epoch: 1 [298859/888800 33.62%] train loss: 5.6147629948100075e-05 \n",
      "epoch: 1 [299970/888800 33.75%] train loss: 5.1058352255495265e-05 \n",
      "epoch: 1 [301081/888800 33.88%] train loss: 4.934111348120496e-05 \n",
      "epoch: 1 [302192/888800 34.00%] train loss: 4.2999072320526466e-05 \n",
      "epoch: 1 [303303/888800 34.12%] train loss: 5.9104982938151807e-05 \n",
      "epoch: 1 [304414/888800 34.25%] train loss: 4.600026659318246e-05 \n",
      "epoch: 1 [305525/888800 34.38%] train loss: 4.919013736071065e-05 \n",
      "epoch: 1 [306636/888800 34.50%] train loss: 5.0684269808698446e-05 \n",
      "epoch: 1 [307747/888800 34.62%] train loss: 4.444041405804455e-05 \n",
      "epoch: 1 [308858/888800 34.75%] train loss: 4.172832268523052e-05 \n",
      "epoch: 1 [309969/888800 34.88%] train loss: 4.278725100448355e-05 \n",
      "epoch: 1 [311080/888800 35.00%] train loss: 4.912775330012664e-05 \n",
      "epoch: 1 [312191/888800 35.12%] train loss: 5.7606932386988774e-05 \n",
      "epoch: 1 [313302/888800 35.25%] train loss: 4.870953853242099e-05 \n",
      "epoch: 1 [314413/888800 35.38%] train loss: 4.3484771595103666e-05 \n",
      "epoch: 1 [315524/888800 35.50%] train loss: 4.7089943109313026e-05 \n",
      "epoch: 1 [316635/888800 35.62%] train loss: 4.3962030758848414e-05 \n",
      "epoch: 1 [317746/888800 35.75%] train loss: 6.16350444033742e-05 \n",
      "epoch: 1 [318857/888800 35.88%] train loss: 5.4118081607157364e-05 \n",
      "epoch: 1 [319968/888800 36.00%] train loss: 4.806960350833833e-05 \n",
      "epoch: 1 [321079/888800 36.12%] train loss: 4.8186848289333284e-05 \n",
      "epoch: 1 [322190/888800 36.25%] train loss: 4.413819624460302e-05 \n",
      "epoch: 1 [323301/888800 36.38%] train loss: 4.3596290197456256e-05 \n",
      "epoch: 1 [324412/888800 36.50%] train loss: 4.174161222181283e-05 \n",
      "epoch: 1 [325523/888800 36.62%] train loss: 4.1843439248623326e-05 \n",
      "epoch: 1 [326634/888800 36.75%] train loss: 5.028355371905491e-05 \n",
      "epoch: 1 [327745/888800 36.88%] train loss: 4.328284558141604e-05 \n",
      "epoch: 1 [328856/888800 37.00%] train loss: 4.975548290531151e-05 \n",
      "epoch: 1 [329967/888800 37.12%] train loss: 4.918353442917578e-05 \n",
      "epoch: 1 [331078/888800 37.25%] train loss: 4.1335588321089745e-05 \n",
      "epoch: 1 [332189/888800 37.38%] train loss: 4.241560600348748e-05 \n",
      "epoch: 1 [333300/888800 37.50%] train loss: 4.449429252417758e-05 \n",
      "epoch: 1 [334411/888800 37.62%] train loss: 4.893495861324482e-05 \n",
      "epoch: 1 [335522/888800 37.75%] train loss: 3.952971019316465e-05 \n",
      "epoch: 1 [336633/888800 37.88%] train loss: 5.020730532123707e-05 \n",
      "epoch: 1 [337744/888800 38.00%] train loss: 5.119810521136969e-05 \n",
      "epoch: 1 [338855/888800 38.12%] train loss: 4.378087760414928e-05 \n",
      "epoch: 1 [339966/888800 38.25%] train loss: 5.447838339023292e-05 \n",
      "epoch: 1 [341077/888800 38.38%] train loss: 4.4633987272391096e-05 \n",
      "epoch: 1 [342188/888800 38.50%] train loss: 5.058475653640926e-05 \n",
      "epoch: 1 [343299/888800 38.62%] train loss: 5.539904668694362e-05 \n",
      "epoch: 1 [344410/888800 38.75%] train loss: 4.0739483665674925e-05 \n",
      "epoch: 1 [345521/888800 38.88%] train loss: 4.1113027691608295e-05 \n",
      "epoch: 1 [346632/888800 39.00%] train loss: 4.327489295974374e-05 \n",
      "epoch: 1 [347743/888800 39.12%] train loss: 4.753658504341729e-05 \n",
      "epoch: 1 [348854/888800 39.25%] train loss: 4.619357059709728e-05 \n",
      "epoch: 1 [349965/888800 39.38%] train loss: 4.169556996203028e-05 \n",
      "epoch: 1 [351076/888800 39.50%] train loss: 4.0813425584929064e-05 \n",
      "epoch: 1 [352187/888800 39.62%] train loss: 4.1791528929024935e-05 \n",
      "epoch: 1 [353298/888800 39.75%] train loss: 4.3001324229408056e-05 \n",
      "epoch: 1 [354409/888800 39.88%] train loss: 4.709902350441553e-05 \n",
      "epoch: 1 [355520/888800 40.00%] train loss: 5.3436415328178555e-05 \n",
      "epoch: 1 [356631/888800 40.12%] train loss: 4.801394243258983e-05 \n",
      "epoch: 1 [357742/888800 40.25%] train loss: 5.231821705820039e-05 \n",
      "epoch: 1 [358853/888800 40.38%] train loss: 4.424910366651602e-05 \n",
      "epoch: 1 [359964/888800 40.50%] train loss: 4.0234055632026866e-05 \n",
      "epoch: 1 [361075/888800 40.62%] train loss: 3.914360422641039e-05 \n",
      "epoch: 1 [362186/888800 40.75%] train loss: 4.97986729897093e-05 \n",
      "epoch: 1 [363297/888800 40.88%] train loss: 4.223886935506016e-05 \n",
      "epoch: 1 [364408/888800 41.00%] train loss: 4.2164247133769095e-05 \n",
      "epoch: 1 [365519/888800 41.12%] train loss: 4.6709188609384e-05 \n",
      "epoch: 1 [366630/888800 41.25%] train loss: 4.4652475480688736e-05 \n",
      "epoch: 1 [367741/888800 41.38%] train loss: 4.093687311979011e-05 \n",
      "epoch: 1 [368852/888800 41.50%] train loss: 4.4571766920853406e-05 \n",
      "epoch: 1 [369963/888800 41.62%] train loss: 5.576528201345354e-05 \n",
      "epoch: 1 [371074/888800 41.75%] train loss: 4.112691749469377e-05 \n",
      "epoch: 1 [372185/888800 41.88%] train loss: 3.835035749943927e-05 \n",
      "epoch: 1 [373296/888800 42.00%] train loss: 4.774035915033892e-05 \n",
      "epoch: 1 [374407/888800 42.12%] train loss: 4.345623165136203e-05 \n",
      "epoch: 1 [375518/888800 42.25%] train loss: 4.681570135289803e-05 \n",
      "epoch: 1 [376629/888800 42.38%] train loss: 5.22754889971111e-05 \n",
      "epoch: 1 [377740/888800 42.50%] train loss: 4.760706360684708e-05 \n",
      "epoch: 1 [378851/888800 42.62%] train loss: 4.43484605057165e-05 \n",
      "epoch: 1 [379962/888800 42.75%] train loss: 4.443909347173758e-05 \n",
      "epoch: 1 [381073/888800 42.88%] train loss: 4.417382660903968e-05 \n",
      "epoch: 1 [382184/888800 43.00%] train loss: 3.4746506571536884e-05 \n",
      "epoch: 1 [383295/888800 43.12%] train loss: 5.1899583922931924e-05 \n",
      "epoch: 1 [384406/888800 43.25%] train loss: 4.35378824477084e-05 \n",
      "epoch: 1 [385517/888800 43.38%] train loss: 4.812297993339598e-05 \n",
      "epoch: 1 [386628/888800 43.50%] train loss: 4.242299837642349e-05 \n",
      "epoch: 1 [387739/888800 43.62%] train loss: 3.861793447867967e-05 \n",
      "epoch: 1 [388850/888800 43.75%] train loss: 5.3995769121684134e-05 \n",
      "epoch: 1 [389961/888800 43.88%] train loss: 4.898934639641084e-05 \n",
      "epoch: 1 [391072/888800 44.00%] train loss: 5.609364598058164e-05 \n",
      "epoch: 1 [392183/888800 44.12%] train loss: 4.2727617255877703e-05 \n",
      "epoch: 1 [393294/888800 44.25%] train loss: 5.257372322375886e-05 \n",
      "epoch: 1 [394405/888800 44.38%] train loss: 4.790242746821605e-05 \n",
      "epoch: 1 [395516/888800 44.50%] train loss: 4.497185364016332e-05 \n",
      "epoch: 1 [396627/888800 44.62%] train loss: 5.158785643288866e-05 \n",
      "epoch: 1 [397738/888800 44.75%] train loss: 5.276201409287751e-05 \n",
      "epoch: 1 [398849/888800 44.88%] train loss: 4.417115997057408e-05 \n",
      "epoch: 1 [399960/888800 45.00%] train loss: 3.8139187381602824e-05 \n",
      "epoch: 1 [401071/888800 45.12%] train loss: 4.57985297543928e-05 \n",
      "epoch: 1 [402182/888800 45.25%] train loss: 3.6396268114913255e-05 \n",
      "epoch: 1 [403293/888800 45.38%] train loss: 3.9714759623166174e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [404404/888800 45.50%] train loss: 4.3211563024669886e-05 \n",
      "epoch: 1 [405515/888800 45.62%] train loss: 4.532920866040513e-05 \n",
      "epoch: 1 [406626/888800 45.75%] train loss: 4.31434455094859e-05 \n",
      "epoch: 1 [407737/888800 45.88%] train loss: 4.7978523070923984e-05 \n",
      "epoch: 1 [408848/888800 46.00%] train loss: 5.0962207751581445e-05 \n",
      "epoch: 1 [409959/888800 46.12%] train loss: 4.464606536203064e-05 \n",
      "epoch: 1 [411070/888800 46.25%] train loss: 4.12721092288848e-05 \n",
      "epoch: 1 [412181/888800 46.38%] train loss: 4.026709575555287e-05 \n",
      "epoch: 1 [413292/888800 46.50%] train loss: 3.849923814414069e-05 \n",
      "epoch: 1 [414403/888800 46.62%] train loss: 5.1274972065584734e-05 \n",
      "epoch: 1 [415514/888800 46.75%] train loss: 5.033093111705966e-05 \n",
      "epoch: 1 [416625/888800 46.88%] train loss: 4.1433271690038964e-05 \n",
      "epoch: 1 [417736/888800 47.00%] train loss: 4.735460242955014e-05 \n",
      "epoch: 1 [418847/888800 47.12%] train loss: 3.805592859862372e-05 \n",
      "epoch: 1 [419958/888800 47.25%] train loss: 4.020563937956467e-05 \n",
      "epoch: 1 [421069/888800 47.38%] train loss: 4.185416401014663e-05 \n",
      "epoch: 1 [422180/888800 47.50%] train loss: 4.2694991861935705e-05 \n",
      "epoch: 1 [423291/888800 47.62%] train loss: 5.359097849577665e-05 \n",
      "epoch: 1 [424402/888800 47.75%] train loss: 5.051525295129977e-05 \n",
      "epoch: 1 [425513/888800 47.88%] train loss: 5.1219030865468085e-05 \n",
      "epoch: 1 [426624/888800 48.00%] train loss: 4.232639184920117e-05 \n",
      "epoch: 1 [427735/888800 48.12%] train loss: 4.392038317746483e-05 \n",
      "epoch: 1 [428846/888800 48.25%] train loss: 5.00853311677929e-05 \n",
      "epoch: 1 [429957/888800 48.38%] train loss: 4.819964669877663e-05 \n",
      "epoch: 1 [431068/888800 48.50%] train loss: 4.975252886652015e-05 \n",
      "epoch: 1 [432179/888800 48.62%] train loss: 4.201485717203468e-05 \n",
      "epoch: 1 [433290/888800 48.75%] train loss: 3.7290901673259214e-05 \n",
      "epoch: 1 [434401/888800 48.88%] train loss: 4.619521860149689e-05 \n",
      "epoch: 1 [435512/888800 49.00%] train loss: 4.075538527104072e-05 \n",
      "epoch: 1 [436623/888800 49.12%] train loss: 4.336740676080808e-05 \n",
      "epoch: 1 [437734/888800 49.25%] train loss: 4.9803100409917533e-05 \n",
      "epoch: 1 [438845/888800 49.38%] train loss: 5.021528704673983e-05 \n",
      "epoch: 1 [439956/888800 49.50%] train loss: 4.564777191262692e-05 \n",
      "epoch: 1 [441067/888800 49.62%] train loss: 4.044695015181787e-05 \n",
      "epoch: 1 [442178/888800 49.75%] train loss: 4.830780380871147e-05 \n",
      "epoch: 1 [443289/888800 49.88%] train loss: 5.3055991884320974e-05 \n",
      "epoch: 1 [444400/888800 50.00%] train loss: 5.21409856446553e-05 \n",
      "epoch: 1 [445511/888800 50.12%] train loss: 5.2685099944937974e-05 \n",
      "epoch: 1 [446622/888800 50.25%] train loss: 3.64471270586364e-05 \n",
      "epoch: 1 [447733/888800 50.38%] train loss: 5.199977022130042e-05 \n",
      "epoch: 1 [448844/888800 50.50%] train loss: 4.9556147132534534e-05 \n",
      "epoch: 1 [449955/888800 50.62%] train loss: 4.3758769606938586e-05 \n",
      "epoch: 1 [451066/888800 50.75%] train loss: 3.84562554245349e-05 \n",
      "epoch: 1 [452177/888800 50.88%] train loss: 4.031792195746675e-05 \n",
      "epoch: 1 [453288/888800 51.00%] train loss: 4.472946602618322e-05 \n",
      "epoch: 1 [454399/888800 51.12%] train loss: 4.248581899446435e-05 \n",
      "epoch: 1 [455510/888800 51.25%] train loss: 4.610557516571134e-05 \n",
      "epoch: 1 [456621/888800 51.38%] train loss: 4.4434807932702824e-05 \n",
      "epoch: 1 [457732/888800 51.50%] train loss: 5.1006150897592306e-05 \n",
      "epoch: 1 [458843/888800 51.62%] train loss: 4.829777026316151e-05 \n",
      "epoch: 1 [459954/888800 51.75%] train loss: 5.393470200942829e-05 \n",
      "epoch: 1 [461065/888800 51.88%] train loss: 4.899519990431145e-05 \n",
      "epoch: 1 [462176/888800 52.00%] train loss: 4.6481582103297114e-05 \n",
      "epoch: 1 [463287/888800 52.12%] train loss: 4.390348112792708e-05 \n",
      "epoch: 1 [464398/888800 52.25%] train loss: 3.994997314293869e-05 \n",
      "epoch: 1 [465509/888800 52.38%] train loss: 4.689133493229747e-05 \n",
      "epoch: 1 [466620/888800 52.50%] train loss: 5.002189936931245e-05 \n",
      "epoch: 1 [467731/888800 52.62%] train loss: 4.952789458911866e-05 \n",
      "epoch: 1 [468842/888800 52.75%] train loss: 4.821209222427569e-05 \n",
      "epoch: 1 [469953/888800 52.88%] train loss: 5.226082794251852e-05 \n",
      "epoch: 1 [471064/888800 53.00%] train loss: 4.104219260625541e-05 \n",
      "epoch: 1 [472175/888800 53.12%] train loss: 4.168678060523234e-05 \n",
      "epoch: 1 [473286/888800 53.25%] train loss: 4.527708006207831e-05 \n",
      "epoch: 1 [474397/888800 53.38%] train loss: 4.591303877532482e-05 \n",
      "epoch: 1 [475508/888800 53.50%] train loss: 4.837767482968047e-05 \n",
      "epoch: 1 [476619/888800 53.62%] train loss: 3.871371518471278e-05 \n",
      "epoch: 1 [477730/888800 53.75%] train loss: 4.6995752200018615e-05 \n",
      "epoch: 1 [478841/888800 53.88%] train loss: 4.1169681935571134e-05 \n",
      "epoch: 1 [479952/888800 54.00%] train loss: 4.2773910536197945e-05 \n",
      "epoch: 1 [481063/888800 54.12%] train loss: 3.991337871411815e-05 \n",
      "epoch: 1 [482174/888800 54.25%] train loss: 3.771582851186395e-05 \n",
      "epoch: 1 [483285/888800 54.38%] train loss: 4.500742943491787e-05 \n",
      "epoch: 1 [484396/888800 54.50%] train loss: 4.06475955969654e-05 \n",
      "epoch: 1 [485507/888800 54.62%] train loss: 4.516009721555747e-05 \n",
      "epoch: 1 [486618/888800 54.75%] train loss: 3.373902654857375e-05 \n",
      "epoch: 1 [487729/888800 54.88%] train loss: 5.371788938646205e-05 \n",
      "epoch: 1 [488840/888800 55.00%] train loss: 4.667094617616385e-05 \n",
      "epoch: 1 [489951/888800 55.12%] train loss: 4.749884465127252e-05 \n",
      "epoch: 1 [491062/888800 55.25%] train loss: 4.8680838517611846e-05 \n",
      "epoch: 1 [492173/888800 55.38%] train loss: 4.159008676651865e-05 \n",
      "epoch: 1 [493284/888800 55.50%] train loss: 4.728321073343977e-05 \n",
      "epoch: 1 [494395/888800 55.62%] train loss: 4.90039456053637e-05 \n",
      "epoch: 1 [495506/888800 55.75%] train loss: 4.54939654446207e-05 \n",
      "epoch: 1 [496617/888800 55.88%] train loss: 5.030075408285484e-05 \n",
      "epoch: 1 [497728/888800 56.00%] train loss: 4.9549515097169206e-05 \n",
      "epoch: 1 [498839/888800 56.12%] train loss: 4.044126399094239e-05 \n",
      "epoch: 1 [499950/888800 56.25%] train loss: 5.270822293823585e-05 \n",
      "epoch: 1 [501061/888800 56.38%] train loss: 3.580648626666516e-05 \n",
      "epoch: 1 [502172/888800 56.50%] train loss: 4.3468400690471753e-05 \n",
      "epoch: 1 [503283/888800 56.62%] train loss: 4.610219184542075e-05 \n",
      "epoch: 1 [504394/888800 56.75%] train loss: 5.470417454489507e-05 \n",
      "epoch: 1 [505505/888800 56.88%] train loss: 4.4019034248776734e-05 \n",
      "epoch: 1 [506616/888800 57.00%] train loss: 4.651877679862082e-05 \n",
      "epoch: 1 [507727/888800 57.12%] train loss: 4.140499004279263e-05 \n",
      "epoch: 1 [508838/888800 57.25%] train loss: 4.791867468156852e-05 \n",
      "epoch: 1 [509949/888800 57.38%] train loss: 4.2101750295842066e-05 \n",
      "epoch: 1 [511060/888800 57.50%] train loss: 3.820926576736383e-05 \n",
      "epoch: 1 [512171/888800 57.62%] train loss: 4.620210165739991e-05 \n",
      "epoch: 1 [513282/888800 57.75%] train loss: 4.6621018555015326e-05 \n",
      "epoch: 1 [514393/888800 57.88%] train loss: 4.3154235754627734e-05 \n",
      "epoch: 1 [515504/888800 58.00%] train loss: 5.240314203547314e-05 \n",
      "epoch: 1 [516615/888800 58.12%] train loss: 5.0141479732701555e-05 \n",
      "epoch: 1 [517726/888800 58.25%] train loss: 3.728482624865137e-05 \n",
      "epoch: 1 [518837/888800 58.38%] train loss: 5.1394919864833355e-05 \n",
      "epoch: 1 [519948/888800 58.50%] train loss: 4.4088232243666425e-05 \n",
      "epoch: 1 [521059/888800 58.62%] train loss: 4.4995384087087587e-05 \n",
      "epoch: 1 [522170/888800 58.75%] train loss: 5.044788122177124e-05 \n",
      "epoch: 1 [523281/888800 58.88%] train loss: 5.064829019829631e-05 \n",
      "epoch: 1 [524392/888800 59.00%] train loss: 3.7485478969756514e-05 \n",
      "epoch: 1 [525503/888800 59.12%] train loss: 4.703122976934537e-05 \n",
      "epoch: 1 [526614/888800 59.25%] train loss: 5.3887641115579754e-05 \n",
      "epoch: 1 [527725/888800 59.38%] train loss: 4.2717034375527874e-05 \n",
      "epoch: 1 [528836/888800 59.50%] train loss: 4.328196882852353e-05 \n",
      "epoch: 1 [529947/888800 59.62%] train loss: 5.385775148170069e-05 \n",
      "epoch: 1 [531058/888800 59.75%] train loss: 4.6130742703098804e-05 \n",
      "epoch: 1 [532169/888800 59.88%] train loss: 4.756749331136234e-05 \n",
      "epoch: 1 [533280/888800 60.00%] train loss: 4.8472116759512573e-05 \n",
      "epoch: 1 [534391/888800 60.12%] train loss: 4.288617492420599e-05 \n",
      "epoch: 1 [535502/888800 60.25%] train loss: 4.282675581634976e-05 \n",
      "epoch: 1 [536613/888800 60.38%] train loss: 3.462781387497671e-05 \n",
      "epoch: 1 [537724/888800 60.50%] train loss: 5.049297396908514e-05 \n",
      "epoch: 1 [538835/888800 60.62%] train loss: 3.9987804484553635e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [539946/888800 60.75%] train loss: 4.440303018782288e-05 \n",
      "epoch: 1 [541057/888800 60.88%] train loss: 4.996208008378744e-05 \n",
      "epoch: 1 [542168/888800 61.00%] train loss: 4.552836617222056e-05 \n",
      "epoch: 1 [543279/888800 61.12%] train loss: 4.657141471398063e-05 \n",
      "epoch: 1 [544390/888800 61.25%] train loss: 4.319387880968861e-05 \n",
      "epoch: 1 [545501/888800 61.38%] train loss: 5.163311288924888e-05 \n",
      "epoch: 1 [546612/888800 61.50%] train loss: 5.5529908422613516e-05 \n",
      "epoch: 1 [547723/888800 61.62%] train loss: 4.417543823365122e-05 \n",
      "epoch: 1 [548834/888800 61.75%] train loss: 4.217581226839684e-05 \n",
      "epoch: 1 [549945/888800 61.88%] train loss: 4.377830555313267e-05 \n",
      "epoch: 1 [551056/888800 62.00%] train loss: 4.5050499466015026e-05 \n",
      "epoch: 1 [552167/888800 62.12%] train loss: 4.488707782002166e-05 \n",
      "epoch: 1 [553278/888800 62.25%] train loss: 4.93673505843617e-05 \n",
      "epoch: 1 [554389/888800 62.38%] train loss: 4.471474312595092e-05 \n",
      "epoch: 1 [555500/888800 62.50%] train loss: 3.4108947147615254e-05 \n",
      "epoch: 1 [556611/888800 62.62%] train loss: 3.453125464147888e-05 \n",
      "epoch: 1 [557722/888800 62.75%] train loss: 4.7943733079591766e-05 \n",
      "epoch: 1 [558833/888800 62.88%] train loss: 4.131680179852992e-05 \n",
      "epoch: 1 [559944/888800 63.00%] train loss: 4.878340769209899e-05 \n",
      "epoch: 1 [561055/888800 63.12%] train loss: 4.714361421065405e-05 \n",
      "epoch: 1 [562166/888800 63.25%] train loss: 4.3010470108129084e-05 \n",
      "epoch: 1 [563277/888800 63.38%] train loss: 3.790351183852181e-05 \n",
      "epoch: 1 [564388/888800 63.50%] train loss: 3.6979687138227746e-05 \n",
      "epoch: 1 [565499/888800 63.62%] train loss: 5.5719861848047e-05 \n",
      "epoch: 1 [566610/888800 63.75%] train loss: 4.792037725565024e-05 \n",
      "epoch: 1 [567721/888800 63.88%] train loss: 4.2943407606799155e-05 \n",
      "epoch: 1 [568832/888800 64.00%] train loss: 4.251088830642402e-05 \n",
      "epoch: 1 [569943/888800 64.12%] train loss: 4.57795467809774e-05 \n",
      "epoch: 1 [571054/888800 64.25%] train loss: 4.367390647530556e-05 \n",
      "epoch: 1 [572165/888800 64.38%] train loss: 4.713249654741958e-05 \n",
      "epoch: 1 [573276/888800 64.50%] train loss: 4.817734588868916e-05 \n",
      "epoch: 1 [574387/888800 64.62%] train loss: 4.28727398684714e-05 \n",
      "epoch: 1 [575498/888800 64.75%] train loss: 4.482762233237736e-05 \n",
      "epoch: 1 [576609/888800 64.88%] train loss: 3.7329366023186594e-05 \n",
      "epoch: 1 [577720/888800 65.00%] train loss: 3.5098990338156e-05 \n",
      "epoch: 1 [578831/888800 65.12%] train loss: 4.600380998454057e-05 \n",
      "epoch: 1 [579942/888800 65.25%] train loss: 4.055324461660348e-05 \n",
      "epoch: 1 [581053/888800 65.38%] train loss: 5.9706755564548075e-05 \n",
      "epoch: 1 [582164/888800 65.50%] train loss: 4.553550752461888e-05 \n",
      "epoch: 1 [583275/888800 65.62%] train loss: 3.8292269891826436e-05 \n",
      "epoch: 1 [584386/888800 65.75%] train loss: 5.183844405109994e-05 \n",
      "epoch: 1 [585497/888800 65.88%] train loss: 4.0154412999982014e-05 \n",
      "epoch: 1 [586608/888800 66.00%] train loss: 4.385220381664112e-05 \n",
      "epoch: 1 [587719/888800 66.12%] train loss: 4.426620580488816e-05 \n",
      "epoch: 1 [588830/888800 66.25%] train loss: 4.1815645090537146e-05 \n",
      "epoch: 1 [589941/888800 66.38%] train loss: 4.136180359637365e-05 \n",
      "epoch: 1 [591052/888800 66.50%] train loss: 4.529435682343319e-05 \n",
      "epoch: 1 [592163/888800 66.62%] train loss: 4.593663470586762e-05 \n",
      "epoch: 1 [593274/888800 66.75%] train loss: 4.727458508568816e-05 \n",
      "epoch: 1 [594385/888800 66.88%] train loss: 4.98738772876095e-05 \n",
      "epoch: 1 [595496/888800 67.00%] train loss: 5.17024818691425e-05 \n",
      "epoch: 1 [596607/888800 67.12%] train loss: 4.6010729420231655e-05 \n",
      "epoch: 1 [597718/888800 67.25%] train loss: 5.298223186400719e-05 \n",
      "epoch: 1 [598829/888800 67.38%] train loss: 4.788810474565253e-05 \n",
      "epoch: 1 [599940/888800 67.50%] train loss: 4.462502329261042e-05 \n",
      "epoch: 1 [601051/888800 67.62%] train loss: 5.476434307638556e-05 \n",
      "epoch: 1 [602162/888800 67.75%] train loss: 4.5854380005039275e-05 \n",
      "epoch: 1 [603273/888800 67.88%] train loss: 4.109538713237271e-05 \n",
      "epoch: 1 [604384/888800 68.00%] train loss: 4.566224379232153e-05 \n",
      "epoch: 1 [605495/888800 68.12%] train loss: 4.9649537686491385e-05 \n",
      "epoch: 1 [606606/888800 68.25%] train loss: 4.2434054194018245e-05 \n",
      "epoch: 1 [607717/888800 68.38%] train loss: 4.720970900962129e-05 \n",
      "epoch: 1 [608828/888800 68.50%] train loss: 5.126619362272322e-05 \n",
      "epoch: 1 [609939/888800 68.62%] train loss: 4.048353366670199e-05 \n",
      "epoch: 1 [611050/888800 68.75%] train loss: 4.5809247239958495e-05 \n",
      "epoch: 1 [612161/888800 68.88%] train loss: 4.821507536689751e-05 \n",
      "epoch: 1 [613272/888800 69.00%] train loss: 4.6602832298958674e-05 \n",
      "epoch: 1 [614383/888800 69.12%] train loss: 5.368520942283794e-05 \n",
      "epoch: 1 [615494/888800 69.25%] train loss: 5.94184675719589e-05 \n",
      "epoch: 1 [616605/888800 69.38%] train loss: 3.391478821868077e-05 \n",
      "epoch: 1 [617716/888800 69.50%] train loss: 4.492737934924662e-05 \n",
      "epoch: 1 [618827/888800 69.62%] train loss: 4.6860564907547086e-05 \n",
      "epoch: 1 [619938/888800 69.75%] train loss: 4.8029822210082784e-05 \n",
      "epoch: 1 [621049/888800 69.88%] train loss: 4.66612764284946e-05 \n",
      "epoch: 1 [622160/888800 70.00%] train loss: 4.903720036963932e-05 \n",
      "epoch: 1 [623271/888800 70.12%] train loss: 4.360928141977638e-05 \n",
      "epoch: 1 [624382/888800 70.25%] train loss: 4.6856712287990376e-05 \n",
      "epoch: 1 [625493/888800 70.38%] train loss: 5.414374027168378e-05 \n",
      "epoch: 1 [626604/888800 70.50%] train loss: 4.0053389966487885e-05 \n",
      "epoch: 1 [627715/888800 70.62%] train loss: 4.792738036485389e-05 \n",
      "epoch: 1 [628826/888800 70.75%] train loss: 5.2666346164187416e-05 \n",
      "epoch: 1 [629937/888800 70.88%] train loss: 4.258407716406509e-05 \n",
      "epoch: 1 [631048/888800 71.00%] train loss: 5.1297851314302534e-05 \n",
      "epoch: 1 [632159/888800 71.12%] train loss: 4.10992834076751e-05 \n",
      "epoch: 1 [633270/888800 71.25%] train loss: 4.987591091776267e-05 \n",
      "epoch: 1 [634381/888800 71.38%] train loss: 4.826808799407445e-05 \n",
      "epoch: 1 [635492/888800 71.50%] train loss: 4.1394869185751304e-05 \n",
      "epoch: 1 [636603/888800 71.62%] train loss: 3.981525878771208e-05 \n",
      "epoch: 1 [637714/888800 71.75%] train loss: 5.141450674273074e-05 \n",
      "epoch: 1 [638825/888800 71.88%] train loss: 4.905203604721464e-05 \n",
      "epoch: 1 [639936/888800 72.00%] train loss: 4.1887211409630254e-05 \n",
      "epoch: 1 [641047/888800 72.12%] train loss: 4.295439794077538e-05 \n",
      "epoch: 1 [642158/888800 72.25%] train loss: 4.457111572264694e-05 \n",
      "epoch: 1 [643269/888800 72.38%] train loss: 4.000879926024936e-05 \n",
      "epoch: 1 [644380/888800 72.50%] train loss: 4.599013482220471e-05 \n",
      "epoch: 1 [645491/888800 72.62%] train loss: 5.592970046564005e-05 \n",
      "epoch: 1 [646602/888800 72.75%] train loss: 4.3897507566725835e-05 \n",
      "epoch: 1 [647713/888800 72.88%] train loss: 4.6202654630178586e-05 \n",
      "epoch: 1 [648824/888800 73.00%] train loss: 5.075133594800718e-05 \n",
      "epoch: 1 [649935/888800 73.12%] train loss: 4.901564898318611e-05 \n",
      "epoch: 1 [651046/888800 73.25%] train loss: 5.176907143322751e-05 \n",
      "epoch: 1 [652157/888800 73.38%] train loss: 4.609179813996889e-05 \n",
      "epoch: 1 [653268/888800 73.50%] train loss: 4.3655494664562866e-05 \n",
      "epoch: 1 [654379/888800 73.62%] train loss: 4.3310461478540674e-05 \n",
      "epoch: 1 [655490/888800 73.75%] train loss: 3.950805330532603e-05 \n",
      "epoch: 1 [656601/888800 73.88%] train loss: 4.541127782431431e-05 \n",
      "epoch: 1 [657712/888800 74.00%] train loss: 4.4964799599256366e-05 \n",
      "epoch: 1 [658823/888800 74.12%] train loss: 4.1009290725924075e-05 \n",
      "epoch: 1 [659934/888800 74.25%] train loss: 4.17709925386589e-05 \n",
      "epoch: 1 [661045/888800 74.38%] train loss: 3.882839155266993e-05 \n",
      "epoch: 1 [662156/888800 74.50%] train loss: 4.053097291034646e-05 \n",
      "epoch: 1 [663267/888800 74.62%] train loss: 4.9848917115014046e-05 \n",
      "epoch: 1 [664378/888800 74.75%] train loss: 3.258793003624305e-05 \n",
      "epoch: 1 [665489/888800 74.88%] train loss: 4.00375975004863e-05 \n",
      "epoch: 1 [666600/888800 75.00%] train loss: 4.749363870359957e-05 \n",
      "epoch: 1 [667711/888800 75.12%] train loss: 4.7963236283976585e-05 \n",
      "epoch: 1 [668822/888800 75.25%] train loss: 5.1095328672090545e-05 \n",
      "epoch: 1 [669933/888800 75.38%] train loss: 4.306977643864229e-05 \n",
      "epoch: 1 [671044/888800 75.50%] train loss: 4.12072658946272e-05 \n",
      "epoch: 1 [672155/888800 75.62%] train loss: 4.1045677789952606e-05 \n",
      "epoch: 1 [673266/888800 75.75%] train loss: 4.85520031361375e-05 \n",
      "epoch: 1 [674377/888800 75.88%] train loss: 3.874043977702968e-05 \n",
      "epoch: 1 [675488/888800 76.00%] train loss: 4.9933965783566236e-05 \n",
      "epoch: 1 [676599/888800 76.12%] train loss: 4.648902176995762e-05 \n",
      "epoch: 1 [677710/888800 76.25%] train loss: 4.639978942577727e-05 \n",
      "epoch: 1 [678821/888800 76.38%] train loss: 5.094407242722809e-05 \n",
      "epoch: 1 [679932/888800 76.50%] train loss: 4.0729639295022935e-05 \n",
      "epoch: 1 [681043/888800 76.62%] train loss: 5.3411171393236145e-05 \n",
      "epoch: 1 [682154/888800 76.75%] train loss: 3.9688766264589503e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [683265/888800 76.88%] train loss: 3.6027689930051565e-05 \n",
      "epoch: 1 [684376/888800 77.00%] train loss: 4.461437129066326e-05 \n",
      "epoch: 1 [685487/888800 77.12%] train loss: 4.7419343900401145e-05 \n",
      "epoch: 1 [686598/888800 77.25%] train loss: 6.094879427109845e-05 \n",
      "epoch: 1 [687709/888800 77.38%] train loss: 3.953724808525294e-05 \n",
      "epoch: 1 [688820/888800 77.50%] train loss: 3.866750921588391e-05 \n",
      "epoch: 1 [689931/888800 77.62%] train loss: 4.811435428564437e-05 \n",
      "epoch: 1 [691042/888800 77.75%] train loss: 4.296300176065415e-05 \n",
      "epoch: 1 [692153/888800 77.88%] train loss: 4.6507961087627336e-05 \n",
      "epoch: 1 [693264/888800 78.00%] train loss: 4.6535682486137375e-05 \n",
      "epoch: 1 [694375/888800 78.12%] train loss: 5.499165126821026e-05 \n",
      "epoch: 1 [695486/888800 78.25%] train loss: 5.171126394998282e-05 \n",
      "epoch: 1 [696597/888800 78.38%] train loss: 3.977039159508422e-05 \n",
      "epoch: 1 [697708/888800 78.50%] train loss: 3.850643406622112e-05 \n",
      "epoch: 1 [698819/888800 78.62%] train loss: 3.9609407394891605e-05 \n",
      "epoch: 1 [699930/888800 78.75%] train loss: 3.59301884600427e-05 \n",
      "epoch: 1 [701041/888800 78.88%] train loss: 4.6086031943559647e-05 \n",
      "epoch: 1 [702152/888800 79.00%] train loss: 4.457709292182699e-05 \n",
      "epoch: 1 [703263/888800 79.12%] train loss: 4.717574847745709e-05 \n",
      "epoch: 1 [704374/888800 79.25%] train loss: 5.119054185342975e-05 \n",
      "epoch: 1 [705485/888800 79.38%] train loss: 5.116781176184304e-05 \n",
      "epoch: 1 [706596/888800 79.50%] train loss: 4.502995579969138e-05 \n",
      "epoch: 1 [707707/888800 79.62%] train loss: 3.5042117815464735e-05 \n",
      "epoch: 1 [708818/888800 79.75%] train loss: 4.620651816367172e-05 \n",
      "epoch: 1 [709929/888800 79.88%] train loss: 4.93900733999908e-05 \n",
      "epoch: 1 [711040/888800 80.00%] train loss: 4.817195440409705e-05 \n",
      "epoch: 1 [712151/888800 80.12%] train loss: 4.461173739400692e-05 \n",
      "epoch: 1 [713262/888800 80.25%] train loss: 4.42603268311359e-05 \n",
      "epoch: 1 [714373/888800 80.38%] train loss: 4.617409285856411e-05 \n",
      "epoch: 1 [715484/888800 80.50%] train loss: 4.580887980409898e-05 \n",
      "epoch: 1 [716595/888800 80.62%] train loss: 4.2842286347877234e-05 \n",
      "epoch: 1 [717706/888800 80.75%] train loss: 4.709118729806505e-05 \n",
      "epoch: 1 [718817/888800 80.88%] train loss: 4.5138051063986495e-05 \n",
      "epoch: 1 [719928/888800 81.00%] train loss: 4.621198968379758e-05 \n",
      "epoch: 1 [721039/888800 81.12%] train loss: 3.6333298339741305e-05 \n",
      "epoch: 1 [722150/888800 81.25%] train loss: 4.352641917648725e-05 \n",
      "epoch: 1 [723261/888800 81.38%] train loss: 4.2769806896103546e-05 \n",
      "epoch: 1 [724372/888800 81.50%] train loss: 4.583016561809927e-05 \n",
      "epoch: 1 [725483/888800 81.62%] train loss: 4.7495512262685224e-05 \n",
      "epoch: 1 [726594/888800 81.75%] train loss: 4.067220288561657e-05 \n",
      "epoch: 1 [727705/888800 81.88%] train loss: 4.670387352234684e-05 \n",
      "epoch: 1 [728816/888800 82.00%] train loss: 4.1001221688929945e-05 \n",
      "epoch: 1 [729927/888800 82.12%] train loss: 4.5443019189406186e-05 \n",
      "epoch: 1 [731038/888800 82.25%] train loss: 4.30975342169404e-05 \n",
      "epoch: 1 [732149/888800 82.38%] train loss: 4.603584238793701e-05 \n",
      "epoch: 1 [733260/888800 82.50%] train loss: 3.868167186737992e-05 \n",
      "epoch: 1 [734371/888800 82.62%] train loss: 5.0224363803863525e-05 \n",
      "epoch: 1 [735482/888800 82.75%] train loss: 4.1404273360967636e-05 \n",
      "epoch: 1 [736593/888800 82.88%] train loss: 5.140835855854675e-05 \n",
      "epoch: 1 [737704/888800 83.00%] train loss: 4.843689384870231e-05 \n",
      "epoch: 1 [738815/888800 83.12%] train loss: 4.126314161112532e-05 \n",
      "epoch: 1 [739926/888800 83.25%] train loss: 4.088838613824919e-05 \n",
      "epoch: 1 [741037/888800 83.38%] train loss: 5.621600939775817e-05 \n",
      "epoch: 1 [742148/888800 83.50%] train loss: 4.842400812776759e-05 \n",
      "epoch: 1 [743259/888800 83.62%] train loss: 4.591114338836633e-05 \n",
      "epoch: 1 [744370/888800 83.75%] train loss: 5.005023194826208e-05 \n",
      "epoch: 1 [745481/888800 83.88%] train loss: 5.369907012209296e-05 \n",
      "epoch: 1 [746592/888800 84.00%] train loss: 4.127176362089813e-05 \n",
      "epoch: 1 [747703/888800 84.12%] train loss: 4.1154595237458125e-05 \n",
      "epoch: 1 [748814/888800 84.25%] train loss: 4.546718264464289e-05 \n",
      "epoch: 1 [749925/888800 84.38%] train loss: 4.220328264636919e-05 \n",
      "epoch: 1 [751036/888800 84.50%] train loss: 4.4832304411102086e-05 \n",
      "epoch: 1 [752147/888800 84.62%] train loss: 4.755168265546672e-05 \n",
      "epoch: 1 [753258/888800 84.75%] train loss: 4.4736661948263645e-05 \n",
      "epoch: 1 [754369/888800 84.88%] train loss: 3.8787013181718066e-05 \n",
      "epoch: 1 [755480/888800 85.00%] train loss: 4.2890795157290995e-05 \n",
      "epoch: 1 [756591/888800 85.12%] train loss: 4.0942290070233867e-05 \n",
      "epoch: 1 [757702/888800 85.25%] train loss: 6.574513827217743e-05 \n",
      "epoch: 1 [758813/888800 85.38%] train loss: 4.187194281257689e-05 \n",
      "epoch: 1 [759924/888800 85.50%] train loss: 5.4765423556091264e-05 \n",
      "epoch: 1 [761035/888800 85.62%] train loss: 4.163592529948801e-05 \n",
      "epoch: 1 [762146/888800 85.75%] train loss: 4.566305869957432e-05 \n",
      "epoch: 1 [763257/888800 85.88%] train loss: 3.862799712806009e-05 \n",
      "epoch: 1 [764368/888800 86.00%] train loss: 4.614159479388036e-05 \n",
      "epoch: 1 [765479/888800 86.12%] train loss: 4.418225944391452e-05 \n",
      "epoch: 1 [766590/888800 86.25%] train loss: 4.179897587164305e-05 \n",
      "epoch: 1 [767701/888800 86.38%] train loss: 4.2503452277742326e-05 \n",
      "epoch: 1 [768812/888800 86.50%] train loss: 4.548828292172402e-05 \n",
      "epoch: 1 [769923/888800 86.62%] train loss: 3.6196310247760266e-05 \n",
      "epoch: 1 [771034/888800 86.75%] train loss: 3.666962220449932e-05 \n",
      "epoch: 1 [772145/888800 86.88%] train loss: 5.09254023199901e-05 \n",
      "epoch: 1 [773256/888800 87.00%] train loss: 4.750187144964002e-05 \n",
      "epoch: 1 [774367/888800 87.12%] train loss: 5.044792123953812e-05 \n",
      "epoch: 1 [775478/888800 87.25%] train loss: 4.992649337509647e-05 \n",
      "epoch: 1 [776589/888800 87.38%] train loss: 4.10354659834411e-05 \n",
      "epoch: 1 [777700/888800 87.50%] train loss: 5.480901381815784e-05 \n",
      "epoch: 1 [778811/888800 87.62%] train loss: 4.40466683357954e-05 \n",
      "epoch: 1 [779922/888800 87.75%] train loss: 4.2801329982466996e-05 \n",
      "epoch: 1 [781033/888800 87.88%] train loss: 5.6309570936718956e-05 \n",
      "epoch: 1 [782144/888800 88.00%] train loss: 3.999305044999346e-05 \n",
      "epoch: 1 [783255/888800 88.12%] train loss: 4.3070976971648633e-05 \n",
      "epoch: 1 [784366/888800 88.25%] train loss: 5.32472477061674e-05 \n",
      "epoch: 1 [785477/888800 88.38%] train loss: 5.7739827752811834e-05 \n",
      "epoch: 1 [786588/888800 88.50%] train loss: 4.5191853132564574e-05 \n",
      "epoch: 1 [787699/888800 88.62%] train loss: 4.644824730348773e-05 \n",
      "epoch: 1 [788810/888800 88.75%] train loss: 4.107405402464792e-05 \n",
      "epoch: 1 [789921/888800 88.88%] train loss: 5.404416879173368e-05 \n",
      "epoch: 1 [791032/888800 89.00%] train loss: 4.205495861242525e-05 \n",
      "epoch: 1 [792143/888800 89.12%] train loss: 3.9188806113088503e-05 \n",
      "epoch: 1 [793254/888800 89.25%] train loss: 4.6738852688577026e-05 \n",
      "epoch: 1 [794365/888800 89.38%] train loss: 4.251789141562767e-05 \n",
      "epoch: 1 [795476/888800 89.50%] train loss: 4.8948459152597934e-05 \n",
      "epoch: 1 [796587/888800 89.62%] train loss: 4.755230474984273e-05 \n",
      "epoch: 1 [797698/888800 89.75%] train loss: 4.412228736327961e-05 \n",
      "epoch: 1 [798809/888800 89.88%] train loss: 5.178443461772986e-05 \n",
      "epoch: 1 [799920/888800 90.00%] train loss: 4.6687753638252616e-05 \n",
      "epoch: 1 [801031/888800 90.12%] train loss: 4.119395816815086e-05 \n",
      "epoch: 1 [802142/888800 90.25%] train loss: 3.82675243599806e-05 \n",
      "epoch: 1 [803253/888800 90.38%] train loss: 4.939193240716122e-05 \n",
      "epoch: 1 [804364/888800 90.50%] train loss: 3.908999860868789e-05 \n",
      "epoch: 1 [805475/888800 90.62%] train loss: 4.2366416892036796e-05 \n",
      "epoch: 1 [806586/888800 90.75%] train loss: 4.384597559692338e-05 \n",
      "epoch: 1 [807697/888800 90.88%] train loss: 4.43186036136467e-05 \n",
      "epoch: 1 [808808/888800 91.00%] train loss: 4.5996908738743514e-05 \n",
      "epoch: 1 [809919/888800 91.12%] train loss: 4.9412417865823954e-05 \n",
      "epoch: 1 [811030/888800 91.25%] train loss: 5.120921559864655e-05 \n",
      "epoch: 1 [812141/888800 91.38%] train loss: 5.091927960165776e-05 \n",
      "epoch: 1 [813252/888800 91.50%] train loss: 4.224215081194416e-05 \n",
      "epoch: 1 [814363/888800 91.62%] train loss: 4.791329047293402e-05 \n",
      "epoch: 1 [815474/888800 91.75%] train loss: 4.828195596928708e-05 \n",
      "epoch: 1 [816585/888800 91.88%] train loss: 4.448847539606504e-05 \n",
      "epoch: 1 [817696/888800 92.00%] train loss: 3.888698120135814e-05 \n",
      "epoch: 1 [818807/888800 92.12%] train loss: 5.0250408094143495e-05 \n",
      "epoch: 1 [819918/888800 92.25%] train loss: 4.438825635588728e-05 \n",
      "epoch: 1 [821029/888800 92.38%] train loss: 3.776355515583418e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [822140/888800 92.50%] train loss: 4.643175270757638e-05 \n",
      "epoch: 1 [823251/888800 92.62%] train loss: 4.8336878535337746e-05 \n",
      "epoch: 1 [824362/888800 92.75%] train loss: 4.39526884292718e-05 \n",
      "epoch: 1 [825473/888800 92.88%] train loss: 4.3791293137473986e-05 \n",
      "epoch: 1 [826584/888800 93.00%] train loss: 5.646976933348924e-05 \n",
      "epoch: 1 [827695/888800 93.12%] train loss: 4.823760173167102e-05 \n",
      "epoch: 1 [828806/888800 93.25%] train loss: 5.182709719520062e-05 \n",
      "epoch: 1 [829917/888800 93.38%] train loss: 5.697728192899376e-05 \n",
      "epoch: 1 [831028/888800 93.50%] train loss: 4.629609247785993e-05 \n",
      "epoch: 1 [832139/888800 93.62%] train loss: 3.702207686728798e-05 \n",
      "epoch: 1 [833250/888800 93.75%] train loss: 4.185253055766225e-05 \n",
      "epoch: 1 [834361/888800 93.88%] train loss: 4.6838325943099335e-05 \n",
      "epoch: 1 [835472/888800 94.00%] train loss: 4.1913390305126086e-05 \n",
      "epoch: 1 [836583/888800 94.12%] train loss: 4.976694253855385e-05 \n",
      "epoch: 1 [837694/888800 94.25%] train loss: 4.890275886282325e-05 \n",
      "epoch: 1 [838805/888800 94.38%] train loss: 5.3006791858933866e-05 \n",
      "epoch: 1 [839916/888800 94.50%] train loss: 5.093378058518283e-05 \n",
      "epoch: 1 [841027/888800 94.62%] train loss: 4.3805415771203116e-05 \n",
      "epoch: 1 [842138/888800 94.75%] train loss: 4.416549563757144e-05 \n",
      "epoch: 1 [843249/888800 94.88%] train loss: 5.00859969179146e-05 \n",
      "epoch: 1 [844360/888800 95.00%] train loss: 4.312757300795056e-05 \n",
      "epoch: 1 [845471/888800 95.12%] train loss: 5.011260509490967e-05 \n",
      "epoch: 1 [846582/888800 95.25%] train loss: 4.2101815779460594e-05 \n",
      "epoch: 1 [847693/888800 95.38%] train loss: 4.367515066405758e-05 \n",
      "epoch: 1 [848804/888800 95.50%] train loss: 5.3284406021703035e-05 \n",
      "epoch: 1 [849915/888800 95.62%] train loss: 4.920440187561326e-05 \n",
      "epoch: 1 [851026/888800 95.75%] train loss: 4.380445898277685e-05 \n",
      "epoch: 1 [852137/888800 95.88%] train loss: 3.721235043485649e-05 \n",
      "epoch: 1 [853248/888800 96.00%] train loss: 4.9729009333532304e-05 \n",
      "epoch: 1 [854359/888800 96.12%] train loss: 4.833224375033751e-05 \n",
      "epoch: 1 [855470/888800 96.25%] train loss: 4.736292612506077e-05 \n",
      "epoch: 1 [856581/888800 96.38%] train loss: 4.6188270061975345e-05 \n",
      "epoch: 1 [857692/888800 96.50%] train loss: 4.505129618337378e-05 \n",
      "epoch: 1 [858803/888800 96.62%] train loss: 4.409325629239902e-05 \n",
      "epoch: 1 [859914/888800 96.75%] train loss: 5.503603824763559e-05 \n",
      "epoch: 1 [861025/888800 96.88%] train loss: 3.8976315408945084e-05 \n",
      "epoch: 1 [862136/888800 97.00%] train loss: 3.9959435525815934e-05 \n",
      "epoch: 1 [863247/888800 97.12%] train loss: 4.5189011871116236e-05 \n",
      "epoch: 1 [864358/888800 97.25%] train loss: 4.592060577124357e-05 \n",
      "epoch: 1 [865469/888800 97.38%] train loss: 4.0543654904467985e-05 \n",
      "epoch: 1 [866580/888800 97.50%] train loss: 3.350606493768282e-05 \n",
      "epoch: 1 [867691/888800 97.62%] train loss: 4.708487540483475e-05 \n",
      "epoch: 1 [868802/888800 97.75%] train loss: 4.352472387836315e-05 \n",
      "epoch: 1 [869913/888800 97.88%] train loss: 5.023803169024177e-05 \n",
      "epoch: 1 [871024/888800 98.00%] train loss: 5.02680049976334e-05 \n",
      "epoch: 1 [872135/888800 98.12%] train loss: 4.15336835430935e-05 \n",
      "epoch: 1 [873246/888800 98.25%] train loss: 4.606405855156481e-05 \n",
      "epoch: 1 [874357/888800 98.38%] train loss: 4.671776696341112e-05 \n",
      "epoch: 1 [875468/888800 98.50%] train loss: 4.465132224140689e-05 \n",
      "epoch: 1 [876579/888800 98.62%] train loss: 4.119277946301736e-05 \n",
      "epoch: 1 [877690/888800 98.75%] train loss: 4.606407674145885e-05 \n",
      "epoch: 1 [878801/888800 98.88%] train loss: 4.931904186378233e-05 \n",
      "epoch: 1 [879912/888800 99.00%] train loss: 5.152235462446697e-05 \n",
      "epoch: 1 [881023/888800 99.12%] train loss: 4.498579437495209e-05 \n",
      "epoch: 1 [882134/888800 99.25%] train loss: 4.448268373380415e-05 \n",
      "epoch: 1 [883245/888800 99.38%] train loss: 3.775523873628117e-05 \n",
      "epoch: 1 [884356/888800 99.50%] train loss: 3.9974718674784526e-05 \n",
      "epoch: 1 [885467/888800 99.62%] train loss: 4.4791500840801746e-05 \n",
      "epoch: 1 [886578/888800 99.75%] train loss: 5.445389251690358e-05 \n",
      "epoch: 1 [887689/888800 99.88%] train loss: 4.5465938455890864e-05 \n",
      "epoch: 2 [0/888800 0.00%] train loss: 4.283943053451367e-05 \n",
      "epoch: 2 [1111/888800 0.12%] train loss: 4.454267036635429e-05 \n",
      "epoch: 2 [2222/888800 0.25%] train loss: 4.0666105633135885e-05 \n",
      "epoch: 2 [3333/888800 0.38%] train loss: 4.4543408876052126e-05 \n",
      "epoch: 2 [4444/888800 0.50%] train loss: 4.809022357221693e-05 \n",
      "epoch: 2 [5555/888800 0.62%] train loss: 4.909420749754645e-05 \n",
      "epoch: 2 [6666/888800 0.75%] train loss: 4.70951636089012e-05 \n",
      "epoch: 2 [7777/888800 0.88%] train loss: 4.681243808590807e-05 \n",
      "epoch: 2 [8888/888800 1.00%] train loss: 4.359804006526247e-05 \n",
      "epoch: 2 [9999/888800 1.12%] train loss: 4.825515497941524e-05 \n",
      "epoch: 2 [11110/888800 1.25%] train loss: 4.670787893701345e-05 \n",
      "epoch: 2 [12221/888800 1.38%] train loss: 4.18904164689593e-05 \n",
      "epoch: 2 [13332/888800 1.50%] train loss: 4.704916864284314e-05 \n",
      "epoch: 2 [14443/888800 1.62%] train loss: 4.502871524891816e-05 \n",
      "epoch: 2 [15554/888800 1.75%] train loss: 4.177698428975418e-05 \n",
      "epoch: 2 [16665/888800 1.88%] train loss: 4.566042480291799e-05 \n",
      "epoch: 2 [17776/888800 2.00%] train loss: 4.0830109355738387e-05 \n",
      "epoch: 2 [18887/888800 2.12%] train loss: 4.649918992072344e-05 \n",
      "epoch: 2 [19998/888800 2.25%] train loss: 4.9240032240049914e-05 \n",
      "epoch: 2 [21109/888800 2.38%] train loss: 5.4949690820649266e-05 \n",
      "epoch: 2 [22220/888800 2.50%] train loss: 4.1749433876248077e-05 \n",
      "epoch: 2 [23331/888800 2.62%] train loss: 5.0605151045601815e-05 \n",
      "epoch: 2 [24442/888800 2.75%] train loss: 5.789537317468785e-05 \n",
      "epoch: 2 [25553/888800 2.88%] train loss: 4.345382330939174e-05 \n",
      "epoch: 2 [26664/888800 3.00%] train loss: 4.937696212437004e-05 \n",
      "epoch: 2 [27775/888800 3.12%] train loss: 3.8729835068807006e-05 \n",
      "epoch: 2 [28886/888800 3.25%] train loss: 4.5305023377295583e-05 \n",
      "epoch: 2 [29997/888800 3.38%] train loss: 4.8169709771173075e-05 \n",
      "epoch: 2 [31108/888800 3.50%] train loss: 4.779618393513374e-05 \n",
      "epoch: 2 [32219/888800 3.62%] train loss: 4.7872908908175305e-05 \n",
      "epoch: 2 [33330/888800 3.75%] train loss: 3.8674072129651904e-05 \n",
      "epoch: 2 [34441/888800 3.88%] train loss: 4.0329814510187134e-05 \n",
      "epoch: 2 [35552/888800 4.00%] train loss: 4.0814862586557865e-05 \n",
      "epoch: 2 [36663/888800 4.12%] train loss: 4.883508154307492e-05 \n",
      "epoch: 2 [37774/888800 4.25%] train loss: 4.76801251352299e-05 \n",
      "epoch: 2 [38885/888800 4.38%] train loss: 4.5522767322836444e-05 \n",
      "epoch: 2 [39996/888800 4.50%] train loss: 5.9104510000906885e-05 \n",
      "epoch: 2 [41107/888800 4.62%] train loss: 4.675623495131731e-05 \n",
      "epoch: 2 [42218/888800 4.75%] train loss: 5.013474219595082e-05 \n",
      "epoch: 2 [43329/888800 4.88%] train loss: 4.396992881083861e-05 \n",
      "epoch: 2 [44440/888800 5.00%] train loss: 3.513116462272592e-05 \n",
      "epoch: 2 [45551/888800 5.12%] train loss: 4.197540692985058e-05 \n",
      "epoch: 2 [46662/888800 5.25%] train loss: 4.43847275164444e-05 \n",
      "epoch: 2 [47773/888800 5.38%] train loss: 4.148609878029674e-05 \n",
      "epoch: 2 [48884/888800 5.50%] train loss: 5.0598959205672145e-05 \n",
      "epoch: 2 [49995/888800 5.62%] train loss: 5.113462248118594e-05 \n",
      "epoch: 2 [51106/888800 5.75%] train loss: 3.703890979522839e-05 \n",
      "epoch: 2 [52217/888800 5.88%] train loss: 4.774498302140273e-05 \n",
      "epoch: 2 [53328/888800 6.00%] train loss: 4.6933168050600216e-05 \n",
      "epoch: 2 [54439/888800 6.12%] train loss: 4.3420313886599615e-05 \n",
      "epoch: 2 [55550/888800 6.25%] train loss: 4.88480509375222e-05 \n",
      "epoch: 2 [56661/888800 6.38%] train loss: 4.1771563701331615e-05 \n",
      "epoch: 2 [57772/888800 6.50%] train loss: 3.941681279684417e-05 \n",
      "epoch: 2 [58883/888800 6.62%] train loss: 4.3606934923445806e-05 \n",
      "epoch: 2 [59994/888800 6.75%] train loss: 3.9430728065781295e-05 \n",
      "epoch: 2 [61105/888800 6.88%] train loss: 5.020577373215929e-05 \n",
      "epoch: 2 [62216/888800 7.00%] train loss: 4.4580901885638013e-05 \n",
      "epoch: 2 [63327/888800 7.12%] train loss: 3.6822741094511e-05 \n",
      "epoch: 2 [64438/888800 7.25%] train loss: 4.74463049613405e-05 \n",
      "epoch: 2 [65549/888800 7.38%] train loss: 4.128458385821432e-05 \n",
      "epoch: 2 [66660/888800 7.50%] train loss: 4.331403397372924e-05 \n",
      "epoch: 2 [67771/888800 7.62%] train loss: 4.484534656512551e-05 \n",
      "epoch: 2 [68882/888800 7.75%] train loss: 4.435963637661189e-05 \n",
      "epoch: 2 [69993/888800 7.88%] train loss: 4.353708936832845e-05 \n",
      "epoch: 2 [71104/888800 8.00%] train loss: 4.719502248917706e-05 \n",
      "epoch: 2 [72215/888800 8.12%] train loss: 4.7340676246676594e-05 \n",
      "epoch: 2 [73326/888800 8.25%] train loss: 4.789261583937332e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 [74437/888800 8.38%] train loss: 4.168429222772829e-05 \n",
      "epoch: 2 [75548/888800 8.50%] train loss: 4.686515239882283e-05 \n",
      "epoch: 2 [76659/888800 8.62%] train loss: 4.735209222417325e-05 \n",
      "epoch: 2 [77770/888800 8.75%] train loss: 4.0799852285999805e-05 \n",
      "epoch: 2 [78881/888800 8.88%] train loss: 4.940733560943045e-05 \n",
      "epoch: 2 [79992/888800 9.00%] train loss: 4.092363815288991e-05 \n",
      "epoch: 2 [81103/888800 9.12%] train loss: 4.9516427679918706e-05 \n",
      "epoch: 2 [82214/888800 9.25%] train loss: 4.508392157731578e-05 \n",
      "epoch: 2 [83325/888800 9.38%] train loss: 5.018832234782167e-05 \n",
      "epoch: 2 [84436/888800 9.50%] train loss: 4.0169696148950607e-05 \n",
      "epoch: 2 [85547/888800 9.62%] train loss: 4.763445394928567e-05 \n",
      "epoch: 2 [86658/888800 9.75%] train loss: 3.909105362254195e-05 \n",
      "epoch: 2 [87769/888800 9.88%] train loss: 4.610319956555031e-05 \n",
      "epoch: 2 [88880/888800 10.00%] train loss: 4.329599687480368e-05 \n",
      "epoch: 2 [89991/888800 10.12%] train loss: 4.102314051124267e-05 \n",
      "epoch: 2 [91102/888800 10.25%] train loss: 4.604598871082999e-05 \n",
      "epoch: 2 [92213/888800 10.38%] train loss: 5.411816164269112e-05 \n",
      "epoch: 2 [93324/888800 10.50%] train loss: 4.089828144060448e-05 \n",
      "epoch: 2 [94435/888800 10.62%] train loss: 4.368642839835957e-05 \n",
      "epoch: 2 [95546/888800 10.75%] train loss: 4.5412285544443876e-05 \n",
      "epoch: 2 [96657/888800 10.88%] train loss: 4.25397083745338e-05 \n",
      "epoch: 2 [97768/888800 11.00%] train loss: 4.2490930354688317e-05 \n",
      "epoch: 2 [98879/888800 11.12%] train loss: 4.638587779481895e-05 \n",
      "epoch: 2 [99990/888800 11.25%] train loss: 4.49547114840243e-05 \n",
      "epoch: 2 [101101/888800 11.38%] train loss: 4.854117287322879e-05 \n",
      "epoch: 2 [102212/888800 11.50%] train loss: 4.4810716644860804e-05 \n",
      "epoch: 2 [103323/888800 11.62%] train loss: 4.8300167691195384e-05 \n",
      "epoch: 2 [104434/888800 11.75%] train loss: 4.178070594207384e-05 \n",
      "epoch: 2 [105545/888800 11.88%] train loss: 3.693557300721295e-05 \n",
      "epoch: 2 [106656/888800 12.00%] train loss: 4.522287781583145e-05 \n",
      "epoch: 2 [107767/888800 12.12%] train loss: 3.744379500858486e-05 \n",
      "epoch: 2 [108878/888800 12.25%] train loss: 4.213682404952124e-05 \n",
      "epoch: 2 [109989/888800 12.38%] train loss: 4.3879306758753955e-05 \n",
      "epoch: 2 [111100/888800 12.50%] train loss: 4.3926742364419624e-05 \n",
      "epoch: 2 [112211/888800 12.62%] train loss: 3.782692874665372e-05 \n",
      "epoch: 2 [113322/888800 12.75%] train loss: 4.8837828217074275e-05 \n",
      "epoch: 2 [114433/888800 12.88%] train loss: 4.584561611409299e-05 \n",
      "epoch: 2 [115544/888800 13.00%] train loss: 5.3980620577931404e-05 \n",
      "epoch: 2 [116655/888800 13.12%] train loss: 5.215526107349433e-05 \n",
      "epoch: 2 [117766/888800 13.25%] train loss: 4.965107291354798e-05 \n",
      "epoch: 2 [118877/888800 13.38%] train loss: 4.393028575577773e-05 \n",
      "epoch: 2 [119988/888800 13.50%] train loss: 4.099306897842325e-05 \n",
      "epoch: 2 [121099/888800 13.62%] train loss: 3.790286791627295e-05 \n",
      "epoch: 2 [122210/888800 13.75%] train loss: 4.9865782784763724e-05 \n",
      "epoch: 2 [123321/888800 13.88%] train loss: 4.557922147796489e-05 \n",
      "epoch: 2 [124432/888800 14.00%] train loss: 3.764906068681739e-05 \n",
      "epoch: 2 [125543/888800 14.12%] train loss: 4.5445562136592343e-05 \n",
      "epoch: 2 [126654/888800 14.25%] train loss: 4.185094076092355e-05 \n",
      "epoch: 2 [127765/888800 14.38%] train loss: 4.789589365827851e-05 \n",
      "epoch: 2 [128876/888800 14.50%] train loss: 4.5805692934663966e-05 \n",
      "epoch: 2 [129987/888800 14.62%] train loss: 4.0602371882414445e-05 \n",
      "epoch: 2 [131098/888800 14.75%] train loss: 4.730506771011278e-05 \n",
      "epoch: 2 [132209/888800 14.88%] train loss: 4.144671402173117e-05 \n",
      "epoch: 2 [133320/888800 15.00%] train loss: 5.130817953613587e-05 \n",
      "epoch: 2 [134431/888800 15.12%] train loss: 4.753008397528902e-05 \n",
      "epoch: 2 [135542/888800 15.25%] train loss: 3.680930967675522e-05 \n",
      "epoch: 2 [136653/888800 15.38%] train loss: 3.944174386560917e-05 \n",
      "epoch: 2 [137764/888800 15.50%] train loss: 4.439229815034196e-05 \n",
      "epoch: 2 [138875/888800 15.62%] train loss: 4.4196924136485904e-05 \n",
      "epoch: 2 [139986/888800 15.75%] train loss: 4.170089232502505e-05 \n",
      "epoch: 2 [141097/888800 15.88%] train loss: 4.661271668737754e-05 \n",
      "epoch: 2 [142208/888800 16.00%] train loss: 4.0109680412570015e-05 \n",
      "epoch: 2 [143319/888800 16.12%] train loss: 4.4108270230935887e-05 \n",
      "epoch: 2 [144430/888800 16.25%] train loss: 3.8750364183215424e-05 \n",
      "epoch: 2 [145541/888800 16.38%] train loss: 4.483673183131032e-05 \n",
      "epoch: 2 [146652/888800 16.50%] train loss: 4.325202462496236e-05 \n",
      "epoch: 2 [147763/888800 16.62%] train loss: 4.460080526769161e-05 \n",
      "epoch: 2 [148874/888800 16.75%] train loss: 4.055536919622682e-05 \n",
      "epoch: 2 [149985/888800 16.88%] train loss: 4.928213820676319e-05 \n",
      "epoch: 2 [151096/888800 17.00%] train loss: 5.248736124485731e-05 \n",
      "epoch: 2 [152207/888800 17.12%] train loss: 4.85678028780967e-05 \n",
      "epoch: 2 [153318/888800 17.25%] train loss: 4.4255692046135664e-05 \n",
      "epoch: 2 [154429/888800 17.38%] train loss: 4.986743442714214e-05 \n",
      "epoch: 2 [155540/888800 17.50%] train loss: 5.397961649578065e-05 \n",
      "epoch: 2 [156651/888800 17.62%] train loss: 4.297917985240929e-05 \n",
      "epoch: 2 [157762/888800 17.75%] train loss: 4.99071174999699e-05 \n",
      "epoch: 2 [158873/888800 17.88%] train loss: 5.272090857033618e-05 \n",
      "epoch: 2 [159984/888800 18.00%] train loss: 4.381129838293418e-05 \n",
      "epoch: 2 [161095/888800 18.12%] train loss: 4.769070437760092e-05 \n",
      "epoch: 2 [162206/888800 18.25%] train loss: 4.2469317122595385e-05 \n",
      "epoch: 2 [163317/888800 18.38%] train loss: 4.2344701796537265e-05 \n",
      "epoch: 2 [164428/888800 18.50%] train loss: 5.050031904829666e-05 \n",
      "epoch: 2 [165539/888800 18.62%] train loss: 4.7266123146982864e-05 \n",
      "epoch: 2 [166650/888800 18.75%] train loss: 4.083204112248495e-05 \n",
      "epoch: 2 [167761/888800 18.88%] train loss: 4.069319402333349e-05 \n",
      "epoch: 2 [168872/888800 19.00%] train loss: 3.66110798495356e-05 \n",
      "epoch: 2 [169983/888800 19.12%] train loss: 4.633018761523999e-05 \n",
      "epoch: 2 [171094/888800 19.25%] train loss: 3.8362995837815106e-05 \n",
      "epoch: 2 [172205/888800 19.38%] train loss: 4.772163447341882e-05 \n",
      "epoch: 2 [173316/888800 19.50%] train loss: 4.914572855341248e-05 \n",
      "epoch: 2 [174427/888800 19.62%] train loss: 4.0986287785926834e-05 \n",
      "epoch: 2 [175538/888800 19.75%] train loss: 3.631579238572158e-05 \n",
      "epoch: 2 [176649/888800 19.88%] train loss: 5.5823558795964345e-05 \n",
      "epoch: 2 [177760/888800 20.00%] train loss: 4.9310907343169674e-05 \n",
      "epoch: 2 [178871/888800 20.12%] train loss: 4.4089647417422384e-05 \n",
      "epoch: 2 [179982/888800 20.25%] train loss: 3.9246897358680144e-05 \n",
      "epoch: 2 [181093/888800 20.38%] train loss: 4.875860031461343e-05 \n",
      "epoch: 2 [182204/888800 20.50%] train loss: 4.0160415665013716e-05 \n",
      "epoch: 2 [183315/888800 20.62%] train loss: 4.347635695012286e-05 \n",
      "epoch: 2 [184426/888800 20.75%] train loss: 3.6493802326731384e-05 \n",
      "epoch: 2 [185537/888800 20.88%] train loss: 4.03904341510497e-05 \n",
      "epoch: 2 [186648/888800 21.00%] train loss: 5.4922897106735036e-05 \n",
      "epoch: 2 [187759/888800 21.12%] train loss: 4.423411883180961e-05 \n",
      "epoch: 2 [188870/888800 21.25%] train loss: 5.081594281364232e-05 \n",
      "epoch: 2 [189981/888800 21.38%] train loss: 5.2346655138535425e-05 \n",
      "epoch: 2 [191092/888800 21.50%] train loss: 5.619145667878911e-05 \n",
      "epoch: 2 [192203/888800 21.62%] train loss: 4.024247027700767e-05 \n",
      "epoch: 2 [193314/888800 21.75%] train loss: 4.2892643250525e-05 \n",
      "epoch: 2 [194425/888800 21.88%] train loss: 4.2384504922665656e-05 \n",
      "epoch: 2 [195536/888800 22.00%] train loss: 3.856998955598101e-05 \n",
      "epoch: 2 [196647/888800 22.12%] train loss: 4.184091812931001e-05 \n",
      "epoch: 2 [197758/888800 22.25%] train loss: 4.963110768585466e-05 \n",
      "epoch: 2 [198869/888800 22.38%] train loss: 4.048079063068144e-05 \n",
      "epoch: 2 [199980/888800 22.50%] train loss: 3.9321676013059914e-05 \n",
      "epoch: 2 [201091/888800 22.62%] train loss: 3.409864075365476e-05 \n",
      "epoch: 2 [202202/888800 22.75%] train loss: 4.807489676750265e-05 \n",
      "epoch: 2 [203313/888800 22.88%] train loss: 4.533314859145321e-05 \n",
      "epoch: 2 [204424/888800 23.00%] train loss: 4.351757525000721e-05 \n",
      "epoch: 2 [205535/888800 23.12%] train loss: 5.235269054537639e-05 \n",
      "epoch: 2 [206646/888800 23.25%] train loss: 4.249159974278882e-05 \n",
      "epoch: 2 [207757/888800 23.38%] train loss: 5.3157866204855964e-05 \n",
      "epoch: 2 [208868/888800 23.50%] train loss: 4.547597200144082e-05 \n",
      "epoch: 2 [209979/888800 23.62%] train loss: 4.2668336391216144e-05 \n",
      "epoch: 2 [211090/888800 23.75%] train loss: 4.6859579015290365e-05 \n",
      "epoch: 2 [212201/888800 23.88%] train loss: 4.33310960943345e-05 \n",
      "epoch: 2 [213312/888800 24.00%] train loss: 3.9920680137583986e-05 \n",
      "epoch: 2 [214423/888800 24.12%] train loss: 4.117466596653685e-05 \n",
      "epoch: 2 [215534/888800 24.25%] train loss: 4.625228757504374e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 [216645/888800 24.38%] train loss: 4.59359071101062e-05 \n",
      "epoch: 2 [217756/888800 24.50%] train loss: 4.251591599313542e-05 \n",
      "epoch: 2 [218867/888800 24.62%] train loss: 5.772114309365861e-05 \n",
      "epoch: 2 [219978/888800 24.75%] train loss: 4.8750851419754326e-05 \n",
      "epoch: 2 [221089/888800 24.88%] train loss: 4.290963988751173e-05 \n",
      "epoch: 2 [222200/888800 25.00%] train loss: 4.584031194099225e-05 \n",
      "epoch: 2 [223311/888800 25.12%] train loss: 4.706075196736492e-05 \n",
      "epoch: 2 [224422/888800 25.25%] train loss: 4.129710578126833e-05 \n",
      "epoch: 2 [225533/888800 25.38%] train loss: 4.180911128059961e-05 \n",
      "epoch: 2 [226644/888800 25.50%] train loss: 4.74524604214821e-05 \n",
      "epoch: 2 [227755/888800 25.62%] train loss: 4.4898053602082655e-05 \n",
      "epoch: 2 [228866/888800 25.75%] train loss: 4.088754212716594e-05 \n",
      "epoch: 2 [229977/888800 25.88%] train loss: 5.0324724725214764e-05 \n",
      "epoch: 2 [231088/888800 26.00%] train loss: 4.407385131344199e-05 \n",
      "epoch: 2 [232199/888800 26.12%] train loss: 4.8311358114006e-05 \n",
      "epoch: 2 [233310/888800 26.25%] train loss: 3.982011185144074e-05 \n",
      "epoch: 2 [234421/888800 26.38%] train loss: 4.892484867013991e-05 \n",
      "epoch: 2 [235532/888800 26.50%] train loss: 4.350976087152958e-05 \n",
      "epoch: 2 [236643/888800 26.62%] train loss: 4.049426570418291e-05 \n",
      "epoch: 2 [237754/888800 26.75%] train loss: 5.443042755359784e-05 \n",
      "epoch: 2 [238865/888800 26.88%] train loss: 3.6651112168328837e-05 \n",
      "epoch: 2 [239976/888800 27.00%] train loss: 4.0431961679132655e-05 \n",
      "epoch: 2 [241087/888800 27.12%] train loss: 4.953924144501798e-05 \n",
      "epoch: 2 [242198/888800 27.25%] train loss: 4.5400429371511564e-05 \n",
      "epoch: 2 [243309/888800 27.38%] train loss: 3.60857775376644e-05 \n",
      "epoch: 2 [244420/888800 27.50%] train loss: 4.4460677600000054e-05 \n",
      "epoch: 2 [245531/888800 27.62%] train loss: 4.594464189722203e-05 \n",
      "epoch: 2 [246642/888800 27.75%] train loss: 4.809058373211883e-05 \n",
      "epoch: 2 [247753/888800 27.88%] train loss: 4.546290074358694e-05 \n",
      "epoch: 2 [248864/888800 28.00%] train loss: 4.044771412736736e-05 \n",
      "epoch: 2 [249975/888800 28.12%] train loss: 4.79420050396584e-05 \n",
      "epoch: 2 [251086/888800 28.25%] train loss: 4.898720362689346e-05 \n",
      "epoch: 2 [252197/888800 28.38%] train loss: 4.941735460306518e-05 \n",
      "epoch: 2 [253308/888800 28.50%] train loss: 5.820834849146195e-05 \n",
      "epoch: 2 [254419/888800 28.62%] train loss: 5.405051706475206e-05 \n",
      "epoch: 2 [255530/888800 28.75%] train loss: 4.72132524009794e-05 \n",
      "epoch: 2 [256641/888800 28.88%] train loss: 4.540377267403528e-05 \n",
      "epoch: 2 [257752/888800 29.00%] train loss: 4.825235373573378e-05 \n",
      "epoch: 2 [258863/888800 29.12%] train loss: 4.669748886954039e-05 \n",
      "epoch: 2 [259974/888800 29.25%] train loss: 5.554855306399986e-05 \n",
      "epoch: 2 [261085/888800 29.38%] train loss: 4.0524828364141285e-05 \n",
      "epoch: 2 [262196/888800 29.50%] train loss: 4.350131348473951e-05 \n",
      "epoch: 2 [263307/888800 29.62%] train loss: 5.2985404181526974e-05 \n",
      "epoch: 2 [264418/888800 29.75%] train loss: 4.8740195779828355e-05 \n",
      "epoch: 2 [265529/888800 29.88%] train loss: 3.9614584238734096e-05 \n",
      "epoch: 2 [266640/888800 30.00%] train loss: 4.401362457429059e-05 \n",
      "epoch: 2 [267751/888800 30.12%] train loss: 4.7007899411255494e-05 \n",
      "epoch: 2 [268862/888800 30.25%] train loss: 3.936212669941597e-05 \n",
      "epoch: 2 [269973/888800 30.38%] train loss: 3.715138154802844e-05 \n",
      "epoch: 2 [271084/888800 30.50%] train loss: 4.1343606426380575e-05 \n",
      "epoch: 2 [272195/888800 30.62%] train loss: 4.278841151972301e-05 \n",
      "epoch: 2 [273306/888800 30.75%] train loss: 4.366657231003046e-05 \n",
      "epoch: 2 [274417/888800 30.88%] train loss: 5.644675184157677e-05 \n",
      "epoch: 2 [275528/888800 31.00%] train loss: 5.050758409197442e-05 \n",
      "epoch: 2 [276639/888800 31.12%] train loss: 4.226119563099928e-05 \n",
      "epoch: 2 [277750/888800 31.25%] train loss: 4.859147884417325e-05 \n",
      "epoch: 2 [278861/888800 31.38%] train loss: 4.271078068995848e-05 \n",
      "epoch: 2 [279972/888800 31.50%] train loss: 4.6127588575473055e-05 \n",
      "epoch: 2 [281083/888800 31.62%] train loss: 5.2981864428147674e-05 \n",
      "epoch: 2 [282194/888800 31.75%] train loss: 4.412768976180814e-05 \n",
      "epoch: 2 [283305/888800 31.88%] train loss: 3.895843474310823e-05 \n",
      "epoch: 2 [284416/888800 32.00%] train loss: 3.731517062988132e-05 \n",
      "epoch: 2 [285527/888800 32.12%] train loss: 4.807519871974364e-05 \n",
      "epoch: 2 [286638/888800 32.25%] train loss: 4.524122050497681e-05 \n",
      "epoch: 2 [287749/888800 32.38%] train loss: 4.0313112549483776e-05 \n",
      "epoch: 2 [288860/888800 32.50%] train loss: 4.3205054680584e-05 \n",
      "epoch: 2 [289971/888800 32.62%] train loss: 4.492584412219003e-05 \n",
      "epoch: 2 [291082/888800 32.75%] train loss: 4.3956151785096154e-05 \n",
      "epoch: 2 [292193/888800 32.88%] train loss: 5.3964518883731216e-05 \n",
      "epoch: 2 [293304/888800 33.00%] train loss: 4.500907743931748e-05 \n",
      "epoch: 2 [294415/888800 33.12%] train loss: 4.493050437304191e-05 \n",
      "epoch: 2 [295526/888800 33.25%] train loss: 5.2270712330937386e-05 \n",
      "epoch: 2 [296637/888800 33.38%] train loss: 3.981193731306121e-05 \n",
      "epoch: 2 [297748/888800 33.50%] train loss: 4.439467375050299e-05 \n",
      "epoch: 2 [298859/888800 33.62%] train loss: 4.3285243009449914e-05 \n",
      "epoch: 2 [299970/888800 33.75%] train loss: 4.4024975068168715e-05 \n",
      "epoch: 2 [301081/888800 33.88%] train loss: 4.6078530431259423e-05 \n",
      "epoch: 2 [302192/888800 34.00%] train loss: 4.7930738219292834e-05 \n",
      "epoch: 2 [303303/888800 34.12%] train loss: 3.920755989383906e-05 \n",
      "epoch: 2 [304414/888800 34.25%] train loss: 4.997373616788536e-05 \n",
      "epoch: 2 [305525/888800 34.38%] train loss: 4.7323574108304456e-05 \n",
      "epoch: 2 [306636/888800 34.50%] train loss: 4.0905251807998866e-05 \n",
      "epoch: 2 [307747/888800 34.62%] train loss: 3.9909071347210556e-05 \n",
      "epoch: 2 [308858/888800 34.75%] train loss: 4.17960764025338e-05 \n",
      "epoch: 2 [309969/888800 34.88%] train loss: 4.058230115333572e-05 \n",
      "epoch: 2 [311080/888800 35.00%] train loss: 6.14225646131672e-05 \n",
      "epoch: 2 [312191/888800 35.12%] train loss: 4.158255615038797e-05 \n",
      "epoch: 2 [313302/888800 35.25%] train loss: 5.0341259338892996e-05 \n",
      "epoch: 2 [314413/888800 35.38%] train loss: 4.369596717879176e-05 \n",
      "epoch: 2 [315524/888800 35.50%] train loss: 3.96993818867486e-05 \n",
      "epoch: 2 [316635/888800 35.62%] train loss: 4.7735822590766475e-05 \n",
      "epoch: 2 [317746/888800 35.75%] train loss: 5.084870645077899e-05 \n",
      "epoch: 2 [318857/888800 35.88%] train loss: 4.732894740300253e-05 \n",
      "epoch: 2 [319968/888800 36.00%] train loss: 4.6272420149762183e-05 \n",
      "epoch: 2 [321079/888800 36.12%] train loss: 4.063351661898196e-05 \n",
      "epoch: 2 [322190/888800 36.25%] train loss: 3.868749990942888e-05 \n",
      "epoch: 2 [323301/888800 36.38%] train loss: 4.4475847971625626e-05 \n",
      "epoch: 2 [324412/888800 36.50%] train loss: 5.059641625848599e-05 \n",
      "epoch: 2 [325523/888800 36.62%] train loss: 3.925918281311169e-05 \n",
      "epoch: 2 [326634/888800 36.75%] train loss: 4.123952385270968e-05 \n",
      "epoch: 2 [327745/888800 36.88%] train loss: 4.974273906555027e-05 \n",
      "epoch: 2 [328856/888800 37.00%] train loss: 3.89407723559998e-05 \n",
      "epoch: 2 [329967/888800 37.12%] train loss: 4.634426659322344e-05 \n",
      "epoch: 2 [331078/888800 37.25%] train loss: 4.099295620108023e-05 \n",
      "epoch: 2 [332189/888800 37.38%] train loss: 4.851368794334121e-05 \n",
      "epoch: 2 [333300/888800 37.50%] train loss: 3.69835615856573e-05 \n",
      "epoch: 2 [334411/888800 37.62%] train loss: 4.5522752770921215e-05 \n",
      "epoch: 2 [335522/888800 37.75%] train loss: 4.440594420884736e-05 \n",
      "epoch: 2 [336633/888800 37.88%] train loss: 3.8812318962300196e-05 \n",
      "epoch: 2 [337744/888800 38.00%] train loss: 4.238532346789725e-05 \n",
      "epoch: 2 [338855/888800 38.12%] train loss: 3.910847954102792e-05 \n",
      "epoch: 2 [339966/888800 38.25%] train loss: 4.9100439355243e-05 \n",
      "epoch: 2 [341077/888800 38.38%] train loss: 4.222210554871708e-05 \n",
      "epoch: 2 [342188/888800 38.50%] train loss: 4.381041435408406e-05 \n",
      "epoch: 2 [343299/888800 38.62%] train loss: 3.9566137274960056e-05 \n",
      "epoch: 2 [344410/888800 38.75%] train loss: 4.021979111712426e-05 \n",
      "epoch: 2 [345521/888800 38.88%] train loss: 3.5219709388911724e-05 \n",
      "epoch: 2 [346632/888800 39.00%] train loss: 4.6206456318031996e-05 \n",
      "epoch: 2 [347743/888800 39.12%] train loss: 4.6816010581096634e-05 \n",
      "epoch: 2 [348854/888800 39.25%] train loss: 3.787483728956431e-05 \n",
      "epoch: 2 [349965/888800 39.38%] train loss: 4.658507168642245e-05 \n",
      "epoch: 2 [351076/888800 39.50%] train loss: 4.0688420995138586e-05 \n",
      "epoch: 2 [352187/888800 39.62%] train loss: 4.5220036554383114e-05 \n",
      "epoch: 2 [353298/888800 39.75%] train loss: 4.06303079216741e-05 \n",
      "epoch: 2 [354409/888800 39.88%] train loss: 4.512340092333034e-05 \n",
      "epoch: 2 [355520/888800 40.00%] train loss: 4.389526657178067e-05 \n",
      "epoch: 2 [356631/888800 40.12%] train loss: 4.8789166612550616e-05 \n",
      "epoch: 2 [357742/888800 40.25%] train loss: 5.084646545583382e-05 \n",
      "epoch: 2 [358853/888800 40.38%] train loss: 4.6674093027831987e-05 \n",
      "epoch: 2 [359964/888800 40.50%] train loss: 4.436702511156909e-05 \n",
      "epoch: 2 [361075/888800 40.62%] train loss: 5.106408571009524e-05 \n",
      "epoch: 2 [362186/888800 40.75%] train loss: 4.367650399217382e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 [363297/888800 40.88%] train loss: 4.4073611206840724e-05 \n",
      "epoch: 2 [364408/888800 41.00%] train loss: 4.4716922275256366e-05 \n",
      "epoch: 2 [365519/888800 41.12%] train loss: 4.2103754822164774e-05 \n",
      "epoch: 2 [366630/888800 41.25%] train loss: 5.5094260460464284e-05 \n",
      "epoch: 2 [367741/888800 41.38%] train loss: 4.463765071704984e-05 \n",
      "epoch: 2 [368852/888800 41.50%] train loss: 4.2257302993675694e-05 \n",
      "epoch: 2 [369963/888800 41.62%] train loss: 4.3578515033004805e-05 \n",
      "epoch: 2 [371074/888800 41.75%] train loss: 5.082410643808544e-05 \n",
      "epoch: 2 [372185/888800 41.88%] train loss: 4.826420990866609e-05 \n",
      "epoch: 2 [373296/888800 42.00%] train loss: 4.376280776341446e-05 \n",
      "epoch: 2 [374407/888800 42.12%] train loss: 4.098323188372888e-05 \n",
      "epoch: 2 [375518/888800 42.25%] train loss: 4.507592529989779e-05 \n",
      "epoch: 2 [376629/888800 42.38%] train loss: 3.8241960282903165e-05 \n",
      "epoch: 2 [377740/888800 42.50%] train loss: 4.4440523197408766e-05 \n",
      "epoch: 2 [378851/888800 42.62%] train loss: 5.063584103481844e-05 \n",
      "epoch: 2 [379962/888800 42.75%] train loss: 3.8690832298016176e-05 \n",
      "epoch: 2 [381073/888800 42.88%] train loss: 4.49032049800735e-05 \n",
      "epoch: 2 [382184/888800 43.00%] train loss: 3.658692367025651e-05 \n",
      "epoch: 2 [383295/888800 43.12%] train loss: 4.0940314647741616e-05 \n",
      "epoch: 2 [384406/888800 43.25%] train loss: 4.4606204028241336e-05 \n",
      "epoch: 2 [385517/888800 43.38%] train loss: 4.394798452267423e-05 \n",
      "epoch: 2 [386628/888800 43.50%] train loss: 4.305642505642027e-05 \n",
      "epoch: 2 [387739/888800 43.62%] train loss: 4.923018786939792e-05 \n",
      "epoch: 2 [388850/888800 43.75%] train loss: 4.608783274306916e-05 \n",
      "epoch: 2 [389961/888800 43.88%] train loss: 4.886621900368482e-05 \n",
      "epoch: 2 [391072/888800 44.00%] train loss: 4.474732486414723e-05 \n",
      "epoch: 2 [392183/888800 44.12%] train loss: 4.353042459115386e-05 \n",
      "epoch: 2 [393294/888800 44.25%] train loss: 4.158755109529011e-05 \n",
      "epoch: 2 [394405/888800 44.38%] train loss: 5.069263352197595e-05 \n",
      "epoch: 2 [395516/888800 44.50%] train loss: 4.688895933213644e-05 \n",
      "epoch: 2 [396627/888800 44.62%] train loss: 5.7631350500741974e-05 \n",
      "epoch: 2 [397738/888800 44.75%] train loss: 4.0016850107349455e-05 \n",
      "epoch: 2 [398849/888800 44.88%] train loss: 4.145943239564076e-05 \n",
      "epoch: 2 [399960/888800 45.00%] train loss: 4.029897536383942e-05 \n",
      "epoch: 2 [401071/888800 45.12%] train loss: 4.301650187699124e-05 \n",
      "epoch: 2 [402182/888800 45.25%] train loss: 4.170413740212098e-05 \n",
      "epoch: 2 [403293/888800 45.38%] train loss: 4.1666036850074306e-05 \n",
      "epoch: 2 [404404/888800 45.50%] train loss: 4.0426944906357676e-05 \n",
      "epoch: 2 [405515/888800 45.62%] train loss: 4.882112625637092e-05 \n",
      "epoch: 2 [406626/888800 45.75%] train loss: 3.7647783756256104e-05 \n",
      "epoch: 2 [407737/888800 45.88%] train loss: 5.0451504648663104e-05 \n",
      "epoch: 2 [408848/888800 46.00%] train loss: 4.4789951061829925e-05 \n",
      "epoch: 2 [409959/888800 46.12%] train loss: 4.908279879600741e-05 \n",
      "epoch: 2 [411070/888800 46.25%] train loss: 4.20600626966916e-05 \n",
      "epoch: 2 [412181/888800 46.38%] train loss: 5.10302597831469e-05 \n",
      "epoch: 2 [413292/888800 46.50%] train loss: 4.710648863692768e-05 \n",
      "epoch: 2 [414403/888800 46.62%] train loss: 4.689381967182271e-05 \n",
      "epoch: 2 [415514/888800 46.75%] train loss: 4.095733311260119e-05 \n",
      "epoch: 2 [416625/888800 46.88%] train loss: 4.982476093573496e-05 \n",
      "epoch: 2 [417736/888800 47.00%] train loss: 4.4867032556794584e-05 \n",
      "epoch: 2 [418847/888800 47.12%] train loss: 4.1302628233097494e-05 \n",
      "epoch: 2 [419958/888800 47.25%] train loss: 4.542004899121821e-05 \n",
      "epoch: 2 [421069/888800 47.38%] train loss: 4.7672176151536405e-05 \n",
      "epoch: 2 [422180/888800 47.50%] train loss: 4.42495038441848e-05 \n",
      "epoch: 2 [423291/888800 47.62%] train loss: 5.185894769965671e-05 \n",
      "epoch: 2 [424402/888800 47.75%] train loss: 3.982283305958845e-05 \n",
      "epoch: 2 [425513/888800 47.88%] train loss: 5.135534956934862e-05 \n",
      "epoch: 2 [426624/888800 48.00%] train loss: 4.3330612243153155e-05 \n",
      "epoch: 2 [427735/888800 48.12%] train loss: 4.400944817462005e-05 \n",
      "epoch: 2 [428846/888800 48.25%] train loss: 4.4195759983267635e-05 \n",
      "epoch: 2 [429957/888800 48.38%] train loss: 4.935807010042481e-05 \n",
      "epoch: 2 [431068/888800 48.50%] train loss: 3.961689071729779e-05 \n",
      "epoch: 2 [432179/888800 48.62%] train loss: 4.636606536223553e-05 \n",
      "epoch: 2 [433290/888800 48.75%] train loss: 4.193950007902458e-05 \n",
      "epoch: 2 [434401/888800 48.88%] train loss: 3.799720434471965e-05 \n",
      "epoch: 2 [435512/888800 49.00%] train loss: 4.805422940989956e-05 \n",
      "epoch: 2 [436623/888800 49.12%] train loss: 3.843042941298336e-05 \n",
      "epoch: 2 [437734/888800 49.25%] train loss: 4.2390645830892026e-05 \n",
      "epoch: 2 [438845/888800 49.38%] train loss: 3.945141361327842e-05 \n",
      "epoch: 2 [439956/888800 49.50%] train loss: 4.482570511754602e-05 \n",
      "epoch: 2 [441067/888800 49.62%] train loss: 4.069075657753274e-05 \n",
      "epoch: 2 [442178/888800 49.75%] train loss: 4.777019057655707e-05 \n",
      "epoch: 2 [443289/888800 49.88%] train loss: 4.68134276161436e-05 \n",
      "epoch: 2 [444400/888800 50.00%] train loss: 3.830592322628945e-05 \n",
      "epoch: 2 [445511/888800 50.12%] train loss: 3.939522139262408e-05 \n",
      "epoch: 2 [446622/888800 50.25%] train loss: 4.3460291635710746e-05 \n",
      "epoch: 2 [447733/888800 50.38%] train loss: 4.374627678771503e-05 \n",
      "epoch: 2 [448844/888800 50.50%] train loss: 4.225458178552799e-05 \n",
      "epoch: 2 [449955/888800 50.62%] train loss: 5.1992326916661114e-05 \n",
      "epoch: 2 [451066/888800 50.75%] train loss: 4.912951771984808e-05 \n",
      "epoch: 2 [452177/888800 50.88%] train loss: 4.536072810878977e-05 \n",
      "epoch: 2 [453288/888800 51.00%] train loss: 4.700406498159282e-05 \n",
      "epoch: 2 [454399/888800 51.12%] train loss: 4.439965050551109e-05 \n",
      "epoch: 2 [455510/888800 51.25%] train loss: 4.116697527933866e-05 \n",
      "epoch: 2 [456621/888800 51.38%] train loss: 4.310126678319648e-05 \n",
      "epoch: 2 [457732/888800 51.50%] train loss: 4.2167437641182914e-05 \n",
      "epoch: 2 [458843/888800 51.62%] train loss: 4.1493687604088336e-05 \n",
      "epoch: 2 [459954/888800 51.75%] train loss: 3.703480615513399e-05 \n",
      "epoch: 2 [461065/888800 51.88%] train loss: 4.2617437429726124e-05 \n",
      "epoch: 2 [462176/888800 52.00%] train loss: 4.719393473351374e-05 \n",
      "epoch: 2 [463287/888800 52.12%] train loss: 4.7748795623192564e-05 \n",
      "epoch: 2 [464398/888800 52.25%] train loss: 3.707069845404476e-05 \n",
      "epoch: 2 [465509/888800 52.38%] train loss: 5.0894395826617256e-05 \n",
      "epoch: 2 [466620/888800 52.50%] train loss: 4.9963487981585786e-05 \n",
      "epoch: 2 [467731/888800 52.62%] train loss: 5.5258853535633534e-05 \n",
      "epoch: 2 [468842/888800 52.75%] train loss: 4.556429121294059e-05 \n",
      "epoch: 2 [469953/888800 52.88%] train loss: 4.374097989057191e-05 \n",
      "epoch: 2 [471064/888800 53.00%] train loss: 4.190755862509832e-05 \n",
      "epoch: 2 [472175/888800 53.12%] train loss: 4.304616231820546e-05 \n",
      "epoch: 2 [473286/888800 53.25%] train loss: 3.9364043914247304e-05 \n",
      "epoch: 2 [474397/888800 53.38%] train loss: 3.894869587384164e-05 \n",
      "epoch: 2 [475508/888800 53.50%] train loss: 5.448293450172059e-05 \n",
      "epoch: 2 [476619/888800 53.62%] train loss: 4.8835914640221745e-05 \n",
      "epoch: 2 [477730/888800 53.75%] train loss: 4.388686647871509e-05 \n",
      "epoch: 2 [478841/888800 53.88%] train loss: 4.1939336369978264e-05 \n",
      "epoch: 2 [479952/888800 54.00%] train loss: 4.996479765395634e-05 \n",
      "epoch: 2 [481063/888800 54.12%] train loss: 4.8186160711338744e-05 \n",
      "epoch: 2 [482174/888800 54.25%] train loss: 5.293127833283506e-05 \n",
      "epoch: 2 [483285/888800 54.38%] train loss: 4.535169500741176e-05 \n",
      "epoch: 2 [484396/888800 54.50%] train loss: 5.008405423723161e-05 \n",
      "epoch: 2 [485507/888800 54.62%] train loss: 4.3928881495958194e-05 \n",
      "epoch: 2 [486618/888800 54.75%] train loss: 4.7813515266170725e-05 \n",
      "epoch: 2 [487729/888800 54.88%] train loss: 4.196588270133361e-05 \n",
      "epoch: 2 [488840/888800 55.00%] train loss: 4.316054764785804e-05 \n",
      "epoch: 2 [489951/888800 55.12%] train loss: 3.957953231292777e-05 \n",
      "epoch: 2 [491062/888800 55.25%] train loss: 4.5132459490559995e-05 \n",
      "epoch: 2 [492173/888800 55.38%] train loss: 4.6739780373172835e-05 \n",
      "epoch: 2 [493284/888800 55.50%] train loss: 3.9510610804427415e-05 \n",
      "epoch: 2 [494395/888800 55.62%] train loss: 4.7110559535212815e-05 \n",
      "epoch: 2 [495506/888800 55.75%] train loss: 4.2481489799683914e-05 \n",
      "epoch: 2 [496617/888800 55.88%] train loss: 4.6819961426081136e-05 \n",
      "epoch: 2 [497728/888800 56.00%] train loss: 5.0735630793496966e-05 \n",
      "epoch: 2 [498839/888800 56.12%] train loss: 4.529341094894335e-05 \n",
      "epoch: 2 [499950/888800 56.25%] train loss: 4.8263253120239824e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 [501061/888800 56.38%] train loss: 4.1296698327641934e-05 \n",
      "epoch: 2 [502172/888800 56.50%] train loss: 3.4460572351235896e-05 \n",
      "epoch: 2 [503283/888800 56.62%] train loss: 3.851297151413746e-05 \n",
      "epoch: 2 [504394/888800 56.75%] train loss: 5.498361133504659e-05 \n",
      "epoch: 2 [505505/888800 56.88%] train loss: 4.367079236544669e-05 \n",
      "epoch: 2 [506616/888800 57.00%] train loss: 4.483501834329218e-05 \n",
      "epoch: 2 [507727/888800 57.12%] train loss: 4.67056488560047e-05 \n",
      "epoch: 2 [508838/888800 57.25%] train loss: 4.95685453643091e-05 \n",
      "epoch: 2 [509949/888800 57.38%] train loss: 3.955195643357001e-05 \n",
      "epoch: 2 [511060/888800 57.50%] train loss: 3.998326064902358e-05 \n",
      "epoch: 2 [512171/888800 57.62%] train loss: 4.336499478085898e-05 \n",
      "epoch: 2 [513282/888800 57.75%] train loss: 4.683690349338576e-05 \n",
      "epoch: 2 [514393/888800 57.88%] train loss: 4.479836570681073e-05 \n",
      "epoch: 2 [515504/888800 58.00%] train loss: 4.344931221567094e-05 \n",
      "epoch: 2 [516615/888800 58.12%] train loss: 5.362143929232843e-05 \n",
      "epoch: 2 [517726/888800 58.25%] train loss: 4.129527587792836e-05 \n",
      "epoch: 2 [518837/888800 58.38%] train loss: 4.962853927281685e-05 \n",
      "epoch: 2 [519948/888800 58.50%] train loss: 3.7420231819851324e-05 \n",
      "epoch: 2 [521059/888800 58.62%] train loss: 4.4018521293764934e-05 \n",
      "epoch: 2 [522170/888800 58.75%] train loss: 4.6719702368136495e-05 \n",
      "epoch: 2 [523281/888800 58.88%] train loss: 4.492695370572619e-05 \n",
      "epoch: 2 [524392/888800 59.00%] train loss: 4.231252387398854e-05 \n",
      "epoch: 2 [525503/888800 59.12%] train loss: 5.561917714658193e-05 \n",
      "epoch: 2 [526614/888800 59.25%] train loss: 4.0733728383202106e-05 \n",
      "epoch: 2 [527725/888800 59.38%] train loss: 4.088328932994045e-05 \n",
      "epoch: 2 [528836/888800 59.50%] train loss: 4.126231578993611e-05 \n",
      "epoch: 2 [529947/888800 59.62%] train loss: 4.381299004307948e-05 \n",
      "epoch: 2 [531058/888800 59.75%] train loss: 4.274653838365339e-05 \n",
      "epoch: 2 [532169/888800 59.88%] train loss: 4.691251888289116e-05 \n",
      "epoch: 2 [533280/888800 60.00%] train loss: 4.3454001570353284e-05 \n",
      "epoch: 2 [534391/888800 60.12%] train loss: 5.238168523646891e-05 \n",
      "epoch: 2 [535502/888800 60.25%] train loss: 4.049531708005816e-05 \n",
      "epoch: 2 [536613/888800 60.38%] train loss: 4.8117908590938896e-05 \n",
      "epoch: 2 [537724/888800 60.50%] train loss: 4.517500929068774e-05 \n",
      "epoch: 2 [538835/888800 60.62%] train loss: 4.028181865578517e-05 \n",
      "epoch: 2 [539946/888800 60.75%] train loss: 4.280955181457102e-05 \n",
      "epoch: 2 [541057/888800 60.88%] train loss: 4.611866097548045e-05 \n",
      "epoch: 2 [542168/888800 61.00%] train loss: 4.2872132326010615e-05 \n",
      "epoch: 2 [543279/888800 61.12%] train loss: 4.3598491174634546e-05 \n",
      "epoch: 2 [544390/888800 61.25%] train loss: 4.6073586418060586e-05 \n",
      "epoch: 2 [545501/888800 61.38%] train loss: 4.7177240048768e-05 \n",
      "epoch: 2 [546612/888800 61.50%] train loss: 4.670135604101233e-05 \n",
      "epoch: 2 [547723/888800 61.62%] train loss: 4.2206629586871713e-05 \n",
      "epoch: 2 [548834/888800 61.75%] train loss: 4.289229400455952e-05 \n",
      "epoch: 2 [549945/888800 61.88%] train loss: 4.447819082997739e-05 \n",
      "epoch: 2 [551056/888800 62.00%] train loss: 4.476288449950516e-05 \n",
      "epoch: 2 [552167/888800 62.12%] train loss: 4.246354365022853e-05 \n",
      "epoch: 2 [553278/888800 62.25%] train loss: 5.1294733566464856e-05 \n",
      "epoch: 2 [554389/888800 62.38%] train loss: 5.4563628509640694e-05 \n",
      "epoch: 2 [555500/888800 62.50%] train loss: 4.298427302273922e-05 \n",
      "epoch: 2 [556611/888800 62.62%] train loss: 4.4174230424687266e-05 \n",
      "epoch: 2 [557722/888800 62.75%] train loss: 3.446299160714261e-05 \n",
      "epoch: 2 [558833/888800 62.88%] train loss: 4.597671068040654e-05 \n",
      "epoch: 2 [559944/888800 63.00%] train loss: 4.631916817743331e-05 \n",
      "epoch: 2 [561055/888800 63.12%] train loss: 3.96484429074917e-05 \n",
      "epoch: 2 [562166/888800 63.25%] train loss: 4.503199670580216e-05 \n",
      "epoch: 2 [563277/888800 63.38%] train loss: 5.204071203479543e-05 \n",
      "epoch: 2 [564388/888800 63.50%] train loss: 4.4158732634969056e-05 \n",
      "epoch: 2 [565499/888800 63.62%] train loss: 5.2198734920239076e-05 \n",
      "epoch: 2 [566610/888800 63.75%] train loss: 4.125667692278512e-05 \n",
      "epoch: 2 [567721/888800 63.88%] train loss: 5.114604937261902e-05 \n",
      "epoch: 2 [568832/888800 64.00%] train loss: 4.7191912017297e-05 \n",
      "epoch: 2 [569943/888800 64.12%] train loss: 3.6917994293617085e-05 \n",
      "epoch: 2 [571054/888800 64.25%] train loss: 4.245540185365826e-05 \n",
      "epoch: 2 [572165/888800 64.38%] train loss: 4.209771941532381e-05 \n",
      "epoch: 2 [573276/888800 64.50%] train loss: 5.07803306390997e-05 \n",
      "epoch: 2 [574387/888800 64.62%] train loss: 4.017073297291063e-05 \n",
      "epoch: 2 [575498/888800 64.75%] train loss: 5.026280996389687e-05 \n",
      "epoch: 2 [576609/888800 64.88%] train loss: 4.589521631714888e-05 \n",
      "epoch: 2 [577720/888800 65.00%] train loss: 4.4998851080890745e-05 \n",
      "epoch: 2 [578831/888800 65.12%] train loss: 4.898940460407175e-05 \n",
      "epoch: 2 [579942/888800 65.25%] train loss: 4.589178570313379e-05 \n",
      "epoch: 2 [581053/888800 65.38%] train loss: 4.08677187806461e-05 \n",
      "epoch: 2 [582164/888800 65.50%] train loss: 3.8851136196171865e-05 \n",
      "epoch: 2 [583275/888800 65.62%] train loss: 4.949678623233922e-05 \n",
      "epoch: 2 [584386/888800 65.75%] train loss: 4.743522731587291e-05 \n",
      "epoch: 2 [585497/888800 65.88%] train loss: 3.8886162656126544e-05 \n",
      "epoch: 2 [586608/888800 66.00%] train loss: 3.897315764334053e-05 \n",
      "epoch: 2 [587719/888800 66.12%] train loss: 5.188193608773872e-05 \n",
      "epoch: 2 [588830/888800 66.25%] train loss: 5.553942537517287e-05 \n",
      "epoch: 2 [589941/888800 66.38%] train loss: 4.124612678424455e-05 \n",
      "epoch: 2 [591052/888800 66.50%] train loss: 5.0728878704831004e-05 \n",
      "epoch: 2 [592163/888800 66.62%] train loss: 4.752098902827129e-05 \n",
      "epoch: 2 [593274/888800 66.75%] train loss: 4.763777178595774e-05 \n",
      "epoch: 2 [594385/888800 66.88%] train loss: 4.8698540922487155e-05 \n",
      "epoch: 2 [595496/888800 67.00%] train loss: 4.8194200644502416e-05 \n",
      "epoch: 2 [596607/888800 67.12%] train loss: 4.820343747269362e-05 \n",
      "epoch: 2 [597718/888800 67.25%] train loss: 4.4453445298131555e-05 \n",
      "epoch: 2 [598829/888800 67.38%] train loss: 4.108368375455029e-05 \n",
      "epoch: 2 [599940/888800 67.50%] train loss: 4.431201159604825e-05 \n",
      "epoch: 2 [601051/888800 67.62%] train loss: 4.520175571087748e-05 \n",
      "epoch: 2 [602162/888800 67.75%] train loss: 4.833379352930933e-05 \n",
      "epoch: 2 [603273/888800 67.88%] train loss: 4.045837704325095e-05 \n",
      "epoch: 2 [604384/888800 68.00%] train loss: 4.486438774620183e-05 \n",
      "epoch: 2 [605495/888800 68.12%] train loss: 4.3511205149115995e-05 \n",
      "epoch: 2 [606606/888800 68.25%] train loss: 4.9736212531570345e-05 \n",
      "epoch: 2 [607717/888800 68.38%] train loss: 4.3315976654412225e-05 \n",
      "epoch: 2 [608828/888800 68.50%] train loss: 4.8179343139054254e-05 \n",
      "epoch: 2 [609939/888800 68.62%] train loss: 4.5333956222748384e-05 \n",
      "epoch: 2 [611050/888800 68.75%] train loss: 4.7960482334019616e-05 \n",
      "epoch: 2 [612161/888800 68.88%] train loss: 3.933178959414363e-05 \n",
      "epoch: 2 [613272/888800 69.00%] train loss: 5.258366945781745e-05 \n",
      "epoch: 2 [614383/888800 69.12%] train loss: 4.410358815221116e-05 \n",
      "epoch: 2 [615494/888800 69.25%] train loss: 4.0311137126991525e-05 \n",
      "epoch: 2 [616605/888800 69.38%] train loss: 3.340898911119439e-05 \n",
      "epoch: 2 [617716/888800 69.50%] train loss: 4.216661909595132e-05 \n",
      "epoch: 2 [618827/888800 69.62%] train loss: 5.5342687119264156e-05 \n",
      "epoch: 2 [619938/888800 69.75%] train loss: 5.465192225528881e-05 \n",
      "epoch: 2 [621049/888800 69.88%] train loss: 4.4995875214226544e-05 \n",
      "epoch: 2 [622160/888800 70.00%] train loss: 4.3597803596640006e-05 \n",
      "epoch: 2 [623271/888800 70.12%] train loss: 4.269267083145678e-05 \n",
      "epoch: 2 [624382/888800 70.25%] train loss: 3.934482083423063e-05 \n",
      "epoch: 2 [625493/888800 70.38%] train loss: 4.304104732000269e-05 \n",
      "epoch: 2 [626604/888800 70.50%] train loss: 5.084895747131668e-05 \n",
      "epoch: 2 [627715/888800 70.62%] train loss: 4.5794287871103734e-05 \n",
      "epoch: 2 [628826/888800 70.75%] train loss: 4.5353179302765056e-05 \n",
      "epoch: 2 [629937/888800 70.88%] train loss: 4.525105032371357e-05 \n",
      "epoch: 2 [631048/888800 71.00%] train loss: 4.750014340970665e-05 \n",
      "epoch: 2 [632159/888800 71.12%] train loss: 4.0605074900668114e-05 \n",
      "epoch: 2 [633270/888800 71.25%] train loss: 4.032077777083032e-05 \n",
      "epoch: 2 [634381/888800 71.38%] train loss: 4.757759961648844e-05 \n",
      "epoch: 2 [635492/888800 71.50%] train loss: 5.940524351899512e-05 \n",
      "epoch: 2 [636603/888800 71.62%] train loss: 4.6246674173744395e-05 \n",
      "epoch: 2 [637714/888800 71.75%] train loss: 4.232783612678759e-05 \n",
      "epoch: 2 [638825/888800 71.88%] train loss: 4.23039891757071e-05 \n",
      "epoch: 2 [639936/888800 72.00%] train loss: 4.5570148358820006e-05 \n",
      "epoch: 2 [641047/888800 72.12%] train loss: 4.3974501750199124e-05 \n",
      "epoch: 2 [642158/888800 72.25%] train loss: 4.445061131264083e-05 \n",
      "epoch: 2 [643269/888800 72.38%] train loss: 4.0738468669587746e-05 \n",
      "epoch: 2 [644380/888800 72.50%] train loss: 4.6451623347820714e-05 \n",
      "epoch: 2 [645491/888800 72.62%] train loss: 4.148804146097973e-05 \n",
      "epoch: 2 [646602/888800 72.75%] train loss: 3.9631471736356616e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 [647713/888800 72.88%] train loss: 4.3122399802086875e-05 \n",
      "epoch: 2 [648824/888800 73.00%] train loss: 4.446218372322619e-05 \n",
      "epoch: 2 [649935/888800 73.12%] train loss: 5.221821993472986e-05 \n",
      "epoch: 2 [651046/888800 73.25%] train loss: 4.726495171780698e-05 \n",
      "epoch: 2 [652157/888800 73.38%] train loss: 3.972306149080396e-05 \n",
      "epoch: 2 [653268/888800 73.50%] train loss: 5.2400555432541296e-05 \n",
      "epoch: 2 [654379/888800 73.62%] train loss: 4.378395533422008e-05 \n",
      "epoch: 2 [655490/888800 73.75%] train loss: 4.691129652201198e-05 \n",
      "epoch: 2 [656601/888800 73.88%] train loss: 5.3701707656728104e-05 \n",
      "epoch: 2 [657712/888800 74.00%] train loss: 4.393327981233597e-05 \n",
      "epoch: 2 [658823/888800 74.12%] train loss: 5.5923970649018884e-05 \n",
      "epoch: 2 [659934/888800 74.25%] train loss: 3.918047877959907e-05 \n",
      "epoch: 2 [661045/888800 74.38%] train loss: 4.286480907467194e-05 \n",
      "epoch: 2 [662156/888800 74.50%] train loss: 4.90065649501048e-05 \n",
      "epoch: 2 [663267/888800 74.62%] train loss: 4.681930295191705e-05 \n",
      "epoch: 2 [664378/888800 74.75%] train loss: 4.29254250775557e-05 \n",
      "epoch: 2 [665489/888800 74.88%] train loss: 4.567822179524228e-05 \n",
      "epoch: 2 [666600/888800 75.00%] train loss: 5.2886924095219e-05 \n",
      "epoch: 2 [667711/888800 75.12%] train loss: 5.096165114082396e-05 \n",
      "epoch: 2 [668822/888800 75.25%] train loss: 4.6282038965728134e-05 \n",
      "epoch: 2 [669933/888800 75.38%] train loss: 4.9454032705398276e-05 \n",
      "epoch: 2 [671044/888800 75.50%] train loss: 4.4110813178122044e-05 \n",
      "epoch: 2 [672155/888800 75.62%] train loss: 5.029679959989153e-05 \n",
      "epoch: 2 [673266/888800 75.75%] train loss: 4.764702680404298e-05 \n",
      "epoch: 2 [674377/888800 75.88%] train loss: 3.927693978766911e-05 \n",
      "epoch: 2 [675488/888800 76.00%] train loss: 4.060775609104894e-05 \n",
      "epoch: 2 [676599/888800 76.12%] train loss: 4.5180207962403074e-05 \n",
      "epoch: 2 [677710/888800 76.25%] train loss: 4.495395114645362e-05 \n",
      "epoch: 2 [678821/888800 76.38%] train loss: 4.600499232765287e-05 \n",
      "epoch: 2 [679932/888800 76.50%] train loss: 4.671478382078931e-05 \n",
      "epoch: 2 [681043/888800 76.62%] train loss: 4.841749250772409e-05 \n",
      "epoch: 2 [682154/888800 76.75%] train loss: 4.536842243396677e-05 \n",
      "epoch: 2 [683265/888800 76.88%] train loss: 4.3837426346726716e-05 \n",
      "epoch: 2 [684376/888800 77.00%] train loss: 4.615496072801761e-05 \n",
      "epoch: 2 [685487/888800 77.12%] train loss: 4.3232630559941754e-05 \n",
      "epoch: 2 [686598/888800 77.25%] train loss: 4.276268009562045e-05 \n",
      "epoch: 2 [687709/888800 77.38%] train loss: 4.437101961229928e-05 \n",
      "epoch: 2 [688820/888800 77.50%] train loss: 3.90062305086758e-05 \n",
      "epoch: 2 [689931/888800 77.62%] train loss: 4.637184247258119e-05 \n",
      "epoch: 2 [691042/888800 77.75%] train loss: 4.282317604520358e-05 \n",
      "epoch: 2 [692153/888800 77.88%] train loss: 4.3455827835714445e-05 \n",
      "epoch: 2 [693264/888800 78.00%] train loss: 4.536473352345638e-05 \n",
      "epoch: 2 [694375/888800 78.12%] train loss: 3.487359208520502e-05 \n",
      "epoch: 2 [695486/888800 78.25%] train loss: 4.357145735411905e-05 \n",
      "epoch: 2 [696597/888800 78.38%] train loss: 4.1913466702681035e-05 \n",
      "epoch: 2 [697708/888800 78.50%] train loss: 4.7889043344184756e-05 \n",
      "epoch: 2 [698819/888800 78.62%] train loss: 4.683655788539909e-05 \n",
      "epoch: 2 [699930/888800 78.75%] train loss: 5.017837247578427e-05 \n",
      "epoch: 2 [701041/888800 78.88%] train loss: 4.469987106858753e-05 \n",
      "epoch: 2 [702152/888800 79.00%] train loss: 4.520199217949994e-05 \n",
      "epoch: 2 [703263/888800 79.12%] train loss: 5.193606193643063e-05 \n",
      "epoch: 2 [704374/888800 79.25%] train loss: 4.2302370275137946e-05 \n",
      "epoch: 2 [705485/888800 79.38%] train loss: 3.698363070725463e-05 \n",
      "epoch: 2 [706596/888800 79.50%] train loss: 4.8324895033147186e-05 \n",
      "epoch: 2 [707707/888800 79.62%] train loss: 4.341430030763149e-05 \n",
      "epoch: 2 [708818/888800 79.75%] train loss: 5.292151399771683e-05 \n",
      "epoch: 2 [709929/888800 79.88%] train loss: 4.420144250616431e-05 \n",
      "epoch: 2 [711040/888800 80.00%] train loss: 4.3921074393438175e-05 \n",
      "epoch: 2 [712151/888800 80.12%] train loss: 5.000686724088155e-05 \n",
      "epoch: 2 [713262/888800 80.25%] train loss: 4.6796856622677296e-05 \n",
      "epoch: 2 [714373/888800 80.38%] train loss: 4.06613944505807e-05 \n",
      "epoch: 2 [715484/888800 80.50%] train loss: 4.520557922660373e-05 \n",
      "epoch: 2 [716595/888800 80.62%] train loss: 3.961324182455428e-05 \n",
      "epoch: 2 [717706/888800 80.75%] train loss: 4.5795426558470353e-05 \n",
      "epoch: 2 [718817/888800 80.88%] train loss: 4.635153527488001e-05 \n",
      "epoch: 2 [719928/888800 81.00%] train loss: 5.000462624593638e-05 \n",
      "epoch: 2 [721039/888800 81.12%] train loss: 5.0426409870851785e-05 \n",
      "epoch: 2 [722150/888800 81.25%] train loss: 3.9805021515348926e-05 \n",
      "epoch: 2 [723261/888800 81.38%] train loss: 4.8207723011728376e-05 \n",
      "epoch: 2 [724372/888800 81.50%] train loss: 4.697171971201897e-05 \n",
      "epoch: 2 [725483/888800 81.62%] train loss: 4.5462686102837324e-05 \n",
      "epoch: 2 [726594/888800 81.75%] train loss: 4.386380533105694e-05 \n",
      "epoch: 2 [727705/888800 81.88%] train loss: 4.1095128835877404e-05 \n",
      "epoch: 2 [728816/888800 82.00%] train loss: 5.388784484239295e-05 \n",
      "epoch: 2 [729927/888800 82.12%] train loss: 3.832243237411603e-05 \n",
      "epoch: 2 [731038/888800 82.25%] train loss: 4.3355928937671706e-05 \n",
      "epoch: 2 [732149/888800 82.38%] train loss: 3.8270929508144036e-05 \n",
      "epoch: 2 [733260/888800 82.50%] train loss: 5.1610175432870165e-05 \n",
      "epoch: 2 [734371/888800 82.62%] train loss: 4.635926234186627e-05 \n",
      "epoch: 2 [735482/888800 82.75%] train loss: 4.597621955326758e-05 \n",
      "epoch: 2 [736593/888800 82.88%] train loss: 4.918493868899532e-05 \n",
      "epoch: 2 [737704/888800 83.00%] train loss: 4.110556619707495e-05 \n",
      "epoch: 2 [738815/888800 83.12%] train loss: 4.40359981439542e-05 \n",
      "epoch: 2 [739926/888800 83.25%] train loss: 4.507173434831202e-05 \n",
      "epoch: 2 [741037/888800 83.38%] train loss: 4.673394141718745e-05 \n",
      "epoch: 2 [742148/888800 83.50%] train loss: 3.7227102438919246e-05 \n",
      "epoch: 2 [743259/888800 83.62%] train loss: 4.349823575466871e-05 \n",
      "epoch: 2 [744370/888800 83.75%] train loss: 4.0426370105706155e-05 \n",
      "epoch: 2 [745481/888800 83.88%] train loss: 4.081403312738985e-05 \n",
      "epoch: 2 [746592/888800 84.00%] train loss: 4.634343713405542e-05 \n",
      "epoch: 2 [747703/888800 84.12%] train loss: 4.2131410737056285e-05 \n",
      "epoch: 2 [748814/888800 84.25%] train loss: 5.0078022468369454e-05 \n",
      "epoch: 2 [749925/888800 84.38%] train loss: 4.538707071333192e-05 \n",
      "epoch: 2 [751036/888800 84.50%] train loss: 3.689778168336488e-05 \n",
      "epoch: 2 [752147/888800 84.62%] train loss: 4.418479875312187e-05 \n",
      "epoch: 2 [753258/888800 84.75%] train loss: 3.690441371873021e-05 \n",
      "epoch: 2 [754369/888800 84.88%] train loss: 3.459183790255338e-05 \n",
      "epoch: 2 [755480/888800 85.00%] train loss: 5.0285372708458453e-05 \n",
      "epoch: 2 [756591/888800 85.12%] train loss: 4.233376239426434e-05 \n",
      "epoch: 2 [757702/888800 85.25%] train loss: 3.631500294432044e-05 \n",
      "epoch: 2 [758813/888800 85.38%] train loss: 5.043772762292065e-05 \n",
      "epoch: 2 [759924/888800 85.50%] train loss: 3.983272108598612e-05 \n",
      "epoch: 2 [761035/888800 85.62%] train loss: 3.958410525228828e-05 \n",
      "epoch: 2 [762146/888800 85.75%] train loss: 4.424899452715181e-05 \n",
      "epoch: 2 [763257/888800 85.88%] train loss: 3.657973138615489e-05 \n",
      "epoch: 2 [764368/888800 86.00%] train loss: 4.110184090677649e-05 \n",
      "epoch: 2 [765479/888800 86.12%] train loss: 4.0702670958125964e-05 \n",
      "epoch: 2 [766590/888800 86.25%] train loss: 4.610907126334496e-05 \n",
      "epoch: 2 [767701/888800 86.38%] train loss: 4.3522737541934475e-05 \n",
      "epoch: 2 [768812/888800 86.50%] train loss: 4.208345853840001e-05 \n",
      "epoch: 2 [769923/888800 86.62%] train loss: 4.7872334107523784e-05 \n",
      "epoch: 2 [771034/888800 86.75%] train loss: 3.715114507940598e-05 \n",
      "epoch: 2 [772145/888800 86.88%] train loss: 3.9816393837099895e-05 \n",
      "epoch: 2 [773256/888800 87.00%] train loss: 5.963932562735863e-05 \n",
      "epoch: 2 [774367/888800 87.12%] train loss: 3.6654455470852554e-05 \n",
      "epoch: 2 [775478/888800 87.25%] train loss: 4.698125849245116e-05 \n",
      "epoch: 2 [776589/888800 87.38%] train loss: 3.7981659261276945e-05 \n",
      "epoch: 2 [777700/888800 87.50%] train loss: 4.240229100105353e-05 \n",
      "epoch: 2 [778811/888800 87.62%] train loss: 4.557066858978942e-05 \n",
      "epoch: 2 [779922/888800 87.75%] train loss: 4.4610296754399315e-05 \n",
      "epoch: 2 [781033/888800 87.88%] train loss: 3.94074922951404e-05 \n",
      "epoch: 2 [782144/888800 88.00%] train loss: 5.124200470163487e-05 \n",
      "epoch: 2 [783255/888800 88.12%] train loss: 5.2627219702117145e-05 \n",
      "epoch: 2 [784366/888800 88.25%] train loss: 4.703398371930234e-05 \n",
      "epoch: 2 [785477/888800 88.38%] train loss: 4.336091660661623e-05 \n",
      "epoch: 2 [786588/888800 88.50%] train loss: 4.430484113981947e-05 \n",
      "epoch: 2 [787699/888800 88.62%] train loss: 4.2919702536892146e-05 \n",
      "epoch: 2 [788810/888800 88.75%] train loss: 4.157236617174931e-05 \n",
      "epoch: 2 [789921/888800 88.88%] train loss: 4.228209218126722e-05 \n",
      "epoch: 2 [791032/888800 89.00%] train loss: 3.56132622982841e-05 \n",
      "epoch: 2 [792143/888800 89.12%] train loss: 4.481484938878566e-05 \n",
      "epoch: 2 [793254/888800 89.25%] train loss: 5.05154202983249e-05 \n",
      "epoch: 2 [794365/888800 89.38%] train loss: 4.664689186029136e-05 \n",
      "epoch: 2 [795476/888800 89.50%] train loss: 3.816641037701629e-05 \n",
      "epoch: 2 [796587/888800 89.62%] train loss: 4.3124411604367197e-05 \n",
      "epoch: 2 [797698/888800 89.75%] train loss: 4.2606039642123505e-05 \n",
      "epoch: 2 [798809/888800 89.88%] train loss: 4.6583765652030706e-05 \n",
      "epoch: 2 [799920/888800 90.00%] train loss: 4.656052988138981e-05 \n",
      "epoch: 2 [801031/888800 90.12%] train loss: 4.531409285846166e-05 \n",
      "epoch: 2 [802142/888800 90.25%] train loss: 4.3497806473169476e-05 \n",
      "epoch: 2 [803253/888800 90.38%] train loss: 4.22529956267681e-05 \n",
      "epoch: 2 [804364/888800 90.50%] train loss: 5.329148189048283e-05 \n",
      "epoch: 2 [805475/888800 90.62%] train loss: 3.894935071002692e-05 \n",
      "epoch: 2 [806586/888800 90.75%] train loss: 5.798331767437048e-05 \n",
      "epoch: 2 [807697/888800 90.88%] train loss: 4.731527224066667e-05 \n",
      "epoch: 2 [808808/888800 91.00%] train loss: 4.628854003385641e-05 \n",
      "epoch: 2 [809919/888800 91.12%] train loss: 3.7703248381149024e-05 \n",
      "epoch: 2 [811030/888800 91.25%] train loss: 3.529593595885672e-05 \n",
      "epoch: 2 [812141/888800 91.38%] train loss: 4.998899748898111e-05 \n",
      "epoch: 2 [813252/888800 91.50%] train loss: 5.036958827986382e-05 \n",
      "epoch: 2 [814363/888800 91.62%] train loss: 4.503887248574756e-05 \n",
      "epoch: 2 [815474/888800 91.75%] train loss: 3.3082731533795595e-05 \n",
      "epoch: 2 [816585/888800 91.88%] train loss: 4.9653066525934264e-05 \n",
      "epoch: 2 [817696/888800 92.00%] train loss: 4.3690772145055234e-05 \n",
      "epoch: 2 [818807/888800 92.12%] train loss: 3.7106492527527735e-05 \n",
      "epoch: 2 [819918/888800 92.25%] train loss: 3.9656930312048644e-05 \n",
      "epoch: 2 [821029/888800 92.38%] train loss: 4.2517553083598614e-05 \n",
      "epoch: 2 [822140/888800 92.50%] train loss: 4.4456322939367965e-05 \n",
      "epoch: 2 [823251/888800 92.62%] train loss: 4.637378515326418e-05 \n",
      "epoch: 2 [824362/888800 92.75%] train loss: 4.1754650737857446e-05 \n",
      "epoch: 2 [825473/888800 92.88%] train loss: 3.426591138122603e-05 \n",
      "epoch: 2 [826584/888800 93.00%] train loss: 4.109453220735304e-05 \n",
      "epoch: 2 [827695/888800 93.12%] train loss: 5.03114570165053e-05 \n",
      "epoch: 2 [828806/888800 93.25%] train loss: 4.308291681809351e-05 \n",
      "epoch: 2 [829917/888800 93.38%] train loss: 3.8837839383631945e-05 \n",
      "epoch: 2 [831028/888800 93.50%] train loss: 3.771105912164785e-05 \n",
      "epoch: 2 [832139/888800 93.62%] train loss: 4.0343875298276544e-05 \n",
      "epoch: 2 [833250/888800 93.75%] train loss: 5.186249836697243e-05 \n",
      "epoch: 2 [834361/888800 93.88%] train loss: 4.20641154050827e-05 \n",
      "epoch: 2 [835472/888800 94.00%] train loss: 4.424866347108036e-05 \n",
      "epoch: 2 [836583/888800 94.12%] train loss: 4.320506195654161e-05 \n",
      "epoch: 2 [837694/888800 94.25%] train loss: 4.833246202906594e-05 \n",
      "epoch: 2 [838805/888800 94.38%] train loss: 4.5724864321528e-05 \n",
      "epoch: 2 [839916/888800 94.50%] train loss: 4.868850373895839e-05 \n",
      "epoch: 2 [841027/888800 94.62%] train loss: 4.2484938603593037e-05 \n",
      "epoch: 2 [842138/888800 94.75%] train loss: 4.0181083022616804e-05 \n",
      "epoch: 2 [843249/888800 94.88%] train loss: 4.0674236515769735e-05 \n",
      "epoch: 2 [844360/888800 95.00%] train loss: 4.6512428525602445e-05 \n",
      "epoch: 2 [845471/888800 95.12%] train loss: 4.491604704526253e-05 \n",
      "epoch: 2 [846582/888800 95.25%] train loss: 4.532836101134308e-05 \n",
      "epoch: 2 [847693/888800 95.38%] train loss: 3.432486118981615e-05 \n",
      "epoch: 2 [848804/888800 95.50%] train loss: 5.148396303411573e-05 \n",
      "epoch: 2 [849915/888800 95.62%] train loss: 3.983858914580196e-05 \n",
      "epoch: 2 [851026/888800 95.75%] train loss: 4.313719546189532e-05 \n",
      "epoch: 2 [852137/888800 95.88%] train loss: 4.4271302613196895e-05 \n",
      "epoch: 2 [853248/888800 96.00%] train loss: 4.830662510357797e-05 \n",
      "epoch: 2 [854359/888800 96.12%] train loss: 4.020949199912138e-05 \n",
      "epoch: 2 [855470/888800 96.25%] train loss: 4.7087316488614306e-05 \n",
      "epoch: 2 [856581/888800 96.38%] train loss: 4.3317315430613235e-05 \n",
      "epoch: 2 [857692/888800 96.50%] train loss: 4.926469046040438e-05 \n",
      "epoch: 2 [858803/888800 96.62%] train loss: 3.3537322451593354e-05 \n",
      "epoch: 2 [859914/888800 96.75%] train loss: 5.034889909438789e-05 \n",
      "epoch: 2 [861025/888800 96.88%] train loss: 4.644527143682353e-05 \n",
      "epoch: 2 [862136/888800 97.00%] train loss: 5.4839863878441975e-05 \n",
      "epoch: 2 [863247/888800 97.12%] train loss: 4.0487851947546005e-05 \n",
      "epoch: 2 [864358/888800 97.25%] train loss: 4.819603418582119e-05 \n",
      "epoch: 2 [865469/888800 97.38%] train loss: 3.558705429895781e-05 \n",
      "epoch: 2 [866580/888800 97.50%] train loss: 4.496288238442503e-05 \n",
      "epoch: 2 [867691/888800 97.62%] train loss: 4.938425627187826e-05 \n",
      "epoch: 2 [868802/888800 97.75%] train loss: 4.766203710460104e-05 \n",
      "epoch: 2 [869913/888800 97.88%] train loss: 3.813945659203455e-05 \n",
      "epoch: 2 [871024/888800 98.00%] train loss: 4.064604945597239e-05 \n",
      "epoch: 2 [872135/888800 98.12%] train loss: 4.3933847337029874e-05 \n",
      "epoch: 2 [873246/888800 98.25%] train loss: 4.4522745156427845e-05 \n",
      "epoch: 2 [874357/888800 98.38%] train loss: 4.29943720519077e-05 \n",
      "epoch: 2 [875468/888800 98.50%] train loss: 4.9785197916207835e-05 \n",
      "epoch: 2 [876579/888800 98.62%] train loss: 4.610049654729664e-05 \n",
      "epoch: 2 [877690/888800 98.75%] train loss: 4.2825598939089105e-05 \n",
      "epoch: 2 [878801/888800 98.88%] train loss: 4.9247184506384656e-05 \n",
      "epoch: 2 [879912/888800 99.00%] train loss: 4.9494487029733136e-05 \n",
      "epoch: 2 [881023/888800 99.12%] train loss: 5.4612199164694175e-05 \n",
      "epoch: 2 [882134/888800 99.25%] train loss: 5.117839464219287e-05 \n",
      "epoch: 2 [883245/888800 99.38%] train loss: 4.185717989457771e-05 \n",
      "epoch: 2 [884356/888800 99.50%] train loss: 4.469254781724885e-05 \n",
      "epoch: 2 [885467/888800 99.62%] train loss: 4.917820115224458e-05 \n",
      "epoch: 2 [886578/888800 99.75%] train loss: 4.518581772572361e-05 \n",
      "epoch: 2 [887689/888800 99.88%] train loss: 5.407756179920398e-05 \n",
      "epoch: 3 [0/888800 0.00%] train loss: 4.710428765974939e-05 \n",
      "epoch: 3 [1111/888800 0.12%] train loss: 5.411628444562666e-05 \n",
      "epoch: 3 [2222/888800 0.25%] train loss: 4.1519346268614754e-05 \n",
      "epoch: 3 [3333/888800 0.38%] train loss: 3.8900147046661004e-05 \n",
      "epoch: 3 [4444/888800 0.50%] train loss: 4.436746166902594e-05 \n",
      "epoch: 3 [5555/888800 0.62%] train loss: 5.1075050578219816e-05 \n",
      "epoch: 3 [6666/888800 0.75%] train loss: 4.887932664132677e-05 \n",
      "epoch: 3 [7777/888800 0.88%] train loss: 4.9516114813741297e-05 \n",
      "epoch: 3 [8888/888800 1.00%] train loss: 3.972258127760142e-05 \n",
      "epoch: 3 [9999/888800 1.12%] train loss: 3.9965161704458296e-05 \n",
      "epoch: 3 [11110/888800 1.25%] train loss: 3.83088226953987e-05 \n",
      "epoch: 3 [12221/888800 1.38%] train loss: 4.455152156879194e-05 \n",
      "epoch: 3 [13332/888800 1.50%] train loss: 4.224734220770188e-05 \n",
      "epoch: 3 [14443/888800 1.62%] train loss: 4.587625153362751e-05 \n",
      "epoch: 3 [15554/888800 1.75%] train loss: 4.567827272694558e-05 \n",
      "epoch: 3 [16665/888800 1.88%] train loss: 3.92811416531913e-05 \n",
      "epoch: 3 [17776/888800 2.00%] train loss: 4.829903627978638e-05 \n",
      "epoch: 3 [18887/888800 2.12%] train loss: 4.251807331456803e-05 \n",
      "epoch: 3 [19998/888800 2.25%] train loss: 4.50669540441595e-05 \n",
      "epoch: 3 [21109/888800 2.38%] train loss: 4.595161590259522e-05 \n",
      "epoch: 3 [22220/888800 2.50%] train loss: 5.309777407092042e-05 \n",
      "epoch: 3 [23331/888800 2.62%] train loss: 4.041624197270721e-05 \n",
      "epoch: 3 [24442/888800 2.75%] train loss: 3.919820301234722e-05 \n",
      "epoch: 3 [25553/888800 2.88%] train loss: 4.388217712403275e-05 \n",
      "epoch: 3 [26664/888800 3.00%] train loss: 5.475625584949739e-05 \n",
      "epoch: 3 [27775/888800 3.12%] train loss: 4.779050141223706e-05 \n",
      "epoch: 3 [28886/888800 3.25%] train loss: 4.957980490871705e-05 \n",
      "epoch: 3 [29997/888800 3.38%] train loss: 4.4774387788493186e-05 \n",
      "epoch: 3 [31108/888800 3.50%] train loss: 4.180212636128999e-05 \n",
      "epoch: 3 [32219/888800 3.62%] train loss: 3.763785935007036e-05 \n",
      "epoch: 3 [33330/888800 3.75%] train loss: 4.414088834892027e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [34441/888800 3.88%] train loss: 4.106567575945519e-05 \n",
      "epoch: 3 [35552/888800 4.00%] train loss: 4.011127384728752e-05 \n",
      "epoch: 3 [36663/888800 4.12%] train loss: 3.8776932342443615e-05 \n",
      "epoch: 3 [37774/888800 4.25%] train loss: 4.7175970394164324e-05 \n",
      "epoch: 3 [38885/888800 4.38%] train loss: 3.810906855505891e-05 \n",
      "epoch: 3 [39996/888800 4.50%] train loss: 4.4446729589253664e-05 \n",
      "epoch: 3 [41107/888800 4.62%] train loss: 3.9647235098527744e-05 \n",
      "epoch: 3 [42218/888800 4.75%] train loss: 3.713323894771747e-05 \n",
      "epoch: 3 [43329/888800 4.88%] train loss: 4.747622733702883e-05 \n",
      "epoch: 3 [44440/888800 5.00%] train loss: 3.830809146165848e-05 \n",
      "epoch: 3 [45551/888800 5.12%] train loss: 4.5600183511851355e-05 \n",
      "epoch: 3 [46662/888800 5.25%] train loss: 4.988356158719398e-05 \n",
      "epoch: 3 [47773/888800 5.38%] train loss: 4.042796717840247e-05 \n",
      "epoch: 3 [48884/888800 5.50%] train loss: 4.425428414833732e-05 \n",
      "epoch: 3 [49995/888800 5.62%] train loss: 5.1477592933224514e-05 \n",
      "epoch: 3 [51106/888800 5.75%] train loss: 4.509601421887055e-05 \n",
      "epoch: 3 [52217/888800 5.88%] train loss: 4.244278170517646e-05 \n",
      "epoch: 3 [53328/888800 6.00%] train loss: 4.2372470488771796e-05 \n",
      "epoch: 3 [54439/888800 6.12%] train loss: 4.246489697834477e-05 \n",
      "epoch: 3 [55550/888800 6.25%] train loss: 4.44739889644552e-05 \n",
      "epoch: 3 [56661/888800 6.38%] train loss: 5.014323687646538e-05 \n",
      "epoch: 3 [57772/888800 6.50%] train loss: 4.139674638281576e-05 \n",
      "epoch: 3 [58883/888800 6.62%] train loss: 4.78614165331237e-05 \n",
      "epoch: 3 [59994/888800 6.75%] train loss: 4.3464508053148165e-05 \n",
      "epoch: 3 [61105/888800 6.88%] train loss: 4.6281198592623696e-05 \n",
      "epoch: 3 [62216/888800 7.00%] train loss: 4.939028440276161e-05 \n",
      "epoch: 3 [63327/888800 7.12%] train loss: 4.455187081475742e-05 \n",
      "epoch: 3 [64438/888800 7.25%] train loss: 4.703771628555842e-05 \n",
      "epoch: 3 [65549/888800 7.38%] train loss: 4.682249709730968e-05 \n",
      "epoch: 3 [66660/888800 7.50%] train loss: 4.062216976308264e-05 \n",
      "epoch: 3 [67771/888800 7.62%] train loss: 3.5588513128459454e-05 \n",
      "epoch: 3 [68882/888800 7.75%] train loss: 4.0446400817018e-05 \n",
      "epoch: 3 [69993/888800 7.88%] train loss: 3.889740401064046e-05 \n",
      "epoch: 3 [71104/888800 8.00%] train loss: 4.694426024798304e-05 \n",
      "epoch: 3 [72215/888800 8.12%] train loss: 3.9579073927598074e-05 \n",
      "epoch: 3 [73326/888800 8.25%] train loss: 4.1237992263631895e-05 \n",
      "epoch: 3 [74437/888800 8.38%] train loss: 5.03202281834092e-05 \n",
      "epoch: 3 [75548/888800 8.50%] train loss: 4.746710692415945e-05 \n",
      "epoch: 3 [76659/888800 8.62%] train loss: 4.034669473185204e-05 \n",
      "epoch: 3 [77770/888800 8.75%] train loss: 4.2063125874847174e-05 \n",
      "epoch: 3 [78881/888800 8.88%] train loss: 4.568481381284073e-05 \n",
      "epoch: 3 [79992/888800 9.00%] train loss: 3.604900848586112e-05 \n",
      "epoch: 3 [81103/888800 9.12%] train loss: 3.4380842407699674e-05 \n",
      "epoch: 3 [82214/888800 9.25%] train loss: 4.360122693469748e-05 \n",
      "epoch: 3 [83325/888800 9.38%] train loss: 5.023790436098352e-05 \n",
      "epoch: 3 [84436/888800 9.50%] train loss: 4.308239294914529e-05 \n",
      "epoch: 3 [85547/888800 9.62%] train loss: 4.228421312291175e-05 \n",
      "epoch: 3 [86658/888800 9.75%] train loss: 4.802378316526301e-05 \n",
      "epoch: 3 [87769/888800 9.88%] train loss: 3.952032056986354e-05 \n",
      "epoch: 3 [88880/888800 10.00%] train loss: 4.368805457488634e-05 \n",
      "epoch: 3 [89991/888800 10.12%] train loss: 4.283593807485886e-05 \n",
      "epoch: 3 [91102/888800 10.25%] train loss: 4.525442636804655e-05 \n",
      "epoch: 3 [92213/888800 10.38%] train loss: 4.071288276463747e-05 \n",
      "epoch: 3 [93324/888800 10.50%] train loss: 4.4865842937724665e-05 \n",
      "epoch: 3 [94435/888800 10.62%] train loss: 3.4986027458216995e-05 \n",
      "epoch: 3 [95546/888800 10.75%] train loss: 3.80921846954152e-05 \n",
      "epoch: 3 [96657/888800 10.88%] train loss: 4.614468343788758e-05 \n",
      "epoch: 3 [97768/888800 11.00%] train loss: 4.802584589924663e-05 \n",
      "epoch: 3 [98879/888800 11.12%] train loss: 4.82286122860387e-05 \n",
      "epoch: 3 [99990/888800 11.25%] train loss: 3.831904905382544e-05 \n",
      "epoch: 3 [101101/888800 11.38%] train loss: 4.7984940465539694e-05 \n",
      "epoch: 3 [102212/888800 11.50%] train loss: 4.6712284529348835e-05 \n",
      "epoch: 3 [103323/888800 11.62%] train loss: 5.0674461817834526e-05 \n",
      "epoch: 3 [104434/888800 11.75%] train loss: 4.1430706914979964e-05 \n",
      "epoch: 3 [105545/888800 11.88%] train loss: 5.543963925447315e-05 \n",
      "epoch: 3 [106656/888800 12.00%] train loss: 4.763036122312769e-05 \n",
      "epoch: 3 [107767/888800 12.12%] train loss: 5.323299046722241e-05 \n",
      "epoch: 3 [108878/888800 12.25%] train loss: 4.365955101093277e-05 \n",
      "epoch: 3 [109989/888800 12.38%] train loss: 3.684370676637627e-05 \n",
      "epoch: 3 [111100/888800 12.50%] train loss: 5.2988005336374044e-05 \n",
      "epoch: 3 [112211/888800 12.62%] train loss: 4.20582655351609e-05 \n",
      "epoch: 3 [113322/888800 12.75%] train loss: 4.3962005292996764e-05 \n",
      "epoch: 3 [114433/888800 12.88%] train loss: 4.345327033661306e-05 \n",
      "epoch: 3 [115544/888800 13.00%] train loss: 3.5498658689903095e-05 \n",
      "epoch: 3 [116655/888800 13.12%] train loss: 3.937098153983243e-05 \n",
      "epoch: 3 [117766/888800 13.25%] train loss: 3.497861325740814e-05 \n",
      "epoch: 3 [118877/888800 13.38%] train loss: 4.0526090742787346e-05 \n",
      "epoch: 3 [119988/888800 13.50%] train loss: 4.675890158978291e-05 \n",
      "epoch: 3 [121099/888800 13.62%] train loss: 4.338348298915662e-05 \n",
      "epoch: 3 [122210/888800 13.75%] train loss: 4.5677763409912586e-05 \n",
      "epoch: 3 [123321/888800 13.88%] train loss: 4.464137236936949e-05 \n",
      "epoch: 3 [124432/888800 14.00%] train loss: 4.6758130338275805e-05 \n",
      "epoch: 3 [125543/888800 14.12%] train loss: 4.4290314690442756e-05 \n",
      "epoch: 3 [126654/888800 14.25%] train loss: 4.1880593926180154e-05 \n",
      "epoch: 3 [127765/888800 14.38%] train loss: 4.949998765368946e-05 \n",
      "epoch: 3 [128876/888800 14.50%] train loss: 4.7401030315086246e-05 \n",
      "epoch: 3 [129987/888800 14.62%] train loss: 4.6298162487801164e-05 \n",
      "epoch: 3 [131098/888800 14.75%] train loss: 4.805283242603764e-05 \n",
      "epoch: 3 [132209/888800 14.88%] train loss: 4.670692214858718e-05 \n",
      "epoch: 3 [133320/888800 15.00%] train loss: 4.5501736167352647e-05 \n",
      "epoch: 3 [134431/888800 15.12%] train loss: 3.86566280212719e-05 \n",
      "epoch: 3 [135542/888800 15.25%] train loss: 4.4988479203311726e-05 \n",
      "epoch: 3 [136653/888800 15.38%] train loss: 4.588926094584167e-05 \n",
      "epoch: 3 [137764/888800 15.50%] train loss: 4.329953662818298e-05 \n",
      "epoch: 3 [138875/888800 15.62%] train loss: 3.9722490328131244e-05 \n",
      "epoch: 3 [139986/888800 15.75%] train loss: 3.887041748384945e-05 \n",
      "epoch: 3 [141097/888800 15.88%] train loss: 3.99736782128457e-05 \n",
      "epoch: 3 [142208/888800 16.00%] train loss: 4.084736792719923e-05 \n",
      "epoch: 3 [143319/888800 16.12%] train loss: 4.389495370560326e-05 \n",
      "epoch: 3 [144430/888800 16.25%] train loss: 4.2518851842032745e-05 \n",
      "epoch: 3 [145541/888800 16.38%] train loss: 4.1718001739354804e-05 \n",
      "epoch: 3 [146652/888800 16.50%] train loss: 4.360182720120065e-05 \n",
      "epoch: 3 [147763/888800 16.62%] train loss: 4.589701347867958e-05 \n",
      "epoch: 3 [148874/888800 16.75%] train loss: 4.35784604633227e-05 \n",
      "epoch: 3 [149985/888800 16.88%] train loss: 4.100311343790963e-05 \n",
      "epoch: 3 [151096/888800 17.00%] train loss: 3.6804147384827957e-05 \n",
      "epoch: 3 [152207/888800 17.12%] train loss: 4.3828709749504924e-05 \n",
      "epoch: 3 [153318/888800 17.25%] train loss: 4.9522695917403325e-05 \n",
      "epoch: 3 [154429/888800 17.38%] train loss: 4.081568476976827e-05 \n",
      "epoch: 3 [155540/888800 17.50%] train loss: 4.495193206821568e-05 \n",
      "epoch: 3 [156651/888800 17.62%] train loss: 4.547062053461559e-05 \n",
      "epoch: 3 [157762/888800 17.75%] train loss: 4.208478276268579e-05 \n",
      "epoch: 3 [158873/888800 17.88%] train loss: 4.681467544287443e-05 \n",
      "epoch: 3 [159984/888800 18.00%] train loss: 5.123826122144237e-05 \n",
      "epoch: 3 [161095/888800 18.12%] train loss: 4.70692066301126e-05 \n",
      "epoch: 3 [162206/888800 18.25%] train loss: 4.940624421578832e-05 \n",
      "epoch: 3 [163317/888800 18.38%] train loss: 4.6587432734668255e-05 \n",
      "epoch: 3 [164428/888800 18.50%] train loss: 4.422213532961905e-05 \n",
      "epoch: 3 [165539/888800 18.62%] train loss: 4.817332228412852e-05 \n",
      "epoch: 3 [166650/888800 18.75%] train loss: 4.222384450258687e-05 \n",
      "epoch: 3 [167761/888800 18.88%] train loss: 3.910837767762132e-05 \n",
      "epoch: 3 [168872/888800 19.00%] train loss: 4.385642023407854e-05 \n",
      "epoch: 3 [169983/888800 19.12%] train loss: 3.5367404052522033e-05 \n",
      "epoch: 3 [171094/888800 19.25%] train loss: 4.350968447397463e-05 \n",
      "epoch: 3 [172205/888800 19.38%] train loss: 4.276768959243782e-05 \n",
      "epoch: 3 [173316/888800 19.50%] train loss: 4.241210626787506e-05 \n",
      "epoch: 3 [174427/888800 19.62%] train loss: 4.3234256736468524e-05 \n",
      "epoch: 3 [175538/888800 19.75%] train loss: 3.7727841117884964e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [176649/888800 19.88%] train loss: 5.110791971674189e-05 \n",
      "epoch: 3 [177760/888800 20.00%] train loss: 4.0902312321122736e-05 \n",
      "epoch: 3 [178871/888800 20.12%] train loss: 4.535282641882077e-05 \n",
      "epoch: 3 [179982/888800 20.25%] train loss: 4.408032327773981e-05 \n",
      "epoch: 3 [181093/888800 20.38%] train loss: 4.230115155223757e-05 \n",
      "epoch: 3 [182204/888800 20.50%] train loss: 4.311896918807179e-05 \n",
      "epoch: 3 [183315/888800 20.62%] train loss: 4.2658652091631666e-05 \n",
      "epoch: 3 [184426/888800 20.75%] train loss: 4.775193883688189e-05 \n",
      "epoch: 3 [185537/888800 20.88%] train loss: 4.1818984755082056e-05 \n",
      "epoch: 3 [186648/888800 21.00%] train loss: 3.632251900853589e-05 \n",
      "epoch: 3 [187759/888800 21.12%] train loss: 4.33925524703227e-05 \n",
      "epoch: 3 [188870/888800 21.25%] train loss: 4.085906039108522e-05 \n",
      "epoch: 3 [189981/888800 21.38%] train loss: 4.378367157187313e-05 \n",
      "epoch: 3 [191092/888800 21.50%] train loss: 4.0114609873853624e-05 \n",
      "epoch: 3 [192203/888800 21.62%] train loss: 4.106987398699857e-05 \n",
      "epoch: 3 [193314/888800 21.75%] train loss: 4.6583943912992254e-05 \n",
      "epoch: 3 [194425/888800 21.88%] train loss: 4.8119713028427213e-05 \n",
      "epoch: 3 [195536/888800 22.00%] train loss: 4.231952698319219e-05 \n",
      "epoch: 3 [196647/888800 22.12%] train loss: 4.05362770834472e-05 \n",
      "epoch: 3 [197758/888800 22.25%] train loss: 3.9576134440721944e-05 \n",
      "epoch: 3 [198869/888800 22.38%] train loss: 4.5754393795505166e-05 \n",
      "epoch: 3 [199980/888800 22.50%] train loss: 4.5294775190996006e-05 \n",
      "epoch: 3 [201091/888800 22.62%] train loss: 4.6503933845087886e-05 \n",
      "epoch: 3 [202202/888800 22.75%] train loss: 4.534887557383627e-05 \n",
      "epoch: 3 [203313/888800 22.88%] train loss: 4.0490693208994344e-05 \n",
      "epoch: 3 [204424/888800 23.00%] train loss: 4.429291220731102e-05 \n",
      "epoch: 3 [205535/888800 23.12%] train loss: 4.066630208399147e-05 \n",
      "epoch: 3 [206646/888800 23.25%] train loss: 3.9466016460210085e-05 \n",
      "epoch: 3 [207757/888800 23.38%] train loss: 3.6098826967645437e-05 \n",
      "epoch: 3 [208868/888800 23.50%] train loss: 4.224097938276827e-05 \n",
      "epoch: 3 [209979/888800 23.62%] train loss: 4.2948009649990126e-05 \n",
      "epoch: 3 [211090/888800 23.75%] train loss: 3.856847251881845e-05 \n",
      "epoch: 3 [212201/888800 23.88%] train loss: 4.121110760024749e-05 \n",
      "epoch: 3 [213312/888800 24.00%] train loss: 4.097767669009045e-05 \n",
      "epoch: 3 [214423/888800 24.12%] train loss: 4.180247924523428e-05 \n",
      "epoch: 3 [215534/888800 24.25%] train loss: 4.154602356720716e-05 \n",
      "epoch: 3 [216645/888800 24.38%] train loss: 4.1348961531184614e-05 \n",
      "epoch: 3 [217756/888800 24.50%] train loss: 3.976797597715631e-05 \n",
      "epoch: 3 [218867/888800 24.62%] train loss: 4.644236832973547e-05 \n",
      "epoch: 3 [219978/888800 24.75%] train loss: 3.734615529538132e-05 \n",
      "epoch: 3 [221089/888800 24.88%] train loss: 4.9404385208617896e-05 \n",
      "epoch: 3 [222200/888800 25.00%] train loss: 4.639013423002325e-05 \n",
      "epoch: 3 [223311/888800 25.12%] train loss: 4.981258462066762e-05 \n",
      "epoch: 3 [224422/888800 25.25%] train loss: 4.951167284161784e-05 \n",
      "epoch: 3 [225533/888800 25.38%] train loss: 4.583333429764025e-05 \n",
      "epoch: 3 [226644/888800 25.50%] train loss: 4.9513600970385596e-05 \n",
      "epoch: 3 [227755/888800 25.62%] train loss: 4.6856701374053955e-05 \n",
      "epoch: 3 [228866/888800 25.75%] train loss: 4.998049189453013e-05 \n",
      "epoch: 3 [229977/888800 25.88%] train loss: 4.499632996157743e-05 \n",
      "epoch: 3 [231088/888800 26.00%] train loss: 5.32341146026738e-05 \n",
      "epoch: 3 [232199/888800 26.12%] train loss: 4.378033918328583e-05 \n",
      "epoch: 3 [233310/888800 26.25%] train loss: 3.935706990887411e-05 \n",
      "epoch: 3 [234421/888800 26.38%] train loss: 4.658735997509211e-05 \n",
      "epoch: 3 [235532/888800 26.50%] train loss: 4.217079549562186e-05 \n",
      "epoch: 3 [236643/888800 26.62%] train loss: 5.358748239814304e-05 \n",
      "epoch: 3 [237754/888800 26.75%] train loss: 5.0630806072149426e-05 \n",
      "epoch: 3 [238865/888800 26.88%] train loss: 4.457646355149336e-05 \n",
      "epoch: 3 [239976/888800 27.00%] train loss: 5.0528684369055554e-05 \n",
      "epoch: 3 [241087/888800 27.12%] train loss: 4.5359498471952975e-05 \n",
      "epoch: 3 [242198/888800 27.25%] train loss: 4.492114749155007e-05 \n",
      "epoch: 3 [243309/888800 27.38%] train loss: 3.589566040318459e-05 \n",
      "epoch: 3 [244420/888800 27.50%] train loss: 4.405079016578384e-05 \n",
      "epoch: 3 [245531/888800 27.62%] train loss: 4.715454997494817e-05 \n",
      "epoch: 3 [246642/888800 27.75%] train loss: 4.8271045670844615e-05 \n",
      "epoch: 3 [247753/888800 27.88%] train loss: 4.173171691945754e-05 \n",
      "epoch: 3 [248864/888800 28.00%] train loss: 4.854100552620366e-05 \n",
      "epoch: 3 [249975/888800 28.12%] train loss: 5.2875671826768667e-05 \n",
      "epoch: 3 [251086/888800 28.25%] train loss: 4.570561941363849e-05 \n",
      "epoch: 3 [252197/888800 28.38%] train loss: 4.726900806417689e-05 \n",
      "epoch: 3 [253308/888800 28.50%] train loss: 5.2679282816825435e-05 \n",
      "epoch: 3 [254419/888800 28.62%] train loss: 4.088882269570604e-05 \n",
      "epoch: 3 [255530/888800 28.75%] train loss: 4.8293473810190335e-05 \n",
      "epoch: 3 [256641/888800 28.88%] train loss: 4.574152626446448e-05 \n",
      "epoch: 3 [257752/888800 29.00%] train loss: 5.0349302910035476e-05 \n",
      "epoch: 3 [258863/888800 29.12%] train loss: 5.0847826059907675e-05 \n",
      "epoch: 3 [259974/888800 29.25%] train loss: 4.6552468120353296e-05 \n",
      "epoch: 3 [261085/888800 29.38%] train loss: 4.5453627535607666e-05 \n",
      "epoch: 3 [262196/888800 29.50%] train loss: 4.1889987187460065e-05 \n",
      "epoch: 3 [263307/888800 29.62%] train loss: 3.6389588785823435e-05 \n",
      "epoch: 3 [264418/888800 29.75%] train loss: 4.510972212301567e-05 \n",
      "epoch: 3 [265529/888800 29.88%] train loss: 3.8664726162096485e-05 \n",
      "epoch: 3 [266640/888800 30.00%] train loss: 5.018718002247624e-05 \n",
      "epoch: 3 [267751/888800 30.12%] train loss: 4.004825677839108e-05 \n",
      "epoch: 3 [268862/888800 30.25%] train loss: 4.5901349949417636e-05 \n",
      "epoch: 3 [269973/888800 30.38%] train loss: 4.580054519465193e-05 \n",
      "epoch: 3 [271084/888800 30.50%] train loss: 4.162911864113994e-05 \n",
      "epoch: 3 [272195/888800 30.62%] train loss: 3.44612417393364e-05 \n",
      "epoch: 3 [273306/888800 30.75%] train loss: 3.993955397163518e-05 \n",
      "epoch: 3 [274417/888800 30.88%] train loss: 4.223109863232821e-05 \n",
      "epoch: 3 [275528/888800 31.00%] train loss: 3.9822924009058625e-05 \n",
      "epoch: 3 [276639/888800 31.12%] train loss: 4.353623080532998e-05 \n",
      "epoch: 3 [277750/888800 31.25%] train loss: 5.216536737862043e-05 \n",
      "epoch: 3 [278861/888800 31.38%] train loss: 4.717632691608742e-05 \n",
      "epoch: 3 [279972/888800 31.50%] train loss: 3.801062484853901e-05 \n",
      "epoch: 3 [281083/888800 31.62%] train loss: 5.223169137025252e-05 \n",
      "epoch: 3 [282194/888800 31.75%] train loss: 4.999750308343209e-05 \n",
      "epoch: 3 [283305/888800 31.88%] train loss: 4.2819807276828215e-05 \n",
      "epoch: 3 [284416/888800 32.00%] train loss: 4.593111225403845e-05 \n",
      "epoch: 3 [285527/888800 32.12%] train loss: 4.7023284423630685e-05 \n",
      "epoch: 3 [286638/888800 32.25%] train loss: 4.1525298001943156e-05 \n",
      "epoch: 3 [287749/888800 32.38%] train loss: 4.34148678323254e-05 \n",
      "epoch: 3 [288860/888800 32.50%] train loss: 5.020400567445904e-05 \n",
      "epoch: 3 [289971/888800 32.62%] train loss: 3.9767772250343114e-05 \n",
      "epoch: 3 [291082/888800 32.75%] train loss: 4.068839189130813e-05 \n",
      "epoch: 3 [292193/888800 32.88%] train loss: 3.892002860084176e-05 \n",
      "epoch: 3 [293304/888800 33.00%] train loss: 4.2045161535497755e-05 \n",
      "epoch: 3 [294415/888800 33.12%] train loss: 3.914958506356925e-05 \n",
      "epoch: 3 [295526/888800 33.25%] train loss: 4.354193151812069e-05 \n",
      "epoch: 3 [296637/888800 33.38%] train loss: 4.558194996207021e-05 \n",
      "epoch: 3 [297748/888800 33.50%] train loss: 4.3116084270877764e-05 \n",
      "epoch: 3 [298859/888800 33.62%] train loss: 4.3439828004920855e-05 \n",
      "epoch: 3 [299970/888800 33.75%] train loss: 3.8214853702811524e-05 \n",
      "epoch: 3 [301081/888800 33.88%] train loss: 4.225440352456644e-05 \n",
      "epoch: 3 [302192/888800 34.00%] train loss: 4.8182591854128987e-05 \n",
      "epoch: 3 [303303/888800 34.12%] train loss: 4.612281554727815e-05 \n",
      "epoch: 3 [304414/888800 34.25%] train loss: 3.908782673534006e-05 \n",
      "epoch: 3 [305525/888800 34.38%] train loss: 3.7732730561401695e-05 \n",
      "epoch: 3 [306636/888800 34.50%] train loss: 4.584102862281725e-05 \n",
      "epoch: 3 [307747/888800 34.62%] train loss: 4.82783216284588e-05 \n",
      "epoch: 3 [308858/888800 34.75%] train loss: 4.072067531524226e-05 \n",
      "epoch: 3 [309969/888800 34.88%] train loss: 4.511952283792198e-05 \n",
      "epoch: 3 [311080/888800 35.00%] train loss: 5.079642869532108e-05 \n",
      "epoch: 3 [312191/888800 35.12%] train loss: 4.537291533779353e-05 \n",
      "epoch: 3 [313302/888800 35.25%] train loss: 4.567387804854661e-05 \n",
      "epoch: 3 [314413/888800 35.38%] train loss: 3.9914077206049114e-05 \n",
      "epoch: 3 [315524/888800 35.50%] train loss: 4.1906274418579414e-05 \n",
      "epoch: 3 [316635/888800 35.62%] train loss: 3.6944711609976366e-05 \n",
      "epoch: 3 [317746/888800 35.75%] train loss: 4.505681135924533e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [318857/888800 35.88%] train loss: 4.039816849399358e-05 \n",
      "epoch: 3 [319968/888800 36.00%] train loss: 4.60340925201308e-05 \n",
      "epoch: 3 [321079/888800 36.12%] train loss: 4.6347122406587005e-05 \n",
      "epoch: 3 [322190/888800 36.25%] train loss: 4.4078649807488546e-05 \n",
      "epoch: 3 [323301/888800 36.38%] train loss: 5.6139710068237036e-05 \n",
      "epoch: 3 [324412/888800 36.50%] train loss: 4.432912464835681e-05 \n",
      "epoch: 3 [325523/888800 36.62%] train loss: 4.205292134429328e-05 \n",
      "epoch: 3 [326634/888800 36.75%] train loss: 5.003848855267279e-05 \n",
      "epoch: 3 [327745/888800 36.88%] train loss: 4.0535087464377284e-05 \n",
      "epoch: 3 [328856/888800 37.00%] train loss: 4.326908310758881e-05 \n",
      "epoch: 3 [329967/888800 37.12%] train loss: 4.546025229501538e-05 \n",
      "epoch: 3 [331078/888800 37.25%] train loss: 4.573726619128138e-05 \n",
      "epoch: 3 [332189/888800 37.38%] train loss: 4.299850115785375e-05 \n",
      "epoch: 3 [333300/888800 37.50%] train loss: 4.774333137902431e-05 \n",
      "epoch: 3 [334411/888800 37.62%] train loss: 4.213793727103621e-05 \n",
      "epoch: 3 [335522/888800 37.75%] train loss: 4.4779644667869434e-05 \n",
      "epoch: 3 [336633/888800 37.88%] train loss: 4.406392326927744e-05 \n",
      "epoch: 3 [337744/888800 38.00%] train loss: 4.9656769988359883e-05 \n",
      "epoch: 3 [338855/888800 38.12%] train loss: 4.06237413699273e-05 \n",
      "epoch: 3 [339966/888800 38.25%] train loss: 3.9495051169069484e-05 \n",
      "epoch: 3 [341077/888800 38.38%] train loss: 4.365800486993976e-05 \n",
      "epoch: 3 [342188/888800 38.50%] train loss: 4.935310425935313e-05 \n",
      "epoch: 3 [343299/888800 38.62%] train loss: 4.16180191677995e-05 \n",
      "epoch: 3 [344410/888800 38.75%] train loss: 4.200930561637506e-05 \n",
      "epoch: 3 [345521/888800 38.88%] train loss: 3.6956069379812106e-05 \n",
      "epoch: 3 [346632/888800 39.00%] train loss: 4.3563253711909056e-05 \n",
      "epoch: 3 [347743/888800 39.12%] train loss: 4.739777068607509e-05 \n",
      "epoch: 3 [348854/888800 39.25%] train loss: 4.478925984585658e-05 \n",
      "epoch: 3 [349965/888800 39.38%] train loss: 3.9066202589310706e-05 \n",
      "epoch: 3 [351076/888800 39.50%] train loss: 3.743543857126497e-05 \n",
      "epoch: 3 [352187/888800 39.62%] train loss: 3.789327820413746e-05 \n",
      "epoch: 3 [353298/888800 39.75%] train loss: 3.6980363802285865e-05 \n",
      "epoch: 3 [354409/888800 39.88%] train loss: 4.436536255525425e-05 \n",
      "epoch: 3 [355520/888800 40.00%] train loss: 3.908342114300467e-05 \n",
      "epoch: 3 [356631/888800 40.12%] train loss: 4.418619573698379e-05 \n",
      "epoch: 3 [357742/888800 40.25%] train loss: 4.23717538069468e-05 \n",
      "epoch: 3 [358853/888800 40.38%] train loss: 3.836154064629227e-05 \n",
      "epoch: 3 [359964/888800 40.50%] train loss: 4.460225682123564e-05 \n",
      "epoch: 3 [361075/888800 40.62%] train loss: 3.8732250686734915e-05 \n",
      "epoch: 3 [362186/888800 40.75%] train loss: 4.463580626179464e-05 \n",
      "epoch: 3 [363297/888800 40.88%] train loss: 5.209194932831451e-05 \n",
      "epoch: 3 [364408/888800 41.00%] train loss: 4.564598202705383e-05 \n",
      "epoch: 3 [365519/888800 41.12%] train loss: 4.047496258863248e-05 \n",
      "epoch: 3 [366630/888800 41.25%] train loss: 3.491249299258925e-05 \n",
      "epoch: 3 [367741/888800 41.38%] train loss: 5.355350731406361e-05 \n",
      "epoch: 3 [368852/888800 41.50%] train loss: 4.2592691897880286e-05 \n",
      "epoch: 3 [369963/888800 41.62%] train loss: 4.103703759028576e-05 \n",
      "epoch: 3 [371074/888800 41.75%] train loss: 4.433665162650868e-05 \n",
      "epoch: 3 [372185/888800 41.88%] train loss: 4.279720815247856e-05 \n",
      "epoch: 3 [373296/888800 42.00%] train loss: 5.130958743393421e-05 \n",
      "epoch: 3 [374407/888800 42.12%] train loss: 4.2524905438767746e-05 \n",
      "epoch: 3 [375518/888800 42.25%] train loss: 3.29274007526692e-05 \n",
      "epoch: 3 [376629/888800 42.38%] train loss: 5.374319152906537e-05 \n",
      "epoch: 3 [377740/888800 42.50%] train loss: 4.674918091041036e-05 \n",
      "epoch: 3 [378851/888800 42.62%] train loss: 3.837545227725059e-05 \n",
      "epoch: 3 [379962/888800 42.75%] train loss: 4.4253465603105724e-05 \n",
      "epoch: 3 [381073/888800 42.88%] train loss: 4.410943802213296e-05 \n",
      "epoch: 3 [382184/888800 43.00%] train loss: 4.120168159715831e-05 \n",
      "epoch: 3 [383295/888800 43.12%] train loss: 4.7601188271073624e-05 \n",
      "epoch: 3 [384406/888800 43.25%] train loss: 4.123099279240705e-05 \n",
      "epoch: 3 [385517/888800 43.38%] train loss: 5.07725308125373e-05 \n",
      "epoch: 3 [386628/888800 43.50%] train loss: 4.6418219426414e-05 \n",
      "epoch: 3 [387739/888800 43.62%] train loss: 4.354861084721051e-05 \n",
      "epoch: 3 [388850/888800 43.75%] train loss: 4.804797936230898e-05 \n",
      "epoch: 3 [389961/888800 43.88%] train loss: 4.218469621264376e-05 \n",
      "epoch: 3 [391072/888800 44.00%] train loss: 4.040759085910395e-05 \n",
      "epoch: 3 [392183/888800 44.12%] train loss: 3.9142782043199986e-05 \n",
      "epoch: 3 [393294/888800 44.25%] train loss: 3.5397097235545516e-05 \n",
      "epoch: 3 [394405/888800 44.38%] train loss: 3.9182523323688656e-05 \n",
      "epoch: 3 [395516/888800 44.50%] train loss: 4.304592948756181e-05 \n",
      "epoch: 3 [396627/888800 44.62%] train loss: 4.5963832235429436e-05 \n",
      "epoch: 3 [397738/888800 44.75%] train loss: 5.1518534746719524e-05 \n",
      "epoch: 3 [398849/888800 44.88%] train loss: 4.3730749894166365e-05 \n",
      "epoch: 3 [399960/888800 45.00%] train loss: 4.596061626216397e-05 \n",
      "epoch: 3 [401071/888800 45.12%] train loss: 4.469813939067535e-05 \n",
      "epoch: 3 [402182/888800 45.25%] train loss: 3.907783320755698e-05 \n",
      "epoch: 3 [403293/888800 45.38%] train loss: 4.610676842276007e-05 \n",
      "epoch: 3 [404404/888800 45.50%] train loss: 4.691517460742034e-05 \n",
      "epoch: 3 [405515/888800 45.62%] train loss: 4.4972108298679814e-05 \n",
      "epoch: 3 [406626/888800 45.75%] train loss: 4.586649447446689e-05 \n",
      "epoch: 3 [407737/888800 45.88%] train loss: 3.5209886846132576e-05 \n",
      "epoch: 3 [408848/888800 46.00%] train loss: 3.927425859728828e-05 \n",
      "epoch: 3 [409959/888800 46.12%] train loss: 4.743861791212112e-05 \n",
      "epoch: 3 [411070/888800 46.25%] train loss: 3.748030576389283e-05 \n",
      "epoch: 3 [412181/888800 46.38%] train loss: 5.199878796702251e-05 \n",
      "epoch: 3 [413292/888800 46.50%] train loss: 4.646857632906176e-05 \n",
      "epoch: 3 [414403/888800 46.62%] train loss: 4.13176094298251e-05 \n",
      "epoch: 3 [415514/888800 46.75%] train loss: 4.231105776852928e-05 \n",
      "epoch: 3 [416625/888800 46.88%] train loss: 4.286419789423235e-05 \n",
      "epoch: 3 [417736/888800 47.00%] train loss: 5.133739978191443e-05 \n",
      "epoch: 3 [418847/888800 47.12%] train loss: 4.867324969382025e-05 \n",
      "epoch: 3 [419958/888800 47.25%] train loss: 4.417323361849412e-05 \n",
      "epoch: 3 [421069/888800 47.38%] train loss: 4.707853076979518e-05 \n",
      "epoch: 3 [422180/888800 47.50%] train loss: 3.9038983231876045e-05 \n",
      "epoch: 3 [423291/888800 47.62%] train loss: 4.581508255796507e-05 \n",
      "epoch: 3 [424402/888800 47.75%] train loss: 5.1203471230110154e-05 \n",
      "epoch: 3 [425513/888800 47.88%] train loss: 3.8162103010108694e-05 \n",
      "epoch: 3 [426624/888800 48.00%] train loss: 3.9712755096843466e-05 \n",
      "epoch: 3 [427735/888800 48.12%] train loss: 4.1611474443925545e-05 \n",
      "epoch: 3 [428846/888800 48.25%] train loss: 4.323413668316789e-05 \n",
      "epoch: 3 [429957/888800 48.38%] train loss: 4.767716018250212e-05 \n",
      "epoch: 3 [431068/888800 48.50%] train loss: 4.5093005610397086e-05 \n",
      "epoch: 3 [432179/888800 48.62%] train loss: 4.199272734695114e-05 \n",
      "epoch: 3 [433290/888800 48.75%] train loss: 4.143790283706039e-05 \n",
      "epoch: 3 [434401/888800 48.88%] train loss: 4.336543133831583e-05 \n",
      "epoch: 3 [435512/888800 49.00%] train loss: 4.178841845714487e-05 \n",
      "epoch: 3 [436623/888800 49.12%] train loss: 5.0163343985332176e-05 \n",
      "epoch: 3 [437734/888800 49.25%] train loss: 4.722238008980639e-05 \n",
      "epoch: 3 [438845/888800 49.38%] train loss: 5.1130093197571114e-05 \n",
      "epoch: 3 [439956/888800 49.50%] train loss: 4.604519926942885e-05 \n",
      "epoch: 3 [441067/888800 49.62%] train loss: 4.3662777898134664e-05 \n",
      "epoch: 3 [442178/888800 49.75%] train loss: 3.931521132471971e-05 \n",
      "epoch: 3 [443289/888800 49.88%] train loss: 3.691308666020632e-05 \n",
      "epoch: 3 [444400/888800 50.00%] train loss: 5.0690123316599056e-05 \n",
      "epoch: 3 [445511/888800 50.12%] train loss: 4.6845168981235474e-05 \n",
      "epoch: 3 [446622/888800 50.25%] train loss: 3.475046105450019e-05 \n",
      "epoch: 3 [447733/888800 50.38%] train loss: 4.343226464698091e-05 \n",
      "epoch: 3 [448844/888800 50.50%] train loss: 3.3998690923908725e-05 \n",
      "epoch: 3 [449955/888800 50.62%] train loss: 3.663183451863006e-05 \n",
      "epoch: 3 [451066/888800 50.75%] train loss: 4.110317604499869e-05 \n",
      "epoch: 3 [452177/888800 50.88%] train loss: 4.926204928779043e-05 \n",
      "epoch: 3 [453288/888800 51.00%] train loss: 3.6314184399088845e-05 \n",
      "epoch: 3 [454399/888800 51.12%] train loss: 4.498573616729118e-05 \n",
      "epoch: 3 [455510/888800 51.25%] train loss: 4.395421638037078e-05 \n",
      "epoch: 3 [456621/888800 51.38%] train loss: 4.348400761955418e-05 \n",
      "epoch: 3 [457732/888800 51.50%] train loss: 4.5503053115680814e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [458843/888800 51.62%] train loss: 4.275630635675043e-05 \n",
      "epoch: 3 [459954/888800 51.75%] train loss: 4.826451186090708e-05 \n",
      "epoch: 3 [461065/888800 51.88%] train loss: 4.986647400073707e-05 \n",
      "epoch: 3 [462176/888800 52.00%] train loss: 3.7589914427371696e-05 \n",
      "epoch: 3 [463287/888800 52.12%] train loss: 4.019338666694239e-05 \n",
      "epoch: 3 [464398/888800 52.25%] train loss: 4.286877083359286e-05 \n",
      "epoch: 3 [465509/888800 52.38%] train loss: 4.15133181377314e-05 \n",
      "epoch: 3 [466620/888800 52.50%] train loss: 4.803084084414877e-05 \n",
      "epoch: 3 [467731/888800 52.62%] train loss: 4.163159246672876e-05 \n",
      "epoch: 3 [468842/888800 52.75%] train loss: 4.4013428123435006e-05 \n",
      "epoch: 3 [469953/888800 52.88%] train loss: 4.267357871867716e-05 \n",
      "epoch: 3 [471064/888800 53.00%] train loss: 4.365831409813836e-05 \n",
      "epoch: 3 [472175/888800 53.12%] train loss: 4.9902071623364463e-05 \n",
      "epoch: 3 [473286/888800 53.25%] train loss: 5.187021452002227e-05 \n",
      "epoch: 3 [474397/888800 53.38%] train loss: 4.2930361814796925e-05 \n",
      "epoch: 3 [475508/888800 53.50%] train loss: 4.974018156644888e-05 \n",
      "epoch: 3 [476619/888800 53.62%] train loss: 4.4808100938098505e-05 \n",
      "epoch: 3 [477730/888800 53.75%] train loss: 4.0174840250983834e-05 \n",
      "epoch: 3 [478841/888800 53.88%] train loss: 4.220369373797439e-05 \n",
      "epoch: 3 [479952/888800 54.00%] train loss: 4.353866825113073e-05 \n",
      "epoch: 3 [481063/888800 54.12%] train loss: 4.2788247810676694e-05 \n",
      "epoch: 3 [482174/888800 54.25%] train loss: 4.1722167225088924e-05 \n",
      "epoch: 3 [483285/888800 54.38%] train loss: 4.913136217510328e-05 \n",
      "epoch: 3 [484396/888800 54.50%] train loss: 4.06628823839128e-05 \n",
      "epoch: 3 [485507/888800 54.62%] train loss: 3.675266998470761e-05 \n",
      "epoch: 3 [486618/888800 54.75%] train loss: 4.2219409806421027e-05 \n",
      "epoch: 3 [487729/888800 54.88%] train loss: 4.332443495513871e-05 \n",
      "epoch: 3 [488840/888800 55.00%] train loss: 4.020892083644867e-05 \n",
      "epoch: 3 [489951/888800 55.12%] train loss: 4.834343781112693e-05 \n",
      "epoch: 3 [491062/888800 55.25%] train loss: 5.0381313485559076e-05 \n",
      "epoch: 3 [492173/888800 55.38%] train loss: 3.7672776670660824e-05 \n",
      "epoch: 3 [493284/888800 55.50%] train loss: 4.287259071134031e-05 \n",
      "epoch: 3 [494395/888800 55.62%] train loss: 4.743005411000922e-05 \n",
      "epoch: 3 [495506/888800 55.75%] train loss: 4.204783181194216e-05 \n",
      "epoch: 3 [496617/888800 55.88%] train loss: 3.753820055862889e-05 \n",
      "epoch: 3 [497728/888800 56.00%] train loss: 5.742217035731301e-05 \n",
      "epoch: 3 [498839/888800 56.12%] train loss: 4.5757948100799695e-05 \n",
      "epoch: 3 [499950/888800 56.25%] train loss: 4.48878672614228e-05 \n",
      "epoch: 3 [501061/888800 56.38%] train loss: 3.970550460508093e-05 \n",
      "epoch: 3 [502172/888800 56.50%] train loss: 4.377936420496553e-05 \n",
      "epoch: 3 [503283/888800 56.62%] train loss: 4.526443808572367e-05 \n",
      "epoch: 3 [504394/888800 56.75%] train loss: 4.144074773648754e-05 \n",
      "epoch: 3 [505505/888800 56.88%] train loss: 4.240771886543371e-05 \n",
      "epoch: 3 [506616/888800 57.00%] train loss: 4.625080691766925e-05 \n",
      "epoch: 3 [507727/888800 57.12%] train loss: 4.2504630982875824e-05 \n",
      "epoch: 3 [508838/888800 57.25%] train loss: 3.898675277014263e-05 \n",
      "epoch: 3 [509949/888800 57.38%] train loss: 4.6576162276323885e-05 \n",
      "epoch: 3 [511060/888800 57.50%] train loss: 4.878451727563515e-05 \n",
      "epoch: 3 [512171/888800 57.62%] train loss: 3.8062044040998444e-05 \n",
      "epoch: 3 [513282/888800 57.75%] train loss: 4.360808452474885e-05 \n",
      "epoch: 3 [514393/888800 57.88%] train loss: 3.7533223803620785e-05 \n",
      "epoch: 3 [515504/888800 58.00%] train loss: 4.964065010426566e-05 \n",
      "epoch: 3 [516615/888800 58.12%] train loss: 3.408714837860316e-05 \n",
      "epoch: 3 [517726/888800 58.25%] train loss: 4.0332051867153496e-05 \n",
      "epoch: 3 [518837/888800 58.38%] train loss: 4.3329298932803795e-05 \n",
      "epoch: 3 [519948/888800 58.50%] train loss: 4.61962481494993e-05 \n",
      "epoch: 3 [521059/888800 58.62%] train loss: 3.075264612562023e-05 \n",
      "epoch: 3 [522170/888800 58.75%] train loss: 5.558963312068954e-05 \n",
      "epoch: 3 [523281/888800 58.88%] train loss: 5.03805058542639e-05 \n",
      "epoch: 3 [524392/888800 59.00%] train loss: 4.048181290272623e-05 \n",
      "epoch: 3 [525503/888800 59.12%] train loss: 3.8568006857531145e-05 \n",
      "epoch: 3 [526614/888800 59.25%] train loss: 4.066211840836331e-05 \n",
      "epoch: 3 [527725/888800 59.38%] train loss: 4.1319712181575596e-05 \n",
      "epoch: 3 [528836/888800 59.50%] train loss: 4.2275190935470164e-05 \n",
      "epoch: 3 [529947/888800 59.62%] train loss: 4.2286021198378876e-05 \n",
      "epoch: 3 [531058/888800 59.75%] train loss: 4.0066548535833135e-05 \n",
      "epoch: 3 [532169/888800 59.88%] train loss: 3.7846388295292854e-05 \n",
      "epoch: 3 [533280/888800 60.00%] train loss: 4.406107109389268e-05 \n",
      "epoch: 3 [534391/888800 60.12%] train loss: 3.897580609191209e-05 \n",
      "epoch: 3 [535502/888800 60.25%] train loss: 4.547677599475719e-05 \n",
      "epoch: 3 [536613/888800 60.38%] train loss: 4.467202234081924e-05 \n",
      "epoch: 3 [537724/888800 60.50%] train loss: 3.929606464225799e-05 \n",
      "epoch: 3 [538835/888800 60.62%] train loss: 4.055495810462162e-05 \n",
      "epoch: 3 [539946/888800 60.75%] train loss: 4.176031143288128e-05 \n",
      "epoch: 3 [541057/888800 60.88%] train loss: 4.0356171666644514e-05 \n",
      "epoch: 3 [542168/888800 61.00%] train loss: 3.995882434537634e-05 \n",
      "epoch: 3 [543279/888800 61.12%] train loss: 3.930021921405569e-05 \n",
      "epoch: 3 [544390/888800 61.25%] train loss: 4.876601087744348e-05 \n",
      "epoch: 3 [545501/888800 61.38%] train loss: 4.031194112030789e-05 \n",
      "epoch: 3 [546612/888800 61.50%] train loss: 4.0686732972972095e-05 \n",
      "epoch: 3 [547723/888800 61.62%] train loss: 4.9423437303630635e-05 \n",
      "epoch: 3 [548834/888800 61.75%] train loss: 3.81350182578899e-05 \n",
      "epoch: 3 [549945/888800 61.88%] train loss: 3.5017288610106334e-05 \n",
      "epoch: 3 [551056/888800 62.00%] train loss: 4.071288640261628e-05 \n",
      "epoch: 3 [552167/888800 62.12%] train loss: 4.11995206377469e-05 \n",
      "epoch: 3 [553278/888800 62.25%] train loss: 5.070146289654076e-05 \n",
      "epoch: 3 [554389/888800 62.38%] train loss: 5.0087204726878554e-05 \n",
      "epoch: 3 [555500/888800 62.50%] train loss: 4.4599873945117e-05 \n",
      "epoch: 3 [556611/888800 62.62%] train loss: 4.676962271332741e-05 \n",
      "epoch: 3 [557722/888800 62.75%] train loss: 3.918943548342213e-05 \n",
      "epoch: 3 [558833/888800 62.88%] train loss: 4.337634891271591e-05 \n",
      "epoch: 3 [559944/888800 63.00%] train loss: 4.209472535876557e-05 \n",
      "epoch: 3 [561055/888800 63.12%] train loss: 4.0530758269596845e-05 \n",
      "epoch: 3 [562166/888800 63.25%] train loss: 4.4087755668442696e-05 \n",
      "epoch: 3 [563277/888800 63.38%] train loss: 3.668582940008491e-05 \n",
      "epoch: 3 [564388/888800 63.50%] train loss: 4.7853794967522845e-05 \n",
      "epoch: 3 [565499/888800 63.62%] train loss: 4.700108547694981e-05 \n",
      "epoch: 3 [566610/888800 63.75%] train loss: 4.673874718719162e-05 \n",
      "epoch: 3 [567721/888800 63.88%] train loss: 4.208938480587676e-05 \n",
      "epoch: 3 [568832/888800 64.00%] train loss: 4.1270115616498515e-05 \n",
      "epoch: 3 [569943/888800 64.12%] train loss: 3.943925548810512e-05 \n",
      "epoch: 3 [571054/888800 64.25%] train loss: 4.493253436521627e-05 \n",
      "epoch: 3 [572165/888800 64.38%] train loss: 4.4504333345685154e-05 \n",
      "epoch: 3 [573276/888800 64.50%] train loss: 4.439704935066402e-05 \n",
      "epoch: 3 [574387/888800 64.62%] train loss: 3.7418754800455645e-05 \n",
      "epoch: 3 [575498/888800 64.75%] train loss: 3.660710353869945e-05 \n",
      "epoch: 3 [576609/888800 64.88%] train loss: 4.21073091274593e-05 \n",
      "epoch: 3 [577720/888800 65.00%] train loss: 4.1438735934207216e-05 \n",
      "epoch: 3 [578831/888800 65.12%] train loss: 4.664632797357626e-05 \n",
      "epoch: 3 [579942/888800 65.25%] train loss: 4.564024493447505e-05 \n",
      "epoch: 3 [581053/888800 65.38%] train loss: 5.763330773334019e-05 \n",
      "epoch: 3 [582164/888800 65.50%] train loss: 4.491021536523476e-05 \n",
      "epoch: 3 [583275/888800 65.62%] train loss: 4.73859763587825e-05 \n",
      "epoch: 3 [584386/888800 65.75%] train loss: 4.3098283640574664e-05 \n",
      "epoch: 3 [585497/888800 65.88%] train loss: 3.49133915733546e-05 \n",
      "epoch: 3 [586608/888800 66.00%] train loss: 4.325591362430714e-05 \n",
      "epoch: 3 [587719/888800 66.12%] train loss: 4.796552093466744e-05 \n",
      "epoch: 3 [588830/888800 66.25%] train loss: 4.8556561523582786e-05 \n",
      "epoch: 3 [589941/888800 66.38%] train loss: 3.476499841781333e-05 \n",
      "epoch: 3 [591052/888800 66.50%] train loss: 4.063323649461381e-05 \n",
      "epoch: 3 [592163/888800 66.62%] train loss: 4.738265124615282e-05 \n",
      "epoch: 3 [593274/888800 66.75%] train loss: 4.971095404471271e-05 \n",
      "epoch: 3 [594385/888800 66.88%] train loss: 4.072525189258158e-05 \n",
      "epoch: 3 [595496/888800 67.00%] train loss: 4.255185922374949e-05 \n",
      "epoch: 3 [596607/888800 67.12%] train loss: 4.696088217315264e-05 \n",
      "epoch: 3 [597718/888800 67.25%] train loss: 4.0811621147440746e-05 \n",
      "epoch: 3 [598829/888800 67.38%] train loss: 3.978270979132503e-05 \n",
      "epoch: 3 [599940/888800 67.50%] train loss: 3.41086633852683e-05 \n",
      "epoch: 3 [601051/888800 67.62%] train loss: 4.0479771996615455e-05 \n",
      "epoch: 3 [602162/888800 67.75%] train loss: 4.2806048440979794e-05 \n",
      "epoch: 3 [603273/888800 67.88%] train loss: 3.314180503366515e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [604384/888800 68.00%] train loss: 3.491768802632578e-05 \n",
      "epoch: 3 [605495/888800 68.12%] train loss: 3.8259746361291036e-05 \n",
      "epoch: 3 [606606/888800 68.25%] train loss: 4.43550270574633e-05 \n",
      "epoch: 3 [607717/888800 68.38%] train loss: 4.813888517674059e-05 \n",
      "epoch: 3 [608828/888800 68.50%] train loss: 4.092547169420868e-05 \n",
      "epoch: 3 [609939/888800 68.62%] train loss: 4.025624002679251e-05 \n",
      "epoch: 3 [611050/888800 68.75%] train loss: 4.8545491154072806e-05 \n",
      "epoch: 3 [612161/888800 68.88%] train loss: 4.020463893539272e-05 \n",
      "epoch: 3 [613272/888800 69.00%] train loss: 3.9044676668709144e-05 \n",
      "epoch: 3 [614383/888800 69.12%] train loss: 4.429291220731102e-05 \n",
      "epoch: 3 [615494/888800 69.25%] train loss: 4.0358409023610875e-05 \n",
      "epoch: 3 [616605/888800 69.38%] train loss: 4.899860141449608e-05 \n",
      "epoch: 3 [617716/888800 69.50%] train loss: 4.176836955593899e-05 \n",
      "epoch: 3 [618827/888800 69.62%] train loss: 4.451218410395086e-05 \n",
      "epoch: 3 [619938/888800 69.75%] train loss: 3.844865204882808e-05 \n",
      "epoch: 3 [621049/888800 69.88%] train loss: 5.079443144495599e-05 \n",
      "epoch: 3 [622160/888800 70.00%] train loss: 4.093649113201536e-05 \n",
      "epoch: 3 [623271/888800 70.12%] train loss: 4.416916272020899e-05 \n",
      "epoch: 3 [624382/888800 70.25%] train loss: 4.3150117562618107e-05 \n",
      "epoch: 3 [625493/888800 70.38%] train loss: 3.857675983454101e-05 \n",
      "epoch: 3 [626604/888800 70.50%] train loss: 4.095220356248319e-05 \n",
      "epoch: 3 [627715/888800 70.62%] train loss: 4.870282646152191e-05 \n",
      "epoch: 3 [628826/888800 70.75%] train loss: 4.423276914167218e-05 \n",
      "epoch: 3 [629937/888800 70.88%] train loss: 4.742028613691218e-05 \n",
      "epoch: 3 [631048/888800 71.00%] train loss: 3.5021203075302765e-05 \n",
      "epoch: 3 [632159/888800 71.12%] train loss: 4.604327114066109e-05 \n",
      "epoch: 3 [633270/888800 71.25%] train loss: 4.115511546842754e-05 \n",
      "epoch: 3 [634381/888800 71.38%] train loss: 4.7865603846730664e-05 \n",
      "epoch: 3 [635492/888800 71.50%] train loss: 4.330973024480045e-05 \n",
      "epoch: 3 [636603/888800 71.62%] train loss: 4.7446752432733774e-05 \n",
      "epoch: 3 [637714/888800 71.75%] train loss: 3.76929237972945e-05 \n",
      "epoch: 3 [638825/888800 71.88%] train loss: 4.15475333284121e-05 \n",
      "epoch: 3 [639936/888800 72.00%] train loss: 5.079225593362935e-05 \n",
      "epoch: 3 [641047/888800 72.12%] train loss: 4.2435778595972806e-05 \n",
      "epoch: 3 [642158/888800 72.25%] train loss: 4.123908365727402e-05 \n",
      "epoch: 3 [643269/888800 72.38%] train loss: 4.0394595998805016e-05 \n",
      "epoch: 3 [644380/888800 72.50%] train loss: 4.412088674143888e-05 \n",
      "epoch: 3 [645491/888800 72.62%] train loss: 4.357870056992397e-05 \n",
      "epoch: 3 [646602/888800 72.75%] train loss: 3.74704941350501e-05 \n",
      "epoch: 3 [647713/888800 72.88%] train loss: 4.305347829358652e-05 \n",
      "epoch: 3 [648824/888800 73.00%] train loss: 4.1974260966526344e-05 \n",
      "epoch: 3 [649935/888800 73.12%] train loss: 4.138215444982052e-05 \n",
      "epoch: 3 [651046/888800 73.25%] train loss: 4.6341818233486265e-05 \n",
      "epoch: 3 [652157/888800 73.38%] train loss: 3.6050543712917715e-05 \n",
      "epoch: 3 [653268/888800 73.50%] train loss: 4.1662435251055285e-05 \n",
      "epoch: 3 [654379/888800 73.62%] train loss: 4.062360312673263e-05 \n",
      "epoch: 3 [655490/888800 73.75%] train loss: 3.856112016364932e-05 \n",
      "epoch: 3 [656601/888800 73.88%] train loss: 4.360560342320241e-05 \n",
      "epoch: 3 [657712/888800 74.00%] train loss: 4.7084839025046676e-05 \n",
      "epoch: 3 [658823/888800 74.12%] train loss: 3.9861090044723824e-05 \n",
      "epoch: 3 [659934/888800 74.25%] train loss: 4.067386907991022e-05 \n",
      "epoch: 3 [661045/888800 74.38%] train loss: 4.541776070254855e-05 \n",
      "epoch: 3 [662156/888800 74.50%] train loss: 4.546998388832435e-05 \n",
      "epoch: 3 [663267/888800 74.62%] train loss: 4.4582302507478744e-05 \n",
      "epoch: 3 [664378/888800 74.75%] train loss: 4.0066923247650266e-05 \n",
      "epoch: 3 [665489/888800 74.88%] train loss: 4.0532286220695823e-05 \n",
      "epoch: 3 [666600/888800 75.00%] train loss: 5.156256884220056e-05 \n",
      "epoch: 3 [667711/888800 75.12%] train loss: 4.8262900236295536e-05 \n",
      "epoch: 3 [668822/888800 75.25%] train loss: 4.965988773619756e-05 \n",
      "epoch: 3 [669933/888800 75.38%] train loss: 3.53579489456024e-05 \n",
      "epoch: 3 [671044/888800 75.50%] train loss: 4.499655551626347e-05 \n",
      "epoch: 3 [672155/888800 75.62%] train loss: 4.066530163981952e-05 \n",
      "epoch: 3 [673266/888800 75.75%] train loss: 3.6723140510730445e-05 \n",
      "epoch: 3 [674377/888800 75.88%] train loss: 4.116591298952699e-05 \n",
      "epoch: 3 [675488/888800 76.00%] train loss: 4.530626756604761e-05 \n",
      "epoch: 3 [676599/888800 76.12%] train loss: 3.816081152763218e-05 \n",
      "epoch: 3 [677710/888800 76.25%] train loss: 4.687769978772849e-05 \n",
      "epoch: 3 [678821/888800 76.38%] train loss: 3.555949660949409e-05 \n",
      "epoch: 3 [679932/888800 76.50%] train loss: 3.793458017753437e-05 \n",
      "epoch: 3 [681043/888800 76.62%] train loss: 3.9301485230680555e-05 \n",
      "epoch: 3 [682154/888800 76.75%] train loss: 4.710302164312452e-05 \n",
      "epoch: 3 [683265/888800 76.88%] train loss: 4.3472515244502574e-05 \n",
      "epoch: 3 [684376/888800 77.00%] train loss: 4.928683483740315e-05 \n",
      "epoch: 3 [685487/888800 77.12%] train loss: 4.937728590448387e-05 \n",
      "epoch: 3 [686598/888800 77.25%] train loss: 4.552175596472807e-05 \n",
      "epoch: 3 [687709/888800 77.38%] train loss: 3.703017864609137e-05 \n",
      "epoch: 3 [688820/888800 77.50%] train loss: 3.6695331800729036e-05 \n",
      "epoch: 3 [689931/888800 77.62%] train loss: 4.189335595583543e-05 \n",
      "epoch: 3 [691042/888800 77.75%] train loss: 4.6486245992127806e-05 \n",
      "epoch: 3 [692153/888800 77.88%] train loss: 4.0949624235508963e-05 \n",
      "epoch: 3 [693264/888800 78.00%] train loss: 3.7641115341102704e-05 \n",
      "epoch: 3 [694375/888800 78.12%] train loss: 4.308727875468321e-05 \n",
      "epoch: 3 [695486/888800 78.25%] train loss: 3.881264274241403e-05 \n",
      "epoch: 3 [696597/888800 78.38%] train loss: 4.4706015614792705e-05 \n",
      "epoch: 3 [697708/888800 78.50%] train loss: 4.621984044206329e-05 \n",
      "epoch: 3 [698819/888800 78.62%] train loss: 3.79324410459958e-05 \n",
      "epoch: 3 [699930/888800 78.75%] train loss: 4.1701750888023525e-05 \n",
      "epoch: 3 [701041/888800 78.88%] train loss: 4.0357645048061386e-05 \n",
      "epoch: 3 [702152/888800 79.00%] train loss: 3.150721749989316e-05 \n",
      "epoch: 3 [703263/888800 79.12%] train loss: 3.804145671892911e-05 \n",
      "epoch: 3 [704374/888800 79.25%] train loss: 3.4611457522260025e-05 \n",
      "epoch: 3 [705485/888800 79.38%] train loss: 4.301636363379657e-05 \n",
      "epoch: 3 [706596/888800 79.50%] train loss: 4.749458094011061e-05 \n",
      "epoch: 3 [707707/888800 79.62%] train loss: 4.561250898404978e-05 \n",
      "epoch: 3 [708818/888800 79.75%] train loss: 3.4982374927494675e-05 \n",
      "epoch: 3 [709929/888800 79.88%] train loss: 3.706082497956231e-05 \n",
      "epoch: 3 [711040/888800 80.00%] train loss: 4.466879181563854e-05 \n",
      "epoch: 3 [712151/888800 80.12%] train loss: 4.810840619029477e-05 \n",
      "epoch: 3 [713262/888800 80.25%] train loss: 4.576950959744863e-05 \n",
      "epoch: 3 [714373/888800 80.38%] train loss: 4.4643344153882936e-05 \n",
      "epoch: 3 [715484/888800 80.50%] train loss: 3.8091940950835124e-05 \n",
      "epoch: 3 [716595/888800 80.62%] train loss: 5.017467265133746e-05 \n",
      "epoch: 3 [717706/888800 80.75%] train loss: 4.39824398199562e-05 \n",
      "epoch: 3 [718817/888800 80.88%] train loss: 4.651897688745521e-05 \n",
      "epoch: 3 [719928/888800 81.00%] train loss: 4.0694125345908105e-05 \n",
      "epoch: 3 [721039/888800 81.12%] train loss: 3.981969348387793e-05 \n",
      "epoch: 3 [722150/888800 81.25%] train loss: 5.266461812425405e-05 \n",
      "epoch: 3 [723261/888800 81.38%] train loss: 3.875267429975793e-05 \n",
      "epoch: 3 [724372/888800 81.50%] train loss: 4.087912384420633e-05 \n",
      "epoch: 3 [725483/888800 81.62%] train loss: 4.5331416913541034e-05 \n",
      "epoch: 3 [726594/888800 81.75%] train loss: 4.103270111954771e-05 \n",
      "epoch: 3 [727705/888800 81.88%] train loss: 4.2686471715569496e-05 \n",
      "epoch: 3 [728816/888800 82.00%] train loss: 4.183196142548695e-05 \n",
      "epoch: 3 [729927/888800 82.12%] train loss: 4.3033811380155385e-05 \n",
      "epoch: 3 [731038/888800 82.25%] train loss: 3.9072609069989994e-05 \n",
      "epoch: 3 [732149/888800 82.38%] train loss: 5.280935511109419e-05 \n",
      "epoch: 3 [733260/888800 82.50%] train loss: 4.145638013142161e-05 \n",
      "epoch: 3 [734371/888800 82.62%] train loss: 4.4704713218379766e-05 \n",
      "epoch: 3 [735482/888800 82.75%] train loss: 3.894473047694191e-05 \n",
      "epoch: 3 [736593/888800 82.88%] train loss: 4.448539766599424e-05 \n",
      "epoch: 3 [737704/888800 83.00%] train loss: 4.485933095565997e-05 \n",
      "epoch: 3 [738815/888800 83.12%] train loss: 4.569032171275467e-05 \n",
      "epoch: 3 [739926/888800 83.25%] train loss: 4.365467611933127e-05 \n",
      "epoch: 3 [741037/888800 83.38%] train loss: 4.0234455809695646e-05 \n",
      "epoch: 3 [742148/888800 83.50%] train loss: 5.061411138740368e-05 \n",
      "epoch: 3 [743259/888800 83.62%] train loss: 4.3338706745998934e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 [744370/888800 83.75%] train loss: 3.7905268982285634e-05 \n",
      "epoch: 3 [745481/888800 83.88%] train loss: 4.501889998209663e-05 \n",
      "epoch: 3 [746592/888800 84.00%] train loss: 4.7125031414907426e-05 \n",
      "epoch: 3 [747703/888800 84.12%] train loss: 3.722853944054805e-05 \n",
      "epoch: 3 [748814/888800 84.25%] train loss: 3.870627915603109e-05 \n",
      "epoch: 3 [749925/888800 84.38%] train loss: 4.503336094785482e-05 \n",
      "epoch: 3 [751036/888800 84.50%] train loss: 4.010445991298184e-05 \n",
      "epoch: 3 [752147/888800 84.62%] train loss: 3.9147609641077e-05 \n",
      "epoch: 3 [753258/888800 84.75%] train loss: 4.776463902089745e-05 \n",
      "epoch: 3 [754369/888800 84.88%] train loss: 4.3470088712638244e-05 \n",
      "epoch: 3 [755480/888800 85.00%] train loss: 4.415737930685282e-05 \n",
      "epoch: 3 [756591/888800 85.12%] train loss: 4.2007282900158316e-05 \n",
      "epoch: 3 [757702/888800 85.25%] train loss: 4.4530537707032636e-05 \n",
      "epoch: 3 [758813/888800 85.38%] train loss: 4.248700133757666e-05 \n",
      "epoch: 3 [759924/888800 85.50%] train loss: 4.344900298747234e-05 \n",
      "epoch: 3 [761035/888800 85.62%] train loss: 4.0271821490023285e-05 \n",
      "epoch: 3 [762146/888800 85.75%] train loss: 4.927009285893291e-05 \n",
      "epoch: 3 [763257/888800 85.88%] train loss: 3.822179860435426e-05 \n",
      "epoch: 3 [764368/888800 86.00%] train loss: 3.69469344150275e-05 \n",
      "epoch: 3 [765479/888800 86.12%] train loss: 5.3398624004330486e-05 \n",
      "epoch: 3 [766590/888800 86.25%] train loss: 3.964660209021531e-05 \n",
      "epoch: 3 [767701/888800 86.38%] train loss: 4.205733785056509e-05 \n",
      "epoch: 3 [768812/888800 86.50%] train loss: 4.0515522414352745e-05 \n",
      "epoch: 3 [769923/888800 86.62%] train loss: 4.5161967136664316e-05 \n",
      "epoch: 3 [771034/888800 86.75%] train loss: 4.738567440654151e-05 \n",
      "epoch: 3 [772145/888800 86.88%] train loss: 4.600316606229171e-05 \n",
      "epoch: 3 [773256/888800 87.00%] train loss: 3.507474684738554e-05 \n",
      "epoch: 3 [774367/888800 87.12%] train loss: 4.2961946746800095e-05 \n",
      "epoch: 3 [775478/888800 87.25%] train loss: 4.835492654819973e-05 \n",
      "epoch: 3 [776589/888800 87.38%] train loss: 3.9231108530657366e-05 \n",
      "epoch: 3 [777700/888800 87.50%] train loss: 4.201367119094357e-05 \n",
      "epoch: 3 [778811/888800 87.62%] train loss: 3.9575919799972326e-05 \n",
      "epoch: 3 [779922/888800 87.75%] train loss: 4.738080679089762e-05 \n",
      "epoch: 3 [781033/888800 87.88%] train loss: 4.713899761554785e-05 \n",
      "epoch: 3 [782144/888800 88.00%] train loss: 4.494157474255189e-05 \n",
      "epoch: 3 [783255/888800 88.12%] train loss: 3.80587371182628e-05 \n",
      "epoch: 3 [784366/888800 88.25%] train loss: 4.54403088951949e-05 \n",
      "epoch: 3 [785477/888800 88.38%] train loss: 4.143882688367739e-05 \n",
      "epoch: 3 [786588/888800 88.50%] train loss: 4.678139157476835e-05 \n",
      "epoch: 3 [787699/888800 88.62%] train loss: 3.900760566466488e-05 \n",
      "epoch: 3 [788810/888800 88.75%] train loss: 4.214687578496523e-05 \n",
      "epoch: 3 [789921/888800 88.88%] train loss: 3.928860314772464e-05 \n",
      "epoch: 3 [791032/888800 89.00%] train loss: 4.147757135797292e-05 \n",
      "epoch: 3 [792143/888800 89.12%] train loss: 4.0934435673989356e-05 \n",
      "epoch: 3 [793254/888800 89.25%] train loss: 4.466108657652512e-05 \n",
      "epoch: 3 [794365/888800 89.38%] train loss: 3.8709622458554804e-05 \n",
      "epoch: 3 [795476/888800 89.50%] train loss: 3.71876813005656e-05 \n",
      "epoch: 3 [796587/888800 89.62%] train loss: 4.395297946757637e-05 \n",
      "epoch: 3 [797698/888800 89.75%] train loss: 4.5337696064962074e-05 \n",
      "epoch: 3 [798809/888800 89.88%] train loss: 4.3169133277842775e-05 \n",
      "epoch: 3 [799920/888800 90.00%] train loss: 4.331335730967112e-05 \n",
      "epoch: 3 [801031/888800 90.12%] train loss: 4.4156542571727186e-05 \n",
      "epoch: 3 [802142/888800 90.25%] train loss: 3.5179768019588664e-05 \n",
      "epoch: 3 [803253/888800 90.38%] train loss: 4.5014086936134845e-05 \n",
      "epoch: 3 [804364/888800 90.50%] train loss: 3.600935451686382e-05 \n",
      "epoch: 3 [805475/888800 90.62%] train loss: 4.294845348340459e-05 \n",
      "epoch: 3 [806586/888800 90.75%] train loss: 3.962674963986501e-05 \n",
      "epoch: 3 [807697/888800 90.88%] train loss: 4.6050234232097864e-05 \n",
      "epoch: 3 [808808/888800 91.00%] train loss: 3.813305011135526e-05 \n",
      "epoch: 3 [809919/888800 91.12%] train loss: 4.528202771325596e-05 \n",
      "epoch: 3 [811030/888800 91.25%] train loss: 3.4684147976804525e-05 \n",
      "epoch: 3 [812141/888800 91.38%] train loss: 4.5382788812275976e-05 \n",
      "epoch: 3 [813252/888800 91.50%] train loss: 3.726330760400742e-05 \n",
      "epoch: 3 [814363/888800 91.62%] train loss: 3.526940054143779e-05 \n",
      "epoch: 3 [815474/888800 91.75%] train loss: 4.506847835727967e-05 \n",
      "epoch: 3 [816585/888800 91.88%] train loss: 3.910781742888503e-05 \n",
      "epoch: 3 [817696/888800 92.00%] train loss: 5.1634015107993037e-05 \n",
      "epoch: 3 [818807/888800 92.12%] train loss: 3.800665945163928e-05 \n",
      "epoch: 3 [819918/888800 92.25%] train loss: 4.719118442153558e-05 \n",
      "epoch: 3 [821029/888800 92.38%] train loss: 4.9036520067602396e-05 \n",
      "epoch: 3 [822140/888800 92.50%] train loss: 4.6703116822754964e-05 \n",
      "epoch: 3 [823251/888800 92.62%] train loss: 4.512202940532006e-05 \n",
      "epoch: 3 [824362/888800 92.75%] train loss: 4.1084407712332904e-05 \n",
      "epoch: 3 [825473/888800 92.88%] train loss: 3.9321523217950016e-05 \n",
      "epoch: 3 [826584/888800 93.00%] train loss: 3.57680328306742e-05 \n",
      "epoch: 3 [827695/888800 93.12%] train loss: 4.0731178160058334e-05 \n",
      "epoch: 3 [828806/888800 93.25%] train loss: 3.753503187908791e-05 \n",
      "epoch: 3 [829917/888800 93.38%] train loss: 4.041483043693006e-05 \n",
      "epoch: 3 [831028/888800 93.50%] train loss: 3.948793892050162e-05 \n",
      "epoch: 3 [832139/888800 93.62%] train loss: 4.424280268722214e-05 \n",
      "epoch: 3 [833250/888800 93.75%] train loss: 4.699175406130962e-05 \n",
      "epoch: 3 [834361/888800 93.88%] train loss: 4.949474168824963e-05 \n",
      "epoch: 3 [835472/888800 94.00%] train loss: 4.536451888270676e-05 \n",
      "epoch: 3 [836583/888800 94.12%] train loss: 4.533652463578619e-05 \n",
      "epoch: 3 [837694/888800 94.25%] train loss: 4.908618939225562e-05 \n",
      "epoch: 3 [838805/888800 94.38%] train loss: 3.8570196920773014e-05 \n",
      "epoch: 3 [839916/888800 94.50%] train loss: 4.037207690998912e-05 \n",
      "epoch: 3 [841027/888800 94.62%] train loss: 4.4724329200107604e-05 \n",
      "epoch: 3 [842138/888800 94.75%] train loss: 3.755522266146727e-05 \n",
      "epoch: 3 [843249/888800 94.88%] train loss: 4.169297972111963e-05 \n",
      "epoch: 3 [844360/888800 95.00%] train loss: 4.798862573807128e-05 \n",
      "epoch: 3 [845471/888800 95.12%] train loss: 3.7608515413012356e-05 \n",
      "epoch: 3 [846582/888800 95.25%] train loss: 4.017220271634869e-05 \n",
      "epoch: 3 [847693/888800 95.38%] train loss: 3.5659148124977946e-05 \n",
      "epoch: 3 [848804/888800 95.50%] train loss: 4.359202284831554e-05 \n",
      "epoch: 3 [849915/888800 95.62%] train loss: 3.670857040560804e-05 \n",
      "epoch: 3 [851026/888800 95.75%] train loss: 4.772195461555384e-05 \n",
      "epoch: 3 [852137/888800 95.88%] train loss: 4.252222061040811e-05 \n",
      "epoch: 3 [853248/888800 96.00%] train loss: 3.799714249907993e-05 \n",
      "epoch: 3 [854359/888800 96.12%] train loss: 3.788751200772822e-05 \n",
      "epoch: 3 [855470/888800 96.25%] train loss: 4.199837349005975e-05 \n",
      "epoch: 3 [856581/888800 96.38%] train loss: 5.10229729115963e-05 \n",
      "epoch: 3 [857692/888800 96.50%] train loss: 3.881096199620515e-05 \n",
      "epoch: 3 [858803/888800 96.62%] train loss: 3.933429979952052e-05 \n",
      "epoch: 3 [859914/888800 96.75%] train loss: 4.751000597025268e-05 \n",
      "epoch: 3 [861025/888800 96.88%] train loss: 4.266143514541909e-05 \n",
      "epoch: 3 [862136/888800 97.00%] train loss: 4.254177474649623e-05 \n",
      "epoch: 3 [863247/888800 97.12%] train loss: 4.0443508623866364e-05 \n",
      "epoch: 3 [864358/888800 97.25%] train loss: 4.7042085498105735e-05 \n",
      "epoch: 3 [865469/888800 97.38%] train loss: 4.084718966623768e-05 \n",
      "epoch: 3 [866580/888800 97.50%] train loss: 4.371919567347504e-05 \n",
      "epoch: 3 [867691/888800 97.62%] train loss: 4.843188798986375e-05 \n",
      "epoch: 3 [868802/888800 97.75%] train loss: 4.4603279093280435e-05 \n",
      "epoch: 3 [869913/888800 97.88%] train loss: 3.643218587967567e-05 \n",
      "epoch: 3 [871024/888800 98.00%] train loss: 3.75228701159358e-05 \n",
      "epoch: 3 [872135/888800 98.12%] train loss: 4.997428186470643e-05 \n",
      "epoch: 3 [873246/888800 98.25%] train loss: 4.246636672178283e-05 \n",
      "epoch: 3 [874357/888800 98.38%] train loss: 4.735215406981297e-05 \n",
      "epoch: 3 [875468/888800 98.50%] train loss: 3.980061592301354e-05 \n",
      "epoch: 3 [876579/888800 98.62%] train loss: 4.792549225385301e-05 \n",
      "epoch: 3 [877690/888800 98.75%] train loss: 4.8174013500101864e-05 \n",
      "epoch: 3 [878801/888800 98.88%] train loss: 5.352391963242553e-05 \n",
      "epoch: 3 [879912/888800 99.00%] train loss: 4.159172021900304e-05 \n",
      "epoch: 3 [881023/888800 99.12%] train loss: 4.673092917073518e-05 \n",
      "epoch: 3 [882134/888800 99.25%] train loss: 4.431466732057743e-05 \n",
      "epoch: 3 [883245/888800 99.38%] train loss: 4.586417708196677e-05 \n",
      "epoch: 3 [884356/888800 99.50%] train loss: 3.922412361134775e-05 \n",
      "epoch: 3 [885467/888800 99.62%] train loss: 4.671244460041635e-05 \n",
      "epoch: 3 [886578/888800 99.75%] train loss: 4.1573861381039023e-05 \n",
      "epoch: 3 [887689/888800 99.88%] train loss: 4.849518518312834e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [0/888800 0.00%] train loss: 4.43295793957077e-05 \n",
      "epoch: 4 [1111/888800 0.12%] train loss: 3.6884142900817096e-05 \n",
      "epoch: 4 [2222/888800 0.25%] train loss: 5.143274029251188e-05 \n",
      "epoch: 4 [3333/888800 0.38%] train loss: 4.818979141418822e-05 \n",
      "epoch: 4 [4444/888800 0.50%] train loss: 4.759045987157151e-05 \n",
      "epoch: 4 [5555/888800 0.62%] train loss: 3.857401679852046e-05 \n",
      "epoch: 4 [6666/888800 0.75%] train loss: 3.9199872844619676e-05 \n",
      "epoch: 4 [7777/888800 0.88%] train loss: 4.6126875531626865e-05 \n",
      "epoch: 4 [8888/888800 1.00%] train loss: 4.7565623390255496e-05 \n",
      "epoch: 4 [9999/888800 1.12%] train loss: 4.67216013930738e-05 \n",
      "epoch: 4 [11110/888800 1.25%] train loss: 4.09195308748167e-05 \n",
      "epoch: 4 [12221/888800 1.38%] train loss: 4.868562609772198e-05 \n",
      "epoch: 4 [13332/888800 1.50%] train loss: 4.4984990381635725e-05 \n",
      "epoch: 4 [14443/888800 1.62%] train loss: 4.259323759470135e-05 \n",
      "epoch: 4 [15554/888800 1.75%] train loss: 4.719072603620589e-05 \n",
      "epoch: 4 [16665/888800 1.88%] train loss: 4.924820314045064e-05 \n",
      "epoch: 4 [17776/888800 2.00%] train loss: 4.242690556566231e-05 \n",
      "epoch: 4 [18887/888800 2.12%] train loss: 4.234967855154537e-05 \n",
      "epoch: 4 [19998/888800 2.25%] train loss: 4.660057311411947e-05 \n",
      "epoch: 4 [21109/888800 2.38%] train loss: 4.734902177006006e-05 \n",
      "epoch: 4 [22220/888800 2.50%] train loss: 4.427962630870752e-05 \n",
      "epoch: 4 [23331/888800 2.62%] train loss: 4.744570833281614e-05 \n",
      "epoch: 4 [24442/888800 2.75%] train loss: 4.469479245017283e-05 \n",
      "epoch: 4 [25553/888800 2.88%] train loss: 4.476117101148702e-05 \n",
      "epoch: 4 [26664/888800 3.00%] train loss: 4.3891490349778906e-05 \n",
      "epoch: 4 [27775/888800 3.12%] train loss: 4.2652834963519126e-05 \n",
      "epoch: 4 [28886/888800 3.25%] train loss: 3.627923069871031e-05 \n",
      "epoch: 4 [29997/888800 3.38%] train loss: 4.28189778176602e-05 \n",
      "epoch: 4 [31108/888800 3.50%] train loss: 4.285957766114734e-05 \n",
      "epoch: 4 [32219/888800 3.62%] train loss: 4.546525451587513e-05 \n",
      "epoch: 4 [33330/888800 3.75%] train loss: 3.8100708479760215e-05 \n",
      "epoch: 4 [34441/888800 3.88%] train loss: 4.196174631942995e-05 \n",
      "epoch: 4 [35552/888800 4.00%] train loss: 4.193997665424831e-05 \n",
      "epoch: 4 [36663/888800 4.12%] train loss: 5.042126576881856e-05 \n",
      "epoch: 4 [37774/888800 4.25%] train loss: 4.072966112289578e-05 \n",
      "epoch: 4 [38885/888800 4.38%] train loss: 4.094908945262432e-05 \n",
      "epoch: 4 [39996/888800 4.50%] train loss: 4.052943768328987e-05 \n",
      "epoch: 4 [41107/888800 4.62%] train loss: 3.714437843882479e-05 \n",
      "epoch: 4 [42218/888800 4.75%] train loss: 4.2725176172098145e-05 \n",
      "epoch: 4 [43329/888800 4.88%] train loss: 4.8798588977660984e-05 \n",
      "epoch: 4 [44440/888800 5.00%] train loss: 3.4132848668377846e-05 \n",
      "epoch: 4 [45551/888800 5.12%] train loss: 4.200003604637459e-05 \n",
      "epoch: 4 [46662/888800 5.25%] train loss: 4.783655094797723e-05 \n",
      "epoch: 4 [47773/888800 5.38%] train loss: 4.4025724491802976e-05 \n",
      "epoch: 4 [48884/888800 5.50%] train loss: 4.12756999139674e-05 \n",
      "epoch: 4 [49995/888800 5.62%] train loss: 4.5975215471116826e-05 \n",
      "epoch: 4 [51106/888800 5.75%] train loss: 4.661193088395521e-05 \n",
      "epoch: 4 [52217/888800 5.88%] train loss: 4.1322891775052994e-05 \n",
      "epoch: 4 [53328/888800 6.00%] train loss: 3.872612796840258e-05 \n",
      "epoch: 4 [54439/888800 6.12%] train loss: 3.7683781556552276e-05 \n",
      "epoch: 4 [55550/888800 6.25%] train loss: 4.37927883467637e-05 \n",
      "epoch: 4 [56661/888800 6.38%] train loss: 4.64349432149902e-05 \n",
      "epoch: 4 [57772/888800 6.50%] train loss: 3.902206299244426e-05 \n",
      "epoch: 4 [58883/888800 6.62%] train loss: 3.819534322246909e-05 \n",
      "epoch: 4 [59994/888800 6.75%] train loss: 4.9699836381478235e-05 \n",
      "epoch: 4 [61105/888800 6.88%] train loss: 5.066335143055767e-05 \n",
      "epoch: 4 [62216/888800 7.00%] train loss: 4.297268242225982e-05 \n",
      "epoch: 4 [63327/888800 7.12%] train loss: 4.3732663471018896e-05 \n",
      "epoch: 4 [64438/888800 7.25%] train loss: 3.910762825398706e-05 \n",
      "epoch: 4 [65549/888800 7.38%] train loss: 4.008999894722365e-05 \n",
      "epoch: 4 [66660/888800 7.50%] train loss: 3.839204509858973e-05 \n",
      "epoch: 4 [67771/888800 7.62%] train loss: 4.3158976041013375e-05 \n",
      "epoch: 4 [68882/888800 7.75%] train loss: 3.912807733286172e-05 \n",
      "epoch: 4 [69993/888800 7.88%] train loss: 3.282820762251504e-05 \n",
      "epoch: 4 [71104/888800 8.00%] train loss: 4.427854946698062e-05 \n",
      "epoch: 4 [72215/888800 8.12%] train loss: 4.338339203968644e-05 \n",
      "epoch: 4 [73326/888800 8.25%] train loss: 3.641380317276344e-05 \n",
      "epoch: 4 [74437/888800 8.38%] train loss: 4.5526092435466126e-05 \n",
      "epoch: 4 [75548/888800 8.50%] train loss: 4.046974572702311e-05 \n",
      "epoch: 4 [76659/888800 8.62%] train loss: 4.067641930305399e-05 \n",
      "epoch: 4 [77770/888800 8.75%] train loss: 4.948797868564725e-05 \n",
      "epoch: 4 [78881/888800 8.88%] train loss: 4.5438504457706586e-05 \n",
      "epoch: 4 [79992/888800 9.00%] train loss: 3.953663690481335e-05 \n",
      "epoch: 4 [81103/888800 9.12%] train loss: 3.900317460647784e-05 \n",
      "epoch: 4 [82214/888800 9.25%] train loss: 3.5343146009836346e-05 \n",
      "epoch: 4 [83325/888800 9.38%] train loss: 4.612283009919338e-05 \n",
      "epoch: 4 [84436/888800 9.50%] train loss: 4.702663864009082e-05 \n",
      "epoch: 4 [85547/888800 9.62%] train loss: 4.5850512833567336e-05 \n",
      "epoch: 4 [86658/888800 9.75%] train loss: 3.74835217371583e-05 \n",
      "epoch: 4 [87769/888800 9.88%] train loss: 4.253771840012632e-05 \n",
      "epoch: 4 [88880/888800 10.00%] train loss: 3.791813287534751e-05 \n",
      "epoch: 4 [89991/888800 10.12%] train loss: 4.0746563172433525e-05 \n",
      "epoch: 4 [91102/888800 10.25%] train loss: 4.0823393646860495e-05 \n",
      "epoch: 4 [92213/888800 10.38%] train loss: 4.560338129522279e-05 \n",
      "epoch: 4 [93324/888800 10.50%] train loss: 4.379606616566889e-05 \n",
      "epoch: 4 [94435/888800 10.62%] train loss: 5.1550570788094774e-05 \n",
      "epoch: 4 [95546/888800 10.75%] train loss: 3.409843338886276e-05 \n",
      "epoch: 4 [96657/888800 10.88%] train loss: 4.4518717913888395e-05 \n",
      "epoch: 4 [97768/888800 11.00%] train loss: 3.9161823224276304e-05 \n",
      "epoch: 4 [98879/888800 11.12%] train loss: 3.770960756810382e-05 \n",
      "epoch: 4 [99990/888800 11.25%] train loss: 4.5549673814093694e-05 \n",
      "epoch: 4 [101101/888800 11.38%] train loss: 4.326949056121521e-05 \n",
      "epoch: 4 [102212/888800 11.50%] train loss: 4.757662463816814e-05 \n",
      "epoch: 4 [103323/888800 11.62%] train loss: 4.0078532038023695e-05 \n",
      "epoch: 4 [104434/888800 11.75%] train loss: 3.7298479583114386e-05 \n",
      "epoch: 4 [105545/888800 11.88%] train loss: 4.296291808714159e-05 \n",
      "epoch: 4 [106656/888800 12.00%] train loss: 4.1130115278065205e-05 \n",
      "epoch: 4 [107767/888800 12.12%] train loss: 4.23543642682489e-05 \n",
      "epoch: 4 [108878/888800 12.25%] train loss: 4.153876579948701e-05 \n",
      "epoch: 4 [109989/888800 12.38%] train loss: 3.650515282060951e-05 \n",
      "epoch: 4 [111100/888800 12.50%] train loss: 3.9185950299724936e-05 \n",
      "epoch: 4 [112211/888800 12.62%] train loss: 4.066337351105176e-05 \n",
      "epoch: 4 [113322/888800 12.75%] train loss: 4.851781341130845e-05 \n",
      "epoch: 4 [114433/888800 12.88%] train loss: 4.398987221065909e-05 \n",
      "epoch: 4 [115544/888800 13.00%] train loss: 4.9398207920603454e-05 \n",
      "epoch: 4 [116655/888800 13.12%] train loss: 4.913832890451886e-05 \n",
      "epoch: 4 [117766/888800 13.25%] train loss: 3.8956572097959e-05 \n",
      "epoch: 4 [118877/888800 13.38%] train loss: 3.980107430834323e-05 \n",
      "epoch: 4 [119988/888800 13.50%] train loss: 3.7694677303079516e-05 \n",
      "epoch: 4 [121099/888800 13.62%] train loss: 3.9981263398658484e-05 \n",
      "epoch: 4 [122210/888800 13.75%] train loss: 4.413988790474832e-05 \n",
      "epoch: 4 [123321/888800 13.88%] train loss: 3.411039142520167e-05 \n",
      "epoch: 4 [124432/888800 14.00%] train loss: 5.5826323659857735e-05 \n",
      "epoch: 4 [125543/888800 14.12%] train loss: 4.09499007218983e-05 \n",
      "epoch: 4 [126654/888800 14.25%] train loss: 3.939534872188233e-05 \n",
      "epoch: 4 [127765/888800 14.38%] train loss: 4.1262999729951844e-05 \n",
      "epoch: 4 [128876/888800 14.50%] train loss: 4.0939514292404056e-05 \n",
      "epoch: 4 [129987/888800 14.62%] train loss: 4.063441519974731e-05 \n",
      "epoch: 4 [131098/888800 14.75%] train loss: 4.03426747652702e-05 \n",
      "epoch: 4 [132209/888800 14.88%] train loss: 3.582736826501787e-05 \n",
      "epoch: 4 [133320/888800 15.00%] train loss: 4.859294858761132e-05 \n",
      "epoch: 4 [134431/888800 15.12%] train loss: 4.422416532179341e-05 \n",
      "epoch: 4 [135542/888800 15.25%] train loss: 3.9415979699697345e-05 \n",
      "epoch: 4 [136653/888800 15.38%] train loss: 3.889018626068719e-05 \n",
      "epoch: 4 [137764/888800 15.50%] train loss: 3.902667958755046e-05 \n",
      "epoch: 4 [138875/888800 15.62%] train loss: 4.017275932710618e-05 \n",
      "epoch: 4 [139986/888800 15.75%] train loss: 3.706686038640328e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [141097/888800 15.88%] train loss: 4.442843055585399e-05 \n",
      "epoch: 4 [142208/888800 16.00%] train loss: 3.790269329329021e-05 \n",
      "epoch: 4 [143319/888800 16.12%] train loss: 4.1129675082629547e-05 \n",
      "epoch: 4 [144430/888800 16.25%] train loss: 4.196993904770352e-05 \n",
      "epoch: 4 [145541/888800 16.38%] train loss: 3.765931251109578e-05 \n",
      "epoch: 4 [146652/888800 16.50%] train loss: 3.5913519241148606e-05 \n",
      "epoch: 4 [147763/888800 16.62%] train loss: 3.904016921296716e-05 \n",
      "epoch: 4 [148874/888800 16.75%] train loss: 5.12991682626307e-05 \n",
      "epoch: 4 [149985/888800 16.88%] train loss: 4.312217788537964e-05 \n",
      "epoch: 4 [151096/888800 17.00%] train loss: 3.365562952239998e-05 \n",
      "epoch: 4 [152207/888800 17.12%] train loss: 5.037777009420097e-05 \n",
      "epoch: 4 [153318/888800 17.25%] train loss: 4.4727854401571676e-05 \n",
      "epoch: 4 [154429/888800 17.38%] train loss: 3.868697240250185e-05 \n",
      "epoch: 4 [155540/888800 17.50%] train loss: 4.6931556425988674e-05 \n",
      "epoch: 4 [156651/888800 17.62%] train loss: 3.7647343560820445e-05 \n",
      "epoch: 4 [157762/888800 17.75%] train loss: 4.4086256821174175e-05 \n",
      "epoch: 4 [158873/888800 17.88%] train loss: 4.216208617435768e-05 \n",
      "epoch: 4 [159984/888800 18.00%] train loss: 3.558341268217191e-05 \n",
      "epoch: 4 [161095/888800 18.12%] train loss: 3.915094930562191e-05 \n",
      "epoch: 4 [162206/888800 18.25%] train loss: 4.349329901742749e-05 \n",
      "epoch: 4 [163317/888800 18.38%] train loss: 3.812272916547954e-05 \n",
      "epoch: 4 [164428/888800 18.50%] train loss: 4.143992191529833e-05 \n",
      "epoch: 4 [165539/888800 18.62%] train loss: 3.826645843219012e-05 \n",
      "epoch: 4 [166650/888800 18.75%] train loss: 4.41875854448881e-05 \n",
      "epoch: 4 [167761/888800 18.88%] train loss: 4.9373349611414596e-05 \n",
      "epoch: 4 [168872/888800 19.00%] train loss: 3.9099595596781e-05 \n",
      "epoch: 4 [169983/888800 19.12%] train loss: 4.028632974950597e-05 \n",
      "epoch: 4 [171094/888800 19.25%] train loss: 3.995711449533701e-05 \n",
      "epoch: 4 [172205/888800 19.38%] train loss: 4.9039586883736774e-05 \n",
      "epoch: 4 [173316/888800 19.50%] train loss: 4.0000839362619445e-05 \n",
      "epoch: 4 [174427/888800 19.62%] train loss: 3.6147201171843335e-05 \n",
      "epoch: 4 [175538/888800 19.75%] train loss: 3.7634996260749176e-05 \n",
      "epoch: 4 [176649/888800 19.88%] train loss: 4.428872125572525e-05 \n",
      "epoch: 4 [177760/888800 20.00%] train loss: 4.696064206655137e-05 \n",
      "epoch: 4 [178871/888800 20.12%] train loss: 4.581095708999783e-05 \n",
      "epoch: 4 [179982/888800 20.25%] train loss: 4.3245076085440814e-05 \n",
      "epoch: 4 [181093/888800 20.38%] train loss: 4.835074287257157e-05 \n",
      "epoch: 4 [182204/888800 20.50%] train loss: 4.162819095654413e-05 \n",
      "epoch: 4 [183315/888800 20.62%] train loss: 4.111934686079621e-05 \n",
      "epoch: 4 [184426/888800 20.75%] train loss: 4.0124552469933406e-05 \n",
      "epoch: 4 [185537/888800 20.88%] train loss: 4.559199442155659e-05 \n",
      "epoch: 4 [186648/888800 21.00%] train loss: 4.1266299376729876e-05 \n",
      "epoch: 4 [187759/888800 21.12%] train loss: 3.853512680507265e-05 \n",
      "epoch: 4 [188870/888800 21.25%] train loss: 5.245465581538156e-05 \n",
      "epoch: 4 [189981/888800 21.38%] train loss: 3.768823808059096e-05 \n",
      "epoch: 4 [191092/888800 21.50%] train loss: 4.559067019727081e-05 \n",
      "epoch: 4 [192203/888800 21.62%] train loss: 4.3954885768471286e-05 \n",
      "epoch: 4 [193314/888800 21.75%] train loss: 4.74178850708995e-05 \n",
      "epoch: 4 [194425/888800 21.88%] train loss: 4.0997620089910924e-05 \n",
      "epoch: 4 [195536/888800 22.00%] train loss: 4.2647719965316355e-05 \n",
      "epoch: 4 [196647/888800 22.12%] train loss: 3.287499202997424e-05 \n",
      "epoch: 4 [197758/888800 22.25%] train loss: 4.3389391066739336e-05 \n",
      "epoch: 4 [198869/888800 22.38%] train loss: 3.3804000850068405e-05 \n",
      "epoch: 4 [199980/888800 22.50%] train loss: 4.122110112803057e-05 \n",
      "epoch: 4 [201091/888800 22.62%] train loss: 4.4633048673858866e-05 \n",
      "epoch: 4 [202202/888800 22.75%] train loss: 3.6802797694690526e-05 \n",
      "epoch: 4 [203313/888800 22.88%] train loss: 5.1258259190944955e-05 \n",
      "epoch: 4 [204424/888800 23.00%] train loss: 4.425788938533515e-05 \n",
      "epoch: 4 [205535/888800 23.12%] train loss: 4.6150606067385525e-05 \n",
      "epoch: 4 [206646/888800 23.25%] train loss: 4.424423968885094e-05 \n",
      "epoch: 4 [207757/888800 23.38%] train loss: 4.743253521155566e-05 \n",
      "epoch: 4 [208868/888800 23.50%] train loss: 4.3800937419291586e-05 \n",
      "epoch: 4 [209979/888800 23.62%] train loss: 4.677552351495251e-05 \n",
      "epoch: 4 [211090/888800 23.75%] train loss: 4.872063436778262e-05 \n",
      "epoch: 4 [212201/888800 23.88%] train loss: 4.403650018502958e-05 \n",
      "epoch: 4 [213312/888800 24.00%] train loss: 4.197480666334741e-05 \n",
      "epoch: 4 [214423/888800 24.12%] train loss: 5.021677861805074e-05 \n",
      "epoch: 4 [215534/888800 24.25%] train loss: 3.954101703129709e-05 \n",
      "epoch: 4 [216645/888800 24.38%] train loss: 4.034600351587869e-05 \n",
      "epoch: 4 [217756/888800 24.50%] train loss: 4.185498255537823e-05 \n",
      "epoch: 4 [218867/888800 24.62%] train loss: 3.976787411374971e-05 \n",
      "epoch: 4 [219978/888800 24.75%] train loss: 4.421605990501121e-05 \n",
      "epoch: 4 [221089/888800 24.88%] train loss: 3.674923937069252e-05 \n",
      "epoch: 4 [222200/888800 25.00%] train loss: 4.453731526155025e-05 \n",
      "epoch: 4 [223311/888800 25.12%] train loss: 3.925320561393164e-05 \n",
      "epoch: 4 [224422/888800 25.25%] train loss: 4.389238893054426e-05 \n",
      "epoch: 4 [225533/888800 25.38%] train loss: 4.4859301851829514e-05 \n",
      "epoch: 4 [226644/888800 25.50%] train loss: 3.7850091757718474e-05 \n",
      "epoch: 4 [227755/888800 25.62%] train loss: 4.2123228922719136e-05 \n",
      "epoch: 4 [228866/888800 25.75%] train loss: 3.7258902011672035e-05 \n",
      "epoch: 4 [229977/888800 25.88%] train loss: 4.4258380512474105e-05 \n",
      "epoch: 4 [231088/888800 26.00%] train loss: 3.715102866408415e-05 \n",
      "epoch: 4 [232199/888800 26.12%] train loss: 4.443844227353111e-05 \n",
      "epoch: 4 [233310/888800 26.25%] train loss: 4.045914101880044e-05 \n",
      "epoch: 4 [234421/888800 26.38%] train loss: 4.4212421926204115e-05 \n",
      "epoch: 4 [235532/888800 26.50%] train loss: 3.884755278704688e-05 \n",
      "epoch: 4 [236643/888800 26.62%] train loss: 3.7709112802986056e-05 \n",
      "epoch: 4 [237754/888800 26.75%] train loss: 4.7741301386849955e-05 \n",
      "epoch: 4 [238865/888800 26.88%] train loss: 3.745250069187023e-05 \n",
      "epoch: 4 [239976/888800 27.00%] train loss: 4.004816946689971e-05 \n",
      "epoch: 4 [241087/888800 27.12%] train loss: 4.527442069957033e-05 \n",
      "epoch: 4 [242198/888800 27.25%] train loss: 4.909294148092158e-05 \n",
      "epoch: 4 [243309/888800 27.38%] train loss: 4.09909371228423e-05 \n",
      "epoch: 4 [244420/888800 27.50%] train loss: 3.6068558983970433e-05 \n",
      "epoch: 4 [245531/888800 27.62%] train loss: 4.255018211551942e-05 \n",
      "epoch: 4 [246642/888800 27.75%] train loss: 4.192441701889038e-05 \n",
      "epoch: 4 [247753/888800 27.88%] train loss: 4.2337822378613055e-05 \n",
      "epoch: 4 [248864/888800 28.00%] train loss: 4.051948417327367e-05 \n",
      "epoch: 4 [249975/888800 28.12%] train loss: 4.851752601098269e-05 \n",
      "epoch: 4 [251086/888800 28.25%] train loss: 5.0339920562691987e-05 \n",
      "epoch: 4 [252197/888800 28.38%] train loss: 4.675696982303634e-05 \n",
      "epoch: 4 [253308/888800 28.50%] train loss: 4.0458267903886735e-05 \n",
      "epoch: 4 [254419/888800 28.62%] train loss: 4.0673323383089155e-05 \n",
      "epoch: 4 [255530/888800 28.75%] train loss: 3.68082219210919e-05 \n",
      "epoch: 4 [256641/888800 28.88%] train loss: 3.633219967014156e-05 \n",
      "epoch: 4 [257752/888800 29.00%] train loss: 4.0443181205773726e-05 \n",
      "epoch: 4 [258863/888800 29.12%] train loss: 4.430472836247645e-05 \n",
      "epoch: 4 [259974/888800 29.25%] train loss: 5.323327422956936e-05 \n",
      "epoch: 4 [261085/888800 29.38%] train loss: 3.832710353890434e-05 \n",
      "epoch: 4 [262196/888800 29.50%] train loss: 4.206172889098525e-05 \n",
      "epoch: 4 [263307/888800 29.62%] train loss: 4.407450251164846e-05 \n",
      "epoch: 4 [264418/888800 29.75%] train loss: 4.284979877411388e-05 \n",
      "epoch: 4 [265529/888800 29.88%] train loss: 3.9103619201341644e-05 \n",
      "epoch: 4 [266640/888800 30.00%] train loss: 4.2580122681101784e-05 \n",
      "epoch: 4 [267751/888800 30.12%] train loss: 4.5273525756783783e-05 \n",
      "epoch: 4 [268862/888800 30.25%] train loss: 4.766376514453441e-05 \n",
      "epoch: 4 [269973/888800 30.38%] train loss: 4.3613166781142354e-05 \n",
      "epoch: 4 [271084/888800 30.50%] train loss: 4.836713196709752e-05 \n",
      "epoch: 4 [272195/888800 30.62%] train loss: 3.9193218981381506e-05 \n",
      "epoch: 4 [273306/888800 30.75%] train loss: 3.6810604797210544e-05 \n",
      "epoch: 4 [274417/888800 30.88%] train loss: 3.526612636051141e-05 \n",
      "epoch: 4 [275528/888800 31.00%] train loss: 5.0772094255080447e-05 \n",
      "epoch: 4 [276639/888800 31.12%] train loss: 4.155706483288668e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [277750/888800 31.25%] train loss: 4.653547512134537e-05 \n",
      "epoch: 4 [278861/888800 31.38%] train loss: 4.318234641687013e-05 \n",
      "epoch: 4 [279972/888800 31.50%] train loss: 4.4164225982967764e-05 \n",
      "epoch: 4 [281083/888800 31.62%] train loss: 4.19843454437796e-05 \n",
      "epoch: 4 [282194/888800 31.75%] train loss: 3.2636984542477876e-05 \n",
      "epoch: 4 [283305/888800 31.88%] train loss: 4.211398845654912e-05 \n",
      "epoch: 4 [284416/888800 32.00%] train loss: 3.5241824662080035e-05 \n",
      "epoch: 4 [285527/888800 32.12%] train loss: 3.6376004572957754e-05 \n",
      "epoch: 4 [286638/888800 32.25%] train loss: 3.8478290662169456e-05 \n",
      "epoch: 4 [287749/888800 32.38%] train loss: 4.5669985411223024e-05 \n",
      "epoch: 4 [288860/888800 32.50%] train loss: 3.6583416658686474e-05 \n",
      "epoch: 4 [289971/888800 32.62%] train loss: 4.775563138537109e-05 \n",
      "epoch: 4 [291082/888800 32.75%] train loss: 4.384401108836755e-05 \n",
      "epoch: 4 [292193/888800 32.88%] train loss: 4.055380850331858e-05 \n",
      "epoch: 4 [293304/888800 33.00%] train loss: 4.622357300831936e-05 \n",
      "epoch: 4 [294415/888800 33.12%] train loss: 3.98385054722894e-05 \n",
      "epoch: 4 [295526/888800 33.25%] train loss: 4.1044339013751596e-05 \n",
      "epoch: 4 [296637/888800 33.38%] train loss: 4.270584031473845e-05 \n",
      "epoch: 4 [297748/888800 33.50%] train loss: 4.023541623610072e-05 \n",
      "epoch: 4 [298859/888800 33.62%] train loss: 4.1090148442890495e-05 \n",
      "epoch: 4 [299970/888800 33.75%] train loss: 4.158589581493288e-05 \n",
      "epoch: 4 [301081/888800 33.88%] train loss: 3.0326076739584096e-05 \n",
      "epoch: 4 [302192/888800 34.00%] train loss: 4.1699426219565794e-05 \n",
      "epoch: 4 [303303/888800 34.12%] train loss: 4.2317471525166184e-05 \n",
      "epoch: 4 [304414/888800 34.25%] train loss: 3.7962196074659005e-05 \n",
      "epoch: 4 [305525/888800 34.38%] train loss: 4.215571971144527e-05 \n",
      "epoch: 4 [306636/888800 34.50%] train loss: 3.342308627907187e-05 \n",
      "epoch: 4 [307747/888800 34.62%] train loss: 3.775689037865959e-05 \n",
      "epoch: 4 [308858/888800 34.75%] train loss: 3.9100727008190006e-05 \n",
      "epoch: 4 [309969/888800 34.88%] train loss: 4.313439058023505e-05 \n",
      "epoch: 4 [311080/888800 35.00%] train loss: 4.267710755812004e-05 \n",
      "epoch: 4 [312191/888800 35.12%] train loss: 4.369617818156257e-05 \n",
      "epoch: 4 [313302/888800 35.25%] train loss: 3.959251262131147e-05 \n",
      "epoch: 4 [314413/888800 35.38%] train loss: 4.510624421527609e-05 \n",
      "epoch: 4 [315524/888800 35.50%] train loss: 3.57255048584193e-05 \n",
      "epoch: 4 [316635/888800 35.62%] train loss: 4.263478331267834e-05 \n",
      "epoch: 4 [317746/888800 35.75%] train loss: 4.182299380772747e-05 \n",
      "epoch: 4 [318857/888800 35.88%] train loss: 3.7753714423161e-05 \n",
      "epoch: 4 [319968/888800 36.00%] train loss: 4.095741314813495e-05 \n",
      "epoch: 4 [321079/888800 36.12%] train loss: 5.483130371430889e-05 \n",
      "epoch: 4 [322190/888800 36.25%] train loss: 4.3759118852904066e-05 \n",
      "epoch: 4 [323301/888800 36.38%] train loss: 4.13472116633784e-05 \n",
      "epoch: 4 [324412/888800 36.50%] train loss: 4.3703155824914575e-05 \n",
      "epoch: 4 [325523/888800 36.62%] train loss: 4.4239917770028114e-05 \n",
      "epoch: 4 [326634/888800 36.75%] train loss: 4.048778282594867e-05 \n",
      "epoch: 4 [327745/888800 36.88%] train loss: 4.434504808159545e-05 \n",
      "epoch: 4 [328856/888800 37.00%] train loss: 3.9540867874166e-05 \n",
      "epoch: 4 [329967/888800 37.12%] train loss: 4.361618266557343e-05 \n",
      "epoch: 4 [331078/888800 37.25%] train loss: 4.730742875835858e-05 \n",
      "epoch: 4 [332189/888800 37.38%] train loss: 3.91723369830288e-05 \n",
      "epoch: 4 [333300/888800 37.50%] train loss: 4.191381231066771e-05 \n",
      "epoch: 4 [334411/888800 37.62%] train loss: 4.230850754538551e-05 \n",
      "epoch: 4 [335522/888800 37.75%] train loss: 4.7901103243930265e-05 \n",
      "epoch: 4 [336633/888800 37.88%] train loss: 4.758227078127675e-05 \n",
      "epoch: 4 [337744/888800 38.00%] train loss: 3.936513894586824e-05 \n",
      "epoch: 4 [338855/888800 38.12%] train loss: 4.713482121587731e-05 \n",
      "epoch: 4 [339966/888800 38.25%] train loss: 3.618304981500842e-05 \n",
      "epoch: 4 [341077/888800 38.38%] train loss: 3.374421794433147e-05 \n",
      "epoch: 4 [342188/888800 38.50%] train loss: 4.112046008231118e-05 \n",
      "epoch: 4 [343299/888800 38.62%] train loss: 4.139254815527238e-05 \n",
      "epoch: 4 [344410/888800 38.75%] train loss: 3.6357541830511764e-05 \n",
      "epoch: 4 [345521/888800 38.88%] train loss: 4.458712646737695e-05 \n",
      "epoch: 4 [346632/888800 39.00%] train loss: 4.032407741760835e-05 \n",
      "epoch: 4 [347743/888800 39.12%] train loss: 4.007644747616723e-05 \n",
      "epoch: 4 [348854/888800 39.25%] train loss: 3.828402259387076e-05 \n",
      "epoch: 4 [349965/888800 39.38%] train loss: 3.355398075655103e-05 \n",
      "epoch: 4 [351076/888800 39.50%] train loss: 4.640218321583234e-05 \n",
      "epoch: 4 [352187/888800 39.62%] train loss: 3.900671799783595e-05 \n",
      "epoch: 4 [353298/888800 39.75%] train loss: 4.55832778243348e-05 \n",
      "epoch: 4 [354409/888800 39.88%] train loss: 4.0841845475370064e-05 \n",
      "epoch: 4 [355520/888800 40.00%] train loss: 3.83678161597345e-05 \n",
      "epoch: 4 [356631/888800 40.12%] train loss: 4.3011081288568676e-05 \n",
      "epoch: 4 [357742/888800 40.25%] train loss: 4.263605660526082e-05 \n",
      "epoch: 4 [358853/888800 40.38%] train loss: 3.9067341276677325e-05 \n",
      "epoch: 4 [359964/888800 40.50%] train loss: 4.316104968893342e-05 \n",
      "epoch: 4 [361075/888800 40.62%] train loss: 4.562648246064782e-05 \n",
      "epoch: 4 [362186/888800 40.75%] train loss: 4.235024971421808e-05 \n",
      "epoch: 4 [363297/888800 40.88%] train loss: 4.439915937837213e-05 \n",
      "epoch: 4 [364408/888800 41.00%] train loss: 4.789069862454198e-05 \n",
      "epoch: 4 [365519/888800 41.12%] train loss: 3.974531136918813e-05 \n",
      "epoch: 4 [366630/888800 41.25%] train loss: 4.352396717877127e-05 \n",
      "epoch: 4 [367741/888800 41.38%] train loss: 3.772143827518448e-05 \n",
      "epoch: 4 [368852/888800 41.50%] train loss: 4.1587933083064854e-05 \n",
      "epoch: 4 [369963/888800 41.62%] train loss: 4.233312210999429e-05 \n",
      "epoch: 4 [371074/888800 41.75%] train loss: 3.8119484088383615e-05 \n",
      "epoch: 4 [372185/888800 41.88%] train loss: 5.040573887526989e-05 \n",
      "epoch: 4 [373296/888800 42.00%] train loss: 4.0810409700497985e-05 \n",
      "epoch: 4 [374407/888800 42.12%] train loss: 5.371823499444872e-05 \n",
      "epoch: 4 [375518/888800 42.25%] train loss: 4.418958997121081e-05 \n",
      "epoch: 4 [376629/888800 42.38%] train loss: 4.74256303277798e-05 \n",
      "epoch: 4 [377740/888800 42.50%] train loss: 4.668946348829195e-05 \n",
      "epoch: 4 [378851/888800 42.62%] train loss: 4.493378582992591e-05 \n",
      "epoch: 4 [379962/888800 42.75%] train loss: 4.071875810041092e-05 \n",
      "epoch: 4 [381073/888800 42.88%] train loss: 4.3115756852785125e-05 \n",
      "epoch: 4 [382184/888800 43.00%] train loss: 5.002356192562729e-05 \n",
      "epoch: 4 [383295/888800 43.12%] train loss: 4.642728526960127e-05 \n",
      "epoch: 4 [384406/888800 43.25%] train loss: 4.4795779103878886e-05 \n",
      "epoch: 4 [385517/888800 43.38%] train loss: 4.3453786929603666e-05 \n",
      "epoch: 4 [386628/888800 43.50%] train loss: 3.77607429982163e-05 \n",
      "epoch: 4 [387739/888800 43.62%] train loss: 4.1064391552936286e-05 \n",
      "epoch: 4 [388850/888800 43.75%] train loss: 3.616045796661638e-05 \n",
      "epoch: 4 [389961/888800 43.88%] train loss: 3.319440656923689e-05 \n",
      "epoch: 4 [391072/888800 44.00%] train loss: 4.7484729293501005e-05 \n",
      "epoch: 4 [392183/888800 44.12%] train loss: 4.354448174126446e-05 \n",
      "epoch: 4 [393294/888800 44.25%] train loss: 4.0602735680295154e-05 \n",
      "epoch: 4 [394405/888800 44.38%] train loss: 4.1594950744183734e-05 \n",
      "epoch: 4 [395516/888800 44.50%] train loss: 4.293215897632763e-05 \n",
      "epoch: 4 [396627/888800 44.62%] train loss: 3.870467116939835e-05 \n",
      "epoch: 4 [397738/888800 44.75%] train loss: 4.431596607901156e-05 \n",
      "epoch: 4 [398849/888800 44.88%] train loss: 4.4579985114978626e-05 \n",
      "epoch: 4 [399960/888800 45.00%] train loss: 4.375659773359075e-05 \n",
      "epoch: 4 [401071/888800 45.12%] train loss: 4.5535372919403017e-05 \n",
      "epoch: 4 [402182/888800 45.25%] train loss: 4.06985855079256e-05 \n",
      "epoch: 4 [403293/888800 45.38%] train loss: 3.623484371928498e-05 \n",
      "epoch: 4 [404404/888800 45.50%] train loss: 4.262703805579804e-05 \n",
      "epoch: 4 [405515/888800 45.62%] train loss: 4.311410884838551e-05 \n",
      "epoch: 4 [406626/888800 45.75%] train loss: 4.0755334339337423e-05 \n",
      "epoch: 4 [407737/888800 45.88%] train loss: 3.7792298826389015e-05 \n",
      "epoch: 4 [408848/888800 46.00%] train loss: 4.0334052755497396e-05 \n",
      "epoch: 4 [409959/888800 46.12%] train loss: 3.466122143436223e-05 \n",
      "epoch: 4 [411070/888800 46.25%] train loss: 3.94298585888464e-05 \n",
      "epoch: 4 [412181/888800 46.38%] train loss: 3.4308253816561773e-05 \n",
      "epoch: 4 [413292/888800 46.50%] train loss: 3.6726320104207844e-05 \n",
      "epoch: 4 [414403/888800 46.62%] train loss: 3.6606921639759094e-05 \n",
      "epoch: 4 [415514/888800 46.75%] train loss: 4.450097549124621e-05 \n",
      "epoch: 4 [416625/888800 46.88%] train loss: 4.552477184915915e-05 \n",
      "epoch: 4 [417736/888800 47.00%] train loss: 4.4250748032936826e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [418847/888800 47.12%] train loss: 3.577365350793116e-05 \n",
      "epoch: 4 [419958/888800 47.25%] train loss: 3.7261703255353495e-05 \n",
      "epoch: 4 [421069/888800 47.38%] train loss: 4.727130726678297e-05 \n",
      "epoch: 4 [422180/888800 47.50%] train loss: 3.62298778782133e-05 \n",
      "epoch: 4 [423291/888800 47.62%] train loss: 4.625419023795985e-05 \n",
      "epoch: 4 [424402/888800 47.75%] train loss: 5.4739139159210026e-05 \n",
      "epoch: 4 [425513/888800 47.88%] train loss: 4.127107240492478e-05 \n",
      "epoch: 4 [426624/888800 48.00%] train loss: 4.6912140533095226e-05 \n",
      "epoch: 4 [427735/888800 48.12%] train loss: 3.700086381286383e-05 \n",
      "epoch: 4 [428846/888800 48.25%] train loss: 4.249129779054783e-05 \n",
      "epoch: 4 [429957/888800 48.38%] train loss: 4.319050640333444e-05 \n",
      "epoch: 4 [431068/888800 48.50%] train loss: 3.801761340582743e-05 \n",
      "epoch: 4 [432179/888800 48.62%] train loss: 4.464049925445579e-05 \n",
      "epoch: 4 [433290/888800 48.75%] train loss: 4.4023512600688264e-05 \n",
      "epoch: 4 [434401/888800 48.88%] train loss: 3.5561755794333294e-05 \n",
      "epoch: 4 [435512/888800 49.00%] train loss: 4.6620305511169136e-05 \n",
      "epoch: 4 [436623/888800 49.12%] train loss: 3.974597711930983e-05 \n",
      "epoch: 4 [437734/888800 49.25%] train loss: 3.381190981599502e-05 \n",
      "epoch: 4 [438845/888800 49.38%] train loss: 4.1434395825490355e-05 \n",
      "epoch: 4 [439956/888800 49.50%] train loss: 4.002565401606262e-05 \n",
      "epoch: 4 [441067/888800 49.62%] train loss: 4.842325870413333e-05 \n",
      "epoch: 4 [442178/888800 49.75%] train loss: 4.9301288527203724e-05 \n",
      "epoch: 4 [443289/888800 49.88%] train loss: 4.1380819311598316e-05 \n",
      "epoch: 4 [444400/888800 50.00%] train loss: 3.626733087003231e-05 \n",
      "epoch: 4 [445511/888800 50.12%] train loss: 3.913237014785409e-05 \n",
      "epoch: 4 [446622/888800 50.25%] train loss: 4.104186882614158e-05 \n",
      "epoch: 4 [447733/888800 50.38%] train loss: 4.808843004866503e-05 \n",
      "epoch: 4 [448844/888800 50.50%] train loss: 4.157661533099599e-05 \n",
      "epoch: 4 [449955/888800 50.62%] train loss: 3.8763220800319687e-05 \n",
      "epoch: 4 [451066/888800 50.75%] train loss: 3.4972941648447886e-05 \n",
      "epoch: 4 [452177/888800 50.88%] train loss: 4.492238076636568e-05 \n",
      "epoch: 4 [453288/888800 51.00%] train loss: 4.540068766800687e-05 \n",
      "epoch: 4 [454399/888800 51.12%] train loss: 4.561672903946601e-05 \n",
      "epoch: 4 [455510/888800 51.25%] train loss: 3.853852831525728e-05 \n",
      "epoch: 4 [456621/888800 51.38%] train loss: 4.729837382910773e-05 \n",
      "epoch: 4 [457732/888800 51.50%] train loss: 4.3857155105797574e-05 \n",
      "epoch: 4 [458843/888800 51.62%] train loss: 4.2233372369082645e-05 \n",
      "epoch: 4 [459954/888800 51.75%] train loss: 4.203712524031289e-05 \n",
      "epoch: 4 [461065/888800 51.88%] train loss: 4.624532812158577e-05 \n",
      "epoch: 4 [462176/888800 52.00%] train loss: 4.0846571209840477e-05 \n",
      "epoch: 4 [463287/888800 52.12%] train loss: 3.2843170629348606e-05 \n",
      "epoch: 4 [464398/888800 52.25%] train loss: 3.860679134959355e-05 \n",
      "epoch: 4 [465509/888800 52.38%] train loss: 3.837524127447978e-05 \n",
      "epoch: 4 [466620/888800 52.50%] train loss: 4.4160573452245444e-05 \n",
      "epoch: 4 [467731/888800 52.62%] train loss: 4.365549830254167e-05 \n",
      "epoch: 4 [468842/888800 52.75%] train loss: 4.0450049709761515e-05 \n",
      "epoch: 4 [469953/888800 52.88%] train loss: 4.438666292116977e-05 \n",
      "epoch: 4 [471064/888800 53.00%] train loss: 3.7375746614998206e-05 \n",
      "epoch: 4 [472175/888800 53.12%] train loss: 4.43722601630725e-05 \n",
      "epoch: 4 [473286/888800 53.25%] train loss: 3.14325479848776e-05 \n",
      "epoch: 4 [474397/888800 53.38%] train loss: 3.5089815355604514e-05 \n",
      "epoch: 4 [475508/888800 53.50%] train loss: 4.3908854422625154e-05 \n",
      "epoch: 4 [476619/888800 53.62%] train loss: 4.5350090658757836e-05 \n",
      "epoch: 4 [477730/888800 53.75%] train loss: 5.0723185267997906e-05 \n",
      "epoch: 4 [478841/888800 53.88%] train loss: 4.224866279400885e-05 \n",
      "epoch: 4 [479952/888800 54.00%] train loss: 4.3046857172157615e-05 \n",
      "epoch: 4 [481063/888800 54.12%] train loss: 4.7081775846891105e-05 \n",
      "epoch: 4 [482174/888800 54.25%] train loss: 4.115941555937752e-05 \n",
      "epoch: 4 [483285/888800 54.38%] train loss: 3.486876448732801e-05 \n",
      "epoch: 4 [484396/888800 54.50%] train loss: 4.4404630898498e-05 \n",
      "epoch: 4 [485507/888800 54.62%] train loss: 3.5353266866877675e-05 \n",
      "epoch: 4 [486618/888800 54.75%] train loss: 3.860449942294508e-05 \n",
      "epoch: 4 [487729/888800 54.88%] train loss: 4.177700975560583e-05 \n",
      "epoch: 4 [488840/888800 55.00%] train loss: 4.487738260650076e-05 \n",
      "epoch: 4 [489951/888800 55.12%] train loss: 3.626960824476555e-05 \n",
      "epoch: 4 [491062/888800 55.25%] train loss: 3.160111009492539e-05 \n",
      "epoch: 4 [492173/888800 55.38%] train loss: 3.501693936414085e-05 \n",
      "epoch: 4 [493284/888800 55.50%] train loss: 4.0300867112819105e-05 \n",
      "epoch: 4 [494395/888800 55.62%] train loss: 4.0429196815239266e-05 \n",
      "epoch: 4 [495506/888800 55.75%] train loss: 3.936820576200262e-05 \n",
      "epoch: 4 [496617/888800 55.88%] train loss: 3.382498834980652e-05 \n",
      "epoch: 4 [497728/888800 56.00%] train loss: 3.9397604268742725e-05 \n",
      "epoch: 4 [498839/888800 56.12%] train loss: 4.1280134610133246e-05 \n",
      "epoch: 4 [499950/888800 56.25%] train loss: 3.4021257306449115e-05 \n",
      "epoch: 4 [501061/888800 56.38%] train loss: 4.397016891743988e-05 \n",
      "epoch: 4 [502172/888800 56.50%] train loss: 3.665123222162947e-05 \n",
      "epoch: 4 [503283/888800 56.62%] train loss: 4.043853550683707e-05 \n",
      "epoch: 4 [504394/888800 56.75%] train loss: 4.2132975067943335e-05 \n",
      "epoch: 4 [505505/888800 56.88%] train loss: 3.48647590726614e-05 \n",
      "epoch: 4 [506616/888800 57.00%] train loss: 4.103204628336243e-05 \n",
      "epoch: 4 [507727/888800 57.12%] train loss: 3.904396726284176e-05 \n",
      "epoch: 4 [508838/888800 57.25%] train loss: 4.3800799176096916e-05 \n",
      "epoch: 4 [509949/888800 57.38%] train loss: 3.9303839002968743e-05 \n",
      "epoch: 4 [511060/888800 57.50%] train loss: 3.749098686967045e-05 \n",
      "epoch: 4 [512171/888800 57.62%] train loss: 5.222169420449063e-05 \n",
      "epoch: 4 [513282/888800 57.75%] train loss: 3.487033609417267e-05 \n",
      "epoch: 4 [514393/888800 57.88%] train loss: 3.660330912680365e-05 \n",
      "epoch: 4 [515504/888800 58.00%] train loss: 3.803153958870098e-05 \n",
      "epoch: 4 [516615/888800 58.12%] train loss: 4.377061122795567e-05 \n",
      "epoch: 4 [517726/888800 58.25%] train loss: 4.2753672460094094e-05 \n",
      "epoch: 4 [518837/888800 58.38%] train loss: 4.303051173337735e-05 \n",
      "epoch: 4 [519948/888800 58.50%] train loss: 4.195087240077555e-05 \n",
      "epoch: 4 [521059/888800 58.62%] train loss: 4.6546916564693674e-05 \n",
      "epoch: 4 [522170/888800 58.75%] train loss: 3.927045327145606e-05 \n",
      "epoch: 4 [523281/888800 58.88%] train loss: 4.244259253027849e-05 \n",
      "epoch: 4 [524392/888800 59.00%] train loss: 4.863767753704451e-05 \n",
      "epoch: 4 [525503/888800 59.12%] train loss: 4.185549187241122e-05 \n",
      "epoch: 4 [526614/888800 59.25%] train loss: 2.5576428015483543e-05 \n",
      "epoch: 4 [527725/888800 59.38%] train loss: 4.3872401874978095e-05 \n",
      "epoch: 4 [528836/888800 59.50%] train loss: 3.996138184447773e-05 \n",
      "epoch: 4 [529947/888800 59.62%] train loss: 3.231440859963186e-05 \n",
      "epoch: 4 [531058/888800 59.75%] train loss: 3.741033287951723e-05 \n",
      "epoch: 4 [532169/888800 59.88%] train loss: 4.0865263144951314e-05 \n",
      "epoch: 4 [533280/888800 60.00%] train loss: 3.952416227548383e-05 \n",
      "epoch: 4 [534391/888800 60.12%] train loss: 3.570089756976813e-05 \n",
      "epoch: 4 [535502/888800 60.25%] train loss: 4.332913158577867e-05 \n",
      "epoch: 4 [536613/888800 60.38%] train loss: 4.3899370211875066e-05 \n",
      "epoch: 4 [537724/888800 60.50%] train loss: 3.6643807106884196e-05 \n",
      "epoch: 4 [538835/888800 60.62%] train loss: 3.582707358873449e-05 \n",
      "epoch: 4 [539946/888800 60.75%] train loss: 4.879920379607938e-05 \n",
      "epoch: 4 [541057/888800 60.88%] train loss: 3.653841122286394e-05 \n",
      "epoch: 4 [542168/888800 61.00%] train loss: 4.2708426917670295e-05 \n",
      "epoch: 4 [543279/888800 61.12%] train loss: 3.970600664615631e-05 \n",
      "epoch: 4 [544390/888800 61.25%] train loss: 3.3862655982375145e-05 \n",
      "epoch: 4 [545501/888800 61.38%] train loss: 4.6283625124488026e-05 \n",
      "epoch: 4 [546612/888800 61.50%] train loss: 4.192942287772894e-05 \n",
      "epoch: 4 [547723/888800 61.62%] train loss: 3.5867135011358187e-05 \n",
      "epoch: 4 [548834/888800 61.75%] train loss: 4.1028055420611054e-05 \n",
      "epoch: 4 [549945/888800 61.88%] train loss: 3.589372499845922e-05 \n",
      "epoch: 4 [551056/888800 62.00%] train loss: 3.8796344597358257e-05 \n",
      "epoch: 4 [552167/888800 62.12%] train loss: 4.004730726592243e-05 \n",
      "epoch: 4 [553278/888800 62.25%] train loss: 3.523567283991724e-05 \n",
      "epoch: 4 [554389/888800 62.38%] train loss: 4.138857184443623e-05 \n",
      "epoch: 4 [555500/888800 62.50%] train loss: 3.69418557966128e-05 \n",
      "epoch: 4 [556611/888800 62.62%] train loss: 4.575051934807561e-05 \n",
      "epoch: 4 [557722/888800 62.75%] train loss: 3.723821646417491e-05 \n",
      "epoch: 4 [558833/888800 62.88%] train loss: 4.035936217405833e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [559944/888800 63.00%] train loss: 4.272045043762773e-05 \n",
      "epoch: 4 [561055/888800 63.12%] train loss: 4.060979699715972e-05 \n",
      "epoch: 4 [562166/888800 63.25%] train loss: 3.6700435884995386e-05 \n",
      "epoch: 4 [563277/888800 63.38%] train loss: 3.5292072425363585e-05 \n",
      "epoch: 4 [564388/888800 63.50%] train loss: 3.530910180415958e-05 \n",
      "epoch: 4 [565499/888800 63.62%] train loss: 3.5329150705365464e-05 \n",
      "epoch: 4 [566610/888800 63.75%] train loss: 4.244664160069078e-05 \n",
      "epoch: 4 [567721/888800 63.88%] train loss: 3.936628854717128e-05 \n",
      "epoch: 4 [568832/888800 64.00%] train loss: 4.095403346582316e-05 \n",
      "epoch: 4 [569943/888800 64.12%] train loss: 4.287537376512773e-05 \n",
      "epoch: 4 [571054/888800 64.25%] train loss: 4.615570287569426e-05 \n",
      "epoch: 4 [572165/888800 64.38%] train loss: 3.9101916627259925e-05 \n",
      "epoch: 4 [573276/888800 64.50%] train loss: 4.093893585377373e-05 \n",
      "epoch: 4 [574387/888800 64.62%] train loss: 4.005654773209244e-05 \n",
      "epoch: 4 [575498/888800 64.75%] train loss: 4.7161156544461846e-05 \n",
      "epoch: 4 [576609/888800 64.88%] train loss: 3.2214829843724146e-05 \n",
      "epoch: 4 [577720/888800 65.00%] train loss: 3.74483824998606e-05 \n",
      "epoch: 4 [578831/888800 65.12%] train loss: 4.487481783144176e-05 \n",
      "epoch: 4 [579942/888800 65.25%] train loss: 3.6406625440577045e-05 \n",
      "epoch: 4 [581053/888800 65.38%] train loss: 4.068559792358428e-05 \n",
      "epoch: 4 [582164/888800 65.50%] train loss: 4.096358679817058e-05 \n",
      "epoch: 4 [583275/888800 65.62%] train loss: 4.373609772301279e-05 \n",
      "epoch: 4 [584386/888800 65.75%] train loss: 3.946153083234094e-05 \n",
      "epoch: 4 [585497/888800 65.88%] train loss: 4.0100672777043656e-05 \n",
      "epoch: 4 [586608/888800 66.00%] train loss: 3.6854824429610744e-05 \n",
      "epoch: 4 [587719/888800 66.12%] train loss: 3.1500592740485445e-05 \n",
      "epoch: 4 [588830/888800 66.25%] train loss: 4.419195465743542e-05 \n",
      "epoch: 4 [589941/888800 66.38%] train loss: 4.515886030276306e-05 \n",
      "epoch: 4 [591052/888800 66.50%] train loss: 4.138309304835275e-05 \n",
      "epoch: 4 [592163/888800 66.62%] train loss: 4.278450069250539e-05 \n",
      "epoch: 4 [593274/888800 66.75%] train loss: 3.441042281338014e-05 \n",
      "epoch: 4 [594385/888800 66.88%] train loss: 4.342051761341281e-05 \n",
      "epoch: 4 [595496/888800 67.00%] train loss: 3.367083263583481e-05 \n",
      "epoch: 4 [596607/888800 67.12%] train loss: 3.6203116906108335e-05 \n",
      "epoch: 4 [597718/888800 67.25%] train loss: 3.0165618227329105e-05 \n",
      "epoch: 4 [598829/888800 67.38%] train loss: 4.456416718312539e-05 \n",
      "epoch: 4 [599940/888800 67.50%] train loss: 4.0205348341260105e-05 \n",
      "epoch: 4 [601051/888800 67.62%] train loss: 5.158805652172305e-05 \n",
      "epoch: 4 [602162/888800 67.75%] train loss: 3.465832560323179e-05 \n",
      "epoch: 4 [603273/888800 67.88%] train loss: 3.639718488557264e-05 \n",
      "epoch: 4 [604384/888800 68.00%] train loss: 3.7712205084972084e-05 \n",
      "epoch: 4 [605495/888800 68.12%] train loss: 4.033229561173357e-05 \n",
      "epoch: 4 [606606/888800 68.25%] train loss: 3.94900307583157e-05 \n",
      "epoch: 4 [607717/888800 68.38%] train loss: 3.9896553062135354e-05 \n",
      "epoch: 4 [608828/888800 68.50%] train loss: 4.244910815032199e-05 \n",
      "epoch: 4 [609939/888800 68.62%] train loss: 4.182481279713102e-05 \n",
      "epoch: 4 [611050/888800 68.75%] train loss: 3.8580754335271195e-05 \n",
      "epoch: 4 [612161/888800 68.88%] train loss: 4.078676283825189e-05 \n",
      "epoch: 4 [613272/888800 69.00%] train loss: 4.2187450162600726e-05 \n",
      "epoch: 4 [614383/888800 69.12%] train loss: 4.0474416891811416e-05 \n",
      "epoch: 4 [615494/888800 69.25%] train loss: 4.572266334434971e-05 \n",
      "epoch: 4 [616605/888800 69.38%] train loss: 3.67300417565275e-05 \n",
      "epoch: 4 [617716/888800 69.50%] train loss: 3.918991205864586e-05 \n",
      "epoch: 4 [618827/888800 69.62%] train loss: 4.266673931851983e-05 \n",
      "epoch: 4 [619938/888800 69.75%] train loss: 4.103590254089795e-05 \n",
      "epoch: 4 [621049/888800 69.88%] train loss: 4.0448747313348576e-05 \n",
      "epoch: 4 [622160/888800 70.00%] train loss: 4.175317371846177e-05 \n",
      "epoch: 4 [623271/888800 70.12%] train loss: 4.249095218256116e-05 \n",
      "epoch: 4 [624382/888800 70.25%] train loss: 3.3199801691807806e-05 \n",
      "epoch: 4 [625493/888800 70.38%] train loss: 3.64328661817126e-05 \n",
      "epoch: 4 [626604/888800 70.50%] train loss: 4.4021773646818474e-05 \n",
      "epoch: 4 [627715/888800 70.62%] train loss: 3.7816902477061376e-05 \n",
      "epoch: 4 [628826/888800 70.75%] train loss: 3.776495941565372e-05 \n",
      "epoch: 4 [629937/888800 70.88%] train loss: 3.9471196942031384e-05 \n",
      "epoch: 4 [631048/888800 71.00%] train loss: 3.8141701224958524e-05 \n",
      "epoch: 4 [632159/888800 71.12%] train loss: 3.4559168852865696e-05 \n",
      "epoch: 4 [633270/888800 71.25%] train loss: 4.783878102898598e-05 \n",
      "epoch: 4 [634381/888800 71.38%] train loss: 3.724163252627477e-05 \n",
      "epoch: 4 [635492/888800 71.50%] train loss: 3.907297650584951e-05 \n",
      "epoch: 4 [636603/888800 71.62%] train loss: 4.265940151526593e-05 \n",
      "epoch: 4 [637714/888800 71.75%] train loss: 3.822390135610476e-05 \n",
      "epoch: 4 [638825/888800 71.88%] train loss: 4.383065606816672e-05 \n",
      "epoch: 4 [639936/888800 72.00%] train loss: 4.75349479529541e-05 \n",
      "epoch: 4 [641047/888800 72.12%] train loss: 3.648951314971782e-05 \n",
      "epoch: 4 [642158/888800 72.25%] train loss: 4.528515273705125e-05 \n",
      "epoch: 4 [643269/888800 72.38%] train loss: 4.16536204284057e-05 \n",
      "epoch: 4 [644380/888800 72.50%] train loss: 4.305075344746001e-05 \n",
      "epoch: 4 [645491/888800 72.62%] train loss: 4.432274363352917e-05 \n",
      "epoch: 4 [646602/888800 72.75%] train loss: 4.352724863565527e-05 \n",
      "epoch: 4 [647713/888800 72.88%] train loss: 3.8581667467951775e-05 \n",
      "epoch: 4 [648824/888800 73.00%] train loss: 4.08004671044182e-05 \n",
      "epoch: 4 [649935/888800 73.12%] train loss: 4.1031380533240736e-05 \n",
      "epoch: 4 [651046/888800 73.25%] train loss: 4.4656455429503694e-05 \n",
      "epoch: 4 [652157/888800 73.38%] train loss: 4.078658457729034e-05 \n",
      "epoch: 4 [653268/888800 73.50%] train loss: 3.5141853004461154e-05 \n",
      "epoch: 4 [654379/888800 73.62%] train loss: 3.562502752174623e-05 \n",
      "epoch: 4 [655490/888800 73.75%] train loss: 3.7991503631928936e-05 \n",
      "epoch: 4 [656601/888800 73.88%] train loss: 3.3433458156650886e-05 \n",
      "epoch: 4 [657712/888800 74.00%] train loss: 3.874913090839982e-05 \n",
      "epoch: 4 [658823/888800 74.12%] train loss: 4.242572686052881e-05 \n",
      "epoch: 4 [659934/888800 74.25%] train loss: 4.0837443521013483e-05 \n",
      "epoch: 4 [661045/888800 74.38%] train loss: 4.217202513245866e-05 \n",
      "epoch: 4 [662156/888800 74.50%] train loss: 4.541798625723459e-05 \n",
      "epoch: 4 [663267/888800 74.62%] train loss: 3.9212747651617974e-05 \n",
      "epoch: 4 [664378/888800 74.75%] train loss: 4.436610106495209e-05 \n",
      "epoch: 4 [665489/888800 74.88%] train loss: 4.114944385946728e-05 \n",
      "epoch: 4 [666600/888800 75.00%] train loss: 4.694130257121287e-05 \n",
      "epoch: 4 [667711/888800 75.12%] train loss: 4.1266699554398656e-05 \n",
      "epoch: 4 [668822/888800 75.25%] train loss: 4.248137338436209e-05 \n",
      "epoch: 4 [669933/888800 75.38%] train loss: 4.236945460434072e-05 \n",
      "epoch: 4 [671044/888800 75.50%] train loss: 3.8763246266171336e-05 \n",
      "epoch: 4 [672155/888800 75.62%] train loss: 3.6924098822055385e-05 \n",
      "epoch: 4 [673266/888800 75.75%] train loss: 4.338429062045179e-05 \n",
      "epoch: 4 [674377/888800 75.88%] train loss: 3.997406747657806e-05 \n",
      "epoch: 4 [675488/888800 76.00%] train loss: 4.3169358832528815e-05 \n",
      "epoch: 4 [676599/888800 76.12%] train loss: 4.077536141267046e-05 \n",
      "epoch: 4 [677710/888800 76.25%] train loss: 4.046811955049634e-05 \n",
      "epoch: 4 [678821/888800 76.38%] train loss: 4.335801349952817e-05 \n",
      "epoch: 4 [679932/888800 76.50%] train loss: 4.1787236114032567e-05 \n",
      "epoch: 4 [681043/888800 76.62%] train loss: 5.053891072748229e-05 \n",
      "epoch: 4 [682154/888800 76.75%] train loss: 4.7144170821411535e-05 \n",
      "epoch: 4 [683265/888800 76.88%] train loss: 4.5024906285107136e-05 \n",
      "epoch: 4 [684376/888800 77.00%] train loss: 3.681893940665759e-05 \n",
      "epoch: 4 [685487/888800 77.12%] train loss: 4.365683707874268e-05 \n",
      "epoch: 4 [686598/888800 77.25%] train loss: 3.8082092942204326e-05 \n",
      "epoch: 4 [687709/888800 77.38%] train loss: 4.649001857615076e-05 \n",
      "epoch: 4 [688820/888800 77.50%] train loss: 4.1696934204082936e-05 \n",
      "epoch: 4 [689931/888800 77.62%] train loss: 4.015340891783126e-05 \n",
      "epoch: 4 [691042/888800 77.75%] train loss: 4.38675306213554e-05 \n",
      "epoch: 4 [692153/888800 77.88%] train loss: 3.694744373206049e-05 \n",
      "epoch: 4 [693264/888800 78.00%] train loss: 4.293733582017012e-05 \n",
      "epoch: 4 [694375/888800 78.12%] train loss: 4.4233562221052125e-05 \n",
      "epoch: 4 [695486/888800 78.25%] train loss: 4.805402932106517e-05 \n",
      "epoch: 4 [696597/888800 78.38%] train loss: 5.1160375733161345e-05 \n",
      "epoch: 4 [697708/888800 78.50%] train loss: 4.5688124373555183e-05 \n",
      "epoch: 4 [698819/888800 78.62%] train loss: 4.158022420597263e-05 \n",
      "epoch: 4 [699930/888800 78.75%] train loss: 3.826146348728798e-05 \n",
      "epoch: 4 [701041/888800 78.88%] train loss: 4.3054413254139945e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [702152/888800 79.00%] train loss: 4.30613654316403e-05 \n",
      "epoch: 4 [703263/888800 79.12%] train loss: 5.1044731662841514e-05 \n",
      "epoch: 4 [704374/888800 79.25%] train loss: 3.8825419323984534e-05 \n",
      "epoch: 4 [705485/888800 79.38%] train loss: 4.374457785161212e-05 \n",
      "epoch: 4 [706596/888800 79.50%] train loss: 3.055385241168551e-05 \n",
      "epoch: 4 [707707/888800 79.62%] train loss: 4.112107853870839e-05 \n",
      "epoch: 4 [708818/888800 79.75%] train loss: 3.6413817724678665e-05 \n",
      "epoch: 4 [709929/888800 79.88%] train loss: 3.661116352304816e-05 \n",
      "epoch: 4 [711040/888800 80.00%] train loss: 4.815061402041465e-05 \n",
      "epoch: 4 [712151/888800 80.12%] train loss: 4.395799624035135e-05 \n",
      "epoch: 4 [713262/888800 80.25%] train loss: 4.0517697925679386e-05 \n",
      "epoch: 4 [714373/888800 80.38%] train loss: 4.2276325984857976e-05 \n",
      "epoch: 4 [715484/888800 80.50%] train loss: 4.236374661559239e-05 \n",
      "epoch: 4 [716595/888800 80.62%] train loss: 4.256872125552036e-05 \n",
      "epoch: 4 [717706/888800 80.75%] train loss: 3.723757981788367e-05 \n",
      "epoch: 4 [718817/888800 80.88%] train loss: 3.906533675035462e-05 \n",
      "epoch: 4 [719928/888800 81.00%] train loss: 3.9615410059923306e-05 \n",
      "epoch: 4 [721039/888800 81.12%] train loss: 4.724014434032142e-05 \n",
      "epoch: 4 [722150/888800 81.25%] train loss: 3.66703316103667e-05 \n",
      "epoch: 4 [723261/888800 81.38%] train loss: 4.2183397454209626e-05 \n",
      "epoch: 4 [724372/888800 81.50%] train loss: 3.227775960112922e-05 \n",
      "epoch: 4 [725483/888800 81.62%] train loss: 3.6814843042520806e-05 \n",
      "epoch: 4 [726594/888800 81.75%] train loss: 4.56823872809764e-05 \n",
      "epoch: 4 [727705/888800 81.88%] train loss: 3.626154284575023e-05 \n",
      "epoch: 4 [728816/888800 82.00%] train loss: 3.60340673069004e-05 \n",
      "epoch: 4 [729927/888800 82.12%] train loss: 4.584324415191077e-05 \n",
      "epoch: 4 [731038/888800 82.25%] train loss: 4.2261955968569964e-05 \n",
      "epoch: 4 [732149/888800 82.38%] train loss: 4.368293593870476e-05 \n",
      "epoch: 4 [733260/888800 82.50%] train loss: 3.386122261872515e-05 \n",
      "epoch: 4 [734371/888800 82.62%] train loss: 3.4922544728033245e-05 \n",
      "epoch: 4 [735482/888800 82.75%] train loss: 4.70806444354821e-05 \n",
      "epoch: 4 [736593/888800 82.88%] train loss: 3.412446676520631e-05 \n",
      "epoch: 4 [737704/888800 83.00%] train loss: 3.8461366784758866e-05 \n",
      "epoch: 4 [738815/888800 83.12%] train loss: 4.5481760025722906e-05 \n",
      "epoch: 4 [739926/888800 83.25%] train loss: 4.045018431497738e-05 \n",
      "epoch: 4 [741037/888800 83.38%] train loss: 4.2243329517077655e-05 \n",
      "epoch: 4 [742148/888800 83.50%] train loss: 3.863730307784863e-05 \n",
      "epoch: 4 [743259/888800 83.62%] train loss: 4.22685916419141e-05 \n",
      "epoch: 4 [744370/888800 83.75%] train loss: 3.855256727547385e-05 \n",
      "epoch: 4 [745481/888800 83.88%] train loss: 4.796791836270131e-05 \n",
      "epoch: 4 [746592/888800 84.00%] train loss: 4.024040754302405e-05 \n",
      "epoch: 4 [747703/888800 84.12%] train loss: 3.998875035904348e-05 \n",
      "epoch: 4 [748814/888800 84.25%] train loss: 3.375325832166709e-05 \n",
      "epoch: 4 [749925/888800 84.38%] train loss: 4.7387969971168786e-05 \n",
      "epoch: 4 [751036/888800 84.50%] train loss: 4.7388472012244165e-05 \n",
      "epoch: 4 [752147/888800 84.62%] train loss: 3.5680677683558315e-05 \n",
      "epoch: 4 [753258/888800 84.75%] train loss: 3.688939614221454e-05 \n",
      "epoch: 4 [754369/888800 84.88%] train loss: 3.422849113121629e-05 \n",
      "epoch: 4 [755480/888800 85.00%] train loss: 4.474080924410373e-05 \n",
      "epoch: 4 [756591/888800 85.12%] train loss: 4.312457167543471e-05 \n",
      "epoch: 4 [757702/888800 85.25%] train loss: 3.0600880563724786e-05 \n",
      "epoch: 4 [758813/888800 85.38%] train loss: 3.84411214326974e-05 \n",
      "epoch: 4 [759924/888800 85.50%] train loss: 4.2358322389191017e-05 \n",
      "epoch: 4 [761035/888800 85.62%] train loss: 3.789921902352944e-05 \n",
      "epoch: 4 [762146/888800 85.75%] train loss: 4.451365384738892e-05 \n",
      "epoch: 4 [763257/888800 85.88%] train loss: 3.521642429404892e-05 \n",
      "epoch: 4 [764368/888800 86.00%] train loss: 3.6752273445017636e-05 \n",
      "epoch: 4 [765479/888800 86.12%] train loss: 3.781505438382737e-05 \n",
      "epoch: 4 [766590/888800 86.25%] train loss: 3.490471499389969e-05 \n",
      "epoch: 4 [767701/888800 86.38%] train loss: 4.5849876187276095e-05 \n",
      "epoch: 4 [768812/888800 86.50%] train loss: 4.214067303109914e-05 \n",
      "epoch: 4 [769923/888800 86.62%] train loss: 4.616400838131085e-05 \n",
      "epoch: 4 [771034/888800 86.75%] train loss: 4.108899520360865e-05 \n",
      "epoch: 4 [772145/888800 86.88%] train loss: 3.539051613188349e-05 \n",
      "epoch: 4 [773256/888800 87.00%] train loss: 3.966534131905064e-05 \n",
      "epoch: 4 [774367/888800 87.12%] train loss: 4.270215140422806e-05 \n",
      "epoch: 4 [775478/888800 87.25%] train loss: 3.5273285902803764e-05 \n",
      "epoch: 4 [776589/888800 87.38%] train loss: 4.127249849261716e-05 \n",
      "epoch: 4 [777700/888800 87.50%] train loss: 4.2132734961342067e-05 \n",
      "epoch: 4 [778811/888800 87.62%] train loss: 4.602901026373729e-05 \n",
      "epoch: 4 [779922/888800 87.75%] train loss: 3.774335709749721e-05 \n",
      "epoch: 4 [781033/888800 87.88%] train loss: 2.8134345484431833e-05 \n",
      "epoch: 4 [782144/888800 88.00%] train loss: 3.9665195799898356e-05 \n",
      "epoch: 4 [783255/888800 88.12%] train loss: 4.1882754885591567e-05 \n",
      "epoch: 4 [784366/888800 88.25%] train loss: 3.4460084862075746e-05 \n",
      "epoch: 4 [785477/888800 88.38%] train loss: 4.147480649407953e-05 \n",
      "epoch: 4 [786588/888800 88.50%] train loss: 3.5029406717512757e-05 \n",
      "epoch: 4 [787699/888800 88.62%] train loss: 4.095647454960272e-05 \n",
      "epoch: 4 [788810/888800 88.75%] train loss: 4.566153438645415e-05 \n",
      "epoch: 4 [789921/888800 88.88%] train loss: 4.5181321183918044e-05 \n",
      "epoch: 4 [791032/888800 89.00%] train loss: 4.76914610771928e-05 \n",
      "epoch: 4 [792143/888800 89.12%] train loss: 4.26227088610176e-05 \n",
      "epoch: 4 [793254/888800 89.25%] train loss: 3.3721054933266714e-05 \n",
      "epoch: 4 [794365/888800 89.38%] train loss: 4.0165221435017884e-05 \n",
      "epoch: 4 [795476/888800 89.50%] train loss: 4.572719262796454e-05 \n",
      "epoch: 4 [796587/888800 89.62%] train loss: 4.8811358283273876e-05 \n",
      "epoch: 4 [797698/888800 89.75%] train loss: 3.9588092477060854e-05 \n",
      "epoch: 4 [798809/888800 89.88%] train loss: 4.4152504415251315e-05 \n",
      "epoch: 4 [799920/888800 90.00%] train loss: 3.8797221350250766e-05 \n",
      "epoch: 4 [801031/888800 90.12%] train loss: 3.541924161254428e-05 \n",
      "epoch: 4 [802142/888800 90.25%] train loss: 4.1217503166990355e-05 \n",
      "epoch: 4 [803253/888800 90.38%] train loss: 3.1730196496937424e-05 \n",
      "epoch: 4 [804364/888800 90.50%] train loss: 4.502963201957755e-05 \n",
      "epoch: 4 [805475/888800 90.62%] train loss: 4.416868614498526e-05 \n",
      "epoch: 4 [806586/888800 90.75%] train loss: 4.642374915420078e-05 \n",
      "epoch: 4 [807697/888800 90.88%] train loss: 3.85396670026239e-05 \n",
      "epoch: 4 [808808/888800 91.00%] train loss: 4.25138532591518e-05 \n",
      "epoch: 4 [809919/888800 91.12%] train loss: 3.500772072584368e-05 \n",
      "epoch: 4 [811030/888800 91.25%] train loss: 3.935850691050291e-05 \n",
      "epoch: 4 [812141/888800 91.38%] train loss: 3.2972940971376374e-05 \n",
      "epoch: 4 [813252/888800 91.50%] train loss: 4.0013612306211144e-05 \n",
      "epoch: 4 [814363/888800 91.62%] train loss: 3.960736285080202e-05 \n",
      "epoch: 4 [815474/888800 91.75%] train loss: 3.3202744816662744e-05 \n",
      "epoch: 4 [816585/888800 91.88%] train loss: 3.5443605156615376e-05 \n",
      "epoch: 4 [817696/888800 92.00%] train loss: 3.6653476854553446e-05 \n",
      "epoch: 4 [818807/888800 92.12%] train loss: 4.086418994120322e-05 \n",
      "epoch: 4 [819918/888800 92.25%] train loss: 4.120553421671502e-05 \n",
      "epoch: 4 [821029/888800 92.38%] train loss: 3.689987715915777e-05 \n",
      "epoch: 4 [822140/888800 92.50%] train loss: 4.543986506178044e-05 \n",
      "epoch: 4 [823251/888800 92.62%] train loss: 3.6110410292167217e-05 \n",
      "epoch: 4 [824362/888800 92.75%] train loss: 3.88872686016839e-05 \n",
      "epoch: 4 [825473/888800 92.88%] train loss: 4.011267446912825e-05 \n",
      "epoch: 4 [826584/888800 93.00%] train loss: 4.2692041461123154e-05 \n",
      "epoch: 4 [827695/888800 93.12%] train loss: 3.726418435689993e-05 \n",
      "epoch: 4 [828806/888800 93.25%] train loss: 3.7396424886537716e-05 \n",
      "epoch: 4 [829917/888800 93.38%] train loss: 4.055806130054407e-05 \n",
      "epoch: 4 [831028/888800 93.50%] train loss: 4.045987952849828e-05 \n",
      "epoch: 4 [832139/888800 93.62%] train loss: 4.5217919250717387e-05 \n",
      "epoch: 4 [833250/888800 93.75%] train loss: 4.038189581478946e-05 \n",
      "epoch: 4 [834361/888800 93.88%] train loss: 3.7680580135202035e-05 \n",
      "epoch: 4 [835472/888800 94.00%] train loss: 3.680944428197108e-05 \n",
      "epoch: 4 [836583/888800 94.12%] train loss: 3.591674249037169e-05 \n",
      "epoch: 4 [837694/888800 94.25%] train loss: 4.0582319343229756e-05 \n",
      "epoch: 4 [838805/888800 94.38%] train loss: 4.572453326545656e-05 \n",
      "epoch: 4 [839916/888800 94.50%] train loss: 3.9915426896186545e-05 \n",
      "epoch: 4 [841027/888800 94.62%] train loss: 3.9964048482943326e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 [842138/888800 94.75%] train loss: 4.890194395557046e-05 \n",
      "epoch: 4 [843249/888800 94.88%] train loss: 3.511372779030353e-05 \n",
      "epoch: 4 [844360/888800 95.00%] train loss: 4.615390571416356e-05 \n",
      "epoch: 4 [845471/888800 95.12%] train loss: 4.247003380442038e-05 \n",
      "epoch: 4 [846582/888800 95.25%] train loss: 3.7711692129960284e-05 \n",
      "epoch: 4 [847693/888800 95.38%] train loss: 4.0802155126584694e-05 \n",
      "epoch: 4 [848804/888800 95.50%] train loss: 4.1546201828168705e-05 \n",
      "epoch: 4 [849915/888800 95.62%] train loss: 3.822948201559484e-05 \n",
      "epoch: 4 [851026/888800 95.75%] train loss: 3.632341031334363e-05 \n",
      "epoch: 4 [852137/888800 95.88%] train loss: 4.377203367766924e-05 \n",
      "epoch: 4 [853248/888800 96.00%] train loss: 3.699240551213734e-05 \n",
      "epoch: 4 [854359/888800 96.12%] train loss: 4.3100510083604604e-05 \n",
      "epoch: 4 [855470/888800 96.25%] train loss: 3.802610808634199e-05 \n",
      "epoch: 4 [856581/888800 96.38%] train loss: 3.905252378899604e-05 \n",
      "epoch: 4 [857692/888800 96.50%] train loss: 3.613699664128944e-05 \n",
      "epoch: 4 [858803/888800 96.62%] train loss: 4.6124863729346544e-05 \n",
      "epoch: 4 [859914/888800 96.75%] train loss: 3.941964314435609e-05 \n",
      "epoch: 4 [861025/888800 96.88%] train loss: 3.099008972640149e-05 \n",
      "epoch: 4 [862136/888800 97.00%] train loss: 3.82307443942409e-05 \n",
      "epoch: 4 [863247/888800 97.12%] train loss: 4.6174784074537456e-05 \n",
      "epoch: 4 [864358/888800 97.25%] train loss: 3.4680480894166976e-05 \n",
      "epoch: 4 [865469/888800 97.38%] train loss: 4.298952262615785e-05 \n",
      "epoch: 4 [866580/888800 97.50%] train loss: 3.87732325179968e-05 \n",
      "epoch: 4 [867691/888800 97.62%] train loss: 3.882997407345101e-05 \n",
      "epoch: 4 [868802/888800 97.75%] train loss: 3.3182866900460795e-05 \n",
      "epoch: 4 [869913/888800 97.88%] train loss: 3.769393515540287e-05 \n",
      "epoch: 4 [871024/888800 98.00%] train loss: 3.71236601495184e-05 \n",
      "epoch: 4 [872135/888800 98.12%] train loss: 3.73333714378532e-05 \n",
      "epoch: 4 [873246/888800 98.25%] train loss: 3.824656596407294e-05 \n",
      "epoch: 4 [874357/888800 98.38%] train loss: 3.749929601326585e-05 \n",
      "epoch: 4 [875468/888800 98.50%] train loss: 3.5416687751421705e-05 \n",
      "epoch: 4 [876579/888800 98.62%] train loss: 4.428843385539949e-05 \n",
      "epoch: 4 [877690/888800 98.75%] train loss: 4.169706517131999e-05 \n",
      "epoch: 4 [878801/888800 98.88%] train loss: 4.121536039747298e-05 \n",
      "epoch: 4 [879912/888800 99.00%] train loss: 3.872721936204471e-05 \n",
      "epoch: 4 [881023/888800 99.12%] train loss: 4.0664792322786525e-05 \n",
      "epoch: 4 [882134/888800 99.25%] train loss: 3.9634036511415616e-05 \n",
      "epoch: 4 [883245/888800 99.38%] train loss: 3.9660095353610814e-05 \n",
      "epoch: 4 [884356/888800 99.50%] train loss: 4.535243715508841e-05 \n",
      "epoch: 4 [885467/888800 99.62%] train loss: 4.302896195440553e-05 \n",
      "epoch: 4 [886578/888800 99.75%] train loss: 3.5296874557388946e-05 \n",
      "epoch: 4 [887689/888800 99.88%] train loss: 4.374864511191845e-05 \n",
      "epoch: 5 [0/888800 0.00%] train loss: 4.394424831843935e-05 \n",
      "epoch: 5 [1111/888800 0.12%] train loss: 3.880524673149921e-05 \n",
      "epoch: 5 [2222/888800 0.25%] train loss: 3.983150963904336e-05 \n",
      "epoch: 5 [3333/888800 0.38%] train loss: 3.6182125768391415e-05 \n",
      "epoch: 5 [4444/888800 0.50%] train loss: 4.357939906185493e-05 \n",
      "epoch: 5 [5555/888800 0.62%] train loss: 3.9211332477862015e-05 \n",
      "epoch: 5 [6666/888800 0.75%] train loss: 3.916939385817386e-05 \n",
      "epoch: 5 [7777/888800 0.88%] train loss: 3.698858563438989e-05 \n",
      "epoch: 5 [8888/888800 1.00%] train loss: 4.2387997382320464e-05 \n",
      "epoch: 5 [9999/888800 1.12%] train loss: 4.1601655539125204e-05 \n",
      "epoch: 5 [11110/888800 1.25%] train loss: 3.849491258733906e-05 \n",
      "epoch: 5 [12221/888800 1.38%] train loss: 4.447016544872895e-05 \n",
      "epoch: 5 [13332/888800 1.50%] train loss: 3.403257142053917e-05 \n",
      "epoch: 5 [14443/888800 1.62%] train loss: 4.2548086639726534e-05 \n",
      "epoch: 5 [15554/888800 1.75%] train loss: 3.9766720874467865e-05 \n",
      "epoch: 5 [16665/888800 1.88%] train loss: 4.0914834244176745e-05 \n",
      "epoch: 5 [17776/888800 2.00%] train loss: 4.043275839649141e-05 \n",
      "epoch: 5 [18887/888800 2.12%] train loss: 3.383399234735407e-05 \n",
      "epoch: 5 [19998/888800 2.25%] train loss: 4.009589974884875e-05 \n",
      "epoch: 5 [21109/888800 2.38%] train loss: 4.4317108404356986e-05 \n",
      "epoch: 5 [22220/888800 2.50%] train loss: 4.7349592932732776e-05 \n",
      "epoch: 5 [23331/888800 2.62%] train loss: 4.1674345993669704e-05 \n",
      "epoch: 5 [24442/888800 2.75%] train loss: 3.741144246305339e-05 \n",
      "epoch: 5 [25553/888800 2.88%] train loss: 3.888866558554582e-05 \n",
      "epoch: 5 [26664/888800 3.00%] train loss: 4.244766023475677e-05 \n",
      "epoch: 5 [27775/888800 3.12%] train loss: 3.7172037991695106e-05 \n",
      "epoch: 5 [28886/888800 3.25%] train loss: 4.048697155667469e-05 \n",
      "epoch: 5 [29997/888800 3.38%] train loss: 3.943115007132292e-05 \n",
      "epoch: 5 [31108/888800 3.50%] train loss: 5.090210470370948e-05 \n",
      "epoch: 5 [32219/888800 3.62%] train loss: 3.7582758523058146e-05 \n",
      "epoch: 5 [33330/888800 3.75%] train loss: 4.056852776557207e-05 \n",
      "epoch: 5 [34441/888800 3.88%] train loss: 3.976532389060594e-05 \n",
      "epoch: 5 [35552/888800 4.00%] train loss: 4.5790533476974815e-05 \n",
      "epoch: 5 [36663/888800 4.12%] train loss: 3.329974424559623e-05 \n",
      "epoch: 5 [37774/888800 4.25%] train loss: 3.242956518079154e-05 \n",
      "epoch: 5 [38885/888800 4.38%] train loss: 4.9880552978720516e-05 \n",
      "epoch: 5 [39996/888800 4.50%] train loss: 3.241197919123806e-05 \n",
      "epoch: 5 [41107/888800 4.62%] train loss: 3.596929309424013e-05 \n",
      "epoch: 5 [42218/888800 4.75%] train loss: 4.2116389522561803e-05 \n",
      "epoch: 5 [43329/888800 4.88%] train loss: 3.8539536035386845e-05 \n",
      "epoch: 5 [44440/888800 5.00%] train loss: 3.807723624049686e-05 \n",
      "epoch: 5 [45551/888800 5.12%] train loss: 4.418320531840436e-05 \n",
      "epoch: 5 [46662/888800 5.25%] train loss: 3.444933099672198e-05 \n",
      "epoch: 5 [47773/888800 5.38%] train loss: 4.492846710490994e-05 \n",
      "epoch: 5 [48884/888800 5.50%] train loss: 4.3589912820607424e-05 \n",
      "epoch: 5 [49995/888800 5.62%] train loss: 3.578639370971359e-05 \n",
      "epoch: 5 [51106/888800 5.75%] train loss: 3.450276199146174e-05 \n",
      "epoch: 5 [52217/888800 5.88%] train loss: 4.109230940230191e-05 \n",
      "epoch: 5 [53328/888800 6.00%] train loss: 3.546696461853571e-05 \n",
      "epoch: 5 [54439/888800 6.12%] train loss: 4.0405029722023755e-05 \n",
      "epoch: 5 [55550/888800 6.25%] train loss: 4.0442944737151265e-05 \n",
      "epoch: 5 [56661/888800 6.38%] train loss: 4.093319512321614e-05 \n",
      "epoch: 5 [57772/888800 6.50%] train loss: 3.869614374707453e-05 \n",
      "epoch: 5 [58883/888800 6.62%] train loss: 4.4002754293615e-05 \n",
      "epoch: 5 [59994/888800 6.75%] train loss: 3.4943834180012345e-05 \n",
      "epoch: 5 [61105/888800 6.88%] train loss: 3.2281343010254204e-05 \n",
      "epoch: 5 [62216/888800 7.00%] train loss: 4.037955295643769e-05 \n",
      "epoch: 5 [63327/888800 7.12%] train loss: 3.2392872526543215e-05 \n",
      "epoch: 5 [64438/888800 7.25%] train loss: 3.693653707159683e-05 \n",
      "epoch: 5 [65549/888800 7.38%] train loss: 3.5874767490895465e-05 \n",
      "epoch: 5 [66660/888800 7.50%] train loss: 5.1883758715121076e-05 \n",
      "epoch: 5 [67771/888800 7.62%] train loss: 3.256912168581039e-05 \n",
      "epoch: 5 [68882/888800 7.75%] train loss: 4.421513949637301e-05 \n",
      "epoch: 5 [69993/888800 7.88%] train loss: 3.490813833195716e-05 \n",
      "epoch: 5 [71104/888800 8.00%] train loss: 3.7399251596070826e-05 \n",
      "epoch: 5 [72215/888800 8.12%] train loss: 3.195359749952331e-05 \n",
      "epoch: 5 [73326/888800 8.25%] train loss: 3.794284202740528e-05 \n",
      "epoch: 5 [74437/888800 8.38%] train loss: 4.004957736469805e-05 \n",
      "epoch: 5 [75548/888800 8.50%] train loss: 3.594815279939212e-05 \n",
      "epoch: 5 [76659/888800 8.62%] train loss: 5.0665406888583675e-05 \n",
      "epoch: 5 [77770/888800 8.75%] train loss: 3.878304414683953e-05 \n",
      "epoch: 5 [78881/888800 8.88%] train loss: 4.540595909929834e-05 \n",
      "epoch: 5 [79992/888800 9.00%] train loss: 3.312031185487285e-05 \n",
      "epoch: 5 [81103/888800 9.12%] train loss: 4.34145076724235e-05 \n",
      "epoch: 5 [82214/888800 9.25%] train loss: 3.9541631849715486e-05 \n",
      "epoch: 5 [83325/888800 9.38%] train loss: 4.3145428207935765e-05 \n",
      "epoch: 5 [84436/888800 9.50%] train loss: 3.931769242626615e-05 \n",
      "epoch: 5 [85547/888800 9.62%] train loss: 4.053538941661827e-05 \n",
      "epoch: 5 [86658/888800 9.75%] train loss: 4.179088500677608e-05 \n",
      "epoch: 5 [87769/888800 9.88%] train loss: 3.61396414518822e-05 \n",
      "epoch: 5 [88880/888800 10.00%] train loss: 4.4690317736240104e-05 \n",
      "epoch: 5 [89991/888800 10.12%] train loss: 4.1094324842561036e-05 \n",
      "epoch: 5 [91102/888800 10.25%] train loss: 4.6826306061120704e-05 \n",
      "epoch: 5 [92213/888800 10.38%] train loss: 3.055194247281179e-05 \n",
      "epoch: 5 [93324/888800 10.50%] train loss: 4.259734851075336e-05 \n",
      "epoch: 5 [94435/888800 10.62%] train loss: 4.442437784746289e-05 \n",
      "epoch: 5 [95546/888800 10.75%] train loss: 4.343585897004232e-05 \n",
      "epoch: 5 [96657/888800 10.88%] train loss: 4.641931809601374e-05 \n",
      "epoch: 5 [97768/888800 11.00%] train loss: 4.45371370005887e-05 \n",
      "epoch: 5 [98879/888800 11.12%] train loss: 4.116495983907953e-05 \n",
      "epoch: 5 [99990/888800 11.25%] train loss: 3.5459492210065946e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [101101/888800 11.38%] train loss: 3.930689854314551e-05 \n",
      "epoch: 5 [102212/888800 11.50%] train loss: 3.565080260159448e-05 \n",
      "epoch: 5 [103323/888800 11.62%] train loss: 4.7671350330347195e-05 \n",
      "epoch: 5 [104434/888800 11.75%] train loss: 3.3627922675805166e-05 \n",
      "epoch: 5 [105545/888800 11.88%] train loss: 4.5396162022370845e-05 \n",
      "epoch: 5 [106656/888800 12.00%] train loss: 3.681717498693615e-05 \n",
      "epoch: 5 [107767/888800 12.12%] train loss: 4.161245306022465e-05 \n",
      "epoch: 5 [108878/888800 12.25%] train loss: 3.655716136563569e-05 \n",
      "epoch: 5 [109989/888800 12.38%] train loss: 3.417790503590368e-05 \n",
      "epoch: 5 [111100/888800 12.50%] train loss: 3.790703703998588e-05 \n",
      "epoch: 5 [112211/888800 12.62%] train loss: 4.547784192254767e-05 \n",
      "epoch: 5 [113322/888800 12.75%] train loss: 4.308525240048766e-05 \n",
      "epoch: 5 [114433/888800 12.88%] train loss: 4.332748721935786e-05 \n",
      "epoch: 5 [115544/888800 13.00%] train loss: 4.25208818342071e-05 \n",
      "epoch: 5 [116655/888800 13.12%] train loss: 3.855893010040745e-05 \n",
      "epoch: 5 [117766/888800 13.25%] train loss: 4.117082426091656e-05 \n",
      "epoch: 5 [118877/888800 13.38%] train loss: 4.059794810018502e-05 \n",
      "epoch: 5 [119988/888800 13.50%] train loss: 3.219593418180011e-05 \n",
      "epoch: 5 [121099/888800 13.62%] train loss: 3.392001963220537e-05 \n",
      "epoch: 5 [122210/888800 13.75%] train loss: 4.0671271563041955e-05 \n",
      "epoch: 5 [123321/888800 13.88%] train loss: 4.636636731447652e-05 \n",
      "epoch: 5 [124432/888800 14.00%] train loss: 3.86501124012284e-05 \n",
      "epoch: 5 [125543/888800 14.12%] train loss: 4.204449578537606e-05 \n",
      "epoch: 5 [126654/888800 14.25%] train loss: 4.19661846535746e-05 \n",
      "epoch: 5 [127765/888800 14.38%] train loss: 3.9783921238267794e-05 \n",
      "epoch: 5 [128876/888800 14.50%] train loss: 3.673528044600971e-05 \n",
      "epoch: 5 [129987/888800 14.62%] train loss: 3.5886765545001253e-05 \n",
      "epoch: 5 [131098/888800 14.75%] train loss: 4.3951746192760766e-05 \n",
      "epoch: 5 [132209/888800 14.88%] train loss: 4.1605857404647395e-05 \n",
      "epoch: 5 [133320/888800 15.00%] train loss: 4.765771154779941e-05 \n",
      "epoch: 5 [134431/888800 15.12%] train loss: 3.785818989854306e-05 \n",
      "epoch: 5 [135542/888800 15.25%] train loss: 4.3267729779472575e-05 \n",
      "epoch: 5 [136653/888800 15.38%] train loss: 4.293079109629616e-05 \n",
      "epoch: 5 [137764/888800 15.50%] train loss: 3.9913051296025515e-05 \n",
      "epoch: 5 [138875/888800 15.62%] train loss: 3.46624365192838e-05 \n",
      "epoch: 5 [139986/888800 15.75%] train loss: 3.6438759707380086e-05 \n",
      "epoch: 5 [141097/888800 15.88%] train loss: 4.8165569751290604e-05 \n",
      "epoch: 5 [142208/888800 16.00%] train loss: 3.525886859279126e-05 \n",
      "epoch: 5 [143319/888800 16.12%] train loss: 3.3810982131399214e-05 \n",
      "epoch: 5 [144430/888800 16.25%] train loss: 3.61332822649274e-05 \n",
      "epoch: 5 [145541/888800 16.38%] train loss: 3.368270699866116e-05 \n",
      "epoch: 5 [146652/888800 16.50%] train loss: 3.0166032956913114e-05 \n",
      "epoch: 5 [147763/888800 16.62%] train loss: 4.2090920032933354e-05 \n",
      "epoch: 5 [148874/888800 16.75%] train loss: 4.626485315384343e-05 \n",
      "epoch: 5 [149985/888800 16.88%] train loss: 3.979945176979527e-05 \n",
      "epoch: 5 [151096/888800 17.00%] train loss: 4.111228554393165e-05 \n",
      "epoch: 5 [152207/888800 17.12%] train loss: 4.060854917042889e-05 \n",
      "epoch: 5 [153318/888800 17.25%] train loss: 3.848478809231892e-05 \n",
      "epoch: 5 [154429/888800 17.38%] train loss: 4.848862954531796e-05 \n",
      "epoch: 5 [155540/888800 17.50%] train loss: 3.629510320024565e-05 \n",
      "epoch: 5 [156651/888800 17.62%] train loss: 4.8108904593391344e-05 \n",
      "epoch: 5 [157762/888800 17.75%] train loss: 2.9754748538834974e-05 \n",
      "epoch: 5 [158873/888800 17.88%] train loss: 3.867518171318807e-05 \n",
      "epoch: 5 [159984/888800 18.00%] train loss: 3.9718048356007785e-05 \n",
      "epoch: 5 [161095/888800 18.12%] train loss: 3.767106318264268e-05 \n",
      "epoch: 5 [162206/888800 18.25%] train loss: 3.809532427112572e-05 \n",
      "epoch: 5 [163317/888800 18.38%] train loss: 3.23530039167963e-05 \n",
      "epoch: 5 [164428/888800 18.50%] train loss: 3.6406101571628824e-05 \n",
      "epoch: 5 [165539/888800 18.62%] train loss: 3.737485531019047e-05 \n",
      "epoch: 5 [166650/888800 18.75%] train loss: 3.8347123336279765e-05 \n",
      "epoch: 5 [167761/888800 18.88%] train loss: 3.7761165003757924e-05 \n",
      "epoch: 5 [168872/888800 19.00%] train loss: 4.090722723049112e-05 \n",
      "epoch: 5 [169983/888800 19.12%] train loss: 4.277396510588005e-05 \n",
      "epoch: 5 [171094/888800 19.25%] train loss: 4.0364637243328616e-05 \n",
      "epoch: 5 [172205/888800 19.38%] train loss: 3.945241405745037e-05 \n",
      "epoch: 5 [173316/888800 19.50%] train loss: 3.8278547435766086e-05 \n",
      "epoch: 5 [174427/888800 19.62%] train loss: 3.682749593281187e-05 \n",
      "epoch: 5 [175538/888800 19.75%] train loss: 4.035092570120469e-05 \n",
      "epoch: 5 [176649/888800 19.88%] train loss: 5.1291233830852434e-05 \n",
      "epoch: 5 [177760/888800 20.00%] train loss: 4.280131179257296e-05 \n",
      "epoch: 5 [178871/888800 20.12%] train loss: 4.235659434925765e-05 \n",
      "epoch: 5 [179982/888800 20.25%] train loss: 4.1749612137209624e-05 \n",
      "epoch: 5 [181093/888800 20.38%] train loss: 4.0930110117187724e-05 \n",
      "epoch: 5 [182204/888800 20.50%] train loss: 4.1174022044287995e-05 \n",
      "epoch: 5 [183315/888800 20.62%] train loss: 3.917133653885685e-05 \n",
      "epoch: 5 [184426/888800 20.75%] train loss: 3.8293834222713485e-05 \n",
      "epoch: 5 [185537/888800 20.88%] train loss: 4.304739195504226e-05 \n",
      "epoch: 5 [186648/888800 21.00%] train loss: 3.8605223380727693e-05 \n",
      "epoch: 5 [187759/888800 21.12%] train loss: 3.14742028422188e-05 \n",
      "epoch: 5 [188870/888800 21.25%] train loss: 4.3452586396597326e-05 \n",
      "epoch: 5 [189981/888800 21.38%] train loss: 3.685690899146721e-05 \n",
      "epoch: 5 [191092/888800 21.50%] train loss: 3.873058449244127e-05 \n",
      "epoch: 5 [192203/888800 21.62%] train loss: 4.58415161119774e-05 \n",
      "epoch: 5 [193314/888800 21.75%] train loss: 3.948036101064645e-05 \n",
      "epoch: 5 [194425/888800 21.88%] train loss: 4.207367601338774e-05 \n",
      "epoch: 5 [195536/888800 22.00%] train loss: 4.247557444614358e-05 \n",
      "epoch: 5 [196647/888800 22.12%] train loss: 3.6674617149401456e-05 \n",
      "epoch: 5 [197758/888800 22.25%] train loss: 4.198740134597756e-05 \n",
      "epoch: 5 [198869/888800 22.38%] train loss: 4.802287003258243e-05 \n",
      "epoch: 5 [199980/888800 22.50%] train loss: 3.1386636692332104e-05 \n",
      "epoch: 5 [201091/888800 22.62%] train loss: 4.307500057620928e-05 \n",
      "epoch: 5 [202202/888800 22.75%] train loss: 3.833899972960353e-05 \n",
      "epoch: 5 [203313/888800 22.88%] train loss: 3.810107591561973e-05 \n",
      "epoch: 5 [204424/888800 23.00%] train loss: 4.445993545232341e-05 \n",
      "epoch: 5 [205535/888800 23.12%] train loss: 4.3622734665405005e-05 \n",
      "epoch: 5 [206646/888800 23.25%] train loss: 4.257508408045396e-05 \n",
      "epoch: 5 [207757/888800 23.38%] train loss: 3.886704507749528e-05 \n",
      "epoch: 5 [208868/888800 23.50%] train loss: 4.879693369730376e-05 \n",
      "epoch: 5 [209979/888800 23.62%] train loss: 3.359578113304451e-05 \n",
      "epoch: 5 [211090/888800 23.75%] train loss: 4.2333555029472336e-05 \n",
      "epoch: 5 [212201/888800 23.88%] train loss: 3.7239249650156125e-05 \n",
      "epoch: 5 [213312/888800 24.00%] train loss: 3.450062285992317e-05 \n",
      "epoch: 5 [214423/888800 24.12%] train loss: 3.114973151241429e-05 \n",
      "epoch: 5 [215534/888800 24.25%] train loss: 5.0596096116350964e-05 \n",
      "epoch: 5 [216645/888800 24.38%] train loss: 3.7537265598075464e-05 \n",
      "epoch: 5 [217756/888800 24.50%] train loss: 3.5979432141175494e-05 \n",
      "epoch: 5 [218867/888800 24.62%] train loss: 4.427228486747481e-05 \n",
      "epoch: 5 [219978/888800 24.75%] train loss: 3.8751702959416434e-05 \n",
      "epoch: 5 [221089/888800 24.88%] train loss: 3.623450538725592e-05 \n",
      "epoch: 5 [222200/888800 25.00%] train loss: 4.3346299207769334e-05 \n",
      "epoch: 5 [223311/888800 25.12%] train loss: 4.170749889453873e-05 \n",
      "epoch: 5 [224422/888800 25.25%] train loss: 3.792806455749087e-05 \n",
      "epoch: 5 [225533/888800 25.38%] train loss: 3.6107296182308346e-05 \n",
      "epoch: 5 [226644/888800 25.50%] train loss: 3.791737253777683e-05 \n",
      "epoch: 5 [227755/888800 25.62%] train loss: 4.1778494050959125e-05 \n",
      "epoch: 5 [228866/888800 25.75%] train loss: 4.6048844524193555e-05 \n",
      "epoch: 5 [229977/888800 25.88%] train loss: 3.4764390875352547e-05 \n",
      "epoch: 5 [231088/888800 26.00%] train loss: 3.838696648017503e-05 \n",
      "epoch: 5 [232199/888800 26.12%] train loss: 3.673390892799944e-05 \n",
      "epoch: 5 [233310/888800 26.25%] train loss: 4.1361279727425426e-05 \n",
      "epoch: 5 [234421/888800 26.38%] train loss: 3.20522922265809e-05 \n",
      "epoch: 5 [235532/888800 26.50%] train loss: 3.942092735087499e-05 \n",
      "epoch: 5 [236643/888800 26.62%] train loss: 4.573088517645374e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [237754/888800 26.75%] train loss: 3.927951547666453e-05 \n",
      "epoch: 5 [238865/888800 26.88%] train loss: 3.6509463825495914e-05 \n",
      "epoch: 5 [239976/888800 27.00%] train loss: 4.20106589444913e-05 \n",
      "epoch: 5 [241087/888800 27.12%] train loss: 3.639133137767203e-05 \n",
      "epoch: 5 [242198/888800 27.25%] train loss: 4.098051431355998e-05 \n",
      "epoch: 5 [243309/888800 27.38%] train loss: 3.984556678915396e-05 \n",
      "epoch: 5 [244420/888800 27.50%] train loss: 3.241478043491952e-05 \n",
      "epoch: 5 [245531/888800 27.62%] train loss: 3.913039108738303e-05 \n",
      "epoch: 5 [246642/888800 27.75%] train loss: 3.330802428536117e-05 \n",
      "epoch: 5 [247753/888800 27.88%] train loss: 4.0927607187768444e-05 \n",
      "epoch: 5 [248864/888800 28.00%] train loss: 4.083019666722976e-05 \n",
      "epoch: 5 [249975/888800 28.12%] train loss: 4.220228947815485e-05 \n",
      "epoch: 5 [251086/888800 28.25%] train loss: 3.4238277294207364e-05 \n",
      "epoch: 5 [252197/888800 28.38%] train loss: 4.432878995430656e-05 \n",
      "epoch: 5 [253308/888800 28.50%] train loss: 4.033190634800121e-05 \n",
      "epoch: 5 [254419/888800 28.62%] train loss: 3.68247419828549e-05 \n",
      "epoch: 5 [255530/888800 28.75%] train loss: 3.740946704056114e-05 \n",
      "epoch: 5 [256641/888800 28.88%] train loss: 4.0896335121942684e-05 \n",
      "epoch: 5 [257752/888800 29.00%] train loss: 4.390853428049013e-05 \n",
      "epoch: 5 [258863/888800 29.12%] train loss: 3.9186477806651965e-05 \n",
      "epoch: 5 [259974/888800 29.25%] train loss: 3.881577868014574e-05 \n",
      "epoch: 5 [261085/888800 29.38%] train loss: 4.671188071370125e-05 \n",
      "epoch: 5 [262196/888800 29.50%] train loss: 3.96688083128538e-05 \n",
      "epoch: 5 [263307/888800 29.62%] train loss: 3.837787880911492e-05 \n",
      "epoch: 5 [264418/888800 29.75%] train loss: 3.988489697803743e-05 \n",
      "epoch: 5 [265529/888800 29.88%] train loss: 3.250539521104656e-05 \n",
      "epoch: 5 [266640/888800 30.00%] train loss: 3.602414653869346e-05 \n",
      "epoch: 5 [267751/888800 30.12%] train loss: 4.056226316606626e-05 \n",
      "epoch: 5 [268862/888800 30.25%] train loss: 3.209915303159505e-05 \n",
      "epoch: 5 [269973/888800 30.38%] train loss: 4.050225834362209e-05 \n",
      "epoch: 5 [271084/888800 30.50%] train loss: 4.24435711465776e-05 \n",
      "epoch: 5 [272195/888800 30.62%] train loss: 4.0452112443745136e-05 \n",
      "epoch: 5 [273306/888800 30.75%] train loss: 4.031551361549646e-05 \n",
      "epoch: 5 [274417/888800 30.88%] train loss: 4.0994491428136826e-05 \n",
      "epoch: 5 [275528/888800 31.00%] train loss: 3.789256152231246e-05 \n",
      "epoch: 5 [276639/888800 31.12%] train loss: 3.56023374479264e-05 \n",
      "epoch: 5 [277750/888800 31.25%] train loss: 3.93805094063282e-05 \n",
      "epoch: 5 [278861/888800 31.38%] train loss: 3.769580143853091e-05 \n",
      "epoch: 5 [279972/888800 31.50%] train loss: 4.4389398681232706e-05 \n",
      "epoch: 5 [281083/888800 31.62%] train loss: 4.228647958370857e-05 \n",
      "epoch: 5 [282194/888800 31.75%] train loss: 4.062029256601818e-05 \n",
      "epoch: 5 [283305/888800 31.88%] train loss: 4.009770418633707e-05 \n",
      "epoch: 5 [284416/888800 32.00%] train loss: 4.266534961061552e-05 \n",
      "epoch: 5 [285527/888800 32.12%] train loss: 4.10974862461444e-05 \n",
      "epoch: 5 [286638/888800 32.25%] train loss: 4.073395757586695e-05 \n",
      "epoch: 5 [287749/888800 32.38%] train loss: 3.869706051773392e-05 \n",
      "epoch: 5 [288860/888800 32.50%] train loss: 3.5972323530586436e-05 \n",
      "epoch: 5 [289971/888800 32.62%] train loss: 3.7858022551517934e-05 \n",
      "epoch: 5 [291082/888800 32.75%] train loss: 2.7062673325417563e-05 \n",
      "epoch: 5 [292193/888800 32.88%] train loss: 3.9151025703176856e-05 \n",
      "epoch: 5 [293304/888800 33.00%] train loss: 3.955282591050491e-05 \n",
      "epoch: 5 [294415/888800 33.12%] train loss: 3.87099789804779e-05 \n",
      "epoch: 5 [295526/888800 33.25%] train loss: 3.7434252590173855e-05 \n",
      "epoch: 5 [296637/888800 33.38%] train loss: 3.351357736391947e-05 \n",
      "epoch: 5 [297748/888800 33.50%] train loss: 3.7431349483085796e-05 \n",
      "epoch: 5 [298859/888800 33.62%] train loss: 3.277081123087555e-05 \n",
      "epoch: 5 [299970/888800 33.75%] train loss: 3.8917645724723116e-05 \n",
      "epoch: 5 [301081/888800 33.88%] train loss: 3.6778666981263086e-05 \n",
      "epoch: 5 [302192/888800 34.00%] train loss: 3.694411861943081e-05 \n",
      "epoch: 5 [303303/888800 34.12%] train loss: 3.022961573151406e-05 \n",
      "epoch: 5 [304414/888800 34.25%] train loss: 4.308190545998514e-05 \n",
      "epoch: 5 [305525/888800 34.38%] train loss: 4.1896702896337956e-05 \n",
      "epoch: 5 [306636/888800 34.50%] train loss: 3.452808959991671e-05 \n",
      "epoch: 5 [307747/888800 34.62%] train loss: 4.19387906731572e-05 \n",
      "epoch: 5 [308858/888800 34.75%] train loss: 4.6331460907822475e-05 \n",
      "epoch: 5 [309969/888800 34.88%] train loss: 3.6259094486013055e-05 \n",
      "epoch: 5 [311080/888800 35.00%] train loss: 3.786885645240545e-05 \n",
      "epoch: 5 [312191/888800 35.12%] train loss: 4.4285010517342016e-05 \n",
      "epoch: 5 [313302/888800 35.25%] train loss: 4.1588795284042135e-05 \n",
      "epoch: 5 [314413/888800 35.38%] train loss: 3.816729804384522e-05 \n",
      "epoch: 5 [315524/888800 35.50%] train loss: 3.647895937319845e-05 \n",
      "epoch: 5 [316635/888800 35.62%] train loss: 3.7200396036496386e-05 \n",
      "epoch: 5 [317746/888800 35.75%] train loss: 3.801969432970509e-05 \n",
      "epoch: 5 [318857/888800 35.88%] train loss: 3.85563398594968e-05 \n",
      "epoch: 5 [319968/888800 36.00%] train loss: 3.812266368186101e-05 \n",
      "epoch: 5 [321079/888800 36.12%] train loss: 4.187968443147838e-05 \n",
      "epoch: 5 [322190/888800 36.25%] train loss: 3.4072498237947e-05 \n",
      "epoch: 5 [323301/888800 36.38%] train loss: 4.199653631076217e-05 \n",
      "epoch: 5 [324412/888800 36.50%] train loss: 4.1862855141516775e-05 \n",
      "epoch: 5 [325523/888800 36.62%] train loss: 4.102514503756538e-05 \n",
      "epoch: 5 [326634/888800 36.75%] train loss: 3.868914791382849e-05 \n",
      "epoch: 5 [327745/888800 36.88%] train loss: 3.232623203075491e-05 \n",
      "epoch: 5 [328856/888800 37.00%] train loss: 4.002271452918649e-05 \n",
      "epoch: 5 [329967/888800 37.12%] train loss: 3.911610838258639e-05 \n",
      "epoch: 5 [331078/888800 37.25%] train loss: 3.8335190765792504e-05 \n",
      "epoch: 5 [332189/888800 37.38%] train loss: 3.7101464840816334e-05 \n",
      "epoch: 5 [333300/888800 37.50%] train loss: 3.968122837250121e-05 \n",
      "epoch: 5 [334411/888800 37.62%] train loss: 3.763425047509372e-05 \n",
      "epoch: 5 [335522/888800 37.75%] train loss: 3.941437171306461e-05 \n",
      "epoch: 5 [336633/888800 37.88%] train loss: 5.075009539723396e-05 \n",
      "epoch: 5 [337744/888800 38.00%] train loss: 3.575314985937439e-05 \n",
      "epoch: 5 [338855/888800 38.12%] train loss: 4.0861646994017065e-05 \n",
      "epoch: 5 [339966/888800 38.25%] train loss: 3.729423406184651e-05 \n",
      "epoch: 5 [341077/888800 38.38%] train loss: 3.9109858334995806e-05 \n",
      "epoch: 5 [342188/888800 38.50%] train loss: 3.849405766231939e-05 \n",
      "epoch: 5 [343299/888800 38.62%] train loss: 4.1788625821936876e-05 \n",
      "epoch: 5 [344410/888800 38.75%] train loss: 4.691085632657632e-05 \n",
      "epoch: 5 [345521/888800 38.88%] train loss: 3.741154432645999e-05 \n",
      "epoch: 5 [346632/888800 39.00%] train loss: 3.8871174183441326e-05 \n",
      "epoch: 5 [347743/888800 39.12%] train loss: 3.600804848247208e-05 \n",
      "epoch: 5 [348854/888800 39.25%] train loss: 3.6675930459750816e-05 \n",
      "epoch: 5 [349965/888800 39.38%] train loss: 4.47973252448719e-05 \n",
      "epoch: 5 [351076/888800 39.50%] train loss: 4.241831993567757e-05 \n",
      "epoch: 5 [352187/888800 39.62%] train loss: 3.486524656182155e-05 \n",
      "epoch: 5 [353298/888800 39.75%] train loss: 4.256252577761188e-05 \n",
      "epoch: 5 [354409/888800 39.88%] train loss: 3.0731163860764354e-05 \n",
      "epoch: 5 [355520/888800 40.00%] train loss: 3.9513401134172454e-05 \n",
      "epoch: 5 [356631/888800 40.12%] train loss: 3.741419277503155e-05 \n",
      "epoch: 5 [357742/888800 40.25%] train loss: 3.860182914650068e-05 \n",
      "epoch: 5 [358853/888800 40.38%] train loss: 4.1571183828637004e-05 \n",
      "epoch: 5 [359964/888800 40.50%] train loss: 3.745475260075182e-05 \n",
      "epoch: 5 [361075/888800 40.62%] train loss: 4.0191738662542775e-05 \n",
      "epoch: 5 [362186/888800 40.75%] train loss: 3.859446587739512e-05 \n",
      "epoch: 5 [363297/888800 40.88%] train loss: 3.63338585884776e-05 \n",
      "epoch: 5 [364408/888800 41.00%] train loss: 3.474737604847178e-05 \n",
      "epoch: 5 [365519/888800 41.12%] train loss: 3.3445430744905025e-05 \n",
      "epoch: 5 [366630/888800 41.25%] train loss: 3.5630502679850906e-05 \n",
      "epoch: 5 [367741/888800 41.38%] train loss: 3.774628567043692e-05 \n",
      "epoch: 5 [368852/888800 41.50%] train loss: 4.505974720814265e-05 \n",
      "epoch: 5 [369963/888800 41.62%] train loss: 3.955473948735744e-05 \n",
      "epoch: 5 [371074/888800 41.75%] train loss: 3.6424014979274943e-05 \n",
      "epoch: 5 [372185/888800 41.88%] train loss: 4.049212293466553e-05 \n",
      "epoch: 5 [373296/888800 42.00%] train loss: 3.684563125716522e-05 \n",
      "epoch: 5 [374407/888800 42.12%] train loss: 4.532345337793231e-05 \n",
      "epoch: 5 [375518/888800 42.25%] train loss: 3.625089084380306e-05 \n",
      "epoch: 5 [376629/888800 42.38%] train loss: 4.041888314532116e-05 \n",
      "epoch: 5 [377740/888800 42.50%] train loss: 3.498335354379378e-05 \n",
      "epoch: 5 [378851/888800 42.62%] train loss: 3.8148253224790096e-05 \n",
      "epoch: 5 [379962/888800 42.75%] train loss: 4.31808439316228e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [381073/888800 42.88%] train loss: 3.514692434691824e-05 \n",
      "epoch: 5 [382184/888800 43.00%] train loss: 3.2227751944446936e-05 \n",
      "epoch: 5 [383295/888800 43.12%] train loss: 4.246844764566049e-05 \n",
      "epoch: 5 [384406/888800 43.25%] train loss: 3.175622259732336e-05 \n",
      "epoch: 5 [385517/888800 43.38%] train loss: 4.4399796024663374e-05 \n",
      "epoch: 5 [386628/888800 43.50%] train loss: 4.107468339498155e-05 \n",
      "epoch: 5 [387739/888800 43.62%] train loss: 3.2985284633468837e-05 \n",
      "epoch: 5 [388850/888800 43.75%] train loss: 3.6672267015092075e-05 \n",
      "epoch: 5 [389961/888800 43.88%] train loss: 4.1782433982007205e-05 \n",
      "epoch: 5 [391072/888800 44.00%] train loss: 4.679652920458466e-05 \n",
      "epoch: 5 [392183/888800 44.12%] train loss: 3.459537765593268e-05 \n",
      "epoch: 5 [393294/888800 44.25%] train loss: 4.05912687710952e-05 \n",
      "epoch: 5 [394405/888800 44.38%] train loss: 4.3865820771316066e-05 \n",
      "epoch: 5 [395516/888800 44.50%] train loss: 3.637840200099163e-05 \n",
      "epoch: 5 [396627/888800 44.62%] train loss: 3.8359270547516644e-05 \n",
      "epoch: 5 [397738/888800 44.75%] train loss: 3.940870738006197e-05 \n",
      "epoch: 5 [398849/888800 44.88%] train loss: 4.052345684613101e-05 \n",
      "epoch: 5 [399960/888800 45.00%] train loss: 3.9609945815755054e-05 \n",
      "epoch: 5 [401071/888800 45.12%] train loss: 4.260475907358341e-05 \n",
      "epoch: 5 [402182/888800 45.25%] train loss: 4.070491195307113e-05 \n",
      "epoch: 5 [403293/888800 45.38%] train loss: 4.280032226233743e-05 \n",
      "epoch: 5 [404404/888800 45.50%] train loss: 3.6897265090374276e-05 \n",
      "epoch: 5 [405515/888800 45.62%] train loss: 4.631647243513726e-05 \n",
      "epoch: 5 [406626/888800 45.75%] train loss: 3.88683911296539e-05 \n",
      "epoch: 5 [407737/888800 45.88%] train loss: 3.9166501665022224e-05 \n",
      "epoch: 5 [408848/888800 46.00%] train loss: 3.7683133996324614e-05 \n",
      "epoch: 5 [409959/888800 46.12%] train loss: 4.041069041704759e-05 \n",
      "epoch: 5 [411070/888800 46.25%] train loss: 4.195805740891956e-05 \n",
      "epoch: 5 [412181/888800 46.38%] train loss: 4.107011409359984e-05 \n",
      "epoch: 5 [413292/888800 46.50%] train loss: 4.3450021621538326e-05 \n",
      "epoch: 5 [414403/888800 46.62%] train loss: 4.000482294941321e-05 \n",
      "epoch: 5 [415514/888800 46.75%] train loss: 3.6649649700848386e-05 \n",
      "epoch: 5 [416625/888800 46.88%] train loss: 3.922297401004471e-05 \n",
      "epoch: 5 [417736/888800 47.00%] train loss: 3.4960983612108976e-05 \n",
      "epoch: 5 [418847/888800 47.12%] train loss: 3.8714537367923185e-05 \n",
      "epoch: 5 [419958/888800 47.25%] train loss: 3.447273775236681e-05 \n",
      "epoch: 5 [421069/888800 47.38%] train loss: 3.898898285115138e-05 \n",
      "epoch: 5 [422180/888800 47.50%] train loss: 4.435360096977092e-05 \n",
      "epoch: 5 [423291/888800 47.62%] train loss: 4.281117799109779e-05 \n",
      "epoch: 5 [424402/888800 47.75%] train loss: 3.2935739000095055e-05 \n",
      "epoch: 5 [425513/888800 47.88%] train loss: 2.906867302954197e-05 \n",
      "epoch: 5 [426624/888800 48.00%] train loss: 4.294247628422454e-05 \n",
      "epoch: 5 [427735/888800 48.12%] train loss: 4.368750160210766e-05 \n",
      "epoch: 5 [428846/888800 48.25%] train loss: 3.924232805729844e-05 \n",
      "epoch: 5 [429957/888800 48.38%] train loss: 3.487780850264244e-05 \n",
      "epoch: 5 [431068/888800 48.50%] train loss: 4.4341853936202824e-05 \n",
      "epoch: 5 [432179/888800 48.62%] train loss: 3.884582474711351e-05 \n",
      "epoch: 5 [433290/888800 48.75%] train loss: 4.2281193600501865e-05 \n",
      "epoch: 5 [434401/888800 48.88%] train loss: 4.217195964884013e-05 \n",
      "epoch: 5 [435512/888800 49.00%] train loss: 3.184911474818364e-05 \n",
      "epoch: 5 [436623/888800 49.12%] train loss: 3.5562767152441666e-05 \n",
      "epoch: 5 [437734/888800 49.25%] train loss: 3.9057285903254524e-05 \n",
      "epoch: 5 [438845/888800 49.38%] train loss: 4.2683419451350346e-05 \n",
      "epoch: 5 [439956/888800 49.50%] train loss: 3.885549813276157e-05 \n",
      "epoch: 5 [441067/888800 49.62%] train loss: 3.390821802895516e-05 \n",
      "epoch: 5 [442178/888800 49.75%] train loss: 4.138875374337658e-05 \n",
      "epoch: 5 [443289/888800 49.88%] train loss: 4.246315802447498e-05 \n",
      "epoch: 5 [444400/888800 50.00%] train loss: 3.7884277844568714e-05 \n",
      "epoch: 5 [445511/888800 50.12%] train loss: 4.0345035813516006e-05 \n",
      "epoch: 5 [446622/888800 50.25%] train loss: 3.576618109946139e-05 \n",
      "epoch: 5 [447733/888800 50.38%] train loss: 3.6007837479701266e-05 \n",
      "epoch: 5 [448844/888800 50.50%] train loss: 3.7411788071040064e-05 \n",
      "epoch: 5 [449955/888800 50.62%] train loss: 3.483882755972445e-05 \n",
      "epoch: 5 [451066/888800 50.75%] train loss: 3.866028055199422e-05 \n",
      "epoch: 5 [452177/888800 50.88%] train loss: 4.0055190765997395e-05 \n",
      "epoch: 5 [453288/888800 51.00%] train loss: 4.4720149162458256e-05 \n",
      "epoch: 5 [454399/888800 51.12%] train loss: 3.3318112400593236e-05 \n",
      "epoch: 5 [455510/888800 51.25%] train loss: 3.397761611267924e-05 \n",
      "epoch: 5 [456621/888800 51.38%] train loss: 3.8907888665562496e-05 \n",
      "epoch: 5 [457732/888800 51.50%] train loss: 4.0550610719947144e-05 \n",
      "epoch: 5 [458843/888800 51.62%] train loss: 4.01659999624826e-05 \n",
      "epoch: 5 [459954/888800 51.75%] train loss: 4.175178401055746e-05 \n",
      "epoch: 5 [461065/888800 51.88%] train loss: 3.588897016015835e-05 \n",
      "epoch: 5 [462176/888800 52.00%] train loss: 3.5187284083804116e-05 \n",
      "epoch: 5 [463287/888800 52.12%] train loss: 3.61709862772841e-05 \n",
      "epoch: 5 [464398/888800 52.25%] train loss: 3.993557402282022e-05 \n",
      "epoch: 5 [465509/888800 52.38%] train loss: 4.399813406052999e-05 \n",
      "epoch: 5 [466620/888800 52.50%] train loss: 3.8885384128661826e-05 \n",
      "epoch: 5 [467731/888800 52.62%] train loss: 3.7681944377254695e-05 \n",
      "epoch: 5 [468842/888800 52.75%] train loss: 4.1377406887477264e-05 \n",
      "epoch: 5 [469953/888800 52.88%] train loss: 3.862392986775376e-05 \n",
      "epoch: 5 [471064/888800 53.00%] train loss: 5.004888589610346e-05 \n",
      "epoch: 5 [472175/888800 53.12%] train loss: 3.744994319276884e-05 \n",
      "epoch: 5 [473286/888800 53.25%] train loss: 3.3832620829343796e-05 \n",
      "epoch: 5 [474397/888800 53.38%] train loss: 3.614124216255732e-05 \n",
      "epoch: 5 [475508/888800 53.50%] train loss: 3.639763599494472e-05 \n",
      "epoch: 5 [476619/888800 53.62%] train loss: 2.9999424441484734e-05 \n",
      "epoch: 5 [477730/888800 53.75%] train loss: 3.8724181649740785e-05 \n",
      "epoch: 5 [478841/888800 53.88%] train loss: 3.336516601848416e-05 \n",
      "epoch: 5 [479952/888800 54.00%] train loss: 3.484237095108256e-05 \n",
      "epoch: 5 [481063/888800 54.12%] train loss: 3.28239293594379e-05 \n",
      "epoch: 5 [482174/888800 54.25%] train loss: 3.750396354007535e-05 \n",
      "epoch: 5 [483285/888800 54.38%] train loss: 3.776989251491614e-05 \n",
      "epoch: 5 [484396/888800 54.50%] train loss: 4.184359931969084e-05 \n",
      "epoch: 5 [485507/888800 54.62%] train loss: 3.428301715757698e-05 \n",
      "epoch: 5 [486618/888800 54.75%] train loss: 4.1636456444393843e-05 \n",
      "epoch: 5 [487729/888800 54.88%] train loss: 4.5104265154805034e-05 \n",
      "epoch: 5 [488840/888800 55.00%] train loss: 4.3188745621591806e-05 \n",
      "epoch: 5 [489951/888800 55.12%] train loss: 3.64575425919611e-05 \n",
      "epoch: 5 [491062/888800 55.25%] train loss: 3.4372809750493616e-05 \n",
      "epoch: 5 [492173/888800 55.38%] train loss: 3.5633423976833e-05 \n",
      "epoch: 5 [493284/888800 55.50%] train loss: 3.429170465096831e-05 \n",
      "epoch: 5 [494395/888800 55.62%] train loss: 3.71348942280747e-05 \n",
      "epoch: 5 [495506/888800 55.75%] train loss: 3.453735916991718e-05 \n",
      "epoch: 5 [496617/888800 55.88%] train loss: 4.236210588715039e-05 \n",
      "epoch: 5 [497728/888800 56.00%] train loss: 3.526556974975392e-05 \n",
      "epoch: 5 [498839/888800 56.12%] train loss: 3.764323264476843e-05 \n",
      "epoch: 5 [499950/888800 56.25%] train loss: 4.6984561777208e-05 \n",
      "epoch: 5 [501061/888800 56.38%] train loss: 4.407495362102054e-05 \n",
      "epoch: 5 [502172/888800 56.50%] train loss: 3.1293366191675887e-05 \n",
      "epoch: 5 [503283/888800 56.62%] train loss: 3.920798553735949e-05 \n",
      "epoch: 5 [504394/888800 56.75%] train loss: 4.2354346078354865e-05 \n",
      "epoch: 5 [505505/888800 56.88%] train loss: 4.384687417768873e-05 \n",
      "epoch: 5 [506616/888800 57.00%] train loss: 4.260836067260243e-05 \n",
      "epoch: 5 [507727/888800 57.12%] train loss: 4.6724082494620234e-05 \n",
      "epoch: 5 [508838/888800 57.25%] train loss: 3.516229844535701e-05 \n",
      "epoch: 5 [509949/888800 57.38%] train loss: 4.187471131444909e-05 \n",
      "epoch: 5 [511060/888800 57.50%] train loss: 4.71208622911945e-05 \n",
      "epoch: 5 [512171/888800 57.62%] train loss: 3.527800436131656e-05 \n",
      "epoch: 5 [513282/888800 57.75%] train loss: 3.718370135175064e-05 \n",
      "epoch: 5 [514393/888800 57.88%] train loss: 3.8777696317993104e-05 \n",
      "epoch: 5 [515504/888800 58.00%] train loss: 3.2114545319927856e-05 \n",
      "epoch: 5 [516615/888800 58.12%] train loss: 4.413537681102753e-05 \n",
      "epoch: 5 [517726/888800 58.25%] train loss: 3.2682983146514744e-05 \n",
      "epoch: 5 [518837/888800 58.38%] train loss: 3.526308137224987e-05 \n",
      "epoch: 5 [519948/888800 58.50%] train loss: 3.5142078559147194e-05 \n",
      "epoch: 5 [521059/888800 58.62%] train loss: 4.2049014155054465e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [522170/888800 58.75%] train loss: 4.047920083394274e-05 \n",
      "epoch: 5 [523281/888800 58.88%] train loss: 3.927314901375212e-05 \n",
      "epoch: 5 [524392/888800 59.00%] train loss: 3.896248381352052e-05 \n",
      "epoch: 5 [525503/888800 59.12%] train loss: 3.510161695885472e-05 \n",
      "epoch: 5 [526614/888800 59.25%] train loss: 3.410123463254422e-05 \n",
      "epoch: 5 [527725/888800 59.38%] train loss: 3.7770707422168925e-05 \n",
      "epoch: 5 [528836/888800 59.50%] train loss: 3.895747067872435e-05 \n",
      "epoch: 5 [529947/888800 59.62%] train loss: 4.204874494462274e-05 \n",
      "epoch: 5 [531058/888800 59.75%] train loss: 3.504922642605379e-05 \n",
      "epoch: 5 [532169/888800 59.88%] train loss: 3.559312244760804e-05 \n",
      "epoch: 5 [533280/888800 60.00%] train loss: 4.076290497323498e-05 \n",
      "epoch: 5 [534391/888800 60.12%] train loss: 3.284612103016116e-05 \n",
      "epoch: 5 [535502/888800 60.25%] train loss: 4.3481857574079186e-05 \n",
      "epoch: 5 [536613/888800 60.38%] train loss: 4.032509241369553e-05 \n",
      "epoch: 5 [537724/888800 60.50%] train loss: 3.7387846532510594e-05 \n",
      "epoch: 5 [538835/888800 60.62%] train loss: 4.102394086658023e-05 \n",
      "epoch: 5 [539946/888800 60.75%] train loss: 3.9358001231448725e-05 \n",
      "epoch: 5 [541057/888800 60.88%] train loss: 3.4775890526361763e-05 \n",
      "epoch: 5 [542168/888800 61.00%] train loss: 3.888129867846146e-05 \n",
      "epoch: 5 [543279/888800 61.12%] train loss: 4.779083974426612e-05 \n",
      "epoch: 5 [544390/888800 61.25%] train loss: 3.691585152409971e-05 \n",
      "epoch: 5 [545501/888800 61.38%] train loss: 3.827477848972194e-05 \n",
      "epoch: 5 [546612/888800 61.50%] train loss: 3.0418341339100152e-05 \n",
      "epoch: 5 [547723/888800 61.62%] train loss: 4.2376086639706045e-05 \n",
      "epoch: 5 [548834/888800 61.75%] train loss: 4.1266401240136474e-05 \n",
      "epoch: 5 [549945/888800 61.88%] train loss: 3.4448265068931505e-05 \n",
      "epoch: 5 [551056/888800 62.00%] train loss: 4.438578980625607e-05 \n",
      "epoch: 5 [552167/888800 62.12%] train loss: 3.2843945518834516e-05 \n",
      "epoch: 5 [553278/888800 62.25%] train loss: 3.922417090507224e-05 \n",
      "epoch: 5 [554389/888800 62.38%] train loss: 3.4903241612482816e-05 \n",
      "epoch: 5 [555500/888800 62.50%] train loss: 3.571056731743738e-05 \n",
      "epoch: 5 [556611/888800 62.62%] train loss: 3.976636435254477e-05 \n",
      "epoch: 5 [557722/888800 62.75%] train loss: 4.749760773847811e-05 \n",
      "epoch: 5 [558833/888800 62.88%] train loss: 3.243823448428884e-05 \n",
      "epoch: 5 [559944/888800 63.00%] train loss: 4.6373628720175475e-05 \n",
      "epoch: 5 [561055/888800 63.12%] train loss: 4.013956640847027e-05 \n",
      "epoch: 5 [562166/888800 63.25%] train loss: 3.921376992366277e-05 \n",
      "epoch: 5 [563277/888800 63.38%] train loss: 4.230336344335228e-05 \n",
      "epoch: 5 [564388/888800 63.50%] train loss: 3.76385978597682e-05 \n",
      "epoch: 5 [565499/888800 63.62%] train loss: 3.205686152796261e-05 \n",
      "epoch: 5 [566610/888800 63.75%] train loss: 3.730071330210194e-05 \n",
      "epoch: 5 [567721/888800 63.88%] train loss: 3.6050081689609215e-05 \n",
      "epoch: 5 [568832/888800 64.00%] train loss: 4.303128662286326e-05 \n",
      "epoch: 5 [569943/888800 64.12%] train loss: 3.706703500938602e-05 \n",
      "epoch: 5 [571054/888800 64.25%] train loss: 3.712208126671612e-05 \n",
      "epoch: 5 [572165/888800 64.38%] train loss: 3.887521961587481e-05 \n",
      "epoch: 5 [573276/888800 64.50%] train loss: 3.3714586606947705e-05 \n",
      "epoch: 5 [574387/888800 64.62%] train loss: 4.1820523620117456e-05 \n",
      "epoch: 5 [575498/888800 64.75%] train loss: 3.88977859984152e-05 \n",
      "epoch: 5 [576609/888800 64.88%] train loss: 3.656437183963135e-05 \n",
      "epoch: 5 [577720/888800 65.00%] train loss: 4.0742197597865015e-05 \n",
      "epoch: 5 [578831/888800 65.12%] train loss: 3.706616917042993e-05 \n",
      "epoch: 5 [579942/888800 65.25%] train loss: 3.7358888221206143e-05 \n",
      "epoch: 5 [581053/888800 65.38%] train loss: 4.0063110645860434e-05 \n",
      "epoch: 5 [582164/888800 65.50%] train loss: 3.375429514562711e-05 \n",
      "epoch: 5 [583275/888800 65.62%] train loss: 3.4828113712137565e-05 \n",
      "epoch: 5 [584386/888800 65.75%] train loss: 3.3398882806068286e-05 \n",
      "epoch: 5 [585497/888800 65.88%] train loss: 3.916905916412361e-05 \n",
      "epoch: 5 [586608/888800 66.00%] train loss: 4.247868855600245e-05 \n",
      "epoch: 5 [587719/888800 66.12%] train loss: 4.9573143769521266e-05 \n",
      "epoch: 5 [588830/888800 66.25%] train loss: 3.303693301859312e-05 \n",
      "epoch: 5 [589941/888800 66.38%] train loss: 3.819747144007124e-05 \n",
      "epoch: 5 [591052/888800 66.50%] train loss: 4.2177769500995055e-05 \n",
      "epoch: 5 [592163/888800 66.62%] train loss: 3.5387805837672204e-05 \n",
      "epoch: 5 [593274/888800 66.75%] train loss: 3.245208063162863e-05 \n",
      "epoch: 5 [594385/888800 66.88%] train loss: 3.2818126783240587e-05 \n",
      "epoch: 5 [595496/888800 67.00%] train loss: 3.893012399203144e-05 \n",
      "epoch: 5 [596607/888800 67.12%] train loss: 4.141065801377408e-05 \n",
      "epoch: 5 [597718/888800 67.25%] train loss: 2.6892268579103984e-05 \n",
      "epoch: 5 [598829/888800 67.38%] train loss: 3.348368045408279e-05 \n",
      "epoch: 5 [599940/888800 67.50%] train loss: 3.304057099740021e-05 \n",
      "epoch: 5 [601051/888800 67.62%] train loss: 4.088896093890071e-05 \n",
      "epoch: 5 [602162/888800 67.75%] train loss: 4.1487870475975797e-05 \n",
      "epoch: 5 [603273/888800 67.88%] train loss: 3.4915337892016396e-05 \n",
      "epoch: 5 [604384/888800 68.00%] train loss: 4.053448355989531e-05 \n",
      "epoch: 5 [605495/888800 68.12%] train loss: 3.424309034016915e-05 \n",
      "epoch: 5 [606606/888800 68.25%] train loss: 3.2890118745854124e-05 \n",
      "epoch: 5 [607717/888800 68.38%] train loss: 4.29230640293099e-05 \n",
      "epoch: 5 [608828/888800 68.50%] train loss: 3.560290497262031e-05 \n",
      "epoch: 5 [609939/888800 68.62%] train loss: 3.5270655644126236e-05 \n",
      "epoch: 5 [611050/888800 68.75%] train loss: 4.073481977684423e-05 \n",
      "epoch: 5 [612161/888800 68.88%] train loss: 4.1446117393206805e-05 \n",
      "epoch: 5 [613272/888800 69.00%] train loss: 3.3952706871787086e-05 \n",
      "epoch: 5 [614383/888800 69.12%] train loss: 3.890607331413776e-05 \n",
      "epoch: 5 [615494/888800 69.25%] train loss: 3.935741915483959e-05 \n",
      "epoch: 5 [616605/888800 69.38%] train loss: 3.0343688194989227e-05 \n",
      "epoch: 5 [617716/888800 69.50%] train loss: 4.184339923085645e-05 \n",
      "epoch: 5 [618827/888800 69.62%] train loss: 3.387289689271711e-05 \n",
      "epoch: 5 [619938/888800 69.75%] train loss: 4.004273796454072e-05 \n",
      "epoch: 5 [621049/888800 69.88%] train loss: 3.5100234526908025e-05 \n",
      "epoch: 5 [622160/888800 70.00%] train loss: 3.46291926689446e-05 \n",
      "epoch: 5 [623271/888800 70.12%] train loss: 3.814048250205815e-05 \n",
      "epoch: 5 [624382/888800 70.25%] train loss: 4.1625509766163304e-05 \n",
      "epoch: 5 [625493/888800 70.38%] train loss: 3.876057598972693e-05 \n",
      "epoch: 5 [626604/888800 70.50%] train loss: 3.905999619746581e-05 \n",
      "epoch: 5 [627715/888800 70.62%] train loss: 4.251967038726434e-05 \n",
      "epoch: 5 [628826/888800 70.75%] train loss: 3.5776494769379497e-05 \n",
      "epoch: 5 [629937/888800 70.88%] train loss: 3.597226896090433e-05 \n",
      "epoch: 5 [631048/888800 71.00%] train loss: 3.6262998037273064e-05 \n",
      "epoch: 5 [632159/888800 71.12%] train loss: 3.59329569619149e-05 \n",
      "epoch: 5 [633270/888800 71.25%] train loss: 3.093925624853e-05 \n",
      "epoch: 5 [634381/888800 71.38%] train loss: 3.1986281101126224e-05 \n",
      "epoch: 5 [635492/888800 71.50%] train loss: 3.956059299525805e-05 \n",
      "epoch: 5 [636603/888800 71.62%] train loss: 4.0268081647809595e-05 \n",
      "epoch: 5 [637714/888800 71.75%] train loss: 3.6235553125152364e-05 \n",
      "epoch: 5 [638825/888800 71.88%] train loss: 3.8881509681232274e-05 \n",
      "epoch: 5 [639936/888800 72.00%] train loss: 3.6093650123802945e-05 \n",
      "epoch: 5 [641047/888800 72.12%] train loss: 3.592437496990897e-05 \n",
      "epoch: 5 [642158/888800 72.25%] train loss: 3.931271203327924e-05 \n",
      "epoch: 5 [643269/888800 72.38%] train loss: 3.501754326862283e-05 \n",
      "epoch: 5 [644380/888800 72.50%] train loss: 3.7958081520628184e-05 \n",
      "epoch: 5 [645491/888800 72.62%] train loss: 3.3701664506224915e-05 \n",
      "epoch: 5 [646602/888800 72.75%] train loss: 3.4673365007620305e-05 \n",
      "epoch: 5 [647713/888800 72.88%] train loss: 3.7260164390318096e-05 \n",
      "epoch: 5 [648824/888800 73.00%] train loss: 3.178257975378074e-05 \n",
      "epoch: 5 [649935/888800 73.12%] train loss: 4.177741357125342e-05 \n",
      "epoch: 5 [651046/888800 73.25%] train loss: 3.710824603331275e-05 \n",
      "epoch: 5 [652157/888800 73.38%] train loss: 4.1147377487504855e-05 \n",
      "epoch: 5 [653268/888800 73.50%] train loss: 3.799806290771812e-05 \n",
      "epoch: 5 [654379/888800 73.62%] train loss: 3.5056105843978e-05 \n",
      "epoch: 5 [655490/888800 73.75%] train loss: 3.183613080182113e-05 \n",
      "epoch: 5 [656601/888800 73.88%] train loss: 3.29131908074487e-05 \n",
      "epoch: 5 [657712/888800 74.00%] train loss: 3.3956610423047096e-05 \n",
      "epoch: 5 [658823/888800 74.12%] train loss: 4.142800025874749e-05 \n",
      "epoch: 5 [659934/888800 74.25%] train loss: 3.822780490736477e-05 \n",
      "epoch: 5 [661045/888800 74.38%] train loss: 4.677045581047423e-05 \n",
      "epoch: 5 [662156/888800 74.50%] train loss: 3.770136027014814e-05 \n",
      "epoch: 5 [663267/888800 74.62%] train loss: 3.532939081196673e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [664378/888800 74.75%] train loss: 3.36332232109271e-05 \n",
      "epoch: 5 [665489/888800 74.88%] train loss: 4.058745616930537e-05 \n",
      "epoch: 5 [666600/888800 75.00%] train loss: 3.3090676879510283e-05 \n",
      "epoch: 5 [667711/888800 75.12%] train loss: 3.686155832838267e-05 \n",
      "epoch: 5 [668822/888800 75.25%] train loss: 3.506724169710651e-05 \n",
      "epoch: 5 [669933/888800 75.38%] train loss: 4.5501074055209756e-05 \n",
      "epoch: 5 [671044/888800 75.50%] train loss: 4.049570998176932e-05 \n",
      "epoch: 5 [672155/888800 75.62%] train loss: 4.2727464460767806e-05 \n",
      "epoch: 5 [673266/888800 75.75%] train loss: 3.901593663613312e-05 \n",
      "epoch: 5 [674377/888800 75.88%] train loss: 3.820626807282679e-05 \n",
      "epoch: 5 [675488/888800 76.00%] train loss: 3.2988889870466664e-05 \n",
      "epoch: 5 [676599/888800 76.12%] train loss: 3.521949838614091e-05 \n",
      "epoch: 5 [677710/888800 76.25%] train loss: 4.020376945845783e-05 \n",
      "epoch: 5 [678821/888800 76.38%] train loss: 4.4958160287933424e-05 \n",
      "epoch: 5 [679932/888800 76.50%] train loss: 3.8069021684350446e-05 \n",
      "epoch: 5 [681043/888800 76.62%] train loss: 4.0103299397742376e-05 \n",
      "epoch: 5 [682154/888800 76.75%] train loss: 3.983900751336478e-05 \n",
      "epoch: 5 [683265/888800 76.88%] train loss: 3.5661927540786564e-05 \n",
      "epoch: 5 [684376/888800 77.00%] train loss: 3.3250216802116483e-05 \n",
      "epoch: 5 [685487/888800 77.12%] train loss: 3.635116445366293e-05 \n",
      "epoch: 5 [686598/888800 77.25%] train loss: 4.029607225675136e-05 \n",
      "epoch: 5 [687709/888800 77.38%] train loss: 3.3646487281657755e-05 \n",
      "epoch: 5 [688820/888800 77.50%] train loss: 4.079207428731024e-05 \n",
      "epoch: 5 [689931/888800 77.62%] train loss: 3.1559920898871496e-05 \n",
      "epoch: 5 [691042/888800 77.75%] train loss: 4.251872087479569e-05 \n",
      "epoch: 5 [692153/888800 77.88%] train loss: 3.9197697333293036e-05 \n",
      "epoch: 5 [693264/888800 78.00%] train loss: 3.941429531550966e-05 \n",
      "epoch: 5 [694375/888800 78.12%] train loss: 3.8977388612693176e-05 \n",
      "epoch: 5 [695486/888800 78.25%] train loss: 3.402146467124112e-05 \n",
      "epoch: 5 [696597/888800 78.38%] train loss: 3.849194399663247e-05 \n",
      "epoch: 5 [697708/888800 78.50%] train loss: 3.3910728234332055e-05 \n",
      "epoch: 5 [698819/888800 78.62%] train loss: 3.5765839129453525e-05 \n",
      "epoch: 5 [699930/888800 78.75%] train loss: 3.6033958167536184e-05 \n",
      "epoch: 5 [701041/888800 78.88%] train loss: 4.394842471810989e-05 \n",
      "epoch: 5 [702152/888800 79.00%] train loss: 3.4442262403899804e-05 \n",
      "epoch: 5 [703263/888800 79.12%] train loss: 3.848131746053696e-05 \n",
      "epoch: 5 [704374/888800 79.25%] train loss: 3.415368701098487e-05 \n",
      "epoch: 5 [705485/888800 79.38%] train loss: 4.1831019188975915e-05 \n",
      "epoch: 5 [706596/888800 79.50%] train loss: 3.282237230450846e-05 \n",
      "epoch: 5 [707707/888800 79.62%] train loss: 3.7296165828593075e-05 \n",
      "epoch: 5 [708818/888800 79.75%] train loss: 3.498427395243198e-05 \n",
      "epoch: 5 [709929/888800 79.88%] train loss: 3.526970249367878e-05 \n",
      "epoch: 5 [711040/888800 80.00%] train loss: 3.751331314560957e-05 \n",
      "epoch: 5 [712151/888800 80.12%] train loss: 3.233804818592034e-05 \n",
      "epoch: 5 [713262/888800 80.25%] train loss: 3.520765676512383e-05 \n",
      "epoch: 5 [714373/888800 80.38%] train loss: 3.805419692071155e-05 \n",
      "epoch: 5 [715484/888800 80.50%] train loss: 3.8760557799832895e-05 \n",
      "epoch: 5 [716595/888800 80.62%] train loss: 3.1007279176265e-05 \n",
      "epoch: 5 [717706/888800 80.75%] train loss: 3.253748582210392e-05 \n",
      "epoch: 5 [718817/888800 80.88%] train loss: 3.375924643478356e-05 \n",
      "epoch: 5 [719928/888800 81.00%] train loss: 3.2789645047159865e-05 \n",
      "epoch: 5 [721039/888800 81.12%] train loss: 3.664948235382326e-05 \n",
      "epoch: 5 [722150/888800 81.25%] train loss: 3.5969424061477184e-05 \n",
      "epoch: 5 [723261/888800 81.38%] train loss: 3.663510869955644e-05 \n",
      "epoch: 5 [724372/888800 81.50%] train loss: 4.242312934366055e-05 \n",
      "epoch: 5 [725483/888800 81.62%] train loss: 3.566478699212894e-05 \n",
      "epoch: 5 [726594/888800 81.75%] train loss: 3.5652057704282925e-05 \n",
      "epoch: 5 [727705/888800 81.88%] train loss: 4.147805520915426e-05 \n",
      "epoch: 5 [728816/888800 82.00%] train loss: 3.3395455830032006e-05 \n",
      "epoch: 5 [729927/888800 82.12%] train loss: 3.8959464291110635e-05 \n",
      "epoch: 5 [731038/888800 82.25%] train loss: 4.4485419493867084e-05 \n",
      "epoch: 5 [732149/888800 82.38%] train loss: 3.554967770469375e-05 \n",
      "epoch: 5 [733260/888800 82.50%] train loss: 3.837219992419705e-05 \n",
      "epoch: 5 [734371/888800 82.62%] train loss: 3.345179356983863e-05 \n",
      "epoch: 5 [735482/888800 82.75%] train loss: 3.313504203106277e-05 \n",
      "epoch: 5 [736593/888800 82.88%] train loss: 3.8378409954020754e-05 \n",
      "epoch: 5 [737704/888800 83.00%] train loss: 3.5687571653397754e-05 \n",
      "epoch: 5 [738815/888800 83.12%] train loss: 3.763136191992089e-05 \n",
      "epoch: 5 [739926/888800 83.25%] train loss: 4.059069760842249e-05 \n",
      "epoch: 5 [741037/888800 83.38%] train loss: 3.625661338446662e-05 \n",
      "epoch: 5 [742148/888800 83.50%] train loss: 4.1761646571103483e-05 \n",
      "epoch: 5 [743259/888800 83.62%] train loss: 3.323898636153899e-05 \n",
      "epoch: 5 [744370/888800 83.75%] train loss: 3.380193084012717e-05 \n",
      "epoch: 5 [745481/888800 83.88%] train loss: 3.13859163725283e-05 \n",
      "epoch: 5 [746592/888800 84.00%] train loss: 3.590753476601094e-05 \n",
      "epoch: 5 [747703/888800 84.12%] train loss: 4.4609056203626096e-05 \n",
      "epoch: 5 [748814/888800 84.25%] train loss: 3.8509588193846866e-05 \n",
      "epoch: 5 [749925/888800 84.38%] train loss: 3.729318632395007e-05 \n",
      "epoch: 5 [751036/888800 84.50%] train loss: 3.99966083932668e-05 \n",
      "epoch: 5 [752147/888800 84.62%] train loss: 3.742435001186095e-05 \n",
      "epoch: 5 [753258/888800 84.75%] train loss: 3.364704389241524e-05 \n",
      "epoch: 5 [754369/888800 84.88%] train loss: 4.20582146034576e-05 \n",
      "epoch: 5 [755480/888800 85.00%] train loss: 3.73154143744614e-05 \n",
      "epoch: 5 [756591/888800 85.12%] train loss: 4.1540071833878756e-05 \n",
      "epoch: 5 [757702/888800 85.25%] train loss: 4.1449893615208566e-05 \n",
      "epoch: 5 [758813/888800 85.38%] train loss: 4.287705451133661e-05 \n",
      "epoch: 5 [759924/888800 85.50%] train loss: 3.2684871257515624e-05 \n",
      "epoch: 5 [761035/888800 85.62%] train loss: 3.8197042158572e-05 \n",
      "epoch: 5 [762146/888800 85.75%] train loss: 3.76184907509014e-05 \n",
      "epoch: 5 [763257/888800 85.88%] train loss: 3.500359525787644e-05 \n",
      "epoch: 5 [764368/888800 86.00%] train loss: 3.264158294769004e-05 \n",
      "epoch: 5 [765479/888800 86.12%] train loss: 3.7021043681306764e-05 \n",
      "epoch: 5 [766590/888800 86.25%] train loss: 3.553114220267162e-05 \n",
      "epoch: 5 [767701/888800 86.38%] train loss: 4.38813294749707e-05 \n",
      "epoch: 5 [768812/888800 86.50%] train loss: 3.8342230254784226e-05 \n",
      "epoch: 5 [769923/888800 86.62%] train loss: 4.1847444663289934e-05 \n",
      "epoch: 5 [771034/888800 86.75%] train loss: 3.245086190872826e-05 \n",
      "epoch: 5 [772145/888800 86.88%] train loss: 3.374580046511255e-05 \n",
      "epoch: 5 [773256/888800 87.00%] train loss: 3.548367021721788e-05 \n",
      "epoch: 5 [774367/888800 87.12%] train loss: 3.3571406675036997e-05 \n",
      "epoch: 5 [775478/888800 87.25%] train loss: 4.267783515388146e-05 \n",
      "epoch: 5 [776589/888800 87.38%] train loss: 3.759476021514274e-05 \n",
      "epoch: 5 [777700/888800 87.50%] train loss: 3.786917659454048e-05 \n",
      "epoch: 5 [778811/888800 87.62%] train loss: 2.9339676984818652e-05 \n",
      "epoch: 5 [779922/888800 87.75%] train loss: 3.394095620024018e-05 \n",
      "epoch: 5 [781033/888800 87.88%] train loss: 3.928713340428658e-05 \n",
      "epoch: 5 [782144/888800 88.00%] train loss: 3.838457996607758e-05 \n",
      "epoch: 5 [783255/888800 88.12%] train loss: 4.2079649574588984e-05 \n",
      "epoch: 5 [784366/888800 88.25%] train loss: 3.700979141285643e-05 \n",
      "epoch: 5 [785477/888800 88.38%] train loss: 4.460714990273118e-05 \n",
      "epoch: 5 [786588/888800 88.50%] train loss: 3.0321547455969267e-05 \n",
      "epoch: 5 [787699/888800 88.62%] train loss: 3.05259927699808e-05 \n",
      "epoch: 5 [788810/888800 88.75%] train loss: 3.658432615338825e-05 \n",
      "epoch: 5 [789921/888800 88.88%] train loss: 3.472663593129255e-05 \n",
      "epoch: 5 [791032/888800 89.00%] train loss: 3.928603109670803e-05 \n",
      "epoch: 5 [792143/888800 89.12%] train loss: 3.7585476093227044e-05 \n",
      "epoch: 5 [793254/888800 89.25%] train loss: 3.710016972036101e-05 \n",
      "epoch: 5 [794365/888800 89.38%] train loss: 3.705474955495447e-05 \n",
      "epoch: 5 [795476/888800 89.50%] train loss: 3.2718533475417644e-05 \n",
      "epoch: 5 [796587/888800 89.62%] train loss: 4.373427145765163e-05 \n",
      "epoch: 5 [797698/888800 89.75%] train loss: 3.267238935222849e-05 \n",
      "epoch: 5 [798809/888800 89.88%] train loss: 2.7965326808043756e-05 \n",
      "epoch: 5 [799920/888800 90.00%] train loss: 4.375761636765674e-05 \n",
      "epoch: 5 [801031/888800 90.12%] train loss: 4.118587094126269e-05 \n",
      "epoch: 5 [802142/888800 90.25%] train loss: 4.015195736428723e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 [803253/888800 90.38%] train loss: 3.5395722079556435e-05 \n",
      "epoch: 5 [804364/888800 90.50%] train loss: 3.673419269034639e-05 \n",
      "epoch: 5 [805475/888800 90.62%] train loss: 3.7300127587514e-05 \n",
      "epoch: 5 [806586/888800 90.75%] train loss: 3.823090810328722e-05 \n",
      "epoch: 5 [807697/888800 90.88%] train loss: 3.8730111555196345e-05 \n",
      "epoch: 5 [808808/888800 91.00%] train loss: 4.345230263425037e-05 \n",
      "epoch: 5 [809919/888800 91.12%] train loss: 4.0934373828349635e-05 \n",
      "epoch: 5 [811030/888800 91.25%] train loss: 3.073786501772702e-05 \n",
      "epoch: 5 [812141/888800 91.38%] train loss: 4.167807855992578e-05 \n",
      "epoch: 5 [813252/888800 91.50%] train loss: 3.4858559956774116e-05 \n",
      "epoch: 5 [814363/888800 91.62%] train loss: 3.784637010539882e-05 \n",
      "epoch: 5 [815474/888800 91.75%] train loss: 3.238091812818311e-05 \n",
      "epoch: 5 [816585/888800 91.88%] train loss: 3.4851782402256504e-05 \n",
      "epoch: 5 [817696/888800 92.00%] train loss: 4.04466554755345e-05 \n",
      "epoch: 5 [818807/888800 92.12%] train loss: 3.664960968308151e-05 \n",
      "epoch: 5 [819918/888800 92.25%] train loss: 3.351449777255766e-05 \n",
      "epoch: 5 [821029/888800 92.38%] train loss: 3.138367537758313e-05 \n",
      "epoch: 5 [822140/888800 92.50%] train loss: 2.9392967917374335e-05 \n",
      "epoch: 5 [823251/888800 92.62%] train loss: 3.420209395699203e-05 \n",
      "epoch: 5 [824362/888800 92.75%] train loss: 4.487107798922807e-05 \n",
      "epoch: 5 [825473/888800 92.88%] train loss: 3.9584552723681554e-05 \n",
      "epoch: 5 [826584/888800 93.00%] train loss: 3.8334212149493396e-05 \n",
      "epoch: 5 [827695/888800 93.12%] train loss: 4.097863711649552e-05 \n",
      "epoch: 5 [828806/888800 93.25%] train loss: 3.557874515536241e-05 \n",
      "epoch: 5 [829917/888800 93.38%] train loss: 3.65140222129412e-05 \n",
      "epoch: 5 [831028/888800 93.50%] train loss: 3.655985710793175e-05 \n",
      "epoch: 5 [832139/888800 93.62%] train loss: 3.773757634917274e-05 \n",
      "epoch: 5 [833250/888800 93.75%] train loss: 4.059946149936877e-05 \n",
      "epoch: 5 [834361/888800 93.88%] train loss: 3.807551911449991e-05 \n",
      "epoch: 5 [835472/888800 94.00%] train loss: 3.5164342989446595e-05 \n",
      "epoch: 5 [836583/888800 94.12%] train loss: 3.485139677650295e-05 \n",
      "epoch: 5 [837694/888800 94.25%] train loss: 3.912561078323051e-05 \n",
      "epoch: 5 [838805/888800 94.38%] train loss: 3.593345536501147e-05 \n",
      "epoch: 5 [839916/888800 94.50%] train loss: 3.075009590247646e-05 \n",
      "epoch: 5 [841027/888800 94.62%] train loss: 3.093750274274498e-05 \n",
      "epoch: 5 [842138/888800 94.75%] train loss: 3.9114427636377513e-05 \n",
      "epoch: 5 [843249/888800 94.88%] train loss: 3.114132778136991e-05 \n",
      "epoch: 5 [844360/888800 95.00%] train loss: 4.174699279246852e-05 \n",
      "epoch: 5 [845471/888800 95.12%] train loss: 2.6735020583146252e-05 \n",
      "epoch: 5 [846582/888800 95.25%] train loss: 3.754355202545412e-05 \n",
      "epoch: 5 [847693/888800 95.38%] train loss: 3.930757520720363e-05 \n",
      "epoch: 5 [848804/888800 95.50%] train loss: 4.40076291852165e-05 \n",
      "epoch: 5 [849915/888800 95.62%] train loss: 3.8088492146926e-05 \n",
      "epoch: 5 [851026/888800 95.75%] train loss: 3.452348391874693e-05 \n",
      "epoch: 5 [852137/888800 95.88%] train loss: 4.0273371268995106e-05 \n",
      "epoch: 5 [853248/888800 96.00%] train loss: 3.1319275876739994e-05 \n",
      "epoch: 5 [854359/888800 96.12%] train loss: 3.58041979779955e-05 \n",
      "epoch: 5 [855470/888800 96.25%] train loss: 2.9750886824331246e-05 \n",
      "epoch: 5 [856581/888800 96.38%] train loss: 3.0251681891968474e-05 \n",
      "epoch: 5 [857692/888800 96.50%] train loss: 3.87553263863083e-05 \n",
      "epoch: 5 [858803/888800 96.62%] train loss: 3.992153506260365e-05 \n",
      "epoch: 5 [859914/888800 96.75%] train loss: 3.5979806852992624e-05 \n",
      "epoch: 5 [861025/888800 96.88%] train loss: 3.6149391235085204e-05 \n",
      "epoch: 5 [862136/888800 97.00%] train loss: 3.306241342215799e-05 \n",
      "epoch: 5 [863247/888800 97.12%] train loss: 4.0614355384605005e-05 \n",
      "epoch: 5 [864358/888800 97.25%] train loss: 3.618778282543644e-05 \n",
      "epoch: 5 [865469/888800 97.38%] train loss: 3.6447268939809874e-05 \n",
      "epoch: 5 [866580/888800 97.50%] train loss: 3.629825005191378e-05 \n",
      "epoch: 5 [867691/888800 97.62%] train loss: 4.06303588533774e-05 \n",
      "epoch: 5 [868802/888800 97.75%] train loss: 3.85891180485487e-05 \n",
      "epoch: 5 [869913/888800 97.88%] train loss: 3.9724702219245955e-05 \n",
      "epoch: 5 [871024/888800 98.00%] train loss: 3.333259155624546e-05 \n",
      "epoch: 5 [872135/888800 98.12%] train loss: 2.8748800104949623e-05 \n",
      "epoch: 5 [873246/888800 98.25%] train loss: 3.829048000625335e-05 \n",
      "epoch: 5 [874357/888800 98.38%] train loss: 3.704123810166493e-05 \n",
      "epoch: 5 [875468/888800 98.50%] train loss: 3.919353548553772e-05 \n",
      "epoch: 5 [876579/888800 98.62%] train loss: 3.780255792662501e-05 \n",
      "epoch: 5 [877690/888800 98.75%] train loss: 3.383831062819809e-05 \n",
      "epoch: 5 [878801/888800 98.88%] train loss: 2.9035531042609364e-05 \n",
      "epoch: 5 [879912/888800 99.00%] train loss: 3.152669160044752e-05 \n",
      "epoch: 5 [881023/888800 99.12%] train loss: 3.437268242123537e-05 \n",
      "epoch: 5 [882134/888800 99.25%] train loss: 3.511647810228169e-05 \n",
      "epoch: 5 [883245/888800 99.38%] train loss: 3.882338205585256e-05 \n",
      "epoch: 5 [884356/888800 99.50%] train loss: 4.423080463311635e-05 \n",
      "epoch: 5 [885467/888800 99.62%] train loss: 3.668458157335408e-05 \n",
      "epoch: 5 [886578/888800 99.75%] train loss: 3.701559398905374e-05 \n",
      "epoch: 5 [887689/888800 99.88%] train loss: 3.998037209385075e-05 \n",
      "epoch: 6 [0/888800 0.00%] train loss: 3.888491482939571e-05 \n",
      "epoch: 6 [1111/888800 0.12%] train loss: 3.5302004107506946e-05 \n",
      "epoch: 6 [2222/888800 0.25%] train loss: 2.857866093108896e-05 \n",
      "epoch: 6 [3333/888800 0.38%] train loss: 4.175331923761405e-05 \n",
      "epoch: 6 [4444/888800 0.50%] train loss: 3.075696076848544e-05 \n",
      "epoch: 6 [5555/888800 0.62%] train loss: 3.248307984904386e-05 \n",
      "epoch: 6 [6666/888800 0.75%] train loss: 3.781731356866658e-05 \n",
      "epoch: 6 [7777/888800 0.88%] train loss: 2.941089951491449e-05 \n",
      "epoch: 6 [8888/888800 1.00%] train loss: 3.172188371536322e-05 \n",
      "epoch: 6 [9999/888800 1.12%] train loss: 3.814878800767474e-05 \n",
      "epoch: 6 [11110/888800 1.25%] train loss: 4.09264030167833e-05 \n",
      "epoch: 6 [12221/888800 1.38%] train loss: 3.479336010059342e-05 \n",
      "epoch: 6 [13332/888800 1.50%] train loss: 3.801437560468912e-05 \n",
      "epoch: 6 [14443/888800 1.62%] train loss: 3.810135603998788e-05 \n",
      "epoch: 6 [15554/888800 1.75%] train loss: 3.3668689866317436e-05 \n",
      "epoch: 6 [16665/888800 1.88%] train loss: 3.4616499760886654e-05 \n",
      "epoch: 6 [17776/888800 2.00%] train loss: 3.542512786225416e-05 \n",
      "epoch: 6 [18887/888800 2.12%] train loss: 4.319140498409979e-05 \n",
      "epoch: 6 [19998/888800 2.25%] train loss: 2.980233693961054e-05 \n",
      "epoch: 6 [21109/888800 2.38%] train loss: 3.9531962102046236e-05 \n",
      "epoch: 6 [22220/888800 2.50%] train loss: 3.232206290704198e-05 \n",
      "epoch: 6 [23331/888800 2.62%] train loss: 3.4333257644902915e-05 \n",
      "epoch: 6 [24442/888800 2.75%] train loss: 3.825172098004259e-05 \n",
      "epoch: 6 [25553/888800 2.88%] train loss: 3.411843135836534e-05 \n",
      "epoch: 6 [26664/888800 3.00%] train loss: 3.2639625715091825e-05 \n",
      "epoch: 6 [27775/888800 3.12%] train loss: 3.350882980157621e-05 \n",
      "epoch: 6 [28886/888800 3.25%] train loss: 3.106444273726083e-05 \n",
      "epoch: 6 [29997/888800 3.38%] train loss: 3.5798937460640445e-05 \n",
      "epoch: 6 [31108/888800 3.50%] train loss: 3.690983430715278e-05 \n",
      "epoch: 6 [32219/888800 3.62%] train loss: 4.062607331434265e-05 \n",
      "epoch: 6 [33330/888800 3.75%] train loss: 3.496466888464056e-05 \n",
      "epoch: 6 [34441/888800 3.88%] train loss: 3.372289938852191e-05 \n",
      "epoch: 6 [35552/888800 4.00%] train loss: 3.824161467491649e-05 \n",
      "epoch: 6 [36663/888800 4.12%] train loss: 3.5167795431334525e-05 \n",
      "epoch: 6 [37774/888800 4.25%] train loss: 3.213596573914401e-05 \n",
      "epoch: 6 [38885/888800 4.38%] train loss: 3.636511610238813e-05 \n",
      "epoch: 6 [39996/888800 4.50%] train loss: 3.720388122019358e-05 \n",
      "epoch: 6 [41107/888800 4.62%] train loss: 3.5985398426419124e-05 \n",
      "epoch: 6 [42218/888800 4.75%] train loss: 3.448213465162553e-05 \n",
      "epoch: 6 [43329/888800 4.88%] train loss: 3.604924859246239e-05 \n",
      "epoch: 6 [44440/888800 5.00%] train loss: 3.487928552203812e-05 \n",
      "epoch: 6 [45551/888800 5.12%] train loss: 3.260698213125579e-05 \n",
      "epoch: 6 [46662/888800 5.25%] train loss: 3.597294198698364e-05 \n",
      "epoch: 6 [47773/888800 5.38%] train loss: 4.3082894990220666e-05 \n",
      "epoch: 6 [48884/888800 5.50%] train loss: 4.0807419281918555e-05 \n",
      "epoch: 6 [49995/888800 5.62%] train loss: 3.461392407189123e-05 \n",
      "epoch: 6 [51106/888800 5.75%] train loss: 2.9898899811087176e-05 \n",
      "epoch: 6 [52217/888800 5.88%] train loss: 3.519231904647313e-05 \n",
      "epoch: 6 [53328/888800 6.00%] train loss: 4.281283327145502e-05 \n",
      "epoch: 6 [54439/888800 6.12%] train loss: 3.8094392948551103e-05 \n",
      "epoch: 6 [55550/888800 6.25%] train loss: 3.331977131892927e-05 \n",
      "epoch: 6 [56661/888800 6.38%] train loss: 3.644520984380506e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [57772/888800 6.50%] train loss: 3.148940595565364e-05 \n",
      "epoch: 6 [58883/888800 6.62%] train loss: 3.57528988388367e-05 \n",
      "epoch: 6 [59994/888800 6.75%] train loss: 4.1365958168171346e-05 \n",
      "epoch: 6 [61105/888800 6.88%] train loss: 3.958907473133877e-05 \n",
      "epoch: 6 [62216/888800 7.00%] train loss: 3.6153644032310694e-05 \n",
      "epoch: 6 [63327/888800 7.12%] train loss: 3.596683745854534e-05 \n",
      "epoch: 6 [64438/888800 7.25%] train loss: 3.537879092618823e-05 \n",
      "epoch: 6 [65549/888800 7.38%] train loss: 3.4363514714641497e-05 \n",
      "epoch: 6 [66660/888800 7.50%] train loss: 3.319228198961355e-05 \n",
      "epoch: 6 [67771/888800 7.62%] train loss: 3.8609025068581104e-05 \n",
      "epoch: 6 [68882/888800 7.75%] train loss: 4.029666160931811e-05 \n",
      "epoch: 6 [69993/888800 7.88%] train loss: 3.2185736927203834e-05 \n",
      "epoch: 6 [71104/888800 8.00%] train loss: 3.873970854328945e-05 \n",
      "epoch: 6 [72215/888800 8.12%] train loss: 3.069701051572338e-05 \n",
      "epoch: 6 [73326/888800 8.25%] train loss: 3.79856355721131e-05 \n",
      "epoch: 6 [74437/888800 8.38%] train loss: 4.0950511902337894e-05 \n",
      "epoch: 6 [75548/888800 8.50%] train loss: 3.0159742891555652e-05 \n",
      "epoch: 6 [76659/888800 8.62%] train loss: 3.6249035474611446e-05 \n",
      "epoch: 6 [77770/888800 8.75%] train loss: 4.4342366891214624e-05 \n",
      "epoch: 6 [78881/888800 8.88%] train loss: 3.6337300116429105e-05 \n",
      "epoch: 6 [79992/888800 9.00%] train loss: 3.676092092064209e-05 \n",
      "epoch: 6 [81103/888800 9.12%] train loss: 3.578735777409747e-05 \n",
      "epoch: 6 [82214/888800 9.25%] train loss: 3.3529351640027016e-05 \n",
      "epoch: 6 [83325/888800 9.38%] train loss: 3.885236583300866e-05 \n",
      "epoch: 6 [84436/888800 9.50%] train loss: 3.43423816957511e-05 \n",
      "epoch: 6 [85547/888800 9.62%] train loss: 3.389754783711396e-05 \n",
      "epoch: 6 [86658/888800 9.75%] train loss: 3.380843554623425e-05 \n",
      "epoch: 6 [87769/888800 9.88%] train loss: 3.9623642805963755e-05 \n",
      "epoch: 6 [88880/888800 10.00%] train loss: 3.586981620173901e-05 \n",
      "epoch: 6 [89991/888800 10.12%] train loss: 3.4216824133181944e-05 \n",
      "epoch: 6 [91102/888800 10.25%] train loss: 3.625784665928222e-05 \n",
      "epoch: 6 [92213/888800 10.38%] train loss: 3.0021961720194668e-05 \n",
      "epoch: 6 [93324/888800 10.50%] train loss: 3.632931475294754e-05 \n",
      "epoch: 6 [94435/888800 10.62%] train loss: 3.5656008549267426e-05 \n",
      "epoch: 6 [95546/888800 10.75%] train loss: 3.468695285846479e-05 \n",
      "epoch: 6 [96657/888800 10.88%] train loss: 3.599163028411567e-05 \n",
      "epoch: 6 [97768/888800 11.00%] train loss: 3.842401929432526e-05 \n",
      "epoch: 6 [98879/888800 11.12%] train loss: 3.732559707714245e-05 \n",
      "epoch: 6 [99990/888800 11.25%] train loss: 3.286349237896502e-05 \n",
      "epoch: 6 [101101/888800 11.38%] train loss: 3.6905370507156476e-05 \n",
      "epoch: 6 [102212/888800 11.50%] train loss: 4.222213101456873e-05 \n",
      "epoch: 6 [103323/888800 11.62%] train loss: 3.832382571999915e-05 \n",
      "epoch: 6 [104434/888800 11.75%] train loss: 3.970739635406062e-05 \n",
      "epoch: 6 [105545/888800 11.88%] train loss: 3.49045149050653e-05 \n",
      "epoch: 6 [106656/888800 12.00%] train loss: 3.2801428460516036e-05 \n",
      "epoch: 6 [107767/888800 12.12%] train loss: 3.3691008866298944e-05 \n",
      "epoch: 6 [108878/888800 12.25%] train loss: 3.7410147342598066e-05 \n",
      "epoch: 6 [109989/888800 12.38%] train loss: 3.404113886062987e-05 \n",
      "epoch: 6 [111100/888800 12.50%] train loss: 3.361270864843391e-05 \n",
      "epoch: 6 [112211/888800 12.62%] train loss: 4.192416599835269e-05 \n",
      "epoch: 6 [113322/888800 12.75%] train loss: 3.151963755954057e-05 \n",
      "epoch: 6 [114433/888800 12.88%] train loss: 2.9876568078179844e-05 \n",
      "epoch: 6 [115544/888800 13.00%] train loss: 3.93490117858164e-05 \n",
      "epoch: 6 [116655/888800 13.12%] train loss: 3.939259113394655e-05 \n",
      "epoch: 6 [117766/888800 13.25%] train loss: 4.033406366943382e-05 \n",
      "epoch: 6 [118877/888800 13.38%] train loss: 3.7083289498696104e-05 \n",
      "epoch: 6 [119988/888800 13.50%] train loss: 3.638989801402204e-05 \n",
      "epoch: 6 [121099/888800 13.62%] train loss: 3.94537637475878e-05 \n",
      "epoch: 6 [122210/888800 13.75%] train loss: 3.447314884397201e-05 \n",
      "epoch: 6 [123321/888800 13.88%] train loss: 3.6356639611767605e-05 \n",
      "epoch: 6 [124432/888800 14.00%] train loss: 3.332037522341125e-05 \n",
      "epoch: 6 [125543/888800 14.12%] train loss: 3.314387868158519e-05 \n",
      "epoch: 6 [126654/888800 14.25%] train loss: 3.716564242495224e-05 \n",
      "epoch: 6 [127765/888800 14.38%] train loss: 3.6377477954374626e-05 \n",
      "epoch: 6 [128876/888800 14.50%] train loss: 3.1380604923469946e-05 \n",
      "epoch: 6 [129987/888800 14.62%] train loss: 3.477192876744084e-05 \n",
      "epoch: 6 [131098/888800 14.75%] train loss: 3.545515573932789e-05 \n",
      "epoch: 6 [132209/888800 14.88%] train loss: 3.6656329029938206e-05 \n",
      "epoch: 6 [133320/888800 15.00%] train loss: 2.8305375963100232e-05 \n",
      "epoch: 6 [134431/888800 15.12%] train loss: 3.954736894229427e-05 \n",
      "epoch: 6 [135542/888800 15.25%] train loss: 3.64392290066462e-05 \n",
      "epoch: 6 [136653/888800 15.38%] train loss: 4.190321487840265e-05 \n",
      "epoch: 6 [137764/888800 15.50%] train loss: 3.982013004133478e-05 \n",
      "epoch: 6 [138875/888800 15.62%] train loss: 4.7805959184188396e-05 \n",
      "epoch: 6 [139986/888800 15.75%] train loss: 3.160007327096537e-05 \n",
      "epoch: 6 [141097/888800 15.88%] train loss: 3.153417492285371e-05 \n",
      "epoch: 6 [142208/888800 16.00%] train loss: 3.448494680924341e-05 \n",
      "epoch: 6 [143319/888800 16.12%] train loss: 3.42757957696449e-05 \n",
      "epoch: 6 [144430/888800 16.25%] train loss: 3.0386492653633468e-05 \n",
      "epoch: 6 [145541/888800 16.38%] train loss: 3.610222847783007e-05 \n",
      "epoch: 6 [146652/888800 16.50%] train loss: 3.6929915950167924e-05 \n",
      "epoch: 6 [147763/888800 16.62%] train loss: 3.580093107302673e-05 \n",
      "epoch: 6 [148874/888800 16.75%] train loss: 3.111999103566632e-05 \n",
      "epoch: 6 [149985/888800 16.88%] train loss: 2.9556815206888132e-05 \n",
      "epoch: 6 [151096/888800 17.00%] train loss: 3.672167440527119e-05 \n",
      "epoch: 6 [152207/888800 17.12%] train loss: 3.772889613173902e-05 \n",
      "epoch: 6 [153318/888800 17.25%] train loss: 3.824118903139606e-05 \n",
      "epoch: 6 [154429/888800 17.38%] train loss: 3.473827018751763e-05 \n",
      "epoch: 6 [155540/888800 17.50%] train loss: 3.717015715665184e-05 \n",
      "epoch: 6 [156651/888800 17.62%] train loss: 4.578729931381531e-05 \n",
      "epoch: 6 [157762/888800 17.75%] train loss: 3.606829704949632e-05 \n",
      "epoch: 6 [158873/888800 17.88%] train loss: 3.5452361771604046e-05 \n",
      "epoch: 6 [159984/888800 18.00%] train loss: 3.4077023883583024e-05 \n",
      "epoch: 6 [161095/888800 18.12%] train loss: 3.984123031841591e-05 \n",
      "epoch: 6 [162206/888800 18.25%] train loss: 4.189080573269166e-05 \n",
      "epoch: 6 [163317/888800 18.38%] train loss: 3.683780596475117e-05 \n",
      "epoch: 6 [164428/888800 18.50%] train loss: 3.380206544534303e-05 \n",
      "epoch: 6 [165539/888800 18.62%] train loss: 3.4904220228781924e-05 \n",
      "epoch: 6 [166650/888800 18.75%] train loss: 3.744686546269804e-05 \n",
      "epoch: 6 [167761/888800 18.88%] train loss: 4.3373009248171e-05 \n",
      "epoch: 6 [168872/888800 19.00%] train loss: 4.130151864956133e-05 \n",
      "epoch: 6 [169983/888800 19.12%] train loss: 3.2392861612606794e-05 \n",
      "epoch: 6 [171094/888800 19.25%] train loss: 3.3887285098899156e-05 \n",
      "epoch: 6 [172205/888800 19.38%] train loss: 4.46752856078092e-05 \n",
      "epoch: 6 [173316/888800 19.50%] train loss: 3.5800778277916834e-05 \n",
      "epoch: 6 [174427/888800 19.62%] train loss: 3.857480260194279e-05 \n",
      "epoch: 6 [175538/888800 19.75%] train loss: 3.571040724636987e-05 \n",
      "epoch: 6 [176649/888800 19.88%] train loss: 3.2023905077949166e-05 \n",
      "epoch: 6 [177760/888800 20.00%] train loss: 3.676468622870743e-05 \n",
      "epoch: 6 [178871/888800 20.12%] train loss: 3.8542475522262976e-05 \n",
      "epoch: 6 [179982/888800 20.25%] train loss: 3.563990321708843e-05 \n",
      "epoch: 6 [181093/888800 20.38%] train loss: 3.380255657248199e-05 \n",
      "epoch: 6 [182204/888800 20.50%] train loss: 3.1914962164592e-05 \n",
      "epoch: 6 [183315/888800 20.62%] train loss: 3.4253036574227735e-05 \n",
      "epoch: 6 [184426/888800 20.75%] train loss: 3.182446016580798e-05 \n",
      "epoch: 6 [185537/888800 20.88%] train loss: 3.2843770895851776e-05 \n",
      "epoch: 6 [186648/888800 21.00%] train loss: 3.1186278647510335e-05 \n",
      "epoch: 6 [187759/888800 21.12%] train loss: 3.395721796550788e-05 \n",
      "epoch: 6 [188870/888800 21.25%] train loss: 3.850840948871337e-05 \n",
      "epoch: 6 [189981/888800 21.38%] train loss: 3.6544101021718234e-05 \n",
      "epoch: 6 [191092/888800 21.50%] train loss: 3.956432192353532e-05 \n",
      "epoch: 6 [192203/888800 21.62%] train loss: 3.467899659881368e-05 \n",
      "epoch: 6 [193314/888800 21.75%] train loss: 3.480612940620631e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [194425/888800 21.88%] train loss: 4.271082070772536e-05 \n",
      "epoch: 6 [195536/888800 22.00%] train loss: 3.6799759982386604e-05 \n",
      "epoch: 6 [196647/888800 22.12%] train loss: 3.9413978811353445e-05 \n",
      "epoch: 6 [197758/888800 22.25%] train loss: 3.9562124584335834e-05 \n",
      "epoch: 6 [198869/888800 22.38%] train loss: 4.000357512268238e-05 \n",
      "epoch: 6 [199980/888800 22.50%] train loss: 3.014912363141775e-05 \n",
      "epoch: 6 [201091/888800 22.62%] train loss: 3.914230182999745e-05 \n",
      "epoch: 6 [202202/888800 22.75%] train loss: 3.8452071748906747e-05 \n",
      "epoch: 6 [203313/888800 22.88%] train loss: 4.1328334191348404e-05 \n",
      "epoch: 6 [204424/888800 23.00%] train loss: 3.77491487597581e-05 \n",
      "epoch: 6 [205535/888800 23.12%] train loss: 3.5082546673947945e-05 \n",
      "epoch: 6 [206646/888800 23.25%] train loss: 3.543690763763152e-05 \n",
      "epoch: 6 [207757/888800 23.38%] train loss: 3.777598249143921e-05 \n",
      "epoch: 6 [208868/888800 23.50%] train loss: 3.707371433847584e-05 \n",
      "epoch: 6 [209979/888800 23.62%] train loss: 3.6540608562063426e-05 \n",
      "epoch: 6 [211090/888800 23.75%] train loss: 2.874421261367388e-05 \n",
      "epoch: 6 [212201/888800 23.88%] train loss: 3.0519437132170424e-05 \n",
      "epoch: 6 [213312/888800 24.00%] train loss: 3.5710636439034715e-05 \n",
      "epoch: 6 [214423/888800 24.12%] train loss: 4.021505810669623e-05 \n",
      "epoch: 6 [215534/888800 24.25%] train loss: 2.763538941508159e-05 \n",
      "epoch: 6 [216645/888800 24.38%] train loss: 3.6714132875204086e-05 \n",
      "epoch: 6 [217756/888800 24.50%] train loss: 3.862327866954729e-05 \n",
      "epoch: 6 [218867/888800 24.62%] train loss: 3.7055106076877564e-05 \n",
      "epoch: 6 [219978/888800 24.75%] train loss: 3.689918958116323e-05 \n",
      "epoch: 6 [221089/888800 24.88%] train loss: 3.7818153941771016e-05 \n",
      "epoch: 6 [222200/888800 25.00%] train loss: 3.488124275463633e-05 \n",
      "epoch: 6 [223311/888800 25.12%] train loss: 3.283211117377505e-05 \n",
      "epoch: 6 [224422/888800 25.25%] train loss: 3.6100253055337816e-05 \n",
      "epoch: 6 [225533/888800 25.38%] train loss: 3.5350312828086317e-05 \n",
      "epoch: 6 [226644/888800 25.50%] train loss: 3.276336065027863e-05 \n",
      "epoch: 6 [227755/888800 25.62%] train loss: 3.56760538124945e-05 \n",
      "epoch: 6 [228866/888800 25.75%] train loss: 3.9319624193012714e-05 \n",
      "epoch: 6 [229977/888800 25.88%] train loss: 4.1273055103374645e-05 \n",
      "epoch: 6 [231088/888800 26.00%] train loss: 3.3260759664699435e-05 \n",
      "epoch: 6 [232199/888800 26.12%] train loss: 3.3242096833419055e-05 \n",
      "epoch: 6 [233310/888800 26.25%] train loss: 3.4964985388796777e-05 \n",
      "epoch: 6 [234421/888800 26.38%] train loss: 3.6277859180700034e-05 \n",
      "epoch: 6 [235532/888800 26.50%] train loss: 3.4771848731907085e-05 \n",
      "epoch: 6 [236643/888800 26.62%] train loss: 3.4837707062251866e-05 \n",
      "epoch: 6 [237754/888800 26.75%] train loss: 3.151499913656153e-05 \n",
      "epoch: 6 [238865/888800 26.88%] train loss: 4.276102117728442e-05 \n",
      "epoch: 6 [239976/888800 27.00%] train loss: 3.585016747820191e-05 \n",
      "epoch: 6 [241087/888800 27.12%] train loss: 3.119905886705965e-05 \n",
      "epoch: 6 [242198/888800 27.25%] train loss: 3.8261161535046995e-05 \n",
      "epoch: 6 [243309/888800 27.38%] train loss: 3.115230720140971e-05 \n",
      "epoch: 6 [244420/888800 27.50%] train loss: 4.2716568714240566e-05 \n",
      "epoch: 6 [245531/888800 27.62%] train loss: 4.012599674751982e-05 \n",
      "epoch: 6 [246642/888800 27.75%] train loss: 2.6204816094832495e-05 \n",
      "epoch: 6 [247753/888800 27.88%] train loss: 3.8062331441324204e-05 \n",
      "epoch: 6 [248864/888800 28.00%] train loss: 3.615358946262859e-05 \n",
      "epoch: 6 [249975/888800 28.12%] train loss: 3.0720992072019726e-05 \n",
      "epoch: 6 [251086/888800 28.25%] train loss: 3.8498317735502496e-05 \n",
      "epoch: 6 [252197/888800 28.38%] train loss: 3.714378544827923e-05 \n",
      "epoch: 6 [253308/888800 28.50%] train loss: 3.426856710575521e-05 \n",
      "epoch: 6 [254419/888800 28.62%] train loss: 4.165417340118438e-05 \n",
      "epoch: 6 [255530/888800 28.75%] train loss: 3.5466448025545105e-05 \n",
      "epoch: 6 [256641/888800 28.88%] train loss: 3.1506770028499886e-05 \n",
      "epoch: 6 [257752/888800 29.00%] train loss: 3.841638317680918e-05 \n",
      "epoch: 6 [258863/888800 29.12%] train loss: 3.4515564038883895e-05 \n",
      "epoch: 6 [259974/888800 29.25%] train loss: 3.9707814721623436e-05 \n",
      "epoch: 6 [261085/888800 29.38%] train loss: 3.3483382139820606e-05 \n",
      "epoch: 6 [262196/888800 29.50%] train loss: 3.162066423101351e-05 \n",
      "epoch: 6 [263307/888800 29.62%] train loss: 3.911577005055733e-05 \n",
      "epoch: 6 [264418/888800 29.75%] train loss: 3.4287160815438256e-05 \n",
      "epoch: 6 [265529/888800 29.88%] train loss: 3.4509197575971484e-05 \n",
      "epoch: 6 [266640/888800 30.00%] train loss: 3.3250413252972066e-05 \n",
      "epoch: 6 [267751/888800 30.12%] train loss: 3.65925116057042e-05 \n",
      "epoch: 6 [268862/888800 30.25%] train loss: 3.1638352083973587e-05 \n",
      "epoch: 6 [269973/888800 30.38%] train loss: 3.938268855563365e-05 \n",
      "epoch: 6 [271084/888800 30.50%] train loss: 3.669230864034034e-05 \n",
      "epoch: 6 [272195/888800 30.62%] train loss: 3.962956907344051e-05 \n",
      "epoch: 6 [273306/888800 30.75%] train loss: 3.352413477841765e-05 \n",
      "epoch: 6 [274417/888800 30.88%] train loss: 3.270641536801122e-05 \n",
      "epoch: 6 [275528/888800 31.00%] train loss: 3.6648911191150546e-05 \n",
      "epoch: 6 [276639/888800 31.12%] train loss: 3.336615554871969e-05 \n",
      "epoch: 6 [277750/888800 31.25%] train loss: 3.488400034257211e-05 \n",
      "epoch: 6 [278861/888800 31.38%] train loss: 3.635747270891443e-05 \n",
      "epoch: 6 [279972/888800 31.50%] train loss: 3.029178515134845e-05 \n",
      "epoch: 6 [281083/888800 31.62%] train loss: 3.942918556276709e-05 \n",
      "epoch: 6 [282194/888800 31.75%] train loss: 3.553988062776625e-05 \n",
      "epoch: 6 [283305/888800 31.88%] train loss: 3.061220922973007e-05 \n",
      "epoch: 6 [284416/888800 32.00%] train loss: 3.886601916747168e-05 \n",
      "epoch: 6 [285527/888800 32.12%] train loss: 3.787511013797484e-05 \n",
      "epoch: 6 [286638/888800 32.25%] train loss: 3.6756202462129295e-05 \n",
      "epoch: 6 [287749/888800 32.38%] train loss: 3.472341995802708e-05 \n",
      "epoch: 6 [288860/888800 32.50%] train loss: 3.5562028642743826e-05 \n",
      "epoch: 6 [289971/888800 32.62%] train loss: 3.485749402898364e-05 \n",
      "epoch: 6 [291082/888800 32.75%] train loss: 3.564960206858814e-05 \n",
      "epoch: 6 [292193/888800 32.88%] train loss: 4.121669917367399e-05 \n",
      "epoch: 6 [293304/888800 33.00%] train loss: 2.818611028487794e-05 \n",
      "epoch: 6 [294415/888800 33.12%] train loss: 4.226529927109368e-05 \n",
      "epoch: 6 [295526/888800 33.25%] train loss: 3.535165888024494e-05 \n",
      "epoch: 6 [296637/888800 33.38%] train loss: 3.043639298994094e-05 \n",
      "epoch: 6 [297748/888800 33.50%] train loss: 3.451737211435102e-05 \n",
      "epoch: 6 [298859/888800 33.62%] train loss: 3.1136478355620056e-05 \n",
      "epoch: 6 [299970/888800 33.75%] train loss: 3.1212697649607435e-05 \n",
      "epoch: 6 [301081/888800 33.88%] train loss: 3.698861110024154e-05 \n",
      "epoch: 6 [302192/888800 34.00%] train loss: 3.487952199066058e-05 \n",
      "epoch: 6 [303303/888800 34.12%] train loss: 2.86503964161966e-05 \n",
      "epoch: 6 [304414/888800 34.25%] train loss: 3.650195139925927e-05 \n",
      "epoch: 6 [305525/888800 34.38%] train loss: 4.223939322400838e-05 \n",
      "epoch: 6 [306636/888800 34.50%] train loss: 4.056497709825635e-05 \n",
      "epoch: 6 [307747/888800 34.62%] train loss: 3.2720858143875375e-05 \n",
      "epoch: 6 [308858/888800 34.75%] train loss: 3.7010599044151604e-05 \n",
      "epoch: 6 [309969/888800 34.88%] train loss: 2.9348046155064367e-05 \n",
      "epoch: 6 [311080/888800 35.00%] train loss: 3.7691075704060495e-05 \n",
      "epoch: 6 [312191/888800 35.12%] train loss: 3.645472679636441e-05 \n",
      "epoch: 6 [313302/888800 35.25%] train loss: 3.713480691658333e-05 \n",
      "epoch: 6 [314413/888800 35.38%] train loss: 3.751722033484839e-05 \n",
      "epoch: 6 [315524/888800 35.50%] train loss: 3.482908141450025e-05 \n",
      "epoch: 6 [316635/888800 35.62%] train loss: 4.112333772354759e-05 \n",
      "epoch: 6 [317746/888800 35.75%] train loss: 3.2127918530022725e-05 \n",
      "epoch: 6 [318857/888800 35.88%] train loss: 3.0462771974271163e-05 \n",
      "epoch: 6 [319968/888800 36.00%] train loss: 3.616453614085913e-05 \n",
      "epoch: 6 [321079/888800 36.12%] train loss: 3.6863453715341166e-05 \n",
      "epoch: 6 [322190/888800 36.25%] train loss: 3.581252894946374e-05 \n",
      "epoch: 6 [323301/888800 36.38%] train loss: 3.372450009919703e-05 \n",
      "epoch: 6 [324412/888800 36.50%] train loss: 3.311390901217237e-05 \n",
      "epoch: 6 [325523/888800 36.62%] train loss: 3.001325239893049e-05 \n",
      "epoch: 6 [326634/888800 36.75%] train loss: 3.651961014838889e-05 \n",
      "epoch: 6 [327745/888800 36.88%] train loss: 3.966302756452933e-05 \n",
      "epoch: 6 [328856/888800 37.00%] train loss: 4.100917067262344e-05 \n",
      "epoch: 6 [329967/888800 37.12%] train loss: 3.647722041932866e-05 \n",
      "epoch: 6 [331078/888800 37.25%] train loss: 3.5078668588539585e-05 \n",
      "epoch: 6 [332189/888800 37.38%] train loss: 3.5223074519308284e-05 \n",
      "epoch: 6 [333300/888800 37.50%] train loss: 3.536172880558297e-05 \n",
      "epoch: 6 [334411/888800 37.62%] train loss: 3.979145549237728e-05 \n",
      "epoch: 6 [335522/888800 37.75%] train loss: 3.946444849134423e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [336633/888800 37.88%] train loss: 3.2523978006793186e-05 \n",
      "epoch: 6 [337744/888800 38.00%] train loss: 3.330179606564343e-05 \n",
      "epoch: 6 [338855/888800 38.12%] train loss: 3.838372867903672e-05 \n",
      "epoch: 6 [339966/888800 38.25%] train loss: 3.6047214962309226e-05 \n",
      "epoch: 6 [341077/888800 38.38%] train loss: 3.69885383406654e-05 \n",
      "epoch: 6 [342188/888800 38.50%] train loss: 3.450591248110868e-05 \n",
      "epoch: 6 [343299/888800 38.62%] train loss: 3.117797677987255e-05 \n",
      "epoch: 6 [344410/888800 38.75%] train loss: 3.647506673587486e-05 \n",
      "epoch: 6 [345521/888800 38.88%] train loss: 4.082973100594245e-05 \n",
      "epoch: 6 [346632/888800 39.00%] train loss: 3.2998985261656344e-05 \n",
      "epoch: 6 [347743/888800 39.12%] train loss: 3.9125334296841174e-05 \n",
      "epoch: 6 [348854/888800 39.25%] train loss: 3.862187440972775e-05 \n",
      "epoch: 6 [349965/888800 39.38%] train loss: 3.906017082044855e-05 \n",
      "epoch: 6 [351076/888800 39.50%] train loss: 3.2618045224808156e-05 \n",
      "epoch: 6 [352187/888800 39.62%] train loss: 3.1376828701468185e-05 \n",
      "epoch: 6 [353298/888800 39.75%] train loss: 3.7580834032269195e-05 \n",
      "epoch: 6 [354409/888800 39.88%] train loss: 3.5343986382940784e-05 \n",
      "epoch: 6 [355520/888800 40.00%] train loss: 3.773337448365055e-05 \n",
      "epoch: 6 [356631/888800 40.12%] train loss: 3.349509643157944e-05 \n",
      "epoch: 6 [357742/888800 40.25%] train loss: 3.3051645004888996e-05 \n",
      "epoch: 6 [358853/888800 40.38%] train loss: 3.5620523703983054e-05 \n",
      "epoch: 6 [359964/888800 40.50%] train loss: 3.847483458230272e-05 \n",
      "epoch: 6 [361075/888800 40.62%] train loss: 2.8973649023100734e-05 \n",
      "epoch: 6 [362186/888800 40.75%] train loss: 3.4331707865931094e-05 \n",
      "epoch: 6 [363297/888800 40.88%] train loss: 3.173504592268728e-05 \n",
      "epoch: 6 [364408/888800 41.00%] train loss: 3.859210846712813e-05 \n",
      "epoch: 6 [365519/888800 41.12%] train loss: 2.916763514804188e-05 \n",
      "epoch: 6 [366630/888800 41.25%] train loss: 2.6839317797566764e-05 \n",
      "epoch: 6 [367741/888800 41.38%] train loss: 3.697810825542547e-05 \n",
      "epoch: 6 [368852/888800 41.50%] train loss: 3.6401510442374274e-05 \n",
      "epoch: 6 [369963/888800 41.62%] train loss: 3.8440804928541183e-05 \n",
      "epoch: 6 [371074/888800 41.75%] train loss: 3.032475979125593e-05 \n",
      "epoch: 6 [372185/888800 41.88%] train loss: 3.5935459891334176e-05 \n",
      "epoch: 6 [373296/888800 42.00%] train loss: 3.0563856853405014e-05 \n",
      "epoch: 6 [374407/888800 42.12%] train loss: 3.266477142460644e-05 \n",
      "epoch: 6 [375518/888800 42.25%] train loss: 3.233651295886375e-05 \n",
      "epoch: 6 [376629/888800 42.38%] train loss: 3.883742829202674e-05 \n",
      "epoch: 6 [377740/888800 42.50%] train loss: 4.090421134606004e-05 \n",
      "epoch: 6 [378851/888800 42.62%] train loss: 3.801342609222047e-05 \n",
      "epoch: 6 [379962/888800 42.75%] train loss: 4.263092341716401e-05 \n",
      "epoch: 6 [381073/888800 42.88%] train loss: 3.7726011214545e-05 \n",
      "epoch: 6 [382184/888800 43.00%] train loss: 3.4261454857187346e-05 \n",
      "epoch: 6 [383295/888800 43.12%] train loss: 3.0259541745181195e-05 \n",
      "epoch: 6 [384406/888800 43.25%] train loss: 3.730018943315372e-05 \n",
      "epoch: 6 [385517/888800 43.38%] train loss: 3.150909105897881e-05 \n",
      "epoch: 6 [386628/888800 43.50%] train loss: 3.9054932130966336e-05 \n",
      "epoch: 6 [387739/888800 43.62%] train loss: 3.777274105232209e-05 \n",
      "epoch: 6 [388850/888800 43.75%] train loss: 3.705436029122211e-05 \n",
      "epoch: 6 [389961/888800 43.88%] train loss: 3.510488386382349e-05 \n",
      "epoch: 6 [391072/888800 44.00%] train loss: 3.5959641536464915e-05 \n",
      "epoch: 6 [392183/888800 44.12%] train loss: 3.7465873901965097e-05 \n",
      "epoch: 6 [393294/888800 44.25%] train loss: 3.589891639421694e-05 \n",
      "epoch: 6 [394405/888800 44.38%] train loss: 3.924269913113676e-05 \n",
      "epoch: 6 [395516/888800 44.50%] train loss: 3.061005918425508e-05 \n",
      "epoch: 6 [396627/888800 44.62%] train loss: 3.502294930513017e-05 \n",
      "epoch: 6 [397738/888800 44.75%] train loss: 3.1138795748120174e-05 \n",
      "epoch: 6 [398849/888800 44.88%] train loss: 4.255488238413818e-05 \n",
      "epoch: 6 [399960/888800 45.00%] train loss: 3.207489135093056e-05 \n",
      "epoch: 6 [401071/888800 45.12%] train loss: 3.273264883318916e-05 \n",
      "epoch: 6 [402182/888800 45.25%] train loss: 3.2980784453684464e-05 \n",
      "epoch: 6 [403293/888800 45.38%] train loss: 4.001957131549716e-05 \n",
      "epoch: 6 [404404/888800 45.50%] train loss: 3.4607081033755094e-05 \n",
      "epoch: 6 [405515/888800 45.62%] train loss: 3.526102955220267e-05 \n",
      "epoch: 6 [406626/888800 45.75%] train loss: 3.372991341166198e-05 \n",
      "epoch: 6 [407737/888800 45.88%] train loss: 3.5714503610506654e-05 \n",
      "epoch: 6 [408848/888800 46.00%] train loss: 3.0945153412176296e-05 \n",
      "epoch: 6 [409959/888800 46.12%] train loss: 3.399415436433628e-05 \n",
      "epoch: 6 [411070/888800 46.25%] train loss: 3.347401070641354e-05 \n",
      "epoch: 6 [412181/888800 46.38%] train loss: 2.8326712708803825e-05 \n",
      "epoch: 6 [413292/888800 46.50%] train loss: 3.4915265132440254e-05 \n",
      "epoch: 6 [414403/888800 46.62%] train loss: 3.591399217839353e-05 \n",
      "epoch: 6 [415514/888800 46.75%] train loss: 3.881317388731986e-05 \n",
      "epoch: 6 [416625/888800 46.88%] train loss: 3.50673908542376e-05 \n",
      "epoch: 6 [417736/888800 47.00%] train loss: 2.630867857078556e-05 \n",
      "epoch: 6 [418847/888800 47.12%] train loss: 3.892186941811815e-05 \n",
      "epoch: 6 [419958/888800 47.25%] train loss: 2.9128155802027322e-05 \n",
      "epoch: 6 [421069/888800 47.38%] train loss: 2.8904001737828366e-05 \n",
      "epoch: 6 [422180/888800 47.50%] train loss: 3.1322815630119294e-05 \n",
      "epoch: 6 [423291/888800 47.62%] train loss: 3.570024637156166e-05 \n",
      "epoch: 6 [424402/888800 47.75%] train loss: 3.544470018823631e-05 \n",
      "epoch: 6 [425513/888800 47.88%] train loss: 2.3383368898066692e-05 \n",
      "epoch: 6 [426624/888800 48.00%] train loss: 3.596365058911033e-05 \n",
      "epoch: 6 [427735/888800 48.12%] train loss: 3.674282561405562e-05 \n",
      "epoch: 6 [428846/888800 48.25%] train loss: 3.5980341635877267e-05 \n",
      "epoch: 6 [429957/888800 48.38%] train loss: 4.0803155570756644e-05 \n",
      "epoch: 6 [431068/888800 48.50%] train loss: 3.1665898859500885e-05 \n",
      "epoch: 6 [432179/888800 48.62%] train loss: 3.557925811037421e-05 \n",
      "epoch: 6 [433290/888800 48.75%] train loss: 3.3576274290680885e-05 \n",
      "epoch: 6 [434401/888800 48.88%] train loss: 3.521520193316974e-05 \n",
      "epoch: 6 [435512/888800 49.00%] train loss: 3.3428455935791135e-05 \n",
      "epoch: 6 [436623/888800 49.12%] train loss: 4.1184703150065616e-05 \n",
      "epoch: 6 [437734/888800 49.25%] train loss: 3.379486224730499e-05 \n",
      "epoch: 6 [438845/888800 49.38%] train loss: 3.056473724427633e-05 \n",
      "epoch: 6 [439956/888800 49.50%] train loss: 3.7309851904865354e-05 \n",
      "epoch: 6 [441067/888800 49.62%] train loss: 3.805746746365912e-05 \n",
      "epoch: 6 [442178/888800 49.75%] train loss: 2.818295433826279e-05 \n",
      "epoch: 6 [443289/888800 49.88%] train loss: 3.903725519194268e-05 \n",
      "epoch: 6 [444400/888800 50.00%] train loss: 3.227341949241236e-05 \n",
      "epoch: 6 [445511/888800 50.12%] train loss: 3.626372927101329e-05 \n",
      "epoch: 6 [446622/888800 50.25%] train loss: 3.9480051782447845e-05 \n",
      "epoch: 6 [447733/888800 50.38%] train loss: 2.932201277872082e-05 \n",
      "epoch: 6 [448844/888800 50.50%] train loss: 3.648918936960399e-05 \n",
      "epoch: 6 [449955/888800 50.62%] train loss: 3.217875200789422e-05 \n",
      "epoch: 6 [451066/888800 50.75%] train loss: 3.230199945392087e-05 \n",
      "epoch: 6 [452177/888800 50.88%] train loss: 3.198837657691911e-05 \n",
      "epoch: 6 [453288/888800 51.00%] train loss: 3.7179645005380735e-05 \n",
      "epoch: 6 [454399/888800 51.12%] train loss: 3.589395055314526e-05 \n",
      "epoch: 6 [455510/888800 51.25%] train loss: 4.1228609916288406e-05 \n",
      "epoch: 6 [456621/888800 51.38%] train loss: 4.3053802073700354e-05 \n",
      "epoch: 6 [457732/888800 51.50%] train loss: 3.484514309093356e-05 \n",
      "epoch: 6 [458843/888800 51.62%] train loss: 3.847049447358586e-05 \n",
      "epoch: 6 [459954/888800 51.75%] train loss: 2.9049630029476248e-05 \n",
      "epoch: 6 [461065/888800 51.88%] train loss: 3.906329584424384e-05 \n",
      "epoch: 6 [462176/888800 52.00%] train loss: 3.646279583335854e-05 \n",
      "epoch: 6 [463287/888800 52.12%] train loss: 3.5856130125466734e-05 \n",
      "epoch: 6 [464398/888800 52.25%] train loss: 3.2946434657787904e-05 \n",
      "epoch: 6 [465509/888800 52.38%] train loss: 3.382725117262453e-05 \n",
      "epoch: 6 [466620/888800 52.50%] train loss: 3.1032217520987615e-05 \n",
      "epoch: 6 [467731/888800 52.62%] train loss: 3.254516559536569e-05 \n",
      "epoch: 6 [468842/888800 52.75%] train loss: 3.603738150559366e-05 \n",
      "epoch: 6 [469953/888800 52.88%] train loss: 3.733103221748024e-05 \n",
      "epoch: 6 [471064/888800 53.00%] train loss: 3.4107706596842036e-05 \n",
      "epoch: 6 [472175/888800 53.12%] train loss: 3.352319254190661e-05 \n",
      "epoch: 6 [473286/888800 53.25%] train loss: 3.96912764699664e-05 \n",
      "epoch: 6 [474397/888800 53.38%] train loss: 3.525039937812835e-05 \n",
      "epoch: 6 [475508/888800 53.50%] train loss: 3.3634842111496255e-05 \n",
      "epoch: 6 [476619/888800 53.62%] train loss: 3.509348971419968e-05 \n",
      "epoch: 6 [477730/888800 53.75%] train loss: 3.6957171687390655e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [478841/888800 53.88%] train loss: 3.8235040847212076e-05 \n",
      "epoch: 6 [479952/888800 54.00%] train loss: 4.0754806832410395e-05 \n",
      "epoch: 6 [481063/888800 54.12%] train loss: 3.727449802681804e-05 \n",
      "epoch: 6 [482174/888800 54.25%] train loss: 3.4172768209828064e-05 \n",
      "epoch: 6 [483285/888800 54.38%] train loss: 3.357414243509993e-05 \n",
      "epoch: 6 [484396/888800 54.50%] train loss: 3.869560896418989e-05 \n",
      "epoch: 6 [485507/888800 54.62%] train loss: 3.433037272770889e-05 \n",
      "epoch: 6 [486618/888800 54.75%] train loss: 3.1474613933824e-05 \n",
      "epoch: 6 [487729/888800 54.88%] train loss: 3.1887921068118885e-05 \n",
      "epoch: 6 [488840/888800 55.00%] train loss: 3.235799158574082e-05 \n",
      "epoch: 6 [489951/888800 55.12%] train loss: 4.059199636685662e-05 \n",
      "epoch: 6 [491062/888800 55.25%] train loss: 3.6003722925670445e-05 \n",
      "epoch: 6 [492173/888800 55.38%] train loss: 3.5501110687619075e-05 \n",
      "epoch: 6 [493284/888800 55.50%] train loss: 3.443665264057927e-05 \n",
      "epoch: 6 [494395/888800 55.62%] train loss: 3.389492485439405e-05 \n",
      "epoch: 6 [495506/888800 55.75%] train loss: 3.611305510275997e-05 \n",
      "epoch: 6 [496617/888800 55.88%] train loss: 3.555078728822991e-05 \n",
      "epoch: 6 [497728/888800 56.00%] train loss: 3.449913128861226e-05 \n",
      "epoch: 6 [498839/888800 56.12%] train loss: 3.6467157769948244e-05 \n",
      "epoch: 6 [499950/888800 56.25%] train loss: 3.8839065382489935e-05 \n",
      "epoch: 6 [501061/888800 56.38%] train loss: 2.8850157832494006e-05 \n",
      "epoch: 6 [502172/888800 56.50%] train loss: 3.1519131880486384e-05 \n",
      "epoch: 6 [503283/888800 56.62%] train loss: 3.241052763769403e-05 \n",
      "epoch: 6 [504394/888800 56.75%] train loss: 3.618441769503988e-05 \n",
      "epoch: 6 [505505/888800 56.88%] train loss: 3.569849650375545e-05 \n",
      "epoch: 6 [506616/888800 57.00%] train loss: 3.410746285226196e-05 \n",
      "epoch: 6 [507727/888800 57.12%] train loss: 2.666847467480693e-05 \n",
      "epoch: 6 [508838/888800 57.25%] train loss: 3.277892028563656e-05 \n",
      "epoch: 6 [509949/888800 57.38%] train loss: 3.680936788441613e-05 \n",
      "epoch: 6 [511060/888800 57.50%] train loss: 3.389800986042246e-05 \n",
      "epoch: 6 [512171/888800 57.62%] train loss: 3.778761674766429e-05 \n",
      "epoch: 6 [513282/888800 57.75%] train loss: 3.38816134899389e-05 \n",
      "epoch: 6 [514393/888800 57.88%] train loss: 3.433859455981292e-05 \n",
      "epoch: 6 [515504/888800 58.00%] train loss: 3.637102054199204e-05 \n",
      "epoch: 6 [516615/888800 58.12%] train loss: 3.596064561861567e-05 \n",
      "epoch: 6 [517726/888800 58.25%] train loss: 3.383943112567067e-05 \n",
      "epoch: 6 [518837/888800 58.38%] train loss: 3.4443612094037235e-05 \n",
      "epoch: 6 [519948/888800 58.50%] train loss: 3.283718251623213e-05 \n",
      "epoch: 6 [521059/888800 58.62%] train loss: 3.8284400943666697e-05 \n",
      "epoch: 6 [522170/888800 58.75%] train loss: 3.31102310155984e-05 \n",
      "epoch: 6 [523281/888800 58.88%] train loss: 2.8908072636113502e-05 \n",
      "epoch: 6 [524392/888800 59.00%] train loss: 3.6767509300261736e-05 \n",
      "epoch: 6 [525503/888800 59.12%] train loss: 3.211228977306746e-05 \n",
      "epoch: 6 [526614/888800 59.25%] train loss: 3.07655573124066e-05 \n",
      "epoch: 6 [527725/888800 59.38%] train loss: 3.1251576729118824e-05 \n",
      "epoch: 6 [528836/888800 59.50%] train loss: 3.003907113452442e-05 \n",
      "epoch: 6 [529947/888800 59.62%] train loss: 3.841282887151465e-05 \n",
      "epoch: 6 [531058/888800 59.75%] train loss: 3.183439184795134e-05 \n",
      "epoch: 6 [532169/888800 59.88%] train loss: 3.169216142850928e-05 \n",
      "epoch: 6 [533280/888800 60.00%] train loss: 3.3723918022587895e-05 \n",
      "epoch: 6 [534391/888800 60.12%] train loss: 3.2468502467963845e-05 \n",
      "epoch: 6 [535502/888800 60.25%] train loss: 3.614408342400566e-05 \n",
      "epoch: 6 [536613/888800 60.38%] train loss: 3.8724632759112865e-05 \n",
      "epoch: 6 [537724/888800 60.50%] train loss: 3.957820445066318e-05 \n",
      "epoch: 6 [538835/888800 60.62%] train loss: 3.4915752621600404e-05 \n",
      "epoch: 6 [539946/888800 60.75%] train loss: 3.6730169085785747e-05 \n",
      "epoch: 6 [541057/888800 60.88%] train loss: 3.373539948370308e-05 \n",
      "epoch: 6 [542168/888800 61.00%] train loss: 3.899598232237622e-05 \n",
      "epoch: 6 [543279/888800 61.12%] train loss: 3.602105061872862e-05 \n",
      "epoch: 6 [544390/888800 61.25%] train loss: 3.212745286873542e-05 \n",
      "epoch: 6 [545501/888800 61.38%] train loss: 3.186329558957368e-05 \n",
      "epoch: 6 [546612/888800 61.50%] train loss: 3.445922629907727e-05 \n",
      "epoch: 6 [547723/888800 61.62%] train loss: 3.2784791983431205e-05 \n",
      "epoch: 6 [548834/888800 61.75%] train loss: 3.736672442755662e-05 \n",
      "epoch: 6 [549945/888800 61.88%] train loss: 3.4690714528551325e-05 \n",
      "epoch: 6 [551056/888800 62.00%] train loss: 3.252507303841412e-05 \n",
      "epoch: 6 [552167/888800 62.12%] train loss: 3.588770414353348e-05 \n",
      "epoch: 6 [553278/888800 62.25%] train loss: 3.239563011447899e-05 \n",
      "epoch: 6 [554389/888800 62.38%] train loss: 2.896958903875202e-05 \n",
      "epoch: 6 [555500/888800 62.50%] train loss: 3.048738835786935e-05 \n",
      "epoch: 6 [556611/888800 62.62%] train loss: 3.69005101674702e-05 \n",
      "epoch: 6 [557722/888800 62.75%] train loss: 3.792425923165865e-05 \n",
      "epoch: 6 [558833/888800 62.88%] train loss: 3.676663982332684e-05 \n",
      "epoch: 6 [559944/888800 63.00%] train loss: 3.9642294723307714e-05 \n",
      "epoch: 6 [561055/888800 63.12%] train loss: 3.7907018850091845e-05 \n",
      "epoch: 6 [562166/888800 63.25%] train loss: 3.937091969419271e-05 \n",
      "epoch: 6 [563277/888800 63.38%] train loss: 3.144043148495257e-05 \n",
      "epoch: 6 [564388/888800 63.50%] train loss: 3.4009386581601575e-05 \n",
      "epoch: 6 [565499/888800 63.62%] train loss: 4.078982237842865e-05 \n",
      "epoch: 6 [566610/888800 63.75%] train loss: 3.843620652332902e-05 \n",
      "epoch: 6 [567721/888800 63.88%] train loss: 3.612147702369839e-05 \n",
      "epoch: 6 [568832/888800 64.00%] train loss: 2.8244156055734493e-05 \n",
      "epoch: 6 [569943/888800 64.12%] train loss: 3.34794276568573e-05 \n",
      "epoch: 6 [571054/888800 64.25%] train loss: 3.432513403822668e-05 \n",
      "epoch: 6 [572165/888800 64.38%] train loss: 3.834645031020045e-05 \n",
      "epoch: 6 [573276/888800 64.50%] train loss: 4.5038203097647056e-05 \n",
      "epoch: 6 [574387/888800 64.62%] train loss: 3.1665498681832105e-05 \n",
      "epoch: 6 [575498/888800 64.75%] train loss: 3.457905404502526e-05 \n",
      "epoch: 6 [576609/888800 64.88%] train loss: 3.5202894650865346e-05 \n",
      "epoch: 6 [577720/888800 65.00%] train loss: 3.628907143138349e-05 \n",
      "epoch: 6 [578831/888800 65.12%] train loss: 3.663663665065542e-05 \n",
      "epoch: 6 [579942/888800 65.25%] train loss: 3.847464540740475e-05 \n",
      "epoch: 6 [581053/888800 65.38%] train loss: 3.4595872421050444e-05 \n",
      "epoch: 6 [582164/888800 65.50%] train loss: 3.6566103517543525e-05 \n",
      "epoch: 6 [583275/888800 65.62%] train loss: 3.2039766665548086e-05 \n",
      "epoch: 6 [584386/888800 65.75%] train loss: 3.961569018429145e-05 \n",
      "epoch: 6 [585497/888800 65.88%] train loss: 3.4609289286891e-05 \n",
      "epoch: 6 [586608/888800 66.00%] train loss: 3.5833636502502486e-05 \n",
      "epoch: 6 [587719/888800 66.12%] train loss: 4.2035768274217844e-05 \n",
      "epoch: 6 [588830/888800 66.25%] train loss: 3.7757559766760096e-05 \n",
      "epoch: 6 [589941/888800 66.38%] train loss: 3.523196937749162e-05 \n",
      "epoch: 6 [591052/888800 66.50%] train loss: 4.0280363464262336e-05 \n",
      "epoch: 6 [592163/888800 66.62%] train loss: 4.093139432370663e-05 \n",
      "epoch: 6 [593274/888800 66.75%] train loss: 3.619460039772093e-05 \n",
      "epoch: 6 [594385/888800 66.88%] train loss: 2.923293322965037e-05 \n",
      "epoch: 6 [595496/888800 67.00%] train loss: 2.9837026886525564e-05 \n",
      "epoch: 6 [596607/888800 67.12%] train loss: 3.4859262086683884e-05 \n",
      "epoch: 6 [597718/888800 67.25%] train loss: 3.280913733760826e-05 \n",
      "epoch: 6 [598829/888800 67.38%] train loss: 4.035656093037687e-05 \n",
      "epoch: 6 [599940/888800 67.50%] train loss: 3.402799120522104e-05 \n",
      "epoch: 6 [601051/888800 67.62%] train loss: 3.2139942049980164e-05 \n",
      "epoch: 6 [602162/888800 67.75%] train loss: 3.338116948725656e-05 \n",
      "epoch: 6 [603273/888800 67.88%] train loss: 3.902192474924959e-05 \n",
      "epoch: 6 [604384/888800 68.00%] train loss: 3.023516183020547e-05 \n",
      "epoch: 6 [605495/888800 68.12%] train loss: 3.696604471770115e-05 \n",
      "epoch: 6 [606606/888800 68.25%] train loss: 3.4549488191260025e-05 \n",
      "epoch: 6 [607717/888800 68.38%] train loss: 3.1173356546787545e-05 \n",
      "epoch: 6 [608828/888800 68.50%] train loss: 3.817624747171067e-05 \n",
      "epoch: 6 [609939/888800 68.62%] train loss: 3.63731051038485e-05 \n",
      "epoch: 6 [611050/888800 68.75%] train loss: 3.401066715014167e-05 \n",
      "epoch: 6 [612161/888800 68.88%] train loss: 3.6133129469817504e-05 \n",
      "epoch: 6 [613272/888800 69.00%] train loss: 3.413765080040321e-05 \n",
      "epoch: 6 [614383/888800 69.12%] train loss: 3.300717435195111e-05 \n",
      "epoch: 6 [615494/888800 69.25%] train loss: 3.281983663327992e-05 \n",
      "epoch: 6 [616605/888800 69.38%] train loss: 3.1932504498399794e-05 \n",
      "epoch: 6 [617716/888800 69.50%] train loss: 3.342030686326325e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [618827/888800 69.62%] train loss: 3.470924639259465e-05 \n",
      "epoch: 6 [619938/888800 69.75%] train loss: 3.0990813684184104e-05 \n",
      "epoch: 6 [621049/888800 69.88%] train loss: 3.621591895353049e-05 \n",
      "epoch: 6 [622160/888800 70.00%] train loss: 3.338660826557316e-05 \n",
      "epoch: 6 [623271/888800 70.12%] train loss: 3.2712141546653584e-05 \n",
      "epoch: 6 [624382/888800 70.25%] train loss: 3.103769267909229e-05 \n",
      "epoch: 6 [625493/888800 70.38%] train loss: 2.933899304480292e-05 \n",
      "epoch: 6 [626604/888800 70.50%] train loss: 3.663285679067485e-05 \n",
      "epoch: 6 [627715/888800 70.62%] train loss: 3.1102055800147355e-05 \n",
      "epoch: 6 [628826/888800 70.75%] train loss: 3.696937346830964e-05 \n",
      "epoch: 6 [629937/888800 70.88%] train loss: 3.1816420232644305e-05 \n",
      "epoch: 6 [631048/888800 71.00%] train loss: 3.204544191248715e-05 \n",
      "epoch: 6 [632159/888800 71.12%] train loss: 3.884921170538291e-05 \n",
      "epoch: 6 [633270/888800 71.25%] train loss: 3.337774978717789e-05 \n",
      "epoch: 6 [634381/888800 71.38%] train loss: 3.1608797144144773e-05 \n",
      "epoch: 6 [635492/888800 71.50%] train loss: 3.1963736546458676e-05 \n",
      "epoch: 6 [636603/888800 71.62%] train loss: 3.143789217574522e-05 \n",
      "epoch: 6 [637714/888800 71.75%] train loss: 2.7734213290386833e-05 \n",
      "epoch: 6 [638825/888800 71.88%] train loss: 4.2061674321303144e-05 \n",
      "epoch: 6 [639936/888800 72.00%] train loss: 3.5953962651547045e-05 \n",
      "epoch: 6 [641047/888800 72.12%] train loss: 3.096138243563473e-05 \n",
      "epoch: 6 [642158/888800 72.25%] train loss: 3.547464439179748e-05 \n",
      "epoch: 6 [643269/888800 72.38%] train loss: 3.6307454138295725e-05 \n",
      "epoch: 6 [644380/888800 72.50%] train loss: 3.0611063266405836e-05 \n",
      "epoch: 6 [645491/888800 72.62%] train loss: 3.706053030327894e-05 \n",
      "epoch: 6 [646602/888800 72.75%] train loss: 2.572545054135844e-05 \n",
      "epoch: 6 [647713/888800 72.88%] train loss: 3.1739513360662386e-05 \n",
      "epoch: 6 [648824/888800 73.00%] train loss: 3.1010287784738466e-05 \n",
      "epoch: 6 [649935/888800 73.12%] train loss: 3.85030907636974e-05 \n",
      "epoch: 6 [651046/888800 73.25%] train loss: 3.4794677048921585e-05 \n",
      "epoch: 6 [652157/888800 73.38%] train loss: 3.891937012667768e-05 \n",
      "epoch: 6 [653268/888800 73.50%] train loss: 3.1713334465166554e-05 \n",
      "epoch: 6 [654379/888800 73.62%] train loss: 3.0407258236664347e-05 \n",
      "epoch: 6 [655490/888800 73.75%] train loss: 3.133543214062229e-05 \n",
      "epoch: 6 [656601/888800 73.88%] train loss: 3.6669338442152366e-05 \n",
      "epoch: 6 [657712/888800 74.00%] train loss: 3.160707274219021e-05 \n",
      "epoch: 6 [658823/888800 74.12%] train loss: 4.0283441194333136e-05 \n",
      "epoch: 6 [659934/888800 74.25%] train loss: 2.8343461963231675e-05 \n",
      "epoch: 6 [661045/888800 74.38%] train loss: 3.3924337913049385e-05 \n",
      "epoch: 6 [662156/888800 74.50%] train loss: 3.4194130421383306e-05 \n",
      "epoch: 6 [663267/888800 74.62%] train loss: 3.086234937654808e-05 \n",
      "epoch: 6 [664378/888800 74.75%] train loss: 3.8564878195757046e-05 \n",
      "epoch: 6 [665489/888800 74.88%] train loss: 3.688341166707687e-05 \n",
      "epoch: 6 [666600/888800 75.00%] train loss: 3.176986501784995e-05 \n",
      "epoch: 6 [667711/888800 75.12%] train loss: 3.3826916478574276e-05 \n",
      "epoch: 6 [668822/888800 75.25%] train loss: 3.557244053808972e-05 \n",
      "epoch: 6 [669933/888800 75.38%] train loss: 3.128881144220941e-05 \n",
      "epoch: 6 [671044/888800 75.50%] train loss: 3.225084947189316e-05 \n",
      "epoch: 6 [672155/888800 75.62%] train loss: 3.0072022127569653e-05 \n",
      "epoch: 6 [673266/888800 75.75%] train loss: 3.3648640965111554e-05 \n",
      "epoch: 6 [674377/888800 75.88%] train loss: 3.673735773190856e-05 \n",
      "epoch: 6 [675488/888800 76.00%] train loss: 3.779921098612249e-05 \n",
      "epoch: 6 [676599/888800 76.12%] train loss: 3.534441930241883e-05 \n",
      "epoch: 6 [677710/888800 76.25%] train loss: 3.1249961466528475e-05 \n",
      "epoch: 6 [678821/888800 76.38%] train loss: 3.331285188323818e-05 \n",
      "epoch: 6 [679932/888800 76.50%] train loss: 3.146141898469068e-05 \n",
      "epoch: 6 [681043/888800 76.62%] train loss: 3.354962245794013e-05 \n",
      "epoch: 6 [682154/888800 76.75%] train loss: 3.3742668165359646e-05 \n",
      "epoch: 6 [683265/888800 76.88%] train loss: 3.079689486185089e-05 \n",
      "epoch: 6 [684376/888800 77.00%] train loss: 4.000539775006473e-05 \n",
      "epoch: 6 [685487/888800 77.12%] train loss: 3.575384835130535e-05 \n",
      "epoch: 6 [686598/888800 77.25%] train loss: 3.280973760411143e-05 \n",
      "epoch: 6 [687709/888800 77.38%] train loss: 3.4699834941420704e-05 \n",
      "epoch: 6 [688820/888800 77.50%] train loss: 3.125119474134408e-05 \n",
      "epoch: 6 [689931/888800 77.62%] train loss: 3.57018579961732e-05 \n",
      "epoch: 6 [691042/888800 77.75%] train loss: 3.140037733828649e-05 \n",
      "epoch: 6 [692153/888800 77.88%] train loss: 3.5442742955638096e-05 \n",
      "epoch: 6 [693264/888800 78.00%] train loss: 3.4593020245665684e-05 \n",
      "epoch: 6 [694375/888800 78.12%] train loss: 3.7524430808844045e-05 \n",
      "epoch: 6 [695486/888800 78.25%] train loss: 4.096741758985445e-05 \n",
      "epoch: 6 [696597/888800 78.38%] train loss: 3.62823047908023e-05 \n",
      "epoch: 6 [697708/888800 78.50%] train loss: 3.419653148739599e-05 \n",
      "epoch: 6 [698819/888800 78.62%] train loss: 3.144258516840637e-05 \n",
      "epoch: 6 [699930/888800 78.75%] train loss: 3.0927305488148704e-05 \n",
      "epoch: 6 [701041/888800 78.88%] train loss: 2.945929554698523e-05 \n",
      "epoch: 6 [702152/888800 79.00%] train loss: 3.012903471244499e-05 \n",
      "epoch: 6 [703263/888800 79.12%] train loss: 2.4597893570899032e-05 \n",
      "epoch: 6 [704374/888800 79.25%] train loss: 3.6435329093365e-05 \n",
      "epoch: 6 [705485/888800 79.38%] train loss: 3.685497722472064e-05 \n",
      "epoch: 6 [706596/888800 79.50%] train loss: 3.4331893402850255e-05 \n",
      "epoch: 6 [707707/888800 79.62%] train loss: 3.6986129998695105e-05 \n",
      "epoch: 6 [708818/888800 79.75%] train loss: 3.140230182907544e-05 \n",
      "epoch: 6 [709929/888800 79.88%] train loss: 3.4344830055488274e-05 \n",
      "epoch: 6 [711040/888800 80.00%] train loss: 3.3024116419255733e-05 \n",
      "epoch: 6 [712151/888800 80.12%] train loss: 2.7511565349414013e-05 \n",
      "epoch: 6 [713262/888800 80.25%] train loss: 3.459424260654487e-05 \n",
      "epoch: 6 [714373/888800 80.38%] train loss: 2.8678599846898578e-05 \n",
      "epoch: 6 [715484/888800 80.50%] train loss: 3.474545883364044e-05 \n",
      "epoch: 6 [716595/888800 80.62%] train loss: 3.344085780554451e-05 \n",
      "epoch: 6 [717706/888800 80.75%] train loss: 3.005661528732162e-05 \n",
      "epoch: 6 [718817/888800 80.88%] train loss: 3.375137021066621e-05 \n",
      "epoch: 6 [719928/888800 81.00%] train loss: 3.116630978183821e-05 \n",
      "epoch: 6 [721039/888800 81.12%] train loss: 3.3566218917258084e-05 \n",
      "epoch: 6 [722150/888800 81.25%] train loss: 3.689672303153202e-05 \n",
      "epoch: 6 [723261/888800 81.38%] train loss: 2.997935371240601e-05 \n",
      "epoch: 6 [724372/888800 81.50%] train loss: 3.727794319274835e-05 \n",
      "epoch: 6 [725483/888800 81.62%] train loss: 3.1096049497136846e-05 \n",
      "epoch: 6 [726594/888800 81.75%] train loss: 2.6360155970905907e-05 \n",
      "epoch: 6 [727705/888800 81.88%] train loss: 3.5079781810054556e-05 \n",
      "epoch: 6 [728816/888800 82.00%] train loss: 2.8796648621209897e-05 \n",
      "epoch: 6 [729927/888800 82.12%] train loss: 3.188770278939046e-05 \n",
      "epoch: 6 [731038/888800 82.25%] train loss: 3.324146746308543e-05 \n",
      "epoch: 6 [732149/888800 82.38%] train loss: 3.469096918706782e-05 \n",
      "epoch: 6 [733260/888800 82.50%] train loss: 3.3929027267731726e-05 \n",
      "epoch: 6 [734371/888800 82.62%] train loss: 2.7653368306346238e-05 \n",
      "epoch: 6 [735482/888800 82.75%] train loss: 3.2305048080161214e-05 \n",
      "epoch: 6 [736593/888800 82.88%] train loss: 3.253329487051815e-05 \n",
      "epoch: 6 [737704/888800 83.00%] train loss: 3.483124964986928e-05 \n",
      "epoch: 6 [738815/888800 83.12%] train loss: 3.046782876481302e-05 \n",
      "epoch: 6 [739926/888800 83.25%] train loss: 3.051625026273541e-05 \n",
      "epoch: 6 [741037/888800 83.38%] train loss: 2.7741190933738835e-05 \n",
      "epoch: 6 [742148/888800 83.50%] train loss: 3.604554876801558e-05 \n",
      "epoch: 6 [743259/888800 83.62%] train loss: 3.3471587812528014e-05 \n",
      "epoch: 6 [744370/888800 83.75%] train loss: 3.753965938813053e-05 \n",
      "epoch: 6 [745481/888800 83.88%] train loss: 3.7348167097661644e-05 \n",
      "epoch: 6 [746592/888800 84.00%] train loss: 3.485680281301029e-05 \n",
      "epoch: 6 [747703/888800 84.12%] train loss: 3.076454595429823e-05 \n",
      "epoch: 6 [748814/888800 84.25%] train loss: 3.715526690939441e-05 \n",
      "epoch: 6 [749925/888800 84.38%] train loss: 2.9172444556024857e-05 \n",
      "epoch: 6 [751036/888800 84.50%] train loss: 2.7483751182444394e-05 \n",
      "epoch: 6 [752147/888800 84.62%] train loss: 3.869480133289471e-05 \n",
      "epoch: 6 [753258/888800 84.75%] train loss: 3.33449752361048e-05 \n",
      "epoch: 6 [754369/888800 84.88%] train loss: 3.77307333110366e-05 \n",
      "epoch: 6 [755480/888800 85.00%] train loss: 3.38651989295613e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 [756591/888800 85.12%] train loss: 3.4928874811157584e-05 \n",
      "epoch: 6 [757702/888800 85.25%] train loss: 3.18474521918688e-05 \n",
      "epoch: 6 [758813/888800 85.38%] train loss: 4.066483961651102e-05 \n",
      "epoch: 6 [759924/888800 85.50%] train loss: 3.0482744477922097e-05 \n",
      "epoch: 6 [761035/888800 85.62%] train loss: 3.507748988340609e-05 \n",
      "epoch: 6 [762146/888800 85.75%] train loss: 2.8892725822515786e-05 \n",
      "epoch: 6 [763257/888800 85.88%] train loss: 3.074505366384983e-05 \n",
      "epoch: 6 [764368/888800 86.00%] train loss: 3.268911314080469e-05 \n",
      "epoch: 6 [765479/888800 86.12%] train loss: 2.9791146516799927e-05 \n",
      "epoch: 6 [766590/888800 86.25%] train loss: 3.164961526636034e-05 \n",
      "epoch: 6 [767701/888800 86.38%] train loss: 3.5009881685255095e-05 \n",
      "epoch: 6 [768812/888800 86.50%] train loss: 3.180786006851122e-05 \n",
      "epoch: 6 [769923/888800 86.62%] train loss: 3.822789221885614e-05 \n",
      "epoch: 6 [771034/888800 86.75%] train loss: 3.296259819762781e-05 \n",
      "epoch: 6 [772145/888800 86.88%] train loss: 3.0983919714344665e-05 \n",
      "epoch: 6 [773256/888800 87.00%] train loss: 2.6673713364289142e-05 \n",
      "epoch: 6 [774367/888800 87.12%] train loss: 3.153291254420765e-05 \n",
      "epoch: 6 [775478/888800 87.25%] train loss: 2.9525668651331216e-05 \n",
      "epoch: 6 [776589/888800 87.38%] train loss: 2.9176397219998762e-05 \n",
      "epoch: 6 [777700/888800 87.50%] train loss: 3.0836799851385877e-05 \n",
      "epoch: 6 [778811/888800 87.62%] train loss: 3.220739745302126e-05 \n",
      "epoch: 6 [779922/888800 87.75%] train loss: 3.371402635821141e-05 \n",
      "epoch: 6 [781033/888800 87.88%] train loss: 2.865072929125745e-05 \n",
      "epoch: 6 [782144/888800 88.00%] train loss: 3.75232266378589e-05 \n",
      "epoch: 6 [783255/888800 88.12%] train loss: 3.1284373108064756e-05 \n",
      "epoch: 6 [784366/888800 88.25%] train loss: 3.229223148082383e-05 \n",
      "epoch: 6 [785477/888800 88.38%] train loss: 2.8457972803153098e-05 \n",
      "epoch: 6 [786588/888800 88.50%] train loss: 3.1068182579474524e-05 \n",
      "epoch: 6 [787699/888800 88.62%] train loss: 3.416879917494953e-05 \n",
      "epoch: 6 [788810/888800 88.75%] train loss: 2.9042294045211747e-05 \n",
      "epoch: 6 [789921/888800 88.88%] train loss: 3.412853766349144e-05 \n",
      "epoch: 6 [791032/888800 89.00%] train loss: 3.458371065789834e-05 \n",
      "epoch: 6 [792143/888800 89.12%] train loss: 3.8477603084174916e-05 \n",
      "epoch: 6 [793254/888800 89.25%] train loss: 3.374721927684732e-05 \n",
      "epoch: 6 [794365/888800 89.38%] train loss: 3.679241126519628e-05 \n",
      "epoch: 6 [795476/888800 89.50%] train loss: 2.887173104682006e-05 \n",
      "epoch: 6 [796587/888800 89.62%] train loss: 3.518169614835642e-05 \n",
      "epoch: 6 [797698/888800 89.75%] train loss: 3.000759352289606e-05 \n",
      "epoch: 6 [798809/888800 89.88%] train loss: 3.5554199712350965e-05 \n",
      "epoch: 6 [799920/888800 90.00%] train loss: 3.482752072159201e-05 \n",
      "epoch: 6 [801031/888800 90.12%] train loss: 3.271208697697148e-05 \n",
      "epoch: 6 [802142/888800 90.25%] train loss: 3.177954931743443e-05 \n",
      "epoch: 6 [803253/888800 90.38%] train loss: 2.99198927677935e-05 \n",
      "epoch: 6 [804364/888800 90.50%] train loss: 3.296579961897805e-05 \n",
      "epoch: 6 [805475/888800 90.62%] train loss: 3.4724675060715526e-05 \n",
      "epoch: 6 [806586/888800 90.75%] train loss: 3.495430792099796e-05 \n",
      "epoch: 6 [807697/888800 90.88%] train loss: 3.19351747748442e-05 \n",
      "epoch: 6 [808808/888800 91.00%] train loss: 3.046924393856898e-05 \n",
      "epoch: 6 [809919/888800 91.12%] train loss: 2.848905569408089e-05 \n",
      "epoch: 6 [811030/888800 91.25%] train loss: 3.7010373489465564e-05 \n",
      "epoch: 6 [812141/888800 91.38%] train loss: 2.7286947442917153e-05 \n",
      "epoch: 6 [813252/888800 91.50%] train loss: 3.139171894872561e-05 \n",
      "epoch: 6 [814363/888800 91.62%] train loss: 3.3833261113613844e-05 \n",
      "epoch: 6 [815474/888800 91.75%] train loss: 3.449627183726989e-05 \n",
      "epoch: 6 [816585/888800 91.88%] train loss: 3.4008058719336987e-05 \n",
      "epoch: 6 [817696/888800 92.00%] train loss: 3.5916436900151893e-05 \n",
      "epoch: 6 [818807/888800 92.12%] train loss: 3.589143307181075e-05 \n",
      "epoch: 6 [819918/888800 92.25%] train loss: 3.299818126833998e-05 \n",
      "epoch: 6 [821029/888800 92.38%] train loss: 2.9949946110718884e-05 \n",
      "epoch: 6 [822140/888800 92.50%] train loss: 3.519756137393415e-05 \n",
      "epoch: 6 [823251/888800 92.62%] train loss: 2.9572518542408943e-05 \n",
      "epoch: 6 [824362/888800 92.75%] train loss: 3.678074790514074e-05 \n",
      "epoch: 6 [825473/888800 92.88%] train loss: 3.0238661565817893e-05 \n",
      "epoch: 6 [826584/888800 93.00%] train loss: 3.6174282286083326e-05 \n",
      "epoch: 6 [827695/888800 93.12%] train loss: 3.0201368645066395e-05 \n",
      "epoch: 6 [828806/888800 93.25%] train loss: 3.856977491523139e-05 \n",
      "epoch: 6 [829917/888800 93.38%] train loss: 3.0659310141345486e-05 \n",
      "epoch: 6 [831028/888800 93.50%] train loss: 3.622359872679226e-05 \n",
      "epoch: 6 [832139/888800 93.62%] train loss: 3.278324584243819e-05 \n",
      "epoch: 6 [833250/888800 93.75%] train loss: 2.950539237644989e-05 \n",
      "epoch: 6 [834361/888800 93.88%] train loss: 3.2343210477847606e-05 \n",
      "epoch: 6 [835472/888800 94.00%] train loss: 3.053611362702213e-05 \n",
      "epoch: 6 [836583/888800 94.12%] train loss: 3.6258039472159e-05 \n",
      "epoch: 6 [837694/888800 94.25%] train loss: 3.0076207622187212e-05 \n",
      "epoch: 6 [838805/888800 94.38%] train loss: 3.821770224021748e-05 \n",
      "epoch: 6 [839916/888800 94.50%] train loss: 3.543053026078269e-05 \n",
      "epoch: 6 [841027/888800 94.62%] train loss: 2.9212465960881673e-05 \n",
      "epoch: 6 [842138/888800 94.75%] train loss: 2.7631340344669297e-05 \n",
      "epoch: 6 [843249/888800 94.88%] train loss: 3.694564657052979e-05 \n",
      "epoch: 6 [844360/888800 95.00%] train loss: 3.6168290534988046e-05 \n",
      "epoch: 6 [845471/888800 95.12%] train loss: 3.849930362775922e-05 \n",
      "epoch: 6 [846582/888800 95.25%] train loss: 3.067099169129506e-05 \n",
      "epoch: 6 [847693/888800 95.38%] train loss: 3.96004288631957e-05 \n",
      "epoch: 6 [848804/888800 95.50%] train loss: 3.783473221119493e-05 \n",
      "epoch: 6 [849915/888800 95.62%] train loss: 2.9819491828675382e-05 \n",
      "epoch: 6 [851026/888800 95.75%] train loss: 3.0185636205715127e-05 \n",
      "epoch: 6 [852137/888800 95.88%] train loss: 3.101386027992703e-05 \n",
      "epoch: 6 [853248/888800 96.00%] train loss: 4.2372859752504155e-05 \n",
      "epoch: 6 [854359/888800 96.12%] train loss: 3.218163692508824e-05 \n",
      "epoch: 6 [855470/888800 96.25%] train loss: 3.0583680199924856e-05 \n",
      "epoch: 6 [856581/888800 96.38%] train loss: 3.8548554584849626e-05 \n",
      "epoch: 6 [857692/888800 96.50%] train loss: 3.101247421000153e-05 \n",
      "epoch: 6 [858803/888800 96.62%] train loss: 3.41716076945886e-05 \n",
      "epoch: 6 [859914/888800 96.75%] train loss: 3.1929212127579376e-05 \n",
      "epoch: 6 [861025/888800 96.88%] train loss: 3.360176560818218e-05 \n",
      "epoch: 6 [862136/888800 97.00%] train loss: 3.379844929440878e-05 \n",
      "epoch: 6 [863247/888800 97.12%] train loss: 3.946420474676415e-05 \n",
      "epoch: 6 [864358/888800 97.25%] train loss: 3.611403008108027e-05 \n",
      "epoch: 6 [865469/888800 97.38%] train loss: 3.4592219890328124e-05 \n",
      "epoch: 6 [866580/888800 97.50%] train loss: 2.8192996978759766e-05 \n",
      "epoch: 6 [867691/888800 97.62%] train loss: 3.0014936783118173e-05 \n",
      "epoch: 6 [868802/888800 97.75%] train loss: 3.22502528433688e-05 \n",
      "epoch: 6 [869913/888800 97.88%] train loss: 2.9363851353991777e-05 \n",
      "epoch: 6 [871024/888800 98.00%] train loss: 3.2717980502638966e-05 \n",
      "epoch: 6 [872135/888800 98.12%] train loss: 3.231181835872121e-05 \n",
      "epoch: 6 [873246/888800 98.25%] train loss: 3.041399577341508e-05 \n",
      "epoch: 6 [874357/888800 98.38%] train loss: 2.9154196454328485e-05 \n",
      "epoch: 6 [875468/888800 98.50%] train loss: 3.666811971925199e-05 \n",
      "epoch: 6 [876579/888800 98.62%] train loss: 2.9856402761652134e-05 \n",
      "epoch: 6 [877690/888800 98.75%] train loss: 3.3182754123117775e-05 \n",
      "epoch: 6 [878801/888800 98.88%] train loss: 3.4366617910563946e-05 \n",
      "epoch: 6 [879912/888800 99.00%] train loss: 3.163324072374962e-05 \n",
      "epoch: 6 [881023/888800 99.12%] train loss: 3.4597134799696505e-05 \n",
      "epoch: 6 [882134/888800 99.25%] train loss: 3.300587195553817e-05 \n",
      "epoch: 6 [883245/888800 99.38%] train loss: 3.296183786005713e-05 \n",
      "epoch: 6 [884356/888800 99.50%] train loss: 3.028863648069091e-05 \n",
      "epoch: 6 [885467/888800 99.62%] train loss: 3.235287658753805e-05 \n",
      "epoch: 6 [886578/888800 99.75%] train loss: 4.279128916095942e-05 \n",
      "epoch: 6 [887689/888800 99.88%] train loss: 3.308117447886616e-05 \n",
      "epoch: 7 [0/888800 0.00%] train loss: 3.7385707400972024e-05 \n",
      "epoch: 7 [1111/888800 0.12%] train loss: 3.490572635200806e-05 \n",
      "epoch: 7 [2222/888800 0.25%] train loss: 3.42492749041412e-05 \n",
      "epoch: 7 [3333/888800 0.38%] train loss: 3.0127626814646646e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [4444/888800 0.50%] train loss: 3.065783312194981e-05 \n",
      "epoch: 7 [5555/888800 0.62%] train loss: 3.5518100048648193e-05 \n",
      "epoch: 7 [6666/888800 0.75%] train loss: 3.017898961843457e-05 \n",
      "epoch: 7 [7777/888800 0.88%] train loss: 3.3632390113780275e-05 \n",
      "epoch: 7 [8888/888800 1.00%] train loss: 2.779183523671236e-05 \n",
      "epoch: 7 [9999/888800 1.12%] train loss: 3.0782350222580135e-05 \n",
      "epoch: 7 [11110/888800 1.25%] train loss: 3.6610061215469614e-05 \n",
      "epoch: 7 [12221/888800 1.38%] train loss: 2.64907084783772e-05 \n",
      "epoch: 7 [13332/888800 1.50%] train loss: 3.1156418117461726e-05 \n",
      "epoch: 7 [14443/888800 1.62%] train loss: 3.826171450782567e-05 \n",
      "epoch: 7 [15554/888800 1.75%] train loss: 3.049295992241241e-05 \n",
      "epoch: 7 [16665/888800 1.88%] train loss: 3.596163878683001e-05 \n",
      "epoch: 7 [17776/888800 2.00%] train loss: 3.843141166726127e-05 \n",
      "epoch: 7 [18887/888800 2.12%] train loss: 2.947435677924659e-05 \n",
      "epoch: 7 [19998/888800 2.25%] train loss: 2.5926112357410602e-05 \n",
      "epoch: 7 [21109/888800 2.38%] train loss: 2.8901835321448743e-05 \n",
      "epoch: 7 [22220/888800 2.50%] train loss: 3.174571611452848e-05 \n",
      "epoch: 7 [23331/888800 2.62%] train loss: 3.113365892204456e-05 \n",
      "epoch: 7 [24442/888800 2.75%] train loss: 3.1931827834341675e-05 \n",
      "epoch: 7 [25553/888800 2.88%] train loss: 2.8369579013087787e-05 \n",
      "epoch: 7 [26664/888800 3.00%] train loss: 4.1155297367367893e-05 \n",
      "epoch: 7 [27775/888800 3.12%] train loss: 4.09052699978929e-05 \n",
      "epoch: 7 [28886/888800 3.25%] train loss: 3.6026787711307406e-05 \n",
      "epoch: 7 [29997/888800 3.38%] train loss: 3.241470767534338e-05 \n",
      "epoch: 7 [31108/888800 3.50%] train loss: 3.6199537134962156e-05 \n",
      "epoch: 7 [32219/888800 3.62%] train loss: 3.4778640838339925e-05 \n",
      "epoch: 7 [33330/888800 3.75%] train loss: 3.034488509001676e-05 \n",
      "epoch: 7 [34441/888800 3.88%] train loss: 3.626762190833688e-05 \n",
      "epoch: 7 [35552/888800 4.00%] train loss: 3.240761361666955e-05 \n",
      "epoch: 7 [36663/888800 4.12%] train loss: 2.7756099370890297e-05 \n",
      "epoch: 7 [37774/888800 4.25%] train loss: 3.318849849165417e-05 \n",
      "epoch: 7 [38885/888800 4.38%] train loss: 2.557428706495557e-05 \n",
      "epoch: 7 [39996/888800 4.50%] train loss: 2.800845686579123e-05 \n",
      "epoch: 7 [41107/888800 4.62%] train loss: 3.21828993037343e-05 \n",
      "epoch: 7 [42218/888800 4.75%] train loss: 3.50813934346661e-05 \n",
      "epoch: 7 [43329/888800 4.88%] train loss: 3.161105632898398e-05 \n",
      "epoch: 7 [44440/888800 5.00%] train loss: 3.4145745303248987e-05 \n",
      "epoch: 7 [45551/888800 5.12%] train loss: 3.305431891931221e-05 \n",
      "epoch: 7 [46662/888800 5.25%] train loss: 3.297663351986557e-05 \n",
      "epoch: 7 [47773/888800 5.38%] train loss: 3.2060608646133915e-05 \n",
      "epoch: 7 [48884/888800 5.50%] train loss: 3.520288737490773e-05 \n",
      "epoch: 7 [49995/888800 5.62%] train loss: 2.825120827765204e-05 \n",
      "epoch: 7 [51106/888800 5.75%] train loss: 3.645437027444132e-05 \n",
      "epoch: 7 [52217/888800 5.88%] train loss: 3.529406603774987e-05 \n",
      "epoch: 7 [53328/888800 6.00%] train loss: 2.793227213260252e-05 \n",
      "epoch: 7 [54439/888800 6.12%] train loss: 2.9594142688438296e-05 \n",
      "epoch: 7 [55550/888800 6.25%] train loss: 3.300736716482788e-05 \n",
      "epoch: 7 [56661/888800 6.38%] train loss: 3.440228829276748e-05 \n",
      "epoch: 7 [57772/888800 6.50%] train loss: 3.506504435790703e-05 \n",
      "epoch: 7 [58883/888800 6.62%] train loss: 3.252414535381831e-05 \n",
      "epoch: 7 [59994/888800 6.75%] train loss: 3.214579919585958e-05 \n",
      "epoch: 7 [61105/888800 6.88%] train loss: 3.074369305977598e-05 \n",
      "epoch: 7 [62216/888800 7.00%] train loss: 3.028834362339694e-05 \n",
      "epoch: 7 [63327/888800 7.12%] train loss: 3.4891632822109386e-05 \n",
      "epoch: 7 [64438/888800 7.25%] train loss: 3.229933281545527e-05 \n",
      "epoch: 7 [65549/888800 7.38%] train loss: 3.324864155729301e-05 \n",
      "epoch: 7 [66660/888800 7.50%] train loss: 3.0287905246950686e-05 \n",
      "epoch: 7 [67771/888800 7.62%] train loss: 3.70719499187544e-05 \n",
      "epoch: 7 [68882/888800 7.75%] train loss: 3.026116064575035e-05 \n",
      "epoch: 7 [69993/888800 7.88%] train loss: 3.0446653909166344e-05 \n",
      "epoch: 7 [71104/888800 8.00%] train loss: 2.9351411285460927e-05 \n",
      "epoch: 7 [72215/888800 8.12%] train loss: 3.3224896469619125e-05 \n",
      "epoch: 7 [73326/888800 8.25%] train loss: 2.9886150514357723e-05 \n",
      "epoch: 7 [74437/888800 8.38%] train loss: 3.383681905688718e-05 \n",
      "epoch: 7 [75548/888800 8.50%] train loss: 3.071402170462534e-05 \n",
      "epoch: 7 [76659/888800 8.62%] train loss: 3.5356857551960275e-05 \n",
      "epoch: 7 [77770/888800 8.75%] train loss: 2.999218850163743e-05 \n",
      "epoch: 7 [78881/888800 8.88%] train loss: 3.386737807886675e-05 \n",
      "epoch: 7 [79992/888800 9.00%] train loss: 3.089156234636903e-05 \n",
      "epoch: 7 [81103/888800 9.12%] train loss: 3.8210811908356845e-05 \n",
      "epoch: 7 [82214/888800 9.25%] train loss: 2.8498876417870633e-05 \n",
      "epoch: 7 [83325/888800 9.38%] train loss: 2.8626693165278994e-05 \n",
      "epoch: 7 [84436/888800 9.50%] train loss: 3.489867958705872e-05 \n",
      "epoch: 7 [85547/888800 9.62%] train loss: 3.472287789918482e-05 \n",
      "epoch: 7 [86658/888800 9.75%] train loss: 3.2784493669169024e-05 \n",
      "epoch: 7 [87769/888800 9.88%] train loss: 3.48073554050643e-05 \n",
      "epoch: 7 [88880/888800 10.00%] train loss: 3.544820356182754e-05 \n",
      "epoch: 7 [89991/888800 10.12%] train loss: 2.8835618650191464e-05 \n",
      "epoch: 7 [91102/888800 10.25%] train loss: 3.5864271922037005e-05 \n",
      "epoch: 7 [92213/888800 10.38%] train loss: 2.9502127290470526e-05 \n",
      "epoch: 7 [93324/888800 10.50%] train loss: 3.3340718800900504e-05 \n",
      "epoch: 7 [94435/888800 10.62%] train loss: 3.272002868470736e-05 \n",
      "epoch: 7 [95546/888800 10.75%] train loss: 2.530009442125447e-05 \n",
      "epoch: 7 [96657/888800 10.88%] train loss: 3.580060365493409e-05 \n",
      "epoch: 7 [97768/888800 11.00%] train loss: 3.539581666700542e-05 \n",
      "epoch: 7 [98879/888800 11.12%] train loss: 3.083779301960021e-05 \n",
      "epoch: 7 [99990/888800 11.25%] train loss: 3.627020487328991e-05 \n",
      "epoch: 7 [101101/888800 11.38%] train loss: 3.9039347029756755e-05 \n",
      "epoch: 7 [102212/888800 11.50%] train loss: 3.611969805206172e-05 \n",
      "epoch: 7 [103323/888800 11.62%] train loss: 3.495677447062917e-05 \n",
      "epoch: 7 [104434/888800 11.75%] train loss: 3.064165503019467e-05 \n",
      "epoch: 7 [105545/888800 11.88%] train loss: 3.485400520730764e-05 \n",
      "epoch: 7 [106656/888800 12.00%] train loss: 3.127129457425326e-05 \n",
      "epoch: 7 [107767/888800 12.12%] train loss: 3.278368239989504e-05 \n",
      "epoch: 7 [108878/888800 12.25%] train loss: 3.3361618989147246e-05 \n",
      "epoch: 7 [109989/888800 12.38%] train loss: 3.956253203796223e-05 \n",
      "epoch: 7 [111100/888800 12.50%] train loss: 2.6063349650939927e-05 \n",
      "epoch: 7 [112211/888800 12.62%] train loss: 2.6210469513898715e-05 \n",
      "epoch: 7 [113322/888800 12.75%] train loss: 2.809466423059348e-05 \n",
      "epoch: 7 [114433/888800 12.88%] train loss: 3.131149787805043e-05 \n",
      "epoch: 7 [115544/888800 13.00%] train loss: 2.8072721761418507e-05 \n",
      "epoch: 7 [116655/888800 13.12%] train loss: 3.6879679100820795e-05 \n",
      "epoch: 7 [117766/888800 13.25%] train loss: 3.09782953991089e-05 \n",
      "epoch: 7 [118877/888800 13.38%] train loss: 3.093725172220729e-05 \n",
      "epoch: 7 [119988/888800 13.50%] train loss: 2.9633232770720497e-05 \n",
      "epoch: 7 [121099/888800 13.62%] train loss: 3.158678737236187e-05 \n",
      "epoch: 7 [122210/888800 13.75%] train loss: 2.9394486773526296e-05 \n",
      "epoch: 7 [123321/888800 13.88%] train loss: 3.19584651151672e-05 \n",
      "epoch: 7 [124432/888800 14.00%] train loss: 2.568422132753767e-05 \n",
      "epoch: 7 [125543/888800 14.12%] train loss: 2.7966158086201176e-05 \n",
      "epoch: 7 [126654/888800 14.25%] train loss: 3.0322597012855113e-05 \n",
      "epoch: 7 [127765/888800 14.38%] train loss: 3.0355671697179787e-05 \n",
      "epoch: 7 [128876/888800 14.50%] train loss: 3.289595042588189e-05 \n",
      "epoch: 7 [129987/888800 14.62%] train loss: 3.447911512921564e-05 \n",
      "epoch: 7 [131098/888800 14.75%] train loss: 3.481056774035096e-05 \n",
      "epoch: 7 [132209/888800 14.88%] train loss: 3.3151907700812444e-05 \n",
      "epoch: 7 [133320/888800 15.00%] train loss: 3.027586171810981e-05 \n",
      "epoch: 7 [134431/888800 15.12%] train loss: 3.697483043652028e-05 \n",
      "epoch: 7 [135542/888800 15.25%] train loss: 3.181118881911971e-05 \n",
      "epoch: 7 [136653/888800 15.38%] train loss: 3.5158227547071874e-05 \n",
      "epoch: 7 [137764/888800 15.50%] train loss: 3.0509614589391276e-05 \n",
      "epoch: 7 [138875/888800 15.62%] train loss: 2.72070483333664e-05 \n",
      "epoch: 7 [139986/888800 15.75%] train loss: 3.3341766538796946e-05 \n",
      "epoch: 7 [141097/888800 15.88%] train loss: 2.8808395654777996e-05 \n",
      "epoch: 7 [142208/888800 16.00%] train loss: 3.516795550240204e-05 \n",
      "epoch: 7 [143319/888800 16.12%] train loss: 3.3161224564537406e-05 \n",
      "epoch: 7 [144430/888800 16.25%] train loss: 2.8534930606838316e-05 \n",
      "epoch: 7 [145541/888800 16.38%] train loss: 3.4645519917830825e-05 \n",
      "epoch: 7 [146652/888800 16.50%] train loss: 2.9543303753598593e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [147763/888800 16.62%] train loss: 3.6359328078106046e-05 \n",
      "epoch: 7 [148874/888800 16.75%] train loss: 2.7625317670754157e-05 \n",
      "epoch: 7 [149985/888800 16.88%] train loss: 3.2256550184683874e-05 \n",
      "epoch: 7 [151096/888800 17.00%] train loss: 3.11604562739376e-05 \n",
      "epoch: 7 [152207/888800 17.12%] train loss: 2.9985247238073498e-05 \n",
      "epoch: 7 [153318/888800 17.25%] train loss: 3.014372123288922e-05 \n",
      "epoch: 7 [154429/888800 17.38%] train loss: 2.99248695228016e-05 \n",
      "epoch: 7 [155540/888800 17.50%] train loss: 3.072522667935118e-05 \n",
      "epoch: 7 [156651/888800 17.62%] train loss: 3.2003867090679705e-05 \n",
      "epoch: 7 [157762/888800 17.75%] train loss: 2.6186533432337455e-05 \n",
      "epoch: 7 [158873/888800 17.88%] train loss: 2.9509443265851587e-05 \n",
      "epoch: 7 [159984/888800 18.00%] train loss: 2.7682890504365787e-05 \n",
      "epoch: 7 [161095/888800 18.12%] train loss: 3.186805042787455e-05 \n",
      "epoch: 7 [162206/888800 18.25%] train loss: 3.1715997465653345e-05 \n",
      "epoch: 7 [163317/888800 18.38%] train loss: 2.7817091904580593e-05 \n",
      "epoch: 7 [164428/888800 18.50%] train loss: 3.300666139693931e-05 \n",
      "epoch: 7 [165539/888800 18.62%] train loss: 3.131074845441617e-05 \n",
      "epoch: 7 [166650/888800 18.75%] train loss: 2.5686193112051114e-05 \n",
      "epoch: 7 [167761/888800 18.88%] train loss: 3.102011396549642e-05 \n",
      "epoch: 7 [168872/888800 19.00%] train loss: 3.5232544178143144e-05 \n",
      "epoch: 7 [169983/888800 19.12%] train loss: 2.79537052847445e-05 \n",
      "epoch: 7 [171094/888800 19.25%] train loss: 2.9935625207144767e-05 \n",
      "epoch: 7 [172205/888800 19.38%] train loss: 3.5830860724672675e-05 \n",
      "epoch: 7 [173316/888800 19.50%] train loss: 3.1990770366974175e-05 \n",
      "epoch: 7 [174427/888800 19.62%] train loss: 2.3091221009963192e-05 \n",
      "epoch: 7 [175538/888800 19.75%] train loss: 3.0470313504338264e-05 \n",
      "epoch: 7 [176649/888800 19.88%] train loss: 2.6391217033960856e-05 \n",
      "epoch: 7 [177760/888800 20.00%] train loss: 3.286770515842363e-05 \n",
      "epoch: 7 [178871/888800 20.12%] train loss: 3.700943125295453e-05 \n",
      "epoch: 7 [179982/888800 20.25%] train loss: 2.817739914462436e-05 \n",
      "epoch: 7 [181093/888800 20.38%] train loss: 2.999600110342726e-05 \n",
      "epoch: 7 [182204/888800 20.50%] train loss: 3.336029112688266e-05 \n",
      "epoch: 7 [183315/888800 20.62%] train loss: 3.2468378776684403e-05 \n",
      "epoch: 7 [184426/888800 20.75%] train loss: 2.9493878173525445e-05 \n",
      "epoch: 7 [185537/888800 20.88%] train loss: 3.3554297260707244e-05 \n",
      "epoch: 7 [186648/888800 21.00%] train loss: 3.167233080603182e-05 \n",
      "epoch: 7 [187759/888800 21.12%] train loss: 3.1956107704900205e-05 \n",
      "epoch: 7 [188870/888800 21.25%] train loss: 2.9551527404692024e-05 \n",
      "epoch: 7 [189981/888800 21.38%] train loss: 3.558656680979766e-05 \n",
      "epoch: 7 [191092/888800 21.50%] train loss: 3.5153298085788265e-05 \n",
      "epoch: 7 [192203/888800 21.62%] train loss: 3.5098306398140267e-05 \n",
      "epoch: 7 [193314/888800 21.75%] train loss: 2.5388377252966166e-05 \n",
      "epoch: 7 [194425/888800 21.88%] train loss: 3.519294114084914e-05 \n",
      "epoch: 7 [195536/888800 22.00%] train loss: 2.8944064979441464e-05 \n",
      "epoch: 7 [196647/888800 22.12%] train loss: 3.762758205994032e-05 \n",
      "epoch: 7 [197758/888800 22.25%] train loss: 2.916424818977248e-05 \n",
      "epoch: 7 [198869/888800 22.38%] train loss: 2.8281934646656737e-05 \n",
      "epoch: 7 [199980/888800 22.50%] train loss: 2.8451857360778376e-05 \n",
      "epoch: 7 [201091/888800 22.62%] train loss: 2.7805243007605895e-05 \n",
      "epoch: 7 [202202/888800 22.75%] train loss: 3.0226114176912233e-05 \n",
      "epoch: 7 [203313/888800 22.88%] train loss: 2.9495709895854816e-05 \n",
      "epoch: 7 [204424/888800 23.00%] train loss: 3.189618291798979e-05 \n",
      "epoch: 7 [205535/888800 23.12%] train loss: 3.3476440876256675e-05 \n",
      "epoch: 7 [206646/888800 23.25%] train loss: 3.1077786843525246e-05 \n",
      "epoch: 7 [207757/888800 23.38%] train loss: 3.285048660472967e-05 \n",
      "epoch: 7 [208868/888800 23.50%] train loss: 3.407163967494853e-05 \n",
      "epoch: 7 [209979/888800 23.62%] train loss: 3.603264121920802e-05 \n",
      "epoch: 7 [211090/888800 23.75%] train loss: 3.2052350434241816e-05 \n",
      "epoch: 7 [212201/888800 23.88%] train loss: 2.6711619284469634e-05 \n",
      "epoch: 7 [213312/888800 24.00%] train loss: 3.503501648083329e-05 \n",
      "epoch: 7 [214423/888800 24.12%] train loss: 3.4972028515767306e-05 \n",
      "epoch: 7 [215534/888800 24.25%] train loss: 2.8480682885856368e-05 \n",
      "epoch: 7 [216645/888800 24.38%] train loss: 2.7146774300490506e-05 \n",
      "epoch: 7 [217756/888800 24.50%] train loss: 3.589312473195605e-05 \n",
      "epoch: 7 [218867/888800 24.62%] train loss: 3.070271122851409e-05 \n",
      "epoch: 7 [219978/888800 24.75%] train loss: 3.0265204259194434e-05 \n",
      "epoch: 7 [221089/888800 24.88%] train loss: 2.8071608539903536e-05 \n",
      "epoch: 7 [222200/888800 25.00%] train loss: 3.4147837141063064e-05 \n",
      "epoch: 7 [223311/888800 25.12%] train loss: 3.3382359106326476e-05 \n",
      "epoch: 7 [224422/888800 25.25%] train loss: 3.451711745583452e-05 \n",
      "epoch: 7 [225533/888800 25.38%] train loss: 3.335834844619967e-05 \n",
      "epoch: 7 [226644/888800 25.50%] train loss: 3.2100600947160274e-05 \n",
      "epoch: 7 [227755/888800 25.62%] train loss: 3.255841147620231e-05 \n",
      "epoch: 7 [228866/888800 25.75%] train loss: 3.407424810575321e-05 \n",
      "epoch: 7 [229977/888800 25.88%] train loss: 3.394956365809776e-05 \n",
      "epoch: 7 [231088/888800 26.00%] train loss: 3.5471563023747876e-05 \n",
      "epoch: 7 [232199/888800 26.12%] train loss: 3.4066604712279513e-05 \n",
      "epoch: 7 [233310/888800 26.25%] train loss: 3.352656131028198e-05 \n",
      "epoch: 7 [234421/888800 26.38%] train loss: 3.4529337426647544e-05 \n",
      "epoch: 7 [235532/888800 26.50%] train loss: 3.652680607046932e-05 \n",
      "epoch: 7 [236643/888800 26.62%] train loss: 3.192957956343889e-05 \n",
      "epoch: 7 [237754/888800 26.75%] train loss: 2.9052087484160438e-05 \n",
      "epoch: 7 [238865/888800 26.88%] train loss: 2.746926838881336e-05 \n",
      "epoch: 7 [239976/888800 27.00%] train loss: 3.0209428587113507e-05 \n",
      "epoch: 7 [241087/888800 27.12%] train loss: 3.859533535433002e-05 \n",
      "epoch: 7 [242198/888800 27.25%] train loss: 3.392678627278656e-05 \n",
      "epoch: 7 [243309/888800 27.38%] train loss: 2.704912913031876e-05 \n",
      "epoch: 7 [244420/888800 27.50%] train loss: 3.237944474676624e-05 \n",
      "epoch: 7 [245531/888800 27.62%] train loss: 3.105003634118475e-05 \n",
      "epoch: 7 [246642/888800 27.75%] train loss: 3.057295180042274e-05 \n",
      "epoch: 7 [247753/888800 27.88%] train loss: 2.7563351977732964e-05 \n",
      "epoch: 7 [248864/888800 28.00%] train loss: 3.514235868351534e-05 \n",
      "epoch: 7 [249975/888800 28.12%] train loss: 3.060064773308113e-05 \n",
      "epoch: 7 [251086/888800 28.25%] train loss: 2.7219924959354103e-05 \n",
      "epoch: 7 [252197/888800 28.38%] train loss: 3.113234924967401e-05 \n",
      "epoch: 7 [253308/888800 28.50%] train loss: 3.253569229855202e-05 \n",
      "epoch: 7 [254419/888800 28.62%] train loss: 3.1559222406940535e-05 \n",
      "epoch: 7 [255530/888800 28.75%] train loss: 2.8692555133602582e-05 \n",
      "epoch: 7 [256641/888800 28.88%] train loss: 3.196236866642721e-05 \n",
      "epoch: 7 [257752/888800 29.00%] train loss: 3.0358805815922096e-05 \n",
      "epoch: 7 [258863/888800 29.12%] train loss: 3.327518061269075e-05 \n",
      "epoch: 7 [259974/888800 29.25%] train loss: 3.5469412978272885e-05 \n",
      "epoch: 7 [261085/888800 29.38%] train loss: 3.211247894796543e-05 \n",
      "epoch: 7 [262196/888800 29.50%] train loss: 2.8209411539137363e-05 \n",
      "epoch: 7 [263307/888800 29.62%] train loss: 2.946532731584739e-05 \n",
      "epoch: 7 [264418/888800 29.75%] train loss: 2.9525735953939147e-05 \n",
      "epoch: 7 [265529/888800 29.88%] train loss: 2.808743556670379e-05 \n",
      "epoch: 7 [266640/888800 30.00%] train loss: 3.0664403311675414e-05 \n",
      "epoch: 7 [267751/888800 30.12%] train loss: 3.202133302693255e-05 \n",
      "epoch: 7 [268862/888800 30.25%] train loss: 2.810642763506621e-05 \n",
      "epoch: 7 [269973/888800 30.38%] train loss: 3.19824721373152e-05 \n",
      "epoch: 7 [271084/888800 30.50%] train loss: 3.0223625799408183e-05 \n",
      "epoch: 7 [272195/888800 30.62%] train loss: 3.216952973161824e-05 \n",
      "epoch: 7 [273306/888800 30.75%] train loss: 2.9009543141000904e-05 \n",
      "epoch: 7 [274417/888800 30.88%] train loss: 3.409862983971834e-05 \n",
      "epoch: 7 [275528/888800 31.00%] train loss: 2.2282658392214216e-05 \n",
      "epoch: 7 [276639/888800 31.12%] train loss: 2.9249165891087614e-05 \n",
      "epoch: 7 [277750/888800 31.25%] train loss: 3.469949297141284e-05 \n",
      "epoch: 7 [278861/888800 31.38%] train loss: 2.8288915927987546e-05 \n",
      "epoch: 7 [279972/888800 31.50%] train loss: 2.864007547032088e-05 \n",
      "epoch: 7 [281083/888800 31.62%] train loss: 2.5957820980693214e-05 \n",
      "epoch: 7 [282194/888800 31.75%] train loss: 2.8292095521464944e-05 \n",
      "epoch: 7 [283305/888800 31.88%] train loss: 2.901655898313038e-05 \n",
      "epoch: 7 [284416/888800 32.00%] train loss: 2.6049210646306165e-05 \n",
      "epoch: 7 [285527/888800 32.12%] train loss: 3.0975588742876425e-05 \n",
      "epoch: 7 [286638/888800 32.25%] train loss: 3.1264098652172834e-05 \n",
      "epoch: 7 [287749/888800 32.38%] train loss: 3.085044590989128e-05 \n",
      "epoch: 7 [288860/888800 32.50%] train loss: 2.769876846286934e-05 \n",
      "epoch: 7 [289971/888800 32.62%] train loss: 2.9967466616653837e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [291082/888800 32.75%] train loss: 3.365174779901281e-05 \n",
      "epoch: 7 [292193/888800 32.88%] train loss: 3.070648745051585e-05 \n",
      "epoch: 7 [293304/888800 33.00%] train loss: 2.4985540221678093e-05 \n",
      "epoch: 7 [294415/888800 33.12%] train loss: 2.8032642148900777e-05 \n",
      "epoch: 7 [295526/888800 33.25%] train loss: 3.264846600359306e-05 \n",
      "epoch: 7 [296637/888800 33.38%] train loss: 2.9063494366710074e-05 \n",
      "epoch: 7 [297748/888800 33.50%] train loss: 3.576538438210264e-05 \n",
      "epoch: 7 [298859/888800 33.62%] train loss: 2.8188886062707752e-05 \n",
      "epoch: 7 [299970/888800 33.75%] train loss: 3.0964842153480276e-05 \n",
      "epoch: 7 [301081/888800 33.88%] train loss: 2.8506290618679486e-05 \n",
      "epoch: 7 [302192/888800 34.00%] train loss: 3.079356247326359e-05 \n",
      "epoch: 7 [303303/888800 34.12%] train loss: 3.3736028854036704e-05 \n",
      "epoch: 7 [304414/888800 34.25%] train loss: 3.3462347346358e-05 \n",
      "epoch: 7 [305525/888800 34.38%] train loss: 2.994150054291822e-05 \n",
      "epoch: 7 [306636/888800 34.50%] train loss: 3.2061096135294065e-05 \n",
      "epoch: 7 [307747/888800 34.62%] train loss: 3.3454449294367805e-05 \n",
      "epoch: 7 [308858/888800 34.75%] train loss: 2.5227658625226468e-05 \n",
      "epoch: 7 [309969/888800 34.88%] train loss: 3.368095713085495e-05 \n",
      "epoch: 7 [311080/888800 35.00%] train loss: 3.2140666007762775e-05 \n",
      "epoch: 7 [312191/888800 35.12%] train loss: 2.7274369131191634e-05 \n",
      "epoch: 7 [313302/888800 35.25%] train loss: 3.0123690521577373e-05 \n",
      "epoch: 7 [314413/888800 35.38%] train loss: 3.280735109001398e-05 \n",
      "epoch: 7 [315524/888800 35.50%] train loss: 3.387770993867889e-05 \n",
      "epoch: 7 [316635/888800 35.62%] train loss: 3.287340950919315e-05 \n",
      "epoch: 7 [317746/888800 35.75%] train loss: 3.260464654886164e-05 \n",
      "epoch: 7 [318857/888800 35.88%] train loss: 2.7675809178617783e-05 \n",
      "epoch: 7 [319968/888800 36.00%] train loss: 3.198486228939146e-05 \n",
      "epoch: 7 [321079/888800 36.12%] train loss: 2.8789301723008975e-05 \n",
      "epoch: 7 [322190/888800 36.25%] train loss: 2.8759777706000023e-05 \n",
      "epoch: 7 [323301/888800 36.38%] train loss: 3.432202720432542e-05 \n",
      "epoch: 7 [324412/888800 36.50%] train loss: 3.503886910039e-05 \n",
      "epoch: 7 [325523/888800 36.62%] train loss: 2.9257360438350588e-05 \n",
      "epoch: 7 [326634/888800 36.75%] train loss: 2.9405126042547636e-05 \n",
      "epoch: 7 [327745/888800 36.88%] train loss: 3.425960676395334e-05 \n",
      "epoch: 7 [328856/888800 37.00%] train loss: 3.11203912133351e-05 \n",
      "epoch: 7 [329967/888800 37.12%] train loss: 2.899993341998197e-05 \n",
      "epoch: 7 [331078/888800 37.25%] train loss: 3.445100082899444e-05 \n",
      "epoch: 7 [332189/888800 37.38%] train loss: 2.8352484150673263e-05 \n",
      "epoch: 7 [333300/888800 37.50%] train loss: 3.544689025147818e-05 \n",
      "epoch: 7 [334411/888800 37.62%] train loss: 3.073322295676917e-05 \n",
      "epoch: 7 [335522/888800 37.75%] train loss: 2.937505087174941e-05 \n",
      "epoch: 7 [336633/888800 37.88%] train loss: 3.09068855131045e-05 \n",
      "epoch: 7 [337744/888800 38.00%] train loss: 2.9898472348577343e-05 \n",
      "epoch: 7 [338855/888800 38.12%] train loss: 2.9066686693113297e-05 \n",
      "epoch: 7 [339966/888800 38.25%] train loss: 3.269369699410163e-05 \n",
      "epoch: 7 [341077/888800 38.38%] train loss: 3.068723890464753e-05 \n",
      "epoch: 7 [342188/888800 38.50%] train loss: 3.543301863828674e-05 \n",
      "epoch: 7 [343299/888800 38.62%] train loss: 3.039937473658938e-05 \n",
      "epoch: 7 [344410/888800 38.75%] train loss: 2.8770977223757654e-05 \n",
      "epoch: 7 [345521/888800 38.88%] train loss: 3.514304989948869e-05 \n",
      "epoch: 7 [346632/888800 39.00%] train loss: 3.255013871239498e-05 \n",
      "epoch: 7 [347743/888800 39.12%] train loss: 3.895482586813159e-05 \n",
      "epoch: 7 [348854/888800 39.25%] train loss: 3.6531102523440495e-05 \n",
      "epoch: 7 [349965/888800 39.38%] train loss: 3.1620078516425565e-05 \n",
      "epoch: 7 [351076/888800 39.50%] train loss: 2.6294681447325274e-05 \n",
      "epoch: 7 [352187/888800 39.62%] train loss: 2.9412152798613533e-05 \n",
      "epoch: 7 [353298/888800 39.75%] train loss: 2.710882472456433e-05 \n",
      "epoch: 7 [354409/888800 39.88%] train loss: 3.166794704156928e-05 \n",
      "epoch: 7 [355520/888800 40.00%] train loss: 3.12788542942144e-05 \n",
      "epoch: 7 [356631/888800 40.12%] train loss: 3.0260747735155746e-05 \n",
      "epoch: 7 [357742/888800 40.25%] train loss: 3.1991319701774046e-05 \n",
      "epoch: 7 [358853/888800 40.38%] train loss: 3.06317706417758e-05 \n",
      "epoch: 7 [359964/888800 40.50%] train loss: 2.4244660380645655e-05 \n",
      "epoch: 7 [361075/888800 40.62%] train loss: 3.225499312975444e-05 \n",
      "epoch: 7 [362186/888800 40.75%] train loss: 3.229130743420683e-05 \n",
      "epoch: 7 [363297/888800 40.88%] train loss: 2.9122154955985025e-05 \n",
      "epoch: 7 [364408/888800 41.00%] train loss: 3.149998156004585e-05 \n",
      "epoch: 7 [365519/888800 41.12%] train loss: 2.9682996682822704e-05 \n",
      "epoch: 7 [366630/888800 41.25%] train loss: 3.2208801712840796e-05 \n",
      "epoch: 7 [367741/888800 41.38%] train loss: 2.8554850359796546e-05 \n",
      "epoch: 7 [368852/888800 41.50%] train loss: 3.0829945899313316e-05 \n",
      "epoch: 7 [369963/888800 41.62%] train loss: 2.9722512408625335e-05 \n",
      "epoch: 7 [371074/888800 41.75%] train loss: 3.2850413845153525e-05 \n",
      "epoch: 7 [372185/888800 41.88%] train loss: 3.431317600188777e-05 \n",
      "epoch: 7 [373296/888800 42.00%] train loss: 3.460482184891589e-05 \n",
      "epoch: 7 [374407/888800 42.12%] train loss: 2.9888309654779732e-05 \n",
      "epoch: 7 [375518/888800 42.25%] train loss: 3.143520007142797e-05 \n",
      "epoch: 7 [376629/888800 42.38%] train loss: 3.1835596018936485e-05 \n",
      "epoch: 7 [377740/888800 42.50%] train loss: 2.580378895800095e-05 \n",
      "epoch: 7 [378851/888800 42.62%] train loss: 2.896038131439127e-05 \n",
      "epoch: 7 [379962/888800 42.75%] train loss: 3.098708111792803e-05 \n",
      "epoch: 7 [381073/888800 42.88%] train loss: 2.691030385904014e-05 \n",
      "epoch: 7 [382184/888800 43.00%] train loss: 3.032846507267095e-05 \n",
      "epoch: 7 [383295/888800 43.12%] train loss: 2.9220340366009623e-05 \n",
      "epoch: 7 [384406/888800 43.25%] train loss: 2.8658863811870106e-05 \n",
      "epoch: 7 [385517/888800 43.38%] train loss: 3.176926838932559e-05 \n",
      "epoch: 7 [386628/888800 43.50%] train loss: 3.5355908039491624e-05 \n",
      "epoch: 7 [387739/888800 43.62%] train loss: 3.2643914892105386e-05 \n",
      "epoch: 7 [388850/888800 43.75%] train loss: 3.333135100547224e-05 \n",
      "epoch: 7 [389961/888800 43.88%] train loss: 2.4349545128643513e-05 \n",
      "epoch: 7 [391072/888800 44.00%] train loss: 3.050625127798412e-05 \n",
      "epoch: 7 [392183/888800 44.12%] train loss: 2.8639247830142267e-05 \n",
      "epoch: 7 [393294/888800 44.25%] train loss: 2.8473510610638186e-05 \n",
      "epoch: 7 [394405/888800 44.38%] train loss: 3.19259925163351e-05 \n",
      "epoch: 7 [395516/888800 44.50%] train loss: 2.6350866392022e-05 \n",
      "epoch: 7 [396627/888800 44.62%] train loss: 2.841577043000143e-05 \n",
      "epoch: 7 [397738/888800 44.75%] train loss: 3.1652714824303985e-05 \n",
      "epoch: 7 [398849/888800 44.88%] train loss: 2.6769206669996493e-05 \n",
      "epoch: 7 [399960/888800 45.00%] train loss: 2.8040196411893703e-05 \n",
      "epoch: 7 [401071/888800 45.12%] train loss: 3.019020914507564e-05 \n",
      "epoch: 7 [402182/888800 45.25%] train loss: 2.9737127988482825e-05 \n",
      "epoch: 7 [403293/888800 45.38%] train loss: 2.763556403806433e-05 \n",
      "epoch: 7 [404404/888800 45.50%] train loss: 3.120681503787637e-05 \n",
      "epoch: 7 [405515/888800 45.62%] train loss: 3.1861512979958206e-05 \n",
      "epoch: 7 [406626/888800 45.75%] train loss: 2.6496421924093738e-05 \n",
      "epoch: 7 [407737/888800 45.88%] train loss: 3.3007952879415825e-05 \n",
      "epoch: 7 [408848/888800 46.00%] train loss: 2.7696021788869984e-05 \n",
      "epoch: 7 [409959/888800 46.12%] train loss: 3.330388062749989e-05 \n",
      "epoch: 7 [411070/888800 46.25%] train loss: 3.3654279832262546e-05 \n",
      "epoch: 7 [412181/888800 46.38%] train loss: 3.13619093503803e-05 \n",
      "epoch: 7 [413292/888800 46.50%] train loss: 3.4104104997823015e-05 \n",
      "epoch: 7 [414403/888800 46.62%] train loss: 3.238179488107562e-05 \n",
      "epoch: 7 [415514/888800 46.75%] train loss: 3.2409145205747336e-05 \n",
      "epoch: 7 [416625/888800 46.88%] train loss: 3.136494706268422e-05 \n",
      "epoch: 7 [417736/888800 47.00%] train loss: 3.807711254921742e-05 \n",
      "epoch: 7 [418847/888800 47.12%] train loss: 2.9262984753586352e-05 \n",
      "epoch: 7 [419958/888800 47.25%] train loss: 3.135553561151028e-05 \n",
      "epoch: 7 [421069/888800 47.38%] train loss: 2.5747283871169202e-05 \n",
      "epoch: 7 [422180/888800 47.50%] train loss: 3.091092366958037e-05 \n",
      "epoch: 7 [423291/888800 47.62%] train loss: 2.774713902908843e-05 \n",
      "epoch: 7 [424402/888800 47.75%] train loss: 2.615568882902153e-05 \n",
      "epoch: 7 [425513/888800 47.88%] train loss: 3.071115861530416e-05 \n",
      "epoch: 7 [426624/888800 48.00%] train loss: 3.077918881899677e-05 \n",
      "epoch: 7 [427735/888800 48.12%] train loss: 2.771282015601173e-05 \n",
      "epoch: 7 [428846/888800 48.25%] train loss: 2.8251066396478564e-05 \n",
      "epoch: 7 [429957/888800 48.38%] train loss: 2.6400979550089687e-05 \n",
      "epoch: 7 [431068/888800 48.50%] train loss: 3.265071791247465e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [432179/888800 48.62%] train loss: 2.9234499379526824e-05 \n",
      "epoch: 7 [433290/888800 48.75%] train loss: 3.405637835385278e-05 \n",
      "epoch: 7 [434401/888800 48.88%] train loss: 3.3817159419413656e-05 \n",
      "epoch: 7 [435512/888800 49.00%] train loss: 3.178645056323148e-05 \n",
      "epoch: 7 [436623/888800 49.12%] train loss: 2.4299057258758694e-05 \n",
      "epoch: 7 [437734/888800 49.25%] train loss: 3.040028786926996e-05 \n",
      "epoch: 7 [438845/888800 49.38%] train loss: 3.2900989026529714e-05 \n",
      "epoch: 7 [439956/888800 49.50%] train loss: 2.5199631636496633e-05 \n",
      "epoch: 7 [441067/888800 49.62%] train loss: 3.123076749034226e-05 \n",
      "epoch: 7 [442178/888800 49.75%] train loss: 3.368286706972867e-05 \n",
      "epoch: 7 [443289/888800 49.88%] train loss: 3.0762148526264355e-05 \n",
      "epoch: 7 [444400/888800 50.00%] train loss: 3.0324366889544763e-05 \n",
      "epoch: 7 [445511/888800 50.12%] train loss: 3.2225740142166615e-05 \n",
      "epoch: 7 [446622/888800 50.25%] train loss: 2.6867675842368044e-05 \n",
      "epoch: 7 [447733/888800 50.38%] train loss: 3.0213774152798578e-05 \n",
      "epoch: 7 [448844/888800 50.50%] train loss: 3.161697895848192e-05 \n",
      "epoch: 7 [449955/888800 50.62%] train loss: 3.209675560356118e-05 \n",
      "epoch: 7 [451066/888800 50.75%] train loss: 3.271478271926753e-05 \n",
      "epoch: 7 [452177/888800 50.88%] train loss: 3.225367981940508e-05 \n",
      "epoch: 7 [453288/888800 51.00%] train loss: 3.818661571131088e-05 \n",
      "epoch: 7 [454399/888800 51.12%] train loss: 2.725745434872806e-05 \n",
      "epoch: 7 [455510/888800 51.25%] train loss: 3.0316299671540037e-05 \n",
      "epoch: 7 [456621/888800 51.38%] train loss: 2.834457700373605e-05 \n",
      "epoch: 7 [457732/888800 51.50%] train loss: 2.9439685022225603e-05 \n",
      "epoch: 7 [458843/888800 51.62%] train loss: 2.9928782169008628e-05 \n",
      "epoch: 7 [459954/888800 51.75%] train loss: 2.4970588128780946e-05 \n",
      "epoch: 7 [461065/888800 51.88%] train loss: 2.9341446861508302e-05 \n",
      "epoch: 7 [462176/888800 52.00%] train loss: 3.24652974086348e-05 \n",
      "epoch: 7 [463287/888800 52.12%] train loss: 3.368747638887726e-05 \n",
      "epoch: 7 [464398/888800 52.25%] train loss: 3.249043220421299e-05 \n",
      "epoch: 7 [465509/888800 52.38%] train loss: 2.919427970482502e-05 \n",
      "epoch: 7 [466620/888800 52.50%] train loss: 2.8662319891736843e-05 \n",
      "epoch: 7 [467731/888800 52.62%] train loss: 2.950536691059824e-05 \n",
      "epoch: 7 [468842/888800 52.75%] train loss: 2.7515741749084555e-05 \n",
      "epoch: 7 [469953/888800 52.88%] train loss: 2.666554064489901e-05 \n",
      "epoch: 7 [471064/888800 53.00%] train loss: 3.2019041100284085e-05 \n",
      "epoch: 7 [472175/888800 53.12%] train loss: 3.218167330487631e-05 \n",
      "epoch: 7 [473286/888800 53.25%] train loss: 3.1345338356914e-05 \n",
      "epoch: 7 [474397/888800 53.38%] train loss: 2.757616493909154e-05 \n",
      "epoch: 7 [475508/888800 53.50%] train loss: 2.9833519874955527e-05 \n",
      "epoch: 7 [476619/888800 53.62%] train loss: 3.0224504371290095e-05 \n",
      "epoch: 7 [477730/888800 53.75%] train loss: 2.9163014914956875e-05 \n",
      "epoch: 7 [478841/888800 53.88%] train loss: 2.52961071964819e-05 \n",
      "epoch: 7 [479952/888800 54.00%] train loss: 3.2177857065107673e-05 \n",
      "epoch: 7 [481063/888800 54.12%] train loss: 2.952217801066581e-05 \n",
      "epoch: 7 [482174/888800 54.25%] train loss: 2.4476301405229606e-05 \n",
      "epoch: 7 [483285/888800 54.38%] train loss: 3.1585092074237764e-05 \n",
      "epoch: 7 [484396/888800 54.50%] train loss: 2.7564727133722045e-05 \n",
      "epoch: 7 [485507/888800 54.62%] train loss: 3.0484094168059528e-05 \n",
      "epoch: 7 [486618/888800 54.75%] train loss: 3.733739868039265e-05 \n",
      "epoch: 7 [487729/888800 54.88%] train loss: 2.6803307264344767e-05 \n",
      "epoch: 7 [488840/888800 55.00%] train loss: 2.7684214728651568e-05 \n",
      "epoch: 7 [489951/888800 55.12%] train loss: 3.2211028155870736e-05 \n",
      "epoch: 7 [491062/888800 55.25%] train loss: 2.8687163649010472e-05 \n",
      "epoch: 7 [492173/888800 55.38%] train loss: 3.118707172689028e-05 \n",
      "epoch: 7 [493284/888800 55.50%] train loss: 2.6611813154886477e-05 \n",
      "epoch: 7 [494395/888800 55.62%] train loss: 3.233116876799613e-05 \n",
      "epoch: 7 [495506/888800 55.75%] train loss: 3.6587720387615263e-05 \n",
      "epoch: 7 [496617/888800 55.88%] train loss: 3.161793574690819e-05 \n",
      "epoch: 7 [497728/888800 56.00%] train loss: 3.12605916406028e-05 \n",
      "epoch: 7 [498839/888800 56.12%] train loss: 2.7062078515882604e-05 \n",
      "epoch: 7 [499950/888800 56.25%] train loss: 2.4055632820818573e-05 \n",
      "epoch: 7 [501061/888800 56.38%] train loss: 2.731594940996729e-05 \n",
      "epoch: 7 [502172/888800 56.50%] train loss: 3.2730389648349956e-05 \n",
      "epoch: 7 [503283/888800 56.62%] train loss: 3.0015609809197485e-05 \n",
      "epoch: 7 [504394/888800 56.75%] train loss: 3.6580138839781284e-05 \n",
      "epoch: 7 [505505/888800 56.88%] train loss: 3.061805182369426e-05 \n",
      "epoch: 7 [506616/888800 57.00%] train loss: 2.803392089845147e-05 \n",
      "epoch: 7 [507727/888800 57.12%] train loss: 2.894119097618386e-05 \n",
      "epoch: 7 [508838/888800 57.25%] train loss: 2.963201950478833e-05 \n",
      "epoch: 7 [509949/888800 57.38%] train loss: 3.229853609809652e-05 \n",
      "epoch: 7 [511060/888800 57.50%] train loss: 2.989622953464277e-05 \n",
      "epoch: 7 [512171/888800 57.62%] train loss: 3.281270255683921e-05 \n",
      "epoch: 7 [513282/888800 57.75%] train loss: 3.218657730030827e-05 \n",
      "epoch: 7 [514393/888800 57.88%] train loss: 3.187112451996654e-05 \n",
      "epoch: 7 [515504/888800 58.00%] train loss: 2.8865528292953968e-05 \n",
      "epoch: 7 [516615/888800 58.12%] train loss: 2.5184555852320045e-05 \n",
      "epoch: 7 [517726/888800 58.25%] train loss: 2.474976827215869e-05 \n",
      "epoch: 7 [518837/888800 58.38%] train loss: 2.5697232558741234e-05 \n",
      "epoch: 7 [519948/888800 58.50%] train loss: 2.5690744223538786e-05 \n",
      "epoch: 7 [521059/888800 58.62%] train loss: 2.6291332687833346e-05 \n",
      "epoch: 7 [522170/888800 58.75%] train loss: 2.9313147024367936e-05 \n",
      "epoch: 7 [523281/888800 58.88%] train loss: 3.0753064493183047e-05 \n",
      "epoch: 7 [524392/888800 59.00%] train loss: 3.4722950658760965e-05 \n",
      "epoch: 7 [525503/888800 59.12%] train loss: 3.087012009928003e-05 \n",
      "epoch: 7 [526614/888800 59.25%] train loss: 3.399905108381063e-05 \n",
      "epoch: 7 [527725/888800 59.38%] train loss: 2.9064309273962863e-05 \n",
      "epoch: 7 [528836/888800 59.50%] train loss: 3.7307538150344044e-05 \n",
      "epoch: 7 [529947/888800 59.62%] train loss: 3.29629510815721e-05 \n",
      "epoch: 7 [531058/888800 59.75%] train loss: 2.783424497465603e-05 \n",
      "epoch: 7 [532169/888800 59.88%] train loss: 2.7151585527462885e-05 \n",
      "epoch: 7 [533280/888800 60.00%] train loss: 3.209542774129659e-05 \n",
      "epoch: 7 [534391/888800 60.12%] train loss: 2.8959722840227187e-05 \n",
      "epoch: 7 [535502/888800 60.25%] train loss: 2.6738545784610324e-05 \n",
      "epoch: 7 [536613/888800 60.38%] train loss: 2.5418996301596053e-05 \n",
      "epoch: 7 [537724/888800 60.50%] train loss: 3.55268748535309e-05 \n",
      "epoch: 7 [538835/888800 60.62%] train loss: 3.386145908734761e-05 \n",
      "epoch: 7 [539946/888800 60.75%] train loss: 2.5335421014460735e-05 \n",
      "epoch: 7 [541057/888800 60.88%] train loss: 3.1388535717269406e-05 \n",
      "epoch: 7 [542168/888800 61.00%] train loss: 3.106138319708407e-05 \n",
      "epoch: 7 [543279/888800 61.12%] train loss: 2.6818148398888297e-05 \n",
      "epoch: 7 [544390/888800 61.25%] train loss: 3.16879668389447e-05 \n",
      "epoch: 7 [545501/888800 61.38%] train loss: 2.929506081272848e-05 \n",
      "epoch: 7 [546612/888800 61.50%] train loss: 3.323574492242187e-05 \n",
      "epoch: 7 [547723/888800 61.62%] train loss: 3.33421521645505e-05 \n",
      "epoch: 7 [548834/888800 61.75%] train loss: 3.007637133123353e-05 \n",
      "epoch: 7 [549945/888800 61.88%] train loss: 3.1155370379565284e-05 \n",
      "epoch: 7 [551056/888800 62.00%] train loss: 2.8129114070907235e-05 \n",
      "epoch: 7 [552167/888800 62.12%] train loss: 2.6325762519263662e-05 \n",
      "epoch: 7 [553278/888800 62.25%] train loss: 3.150567863485776e-05 \n",
      "epoch: 7 [554389/888800 62.38%] train loss: 3.0628438253188506e-05 \n",
      "epoch: 7 [555500/888800 62.50%] train loss: 2.9835606255801395e-05 \n",
      "epoch: 7 [556611/888800 62.62%] train loss: 3.069060403504409e-05 \n",
      "epoch: 7 [557722/888800 62.75%] train loss: 3.165512316627428e-05 \n",
      "epoch: 7 [558833/888800 62.88%] train loss: 2.9468495995388366e-05 \n",
      "epoch: 7 [559944/888800 63.00%] train loss: 3.22577434417326e-05 \n",
      "epoch: 7 [561055/888800 63.12%] train loss: 2.8372518499963917e-05 \n",
      "epoch: 7 [562166/888800 63.25%] train loss: 3.229225330869667e-05 \n",
      "epoch: 7 [563277/888800 63.38%] train loss: 2.8777349143638276e-05 \n",
      "epoch: 7 [564388/888800 63.50%] train loss: 2.401957317488268e-05 \n",
      "epoch: 7 [565499/888800 63.62%] train loss: 3.170093987137079e-05 \n",
      "epoch: 7 [566610/888800 63.75%] train loss: 2.8461889087338932e-05 \n",
      "epoch: 7 [567721/888800 63.88%] train loss: 3.0586685170419514e-05 \n",
      "epoch: 7 [568832/888800 64.00%] train loss: 2.7062562367063947e-05 \n",
      "epoch: 7 [569943/888800 64.12%] train loss: 2.974464587168768e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [571054/888800 64.25%] train loss: 3.1441526516573504e-05 \n",
      "epoch: 7 [572165/888800 64.38%] train loss: 2.868370938813314e-05 \n",
      "epoch: 7 [573276/888800 64.50%] train loss: 3.052893225685693e-05 \n",
      "epoch: 7 [574387/888800 64.62%] train loss: 3.0433071515290067e-05 \n",
      "epoch: 7 [575498/888800 64.75%] train loss: 2.6385610908619128e-05 \n",
      "epoch: 7 [576609/888800 64.88%] train loss: 2.157812923542224e-05 \n",
      "epoch: 7 [577720/888800 65.00%] train loss: 3.060997187276371e-05 \n",
      "epoch: 7 [578831/888800 65.12%] train loss: 2.7079653591499664e-05 \n",
      "epoch: 7 [579942/888800 65.25%] train loss: 3.676167398225516e-05 \n",
      "epoch: 7 [581053/888800 65.38%] train loss: 2.955124364234507e-05 \n",
      "epoch: 7 [582164/888800 65.50%] train loss: 3.2821219065226614e-05 \n",
      "epoch: 7 [583275/888800 65.62%] train loss: 2.981900433951523e-05 \n",
      "epoch: 7 [584386/888800 65.75%] train loss: 3.471872696536593e-05 \n",
      "epoch: 7 [585497/888800 65.88%] train loss: 2.8458629458327778e-05 \n",
      "epoch: 7 [586608/888800 66.00%] train loss: 2.7501491786097176e-05 \n",
      "epoch: 7 [587719/888800 66.12%] train loss: 2.7326388590154238e-05 \n",
      "epoch: 7 [588830/888800 66.25%] train loss: 3.004299469466787e-05 \n",
      "epoch: 7 [589941/888800 66.38%] train loss: 3.154593287035823e-05 \n",
      "epoch: 7 [591052/888800 66.50%] train loss: 2.3313763449550606e-05 \n",
      "epoch: 7 [592163/888800 66.62%] train loss: 2.755814239208121e-05 \n",
      "epoch: 7 [593274/888800 66.75%] train loss: 2.5866724172374234e-05 \n",
      "epoch: 7 [594385/888800 66.88%] train loss: 2.9438515412039123e-05 \n",
      "epoch: 7 [595496/888800 67.00%] train loss: 3.0575574783142656e-05 \n",
      "epoch: 7 [596607/888800 67.12%] train loss: 3.585753802326508e-05 \n",
      "epoch: 7 [597718/888800 67.25%] train loss: 2.4695567844901234e-05 \n",
      "epoch: 7 [598829/888800 67.38%] train loss: 3.3623633498791605e-05 \n",
      "epoch: 7 [599940/888800 67.50%] train loss: 2.9963279303046875e-05 \n",
      "epoch: 7 [601051/888800 67.62%] train loss: 2.8779524654964916e-05 \n",
      "epoch: 7 [602162/888800 67.75%] train loss: 2.88244536932325e-05 \n",
      "epoch: 7 [603273/888800 67.88%] train loss: 2.789328027574811e-05 \n",
      "epoch: 7 [604384/888800 68.00%] train loss: 2.6929717932944186e-05 \n",
      "epoch: 7 [605495/888800 68.12%] train loss: 2.7283496820018627e-05 \n",
      "epoch: 7 [606606/888800 68.25%] train loss: 3.2646530598867685e-05 \n",
      "epoch: 7 [607717/888800 68.38%] train loss: 2.8258484235266224e-05 \n",
      "epoch: 7 [608828/888800 68.50%] train loss: 2.692786802072078e-05 \n",
      "epoch: 7 [609939/888800 68.62%] train loss: 3.082720286329277e-05 \n",
      "epoch: 7 [611050/888800 68.75%] train loss: 3.5696401027962565e-05 \n",
      "epoch: 7 [612161/888800 68.88%] train loss: 3.158663821523078e-05 \n",
      "epoch: 7 [613272/888800 69.00%] train loss: 2.512922219466418e-05 \n",
      "epoch: 7 [614383/888800 69.12%] train loss: 2.9211380024207756e-05 \n",
      "epoch: 7 [615494/888800 69.25%] train loss: 3.117814412689768e-05 \n",
      "epoch: 7 [616605/888800 69.38%] train loss: 2.859730739146471e-05 \n",
      "epoch: 7 [617716/888800 69.50%] train loss: 2.8464619390433654e-05 \n",
      "epoch: 7 [618827/888800 69.62%] train loss: 3.096253203693777e-05 \n",
      "epoch: 7 [619938/888800 69.75%] train loss: 3.171411299263127e-05 \n",
      "epoch: 7 [621049/888800 69.88%] train loss: 3.146688686683774e-05 \n",
      "epoch: 7 [622160/888800 70.00%] train loss: 2.8994005333515815e-05 \n",
      "epoch: 7 [623271/888800 70.12%] train loss: 3.0568171496270224e-05 \n",
      "epoch: 7 [624382/888800 70.25%] train loss: 3.281504177721217e-05 \n",
      "epoch: 7 [625493/888800 70.38%] train loss: 2.9370279662543908e-05 \n",
      "epoch: 7 [626604/888800 70.50%] train loss: 3.994704456999898e-05 \n",
      "epoch: 7 [627715/888800 70.62%] train loss: 3.09265851683449e-05 \n",
      "epoch: 7 [628826/888800 70.75%] train loss: 3.2340285542886704e-05 \n",
      "epoch: 7 [629937/888800 70.88%] train loss: 3.3059641282306984e-05 \n",
      "epoch: 7 [631048/888800 71.00%] train loss: 3.1071656849235296e-05 \n",
      "epoch: 7 [632159/888800 71.12%] train loss: 3.174422090523876e-05 \n",
      "epoch: 7 [633270/888800 71.25%] train loss: 2.903730455727782e-05 \n",
      "epoch: 7 [634381/888800 71.38%] train loss: 2.4056289475993253e-05 \n",
      "epoch: 7 [635492/888800 71.50%] train loss: 3.2227817428065464e-05 \n",
      "epoch: 7 [636603/888800 71.62%] train loss: 2.5944913431885652e-05 \n",
      "epoch: 7 [637714/888800 71.75%] train loss: 3.343324351590127e-05 \n",
      "epoch: 7 [638825/888800 71.88%] train loss: 3.127814852632582e-05 \n",
      "epoch: 7 [639936/888800 72.00%] train loss: 2.8343471058178693e-05 \n",
      "epoch: 7 [641047/888800 72.12%] train loss: 3.37749115715269e-05 \n",
      "epoch: 7 [642158/888800 72.25%] train loss: 2.7081081498181447e-05 \n",
      "epoch: 7 [643269/888800 72.38%] train loss: 3.164511144859716e-05 \n",
      "epoch: 7 [644380/888800 72.50%] train loss: 2.7595207939157262e-05 \n",
      "epoch: 7 [645491/888800 72.62%] train loss: 2.9071046810713597e-05 \n",
      "epoch: 7 [646602/888800 72.75%] train loss: 3.187122638337314e-05 \n",
      "epoch: 7 [647713/888800 72.88%] train loss: 2.8544516680995002e-05 \n",
      "epoch: 7 [648824/888800 73.00%] train loss: 2.6646950573194772e-05 \n",
      "epoch: 7 [649935/888800 73.12%] train loss: 3.1176583433989435e-05 \n",
      "epoch: 7 [651046/888800 73.25%] train loss: 2.626718378451187e-05 \n",
      "epoch: 7 [652157/888800 73.38%] train loss: 3.175606616423465e-05 \n",
      "epoch: 7 [653268/888800 73.50%] train loss: 2.9606637326651253e-05 \n",
      "epoch: 7 [654379/888800 73.62%] train loss: 2.859136657207273e-05 \n",
      "epoch: 7 [655490/888800 73.75%] train loss: 2.9172007998568006e-05 \n",
      "epoch: 7 [656601/888800 73.88%] train loss: 3.029146319022402e-05 \n",
      "epoch: 7 [657712/888800 74.00%] train loss: 3.0725146643817425e-05 \n",
      "epoch: 7 [658823/888800 74.12%] train loss: 2.78180705208797e-05 \n",
      "epoch: 7 [659934/888800 74.25%] train loss: 2.749828672676813e-05 \n",
      "epoch: 7 [661045/888800 74.38%] train loss: 2.614408549561631e-05 \n",
      "epoch: 7 [662156/888800 74.50%] train loss: 3.203585583833046e-05 \n",
      "epoch: 7 [663267/888800 74.62%] train loss: 2.8406502678990364e-05 \n",
      "epoch: 7 [664378/888800 74.75%] train loss: 3.3144224289571866e-05 \n",
      "epoch: 7 [665489/888800 74.88%] train loss: 2.812451020872686e-05 \n",
      "epoch: 7 [666600/888800 75.00%] train loss: 3.088012817897834e-05 \n",
      "epoch: 7 [667711/888800 75.12%] train loss: 2.5565974283381365e-05 \n",
      "epoch: 7 [668822/888800 75.25%] train loss: 3.0173343475325964e-05 \n",
      "epoch: 7 [669933/888800 75.38%] train loss: 2.9486911444109865e-05 \n",
      "epoch: 7 [671044/888800 75.50%] train loss: 2.934634903795086e-05 \n",
      "epoch: 7 [672155/888800 75.62%] train loss: 3.2664480386301875e-05 \n",
      "epoch: 7 [673266/888800 75.75%] train loss: 2.7556297936826013e-05 \n",
      "epoch: 7 [674377/888800 75.88%] train loss: 2.5268194804084487e-05 \n",
      "epoch: 7 [675488/888800 76.00%] train loss: 2.9716577046201564e-05 \n",
      "epoch: 7 [676599/888800 76.12%] train loss: 3.3411906770197675e-05 \n",
      "epoch: 7 [677710/888800 76.25%] train loss: 2.7122649044031277e-05 \n",
      "epoch: 7 [678821/888800 76.38%] train loss: 2.8619460863410495e-05 \n",
      "epoch: 7 [679932/888800 76.50%] train loss: 2.863836198230274e-05 \n",
      "epoch: 7 [681043/888800 76.62%] train loss: 2.590944495750591e-05 \n",
      "epoch: 7 [682154/888800 76.75%] train loss: 2.7574662453844212e-05 \n",
      "epoch: 7 [683265/888800 76.88%] train loss: 3.618173286668025e-05 \n",
      "epoch: 7 [684376/888800 77.00%] train loss: 3.259128061472438e-05 \n",
      "epoch: 7 [685487/888800 77.12%] train loss: 2.6473730031284504e-05 \n",
      "epoch: 7 [686598/888800 77.25%] train loss: 2.813056380546186e-05 \n",
      "epoch: 7 [687709/888800 77.38%] train loss: 2.80589702015277e-05 \n",
      "epoch: 7 [688820/888800 77.50%] train loss: 3.1597886845702305e-05 \n",
      "epoch: 7 [689931/888800 77.62%] train loss: 2.5396308046765625e-05 \n",
      "epoch: 7 [691042/888800 77.75%] train loss: 2.620000668684952e-05 \n",
      "epoch: 7 [692153/888800 77.88%] train loss: 3.9947673940332606e-05 \n",
      "epoch: 7 [693264/888800 78.00%] train loss: 3.0314153264043853e-05 \n",
      "epoch: 7 [694375/888800 78.12%] train loss: 2.687197775230743e-05 \n",
      "epoch: 7 [695486/888800 78.25%] train loss: 3.321687472634949e-05 \n",
      "epoch: 7 [696597/888800 78.38%] train loss: 2.5744084268808365e-05 \n",
      "epoch: 7 [697708/888800 78.50%] train loss: 3.1622294045519084e-05 \n",
      "epoch: 7 [698819/888800 78.62%] train loss: 3.059792652493343e-05 \n",
      "epoch: 7 [699930/888800 78.75%] train loss: 3.5362761991564184e-05 \n",
      "epoch: 7 [701041/888800 78.88%] train loss: 2.936778219009284e-05 \n",
      "epoch: 7 [702152/888800 79.00%] train loss: 2.586123810033314e-05 \n",
      "epoch: 7 [703263/888800 79.12%] train loss: 3.320746327517554e-05 \n",
      "epoch: 7 [704374/888800 79.25%] train loss: 3.0063378289924003e-05 \n",
      "epoch: 7 [705485/888800 79.38%] train loss: 2.6447851269040257e-05 \n",
      "epoch: 7 [706596/888800 79.50%] train loss: 3.11864132527262e-05 \n",
      "epoch: 7 [707707/888800 79.62%] train loss: 3.1632924219593406e-05 \n",
      "epoch: 7 [708818/888800 79.75%] train loss: 3.1313946237787604e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [709929/888800 79.88%] train loss: 2.8293476134422235e-05 \n",
      "epoch: 7 [711040/888800 80.00%] train loss: 2.7615191356744617e-05 \n",
      "epoch: 7 [712151/888800 80.12%] train loss: 2.5702036509756e-05 \n",
      "epoch: 7 [713262/888800 80.25%] train loss: 2.841679634002503e-05 \n",
      "epoch: 7 [714373/888800 80.38%] train loss: 2.927666537289042e-05 \n",
      "epoch: 7 [715484/888800 80.50%] train loss: 2.8757705877069384e-05 \n",
      "epoch: 7 [716595/888800 80.62%] train loss: 3.0513565434375778e-05 \n",
      "epoch: 7 [717706/888800 80.75%] train loss: 2.467942249495536e-05 \n",
      "epoch: 7 [718817/888800 80.88%] train loss: 2.65746839431813e-05 \n",
      "epoch: 7 [719928/888800 81.00%] train loss: 3.550855763023719e-05 \n",
      "epoch: 7 [721039/888800 81.12%] train loss: 2.6284940759069286e-05 \n",
      "epoch: 7 [722150/888800 81.25%] train loss: 3.2051801099441946e-05 \n",
      "epoch: 7 [723261/888800 81.38%] train loss: 3.1721465347800404e-05 \n",
      "epoch: 7 [724372/888800 81.50%] train loss: 2.9117107260390185e-05 \n",
      "epoch: 7 [725483/888800 81.62%] train loss: 2.6581465135677718e-05 \n",
      "epoch: 7 [726594/888800 81.75%] train loss: 3.244273830205202e-05 \n",
      "epoch: 7 [727705/888800 81.88%] train loss: 3.477999416645616e-05 \n",
      "epoch: 7 [728816/888800 82.00%] train loss: 3.2236759579973295e-05 \n",
      "epoch: 7 [729927/888800 82.12%] train loss: 3.073728294111788e-05 \n",
      "epoch: 7 [731038/888800 82.25%] train loss: 2.513246909074951e-05 \n",
      "epoch: 7 [732149/888800 82.38%] train loss: 2.4664865122758783e-05 \n",
      "epoch: 7 [733260/888800 82.50%] train loss: 3.011778971995227e-05 \n",
      "epoch: 7 [734371/888800 82.62%] train loss: 2.6489404262974858e-05 \n",
      "epoch: 7 [735482/888800 82.75%] train loss: 3.0790568416705355e-05 \n",
      "epoch: 7 [736593/888800 82.88%] train loss: 2.8101203497499228e-05 \n",
      "epoch: 7 [737704/888800 83.00%] train loss: 2.8879094315925613e-05 \n",
      "epoch: 7 [738815/888800 83.12%] train loss: 2.851042154361494e-05 \n",
      "epoch: 7 [739926/888800 83.25%] train loss: 2.94331166514894e-05 \n",
      "epoch: 7 [741037/888800 83.38%] train loss: 2.9600774723803625e-05 \n",
      "epoch: 7 [742148/888800 83.50%] train loss: 2.5493227440165356e-05 \n",
      "epoch: 7 [743259/888800 83.62%] train loss: 2.8720687623717822e-05 \n",
      "epoch: 7 [744370/888800 83.75%] train loss: 2.7457777832751162e-05 \n",
      "epoch: 7 [745481/888800 83.88%] train loss: 2.868610499717761e-05 \n",
      "epoch: 7 [746592/888800 84.00%] train loss: 2.9188166081439704e-05 \n",
      "epoch: 7 [747703/888800 84.12%] train loss: 2.7771780878538266e-05 \n",
      "epoch: 7 [748814/888800 84.25%] train loss: 2.7634172511170618e-05 \n",
      "epoch: 7 [749925/888800 84.38%] train loss: 2.0807487089768983e-05 \n",
      "epoch: 7 [751036/888800 84.50%] train loss: 3.133547579636797e-05 \n",
      "epoch: 7 [752147/888800 84.62%] train loss: 3.268795626354404e-05 \n",
      "epoch: 7 [753258/888800 84.75%] train loss: 2.571792902017478e-05 \n",
      "epoch: 7 [754369/888800 84.88%] train loss: 2.795028376567643e-05 \n",
      "epoch: 7 [755480/888800 85.00%] train loss: 2.8526359528768808e-05 \n",
      "epoch: 7 [756591/888800 85.12%] train loss: 3.39167017955333e-05 \n",
      "epoch: 7 [757702/888800 85.25%] train loss: 2.8607573767658323e-05 \n",
      "epoch: 7 [758813/888800 85.38%] train loss: 3.305921927676536e-05 \n",
      "epoch: 7 [759924/888800 85.50%] train loss: 2.7157500881003216e-05 \n",
      "epoch: 7 [761035/888800 85.62%] train loss: 3.0953058740124106e-05 \n",
      "epoch: 7 [762146/888800 85.75%] train loss: 2.816301457642112e-05 \n",
      "epoch: 7 [763257/888800 85.88%] train loss: 3.6388588341651484e-05 \n",
      "epoch: 7 [764368/888800 86.00%] train loss: 2.9827157050021924e-05 \n",
      "epoch: 7 [765479/888800 86.12%] train loss: 2.7899879569304176e-05 \n",
      "epoch: 7 [766590/888800 86.25%] train loss: 3.0243074434110895e-05 \n",
      "epoch: 7 [767701/888800 86.38%] train loss: 2.9353534046094865e-05 \n",
      "epoch: 7 [768812/888800 86.50%] train loss: 2.7975995180895552e-05 \n",
      "epoch: 7 [769923/888800 86.62%] train loss: 2.8569258574862033e-05 \n",
      "epoch: 7 [771034/888800 86.75%] train loss: 2.858128573279828e-05 \n",
      "epoch: 7 [772145/888800 86.88%] train loss: 3.285016646259464e-05 \n",
      "epoch: 7 [773256/888800 87.00%] train loss: 2.4343753466382623e-05 \n",
      "epoch: 7 [774367/888800 87.12%] train loss: 2.9226113838376477e-05 \n",
      "epoch: 7 [775478/888800 87.25%] train loss: 3.232069138903171e-05 \n",
      "epoch: 7 [776589/888800 87.38%] train loss: 3.317368100397289e-05 \n",
      "epoch: 7 [777700/888800 87.50%] train loss: 2.5293889848398976e-05 \n",
      "epoch: 7 [778811/888800 87.62%] train loss: 3.009039028256666e-05 \n",
      "epoch: 7 [779922/888800 87.75%] train loss: 2.0463421606109478e-05 \n",
      "epoch: 7 [781033/888800 87.88%] train loss: 2.6151188649237156e-05 \n",
      "epoch: 7 [782144/888800 88.00%] train loss: 3.253332761232741e-05 \n",
      "epoch: 7 [783255/888800 88.12%] train loss: 2.4503808162990026e-05 \n",
      "epoch: 7 [784366/888800 88.25%] train loss: 2.933717223640997e-05 \n",
      "epoch: 7 [785477/888800 88.38%] train loss: 2.8688094971585087e-05 \n",
      "epoch: 7 [786588/888800 88.50%] train loss: 2.502567440387793e-05 \n",
      "epoch: 7 [787699/888800 88.62%] train loss: 3.236877091694623e-05 \n",
      "epoch: 7 [788810/888800 88.75%] train loss: 3.1129438866628334e-05 \n",
      "epoch: 7 [789921/888800 88.88%] train loss: 3.125692091998644e-05 \n",
      "epoch: 7 [791032/888800 89.00%] train loss: 2.6488212824915536e-05 \n",
      "epoch: 7 [792143/888800 89.12%] train loss: 2.582789420557674e-05 \n",
      "epoch: 7 [793254/888800 89.25%] train loss: 3.204396125511266e-05 \n",
      "epoch: 7 [794365/888800 89.38%] train loss: 2.8428770747268572e-05 \n",
      "epoch: 7 [795476/888800 89.50%] train loss: 2.6367330065113492e-05 \n",
      "epoch: 7 [796587/888800 89.62%] train loss: 2.995871182065457e-05 \n",
      "epoch: 7 [797698/888800 89.75%] train loss: 2.8750071578542702e-05 \n",
      "epoch: 7 [798809/888800 89.88%] train loss: 2.7803325792774558e-05 \n",
      "epoch: 7 [799920/888800 90.00%] train loss: 2.772693733277265e-05 \n",
      "epoch: 7 [801031/888800 90.12%] train loss: 3.0457498723990284e-05 \n",
      "epoch: 7 [802142/888800 90.25%] train loss: 2.778801353997551e-05 \n",
      "epoch: 7 [803253/888800 90.38%] train loss: 2.339131970074959e-05 \n",
      "epoch: 7 [804364/888800 90.50%] train loss: 2.9132703275536187e-05 \n",
      "epoch: 7 [805475/888800 90.62%] train loss: 2.6060974050778896e-05 \n",
      "epoch: 7 [806586/888800 90.75%] train loss: 2.995700742758345e-05 \n",
      "epoch: 7 [807697/888800 90.88%] train loss: 2.907179805333726e-05 \n",
      "epoch: 7 [808808/888800 91.00%] train loss: 2.9652757802978158e-05 \n",
      "epoch: 7 [809919/888800 91.12%] train loss: 3.222180384909734e-05 \n",
      "epoch: 7 [811030/888800 91.25%] train loss: 2.9337108571780846e-05 \n",
      "epoch: 7 [812141/888800 91.38%] train loss: 3.262287282268517e-05 \n",
      "epoch: 7 [813252/888800 91.50%] train loss: 3.0500215871143155e-05 \n",
      "epoch: 7 [814363/888800 91.62%] train loss: 2.7875585146830417e-05 \n",
      "epoch: 7 [815474/888800 91.75%] train loss: 2.9318780434550717e-05 \n",
      "epoch: 7 [816585/888800 91.88%] train loss: 3.0998329748399556e-05 \n",
      "epoch: 7 [817696/888800 92.00%] train loss: 2.487779056536965e-05 \n",
      "epoch: 7 [818807/888800 92.12%] train loss: 2.4008315449464135e-05 \n",
      "epoch: 7 [819918/888800 92.25%] train loss: 2.8097005269955844e-05 \n",
      "epoch: 7 [821029/888800 92.38%] train loss: 2.9954513593111187e-05 \n",
      "epoch: 7 [822140/888800 92.50%] train loss: 3.0700713978149e-05 \n",
      "epoch: 7 [823251/888800 92.62%] train loss: 3.1128936825552955e-05 \n",
      "epoch: 7 [824362/888800 92.75%] train loss: 2.6023657483165152e-05 \n",
      "epoch: 7 [825473/888800 92.88%] train loss: 2.6095647626789287e-05 \n",
      "epoch: 7 [826584/888800 93.00%] train loss: 2.9570112019428052e-05 \n",
      "epoch: 7 [827695/888800 93.12%] train loss: 2.9646296752616763e-05 \n",
      "epoch: 7 [828806/888800 93.25%] train loss: 3.291641769465059e-05 \n",
      "epoch: 7 [829917/888800 93.38%] train loss: 2.8182650567032397e-05 \n",
      "epoch: 7 [831028/888800 93.50%] train loss: 2.835914710885845e-05 \n",
      "epoch: 7 [832139/888800 93.62%] train loss: 3.350966653670184e-05 \n",
      "epoch: 7 [833250/888800 93.75%] train loss: 2.5310993805760518e-05 \n",
      "epoch: 7 [834361/888800 93.88%] train loss: 2.9554683351307176e-05 \n",
      "epoch: 7 [835472/888800 94.00%] train loss: 2.8703765565296635e-05 \n",
      "epoch: 7 [836583/888800 94.12%] train loss: 3.1172541639534757e-05 \n",
      "epoch: 7 [837694/888800 94.25%] train loss: 2.6212763259536587e-05 \n",
      "epoch: 7 [838805/888800 94.38%] train loss: 2.480612602084875e-05 \n",
      "epoch: 7 [839916/888800 94.50%] train loss: 2.7938369385083206e-05 \n",
      "epoch: 7 [841027/888800 94.62%] train loss: 3.15350953314919e-05 \n",
      "epoch: 7 [842138/888800 94.75%] train loss: 2.382969432801474e-05 \n",
      "epoch: 7 [843249/888800 94.88%] train loss: 2.649320049386006e-05 \n",
      "epoch: 7 [844360/888800 95.00%] train loss: 2.5622299290262163e-05 \n",
      "epoch: 7 [845471/888800 95.12%] train loss: 2.7953466997132637e-05 \n",
      "epoch: 7 [846582/888800 95.25%] train loss: 2.8326316169113852e-05 \n",
      "epoch: 7 [847693/888800 95.38%] train loss: 2.3414979295921512e-05 \n",
      "epoch: 7 [848804/888800 95.50%] train loss: 2.7088617571280338e-05 \n",
      "epoch: 7 [849915/888800 95.62%] train loss: 2.436315298837144e-05 \n",
      "epoch: 7 [851026/888800 95.75%] train loss: 2.844566733983811e-05 \n",
      "epoch: 7 [852137/888800 95.88%] train loss: 3.1830168154556304e-05 \n",
      "epoch: 7 [853248/888800 96.00%] train loss: 3.120292240055278e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 [854359/888800 96.12%] train loss: 2.935781958512962e-05 \n",
      "epoch: 7 [855470/888800 96.25%] train loss: 2.6871750378631987e-05 \n",
      "epoch: 7 [856581/888800 96.38%] train loss: 2.4776147256488912e-05 \n",
      "epoch: 7 [857692/888800 96.50%] train loss: 3.081105387536809e-05 \n",
      "epoch: 7 [858803/888800 96.62%] train loss: 2.664592284418177e-05 \n",
      "epoch: 7 [859914/888800 96.75%] train loss: 3.1087456591194496e-05 \n",
      "epoch: 7 [861025/888800 96.88%] train loss: 2.667413718882017e-05 \n",
      "epoch: 7 [862136/888800 97.00%] train loss: 2.8252052288735285e-05 \n",
      "epoch: 7 [863247/888800 97.12%] train loss: 2.739824958553072e-05 \n",
      "epoch: 7 [864358/888800 97.25%] train loss: 2.4586932340753265e-05 \n",
      "epoch: 7 [865469/888800 97.38%] train loss: 2.7142885301145725e-05 \n",
      "epoch: 7 [866580/888800 97.50%] train loss: 2.2648193407803774e-05 \n",
      "epoch: 7 [867691/888800 97.62%] train loss: 2.724377191043459e-05 \n",
      "epoch: 7 [868802/888800 97.75%] train loss: 2.579994179541245e-05 \n",
      "epoch: 7 [869913/888800 97.88%] train loss: 3.236144038964994e-05 \n",
      "epoch: 7 [871024/888800 98.00%] train loss: 2.440155003569089e-05 \n",
      "epoch: 7 [872135/888800 98.12%] train loss: 2.9140894184820354e-05 \n",
      "epoch: 7 [873246/888800 98.25%] train loss: 2.7872589271282777e-05 \n",
      "epoch: 7 [874357/888800 98.38%] train loss: 2.626512105052825e-05 \n",
      "epoch: 7 [875468/888800 98.50%] train loss: 2.9238379283924587e-05 \n",
      "epoch: 7 [876579/888800 98.62%] train loss: 2.678034798009321e-05 \n",
      "epoch: 7 [877690/888800 98.75%] train loss: 2.7386462534195744e-05 \n",
      "epoch: 7 [878801/888800 98.88%] train loss: 2.456954462104477e-05 \n",
      "epoch: 7 [879912/888800 99.00%] train loss: 2.474121720297262e-05 \n",
      "epoch: 7 [881023/888800 99.12%] train loss: 2.598239188955631e-05 \n",
      "epoch: 7 [882134/888800 99.25%] train loss: 3.0736016924493015e-05 \n",
      "epoch: 7 [883245/888800 99.38%] train loss: 2.740077798080165e-05 \n",
      "epoch: 7 [884356/888800 99.50%] train loss: 3.0484527087537572e-05 \n",
      "epoch: 7 [885467/888800 99.62%] train loss: 3.091100006713532e-05 \n",
      "epoch: 7 [886578/888800 99.75%] train loss: 2.763454358500894e-05 \n",
      "epoch: 7 [887689/888800 99.88%] train loss: 2.632685391290579e-05 \n",
      "epoch: 8 [0/888800 0.00%] train loss: 2.6709276426117867e-05 \n",
      "epoch: 8 [1111/888800 0.12%] train loss: 2.411158857285045e-05 \n",
      "epoch: 8 [2222/888800 0.25%] train loss: 2.8358983399812132e-05 \n",
      "epoch: 8 [3333/888800 0.38%] train loss: 2.853786281775683e-05 \n",
      "epoch: 8 [4444/888800 0.50%] train loss: 2.4608300009276718e-05 \n",
      "epoch: 8 [5555/888800 0.62%] train loss: 2.894802855735179e-05 \n",
      "epoch: 8 [6666/888800 0.75%] train loss: 2.9112876291037537e-05 \n",
      "epoch: 8 [7777/888800 0.88%] train loss: 2.8822641979786567e-05 \n",
      "epoch: 8 [8888/888800 1.00%] train loss: 3.003281199198682e-05 \n",
      "epoch: 8 [9999/888800 1.12%] train loss: 2.8459300665417686e-05 \n",
      "epoch: 8 [11110/888800 1.25%] train loss: 2.5213574190274812e-05 \n",
      "epoch: 8 [12221/888800 1.38%] train loss: 2.306540591234807e-05 \n",
      "epoch: 8 [13332/888800 1.50%] train loss: 2.565728937042877e-05 \n",
      "epoch: 8 [14443/888800 1.62%] train loss: 3.0356402930920012e-05 \n",
      "epoch: 8 [15554/888800 1.75%] train loss: 2.9592452847282402e-05 \n",
      "epoch: 8 [16665/888800 1.88%] train loss: 2.305825000803452e-05 \n",
      "epoch: 8 [17776/888800 2.00%] train loss: 2.3595948732690886e-05 \n",
      "epoch: 8 [18887/888800 2.12%] train loss: 2.763710290309973e-05 \n",
      "epoch: 8 [19998/888800 2.25%] train loss: 2.4717010091990232e-05 \n",
      "epoch: 8 [21109/888800 2.38%] train loss: 2.5225219360436313e-05 \n",
      "epoch: 8 [22220/888800 2.50%] train loss: 2.631435199873522e-05 \n",
      "epoch: 8 [23331/888800 2.62%] train loss: 2.4115257474477403e-05 \n",
      "epoch: 8 [24442/888800 2.75%] train loss: 3.256879426771775e-05 \n",
      "epoch: 8 [25553/888800 2.88%] train loss: 3.0751751182833686e-05 \n",
      "epoch: 8 [26664/888800 3.00%] train loss: 2.8922087949467823e-05 \n",
      "epoch: 8 [27775/888800 3.12%] train loss: 2.9635499231517315e-05 \n",
      "epoch: 8 [28886/888800 3.25%] train loss: 2.5833005565800704e-05 \n",
      "epoch: 8 [29997/888800 3.38%] train loss: 2.947453140222933e-05 \n",
      "epoch: 8 [31108/888800 3.50%] train loss: 3.1226194550981745e-05 \n",
      "epoch: 8 [32219/888800 3.62%] train loss: 2.97573787975125e-05 \n",
      "epoch: 8 [33330/888800 3.75%] train loss: 3.13627278956119e-05 \n",
      "epoch: 8 [34441/888800 3.88%] train loss: 2.6369638362666592e-05 \n",
      "epoch: 8 [35552/888800 4.00%] train loss: 2.7412077542976476e-05 \n",
      "epoch: 8 [36663/888800 4.12%] train loss: 1.9831961253657937e-05 \n",
      "epoch: 8 [37774/888800 4.25%] train loss: 2.6617497496772557e-05 \n",
      "epoch: 8 [38885/888800 4.38%] train loss: 2.6099442038685083e-05 \n",
      "epoch: 8 [39996/888800 4.50%] train loss: 2.8026710424455814e-05 \n",
      "epoch: 8 [41107/888800 4.62%] train loss: 2.6354926376370713e-05 \n",
      "epoch: 8 [42218/888800 4.75%] train loss: 2.9390294002951123e-05 \n",
      "epoch: 8 [43329/888800 4.88%] train loss: 2.5637866201577708e-05 \n",
      "epoch: 8 [44440/888800 5.00%] train loss: 2.6960480681736954e-05 \n",
      "epoch: 8 [45551/888800 5.12%] train loss: 2.5712975912028924e-05 \n",
      "epoch: 8 [46662/888800 5.25%] train loss: 2.8655380447162315e-05 \n",
      "epoch: 8 [47773/888800 5.38%] train loss: 2.3489783416152932e-05 \n",
      "epoch: 8 [48884/888800 5.50%] train loss: 2.7188778403797187e-05 \n",
      "epoch: 8 [49995/888800 5.62%] train loss: 3.0007888199179433e-05 \n",
      "epoch: 8 [51106/888800 5.75%] train loss: 2.594743637018837e-05 \n",
      "epoch: 8 [52217/888800 5.88%] train loss: 2.3665781554882415e-05 \n",
      "epoch: 8 [53328/888800 6.00%] train loss: 3.056762943742797e-05 \n",
      "epoch: 8 [54439/888800 6.12%] train loss: 2.424311423965264e-05 \n",
      "epoch: 8 [55550/888800 6.25%] train loss: 2.882101216528099e-05 \n",
      "epoch: 8 [56661/888800 6.38%] train loss: 3.136564919259399e-05 \n",
      "epoch: 8 [57772/888800 6.50%] train loss: 2.792231498460751e-05 \n",
      "epoch: 8 [58883/888800 6.62%] train loss: 2.974649760290049e-05 \n",
      "epoch: 8 [59994/888800 6.75%] train loss: 2.760767165455036e-05 \n",
      "epoch: 8 [61105/888800 6.88%] train loss: 2.3484562916564755e-05 \n",
      "epoch: 8 [62216/888800 7.00%] train loss: 2.8985803510295227e-05 \n",
      "epoch: 8 [63327/888800 7.12%] train loss: 2.949353620351758e-05 \n",
      "epoch: 8 [64438/888800 7.25%] train loss: 3.071275205002166e-05 \n",
      "epoch: 8 [65549/888800 7.38%] train loss: 2.5663302949396893e-05 \n",
      "epoch: 8 [66660/888800 7.50%] train loss: 3.0089566280366853e-05 \n",
      "epoch: 8 [67771/888800 7.62%] train loss: 3.046926030947361e-05 \n",
      "epoch: 8 [68882/888800 7.75%] train loss: 3.001153345394414e-05 \n",
      "epoch: 8 [69993/888800 7.88%] train loss: 2.3865377443144098e-05 \n",
      "epoch: 8 [71104/888800 8.00%] train loss: 3.0791481549385935e-05 \n",
      "epoch: 8 [72215/888800 8.12%] train loss: 2.7387673981138505e-05 \n",
      "epoch: 8 [73326/888800 8.25%] train loss: 2.472862252034247e-05 \n",
      "epoch: 8 [74437/888800 8.38%] train loss: 2.9911425372119993e-05 \n",
      "epoch: 8 [75548/888800 8.50%] train loss: 2.5866669602692127e-05 \n",
      "epoch: 8 [76659/888800 8.62%] train loss: 3.210157228750177e-05 \n",
      "epoch: 8 [77770/888800 8.75%] train loss: 2.810363548633177e-05 \n",
      "epoch: 8 [78881/888800 8.88%] train loss: 2.456924266880378e-05 \n",
      "epoch: 8 [79992/888800 9.00%] train loss: 2.4331693566637114e-05 \n",
      "epoch: 8 [81103/888800 9.12%] train loss: 2.7537949790712446e-05 \n",
      "epoch: 8 [82214/888800 9.25%] train loss: 2.5638923034421168e-05 \n",
      "epoch: 8 [83325/888800 9.38%] train loss: 2.6078057999256998e-05 \n",
      "epoch: 8 [84436/888800 9.50%] train loss: 2.7155996576766483e-05 \n",
      "epoch: 8 [85547/888800 9.62%] train loss: 2.7732794478652067e-05 \n",
      "epoch: 8 [86658/888800 9.75%] train loss: 2.6193985831923783e-05 \n",
      "epoch: 8 [87769/888800 9.88%] train loss: 2.971811409224756e-05 \n",
      "epoch: 8 [88880/888800 10.00%] train loss: 2.821127236529719e-05 \n",
      "epoch: 8 [89991/888800 10.12%] train loss: 2.406808198429644e-05 \n",
      "epoch: 8 [91102/888800 10.25%] train loss: 2.5797462512855418e-05 \n",
      "epoch: 8 [92213/888800 10.38%] train loss: 2.8227394068380818e-05 \n",
      "epoch: 8 [93324/888800 10.50%] train loss: 2.0943152776453644e-05 \n",
      "epoch: 8 [94435/888800 10.62%] train loss: 2.650044916663319e-05 \n",
      "epoch: 8 [95546/888800 10.75%] train loss: 2.9635197279276326e-05 \n",
      "epoch: 8 [96657/888800 10.88%] train loss: 2.712799141590949e-05 \n",
      "epoch: 8 [97768/888800 11.00%] train loss: 2.463170312694274e-05 \n",
      "epoch: 8 [98879/888800 11.12%] train loss: 2.7021931600756943e-05 \n",
      "epoch: 8 [99990/888800 11.25%] train loss: 2.5804423785302788e-05 \n",
      "epoch: 8 [101101/888800 11.38%] train loss: 2.641457467689179e-05 \n",
      "epoch: 8 [102212/888800 11.50%] train loss: 2.762856092886068e-05 \n",
      "epoch: 8 [103323/888800 11.62%] train loss: 2.9263161195558496e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [104434/888800 11.75%] train loss: 2.9092861950630322e-05 \n",
      "epoch: 8 [105545/888800 11.88%] train loss: 2.794512693071738e-05 \n",
      "epoch: 8 [106656/888800 12.00%] train loss: 2.7031064746552147e-05 \n",
      "epoch: 8 [107767/888800 12.12%] train loss: 2.6852459996007383e-05 \n",
      "epoch: 8 [108878/888800 12.25%] train loss: 2.8475009457906708e-05 \n",
      "epoch: 8 [109989/888800 12.38%] train loss: 2.3335574951488525e-05 \n",
      "epoch: 8 [111100/888800 12.50%] train loss: 2.8010263122268952e-05 \n",
      "epoch: 8 [112211/888800 12.62%] train loss: 3.0325727493618615e-05 \n",
      "epoch: 8 [113322/888800 12.75%] train loss: 2.5860448658932e-05 \n",
      "epoch: 8 [114433/888800 12.88%] train loss: 2.569594835222233e-05 \n",
      "epoch: 8 [115544/888800 13.00%] train loss: 2.3400874852086417e-05 \n",
      "epoch: 8 [116655/888800 13.12%] train loss: 2.8143538656877354e-05 \n",
      "epoch: 8 [117766/888800 13.25%] train loss: 2.6733776394394226e-05 \n",
      "epoch: 8 [118877/888800 13.38%] train loss: 2.630705239425879e-05 \n",
      "epoch: 8 [119988/888800 13.50%] train loss: 2.1813100829604082e-05 \n",
      "epoch: 8 [121099/888800 13.62%] train loss: 2.5301482310169376e-05 \n",
      "epoch: 8 [122210/888800 13.75%] train loss: 2.3169130145106465e-05 \n",
      "epoch: 8 [123321/888800 13.88%] train loss: 2.6707431970862672e-05 \n",
      "epoch: 8 [124432/888800 14.00%] train loss: 2.9305958378245123e-05 \n",
      "epoch: 8 [125543/888800 14.12%] train loss: 2.4626484446343966e-05 \n",
      "epoch: 8 [126654/888800 14.25%] train loss: 2.477108864695765e-05 \n",
      "epoch: 8 [127765/888800 14.38%] train loss: 2.893941018555779e-05 \n",
      "epoch: 8 [128876/888800 14.50%] train loss: 2.440378739265725e-05 \n",
      "epoch: 8 [129987/888800 14.62%] train loss: 2.9238224669825286e-05 \n",
      "epoch: 8 [131098/888800 14.75%] train loss: 2.6319166863686405e-05 \n",
      "epoch: 8 [132209/888800 14.88%] train loss: 2.2526974134962074e-05 \n",
      "epoch: 8 [133320/888800 15.00%] train loss: 2.4689914425835013e-05 \n",
      "epoch: 8 [134431/888800 15.12%] train loss: 2.4515220502507873e-05 \n",
      "epoch: 8 [135542/888800 15.25%] train loss: 2.9046575946267694e-05 \n",
      "epoch: 8 [136653/888800 15.38%] train loss: 2.5321445718873292e-05 \n",
      "epoch: 8 [137764/888800 15.50%] train loss: 2.6365982193965465e-05 \n",
      "epoch: 8 [138875/888800 15.62%] train loss: 3.060609014937654e-05 \n",
      "epoch: 8 [139986/888800 15.75%] train loss: 2.6639692805474624e-05 \n",
      "epoch: 8 [141097/888800 15.88%] train loss: 2.9276081477291882e-05 \n",
      "epoch: 8 [142208/888800 16.00%] train loss: 2.9525504942284897e-05 \n",
      "epoch: 8 [143319/888800 16.12%] train loss: 1.9649412934086286e-05 \n",
      "epoch: 8 [144430/888800 16.25%] train loss: 2.773008236545138e-05 \n",
      "epoch: 8 [145541/888800 16.38%] train loss: 2.5406285203644074e-05 \n",
      "epoch: 8 [146652/888800 16.50%] train loss: 3.101348920608871e-05 \n",
      "epoch: 8 [147763/888800 16.62%] train loss: 3.2449173886561766e-05 \n",
      "epoch: 8 [148874/888800 16.75%] train loss: 2.2199157683644444e-05 \n",
      "epoch: 8 [149985/888800 16.88%] train loss: 2.6773292120196857e-05 \n",
      "epoch: 8 [151096/888800 17.00%] train loss: 3.162933717248961e-05 \n",
      "epoch: 8 [152207/888800 17.12%] train loss: 2.6338215320720337e-05 \n",
      "epoch: 8 [153318/888800 17.25%] train loss: 2.5301749701611698e-05 \n",
      "epoch: 8 [154429/888800 17.38%] train loss: 2.4832614144543186e-05 \n",
      "epoch: 8 [155540/888800 17.50%] train loss: 3.220945654902607e-05 \n",
      "epoch: 8 [156651/888800 17.62%] train loss: 2.7061385480919853e-05 \n",
      "epoch: 8 [157762/888800 17.75%] train loss: 2.5948573238565587e-05 \n",
      "epoch: 8 [158873/888800 17.88%] train loss: 2.940174817922525e-05 \n",
      "epoch: 8 [159984/888800 18.00%] train loss: 2.5635412384872325e-05 \n",
      "epoch: 8 [161095/888800 18.12%] train loss: 2.3523951313109137e-05 \n",
      "epoch: 8 [162206/888800 18.25%] train loss: 2.8129355996497907e-05 \n",
      "epoch: 8 [163317/888800 18.38%] train loss: 2.3585245799040422e-05 \n",
      "epoch: 8 [164428/888800 18.50%] train loss: 2.4093897081911564e-05 \n",
      "epoch: 8 [165539/888800 18.62%] train loss: 2.844787923095282e-05 \n",
      "epoch: 8 [166650/888800 18.75%] train loss: 2.5929395633284003e-05 \n",
      "epoch: 8 [167761/888800 18.88%] train loss: 2.61695258814143e-05 \n",
      "epoch: 8 [168872/888800 19.00%] train loss: 2.4311240849783644e-05 \n",
      "epoch: 8 [169983/888800 19.12%] train loss: 2.6946256184601225e-05 \n",
      "epoch: 8 [171094/888800 19.25%] train loss: 2.5978411940741353e-05 \n",
      "epoch: 8 [172205/888800 19.38%] train loss: 2.645368113007862e-05 \n",
      "epoch: 8 [173316/888800 19.50%] train loss: 2.7996135031571612e-05 \n",
      "epoch: 8 [174427/888800 19.62%] train loss: 2.868894807761535e-05 \n",
      "epoch: 8 [175538/888800 19.75%] train loss: 2.897077865782194e-05 \n",
      "epoch: 8 [176649/888800 19.88%] train loss: 2.4133556507877074e-05 \n",
      "epoch: 8 [177760/888800 20.00%] train loss: 2.9779019314446487e-05 \n",
      "epoch: 8 [178871/888800 20.12%] train loss: 2.9375460144365206e-05 \n",
      "epoch: 8 [179982/888800 20.25%] train loss: 2.7762871468439698e-05 \n",
      "epoch: 8 [181093/888800 20.38%] train loss: 3.0143139156280085e-05 \n",
      "epoch: 8 [182204/888800 20.50%] train loss: 3.108728924416937e-05 \n",
      "epoch: 8 [183315/888800 20.62%] train loss: 2.3713118935120292e-05 \n",
      "epoch: 8 [184426/888800 20.75%] train loss: 2.594931902422104e-05 \n",
      "epoch: 8 [185537/888800 20.88%] train loss: 2.567697265476454e-05 \n",
      "epoch: 8 [186648/888800 21.00%] train loss: 2.7685711756930687e-05 \n",
      "epoch: 8 [187759/888800 21.12%] train loss: 2.664314342837315e-05 \n",
      "epoch: 8 [188870/888800 21.25%] train loss: 2.956255957542453e-05 \n",
      "epoch: 8 [189981/888800 21.38%] train loss: 2.525780837459024e-05 \n",
      "epoch: 8 [191092/888800 21.50%] train loss: 2.4536915589123964e-05 \n",
      "epoch: 8 [192203/888800 21.62%] train loss: 2.4961524104583077e-05 \n",
      "epoch: 8 [193314/888800 21.75%] train loss: 2.4219758415711112e-05 \n",
      "epoch: 8 [194425/888800 21.88%] train loss: 2.627197864057962e-05 \n",
      "epoch: 8 [195536/888800 22.00%] train loss: 2.7639858672046103e-05 \n",
      "epoch: 8 [196647/888800 22.12%] train loss: 2.5831759558059275e-05 \n",
      "epoch: 8 [197758/888800 22.25%] train loss: 2.5993151211878285e-05 \n",
      "epoch: 8 [198869/888800 22.38%] train loss: 2.3570109988213517e-05 \n",
      "epoch: 8 [199980/888800 22.50%] train loss: 2.3379403501166962e-05 \n",
      "epoch: 8 [201091/888800 22.62%] train loss: 2.5192539396812208e-05 \n",
      "epoch: 8 [202202/888800 22.75%] train loss: 2.534680243115872e-05 \n",
      "epoch: 8 [203313/888800 22.88%] train loss: 2.6171204808633775e-05 \n",
      "epoch: 8 [204424/888800 23.00%] train loss: 3.0000162951182574e-05 \n",
      "epoch: 8 [205535/888800 23.12%] train loss: 2.9124441425665282e-05 \n",
      "epoch: 8 [206646/888800 23.25%] train loss: 2.515215783205349e-05 \n",
      "epoch: 8 [207757/888800 23.38%] train loss: 3.4639426303328946e-05 \n",
      "epoch: 8 [208868/888800 23.50%] train loss: 3.082177136093378e-05 \n",
      "epoch: 8 [209979/888800 23.62%] train loss: 2.6049570806208067e-05 \n",
      "epoch: 8 [211090/888800 23.75%] train loss: 2.5088140318985097e-05 \n",
      "epoch: 8 [212201/888800 23.88%] train loss: 2.503273390175309e-05 \n",
      "epoch: 8 [213312/888800 24.00%] train loss: 2.6138926841667853e-05 \n",
      "epoch: 8 [214423/888800 24.12%] train loss: 2.5322242436232045e-05 \n",
      "epoch: 8 [215534/888800 24.25%] train loss: 2.7099964427179657e-05 \n",
      "epoch: 8 [216645/888800 24.38%] train loss: 2.445892823743634e-05 \n",
      "epoch: 8 [217756/888800 24.50%] train loss: 2.6022269594250247e-05 \n",
      "epoch: 8 [218867/888800 24.62%] train loss: 2.5889881726470776e-05 \n",
      "epoch: 8 [219978/888800 24.75%] train loss: 3.0132523534120992e-05 \n",
      "epoch: 8 [221089/888800 24.88%] train loss: 2.7997331926599145e-05 \n",
      "epoch: 8 [222200/888800 25.00%] train loss: 2.749187478912063e-05 \n",
      "epoch: 8 [223311/888800 25.12%] train loss: 2.9033464670646936e-05 \n",
      "epoch: 8 [224422/888800 25.25%] train loss: 2.7462656362331472e-05 \n",
      "epoch: 8 [225533/888800 25.38%] train loss: 2.570512515376322e-05 \n",
      "epoch: 8 [226644/888800 25.50%] train loss: 2.5576162443030626e-05 \n",
      "epoch: 8 [227755/888800 25.62%] train loss: 2.91049054794712e-05 \n",
      "epoch: 8 [228866/888800 25.75%] train loss: 2.720716474868823e-05 \n",
      "epoch: 8 [229977/888800 25.88%] train loss: 2.606052476039622e-05 \n",
      "epoch: 8 [231088/888800 26.00%] train loss: 2.8454163839342073e-05 \n",
      "epoch: 8 [232199/888800 26.12%] train loss: 2.6593666916596703e-05 \n",
      "epoch: 8 [233310/888800 26.25%] train loss: 2.87800285150297e-05 \n",
      "epoch: 8 [234421/888800 26.38%] train loss: 2.8636477509280667e-05 \n",
      "epoch: 8 [235532/888800 26.50%] train loss: 2.9046750569250435e-05 \n",
      "epoch: 8 [236643/888800 26.62%] train loss: 2.726566162891686e-05 \n",
      "epoch: 8 [237754/888800 26.75%] train loss: 2.5352717784699053e-05 \n",
      "epoch: 8 [238865/888800 26.88%] train loss: 2.6142695787712e-05 \n",
      "epoch: 8 [239976/888800 27.00%] train loss: 3.2146981538971886e-05 \n",
      "epoch: 8 [241087/888800 27.12%] train loss: 2.5226401703548618e-05 \n",
      "epoch: 8 [242198/888800 27.25%] train loss: 2.3952799892867915e-05 \n",
      "epoch: 8 [243309/888800 27.38%] train loss: 2.8258464226382785e-05 \n",
      "epoch: 8 [244420/888800 27.50%] train loss: 2.7963635147898458e-05 \n",
      "epoch: 8 [245531/888800 27.62%] train loss: 3.0478280677925795e-05 \n",
      "epoch: 8 [246642/888800 27.75%] train loss: 2.5109135094680823e-05 \n",
      "epoch: 8 [247753/888800 27.88%] train loss: 3.153705984004773e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [248864/888800 28.00%] train loss: 2.4138327717082575e-05 \n",
      "epoch: 8 [249975/888800 28.12%] train loss: 2.4150614990503527e-05 \n",
      "epoch: 8 [251086/888800 28.25%] train loss: 2.6235242330585606e-05 \n",
      "epoch: 8 [252197/888800 28.38%] train loss: 2.7140793463331647e-05 \n",
      "epoch: 8 [253308/888800 28.50%] train loss: 2.9193086447776295e-05 \n",
      "epoch: 8 [254419/888800 28.62%] train loss: 2.6696141503634863e-05 \n",
      "epoch: 8 [255530/888800 28.75%] train loss: 2.185979792557191e-05 \n",
      "epoch: 8 [256641/888800 28.88%] train loss: 2.4674509404576384e-05 \n",
      "epoch: 8 [257752/888800 29.00%] train loss: 2.6624851670931093e-05 \n",
      "epoch: 8 [258863/888800 29.12%] train loss: 2.1626779926009476e-05 \n",
      "epoch: 8 [259974/888800 29.25%] train loss: 2.499931724742055e-05 \n",
      "epoch: 8 [261085/888800 29.38%] train loss: 2.8858908990514465e-05 \n",
      "epoch: 8 [262196/888800 29.50%] train loss: 2.499122274457477e-05 \n",
      "epoch: 8 [263307/888800 29.62%] train loss: 2.733766996243503e-05 \n",
      "epoch: 8 [264418/888800 29.75%] train loss: 2.9948618248454295e-05 \n",
      "epoch: 8 [265529/888800 29.88%] train loss: 2.8406579076545313e-05 \n",
      "epoch: 8 [266640/888800 30.00%] train loss: 2.8622140234801918e-05 \n",
      "epoch: 8 [267751/888800 30.12%] train loss: 2.3229884391184896e-05 \n",
      "epoch: 8 [268862/888800 30.25%] train loss: 2.6357723982073367e-05 \n",
      "epoch: 8 [269973/888800 30.38%] train loss: 3.246105188736692e-05 \n",
      "epoch: 8 [271084/888800 30.50%] train loss: 2.9098648155923e-05 \n",
      "epoch: 8 [272195/888800 30.62%] train loss: 3.105571158812381e-05 \n",
      "epoch: 8 [273306/888800 30.75%] train loss: 2.5496356101939455e-05 \n",
      "epoch: 8 [274417/888800 30.88%] train loss: 2.840902379830368e-05 \n",
      "epoch: 8 [275528/888800 31.00%] train loss: 2.4559009034419432e-05 \n",
      "epoch: 8 [276639/888800 31.12%] train loss: 2.7795702408184297e-05 \n",
      "epoch: 8 [277750/888800 31.25%] train loss: 2.2573502064915374e-05 \n",
      "epoch: 8 [278861/888800 31.38%] train loss: 2.5684905267553404e-05 \n",
      "epoch: 8 [279972/888800 31.50%] train loss: 2.9243421522551216e-05 \n",
      "epoch: 8 [281083/888800 31.62%] train loss: 2.6616080504027195e-05 \n",
      "epoch: 8 [282194/888800 31.75%] train loss: 2.3157417672337033e-05 \n",
      "epoch: 8 [283305/888800 31.88%] train loss: 2.5415371055714786e-05 \n",
      "epoch: 8 [284416/888800 32.00%] train loss: 2.7362922992324457e-05 \n",
      "epoch: 8 [285527/888800 32.12%] train loss: 2.748187762335874e-05 \n",
      "epoch: 8 [286638/888800 32.25%] train loss: 2.263699207105674e-05 \n",
      "epoch: 8 [287749/888800 32.38%] train loss: 2.26461543206824e-05 \n",
      "epoch: 8 [288860/888800 32.50%] train loss: 2.7265527023700997e-05 \n",
      "epoch: 8 [289971/888800 32.62%] train loss: 2.7613088604994118e-05 \n",
      "epoch: 8 [291082/888800 32.75%] train loss: 2.3801845600246452e-05 \n",
      "epoch: 8 [292193/888800 32.88%] train loss: 2.6328101739636622e-05 \n",
      "epoch: 8 [293304/888800 33.00%] train loss: 2.8135029424447566e-05 \n",
      "epoch: 8 [294415/888800 33.12%] train loss: 2.5534589440212585e-05 \n",
      "epoch: 8 [295526/888800 33.25%] train loss: 2.7112984753330238e-05 \n",
      "epoch: 8 [296637/888800 33.38%] train loss: 2.730444975895807e-05 \n",
      "epoch: 8 [297748/888800 33.50%] train loss: 3.0129169317660853e-05 \n",
      "epoch: 8 [298859/888800 33.62%] train loss: 2.2636297217104584e-05 \n",
      "epoch: 8 [299970/888800 33.75%] train loss: 2.7913534722756594e-05 \n",
      "epoch: 8 [301081/888800 33.88%] train loss: 2.505260636098683e-05 \n",
      "epoch: 8 [302192/888800 34.00%] train loss: 3.047883728868328e-05 \n",
      "epoch: 8 [303303/888800 34.12%] train loss: 2.9294114938238636e-05 \n",
      "epoch: 8 [304414/888800 34.25%] train loss: 2.8673590350081213e-05 \n",
      "epoch: 8 [305525/888800 34.38%] train loss: 2.76189275609795e-05 \n",
      "epoch: 8 [306636/888800 34.50%] train loss: 2.904886605392676e-05 \n",
      "epoch: 8 [307747/888800 34.62%] train loss: 3.132376150460914e-05 \n",
      "epoch: 8 [308858/888800 34.75%] train loss: 2.5064917281270027e-05 \n",
      "epoch: 8 [309969/888800 34.88%] train loss: 2.563378802733496e-05 \n",
      "epoch: 8 [311080/888800 35.00%] train loss: 2.85315873043146e-05 \n",
      "epoch: 8 [312191/888800 35.12%] train loss: 2.3704425984760746e-05 \n",
      "epoch: 8 [313302/888800 35.25%] train loss: 2.94992405542871e-05 \n",
      "epoch: 8 [314413/888800 35.38%] train loss: 2.8840688173659146e-05 \n",
      "epoch: 8 [315524/888800 35.50%] train loss: 2.77177296084119e-05 \n",
      "epoch: 8 [316635/888800 35.62%] train loss: 2.5905879738274962e-05 \n",
      "epoch: 8 [317746/888800 35.75%] train loss: 2.0501098333625123e-05 \n",
      "epoch: 8 [318857/888800 35.88%] train loss: 2.8892818590975367e-05 \n",
      "epoch: 8 [319968/888800 36.00%] train loss: 3.1757062970427796e-05 \n",
      "epoch: 8 [321079/888800 36.12%] train loss: 2.7284131647320464e-05 \n",
      "epoch: 8 [322190/888800 36.25%] train loss: 2.6207759219687432e-05 \n",
      "epoch: 8 [323301/888800 36.38%] train loss: 2.4999904780997895e-05 \n",
      "epoch: 8 [324412/888800 36.50%] train loss: 2.7353969926480204e-05 \n",
      "epoch: 8 [325523/888800 36.62%] train loss: 2.4132019461831078e-05 \n",
      "epoch: 8 [326634/888800 36.75%] train loss: 2.9815182642778382e-05 \n",
      "epoch: 8 [327745/888800 36.88%] train loss: 2.8803136956412345e-05 \n",
      "epoch: 8 [328856/888800 37.00%] train loss: 2.078454417642206e-05 \n",
      "epoch: 8 [329967/888800 37.12%] train loss: 2.7282736482447945e-05 \n",
      "epoch: 8 [331078/888800 37.25%] train loss: 2.9667662602150813e-05 \n",
      "epoch: 8 [332189/888800 37.38%] train loss: 2.9906716008554213e-05 \n",
      "epoch: 8 [333300/888800 37.50%] train loss: 2.5931891286745667e-05 \n",
      "epoch: 8 [334411/888800 37.62%] train loss: 2.3881166271166876e-05 \n",
      "epoch: 8 [335522/888800 37.75%] train loss: 2.613157448649872e-05 \n",
      "epoch: 8 [336633/888800 37.88%] train loss: 2.8832628231612034e-05 \n",
      "epoch: 8 [337744/888800 38.00%] train loss: 2.4623790523037314e-05 \n",
      "epoch: 8 [338855/888800 38.12%] train loss: 2.6587369575281627e-05 \n",
      "epoch: 8 [339966/888800 38.25%] train loss: 2.1681156795239076e-05 \n",
      "epoch: 8 [341077/888800 38.38%] train loss: 2.0656099877669476e-05 \n",
      "epoch: 8 [342188/888800 38.50%] train loss: 2.3367399990092963e-05 \n",
      "epoch: 8 [343299/888800 38.62%] train loss: 2.5901888875523582e-05 \n",
      "epoch: 8 [344410/888800 38.75%] train loss: 2.585857146186754e-05 \n",
      "epoch: 8 [345521/888800 38.88%] train loss: 2.062300336547196e-05 \n",
      "epoch: 8 [346632/888800 39.00%] train loss: 2.4206903617596254e-05 \n",
      "epoch: 8 [347743/888800 39.12%] train loss: 2.648130976012908e-05 \n",
      "epoch: 8 [348854/888800 39.25%] train loss: 2.6988684112438932e-05 \n",
      "epoch: 8 [349965/888800 39.38%] train loss: 2.7520090952748433e-05 \n",
      "epoch: 8 [351076/888800 39.50%] train loss: 2.24686609726632e-05 \n",
      "epoch: 8 [352187/888800 39.62%] train loss: 2.3903410692582838e-05 \n",
      "epoch: 8 [353298/888800 39.75%] train loss: 2.3675445845583454e-05 \n",
      "epoch: 8 [354409/888800 39.88%] train loss: 2.7780670279753394e-05 \n",
      "epoch: 8 [355520/888800 40.00%] train loss: 2.3713575501460582e-05 \n",
      "epoch: 8 [356631/888800 40.12%] train loss: 2.722199133131653e-05 \n",
      "epoch: 8 [357742/888800 40.25%] train loss: 3.0442364732152782e-05 \n",
      "epoch: 8 [358853/888800 40.38%] train loss: 2.9162491046008654e-05 \n",
      "epoch: 8 [359964/888800 40.50%] train loss: 2.936767486971803e-05 \n",
      "epoch: 8 [361075/888800 40.62%] train loss: 2.232645420008339e-05 \n",
      "epoch: 8 [362186/888800 40.75%] train loss: 3.254257535445504e-05 \n",
      "epoch: 8 [363297/888800 40.88%] train loss: 2.6676752895582467e-05 \n",
      "epoch: 8 [364408/888800 41.00%] train loss: 2.464431236148812e-05 \n",
      "epoch: 8 [365519/888800 41.12%] train loss: 2.330952338525094e-05 \n",
      "epoch: 8 [366630/888800 41.25%] train loss: 2.788976598822046e-05 \n",
      "epoch: 8 [367741/888800 41.38%] train loss: 2.9065278795314953e-05 \n",
      "epoch: 8 [368852/888800 41.50%] train loss: 2.906720692408271e-05 \n",
      "epoch: 8 [369963/888800 41.62%] train loss: 2.8352114895824343e-05 \n",
      "epoch: 8 [371074/888800 41.75%] train loss: 2.3975417207111605e-05 \n",
      "epoch: 8 [372185/888800 41.88%] train loss: 2.5575229301466607e-05 \n",
      "epoch: 8 [373296/888800 42.00%] train loss: 2.503194446035195e-05 \n",
      "epoch: 8 [374407/888800 42.12%] train loss: 2.5561217626091093e-05 \n",
      "epoch: 8 [375518/888800 42.25%] train loss: 2.1504149117390625e-05 \n",
      "epoch: 8 [376629/888800 42.38%] train loss: 2.679081262613181e-05 \n",
      "epoch: 8 [377740/888800 42.50%] train loss: 2.7564614356379025e-05 \n",
      "epoch: 8 [378851/888800 42.62%] train loss: 2.589903124317061e-05 \n",
      "epoch: 8 [379962/888800 42.75%] train loss: 2.2289690605248325e-05 \n",
      "epoch: 8 [381073/888800 42.88%] train loss: 3.1895626307232305e-05 \n",
      "epoch: 8 [382184/888800 43.00%] train loss: 2.734306144702714e-05 \n",
      "epoch: 8 [383295/888800 43.12%] train loss: 2.330410643480718e-05 \n",
      "epoch: 8 [384406/888800 43.25%] train loss: 2.860588392650243e-05 \n",
      "epoch: 8 [385517/888800 43.38%] train loss: 2.9842763979104348e-05 \n",
      "epoch: 8 [386628/888800 43.50%] train loss: 2.2484227883978747e-05 \n",
      "epoch: 8 [387739/888800 43.62%] train loss: 2.9991326300660148e-05 \n",
      "epoch: 8 [388850/888800 43.75%] train loss: 2.531943391659297e-05 \n",
      "epoch: 8 [389961/888800 43.88%] train loss: 2.4540009690099396e-05 \n",
      "epoch: 8 [391072/888800 44.00%] train loss: 3.123388523817994e-05 \n",
      "epoch: 8 [392183/888800 44.12%] train loss: 2.7556718123378232e-05 \n",
      "epoch: 8 [393294/888800 44.25%] train loss: 2.424879312457051e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [394405/888800 44.38%] train loss: 2.4764802219578996e-05 \n",
      "epoch: 8 [395516/888800 44.50%] train loss: 2.6018959033535793e-05 \n",
      "epoch: 8 [396627/888800 44.62%] train loss: 2.4133967599482276e-05 \n",
      "epoch: 8 [397738/888800 44.75%] train loss: 2.9009308491367847e-05 \n",
      "epoch: 8 [398849/888800 44.88%] train loss: 2.4838374883984216e-05 \n",
      "epoch: 8 [399960/888800 45.00%] train loss: 2.642209074110724e-05 \n",
      "epoch: 8 [401071/888800 45.12%] train loss: 2.4953405954875052e-05 \n",
      "epoch: 8 [402182/888800 45.25%] train loss: 3.102271512034349e-05 \n",
      "epoch: 8 [403293/888800 45.38%] train loss: 2.4303593818331137e-05 \n",
      "epoch: 8 [404404/888800 45.50%] train loss: 2.3979999241419137e-05 \n",
      "epoch: 8 [405515/888800 45.62%] train loss: 2.2819049263489433e-05 \n",
      "epoch: 8 [406626/888800 45.75%] train loss: 2.8697706511593424e-05 \n",
      "epoch: 8 [407737/888800 45.88%] train loss: 2.414114169368986e-05 \n",
      "epoch: 8 [408848/888800 46.00%] train loss: 2.4363953343709e-05 \n",
      "epoch: 8 [409959/888800 46.12%] train loss: 2.715213668125216e-05 \n",
      "epoch: 8 [411070/888800 46.25%] train loss: 2.356636105105281e-05 \n",
      "epoch: 8 [412181/888800 46.38%] train loss: 2.40601093537407e-05 \n",
      "epoch: 8 [413292/888800 46.50%] train loss: 2.9314114726730622e-05 \n",
      "epoch: 8 [414403/888800 46.62%] train loss: 2.485061668267008e-05 \n",
      "epoch: 8 [415514/888800 46.75%] train loss: 2.8793889214284718e-05 \n",
      "epoch: 8 [416625/888800 46.88%] train loss: 2.5227011064998806e-05 \n",
      "epoch: 8 [417736/888800 47.00%] train loss: 2.1745425328845158e-05 \n",
      "epoch: 8 [418847/888800 47.12%] train loss: 2.618890539451968e-05 \n",
      "epoch: 8 [419958/888800 47.25%] train loss: 2.667812987056095e-05 \n",
      "epoch: 8 [421069/888800 47.38%] train loss: 2.522998875065241e-05 \n",
      "epoch: 8 [422180/888800 47.50%] train loss: 2.9950184398330748e-05 \n",
      "epoch: 8 [423291/888800 47.62%] train loss: 2.5969857233576477e-05 \n",
      "epoch: 8 [424402/888800 47.75%] train loss: 2.8524762456072494e-05 \n",
      "epoch: 8 [425513/888800 47.88%] train loss: 2.247653537779115e-05 \n",
      "epoch: 8 [426624/888800 48.00%] train loss: 2.45802821154939e-05 \n",
      "epoch: 8 [427735/888800 48.12%] train loss: 2.720450902415905e-05 \n",
      "epoch: 8 [428846/888800 48.25%] train loss: 2.6744415663415566e-05 \n",
      "epoch: 8 [429957/888800 48.38%] train loss: 2.4931165171437897e-05 \n",
      "epoch: 8 [431068/888800 48.50%] train loss: 2.9512242690543644e-05 \n",
      "epoch: 8 [432179/888800 48.62%] train loss: 2.9221617296570912e-05 \n",
      "epoch: 8 [433290/888800 48.75%] train loss: 2.5872664991766214e-05 \n",
      "epoch: 8 [434401/888800 48.88%] train loss: 2.859527558030095e-05 \n",
      "epoch: 8 [435512/888800 49.00%] train loss: 2.6697593057178892e-05 \n",
      "epoch: 8 [436623/888800 49.12%] train loss: 2.2812408133177087e-05 \n",
      "epoch: 8 [437734/888800 49.25%] train loss: 2.6923991754301824e-05 \n",
      "epoch: 8 [438845/888800 49.38%] train loss: 2.68795538431732e-05 \n",
      "epoch: 8 [439956/888800 49.50%] train loss: 2.428173684165813e-05 \n",
      "epoch: 8 [441067/888800 49.62%] train loss: 2.5236116925952956e-05 \n",
      "epoch: 8 [442178/888800 49.75%] train loss: 2.018586928898003e-05 \n",
      "epoch: 8 [443289/888800 49.88%] train loss: 2.1379051759140566e-05 \n",
      "epoch: 8 [444400/888800 50.00%] train loss: 2.2453497876995243e-05 \n",
      "epoch: 8 [445511/888800 50.12%] train loss: 2.267616036988329e-05 \n",
      "epoch: 8 [446622/888800 50.25%] train loss: 2.0576524548232555e-05 \n",
      "epoch: 8 [447733/888800 50.38%] train loss: 2.6007852284237742e-05 \n",
      "epoch: 8 [448844/888800 50.50%] train loss: 2.926575325545855e-05 \n",
      "epoch: 8 [449955/888800 50.62%] train loss: 2.497803325240966e-05 \n",
      "epoch: 8 [451066/888800 50.75%] train loss: 2.5034747523022816e-05 \n",
      "epoch: 8 [452177/888800 50.88%] train loss: 2.5603334506740794e-05 \n",
      "epoch: 8 [453288/888800 51.00%] train loss: 2.2521289793075994e-05 \n",
      "epoch: 8 [454399/888800 51.12%] train loss: 2.2283684302237816e-05 \n",
      "epoch: 8 [455510/888800 51.25%] train loss: 2.3645297915209085e-05 \n",
      "epoch: 8 [456621/888800 51.38%] train loss: 2.646472603373695e-05 \n",
      "epoch: 8 [457732/888800 51.50%] train loss: 2.5955174351111054e-05 \n",
      "epoch: 8 [458843/888800 51.62%] train loss: 2.8302361897658557e-05 \n",
      "epoch: 8 [459954/888800 51.75%] train loss: 3.0093784516793676e-05 \n",
      "epoch: 8 [461065/888800 51.88%] train loss: 2.2754989913664758e-05 \n",
      "epoch: 8 [462176/888800 52.00%] train loss: 2.3717151634627953e-05 \n",
      "epoch: 8 [463287/888800 52.12%] train loss: 2.7553913241717964e-05 \n",
      "epoch: 8 [464398/888800 52.25%] train loss: 3.0019309633644298e-05 \n",
      "epoch: 8 [465509/888800 52.38%] train loss: 3.006972292496357e-05 \n",
      "epoch: 8 [466620/888800 52.50%] train loss: 3.022954479092732e-05 \n",
      "epoch: 8 [467731/888800 52.62%] train loss: 2.2870424800203182e-05 \n",
      "epoch: 8 [468842/888800 52.75%] train loss: 2.539227352826856e-05 \n",
      "epoch: 8 [469953/888800 52.88%] train loss: 2.761192990874406e-05 \n",
      "epoch: 8 [471064/888800 53.00%] train loss: 2.5854347768472508e-05 \n",
      "epoch: 8 [472175/888800 53.12%] train loss: 2.924962609540671e-05 \n",
      "epoch: 8 [473286/888800 53.25%] train loss: 2.208654950663913e-05 \n",
      "epoch: 8 [474397/888800 53.38%] train loss: 2.8576065233210102e-05 \n",
      "epoch: 8 [475508/888800 53.50%] train loss: 2.259457323816605e-05 \n",
      "epoch: 8 [476619/888800 53.62%] train loss: 2.4209401090047322e-05 \n",
      "epoch: 8 [477730/888800 53.75%] train loss: 2.0231553207850084e-05 \n",
      "epoch: 8 [478841/888800 53.88%] train loss: 2.857679282897152e-05 \n",
      "epoch: 8 [479952/888800 54.00%] train loss: 2.4557624783483334e-05 \n",
      "epoch: 8 [481063/888800 54.12%] train loss: 2.410878732916899e-05 \n",
      "epoch: 8 [482174/888800 54.25%] train loss: 3.0319344659801573e-05 \n",
      "epoch: 8 [483285/888800 54.38%] train loss: 2.9759672543150373e-05 \n",
      "epoch: 8 [484396/888800 54.50%] train loss: 2.8270042093936354e-05 \n",
      "epoch: 8 [485507/888800 54.62%] train loss: 2.465062789269723e-05 \n",
      "epoch: 8 [486618/888800 54.75%] train loss: 2.6162022550124675e-05 \n",
      "epoch: 8 [487729/888800 54.88%] train loss: 2.8493630452430807e-05 \n",
      "epoch: 8 [488840/888800 55.00%] train loss: 2.2775493562221527e-05 \n",
      "epoch: 8 [489951/888800 55.12%] train loss: 2.1493064195965417e-05 \n",
      "epoch: 8 [491062/888800 55.25%] train loss: 2.6479779990040697e-05 \n",
      "epoch: 8 [492173/888800 55.38%] train loss: 2.4001255951588973e-05 \n",
      "epoch: 8 [493284/888800 55.50%] train loss: 2.1767153157270513e-05 \n",
      "epoch: 8 [494395/888800 55.62%] train loss: 2.647194378369022e-05 \n",
      "epoch: 8 [495506/888800 55.75%] train loss: 2.5963483494706452e-05 \n",
      "epoch: 8 [496617/888800 55.88%] train loss: 2.326990397705231e-05 \n",
      "epoch: 8 [497728/888800 56.00%] train loss: 2.6306286599719897e-05 \n",
      "epoch: 8 [498839/888800 56.12%] train loss: 2.975597271870356e-05 \n",
      "epoch: 8 [499950/888800 56.25%] train loss: 2.295214835612569e-05 \n",
      "epoch: 8 [501061/888800 56.38%] train loss: 2.0279214368201792e-05 \n",
      "epoch: 8 [502172/888800 56.50%] train loss: 2.0729939933517016e-05 \n",
      "epoch: 8 [503283/888800 56.62%] train loss: 2.236556974821724e-05 \n",
      "epoch: 8 [504394/888800 56.75%] train loss: 2.2419071683543734e-05 \n",
      "epoch: 8 [505505/888800 56.88%] train loss: 2.5425968487979844e-05 \n",
      "epoch: 8 [506616/888800 57.00%] train loss: 2.7146666980115697e-05 \n",
      "epoch: 8 [507727/888800 57.12%] train loss: 3.115189610980451e-05 \n",
      "epoch: 8 [508838/888800 57.25%] train loss: 2.2026679289410822e-05 \n",
      "epoch: 8 [509949/888800 57.38%] train loss: 2.214882624684833e-05 \n",
      "epoch: 8 [511060/888800 57.50%] train loss: 2.3037933715386316e-05 \n",
      "epoch: 8 [512171/888800 57.62%] train loss: 2.6533811251283623e-05 \n",
      "epoch: 8 [513282/888800 57.75%] train loss: 2.487783058313653e-05 \n",
      "epoch: 8 [514393/888800 57.88%] train loss: 2.283221147081349e-05 \n",
      "epoch: 8 [515504/888800 58.00%] train loss: 2.6302259357180446e-05 \n",
      "epoch: 8 [516615/888800 58.12%] train loss: 2.571898585301824e-05 \n",
      "epoch: 8 [517726/888800 58.25%] train loss: 2.61302811850328e-05 \n",
      "epoch: 8 [518837/888800 58.38%] train loss: 2.5312132493127137e-05 \n",
      "epoch: 8 [519948/888800 58.50%] train loss: 2.3009251890471205e-05 \n",
      "epoch: 8 [521059/888800 58.62%] train loss: 2.5681340048322454e-05 \n",
      "epoch: 8 [522170/888800 58.75%] train loss: 2.9137081583030522e-05 \n",
      "epoch: 8 [523281/888800 58.88%] train loss: 2.29608231165912e-05 \n",
      "epoch: 8 [524392/888800 59.00%] train loss: 2.4764651243458502e-05 \n",
      "epoch: 8 [525503/888800 59.12%] train loss: 2.539874731155578e-05 \n",
      "epoch: 8 [526614/888800 59.25%] train loss: 2.2432301193475723e-05 \n",
      "epoch: 8 [527725/888800 59.38%] train loss: 2.742617107287515e-05 \n",
      "epoch: 8 [528836/888800 59.50%] train loss: 2.703780774027109e-05 \n",
      "epoch: 8 [529947/888800 59.62%] train loss: 2.579037936811801e-05 \n",
      "epoch: 8 [531058/888800 59.75%] train loss: 2.3184140445664525e-05 \n",
      "epoch: 8 [532169/888800 59.88%] train loss: 2.312988908670377e-05 \n",
      "epoch: 8 [533280/888800 60.00%] train loss: 2.0832798327319324e-05 \n",
      "epoch: 8 [534391/888800 60.12%] train loss: 2.554803177190479e-05 \n",
      "epoch: 8 [535502/888800 60.25%] train loss: 2.422986290184781e-05 \n",
      "epoch: 8 [536613/888800 60.38%] train loss: 2.911561205110047e-05 \n",
      "epoch: 8 [537724/888800 60.50%] train loss: 2.6302746846340597e-05 \n",
      "epoch: 8 [538835/888800 60.62%] train loss: 2.540874447731767e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [539946/888800 60.75%] train loss: 2.8903159545734525e-05 \n",
      "epoch: 8 [541057/888800 60.88%] train loss: 2.4162936824723147e-05 \n",
      "epoch: 8 [542168/888800 61.00%] train loss: 3.082418697886169e-05 \n",
      "epoch: 8 [543279/888800 61.12%] train loss: 2.4178207240765914e-05 \n",
      "epoch: 8 [544390/888800 61.25%] train loss: 2.409169974271208e-05 \n",
      "epoch: 8 [545501/888800 61.38%] train loss: 2.2527119654114358e-05 \n",
      "epoch: 8 [546612/888800 61.50%] train loss: 2.720038355619181e-05 \n",
      "epoch: 8 [547723/888800 61.62%] train loss: 2.1698633645428345e-05 \n",
      "epoch: 8 [548834/888800 61.75%] train loss: 2.2147012714412995e-05 \n",
      "epoch: 8 [549945/888800 61.88%] train loss: 2.913495700340718e-05 \n",
      "epoch: 8 [551056/888800 62.00%] train loss: 2.608034628792666e-05 \n",
      "epoch: 8 [552167/888800 62.12%] train loss: 2.461105577822309e-05 \n",
      "epoch: 8 [553278/888800 62.25%] train loss: 2.695478906389326e-05 \n",
      "epoch: 8 [554389/888800 62.38%] train loss: 2.5490784537396394e-05 \n",
      "epoch: 8 [555500/888800 62.50%] train loss: 2.7173366106580943e-05 \n",
      "epoch: 8 [556611/888800 62.62%] train loss: 2.8975720852031372e-05 \n",
      "epoch: 8 [557722/888800 62.75%] train loss: 2.467240483383648e-05 \n",
      "epoch: 8 [558833/888800 62.88%] train loss: 2.4180490072467364e-05 \n",
      "epoch: 8 [559944/888800 63.00%] train loss: 2.5780080250115134e-05 \n",
      "epoch: 8 [561055/888800 63.12%] train loss: 2.1702458980144e-05 \n",
      "epoch: 8 [562166/888800 63.25%] train loss: 2.742530887189787e-05 \n",
      "epoch: 8 [563277/888800 63.38%] train loss: 2.579140527814161e-05 \n",
      "epoch: 8 [564388/888800 63.50%] train loss: 2.38629163504811e-05 \n",
      "epoch: 8 [565499/888800 63.62%] train loss: 2.6239176804665476e-05 \n",
      "epoch: 8 [566610/888800 63.75%] train loss: 2.318076258234214e-05 \n",
      "epoch: 8 [567721/888800 63.88%] train loss: 1.941882146638818e-05 \n",
      "epoch: 8 [568832/888800 64.00%] train loss: 2.9042692403891124e-05 \n",
      "epoch: 8 [569943/888800 64.12%] train loss: 2.6994081053999253e-05 \n",
      "epoch: 8 [571054/888800 64.25%] train loss: 2.817615859385114e-05 \n",
      "epoch: 8 [572165/888800 64.38%] train loss: 2.881256295950152e-05 \n",
      "epoch: 8 [573276/888800 64.50%] train loss: 2.7363486879039556e-05 \n",
      "epoch: 8 [574387/888800 64.62%] train loss: 2.1351055693230592e-05 \n",
      "epoch: 8 [575498/888800 64.75%] train loss: 2.8586990083567798e-05 \n",
      "epoch: 8 [576609/888800 64.88%] train loss: 2.3819318812456913e-05 \n",
      "epoch: 8 [577720/888800 65.00%] train loss: 2.4891347493394278e-05 \n",
      "epoch: 8 [578831/888800 65.12%] train loss: 2.783729178190697e-05 \n",
      "epoch: 8 [579942/888800 65.25%] train loss: 2.6310086468583904e-05 \n",
      "epoch: 8 [581053/888800 65.38%] train loss: 2.318413316970691e-05 \n",
      "epoch: 8 [582164/888800 65.50%] train loss: 2.379254874540493e-05 \n",
      "epoch: 8 [583275/888800 65.62%] train loss: 2.0524194042081945e-05 \n",
      "epoch: 8 [584386/888800 65.75%] train loss: 2.2857902877149172e-05 \n",
      "epoch: 8 [585497/888800 65.88%] train loss: 2.305949601577595e-05 \n",
      "epoch: 8 [586608/888800 66.00%] train loss: 2.7476729883346707e-05 \n",
      "epoch: 8 [587719/888800 66.12%] train loss: 2.2788184651290067e-05 \n",
      "epoch: 8 [588830/888800 66.25%] train loss: 2.3966051230672747e-05 \n",
      "epoch: 8 [589941/888800 66.38%] train loss: 3.03471115330467e-05 \n",
      "epoch: 8 [591052/888800 66.50%] train loss: 2.6841913495445624e-05 \n",
      "epoch: 8 [592163/888800 66.62%] train loss: 2.4634373403387144e-05 \n",
      "epoch: 8 [593274/888800 66.75%] train loss: 2.6566371161607094e-05 \n",
      "epoch: 8 [594385/888800 66.88%] train loss: 2.2895197616890073e-05 \n",
      "epoch: 8 [595496/888800 67.00%] train loss: 2.1768308215541765e-05 \n",
      "epoch: 8 [596607/888800 67.12%] train loss: 2.6695306587498635e-05 \n",
      "epoch: 8 [597718/888800 67.25%] train loss: 2.5051187549252063e-05 \n",
      "epoch: 8 [598829/888800 67.38%] train loss: 2.1834752260474488e-05 \n",
      "epoch: 8 [599940/888800 67.50%] train loss: 2.703872451093048e-05 \n",
      "epoch: 8 [601051/888800 67.62%] train loss: 2.850684722943697e-05 \n",
      "epoch: 8 [602162/888800 67.75%] train loss: 2.306175338162575e-05 \n",
      "epoch: 8 [603273/888800 67.88%] train loss: 2.2594053007196635e-05 \n",
      "epoch: 8 [604384/888800 68.00%] train loss: 2.670219328138046e-05 \n",
      "epoch: 8 [605495/888800 68.12%] train loss: 2.2048452592571266e-05 \n",
      "epoch: 8 [606606/888800 68.25%] train loss: 2.8179223590996116e-05 \n",
      "epoch: 8 [607717/888800 68.38%] train loss: 2.6562574930721894e-05 \n",
      "epoch: 8 [608828/888800 68.50%] train loss: 2.5996863769250922e-05 \n",
      "epoch: 8 [609939/888800 68.62%] train loss: 2.5054672732949257e-05 \n",
      "epoch: 8 [611050/888800 68.75%] train loss: 2.333247357455548e-05 \n",
      "epoch: 8 [612161/888800 68.88%] train loss: 2.6077441361849196e-05 \n",
      "epoch: 8 [613272/888800 69.00%] train loss: 2.368770401517395e-05 \n",
      "epoch: 8 [614383/888800 69.12%] train loss: 2.3662345483899117e-05 \n",
      "epoch: 8 [615494/888800 69.25%] train loss: 2.33818336710101e-05 \n",
      "epoch: 8 [616605/888800 69.38%] train loss: 2.4273920644191094e-05 \n",
      "epoch: 8 [617716/888800 69.50%] train loss: 2.4470631615258753e-05 \n",
      "epoch: 8 [618827/888800 69.62%] train loss: 2.3035736376186833e-05 \n",
      "epoch: 8 [619938/888800 69.75%] train loss: 2.3819724447093904e-05 \n",
      "epoch: 8 [621049/888800 69.88%] train loss: 2.8982323783566244e-05 \n",
      "epoch: 8 [622160/888800 70.00%] train loss: 2.5517487301840447e-05 \n",
      "epoch: 8 [623271/888800 70.12%] train loss: 2.372177732468117e-05 \n",
      "epoch: 8 [624382/888800 70.25%] train loss: 2.7480880817165598e-05 \n",
      "epoch: 8 [625493/888800 70.38%] train loss: 2.263600799778942e-05 \n",
      "epoch: 8 [626604/888800 70.50%] train loss: 2.2595228074351326e-05 \n",
      "epoch: 8 [627715/888800 70.62%] train loss: 2.6593339498504065e-05 \n",
      "epoch: 8 [628826/888800 70.75%] train loss: 2.6103598429472186e-05 \n",
      "epoch: 8 [629937/888800 70.88%] train loss: 2.85301521216752e-05 \n",
      "epoch: 8 [631048/888800 71.00%] train loss: 2.514366860850714e-05 \n",
      "epoch: 8 [632159/888800 71.12%] train loss: 2.4417711756541394e-05 \n",
      "epoch: 8 [633270/888800 71.25%] train loss: 2.2416608771891333e-05 \n",
      "epoch: 8 [634381/888800 71.38%] train loss: 2.168254832213279e-05 \n",
      "epoch: 8 [635492/888800 71.50%] train loss: 1.9946368411183357e-05 \n",
      "epoch: 8 [636603/888800 71.62%] train loss: 2.7048023184761405e-05 \n",
      "epoch: 8 [637714/888800 71.75%] train loss: 2.5340377760585397e-05 \n",
      "epoch: 8 [638825/888800 71.88%] train loss: 2.7231213607592508e-05 \n",
      "epoch: 8 [639936/888800 72.00%] train loss: 2.1015212041675113e-05 \n",
      "epoch: 8 [641047/888800 72.12%] train loss: 2.3009404685581103e-05 \n",
      "epoch: 8 [642158/888800 72.25%] train loss: 2.1400592231657356e-05 \n",
      "epoch: 8 [643269/888800 72.38%] train loss: 2.746891914284788e-05 \n",
      "epoch: 8 [644380/888800 72.50%] train loss: 2.3474425688618794e-05 \n",
      "epoch: 8 [645491/888800 72.62%] train loss: 2.7866402888321318e-05 \n",
      "epoch: 8 [646602/888800 72.75%] train loss: 2.5272933271480724e-05 \n",
      "epoch: 8 [647713/888800 72.88%] train loss: 2.1284482500050217e-05 \n",
      "epoch: 8 [648824/888800 73.00%] train loss: 2.5252542400266975e-05 \n",
      "epoch: 8 [649935/888800 73.12%] train loss: 2.5267050659749657e-05 \n",
      "epoch: 8 [651046/888800 73.25%] train loss: 2.274303369631525e-05 \n",
      "epoch: 8 [652157/888800 73.38%] train loss: 2.4143992050085217e-05 \n",
      "epoch: 8 [653268/888800 73.50%] train loss: 2.7264870368526317e-05 \n",
      "epoch: 8 [654379/888800 73.62%] train loss: 2.2733007426722907e-05 \n",
      "epoch: 8 [655490/888800 73.75%] train loss: 2.031249096035026e-05 \n",
      "epoch: 8 [656601/888800 73.88%] train loss: 2.451715226925444e-05 \n",
      "epoch: 8 [657712/888800 74.00%] train loss: 2.100665369653143e-05 \n",
      "epoch: 8 [658823/888800 74.12%] train loss: 2.1754616682301275e-05 \n",
      "epoch: 8 [659934/888800 74.25%] train loss: 2.1859292246517725e-05 \n",
      "epoch: 8 [661045/888800 74.38%] train loss: 2.655429307196755e-05 \n",
      "epoch: 8 [662156/888800 74.50%] train loss: 2.5219553208444268e-05 \n",
      "epoch: 8 [663267/888800 74.62%] train loss: 2.197914909629617e-05 \n",
      "epoch: 8 [664378/888800 74.75%] train loss: 2.5936844394891523e-05 \n",
      "epoch: 8 [665489/888800 74.88%] train loss: 2.1514040781767108e-05 \n",
      "epoch: 8 [666600/888800 75.00%] train loss: 2.4007729734876193e-05 \n",
      "epoch: 8 [667711/888800 75.12%] train loss: 2.5036446459125727e-05 \n",
      "epoch: 8 [668822/888800 75.25%] train loss: 2.590770054666791e-05 \n",
      "epoch: 8 [669933/888800 75.38%] train loss: 2.520887937862426e-05 \n",
      "epoch: 8 [671044/888800 75.50%] train loss: 2.00124632101506e-05 \n",
      "epoch: 8 [672155/888800 75.62%] train loss: 2.0513165509328246e-05 \n",
      "epoch: 8 [673266/888800 75.75%] train loss: 2.3279988454305567e-05 \n",
      "epoch: 8 [674377/888800 75.88%] train loss: 2.2732092475052923e-05 \n",
      "epoch: 8 [675488/888800 76.00%] train loss: 2.4787974325590767e-05 \n",
      "epoch: 8 [676599/888800 76.12%] train loss: 2.7333615435054526e-05 \n",
      "epoch: 8 [677710/888800 76.25%] train loss: 2.1220896087470464e-05 \n",
      "epoch: 8 [678821/888800 76.38%] train loss: 2.453576416883152e-05 \n",
      "epoch: 8 [679932/888800 76.50%] train loss: 2.4423257855232805e-05 \n",
      "epoch: 8 [681043/888800 76.62%] train loss: 2.3182421500678174e-05 \n",
      "epoch: 8 [682154/888800 76.75%] train loss: 2.5049705072888173e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [683265/888800 76.88%] train loss: 2.2530884962179698e-05 \n",
      "epoch: 8 [684376/888800 77.00%] train loss: 2.094402225338854e-05 \n",
      "epoch: 8 [685487/888800 77.12%] train loss: 2.5219635062967427e-05 \n",
      "epoch: 8 [686598/888800 77.25%] train loss: 2.020631291088648e-05 \n",
      "epoch: 8 [687709/888800 77.38%] train loss: 2.0652303646784276e-05 \n",
      "epoch: 8 [688820/888800 77.50%] train loss: 2.7367394068278372e-05 \n",
      "epoch: 8 [689931/888800 77.62%] train loss: 2.6867794076679274e-05 \n",
      "epoch: 8 [691042/888800 77.75%] train loss: 2.3879050786490552e-05 \n",
      "epoch: 8 [692153/888800 77.88%] train loss: 2.131036490027327e-05 \n",
      "epoch: 8 [693264/888800 78.00%] train loss: 2.5138366254395805e-05 \n",
      "epoch: 8 [694375/888800 78.12%] train loss: 2.6027870262623765e-05 \n",
      "epoch: 8 [695486/888800 78.25%] train loss: 2.150183354387991e-05 \n",
      "epoch: 8 [696597/888800 78.38%] train loss: 2.7470803615869954e-05 \n",
      "epoch: 8 [697708/888800 78.50%] train loss: 2.6997011445928365e-05 \n",
      "epoch: 8 [698819/888800 78.62%] train loss: 2.4435701561742462e-05 \n",
      "epoch: 8 [699930/888800 78.75%] train loss: 2.3376474928227253e-05 \n",
      "epoch: 8 [701041/888800 78.88%] train loss: 2.3234686523210257e-05 \n",
      "epoch: 8 [702152/888800 79.00%] train loss: 2.1404450308182277e-05 \n",
      "epoch: 8 [703263/888800 79.12%] train loss: 2.508426405256614e-05 \n",
      "epoch: 8 [704374/888800 79.25%] train loss: 2.317847429367248e-05 \n",
      "epoch: 8 [705485/888800 79.38%] train loss: 2.2500935301650316e-05 \n",
      "epoch: 8 [706596/888800 79.50%] train loss: 2.342401785426773e-05 \n",
      "epoch: 8 [707707/888800 79.62%] train loss: 2.496061824786011e-05 \n",
      "epoch: 8 [708818/888800 79.75%] train loss: 2.3218719434225932e-05 \n",
      "epoch: 8 [709929/888800 79.88%] train loss: 2.364116517128423e-05 \n",
      "epoch: 8 [711040/888800 80.00%] train loss: 2.6082474505528808e-05 \n",
      "epoch: 8 [712151/888800 80.12%] train loss: 2.3578573745908216e-05 \n",
      "epoch: 8 [713262/888800 80.25%] train loss: 2.2942069335840642e-05 \n",
      "epoch: 8 [714373/888800 80.38%] train loss: 2.489114376658108e-05 \n",
      "epoch: 8 [715484/888800 80.50%] train loss: 2.3421614969265647e-05 \n",
      "epoch: 8 [716595/888800 80.62%] train loss: 2.234133171441499e-05 \n",
      "epoch: 8 [717706/888800 80.75%] train loss: 2.702953679545317e-05 \n",
      "epoch: 8 [718817/888800 80.88%] train loss: 2.292296994710341e-05 \n",
      "epoch: 8 [719928/888800 81.00%] train loss: 1.9161358068231493e-05 \n",
      "epoch: 8 [721039/888800 81.12%] train loss: 2.434304406051524e-05 \n",
      "epoch: 8 [722150/888800 81.25%] train loss: 2.3963340936461464e-05 \n",
      "epoch: 8 [723261/888800 81.38%] train loss: 2.2241049009608105e-05 \n",
      "epoch: 8 [724372/888800 81.50%] train loss: 2.0134579244768247e-05 \n",
      "epoch: 8 [725483/888800 81.62%] train loss: 2.5717399694258347e-05 \n",
      "epoch: 8 [726594/888800 81.75%] train loss: 2.3469789084629156e-05 \n",
      "epoch: 8 [727705/888800 81.88%] train loss: 2.685113940970041e-05 \n",
      "epoch: 8 [728816/888800 82.00%] train loss: 1.9916325982194394e-05 \n",
      "epoch: 8 [729927/888800 82.12%] train loss: 2.2112631995696574e-05 \n",
      "epoch: 8 [731038/888800 82.25%] train loss: 2.5121233193203807e-05 \n",
      "epoch: 8 [732149/888800 82.38%] train loss: 2.3499034796259366e-05 \n",
      "epoch: 8 [733260/888800 82.50%] train loss: 2.405249688308686e-05 \n",
      "epoch: 8 [734371/888800 82.62%] train loss: 2.6670328225009143e-05 \n",
      "epoch: 8 [735482/888800 82.75%] train loss: 2.1244020899757743e-05 \n",
      "epoch: 8 [736593/888800 82.88%] train loss: 2.240666617581155e-05 \n",
      "epoch: 8 [737704/888800 83.00%] train loss: 2.6771367629407905e-05 \n",
      "epoch: 8 [738815/888800 83.12%] train loss: 2.338191552553326e-05 \n",
      "epoch: 8 [739926/888800 83.25%] train loss: 2.2813213945482858e-05 \n",
      "epoch: 8 [741037/888800 83.38%] train loss: 2.81732136500068e-05 \n",
      "epoch: 8 [742148/888800 83.50%] train loss: 2.4459925043629482e-05 \n",
      "epoch: 8 [743259/888800 83.62%] train loss: 2.605336339911446e-05 \n",
      "epoch: 8 [744370/888800 83.75%] train loss: 2.3484522898797877e-05 \n",
      "epoch: 8 [745481/888800 83.88%] train loss: 2.407595093245618e-05 \n",
      "epoch: 8 [746592/888800 84.00%] train loss: 2.4830211259541102e-05 \n",
      "epoch: 8 [747703/888800 84.12%] train loss: 2.6755029466585256e-05 \n",
      "epoch: 8 [748814/888800 84.25%] train loss: 2.1358202502597123e-05 \n",
      "epoch: 8 [749925/888800 84.38%] train loss: 2.4255847165477462e-05 \n",
      "epoch: 8 [751036/888800 84.50%] train loss: 2.452480657666456e-05 \n",
      "epoch: 8 [752147/888800 84.62%] train loss: 2.4759081497904845e-05 \n",
      "epoch: 8 [753258/888800 84.75%] train loss: 2.1201401978032663e-05 \n",
      "epoch: 8 [754369/888800 84.88%] train loss: 2.104722079820931e-05 \n",
      "epoch: 8 [755480/888800 85.00%] train loss: 2.082384889945388e-05 \n",
      "epoch: 8 [756591/888800 85.12%] train loss: 2.3593773221364245e-05 \n",
      "epoch: 8 [757702/888800 85.25%] train loss: 2.3848950149840675e-05 \n",
      "epoch: 8 [758813/888800 85.38%] train loss: 2.515547748771496e-05 \n",
      "epoch: 8 [759924/888800 85.50%] train loss: 2.5026698494912125e-05 \n",
      "epoch: 8 [761035/888800 85.62%] train loss: 2.1992551410221495e-05 \n",
      "epoch: 8 [762146/888800 85.75%] train loss: 2.4133973056450486e-05 \n",
      "epoch: 8 [763257/888800 85.88%] train loss: 2.363523526582867e-05 \n",
      "epoch: 8 [764368/888800 86.00%] train loss: 2.713821413635742e-05 \n",
      "epoch: 8 [765479/888800 86.12%] train loss: 2.4593944544903934e-05 \n",
      "epoch: 8 [766590/888800 86.25%] train loss: 2.3392634830088355e-05 \n",
      "epoch: 8 [767701/888800 86.38%] train loss: 2.333178599656094e-05 \n",
      "epoch: 8 [768812/888800 86.50%] train loss: 2.115927782142535e-05 \n",
      "epoch: 8 [769923/888800 86.62%] train loss: 2.3608192350366153e-05 \n",
      "epoch: 8 [771034/888800 86.75%] train loss: 2.2304873709799722e-05 \n",
      "epoch: 8 [772145/888800 86.88%] train loss: 2.2409325538319536e-05 \n",
      "epoch: 8 [773256/888800 87.00%] train loss: 2.7030700948671438e-05 \n",
      "epoch: 8 [774367/888800 87.12%] train loss: 2.491371924406849e-05 \n",
      "epoch: 8 [775478/888800 87.25%] train loss: 2.4952023522928357e-05 \n",
      "epoch: 8 [776589/888800 87.38%] train loss: 2.8915213988511823e-05 \n",
      "epoch: 8 [777700/888800 87.50%] train loss: 2.5001108951983042e-05 \n",
      "epoch: 8 [778811/888800 87.62%] train loss: 2.3018053980194964e-05 \n",
      "epoch: 8 [779922/888800 87.75%] train loss: 2.389368091826327e-05 \n",
      "epoch: 8 [781033/888800 87.88%] train loss: 2.707509156607557e-05 \n",
      "epoch: 8 [782144/888800 88.00%] train loss: 2.048742135229986e-05 \n",
      "epoch: 8 [783255/888800 88.12%] train loss: 2.0795370801351964e-05 \n",
      "epoch: 8 [784366/888800 88.25%] train loss: 2.4002743884921074e-05 \n",
      "epoch: 8 [785477/888800 88.38%] train loss: 1.9065792002948e-05 \n",
      "epoch: 8 [786588/888800 88.50%] train loss: 2.3526052245870233e-05 \n",
      "epoch: 8 [787699/888800 88.62%] train loss: 2.089373992930632e-05 \n",
      "epoch: 8 [788810/888800 88.75%] train loss: 2.367277556913905e-05 \n",
      "epoch: 8 [789921/888800 88.88%] train loss: 2.340319406357594e-05 \n",
      "epoch: 8 [791032/888800 89.00%] train loss: 2.732316352194175e-05 \n",
      "epoch: 8 [792143/888800 89.12%] train loss: 2.0883424440398812e-05 \n",
      "epoch: 8 [793254/888800 89.25%] train loss: 2.024143213930074e-05 \n",
      "epoch: 8 [794365/888800 89.38%] train loss: 2.4141165340552106e-05 \n",
      "epoch: 8 [795476/888800 89.50%] train loss: 2.1453115550684743e-05 \n",
      "epoch: 8 [796587/888800 89.62%] train loss: 2.3232150851981714e-05 \n",
      "epoch: 8 [797698/888800 89.75%] train loss: 2.209831654909067e-05 \n",
      "epoch: 8 [798809/888800 89.88%] train loss: 1.834389149735216e-05 \n",
      "epoch: 8 [799920/888800 90.00%] train loss: 2.201800270995591e-05 \n",
      "epoch: 8 [801031/888800 90.12%] train loss: 1.9679437173181213e-05 \n",
      "epoch: 8 [802142/888800 90.25%] train loss: 2.3641936422791332e-05 \n",
      "epoch: 8 [803253/888800 90.38%] train loss: 2.0556111849145964e-05 \n",
      "epoch: 8 [804364/888800 90.50%] train loss: 2.3164324375102296e-05 \n",
      "epoch: 8 [805475/888800 90.62%] train loss: 2.4851286070770584e-05 \n",
      "epoch: 8 [806586/888800 90.75%] train loss: 2.2114109015092254e-05 \n",
      "epoch: 8 [807697/888800 90.88%] train loss: 2.329214839846827e-05 \n",
      "epoch: 8 [808808/888800 91.00%] train loss: 2.1996707801008597e-05 \n",
      "epoch: 8 [809919/888800 91.12%] train loss: 2.465609577484429e-05 \n",
      "epoch: 8 [811030/888800 91.25%] train loss: 2.5068815375561826e-05 \n",
      "epoch: 8 [812141/888800 91.38%] train loss: 2.5349216230097227e-05 \n",
      "epoch: 8 [813252/888800 91.50%] train loss: 2.4297323761857115e-05 \n",
      "epoch: 8 [814363/888800 91.62%] train loss: 2.3104606952983886e-05 \n",
      "epoch: 8 [815474/888800 91.75%] train loss: 2.4827422748785466e-05 \n",
      "epoch: 8 [816585/888800 91.88%] train loss: 2.5644716515671462e-05 \n",
      "epoch: 8 [817696/888800 92.00%] train loss: 2.2695059669786133e-05 \n",
      "epoch: 8 [818807/888800 92.12%] train loss: 2.3255857740878128e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 [819918/888800 92.25%] train loss: 2.481606679793913e-05 \n",
      "epoch: 8 [821029/888800 92.38%] train loss: 2.5363826352986507e-05 \n",
      "epoch: 8 [822140/888800 92.50%] train loss: 2.119236705766525e-05 \n",
      "epoch: 8 [823251/888800 92.62%] train loss: 2.4594297428848222e-05 \n",
      "epoch: 8 [824362/888800 92.75%] train loss: 2.0115141524001956e-05 \n",
      "epoch: 8 [825473/888800 92.88%] train loss: 2.1316249330993742e-05 \n",
      "epoch: 8 [826584/888800 93.00%] train loss: 2.4409226170973852e-05 \n",
      "epoch: 8 [827695/888800 93.12%] train loss: 2.6383049771538936e-05 \n",
      "epoch: 8 [828806/888800 93.25%] train loss: 2.538548687880393e-05 \n",
      "epoch: 8 [829917/888800 93.38%] train loss: 2.2822128812549636e-05 \n",
      "epoch: 8 [831028/888800 93.50%] train loss: 2.2400541638489813e-05 \n",
      "epoch: 8 [832139/888800 93.62%] train loss: 2.183475407946389e-05 \n",
      "epoch: 8 [833250/888800 93.75%] train loss: 2.2829888621345162e-05 \n",
      "epoch: 8 [834361/888800 93.88%] train loss: 1.9465178411337547e-05 \n",
      "epoch: 8 [835472/888800 94.00%] train loss: 2.1065705368528143e-05 \n",
      "epoch: 8 [836583/888800 94.12%] train loss: 2.1796004148200154e-05 \n",
      "epoch: 8 [837694/888800 94.25%] train loss: 2.341603430977557e-05 \n",
      "epoch: 8 [838805/888800 94.38%] train loss: 2.0624545868486166e-05 \n",
      "epoch: 8 [839916/888800 94.50%] train loss: 2.4300412405864336e-05 \n",
      "epoch: 8 [841027/888800 94.62%] train loss: 2.5177681891364045e-05 \n",
      "epoch: 8 [842138/888800 94.75%] train loss: 2.245350697194226e-05 \n",
      "epoch: 8 [843249/888800 94.88%] train loss: 2.4156979634426534e-05 \n",
      "epoch: 8 [844360/888800 95.00%] train loss: 1.997394792851992e-05 \n",
      "epoch: 8 [845471/888800 95.12%] train loss: 2.2476102458313107e-05 \n",
      "epoch: 8 [846582/888800 95.25%] train loss: 2.440864045638591e-05 \n",
      "epoch: 8 [847693/888800 95.38%] train loss: 2.16866064874921e-05 \n",
      "epoch: 8 [848804/888800 95.50%] train loss: 2.39383771258872e-05 \n",
      "epoch: 8 [849915/888800 95.62%] train loss: 2.5691671908134595e-05 \n",
      "epoch: 8 [851026/888800 95.75%] train loss: 1.932413761096541e-05 \n",
      "epoch: 8 [852137/888800 95.88%] train loss: 2.3671480448683724e-05 \n",
      "epoch: 8 [853248/888800 96.00%] train loss: 2.270113691338338e-05 \n",
      "epoch: 8 [854359/888800 96.12%] train loss: 2.216949906141963e-05 \n",
      "epoch: 8 [855470/888800 96.25%] train loss: 2.5238316084141843e-05 \n",
      "epoch: 8 [856581/888800 96.38%] train loss: 2.5071771233342588e-05 \n",
      "epoch: 8 [857692/888800 96.50%] train loss: 2.3916947611724027e-05 \n",
      "epoch: 8 [858803/888800 96.62%] train loss: 2.037927697529085e-05 \n",
      "epoch: 8 [859914/888800 96.75%] train loss: 1.98564121092204e-05 \n",
      "epoch: 8 [861025/888800 96.88%] train loss: 2.1531190213863738e-05 \n",
      "epoch: 8 [862136/888800 97.00%] train loss: 2.3761658667353913e-05 \n",
      "epoch: 8 [863247/888800 97.12%] train loss: 2.063775718852412e-05 \n",
      "epoch: 8 [864358/888800 97.25%] train loss: 2.4323091565747745e-05 \n",
      "epoch: 8 [865469/888800 97.38%] train loss: 2.4728862626943737e-05 \n",
      "epoch: 8 [866580/888800 97.50%] train loss: 2.367673187109176e-05 \n",
      "epoch: 8 [867691/888800 97.62%] train loss: 2.327298716409132e-05 \n",
      "epoch: 8 [868802/888800 97.75%] train loss: 2.586753726063762e-05 \n",
      "epoch: 8 [869913/888800 97.88%] train loss: 2.4495380785083398e-05 \n",
      "epoch: 8 [871024/888800 98.00%] train loss: 2.0968644093954936e-05 \n",
      "epoch: 8 [872135/888800 98.12%] train loss: 2.3365801098407246e-05 \n",
      "epoch: 8 [873246/888800 98.25%] train loss: 2.4240529455710202e-05 \n",
      "epoch: 8 [874357/888800 98.38%] train loss: 2.1888048649998382e-05 \n",
      "epoch: 8 [875468/888800 98.50%] train loss: 1.9403283658903092e-05 \n",
      "epoch: 8 [876579/888800 98.62%] train loss: 2.4697887056390755e-05 \n",
      "epoch: 8 [877690/888800 98.75%] train loss: 2.2020813048584387e-05 \n",
      "epoch: 8 [878801/888800 98.88%] train loss: 2.414631308056414e-05 \n",
      "epoch: 8 [879912/888800 99.00%] train loss: 2.3509264792664908e-05 \n",
      "epoch: 8 [881023/888800 99.12%] train loss: 2.1634767108480446e-05 \n",
      "epoch: 8 [882134/888800 99.25%] train loss: 2.233875056845136e-05 \n",
      "epoch: 8 [883245/888800 99.38%] train loss: 2.296105958521366e-05 \n",
      "epoch: 8 [884356/888800 99.50%] train loss: 2.3812572180759162e-05 \n",
      "epoch: 8 [885467/888800 99.62%] train loss: 2.3639508071937598e-05 \n",
      "epoch: 8 [886578/888800 99.75%] train loss: 1.7899768863571808e-05 \n",
      "epoch: 8 [887689/888800 99.88%] train loss: 2.0488470909185708e-05 \n",
      "epoch: 9 [0/888800 0.00%] train loss: 2.249686986033339e-05 \n",
      "epoch: 9 [1111/888800 0.12%] train loss: 2.224220588686876e-05 \n",
      "epoch: 9 [2222/888800 0.25%] train loss: 2.337055411771871e-05 \n",
      "epoch: 9 [3333/888800 0.38%] train loss: 2.3257902284967713e-05 \n",
      "epoch: 9 [4444/888800 0.50%] train loss: 2.5313080186606385e-05 \n",
      "epoch: 9 [5555/888800 0.62%] train loss: 2.3115044314181432e-05 \n",
      "epoch: 9 [6666/888800 0.75%] train loss: 2.470667277520988e-05 \n",
      "epoch: 9 [7777/888800 0.88%] train loss: 1.875536509032827e-05 \n",
      "epoch: 9 [8888/888800 1.00%] train loss: 2.2632670152233914e-05 \n",
      "epoch: 9 [9999/888800 1.12%] train loss: 2.2381240341928788e-05 \n",
      "epoch: 9 [11110/888800 1.25%] train loss: 1.9964525563409552e-05 \n",
      "epoch: 9 [12221/888800 1.38%] train loss: 2.2067228201194666e-05 \n",
      "epoch: 9 [13332/888800 1.50%] train loss: 2.6398789486847818e-05 \n",
      "epoch: 9 [14443/888800 1.62%] train loss: 2.7961383239016868e-05 \n",
      "epoch: 9 [15554/888800 1.75%] train loss: 2.1799201931571588e-05 \n",
      "epoch: 9 [16665/888800 1.88%] train loss: 2.526657590351533e-05 \n",
      "epoch: 9 [17776/888800 2.00%] train loss: 2.5335424652439542e-05 \n",
      "epoch: 9 [18887/888800 2.12%] train loss: 2.1431324057630263e-05 \n",
      "epoch: 9 [19998/888800 2.25%] train loss: 2.1239651687210426e-05 \n",
      "epoch: 9 [21109/888800 2.38%] train loss: 2.294093428645283e-05 \n",
      "epoch: 9 [22220/888800 2.50%] train loss: 2.4677450710441917e-05 \n",
      "epoch: 9 [23331/888800 2.62%] train loss: 2.2742087821825407e-05 \n",
      "epoch: 9 [24442/888800 2.75%] train loss: 2.3863371097831987e-05 \n",
      "epoch: 9 [25553/888800 2.88%] train loss: 2.4443625079584308e-05 \n",
      "epoch: 9 [26664/888800 3.00%] train loss: 2.2739253836334683e-05 \n",
      "epoch: 9 [27775/888800 3.12%] train loss: 2.5621149688959122e-05 \n",
      "epoch: 9 [28886/888800 3.25%] train loss: 2.4247476176242344e-05 \n",
      "epoch: 9 [29997/888800 3.38%] train loss: 2.5383247702848166e-05 \n",
      "epoch: 9 [31108/888800 3.50%] train loss: 2.5510213163215667e-05 \n",
      "epoch: 9 [32219/888800 3.62%] train loss: 2.3219552531372756e-05 \n",
      "epoch: 9 [33330/888800 3.75%] train loss: 2.3598036932526156e-05 \n",
      "epoch: 9 [34441/888800 3.88%] train loss: 2.4905495592975058e-05 \n",
      "epoch: 9 [35552/888800 4.00%] train loss: 2.873634730349295e-05 \n",
      "epoch: 9 [36663/888800 4.12%] train loss: 1.9569626601878554e-05 \n",
      "epoch: 9 [37774/888800 4.25%] train loss: 2.108476110151969e-05 \n",
      "epoch: 9 [38885/888800 4.38%] train loss: 2.0056870198459364e-05 \n",
      "epoch: 9 [39996/888800 4.50%] train loss: 2.2235679352888837e-05 \n",
      "epoch: 9 [41107/888800 4.62%] train loss: 2.3364336811937392e-05 \n",
      "epoch: 9 [42218/888800 4.75%] train loss: 2.2885522412252612e-05 \n",
      "epoch: 9 [43329/888800 4.88%] train loss: 2.3561075067846105e-05 \n",
      "epoch: 9 [44440/888800 5.00%] train loss: 2.2850397726870142e-05 \n",
      "epoch: 9 [45551/888800 5.12%] train loss: 2.0264804334146902e-05 \n",
      "epoch: 9 [46662/888800 5.25%] train loss: 2.0940486137988046e-05 \n",
      "epoch: 9 [47773/888800 5.38%] train loss: 2.0563324142131023e-05 \n",
      "epoch: 9 [48884/888800 5.50%] train loss: 2.13333096326096e-05 \n",
      "epoch: 9 [49995/888800 5.62%] train loss: 2.060007318505086e-05 \n",
      "epoch: 9 [51106/888800 5.75%] train loss: 2.3665581466048025e-05 \n",
      "epoch: 9 [52217/888800 5.88%] train loss: 2.3717353542451747e-05 \n",
      "epoch: 9 [53328/888800 6.00%] train loss: 2.0949930330971256e-05 \n",
      "epoch: 9 [54439/888800 6.12%] train loss: 2.1240181013126858e-05 \n",
      "epoch: 9 [55550/888800 6.25%] train loss: 2.5056744561879896e-05 \n",
      "epoch: 9 [56661/888800 6.38%] train loss: 2.4479399144183844e-05 \n",
      "epoch: 9 [57772/888800 6.50%] train loss: 2.1345374989323318e-05 \n",
      "epoch: 9 [58883/888800 6.62%] train loss: 2.0289351596147753e-05 \n",
      "epoch: 9 [59994/888800 6.75%] train loss: 2.649795715115033e-05 \n",
      "epoch: 9 [61105/888800 6.88%] train loss: 2.2764434106647968e-05 \n",
      "epoch: 9 [62216/888800 7.00%] train loss: 2.0387806216604076e-05 \n",
      "epoch: 9 [63327/888800 7.12%] train loss: 2.2544820240000263e-05 \n",
      "epoch: 9 [64438/888800 7.25%] train loss: 1.9172479369444773e-05 \n",
      "epoch: 9 [65549/888800 7.38%] train loss: 1.782985964382533e-05 \n",
      "epoch: 9 [66660/888800 7.50%] train loss: 2.0541019694064744e-05 \n",
      "epoch: 9 [67771/888800 7.62%] train loss: 2.078623219858855e-05 \n",
      "epoch: 9 [68882/888800 7.75%] train loss: 2.0849645807174966e-05 \n",
      "epoch: 9 [69993/888800 7.88%] train loss: 2.008727278735023e-05 \n",
      "epoch: 9 [71104/888800 8.00%] train loss: 2.2782172891311347e-05 \n",
      "epoch: 9 [72215/888800 8.12%] train loss: 2.3387252440443262e-05 \n",
      "epoch: 9 [73326/888800 8.25%] train loss: 2.3291380784939975e-05 \n",
      "epoch: 9 [74437/888800 8.38%] train loss: 2.078929901472293e-05 \n",
      "epoch: 9 [75548/888800 8.50%] train loss: 2.483766365912743e-05 \n",
      "epoch: 9 [76659/888800 8.62%] train loss: 2.0138881154707633e-05 \n",
      "epoch: 9 [77770/888800 8.75%] train loss: 2.1945146727375686e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [78881/888800 8.88%] train loss: 2.128583400917705e-05 \n",
      "epoch: 9 [79992/888800 9.00%] train loss: 2.2512282157549635e-05 \n",
      "epoch: 9 [81103/888800 9.12%] train loss: 2.2953914594836533e-05 \n",
      "epoch: 9 [82214/888800 9.25%] train loss: 2.341678919037804e-05 \n",
      "epoch: 9 [83325/888800 9.38%] train loss: 2.3235070329974405e-05 \n",
      "epoch: 9 [84436/888800 9.50%] train loss: 2.3343674911302514e-05 \n",
      "epoch: 9 [85547/888800 9.62%] train loss: 2.4127186406985857e-05 \n",
      "epoch: 9 [86658/888800 9.75%] train loss: 2.246414078399539e-05 \n",
      "epoch: 9 [87769/888800 9.88%] train loss: 2.358044366701506e-05 \n",
      "epoch: 9 [88880/888800 10.00%] train loss: 2.6722798793343827e-05 \n",
      "epoch: 9 [89991/888800 10.12%] train loss: 2.4926943297032267e-05 \n",
      "epoch: 9 [91102/888800 10.25%] train loss: 2.3473226974601857e-05 \n",
      "epoch: 9 [92213/888800 10.38%] train loss: 2.1492825908353552e-05 \n",
      "epoch: 9 [93324/888800 10.50%] train loss: 2.652670991665218e-05 \n",
      "epoch: 9 [94435/888800 10.62%] train loss: 1.9482578863971867e-05 \n",
      "epoch: 9 [95546/888800 10.75%] train loss: 2.4366594516322948e-05 \n",
      "epoch: 9 [96657/888800 10.88%] train loss: 2.0921183022437617e-05 \n",
      "epoch: 9 [97768/888800 11.00%] train loss: 2.525998752389569e-05 \n",
      "epoch: 9 [98879/888800 11.12%] train loss: 2.0487028450588696e-05 \n",
      "epoch: 9 [99990/888800 11.25%] train loss: 2.5143259335891344e-05 \n",
      "epoch: 9 [101101/888800 11.38%] train loss: 2.1962558093946427e-05 \n",
      "epoch: 9 [102212/888800 11.50%] train loss: 2.0237239368725568e-05 \n",
      "epoch: 9 [103323/888800 11.62%] train loss: 2.085508094751276e-05 \n",
      "epoch: 9 [104434/888800 11.75%] train loss: 2.2492244170280173e-05 \n",
      "epoch: 9 [105545/888800 11.88%] train loss: 1.9441367840045132e-05 \n",
      "epoch: 9 [106656/888800 12.00%] train loss: 2.1050240320619196e-05 \n",
      "epoch: 9 [107767/888800 12.12%] train loss: 2.0803419829462655e-05 \n",
      "epoch: 9 [108878/888800 12.25%] train loss: 2.263005262648221e-05 \n",
      "epoch: 9 [109989/888800 12.38%] train loss: 2.186710298701655e-05 \n",
      "epoch: 9 [111100/888800 12.50%] train loss: 2.1123822079971433e-05 \n",
      "epoch: 9 [112211/888800 12.62%] train loss: 2.088794826704543e-05 \n",
      "epoch: 9 [113322/888800 12.75%] train loss: 2.1581996406894177e-05 \n",
      "epoch: 9 [114433/888800 12.88%] train loss: 2.2940424969419837e-05 \n",
      "epoch: 9 [115544/888800 13.00%] train loss: 2.518021392461378e-05 \n",
      "epoch: 9 [116655/888800 13.12%] train loss: 2.2939670088817365e-05 \n",
      "epoch: 9 [117766/888800 13.25%] train loss: 2.428876541671343e-05 \n",
      "epoch: 9 [118877/888800 13.38%] train loss: 2.5213821572833695e-05 \n",
      "epoch: 9 [119988/888800 13.50%] train loss: 2.1953344912617467e-05 \n",
      "epoch: 9 [121099/888800 13.62%] train loss: 1.8049935533781536e-05 \n",
      "epoch: 9 [122210/888800 13.75%] train loss: 1.903346856124699e-05 \n",
      "epoch: 9 [123321/888800 13.88%] train loss: 2.404109363851603e-05 \n",
      "epoch: 9 [124432/888800 14.00%] train loss: 2.5368821297888644e-05 \n",
      "epoch: 9 [125543/888800 14.12%] train loss: 2.2646399884251878e-05 \n",
      "epoch: 9 [126654/888800 14.25%] train loss: 2.1569227101281285e-05 \n",
      "epoch: 9 [127765/888800 14.38%] train loss: 2.3217320631374605e-05 \n",
      "epoch: 9 [128876/888800 14.50%] train loss: 2.212106301158201e-05 \n",
      "epoch: 9 [129987/888800 14.62%] train loss: 1.928541860252153e-05 \n",
      "epoch: 9 [131098/888800 14.75%] train loss: 1.8473987438483164e-05 \n",
      "epoch: 9 [132209/888800 14.88%] train loss: 2.3403157683787867e-05 \n",
      "epoch: 9 [133320/888800 15.00%] train loss: 2.2511057977681048e-05 \n",
      "epoch: 9 [134431/888800 15.12%] train loss: 2.060664519376587e-05 \n",
      "epoch: 9 [135542/888800 15.25%] train loss: 2.2832935428596102e-05 \n",
      "epoch: 9 [136653/888800 15.38%] train loss: 2.1374891730374657e-05 \n",
      "epoch: 9 [137764/888800 15.50%] train loss: 2.134999886038713e-05 \n",
      "epoch: 9 [138875/888800 15.62%] train loss: 2.206297722295858e-05 \n",
      "epoch: 9 [139986/888800 15.75%] train loss: 2.1865867893211544e-05 \n",
      "epoch: 9 [141097/888800 15.88%] train loss: 2.307966678927187e-05 \n",
      "epoch: 9 [142208/888800 16.00%] train loss: 2.3516833607573062e-05 \n",
      "epoch: 9 [143319/888800 16.12%] train loss: 2.6559313482721336e-05 \n",
      "epoch: 9 [144430/888800 16.25%] train loss: 2.0642080926336348e-05 \n",
      "epoch: 9 [145541/888800 16.38%] train loss: 2.490140286681708e-05 \n",
      "epoch: 9 [146652/888800 16.50%] train loss: 2.186459460062906e-05 \n",
      "epoch: 9 [147763/888800 16.62%] train loss: 2.1605899746646173e-05 \n",
      "epoch: 9 [148874/888800 16.75%] train loss: 2.1082183593534864e-05 \n",
      "epoch: 9 [149985/888800 16.88%] train loss: 2.042781670752447e-05 \n",
      "epoch: 9 [151096/888800 17.00%] train loss: 2.232891711173579e-05 \n",
      "epoch: 9 [152207/888800 17.12%] train loss: 2.374604628130328e-05 \n",
      "epoch: 9 [153318/888800 17.25%] train loss: 2.325560308236163e-05 \n",
      "epoch: 9 [154429/888800 17.38%] train loss: 2.3579841581522487e-05 \n",
      "epoch: 9 [155540/888800 17.50%] train loss: 1.7672506146482192e-05 \n",
      "epoch: 9 [156651/888800 17.62%] train loss: 2.0479574232012965e-05 \n",
      "epoch: 9 [157762/888800 17.75%] train loss: 2.319360828550998e-05 \n",
      "epoch: 9 [158873/888800 17.88%] train loss: 2.0795345335500315e-05 \n",
      "epoch: 9 [159984/888800 18.00%] train loss: 2.4217753889388405e-05 \n",
      "epoch: 9 [161095/888800 18.12%] train loss: 1.9023214917979203e-05 \n",
      "epoch: 9 [162206/888800 18.25%] train loss: 2.0188170310575515e-05 \n",
      "epoch: 9 [163317/888800 18.38%] train loss: 2.3315184080274776e-05 \n",
      "epoch: 9 [164428/888800 18.50%] train loss: 2.3620048523298465e-05 \n",
      "epoch: 9 [165539/888800 18.62%] train loss: 2.4699620553292334e-05 \n",
      "epoch: 9 [166650/888800 18.75%] train loss: 2.4609045794932172e-05 \n",
      "epoch: 9 [167761/888800 18.88%] train loss: 2.12511295103468e-05 \n",
      "epoch: 9 [168872/888800 19.00%] train loss: 2.5311413992312737e-05 \n",
      "epoch: 9 [169983/888800 19.12%] train loss: 2.2685566364089027e-05 \n",
      "epoch: 9 [171094/888800 19.25%] train loss: 2.5189632651745342e-05 \n",
      "epoch: 9 [172205/888800 19.38%] train loss: 2.0721634427900426e-05 \n",
      "epoch: 9 [173316/888800 19.50%] train loss: 2.342770130780991e-05 \n",
      "epoch: 9 [174427/888800 19.62%] train loss: 2.2109405108494684e-05 \n",
      "epoch: 9 [175538/888800 19.75%] train loss: 2.1102210666867904e-05 \n",
      "epoch: 9 [176649/888800 19.88%] train loss: 2.031297844951041e-05 \n",
      "epoch: 9 [177760/888800 20.00%] train loss: 2.0308871171437204e-05 \n",
      "epoch: 9 [178871/888800 20.12%] train loss: 2.08993715204997e-05 \n",
      "epoch: 9 [179982/888800 20.25%] train loss: 1.9835115381283686e-05 \n",
      "epoch: 9 [181093/888800 20.38%] train loss: 1.9916284145438112e-05 \n",
      "epoch: 9 [182204/888800 20.50%] train loss: 2.0290008251322433e-05 \n",
      "epoch: 9 [183315/888800 20.62%] train loss: 2.0496601791819558e-05 \n",
      "epoch: 9 [184426/888800 20.75%] train loss: 2.2025158614269458e-05 \n",
      "epoch: 9 [185537/888800 20.88%] train loss: 1.886899735836778e-05 \n",
      "epoch: 9 [186648/888800 21.00%] train loss: 2.3830709324101917e-05 \n",
      "epoch: 9 [187759/888800 21.12%] train loss: 2.0248773580533452e-05 \n",
      "epoch: 9 [188870/888800 21.25%] train loss: 2.2574928152607754e-05 \n",
      "epoch: 9 [189981/888800 21.38%] train loss: 2.2342903321259655e-05 \n",
      "epoch: 9 [191092/888800 21.50%] train loss: 2.309819137735758e-05 \n",
      "epoch: 9 [192203/888800 21.62%] train loss: 2.1136740542715415e-05 \n",
      "epoch: 9 [193314/888800 21.75%] train loss: 2.3239545043907128e-05 \n",
      "epoch: 9 [194425/888800 21.88%] train loss: 2.4716222469578497e-05 \n",
      "epoch: 9 [195536/888800 22.00%] train loss: 2.368269815633539e-05 \n",
      "epoch: 9 [196647/888800 22.12%] train loss: 2.3667305868002586e-05 \n",
      "epoch: 9 [197758/888800 22.25%] train loss: 2.0968234821339138e-05 \n",
      "epoch: 9 [198869/888800 22.38%] train loss: 2.2249338144320063e-05 \n",
      "epoch: 9 [199980/888800 22.50%] train loss: 1.9494240405038e-05 \n",
      "epoch: 9 [201091/888800 22.62%] train loss: 2.1659318008460104e-05 \n",
      "epoch: 9 [202202/888800 22.75%] train loss: 2.050722650892567e-05 \n",
      "epoch: 9 [203313/888800 22.88%] train loss: 2.021751060965471e-05 \n",
      "epoch: 9 [204424/888800 23.00%] train loss: 2.268721982545685e-05 \n",
      "epoch: 9 [205535/888800 23.12%] train loss: 2.1851403289474547e-05 \n",
      "epoch: 9 [206646/888800 23.25%] train loss: 1.825395338528324e-05 \n",
      "epoch: 9 [207757/888800 23.38%] train loss: 2.067308741970919e-05 \n",
      "epoch: 9 [208868/888800 23.50%] train loss: 2.3954800781211816e-05 \n",
      "epoch: 9 [209979/888800 23.62%] train loss: 2.4007766114664264e-05 \n",
      "epoch: 9 [211090/888800 23.75%] train loss: 2.0120780391152948e-05 \n",
      "epoch: 9 [212201/888800 23.88%] train loss: 2.13623970921617e-05 \n",
      "epoch: 9 [213312/888800 24.00%] train loss: 2.2098985937191173e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [214423/888800 24.12%] train loss: 2.317242069693748e-05 \n",
      "epoch: 9 [215534/888800 24.25%] train loss: 1.983327092602849e-05 \n",
      "epoch: 9 [216645/888800 24.38%] train loss: 2.255760227853898e-05 \n",
      "epoch: 9 [217756/888800 24.50%] train loss: 2.1996525902068242e-05 \n",
      "epoch: 9 [218867/888800 24.62%] train loss: 2.2194592020241544e-05 \n",
      "epoch: 9 [219978/888800 24.75%] train loss: 2.0672609025496058e-05 \n",
      "epoch: 9 [221089/888800 24.88%] train loss: 2.035524812527001e-05 \n",
      "epoch: 9 [222200/888800 25.00%] train loss: 1.9139173673465848e-05 \n",
      "epoch: 9 [223311/888800 25.12%] train loss: 2.361435144848656e-05 \n",
      "epoch: 9 [224422/888800 25.25%] train loss: 1.760824852681253e-05 \n",
      "epoch: 9 [225533/888800 25.38%] train loss: 2.0502047846093774e-05 \n",
      "epoch: 9 [226644/888800 25.50%] train loss: 1.6739875718485564e-05 \n",
      "epoch: 9 [227755/888800 25.62%] train loss: 2.4754157493589446e-05 \n",
      "epoch: 9 [228866/888800 25.75%] train loss: 2.019689964072313e-05 \n",
      "epoch: 9 [229977/888800 25.88%] train loss: 1.9667486412799917e-05 \n",
      "epoch: 9 [231088/888800 26.00%] train loss: 2.1832580387126654e-05 \n",
      "epoch: 9 [232199/888800 26.12%] train loss: 1.7967950043384917e-05 \n",
      "epoch: 9 [233310/888800 26.25%] train loss: 2.0964633222320117e-05 \n",
      "epoch: 9 [234421/888800 26.38%] train loss: 2.1634508811985143e-05 \n",
      "epoch: 9 [235532/888800 26.50%] train loss: 2.5559511414030567e-05 \n",
      "epoch: 9 [236643/888800 26.62%] train loss: 2.3044596673571505e-05 \n",
      "epoch: 9 [237754/888800 26.75%] train loss: 2.348114321648609e-05 \n",
      "epoch: 9 [238865/888800 26.88%] train loss: 2.139886601071339e-05 \n",
      "epoch: 9 [239976/888800 27.00%] train loss: 2.1947516870568506e-05 \n",
      "epoch: 9 [241087/888800 27.12%] train loss: 2.2445568902185187e-05 \n",
      "epoch: 9 [242198/888800 27.25%] train loss: 2.203093026764691e-05 \n",
      "epoch: 9 [243309/888800 27.38%] train loss: 2.0628654965548776e-05 \n",
      "epoch: 9 [244420/888800 27.50%] train loss: 2.0243394828867167e-05 \n",
      "epoch: 9 [245531/888800 27.62%] train loss: 1.864578007371165e-05 \n",
      "epoch: 9 [246642/888800 27.75%] train loss: 2.1297402781783603e-05 \n",
      "epoch: 9 [247753/888800 27.88%] train loss: 1.788018380466383e-05 \n",
      "epoch: 9 [248864/888800 28.00%] train loss: 2.4789322196738794e-05 \n",
      "epoch: 9 [249975/888800 28.12%] train loss: 1.7643555111135356e-05 \n",
      "epoch: 9 [251086/888800 28.25%] train loss: 1.9216780856368132e-05 \n",
      "epoch: 9 [252197/888800 28.38%] train loss: 2.283542744407896e-05 \n",
      "epoch: 9 [253308/888800 28.50%] train loss: 2.1916290279477835e-05 \n",
      "epoch: 9 [254419/888800 28.62%] train loss: 2.3353346477961168e-05 \n",
      "epoch: 9 [255530/888800 28.75%] train loss: 2.1143248886801302e-05 \n",
      "epoch: 9 [256641/888800 28.88%] train loss: 2.030113864748273e-05 \n",
      "epoch: 9 [257752/888800 29.00%] train loss: 2.2223211999516934e-05 \n",
      "epoch: 9 [258863/888800 29.12%] train loss: 2.0374298401293345e-05 \n",
      "epoch: 9 [259974/888800 29.25%] train loss: 2.1576774088316597e-05 \n",
      "epoch: 9 [261085/888800 29.38%] train loss: 2.0668760043918155e-05 \n",
      "epoch: 9 [262196/888800 29.50%] train loss: 2.3179740310297348e-05 \n",
      "epoch: 9 [263307/888800 29.62%] train loss: 1.98980669665616e-05 \n",
      "epoch: 9 [264418/888800 29.75%] train loss: 2.3829501515137963e-05 \n",
      "epoch: 9 [265529/888800 29.88%] train loss: 2.249952194688376e-05 \n",
      "epoch: 9 [266640/888800 30.00%] train loss: 2.169685649278108e-05 \n",
      "epoch: 9 [267751/888800 30.12%] train loss: 2.155589208996389e-05 \n",
      "epoch: 9 [268862/888800 30.25%] train loss: 2.4122869945131242e-05 \n",
      "epoch: 9 [269973/888800 30.38%] train loss: 2.4185235815821216e-05 \n",
      "epoch: 9 [271084/888800 30.50%] train loss: 1.8566448488854803e-05 \n",
      "epoch: 9 [272195/888800 30.62%] train loss: 2.0012112145195715e-05 \n",
      "epoch: 9 [273306/888800 30.75%] train loss: 2.308069815626368e-05 \n",
      "epoch: 9 [274417/888800 30.88%] train loss: 2.6315623472328298e-05 \n",
      "epoch: 9 [275528/888800 31.00%] train loss: 2.1433539586723782e-05 \n",
      "epoch: 9 [276639/888800 31.12%] train loss: 2.297673017892521e-05 \n",
      "epoch: 9 [277750/888800 31.25%] train loss: 1.9499277186696418e-05 \n",
      "epoch: 9 [278861/888800 31.38%] train loss: 1.8848208128474653e-05 \n",
      "epoch: 9 [279972/888800 31.50%] train loss: 2.1384477804531343e-05 \n",
      "epoch: 9 [281083/888800 31.62%] train loss: 2.453551314829383e-05 \n",
      "epoch: 9 [282194/888800 31.75%] train loss: 2.053026037174277e-05 \n",
      "epoch: 9 [283305/888800 31.88%] train loss: 2.2586043996852823e-05 \n",
      "epoch: 9 [284416/888800 32.00%] train loss: 1.959949076990597e-05 \n",
      "epoch: 9 [285527/888800 32.12%] train loss: 2.4644496079417877e-05 \n",
      "epoch: 9 [286638/888800 32.25%] train loss: 2.4667009711265564e-05 \n",
      "epoch: 9 [287749/888800 32.38%] train loss: 1.890596468001604e-05 \n",
      "epoch: 9 [288860/888800 32.50%] train loss: 1.993037403735798e-05 \n",
      "epoch: 9 [289971/888800 32.62%] train loss: 2.1131791072548367e-05 \n",
      "epoch: 9 [291082/888800 32.75%] train loss: 1.798889752535615e-05 \n",
      "epoch: 9 [292193/888800 32.88%] train loss: 1.9006076399818994e-05 \n",
      "epoch: 9 [293304/888800 33.00%] train loss: 2.356016011617612e-05 \n",
      "epoch: 9 [294415/888800 33.12%] train loss: 2.0514544303296134e-05 \n",
      "epoch: 9 [295526/888800 33.25%] train loss: 1.9834336853818968e-05 \n",
      "epoch: 9 [296637/888800 33.38%] train loss: 2.1391471818787977e-05 \n",
      "epoch: 9 [297748/888800 33.50%] train loss: 2.3259934096131474e-05 \n",
      "epoch: 9 [298859/888800 33.62%] train loss: 2.289086114615202e-05 \n",
      "epoch: 9 [299970/888800 33.75%] train loss: 2.4970935555757023e-05 \n",
      "epoch: 9 [301081/888800 33.88%] train loss: 2.3100777980289422e-05 \n",
      "epoch: 9 [302192/888800 34.00%] train loss: 1.994879676203709e-05 \n",
      "epoch: 9 [303303/888800 34.12%] train loss: 2.096603566315025e-05 \n",
      "epoch: 9 [304414/888800 34.25%] train loss: 2.1765796191175468e-05 \n",
      "epoch: 9 [305525/888800 34.38%] train loss: 2.2167410861584358e-05 \n",
      "epoch: 9 [306636/888800 34.50%] train loss: 1.9563116438803263e-05 \n",
      "epoch: 9 [307747/888800 34.62%] train loss: 1.926548793562688e-05 \n",
      "epoch: 9 [308858/888800 34.75%] train loss: 2.003143345064018e-05 \n",
      "epoch: 9 [309969/888800 34.88%] train loss: 1.84117798198713e-05 \n",
      "epoch: 9 [311080/888800 35.00%] train loss: 1.9418561350903474e-05 \n",
      "epoch: 9 [312191/888800 35.12%] train loss: 2.249617682537064e-05 \n",
      "epoch: 9 [313302/888800 35.25%] train loss: 2.101476457028184e-05 \n",
      "epoch: 9 [314413/888800 35.38%] train loss: 2.28926473937463e-05 \n",
      "epoch: 9 [315524/888800 35.50%] train loss: 2.1384490537457168e-05 \n",
      "epoch: 9 [316635/888800 35.62%] train loss: 2.1822157577844337e-05 \n",
      "epoch: 9 [317746/888800 35.75%] train loss: 1.9891740521416068e-05 \n",
      "epoch: 9 [318857/888800 35.88%] train loss: 2.4204160581575707e-05 \n",
      "epoch: 9 [319968/888800 36.00%] train loss: 1.8967206415254623e-05 \n",
      "epoch: 9 [321079/888800 36.12%] train loss: 2.047044654318597e-05 \n",
      "epoch: 9 [322190/888800 36.25%] train loss: 2.2247477318160236e-05 \n",
      "epoch: 9 [323301/888800 36.38%] train loss: 2.1356332581490278e-05 \n",
      "epoch: 9 [324412/888800 36.50%] train loss: 2.1556166757363826e-05 \n",
      "epoch: 9 [325523/888800 36.62%] train loss: 2.4609693355159834e-05 \n",
      "epoch: 9 [326634/888800 36.75%] train loss: 2.3563095965073444e-05 \n",
      "epoch: 9 [327745/888800 36.88%] train loss: 1.9616811187006533e-05 \n",
      "epoch: 9 [328856/888800 37.00%] train loss: 1.9906081433873624e-05 \n",
      "epoch: 9 [329967/888800 37.12%] train loss: 2.0263842088752426e-05 \n",
      "epoch: 9 [331078/888800 37.25%] train loss: 1.941650771186687e-05 \n",
      "epoch: 9 [332189/888800 37.38%] train loss: 2.267269155709073e-05 \n",
      "epoch: 9 [333300/888800 37.50%] train loss: 2.3730306565994397e-05 \n",
      "epoch: 9 [334411/888800 37.62%] train loss: 2.3753646019031294e-05 \n",
      "epoch: 9 [335522/888800 37.75%] train loss: 2.5806129997363314e-05 \n",
      "epoch: 9 [336633/888800 37.88%] train loss: 1.99154565052595e-05 \n",
      "epoch: 9 [337744/888800 38.00%] train loss: 1.8230964997201227e-05 \n",
      "epoch: 9 [338855/888800 38.12%] train loss: 2.0575354938046075e-05 \n",
      "epoch: 9 [339966/888800 38.25%] train loss: 2.211993523815181e-05 \n",
      "epoch: 9 [341077/888800 38.38%] train loss: 2.3312622943194583e-05 \n",
      "epoch: 9 [342188/888800 38.50%] train loss: 1.808480556064751e-05 \n",
      "epoch: 9 [343299/888800 38.62%] train loss: 2.0873427274636924e-05 \n",
      "epoch: 9 [344410/888800 38.75%] train loss: 1.890468229248654e-05 \n",
      "epoch: 9 [345521/888800 38.88%] train loss: 2.3265683921636082e-05 \n",
      "epoch: 9 [346632/888800 39.00%] train loss: 1.7780164853320457e-05 \n",
      "epoch: 9 [347743/888800 39.12%] train loss: 2.2066560632083565e-05 \n",
      "epoch: 9 [348854/888800 39.25%] train loss: 2.0980416593374684e-05 \n",
      "epoch: 9 [349965/888800 39.38%] train loss: 1.960669396794401e-05 \n",
      "epoch: 9 [351076/888800 39.50%] train loss: 2.2891996195539832e-05 \n",
      "epoch: 9 [352187/888800 39.62%] train loss: 1.9573664758354425e-05 \n",
      "epoch: 9 [353298/888800 39.75%] train loss: 2.2145470211398788e-05 \n",
      "epoch: 9 [354409/888800 39.88%] train loss: 2.0763216525665484e-05 \n",
      "epoch: 9 [355520/888800 40.00%] train loss: 2.2362877643899992e-05 \n",
      "epoch: 9 [356631/888800 40.12%] train loss: 2.241352376586292e-05 \n",
      "epoch: 9 [357742/888800 40.25%] train loss: 1.8258337149745785e-05 \n",
      "epoch: 9 [358853/888800 40.38%] train loss: 2.1700456272810698e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [359964/888800 40.50%] train loss: 1.946362499438692e-05 \n",
      "epoch: 9 [361075/888800 40.62%] train loss: 1.8107586583937518e-05 \n",
      "epoch: 9 [362186/888800 40.75%] train loss: 2.218518784502521e-05 \n",
      "epoch: 9 [363297/888800 40.88%] train loss: 1.939134017447941e-05 \n",
      "epoch: 9 [364408/888800 41.00%] train loss: 1.8345752323511988e-05 \n",
      "epoch: 9 [365519/888800 41.12%] train loss: 1.953236096596811e-05 \n",
      "epoch: 9 [366630/888800 41.25%] train loss: 1.937767956405878e-05 \n",
      "epoch: 9 [367741/888800 41.38%] train loss: 2.1262347217998467e-05 \n",
      "epoch: 9 [368852/888800 41.50%] train loss: 2.2315905880532227e-05 \n",
      "epoch: 9 [369963/888800 41.62%] train loss: 1.9943716324632987e-05 \n",
      "epoch: 9 [371074/888800 41.75%] train loss: 2.3024429538054392e-05 \n",
      "epoch: 9 [372185/888800 41.88%] train loss: 2.1871070202905685e-05 \n",
      "epoch: 9 [373296/888800 42.00%] train loss: 2.1994041162543e-05 \n",
      "epoch: 9 [374407/888800 42.12%] train loss: 2.3593916921527125e-05 \n",
      "epoch: 9 [375518/888800 42.25%] train loss: 2.621552994241938e-05 \n",
      "epoch: 9 [376629/888800 42.38%] train loss: 1.7717919035931118e-05 \n",
      "epoch: 9 [377740/888800 42.50%] train loss: 2.0186513211228885e-05 \n",
      "epoch: 9 [378851/888800 42.62%] train loss: 2.3027550923870876e-05 \n",
      "epoch: 9 [379962/888800 42.75%] train loss: 1.8286633348907344e-05 \n",
      "epoch: 9 [381073/888800 42.88%] train loss: 2.0340306946309283e-05 \n",
      "epoch: 9 [382184/888800 43.00%] train loss: 2.3289299861062318e-05 \n",
      "epoch: 9 [383295/888800 43.12%] train loss: 2.2693177015753463e-05 \n",
      "epoch: 9 [384406/888800 43.25%] train loss: 1.8588378225103952e-05 \n",
      "epoch: 9 [385517/888800 43.38%] train loss: 2.057053461612668e-05 \n",
      "epoch: 9 [386628/888800 43.50%] train loss: 2.073128052870743e-05 \n",
      "epoch: 9 [387739/888800 43.62%] train loss: 2.161537304345984e-05 \n",
      "epoch: 9 [388850/888800 43.75%] train loss: 1.9277485989732668e-05 \n",
      "epoch: 9 [389961/888800 43.88%] train loss: 2.4012444555410184e-05 \n",
      "epoch: 9 [391072/888800 44.00%] train loss: 2.1580621250905097e-05 \n",
      "epoch: 9 [392183/888800 44.12%] train loss: 2.036311707342975e-05 \n",
      "epoch: 9 [393294/888800 44.25%] train loss: 1.930495818669442e-05 \n",
      "epoch: 9 [394405/888800 44.38%] train loss: 1.8758522855932824e-05 \n",
      "epoch: 9 [395516/888800 44.50%] train loss: 2.0175444660708308e-05 \n",
      "epoch: 9 [396627/888800 44.62%] train loss: 2.4109831429086626e-05 \n",
      "epoch: 9 [397738/888800 44.75%] train loss: 2.2050087864045054e-05 \n",
      "epoch: 9 [398849/888800 44.88%] train loss: 2.324050001334399e-05 \n",
      "epoch: 9 [399960/888800 45.00%] train loss: 2.2517915567732416e-05 \n",
      "epoch: 9 [401071/888800 45.12%] train loss: 2.001896791625768e-05 \n",
      "epoch: 9 [402182/888800 45.25%] train loss: 2.1778096197522245e-05 \n",
      "epoch: 9 [403293/888800 45.38%] train loss: 2.061867417069152e-05 \n",
      "epoch: 9 [404404/888800 45.50%] train loss: 1.984808113775216e-05 \n",
      "epoch: 9 [405515/888800 45.62%] train loss: 2.301317363162525e-05 \n",
      "epoch: 9 [406626/888800 45.75%] train loss: 2.1911755538894795e-05 \n",
      "epoch: 9 [407737/888800 45.88%] train loss: 1.4935300896468107e-05 \n",
      "epoch: 9 [408848/888800 46.00%] train loss: 1.9897741367458366e-05 \n",
      "epoch: 9 [409959/888800 46.12%] train loss: 1.9709586922544986e-05 \n",
      "epoch: 9 [411070/888800 46.25%] train loss: 2.1703075617551804e-05 \n",
      "epoch: 9 [412181/888800 46.38%] train loss: 2.2576903575100005e-05 \n",
      "epoch: 9 [413292/888800 46.50%] train loss: 2.2312766304821707e-05 \n",
      "epoch: 9 [414403/888800 46.62%] train loss: 2.0227336790412664e-05 \n",
      "epoch: 9 [415514/888800 46.75%] train loss: 2.1735009795520455e-05 \n",
      "epoch: 9 [416625/888800 46.88%] train loss: 2.161562406399753e-05 \n",
      "epoch: 9 [417736/888800 47.00%] train loss: 1.9218005036236718e-05 \n",
      "epoch: 9 [418847/888800 47.12%] train loss: 2.1300931621226482e-05 \n",
      "epoch: 9 [419958/888800 47.25%] train loss: 1.9913612050004303e-05 \n",
      "epoch: 9 [421069/888800 47.38%] train loss: 2.0141482309554704e-05 \n",
      "epoch: 9 [422180/888800 47.50%] train loss: 2.0732441043946892e-05 \n",
      "epoch: 9 [423291/888800 47.62%] train loss: 2.2229949536267668e-05 \n",
      "epoch: 9 [424402/888800 47.75%] train loss: 1.931703809532337e-05 \n",
      "epoch: 9 [425513/888800 47.88%] train loss: 1.975257328012958e-05 \n",
      "epoch: 9 [426624/888800 48.00%] train loss: 1.7415470210835338e-05 \n",
      "epoch: 9 [427735/888800 48.12%] train loss: 2.294688420079183e-05 \n",
      "epoch: 9 [428846/888800 48.25%] train loss: 2.2134943719720468e-05 \n",
      "epoch: 9 [429957/888800 48.38%] train loss: 1.9905495719285682e-05 \n",
      "epoch: 9 [431068/888800 48.50%] train loss: 2.1882180590182543e-05 \n",
      "epoch: 9 [432179/888800 48.62%] train loss: 2.434484486002475e-05 \n",
      "epoch: 9 [433290/888800 48.75%] train loss: 1.828160930017475e-05 \n",
      "epoch: 9 [434401/888800 48.88%] train loss: 2.3818662157282233e-05 \n",
      "epoch: 9 [435512/888800 49.00%] train loss: 2.0345160010037944e-05 \n",
      "epoch: 9 [436623/888800 49.12%] train loss: 2.2040745534468442e-05 \n",
      "epoch: 9 [437734/888800 49.25%] train loss: 1.9378476281417534e-05 \n",
      "epoch: 9 [438845/888800 49.38%] train loss: 2.14680731005501e-05 \n",
      "epoch: 9 [439956/888800 49.50%] train loss: 2.011495416809339e-05 \n",
      "epoch: 9 [441067/888800 49.62%] train loss: 2.0075693100807257e-05 \n",
      "epoch: 9 [442178/888800 49.75%] train loss: 1.8680613720789552e-05 \n",
      "epoch: 9 [443289/888800 49.88%] train loss: 1.9317016267450526e-05 \n",
      "epoch: 9 [444400/888800 50.00%] train loss: 1.924255775520578e-05 \n",
      "epoch: 9 [445511/888800 50.12%] train loss: 1.726357550069224e-05 \n",
      "epoch: 9 [446622/888800 50.25%] train loss: 1.9890760086127557e-05 \n",
      "epoch: 9 [447733/888800 50.38%] train loss: 2.1693707822123542e-05 \n",
      "epoch: 9 [448844/888800 50.50%] train loss: 2.0961155314580537e-05 \n",
      "epoch: 9 [449955/888800 50.62%] train loss: 2.031096300925128e-05 \n",
      "epoch: 9 [451066/888800 50.75%] train loss: 1.9099965356872417e-05 \n",
      "epoch: 9 [452177/888800 50.88%] train loss: 2.2022180928615853e-05 \n",
      "epoch: 9 [453288/888800 51.00%] train loss: 2.2893984350957908e-05 \n",
      "epoch: 9 [454399/888800 51.12%] train loss: 2.1473897504620254e-05 \n",
      "epoch: 9 [455510/888800 51.25%] train loss: 2.0296951333875768e-05 \n",
      "epoch: 9 [456621/888800 51.38%] train loss: 2.3153535948949866e-05 \n",
      "epoch: 9 [457732/888800 51.50%] train loss: 1.9934646843466908e-05 \n",
      "epoch: 9 [458843/888800 51.62%] train loss: 1.938817513291724e-05 \n",
      "epoch: 9 [459954/888800 51.75%] train loss: 2.0423336536623538e-05 \n",
      "epoch: 9 [461065/888800 51.88%] train loss: 1.9795275875367224e-05 \n",
      "epoch: 9 [462176/888800 52.00%] train loss: 1.68728620337788e-05 \n",
      "epoch: 9 [463287/888800 52.12%] train loss: 2.005303031182848e-05 \n",
      "epoch: 9 [464398/888800 52.25%] train loss: 1.972750214918051e-05 \n",
      "epoch: 9 [465509/888800 52.38%] train loss: 2.3853586753830314e-05 \n",
      "epoch: 9 [466620/888800 52.50%] train loss: 2.131237488356419e-05 \n",
      "epoch: 9 [467731/888800 52.62%] train loss: 1.8425096641294658e-05 \n",
      "epoch: 9 [468842/888800 52.75%] train loss: 2.2764479581383057e-05 \n",
      "epoch: 9 [469953/888800 52.88%] train loss: 2.0551935449475423e-05 \n",
      "epoch: 9 [471064/888800 53.00%] train loss: 2.0136860257480294e-05 \n",
      "epoch: 9 [472175/888800 53.12%] train loss: 2.1502846720977686e-05 \n",
      "epoch: 9 [473286/888800 53.25%] train loss: 2.122541809512768e-05 \n",
      "epoch: 9 [474397/888800 53.38%] train loss: 1.8785553038469516e-05 \n",
      "epoch: 9 [475508/888800 53.50%] train loss: 2.1250491045066155e-05 \n",
      "epoch: 9 [476619/888800 53.62%] train loss: 2.166285594285e-05 \n",
      "epoch: 9 [477730/888800 53.75%] train loss: 1.986738425330259e-05 \n",
      "epoch: 9 [478841/888800 53.88%] train loss: 1.9319610146339983e-05 \n",
      "epoch: 9 [479952/888800 54.00%] train loss: 1.961651287274435e-05 \n",
      "epoch: 9 [481063/888800 54.12%] train loss: 2.0613824744941667e-05 \n",
      "epoch: 9 [482174/888800 54.25%] train loss: 1.9521658032317646e-05 \n",
      "epoch: 9 [483285/888800 54.38%] train loss: 1.84800592251122e-05 \n",
      "epoch: 9 [484396/888800 54.50%] train loss: 2.0138768377364613e-05 \n",
      "epoch: 9 [485507/888800 54.62%] train loss: 1.9115024770144373e-05 \n",
      "epoch: 9 [486618/888800 54.75%] train loss: 2.1674819436157122e-05 \n",
      "epoch: 9 [487729/888800 54.88%] train loss: 2.0259680240997113e-05 \n",
      "epoch: 9 [488840/888800 55.00%] train loss: 2.379195939283818e-05 \n",
      "epoch: 9 [489951/888800 55.12%] train loss: 2.067679088213481e-05 \n",
      "epoch: 9 [491062/888800 55.25%] train loss: 1.854518268373795e-05 \n",
      "epoch: 9 [492173/888800 55.38%] train loss: 2.1183688659220934e-05 \n",
      "epoch: 9 [493284/888800 55.50%] train loss: 1.9794295440078713e-05 \n",
      "epoch: 9 [494395/888800 55.62%] train loss: 2.124284401361365e-05 \n",
      "epoch: 9 [495506/888800 55.75%] train loss: 1.8901215298683383e-05 \n",
      "epoch: 9 [496617/888800 55.88%] train loss: 2.2476071535493247e-05 \n",
      "epoch: 9 [497728/888800 56.00%] train loss: 2.1309637304511853e-05 \n",
      "epoch: 9 [498839/888800 56.12%] train loss: 2.0494637283263728e-05 \n",
      "epoch: 9 [499950/888800 56.25%] train loss: 2.0202884115860797e-05 \n",
      "epoch: 9 [501061/888800 56.38%] train loss: 1.9427650840952992e-05 \n",
      "epoch: 9 [502172/888800 56.50%] train loss: 1.9669500034069642e-05 \n",
      "epoch: 9 [503283/888800 56.62%] train loss: 1.9296485334052704e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [504394/888800 56.75%] train loss: 1.8115975763066672e-05 \n",
      "epoch: 9 [505505/888800 56.88%] train loss: 2.219784801127389e-05 \n",
      "epoch: 9 [506616/888800 57.00%] train loss: 2.3699714802205563e-05 \n",
      "epoch: 9 [507727/888800 57.12%] train loss: 2.2468231691163965e-05 \n",
      "epoch: 9 [508838/888800 57.25%] train loss: 1.732837154122535e-05 \n",
      "epoch: 9 [509949/888800 57.38%] train loss: 1.9692790374392644e-05 \n",
      "epoch: 9 [511060/888800 57.50%] train loss: 2.049352042376995e-05 \n",
      "epoch: 9 [512171/888800 57.62%] train loss: 2.436063005006872e-05 \n",
      "epoch: 9 [513282/888800 57.75%] train loss: 1.9962864826084115e-05 \n",
      "epoch: 9 [514393/888800 57.88%] train loss: 2.0241910533513874e-05 \n",
      "epoch: 9 [515504/888800 58.00%] train loss: 2.159843461413402e-05 \n",
      "epoch: 9 [516615/888800 58.12%] train loss: 1.7644390027271584e-05 \n",
      "epoch: 9 [517726/888800 58.25%] train loss: 1.8832244677469134e-05 \n",
      "epoch: 9 [518837/888800 58.38%] train loss: 2.0988436517654918e-05 \n",
      "epoch: 9 [519948/888800 58.50%] train loss: 1.918447196658235e-05 \n",
      "epoch: 9 [521059/888800 58.62%] train loss: 2.1434074369608425e-05 \n",
      "epoch: 9 [522170/888800 58.75%] train loss: 2.045627661573235e-05 \n",
      "epoch: 9 [523281/888800 58.88%] train loss: 1.625872937438544e-05 \n",
      "epoch: 9 [524392/888800 59.00%] train loss: 1.9832888938253745e-05 \n",
      "epoch: 9 [525503/888800 59.12%] train loss: 2.2827247448731214e-05 \n",
      "epoch: 9 [526614/888800 59.25%] train loss: 2.1752077373093925e-05 \n",
      "epoch: 9 [527725/888800 59.38%] train loss: 1.9899340259144083e-05 \n",
      "epoch: 9 [528836/888800 59.50%] train loss: 2.2686755983158946e-05 \n",
      "epoch: 9 [529947/888800 59.62%] train loss: 2.075585871352814e-05 \n",
      "epoch: 9 [531058/888800 59.75%] train loss: 1.898292248370126e-05 \n",
      "epoch: 9 [532169/888800 59.88%] train loss: 2.0114177459618077e-05 \n",
      "epoch: 9 [533280/888800 60.00%] train loss: 2.0161473003099672e-05 \n",
      "epoch: 9 [534391/888800 60.12%] train loss: 1.9942934159189463e-05 \n",
      "epoch: 9 [535502/888800 60.25%] train loss: 1.5150930266827345e-05 \n",
      "epoch: 9 [536613/888800 60.38%] train loss: 1.797227560018655e-05 \n",
      "epoch: 9 [537724/888800 60.50%] train loss: 2.0372232029330917e-05 \n",
      "epoch: 9 [538835/888800 60.62%] train loss: 1.9100954887107946e-05 \n",
      "epoch: 9 [539946/888800 60.75%] train loss: 2.1855756131117232e-05 \n",
      "epoch: 9 [541057/888800 60.88%] train loss: 1.9503580915625207e-05 \n",
      "epoch: 9 [542168/888800 61.00%] train loss: 2.0173534721834585e-05 \n",
      "epoch: 9 [543279/888800 61.12%] train loss: 2.264748400193639e-05 \n",
      "epoch: 9 [544390/888800 61.25%] train loss: 2.262987254653126e-05 \n",
      "epoch: 9 [545501/888800 61.38%] train loss: 2.1631627532769926e-05 \n",
      "epoch: 9 [546612/888800 61.50%] train loss: 2.132218833139632e-05 \n",
      "epoch: 9 [547723/888800 61.62%] train loss: 2.4051536456681788e-05 \n",
      "epoch: 9 [548834/888800 61.75%] train loss: 1.8734321201918647e-05 \n",
      "epoch: 9 [549945/888800 61.88%] train loss: 1.7794645827962086e-05 \n",
      "epoch: 9 [551056/888800 62.00%] train loss: 1.8427894246997312e-05 \n",
      "epoch: 9 [552167/888800 62.12%] train loss: 1.8886348698288202e-05 \n",
      "epoch: 9 [553278/888800 62.25%] train loss: 2.0098326785955578e-05 \n",
      "epoch: 9 [554389/888800 62.38%] train loss: 1.9567964045563713e-05 \n",
      "epoch: 9 [555500/888800 62.50%] train loss: 1.7151176507468335e-05 \n",
      "epoch: 9 [556611/888800 62.62%] train loss: 2.1772108084405772e-05 \n",
      "epoch: 9 [557722/888800 62.75%] train loss: 1.8983924746862613e-05 \n",
      "epoch: 9 [558833/888800 62.88%] train loss: 1.9791817976511084e-05 \n",
      "epoch: 9 [559944/888800 63.00%] train loss: 2.3877522835391574e-05 \n",
      "epoch: 9 [561055/888800 63.12%] train loss: 1.7796963220462203e-05 \n",
      "epoch: 9 [562166/888800 63.25%] train loss: 2.1517080313060433e-05 \n",
      "epoch: 9 [563277/888800 63.38%] train loss: 1.860272095655091e-05 \n",
      "epoch: 9 [564388/888800 63.50%] train loss: 1.9034214346902445e-05 \n",
      "epoch: 9 [565499/888800 63.62%] train loss: 2.0921519535477273e-05 \n",
      "epoch: 9 [566610/888800 63.75%] train loss: 1.9142713426845148e-05 \n",
      "epoch: 9 [567721/888800 63.88%] train loss: 1.903156953630969e-05 \n",
      "epoch: 9 [568832/888800 64.00%] train loss: 2.086138556478545e-05 \n",
      "epoch: 9 [569943/888800 64.12%] train loss: 1.8654473024071194e-05 \n",
      "epoch: 9 [571054/888800 64.25%] train loss: 2.0956638763891533e-05 \n",
      "epoch: 9 [572165/888800 64.38%] train loss: 1.8844242731574923e-05 \n",
      "epoch: 9 [573276/888800 64.50%] train loss: 1.8324559277971275e-05 \n",
      "epoch: 9 [574387/888800 64.62%] train loss: 2.0622370357159525e-05 \n",
      "epoch: 9 [575498/888800 64.75%] train loss: 2.1586785805993713e-05 \n",
      "epoch: 9 [576609/888800 64.88%] train loss: 1.9999857613584027e-05 \n",
      "epoch: 9 [577720/888800 65.00%] train loss: 1.8885717508965172e-05 \n",
      "epoch: 9 [578831/888800 65.12%] train loss: 1.9287184841232374e-05 \n",
      "epoch: 9 [579942/888800 65.25%] train loss: 1.7072457922040485e-05 \n",
      "epoch: 9 [581053/888800 65.38%] train loss: 2.1188150640227832e-05 \n",
      "epoch: 9 [582164/888800 65.50%] train loss: 1.7341810234938748e-05 \n",
      "epoch: 9 [583275/888800 65.62%] train loss: 2.136994226020761e-05 \n",
      "epoch: 9 [584386/888800 65.75%] train loss: 2.0505463908193633e-05 \n",
      "epoch: 9 [585497/888800 65.88%] train loss: 1.7207739801960997e-05 \n",
      "epoch: 9 [586608/888800 66.00%] train loss: 1.9702136341948062e-05 \n",
      "epoch: 9 [587719/888800 66.12%] train loss: 2.0093666535103694e-05 \n",
      "epoch: 9 [588830/888800 66.25%] train loss: 2.066817251034081e-05 \n",
      "epoch: 9 [589941/888800 66.38%] train loss: 2.0660494556068443e-05 \n",
      "epoch: 9 [591052/888800 66.50%] train loss: 2.0232911992934532e-05 \n",
      "epoch: 9 [592163/888800 66.62%] train loss: 1.9085742678726092e-05 \n",
      "epoch: 9 [593274/888800 66.75%] train loss: 2.237677836092189e-05 \n",
      "epoch: 9 [594385/888800 66.88%] train loss: 2.1033602024544962e-05 \n",
      "epoch: 9 [595496/888800 67.00%] train loss: 2.0311463231337257e-05 \n",
      "epoch: 9 [596607/888800 67.12%] train loss: 1.8664764866116457e-05 \n",
      "epoch: 9 [597718/888800 67.25%] train loss: 1.8544364138506353e-05 \n",
      "epoch: 9 [598829/888800 67.38%] train loss: 2.120550379913766e-05 \n",
      "epoch: 9 [599940/888800 67.50%] train loss: 2.287613278895151e-05 \n",
      "epoch: 9 [601051/888800 67.62%] train loss: 2.1523524992517196e-05 \n",
      "epoch: 9 [602162/888800 67.75%] train loss: 1.836966839618981e-05 \n",
      "epoch: 9 [603273/888800 67.88%] train loss: 1.9306724425405264e-05 \n",
      "epoch: 9 [604384/888800 68.00%] train loss: 1.8258640920976177e-05 \n",
      "epoch: 9 [605495/888800 68.12%] train loss: 2.27602431550622e-05 \n",
      "epoch: 9 [606606/888800 68.25%] train loss: 2.3666152628720738e-05 \n",
      "epoch: 9 [607717/888800 68.38%] train loss: 1.7256255887332372e-05 \n",
      "epoch: 9 [608828/888800 68.50%] train loss: 1.7694972484605387e-05 \n",
      "epoch: 9 [609939/888800 68.62%] train loss: 2.123209196724929e-05 \n",
      "epoch: 9 [611050/888800 68.75%] train loss: 2.1923149688518606e-05 \n",
      "epoch: 9 [612161/888800 68.88%] train loss: 2.1165064026718028e-05 \n",
      "epoch: 9 [613272/888800 69.00%] train loss: 1.914857784868218e-05 \n",
      "epoch: 9 [614383/888800 69.12%] train loss: 1.7517055312055163e-05 \n",
      "epoch: 9 [615494/888800 69.25%] train loss: 1.9684935978148133e-05 \n",
      "epoch: 9 [616605/888800 69.38%] train loss: 2.1408270185929723e-05 \n",
      "epoch: 9 [617716/888800 69.50%] train loss: 2.2047035599825904e-05 \n",
      "epoch: 9 [618827/888800 69.62%] train loss: 2.3158439944381826e-05 \n",
      "epoch: 9 [619938/888800 69.75%] train loss: 1.7970703993341886e-05 \n",
      "epoch: 9 [621049/888800 69.88%] train loss: 1.8441789507051e-05 \n",
      "epoch: 9 [622160/888800 70.00%] train loss: 1.829557731980458e-05 \n",
      "epoch: 9 [623271/888800 70.12%] train loss: 1.971091296582017e-05 \n",
      "epoch: 9 [624382/888800 70.25%] train loss: 2.226859942311421e-05 \n",
      "epoch: 9 [625493/888800 70.38%] train loss: 1.9061837519984692e-05 \n",
      "epoch: 9 [626604/888800 70.50%] train loss: 2.41581929003587e-05 \n",
      "epoch: 9 [627715/888800 70.62%] train loss: 1.773452095221728e-05 \n",
      "epoch: 9 [628826/888800 70.75%] train loss: 1.9576589693315327e-05 \n",
      "epoch: 9 [629937/888800 70.88%] train loss: 1.9658578821690753e-05 \n",
      "epoch: 9 [631048/888800 71.00%] train loss: 2.0383829905767925e-05 \n",
      "epoch: 9 [632159/888800 71.12%] train loss: 1.8173734133597463e-05 \n",
      "epoch: 9 [633270/888800 71.25%] train loss: 2.10642465390265e-05 \n",
      "epoch: 9 [634381/888800 71.38%] train loss: 2.127584048139397e-05 \n",
      "epoch: 9 [635492/888800 71.50%] train loss: 1.8847609680960886e-05 \n",
      "epoch: 9 [636603/888800 71.62%] train loss: 1.943410279636737e-05 \n",
      "epoch: 9 [637714/888800 71.75%] train loss: 1.8213739167549647e-05 \n",
      "epoch: 9 [638825/888800 71.88%] train loss: 1.887353755591903e-05 \n",
      "epoch: 9 [639936/888800 72.00%] train loss: 2.0328461687313393e-05 \n",
      "epoch: 9 [641047/888800 72.12%] train loss: 1.9660899852169678e-05 \n",
      "epoch: 9 [642158/888800 72.25%] train loss: 2.0555236915242858e-05 \n",
      "epoch: 9 [643269/888800 72.38%] train loss: 2.0921901523252018e-05 \n",
      "epoch: 9 [644380/888800 72.50%] train loss: 2.094407864206005e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [645491/888800 72.62%] train loss: 2.3536853404948488e-05 \n",
      "epoch: 9 [646602/888800 72.75%] train loss: 1.8011305655818433e-05 \n",
      "epoch: 9 [647713/888800 72.88%] train loss: 2.1713278329116292e-05 \n",
      "epoch: 9 [648824/888800 73.00%] train loss: 2.1428191757877357e-05 \n",
      "epoch: 9 [649935/888800 73.12%] train loss: 1.8753362382994965e-05 \n",
      "epoch: 9 [651046/888800 73.25%] train loss: 1.9845430870191194e-05 \n",
      "epoch: 9 [652157/888800 73.38%] train loss: 1.632859493838623e-05 \n",
      "epoch: 9 [653268/888800 73.50%] train loss: 2.306777059857268e-05 \n",
      "epoch: 9 [654379/888800 73.62%] train loss: 2.033774580922909e-05 \n",
      "epoch: 9 [655490/888800 73.75%] train loss: 1.9352197341504507e-05 \n",
      "epoch: 9 [656601/888800 73.88%] train loss: 1.8863838704419322e-05 \n",
      "epoch: 9 [657712/888800 74.00%] train loss: 2.151163607777562e-05 \n",
      "epoch: 9 [658823/888800 74.12%] train loss: 2.075666816381272e-05 \n",
      "epoch: 9 [659934/888800 74.25%] train loss: 2.0090152247576043e-05 \n",
      "epoch: 9 [661045/888800 74.38%] train loss: 2.017555925704073e-05 \n",
      "epoch: 9 [662156/888800 74.50%] train loss: 1.839288233895786e-05 \n",
      "epoch: 9 [663267/888800 74.62%] train loss: 1.997643084905576e-05 \n",
      "epoch: 9 [664378/888800 74.75%] train loss: 1.9988376152468845e-05 \n",
      "epoch: 9 [665489/888800 74.88%] train loss: 2.085665073536802e-05 \n",
      "epoch: 9 [666600/888800 75.00%] train loss: 1.8459086277289316e-05 \n",
      "epoch: 9 [667711/888800 75.12%] train loss: 2.128925916622393e-05 \n",
      "epoch: 9 [668822/888800 75.25%] train loss: 1.890318890218623e-05 \n",
      "epoch: 9 [669933/888800 75.38%] train loss: 1.7727947124512866e-05 \n",
      "epoch: 9 [671044/888800 75.50%] train loss: 1.946985321410466e-05 \n",
      "epoch: 9 [672155/888800 75.62%] train loss: 1.9591127056628466e-05 \n",
      "epoch: 9 [673266/888800 75.75%] train loss: 1.8451872165314853e-05 \n",
      "epoch: 9 [674377/888800 75.88%] train loss: 2.058616155409254e-05 \n",
      "epoch: 9 [675488/888800 76.00%] train loss: 2.1687172193196602e-05 \n",
      "epoch: 9 [676599/888800 76.12%] train loss: 2.1744874175055884e-05 \n",
      "epoch: 9 [677710/888800 76.25%] train loss: 1.6148225768120028e-05 \n",
      "epoch: 9 [678821/888800 76.38%] train loss: 1.7869109797175042e-05 \n",
      "epoch: 9 [679932/888800 76.50%] train loss: 1.774628799466882e-05 \n",
      "epoch: 9 [681043/888800 76.62%] train loss: 2.1859457774553448e-05 \n",
      "epoch: 9 [682154/888800 76.75%] train loss: 1.8179602193413302e-05 \n",
      "epoch: 9 [683265/888800 76.88%] train loss: 2.3561844500363804e-05 \n",
      "epoch: 9 [684376/888800 77.00%] train loss: 1.987246287171729e-05 \n",
      "epoch: 9 [685487/888800 77.12%] train loss: 2.025357935053762e-05 \n",
      "epoch: 9 [686598/888800 77.25%] train loss: 1.841408447944559e-05 \n",
      "epoch: 9 [687709/888800 77.38%] train loss: 1.956321284524165e-05 \n",
      "epoch: 9 [688820/888800 77.50%] train loss: 2.1903486413066275e-05 \n",
      "epoch: 9 [689931/888800 77.62%] train loss: 2.0534534996841103e-05 \n",
      "epoch: 9 [691042/888800 77.75%] train loss: 2.000798485823907e-05 \n",
      "epoch: 9 [692153/888800 77.88%] train loss: 1.8677670595934615e-05 \n",
      "epoch: 9 [693264/888800 78.00%] train loss: 1.7059432138921693e-05 \n",
      "epoch: 9 [694375/888800 78.12%] train loss: 2.0014445908600464e-05 \n",
      "epoch: 9 [695486/888800 78.25%] train loss: 2.14929023059085e-05 \n",
      "epoch: 9 [696597/888800 78.38%] train loss: 1.8535050912760198e-05 \n",
      "epoch: 9 [697708/888800 78.50%] train loss: 1.912066545628477e-05 \n",
      "epoch: 9 [698819/888800 78.62%] train loss: 1.7699172531138174e-05 \n",
      "epoch: 9 [699930/888800 78.75%] train loss: 2.0960749679943547e-05 \n",
      "epoch: 9 [701041/888800 78.88%] train loss: 2.313446566404309e-05 \n",
      "epoch: 9 [702152/888800 79.00%] train loss: 1.8711241864366457e-05 \n",
      "epoch: 9 [703263/888800 79.12%] train loss: 1.7323873180430382e-05 \n",
      "epoch: 9 [704374/888800 79.25%] train loss: 2.1322133761714213e-05 \n",
      "epoch: 9 [705485/888800 79.38%] train loss: 1.996075843635481e-05 \n",
      "epoch: 9 [706596/888800 79.50%] train loss: 1.7019887309288606e-05 \n",
      "epoch: 9 [707707/888800 79.62%] train loss: 2.065495209535584e-05 \n",
      "epoch: 9 [708818/888800 79.75%] train loss: 1.775511191226542e-05 \n",
      "epoch: 9 [709929/888800 79.88%] train loss: 1.8892320440500043e-05 \n",
      "epoch: 9 [711040/888800 80.00%] train loss: 2.02743449335685e-05 \n",
      "epoch: 9 [712151/888800 80.12%] train loss: 2.0365394448162988e-05 \n",
      "epoch: 9 [713262/888800 80.25%] train loss: 2.2600659576710314e-05 \n",
      "epoch: 9 [714373/888800 80.38%] train loss: 1.9529748897184618e-05 \n",
      "epoch: 9 [715484/888800 80.50%] train loss: 1.565192360430956e-05 \n",
      "epoch: 9 [716595/888800 80.62%] train loss: 2.188110192946624e-05 \n",
      "epoch: 9 [717706/888800 80.75%] train loss: 1.95421544049168e-05 \n",
      "epoch: 9 [718817/888800 80.88%] train loss: 1.7921673133969307e-05 \n",
      "epoch: 9 [719928/888800 81.00%] train loss: 1.9886156223947182e-05 \n",
      "epoch: 9 [721039/888800 81.12%] train loss: 2.0064811906195246e-05 \n",
      "epoch: 9 [722150/888800 81.25%] train loss: 1.8500180885894224e-05 \n",
      "epoch: 9 [723261/888800 81.38%] train loss: 1.8138684026780538e-05 \n",
      "epoch: 9 [724372/888800 81.50%] train loss: 2.3957867597346194e-05 \n",
      "epoch: 9 [725483/888800 81.62%] train loss: 1.930898906721268e-05 \n",
      "epoch: 9 [726594/888800 81.75%] train loss: 2.1863534129806794e-05 \n",
      "epoch: 9 [727705/888800 81.88%] train loss: 1.833057831390761e-05 \n",
      "epoch: 9 [728816/888800 82.00%] train loss: 1.961918496817816e-05 \n",
      "epoch: 9 [729927/888800 82.12%] train loss: 1.9013012206414714e-05 \n",
      "epoch: 9 [731038/888800 82.25%] train loss: 1.901825817185454e-05 \n",
      "epoch: 9 [732149/888800 82.38%] train loss: 2.2001964680384845e-05 \n",
      "epoch: 9 [733260/888800 82.50%] train loss: 2.0488638256210834e-05 \n",
      "epoch: 9 [734371/888800 82.62%] train loss: 1.8877937691286206e-05 \n",
      "epoch: 9 [735482/888800 82.75%] train loss: 1.8484377505956218e-05 \n",
      "epoch: 9 [736593/888800 82.88%] train loss: 1.9416413124417886e-05 \n",
      "epoch: 9 [737704/888800 83.00%] train loss: 2.1603298591799103e-05 \n",
      "epoch: 9 [738815/888800 83.12%] train loss: 1.7285718058701605e-05 \n",
      "epoch: 9 [739926/888800 83.25%] train loss: 1.8293600078322925e-05 \n",
      "epoch: 9 [741037/888800 83.38%] train loss: 1.9379334844416007e-05 \n",
      "epoch: 9 [742148/888800 83.50%] train loss: 2.0121851775911637e-05 \n",
      "epoch: 9 [743259/888800 83.62%] train loss: 1.834521026466973e-05 \n",
      "epoch: 9 [744370/888800 83.75%] train loss: 1.5894351236056536e-05 \n",
      "epoch: 9 [745481/888800 83.88%] train loss: 1.676897591096349e-05 \n",
      "epoch: 9 [746592/888800 84.00%] train loss: 1.898486152640544e-05 \n",
      "epoch: 9 [747703/888800 84.12%] train loss: 2.088672772515565e-05 \n",
      "epoch: 9 [748814/888800 84.25%] train loss: 1.943095776368864e-05 \n",
      "epoch: 9 [749925/888800 84.38%] train loss: 1.8376971638645045e-05 \n",
      "epoch: 9 [751036/888800 84.50%] train loss: 2.158143797714729e-05 \n",
      "epoch: 9 [752147/888800 84.62%] train loss: 1.894067827379331e-05 \n",
      "epoch: 9 [753258/888800 84.75%] train loss: 2.233419581898488e-05 \n",
      "epoch: 9 [754369/888800 84.88%] train loss: 2.0217272322042845e-05 \n",
      "epoch: 9 [755480/888800 85.00%] train loss: 1.8753966287476942e-05 \n",
      "epoch: 9 [756591/888800 85.12%] train loss: 1.7333000869257376e-05 \n",
      "epoch: 9 [757702/888800 85.25%] train loss: 1.9649778550956398e-05 \n",
      "epoch: 9 [758813/888800 85.38%] train loss: 1.76518369698897e-05 \n",
      "epoch: 9 [759924/888800 85.50%] train loss: 2.0273104382795282e-05 \n",
      "epoch: 9 [761035/888800 85.62%] train loss: 1.982849062187597e-05 \n",
      "epoch: 9 [762146/888800 85.75%] train loss: 1.883021650428418e-05 \n",
      "epoch: 9 [763257/888800 85.88%] train loss: 1.743527718645055e-05 \n",
      "epoch: 9 [764368/888800 86.00%] train loss: 1.9998728021164425e-05 \n",
      "epoch: 9 [765479/888800 86.12%] train loss: 1.8770080714602955e-05 \n",
      "epoch: 9 [766590/888800 86.25%] train loss: 1.802479164325632e-05 \n",
      "epoch: 9 [767701/888800 86.38%] train loss: 1.892348336696159e-05 \n",
      "epoch: 9 [768812/888800 86.50%] train loss: 1.8467115296516567e-05 \n",
      "epoch: 9 [769923/888800 86.62%] train loss: 2.018648046941962e-05 \n",
      "epoch: 9 [771034/888800 86.75%] train loss: 1.7987515093409456e-05 \n",
      "epoch: 9 [772145/888800 86.88%] train loss: 1.71155570569681e-05 \n",
      "epoch: 9 [773256/888800 87.00%] train loss: 1.9375265765120275e-05 \n",
      "epoch: 9 [774367/888800 87.12%] train loss: 1.777363104338292e-05 \n",
      "epoch: 9 [775478/888800 87.25%] train loss: 1.754352888383437e-05 \n",
      "epoch: 9 [776589/888800 87.38%] train loss: 1.822940248530358e-05 \n",
      "epoch: 9 [777700/888800 87.50%] train loss: 2.0086768927285448e-05 \n",
      "epoch: 9 [778811/888800 87.62%] train loss: 1.7316973753622733e-05 \n",
      "epoch: 9 [779922/888800 87.75%] train loss: 2.036266596405767e-05 \n",
      "epoch: 9 [781033/888800 87.88%] train loss: 1.6628342564217746e-05 \n",
      "epoch: 9 [782144/888800 88.00%] train loss: 1.794284617062658e-05 \n",
      "epoch: 9 [783255/888800 88.12%] train loss: 1.988055373658426e-05 \n",
      "epoch: 9 [784366/888800 88.25%] train loss: 1.643594259803649e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 [785477/888800 88.38%] train loss: 2.172421955037862e-05 \n",
      "epoch: 9 [786588/888800 88.50%] train loss: 2.1753099645138718e-05 \n",
      "epoch: 9 [787699/888800 88.62%] train loss: 2.0161027350695804e-05 \n",
      "epoch: 9 [788810/888800 88.75%] train loss: 1.9124896425637417e-05 \n",
      "epoch: 9 [789921/888800 88.88%] train loss: 1.863437137217261e-05 \n",
      "epoch: 9 [791032/888800 89.00%] train loss: 2.3019299987936392e-05 \n",
      "epoch: 9 [792143/888800 89.12%] train loss: 1.7951630070456304e-05 \n",
      "epoch: 9 [793254/888800 89.25%] train loss: 1.8892353182309307e-05 \n",
      "epoch: 9 [794365/888800 89.38%] train loss: 2.046041117864661e-05 \n",
      "epoch: 9 [795476/888800 89.50%] train loss: 1.6393494661315344e-05 \n",
      "epoch: 9 [796587/888800 89.62%] train loss: 1.853682624641806e-05 \n",
      "epoch: 9 [797698/888800 89.75%] train loss: 2.0042076357640326e-05 \n",
      "epoch: 9 [798809/888800 89.88%] train loss: 1.850420085247606e-05 \n",
      "epoch: 9 [799920/888800 90.00%] train loss: 1.9332497686264105e-05 \n",
      "epoch: 9 [801031/888800 90.12%] train loss: 1.919538226502482e-05 \n",
      "epoch: 9 [802142/888800 90.25%] train loss: 1.983750371437054e-05 \n",
      "epoch: 9 [803253/888800 90.38%] train loss: 1.731007250782568e-05 \n",
      "epoch: 9 [804364/888800 90.50%] train loss: 1.8518710930948146e-05 \n",
      "epoch: 9 [805475/888800 90.62%] train loss: 2.0288554878789e-05 \n",
      "epoch: 9 [806586/888800 90.75%] train loss: 1.78585196408676e-05 \n",
      "epoch: 9 [807697/888800 90.88%] train loss: 2.0327386664575897e-05 \n",
      "epoch: 9 [808808/888800 91.00%] train loss: 1.9208662706660107e-05 \n",
      "epoch: 9 [809919/888800 91.12%] train loss: 1.8703638488659635e-05 \n",
      "epoch: 9 [811030/888800 91.25%] train loss: 1.941289519891143e-05 \n",
      "epoch: 9 [812141/888800 91.38%] train loss: 1.6227821106440388e-05 \n",
      "epoch: 9 [813252/888800 91.50%] train loss: 2.0198198399157263e-05 \n",
      "epoch: 9 [814363/888800 91.62%] train loss: 1.8095544874086045e-05 \n",
      "epoch: 9 [815474/888800 91.75%] train loss: 1.8059665308101103e-05 \n",
      "epoch: 9 [816585/888800 91.88%] train loss: 1.951100603037048e-05 \n",
      "epoch: 9 [817696/888800 92.00%] train loss: 1.890778003144078e-05 \n",
      "epoch: 9 [818807/888800 92.12%] train loss: 1.6593572581768967e-05 \n",
      "epoch: 9 [819918/888800 92.25%] train loss: 1.9348837668076158e-05 \n",
      "epoch: 9 [821029/888800 92.38%] train loss: 2.0129624317632988e-05 \n",
      "epoch: 9 [822140/888800 92.50%] train loss: 1.9639979655039497e-05 \n",
      "epoch: 9 [823251/888800 92.62%] train loss: 1.9121129298582673e-05 \n",
      "epoch: 9 [824362/888800 92.75%] train loss: 1.970760422409512e-05 \n",
      "epoch: 9 [825473/888800 92.88%] train loss: 1.872834218374919e-05 \n",
      "epoch: 9 [826584/888800 93.00%] train loss: 1.8672222722670995e-05 \n",
      "epoch: 9 [827695/888800 93.12%] train loss: 1.7862328604678623e-05 \n",
      "epoch: 9 [828806/888800 93.25%] train loss: 1.766043533280026e-05 \n",
      "epoch: 9 [829917/888800 93.38%] train loss: 1.917152440000791e-05 \n",
      "epoch: 9 [831028/888800 93.50%] train loss: 1.9190341845387593e-05 \n",
      "epoch: 9 [832139/888800 93.62%] train loss: 1.8322205505683087e-05 \n",
      "epoch: 9 [833250/888800 93.75%] train loss: 2.010580283240415e-05 \n",
      "epoch: 9 [834361/888800 93.88%] train loss: 2.0732259145006537e-05 \n",
      "epoch: 9 [835472/888800 94.00%] train loss: 1.8299289877177216e-05 \n",
      "epoch: 9 [836583/888800 94.12%] train loss: 1.709479147393722e-05 \n",
      "epoch: 9 [837694/888800 94.25%] train loss: 1.8058168279821984e-05 \n",
      "epoch: 9 [838805/888800 94.38%] train loss: 2.0477789803408086e-05 \n",
      "epoch: 9 [839916/888800 94.50%] train loss: 2.024441710091196e-05 \n",
      "epoch: 9 [841027/888800 94.62%] train loss: 1.7411206499673426e-05 \n",
      "epoch: 9 [842138/888800 94.75%] train loss: 1.8100832676282153e-05 \n",
      "epoch: 9 [843249/888800 94.88%] train loss: 2.192052488680929e-05 \n",
      "epoch: 9 [844360/888800 95.00%] train loss: 1.5759726011310704e-05 \n",
      "epoch: 9 [845471/888800 95.12%] train loss: 1.7850921722128987e-05 \n",
      "epoch: 9 [846582/888800 95.25%] train loss: 1.9216467990190722e-05 \n",
      "epoch: 9 [847693/888800 95.38%] train loss: 1.8059765352518298e-05 \n",
      "epoch: 9 [848804/888800 95.50%] train loss: 1.850362059485633e-05 \n",
      "epoch: 9 [849915/888800 95.62%] train loss: 2.0283536287024617e-05 \n",
      "epoch: 9 [851026/888800 95.75%] train loss: 2.1055784600321203e-05 \n",
      "epoch: 9 [852137/888800 95.88%] train loss: 1.9478249669191428e-05 \n",
      "epoch: 9 [853248/888800 96.00%] train loss: 2.120281533279922e-05 \n",
      "epoch: 9 [854359/888800 96.12%] train loss: 1.8536382413003594e-05 \n",
      "epoch: 9 [855470/888800 96.25%] train loss: 1.8465616449248046e-05 \n",
      "epoch: 9 [856581/888800 96.38%] train loss: 2.0097057131351903e-05 \n",
      "epoch: 9 [857692/888800 96.50%] train loss: 1.9264100046711974e-05 \n",
      "epoch: 9 [858803/888800 96.62%] train loss: 1.9539262211765163e-05 \n",
      "epoch: 9 [859914/888800 96.75%] train loss: 1.6546700862818398e-05 \n",
      "epoch: 9 [861025/888800 96.88%] train loss: 1.7579051927896217e-05 \n",
      "epoch: 9 [862136/888800 97.00%] train loss: 2.0446010239538737e-05 \n",
      "epoch: 9 [863247/888800 97.12%] train loss: 1.7462874893681146e-05 \n",
      "epoch: 9 [864358/888800 97.25%] train loss: 2.0950965335941873e-05 \n",
      "epoch: 9 [865469/888800 97.38%] train loss: 1.7579424820723943e-05 \n",
      "epoch: 9 [866580/888800 97.50%] train loss: 1.8951755919260904e-05 \n",
      "epoch: 9 [867691/888800 97.62%] train loss: 1.6331838196492754e-05 \n",
      "epoch: 9 [868802/888800 97.75%] train loss: 1.4232924513635226e-05 \n",
      "epoch: 9 [869913/888800 97.88%] train loss: 2.2393880499294028e-05 \n",
      "epoch: 9 [871024/888800 98.00%] train loss: 1.7513577404315583e-05 \n",
      "epoch: 9 [872135/888800 98.12%] train loss: 1.6885725926840678e-05 \n",
      "epoch: 9 [873246/888800 98.25%] train loss: 2.1491723600775003e-05 \n",
      "epoch: 9 [874357/888800 98.38%] train loss: 2.0671714082709514e-05 \n",
      "epoch: 9 [875468/888800 98.50%] train loss: 1.702676308923401e-05 \n",
      "epoch: 9 [876579/888800 98.62%] train loss: 2.0180988940410316e-05 \n",
      "epoch: 9 [877690/888800 98.75%] train loss: 2.100528945447877e-05 \n",
      "epoch: 9 [878801/888800 98.88%] train loss: 2.2165591872180812e-05 \n",
      "epoch: 9 [879912/888800 99.00%] train loss: 2.089715599140618e-05 \n",
      "epoch: 9 [881023/888800 99.12%] train loss: 1.6823903933982365e-05 \n",
      "epoch: 9 [882134/888800 99.25%] train loss: 1.7869648218038492e-05 \n",
      "epoch: 9 [883245/888800 99.38%] train loss: 1.8405946320854127e-05 \n",
      "epoch: 9 [884356/888800 99.50%] train loss: 1.826085281209089e-05 \n",
      "epoch: 9 [885467/888800 99.62%] train loss: 1.8998756786459126e-05 \n",
      "epoch: 9 [886578/888800 99.75%] train loss: 2.099084849760402e-05 \n",
      "epoch: 9 [887689/888800 99.88%] train loss: 1.85602912097238e-05 \n",
      "epoch: 10 [0/888800 0.00%] train loss: 1.9000068277819082e-05 \n",
      "epoch: 10 [1111/888800 0.12%] train loss: 2.02645460376516e-05 \n",
      "epoch: 10 [2222/888800 0.25%] train loss: 1.6521700672456063e-05 \n",
      "epoch: 10 [3333/888800 0.38%] train loss: 1.8786717191687785e-05 \n",
      "epoch: 10 [4444/888800 0.50%] train loss: 1.5335310308728367e-05 \n",
      "epoch: 10 [5555/888800 0.62%] train loss: 1.8499986254028045e-05 \n",
      "epoch: 10 [6666/888800 0.75%] train loss: 2.0704403141280636e-05 \n",
      "epoch: 10 [7777/888800 0.88%] train loss: 1.7726910300552845e-05 \n",
      "epoch: 10 [8888/888800 1.00%] train loss: 1.7679725715424865e-05 \n",
      "epoch: 10 [9999/888800 1.12%] train loss: 1.5089146472746506e-05 \n",
      "epoch: 10 [11110/888800 1.25%] train loss: 1.9546530893421732e-05 \n",
      "epoch: 10 [12221/888800 1.38%] train loss: 1.7982898498303257e-05 \n",
      "epoch: 10 [13332/888800 1.50%] train loss: 1.8412742065265775e-05 \n",
      "epoch: 10 [14443/888800 1.62%] train loss: 1.9140687072649598e-05 \n",
      "epoch: 10 [15554/888800 1.75%] train loss: 1.942270500876475e-05 \n",
      "epoch: 10 [16665/888800 1.88%] train loss: 1.8613807696965523e-05 \n",
      "epoch: 10 [17776/888800 2.00%] train loss: 2.0959872927051038e-05 \n",
      "epoch: 10 [18887/888800 2.12%] train loss: 1.7652266251388937e-05 \n",
      "epoch: 10 [19998/888800 2.25%] train loss: 1.8283350073033944e-05 \n",
      "epoch: 10 [21109/888800 2.38%] train loss: 1.670902202022262e-05 \n",
      "epoch: 10 [22220/888800 2.50%] train loss: 1.8707301933318377e-05 \n",
      "epoch: 10 [23331/888800 2.62%] train loss: 1.7272765035158955e-05 \n",
      "epoch: 10 [24442/888800 2.75%] train loss: 1.5791907571838237e-05 \n",
      "epoch: 10 [25553/888800 2.88%] train loss: 1.956210508069489e-05 \n",
      "epoch: 10 [26664/888800 3.00%] train loss: 1.9361541490070522e-05 \n",
      "epoch: 10 [27775/888800 3.12%] train loss: 1.72734544321429e-05 \n",
      "epoch: 10 [28886/888800 3.25%] train loss: 1.5876081306487322e-05 \n",
      "epoch: 10 [29997/888800 3.38%] train loss: 2.0253037291695364e-05 \n",
      "epoch: 10 [31108/888800 3.50%] train loss: 1.9503217117744498e-05 \n",
      "epoch: 10 [32219/888800 3.62%] train loss: 1.9662453269120306e-05 \n",
      "epoch: 10 [33330/888800 3.75%] train loss: 1.8681123037822545e-05 \n",
      "epoch: 10 [34441/888800 3.88%] train loss: 1.912741208798252e-05 \n",
      "epoch: 10 [35552/888800 4.00%] train loss: 1.727339440549258e-05 \n",
      "epoch: 10 [36663/888800 4.12%] train loss: 1.6264764781226404e-05 \n",
      "epoch: 10 [37774/888800 4.25%] train loss: 1.7293043129029684e-05 \n",
      "epoch: 10 [38885/888800 4.38%] train loss: 1.92913539649453e-05 \n",
      "epoch: 10 [39996/888800 4.50%] train loss: 1.9541545043466613e-05 \n",
      "epoch: 10 [41107/888800 4.62%] train loss: 1.826566040108446e-05 \n",
      "epoch: 10 [42218/888800 4.75%] train loss: 1.8748598449747078e-05 \n",
      "epoch: 10 [43329/888800 4.88%] train loss: 1.6236877854680642e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [44440/888800 5.00%] train loss: 1.825384606490843e-05 \n",
      "epoch: 10 [45551/888800 5.12%] train loss: 1.9034645447391085e-05 \n",
      "epoch: 10 [46662/888800 5.25%] train loss: 1.8092923710355535e-05 \n",
      "epoch: 10 [47773/888800 5.38%] train loss: 1.754215372784529e-05 \n",
      "epoch: 10 [48884/888800 5.50%] train loss: 1.9229664758313447e-05 \n",
      "epoch: 10 [49995/888800 5.62%] train loss: 2.137639057764318e-05 \n",
      "epoch: 10 [51106/888800 5.75%] train loss: 1.8870174244511873e-05 \n",
      "epoch: 10 [52217/888800 5.88%] train loss: 1.8778504454530776e-05 \n",
      "epoch: 10 [53328/888800 6.00%] train loss: 1.915748907777015e-05 \n",
      "epoch: 10 [54439/888800 6.12%] train loss: 2.0403434973559342e-05 \n",
      "epoch: 10 [55550/888800 6.25%] train loss: 1.4213200302037876e-05 \n",
      "epoch: 10 [56661/888800 6.38%] train loss: 1.8449689378030598e-05 \n",
      "epoch: 10 [57772/888800 6.50%] train loss: 1.6936219253693707e-05 \n",
      "epoch: 10 [58883/888800 6.62%] train loss: 1.8201299099018797e-05 \n",
      "epoch: 10 [59994/888800 6.75%] train loss: 1.8576451111584902e-05 \n",
      "epoch: 10 [61105/888800 6.88%] train loss: 1.8658094631973654e-05 \n",
      "epoch: 10 [62216/888800 7.00%] train loss: 1.8748867660178803e-05 \n",
      "epoch: 10 [63327/888800 7.12%] train loss: 1.7026657587848604e-05 \n",
      "epoch: 10 [64438/888800 7.25%] train loss: 1.8622769857756793e-05 \n",
      "epoch: 10 [65549/888800 7.38%] train loss: 1.7141383068519644e-05 \n",
      "epoch: 10 [66660/888800 7.50%] train loss: 2.0058199879713356e-05 \n",
      "epoch: 10 [67771/888800 7.62%] train loss: 1.7543719877721742e-05 \n",
      "epoch: 10 [68882/888800 7.75%] train loss: 1.6039572074078023e-05 \n",
      "epoch: 10 [69993/888800 7.88%] train loss: 1.9579629224608652e-05 \n",
      "epoch: 10 [71104/888800 8.00%] train loss: 2.2756146790925413e-05 \n",
      "epoch: 10 [72215/888800 8.12%] train loss: 1.9199182133888826e-05 \n",
      "epoch: 10 [73326/888800 8.25%] train loss: 1.8637732864590362e-05 \n",
      "epoch: 10 [74437/888800 8.38%] train loss: 1.844684265961405e-05 \n",
      "epoch: 10 [75548/888800 8.50%] train loss: 1.705642534943763e-05 \n",
      "epoch: 10 [76659/888800 8.62%] train loss: 2.0121085981372744e-05 \n",
      "epoch: 10 [77770/888800 8.75%] train loss: 1.601282747287769e-05 \n",
      "epoch: 10 [78881/888800 8.88%] train loss: 1.8906075638369657e-05 \n",
      "epoch: 10 [79992/888800 9.00%] train loss: 1.9027780581382103e-05 \n",
      "epoch: 10 [81103/888800 9.12%] train loss: 1.506521221017465e-05 \n",
      "epoch: 10 [82214/888800 9.25%] train loss: 1.9611188690760173e-05 \n",
      "epoch: 10 [83325/888800 9.38%] train loss: 2.1146213839529082e-05 \n",
      "epoch: 10 [84436/888800 9.50%] train loss: 2.0248666260158643e-05 \n",
      "epoch: 10 [85547/888800 9.62%] train loss: 1.876859096228145e-05 \n",
      "epoch: 10 [86658/888800 9.75%] train loss: 1.8805309082381427e-05 \n",
      "epoch: 10 [87769/888800 9.88%] train loss: 1.849716318247374e-05 \n",
      "epoch: 10 [88880/888800 10.00%] train loss: 1.7500753529020585e-05 \n",
      "epoch: 10 [89991/888800 10.12%] train loss: 1.8951488527818583e-05 \n",
      "epoch: 10 [91102/888800 10.25%] train loss: 1.7893980839289725e-05 \n",
      "epoch: 10 [92213/888800 10.38%] train loss: 1.6835881979204714e-05 \n",
      "epoch: 10 [93324/888800 10.50%] train loss: 1.7666085113887675e-05 \n",
      "epoch: 10 [94435/888800 10.62%] train loss: 1.532153328298591e-05 \n",
      "epoch: 10 [95546/888800 10.75%] train loss: 2.0257404685253277e-05 \n",
      "epoch: 10 [96657/888800 10.88%] train loss: 1.6091524230432697e-05 \n",
      "epoch: 10 [97768/888800 11.00%] train loss: 1.8575943613541313e-05 \n",
      "epoch: 10 [98879/888800 11.12%] train loss: 1.574892485223245e-05 \n",
      "epoch: 10 [99990/888800 11.25%] train loss: 1.833339047152549e-05 \n",
      "epoch: 10 [101101/888800 11.38%] train loss: 2.173817847506143e-05 \n",
      "epoch: 10 [102212/888800 11.50%] train loss: 1.853924732131418e-05 \n",
      "epoch: 10 [103323/888800 11.62%] train loss: 1.928393066918943e-05 \n",
      "epoch: 10 [104434/888800 11.75%] train loss: 1.71061183209531e-05 \n",
      "epoch: 10 [105545/888800 11.88%] train loss: 1.8680964785744436e-05 \n",
      "epoch: 10 [106656/888800 12.00%] train loss: 1.7864515029941685e-05 \n",
      "epoch: 10 [107767/888800 12.12%] train loss: 1.5892775991233066e-05 \n",
      "epoch: 10 [108878/888800 12.25%] train loss: 1.949154830072075e-05 \n",
      "epoch: 10 [109989/888800 12.38%] train loss: 1.7083573766285554e-05 \n",
      "epoch: 10 [111100/888800 12.50%] train loss: 1.9307733964524232e-05 \n",
      "epoch: 10 [112211/888800 12.62%] train loss: 1.8292605091119185e-05 \n",
      "epoch: 10 [113322/888800 12.75%] train loss: 2.204385782533791e-05 \n",
      "epoch: 10 [114433/888800 12.88%] train loss: 1.740598600008525e-05 \n",
      "epoch: 10 [115544/888800 13.00%] train loss: 1.881755997601431e-05 \n",
      "epoch: 10 [116655/888800 13.12%] train loss: 1.989863631024491e-05 \n",
      "epoch: 10 [117766/888800 13.25%] train loss: 1.8046810509986244e-05 \n",
      "epoch: 10 [118877/888800 13.38%] train loss: 1.6983942259685136e-05 \n",
      "epoch: 10 [119988/888800 13.50%] train loss: 1.685740426182747e-05 \n",
      "epoch: 10 [121099/888800 13.62%] train loss: 1.999667438212782e-05 \n",
      "epoch: 10 [122210/888800 13.75%] train loss: 1.9469829567242414e-05 \n",
      "epoch: 10 [123321/888800 13.88%] train loss: 1.7936517906491645e-05 \n",
      "epoch: 10 [124432/888800 14.00%] train loss: 2.1396273950813338e-05 \n",
      "epoch: 10 [125543/888800 14.12%] train loss: 1.792342845874373e-05 \n",
      "epoch: 10 [126654/888800 14.25%] train loss: 1.872781831480097e-05 \n",
      "epoch: 10 [127765/888800 14.38%] train loss: 1.7900489183375612e-05 \n",
      "epoch: 10 [128876/888800 14.50%] train loss: 1.7690210370346904e-05 \n",
      "epoch: 10 [129987/888800 14.62%] train loss: 1.877045360743068e-05 \n",
      "epoch: 10 [131098/888800 14.75%] train loss: 1.900403731269762e-05 \n",
      "epoch: 10 [132209/888800 14.88%] train loss: 1.9017777958652005e-05 \n",
      "epoch: 10 [133320/888800 15.00%] train loss: 1.9022851120098494e-05 \n",
      "epoch: 10 [134431/888800 15.12%] train loss: 2.2074225853430107e-05 \n",
      "epoch: 10 [135542/888800 15.25%] train loss: 1.7079766621463932e-05 \n",
      "epoch: 10 [136653/888800 15.38%] train loss: 1.5217739019135479e-05 \n",
      "epoch: 10 [137764/888800 15.50%] train loss: 1.7592936274013482e-05 \n",
      "epoch: 10 [138875/888800 15.62%] train loss: 1.7443277101847343e-05 \n",
      "epoch: 10 [139986/888800 15.75%] train loss: 1.9005929061677307e-05 \n",
      "epoch: 10 [141097/888800 15.88%] train loss: 1.790379246813245e-05 \n",
      "epoch: 10 [142208/888800 16.00%] train loss: 1.6904014046303928e-05 \n",
      "epoch: 10 [143319/888800 16.12%] train loss: 1.922325463965535e-05 \n",
      "epoch: 10 [144430/888800 16.25%] train loss: 1.7518681488581933e-05 \n",
      "epoch: 10 [145541/888800 16.38%] train loss: 1.8086753698298708e-05 \n",
      "epoch: 10 [146652/888800 16.50%] train loss: 1.8800454199663363e-05 \n",
      "epoch: 10 [147763/888800 16.62%] train loss: 1.8031663785222918e-05 \n",
      "epoch: 10 [148874/888800 16.75%] train loss: 1.601755866431631e-05 \n",
      "epoch: 10 [149985/888800 16.88%] train loss: 1.919676287798211e-05 \n",
      "epoch: 10 [151096/888800 17.00%] train loss: 1.95042448467575e-05 \n",
      "epoch: 10 [152207/888800 17.12%] train loss: 1.8252156223752536e-05 \n",
      "epoch: 10 [153318/888800 17.25%] train loss: 1.581323340360541e-05 \n",
      "epoch: 10 [154429/888800 17.38%] train loss: 1.9058321413467638e-05 \n",
      "epoch: 10 [155540/888800 17.50%] train loss: 1.89311831491068e-05 \n",
      "epoch: 10 [156651/888800 17.62%] train loss: 1.9035369405173697e-05 \n",
      "epoch: 10 [157762/888800 17.75%] train loss: 1.6501668142154813e-05 \n",
      "epoch: 10 [158873/888800 17.88%] train loss: 1.705380782368593e-05 \n",
      "epoch: 10 [159984/888800 18.00%] train loss: 1.6664716895320453e-05 \n",
      "epoch: 10 [161095/888800 18.12%] train loss: 1.7553284124005586e-05 \n",
      "epoch: 10 [162206/888800 18.25%] train loss: 1.8631762941367924e-05 \n",
      "epoch: 10 [163317/888800 18.38%] train loss: 1.633819738344755e-05 \n",
      "epoch: 10 [164428/888800 18.50%] train loss: 1.8071588783641346e-05 \n",
      "epoch: 10 [165539/888800 18.62%] train loss: 1.989640441024676e-05 \n",
      "epoch: 10 [166650/888800 18.75%] train loss: 1.825037361413706e-05 \n",
      "epoch: 10 [167761/888800 18.88%] train loss: 1.7670430679572746e-05 \n",
      "epoch: 10 [168872/888800 19.00%] train loss: 1.8317474314244464e-05 \n",
      "epoch: 10 [169983/888800 19.12%] train loss: 1.7324940927210264e-05 \n",
      "epoch: 10 [171094/888800 19.25%] train loss: 1.5587043890263885e-05 \n",
      "epoch: 10 [172205/888800 19.38%] train loss: 1.7309386748820543e-05 \n",
      "epoch: 10 [173316/888800 19.50%] train loss: 1.7779768313630484e-05 \n",
      "epoch: 10 [174427/888800 19.62%] train loss: 1.8039629139821045e-05 \n",
      "epoch: 10 [175538/888800 19.75%] train loss: 2.1175317669985816e-05 \n",
      "epoch: 10 [176649/888800 19.88%] train loss: 1.655733103689272e-05 \n",
      "epoch: 10 [177760/888800 20.00%] train loss: 1.560615601192694e-05 \n",
      "epoch: 10 [178871/888800 20.12%] train loss: 1.8415847080177628e-05 \n",
      "epoch: 10 [179982/888800 20.25%] train loss: 1.794669333321508e-05 \n",
      "epoch: 10 [181093/888800 20.38%] train loss: 1.6936457541305572e-05 \n",
      "epoch: 10 [182204/888800 20.50%] train loss: 1.7859139916254207e-05 \n",
      "epoch: 10 [183315/888800 20.62%] train loss: 1.7419244613847695e-05 \n",
      "epoch: 10 [184426/888800 20.75%] train loss: 1.687551775830798e-05 \n",
      "epoch: 10 [185537/888800 20.88%] train loss: 1.7870184819912538e-05 \n",
      "epoch: 10 [186648/888800 21.00%] train loss: 1.8311689927941188e-05 \n",
      "epoch: 10 [187759/888800 21.12%] train loss: 1.835819784901105e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [188870/888800 21.25%] train loss: 1.833740680012852e-05 \n",
      "epoch: 10 [189981/888800 21.38%] train loss: 1.7129568732343614e-05 \n",
      "epoch: 10 [191092/888800 21.50%] train loss: 2.0349039914435707e-05 \n",
      "epoch: 10 [192203/888800 21.62%] train loss: 1.8613987776916474e-05 \n",
      "epoch: 10 [193314/888800 21.75%] train loss: 1.6892425264813937e-05 \n",
      "epoch: 10 [194425/888800 21.88%] train loss: 1.7111840861616656e-05 \n",
      "epoch: 10 [195536/888800 22.00%] train loss: 1.674119266681373e-05 \n",
      "epoch: 10 [196647/888800 22.12%] train loss: 1.9664539649966173e-05 \n",
      "epoch: 10 [197758/888800 22.25%] train loss: 1.7577995095052756e-05 \n",
      "epoch: 10 [198869/888800 22.38%] train loss: 1.792496732377913e-05 \n",
      "epoch: 10 [199980/888800 22.50%] train loss: 1.7848842617240734e-05 \n",
      "epoch: 10 [201091/888800 22.62%] train loss: 1.7704944184515625e-05 \n",
      "epoch: 10 [202202/888800 22.75%] train loss: 2.058775135083124e-05 \n",
      "epoch: 10 [203313/888800 22.88%] train loss: 1.9884402718162164e-05 \n",
      "epoch: 10 [204424/888800 23.00%] train loss: 1.985124617931433e-05 \n",
      "epoch: 10 [205535/888800 23.12%] train loss: 1.6778998542577028e-05 \n",
      "epoch: 10 [206646/888800 23.25%] train loss: 2.0278424926800653e-05 \n",
      "epoch: 10 [207757/888800 23.38%] train loss: 1.6514441085746512e-05 \n",
      "epoch: 10 [208868/888800 23.50%] train loss: 2.0636589397327043e-05 \n",
      "epoch: 10 [209979/888800 23.62%] train loss: 1.6620451788185164e-05 \n",
      "epoch: 10 [211090/888800 23.75%] train loss: 1.7762697098078206e-05 \n",
      "epoch: 10 [212201/888800 23.88%] train loss: 1.8859387637348846e-05 \n",
      "epoch: 10 [213312/888800 24.00%] train loss: 1.616026202100329e-05 \n",
      "epoch: 10 [214423/888800 24.12%] train loss: 1.7114676666096784e-05 \n",
      "epoch: 10 [215534/888800 24.25%] train loss: 1.8993794583366252e-05 \n",
      "epoch: 10 [216645/888800 24.38%] train loss: 1.5780849935254082e-05 \n",
      "epoch: 10 [217756/888800 24.50%] train loss: 1.5727408026577905e-05 \n",
      "epoch: 10 [218867/888800 24.62%] train loss: 1.9030934709007852e-05 \n",
      "epoch: 10 [219978/888800 24.75%] train loss: 1.7816473700804636e-05 \n",
      "epoch: 10 [221089/888800 24.88%] train loss: 1.6764806787250564e-05 \n",
      "epoch: 10 [222200/888800 25.00%] train loss: 1.908655212901067e-05 \n",
      "epoch: 10 [223311/888800 25.12%] train loss: 1.7345208107144572e-05 \n",
      "epoch: 10 [224422/888800 25.25%] train loss: 1.6677813619025983e-05 \n",
      "epoch: 10 [225533/888800 25.38%] train loss: 2.054517790384125e-05 \n",
      "epoch: 10 [226644/888800 25.50%] train loss: 1.6875730580068193e-05 \n",
      "epoch: 10 [227755/888800 25.62%] train loss: 1.7137806935352273e-05 \n",
      "epoch: 10 [228866/888800 25.75%] train loss: 1.6783018509158865e-05 \n",
      "epoch: 10 [229977/888800 25.88%] train loss: 1.7784130250220187e-05 \n",
      "epoch: 10 [231088/888800 26.00%] train loss: 1.8909346181317233e-05 \n",
      "epoch: 10 [232199/888800 26.12%] train loss: 1.748370959830936e-05 \n",
      "epoch: 10 [233310/888800 26.25%] train loss: 1.674316263233777e-05 \n",
      "epoch: 10 [234421/888800 26.38%] train loss: 1.6595520719420165e-05 \n",
      "epoch: 10 [235532/888800 26.50%] train loss: 1.9988801795989275e-05 \n",
      "epoch: 10 [236643/888800 26.62%] train loss: 1.7921614926308393e-05 \n",
      "epoch: 10 [237754/888800 26.75%] train loss: 1.7108999600168318e-05 \n",
      "epoch: 10 [238865/888800 26.88%] train loss: 1.9354705727891997e-05 \n",
      "epoch: 10 [239976/888800 27.00%] train loss: 1.8714852558332495e-05 \n",
      "epoch: 10 [241087/888800 27.12%] train loss: 1.666543357714545e-05 \n",
      "epoch: 10 [242198/888800 27.25%] train loss: 2.0928246158291586e-05 \n",
      "epoch: 10 [243309/888800 27.38%] train loss: 1.8021100913756527e-05 \n",
      "epoch: 10 [244420/888800 27.50%] train loss: 1.9390417946851812e-05 \n",
      "epoch: 10 [245531/888800 27.62%] train loss: 1.6868671082193032e-05 \n",
      "epoch: 10 [246642/888800 27.75%] train loss: 1.818438249756582e-05 \n",
      "epoch: 10 [247753/888800 27.88%] train loss: 1.593731576576829e-05 \n",
      "epoch: 10 [248864/888800 28.00%] train loss: 1.823758975660894e-05 \n",
      "epoch: 10 [249975/888800 28.12%] train loss: 1.5911433365545236e-05 \n",
      "epoch: 10 [251086/888800 28.25%] train loss: 1.6185949789360166e-05 \n",
      "epoch: 10 [252197/888800 28.38%] train loss: 1.7133392248069867e-05 \n",
      "epoch: 10 [253308/888800 28.50%] train loss: 1.7449936422053725e-05 \n",
      "epoch: 10 [254419/888800 28.62%] train loss: 1.549936678202357e-05 \n",
      "epoch: 10 [255530/888800 28.75%] train loss: 1.7156777175841853e-05 \n",
      "epoch: 10 [256641/888800 28.88%] train loss: 1.8318613001611084e-05 \n",
      "epoch: 10 [257752/888800 29.00%] train loss: 1.6525724277016707e-05 \n",
      "epoch: 10 [258863/888800 29.12%] train loss: 1.668310142122209e-05 \n",
      "epoch: 10 [259974/888800 29.25%] train loss: 1.5462263036170043e-05 \n",
      "epoch: 10 [261085/888800 29.38%] train loss: 1.710295327939093e-05 \n",
      "epoch: 10 [262196/888800 29.50%] train loss: 1.7244297850993462e-05 \n",
      "epoch: 10 [263307/888800 29.62%] train loss: 1.5534122212557122e-05 \n",
      "epoch: 10 [264418/888800 29.75%] train loss: 1.876696478575468e-05 \n",
      "epoch: 10 [265529/888800 29.88%] train loss: 1.895398600026965e-05 \n",
      "epoch: 10 [266640/888800 30.00%] train loss: 1.701749897620175e-05 \n",
      "epoch: 10 [267751/888800 30.12%] train loss: 1.707473347778432e-05 \n",
      "epoch: 10 [268862/888800 30.25%] train loss: 1.83514530363027e-05 \n",
      "epoch: 10 [269973/888800 30.38%] train loss: 1.7483862393419258e-05 \n",
      "epoch: 10 [271084/888800 30.50%] train loss: 1.5915466065052897e-05 \n",
      "epoch: 10 [272195/888800 30.62%] train loss: 1.601051917532459e-05 \n",
      "epoch: 10 [273306/888800 30.75%] train loss: 1.8908920537796803e-05 \n",
      "epoch: 10 [274417/888800 30.88%] train loss: 1.7389480490237474e-05 \n",
      "epoch: 10 [275528/888800 31.00%] train loss: 1.79159760591574e-05 \n",
      "epoch: 10 [276639/888800 31.12%] train loss: 1.8517344869906083e-05 \n",
      "epoch: 10 [277750/888800 31.25%] train loss: 1.8394555809209123e-05 \n",
      "epoch: 10 [278861/888800 31.38%] train loss: 1.6585003322688863e-05 \n",
      "epoch: 10 [279972/888800 31.50%] train loss: 1.6629384845145978e-05 \n",
      "epoch: 10 [281083/888800 31.62%] train loss: 1.9124900063616224e-05 \n",
      "epoch: 10 [282194/888800 31.75%] train loss: 2.0543047867249697e-05 \n",
      "epoch: 10 [283305/888800 31.88%] train loss: 1.9217126464354806e-05 \n",
      "epoch: 10 [284416/888800 32.00%] train loss: 1.6415338905062526e-05 \n",
      "epoch: 10 [285527/888800 32.12%] train loss: 1.7690632375888526e-05 \n",
      "epoch: 10 [286638/888800 32.25%] train loss: 1.726322079775855e-05 \n",
      "epoch: 10 [287749/888800 32.38%] train loss: 1.8492570234229788e-05 \n",
      "epoch: 10 [288860/888800 32.50%] train loss: 1.8820226614479907e-05 \n",
      "epoch: 10 [289971/888800 32.62%] train loss: 1.5732277461211197e-05 \n",
      "epoch: 10 [291082/888800 32.75%] train loss: 1.754818731569685e-05 \n",
      "epoch: 10 [292193/888800 32.88%] train loss: 1.7351272617815994e-05 \n",
      "epoch: 10 [293304/888800 33.00%] train loss: 1.8298649592907168e-05 \n",
      "epoch: 10 [294415/888800 33.12%] train loss: 1.8264576283399947e-05 \n",
      "epoch: 10 [295526/888800 33.25%] train loss: 1.690813405730296e-05 \n",
      "epoch: 10 [296637/888800 33.38%] train loss: 1.8125043425243348e-05 \n",
      "epoch: 10 [297748/888800 33.50%] train loss: 1.704792884993367e-05 \n",
      "epoch: 10 [298859/888800 33.62%] train loss: 1.828604581533e-05 \n",
      "epoch: 10 [299970/888800 33.75%] train loss: 1.6648606106173247e-05 \n",
      "epoch: 10 [301081/888800 33.88%] train loss: 1.8480881408322603e-05 \n",
      "epoch: 10 [302192/888800 34.00%] train loss: 2.079914884234313e-05 \n",
      "epoch: 10 [303303/888800 34.12%] train loss: 1.8899041606346145e-05 \n",
      "epoch: 10 [304414/888800 34.25%] train loss: 1.8075441403198056e-05 \n",
      "epoch: 10 [305525/888800 34.38%] train loss: 1.599079041625373e-05 \n",
      "epoch: 10 [306636/888800 34.50%] train loss: 1.8270664440933615e-05 \n",
      "epoch: 10 [307747/888800 34.62%] train loss: 1.7756878150976263e-05 \n",
      "epoch: 10 [308858/888800 34.75%] train loss: 1.7937098164111376e-05 \n",
      "epoch: 10 [309969/888800 34.88%] train loss: 1.7639855286688544e-05 \n",
      "epoch: 10 [311080/888800 35.00%] train loss: 1.799459096218925e-05 \n",
      "epoch: 10 [312191/888800 35.12%] train loss: 1.6711072021280415e-05 \n",
      "epoch: 10 [313302/888800 35.25%] train loss: 1.7975966329686344e-05 \n",
      "epoch: 10 [314413/888800 35.38%] train loss: 1.9579141735448502e-05 \n",
      "epoch: 10 [315524/888800 35.50%] train loss: 1.7101205230574124e-05 \n",
      "epoch: 10 [316635/888800 35.62%] train loss: 1.6713520381017588e-05 \n",
      "epoch: 10 [317746/888800 35.75%] train loss: 1.6574011169723235e-05 \n",
      "epoch: 10 [318857/888800 35.88%] train loss: 1.8850056221708655e-05 \n",
      "epoch: 10 [319968/888800 36.00%] train loss: 1.6768926798249595e-05 \n",
      "epoch: 10 [321079/888800 36.12%] train loss: 1.732910459395498e-05 \n",
      "epoch: 10 [322190/888800 36.25%] train loss: 1.6800362573121674e-05 \n",
      "epoch: 10 [323301/888800 36.38%] train loss: 1.5674026144552045e-05 \n",
      "epoch: 10 [324412/888800 36.50%] train loss: 1.7263078916585073e-05 \n",
      "epoch: 10 [325523/888800 36.62%] train loss: 1.8192391507909633e-05 \n",
      "epoch: 10 [326634/888800 36.75%] train loss: 1.3833038792654406e-05 \n",
      "epoch: 10 [327745/888800 36.88%] train loss: 1.6455629520351067e-05 \n",
      "epoch: 10 [328856/888800 37.00%] train loss: 1.7404665413778275e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [329967/888800 37.12%] train loss: 1.7552811186760664e-05 \n",
      "epoch: 10 [331078/888800 37.25%] train loss: 1.8049164282274432e-05 \n",
      "epoch: 10 [332189/888800 37.38%] train loss: 1.648217767069582e-05 \n",
      "epoch: 10 [333300/888800 37.50%] train loss: 1.7650290828896686e-05 \n",
      "epoch: 10 [334411/888800 37.62%] train loss: 1.5235731552820653e-05 \n",
      "epoch: 10 [335522/888800 37.75%] train loss: 1.864392834249884e-05 \n",
      "epoch: 10 [336633/888800 37.88%] train loss: 1.5748317309771664e-05 \n",
      "epoch: 10 [337744/888800 38.00%] train loss: 1.9117078409180976e-05 \n",
      "epoch: 10 [338855/888800 38.12%] train loss: 1.6932708604144864e-05 \n",
      "epoch: 10 [339966/888800 38.25%] train loss: 1.6518668417120352e-05 \n",
      "epoch: 10 [341077/888800 38.38%] train loss: 1.7257329091080464e-05 \n",
      "epoch: 10 [342188/888800 38.50%] train loss: 1.589780003996566e-05 \n",
      "epoch: 10 [343299/888800 38.62%] train loss: 1.6378362488467246e-05 \n",
      "epoch: 10 [344410/888800 38.75%] train loss: 1.7398813724867068e-05 \n",
      "epoch: 10 [345521/888800 38.88%] train loss: 1.6184199921553954e-05 \n",
      "epoch: 10 [346632/888800 39.00%] train loss: 1.7427981219952926e-05 \n",
      "epoch: 10 [347743/888800 39.12%] train loss: 1.7631642549531534e-05 \n",
      "epoch: 10 [348854/888800 39.25%] train loss: 1.5920892110443674e-05 \n",
      "epoch: 10 [349965/888800 39.38%] train loss: 1.824896753532812e-05 \n",
      "epoch: 10 [351076/888800 39.50%] train loss: 1.6957379557425156e-05 \n",
      "epoch: 10 [352187/888800 39.62%] train loss: 1.711602453724481e-05 \n",
      "epoch: 10 [353298/888800 39.75%] train loss: 1.6505757230333984e-05 \n",
      "epoch: 10 [354409/888800 39.88%] train loss: 1.594581590325106e-05 \n",
      "epoch: 10 [355520/888800 40.00%] train loss: 1.4343512702907901e-05 \n",
      "epoch: 10 [356631/888800 40.12%] train loss: 1.5850755517021753e-05 \n",
      "epoch: 10 [357742/888800 40.25%] train loss: 1.8783199266181327e-05 \n",
      "epoch: 10 [358853/888800 40.38%] train loss: 1.8650169295142405e-05 \n",
      "epoch: 10 [359964/888800 40.50%] train loss: 1.5087124666024465e-05 \n",
      "epoch: 10 [361075/888800 40.62%] train loss: 1.6306034012814052e-05 \n",
      "epoch: 10 [362186/888800 40.75%] train loss: 1.847885869210586e-05 \n",
      "epoch: 10 [363297/888800 40.88%] train loss: 1.926112236105837e-05 \n",
      "epoch: 10 [364408/888800 41.00%] train loss: 1.7087058949982747e-05 \n",
      "epoch: 10 [365519/888800 41.12%] train loss: 1.714666905172635e-05 \n",
      "epoch: 10 [366630/888800 41.25%] train loss: 1.7254586055059917e-05 \n",
      "epoch: 10 [367741/888800 41.38%] train loss: 1.851815977715887e-05 \n",
      "epoch: 10 [368852/888800 41.50%] train loss: 1.9558801795938052e-05 \n",
      "epoch: 10 [369963/888800 41.62%] train loss: 1.6162690371857025e-05 \n",
      "epoch: 10 [371074/888800 41.75%] train loss: 1.75495461007813e-05 \n",
      "epoch: 10 [372185/888800 41.88%] train loss: 1.5811303455848247e-05 \n",
      "epoch: 10 [373296/888800 42.00%] train loss: 1.6245916413026862e-05 \n",
      "epoch: 10 [374407/888800 42.12%] train loss: 1.637451168789994e-05 \n",
      "epoch: 10 [375518/888800 42.25%] train loss: 1.6882378986338153e-05 \n",
      "epoch: 10 [376629/888800 42.38%] train loss: 1.839403557823971e-05 \n",
      "epoch: 10 [377740/888800 42.50%] train loss: 1.7910477254190482e-05 \n",
      "epoch: 10 [378851/888800 42.62%] train loss: 1.8733988326857798e-05 \n",
      "epoch: 10 [379962/888800 42.75%] train loss: 1.9144184989272617e-05 \n",
      "epoch: 10 [381073/888800 42.88%] train loss: 1.6007830708986148e-05 \n",
      "epoch: 10 [382184/888800 43.00%] train loss: 1.782000981620513e-05 \n",
      "epoch: 10 [383295/888800 43.12%] train loss: 1.863540273916442e-05 \n",
      "epoch: 10 [384406/888800 43.25%] train loss: 1.6968489944702014e-05 \n",
      "epoch: 10 [385517/888800 43.38%] train loss: 1.8801578335114755e-05 \n",
      "epoch: 10 [386628/888800 43.50%] train loss: 1.6230744222411886e-05 \n",
      "epoch: 10 [387739/888800 43.62%] train loss: 1.6604102711426094e-05 \n",
      "epoch: 10 [388850/888800 43.75%] train loss: 1.8302815078641288e-05 \n",
      "epoch: 10 [389961/888800 43.88%] train loss: 1.873587643785868e-05 \n",
      "epoch: 10 [391072/888800 44.00%] train loss: 1.8537179130362347e-05 \n",
      "epoch: 10 [392183/888800 44.12%] train loss: 1.4819265743426513e-05 \n",
      "epoch: 10 [393294/888800 44.25%] train loss: 1.6657952073728666e-05 \n",
      "epoch: 10 [394405/888800 44.38%] train loss: 1.5803057976881973e-05 \n",
      "epoch: 10 [395516/888800 44.50%] train loss: 1.6542291632504202e-05 \n",
      "epoch: 10 [396627/888800 44.62%] train loss: 1.604991666681599e-05 \n",
      "epoch: 10 [397738/888800 44.75%] train loss: 1.632239764148835e-05 \n",
      "epoch: 10 [398849/888800 44.88%] train loss: 1.8846747479983605e-05 \n",
      "epoch: 10 [399960/888800 45.00%] train loss: 1.8899714632425457e-05 \n",
      "epoch: 10 [401071/888800 45.12%] train loss: 1.618108399270568e-05 \n",
      "epoch: 10 [402182/888800 45.25%] train loss: 1.701852488622535e-05 \n",
      "epoch: 10 [403293/888800 45.38%] train loss: 1.8869512132368982e-05 \n",
      "epoch: 10 [404404/888800 45.50%] train loss: 1.5858417100389488e-05 \n",
      "epoch: 10 [405515/888800 45.62%] train loss: 1.639192851143889e-05 \n",
      "epoch: 10 [406626/888800 45.75%] train loss: 1.6171801689779386e-05 \n",
      "epoch: 10 [407737/888800 45.88%] train loss: 1.6215775758610107e-05 \n",
      "epoch: 10 [408848/888800 46.00%] train loss: 1.7391834262525663e-05 \n",
      "epoch: 10 [409959/888800 46.12%] train loss: 1.9582283130148426e-05 \n",
      "epoch: 10 [411070/888800 46.25%] train loss: 1.6486570530105382e-05 \n",
      "epoch: 10 [412181/888800 46.38%] train loss: 1.9805171177722514e-05 \n",
      "epoch: 10 [413292/888800 46.50%] train loss: 1.8327888028579764e-05 \n",
      "epoch: 10 [414403/888800 46.62%] train loss: 1.7384705643053167e-05 \n",
      "epoch: 10 [415514/888800 46.75%] train loss: 1.4993267541285604e-05 \n",
      "epoch: 10 [416625/888800 46.88%] train loss: 1.7309655959252268e-05 \n",
      "epoch: 10 [417736/888800 47.00%] train loss: 1.7342499631922692e-05 \n",
      "epoch: 10 [418847/888800 47.12%] train loss: 1.725840957078617e-05 \n",
      "epoch: 10 [419958/888800 47.25%] train loss: 1.7721287804306485e-05 \n",
      "epoch: 10 [421069/888800 47.38%] train loss: 1.7017164282151498e-05 \n",
      "epoch: 10 [422180/888800 47.50%] train loss: 1.8908373021986336e-05 \n",
      "epoch: 10 [423291/888800 47.62%] train loss: 1.638313551666215e-05 \n",
      "epoch: 10 [424402/888800 47.75%] train loss: 1.5912888557068072e-05 \n",
      "epoch: 10 [425513/888800 47.88%] train loss: 1.667340984568e-05 \n",
      "epoch: 10 [426624/888800 48.00%] train loss: 1.6108897398225963e-05 \n",
      "epoch: 10 [427735/888800 48.12%] train loss: 1.6719606719561853e-05 \n",
      "epoch: 10 [428846/888800 48.25%] train loss: 2.0536494048428722e-05 \n",
      "epoch: 10 [429957/888800 48.38%] train loss: 1.6652524209348485e-05 \n",
      "epoch: 10 [431068/888800 48.50%] train loss: 1.774630982254166e-05 \n",
      "epoch: 10 [432179/888800 48.62%] train loss: 1.7970498447539285e-05 \n",
      "epoch: 10 [433290/888800 48.75%] train loss: 1.6392710676882416e-05 \n",
      "epoch: 10 [434401/888800 48.88%] train loss: 1.7023581676767208e-05 \n",
      "epoch: 10 [435512/888800 49.00%] train loss: 1.705876456981059e-05 \n",
      "epoch: 10 [436623/888800 49.12%] train loss: 1.6454790966236033e-05 \n",
      "epoch: 10 [437734/888800 49.25%] train loss: 1.5062401871546172e-05 \n",
      "epoch: 10 [438845/888800 49.38%] train loss: 1.3770812984148506e-05 \n",
      "epoch: 10 [439956/888800 49.50%] train loss: 1.9290420823381282e-05 \n",
      "epoch: 10 [441067/888800 49.62%] train loss: 1.7585591194801964e-05 \n",
      "epoch: 10 [442178/888800 49.75%] train loss: 1.7764459698810242e-05 \n",
      "epoch: 10 [443289/888800 49.88%] train loss: 1.7295469660894014e-05 \n",
      "epoch: 10 [444400/888800 50.00%] train loss: 1.5859081031521782e-05 \n",
      "epoch: 10 [445511/888800 50.12%] train loss: 1.9434786736383103e-05 \n",
      "epoch: 10 [446622/888800 50.25%] train loss: 1.647386852710042e-05 \n",
      "epoch: 10 [447733/888800 50.38%] train loss: 1.7981014025281183e-05 \n",
      "epoch: 10 [448844/888800 50.50%] train loss: 1.6917230823310092e-05 \n",
      "epoch: 10 [449955/888800 50.62%] train loss: 1.648148645472247e-05 \n",
      "epoch: 10 [451066/888800 50.75%] train loss: 1.5776471627759747e-05 \n",
      "epoch: 10 [452177/888800 50.88%] train loss: 1.5933435861370526e-05 \n",
      "epoch: 10 [453288/888800 51.00%] train loss: 1.7212067177752033e-05 \n",
      "epoch: 10 [454399/888800 51.12%] train loss: 1.673692895565182e-05 \n",
      "epoch: 10 [455510/888800 51.25%] train loss: 1.602933116373606e-05 \n",
      "epoch: 10 [456621/888800 51.38%] train loss: 1.7798622138798237e-05 \n",
      "epoch: 10 [457732/888800 51.50%] train loss: 1.9072960640187375e-05 \n",
      "epoch: 10 [458843/888800 51.62%] train loss: 1.5284153050743043e-05 \n",
      "epoch: 10 [459954/888800 51.75%] train loss: 1.6714777302695438e-05 \n",
      "epoch: 10 [461065/888800 51.88%] train loss: 1.7184254829771817e-05 \n",
      "epoch: 10 [462176/888800 52.00%] train loss: 1.4928945347492117e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [463287/888800 52.12%] train loss: 1.899207018141169e-05 \n",
      "epoch: 10 [464398/888800 52.25%] train loss: 1.4453684343607165e-05 \n",
      "epoch: 10 [465509/888800 52.38%] train loss: 1.7058073353837244e-05 \n",
      "epoch: 10 [466620/888800 52.50%] train loss: 1.654688639973756e-05 \n",
      "epoch: 10 [467731/888800 52.62%] train loss: 1.657893335504923e-05 \n",
      "epoch: 10 [468842/888800 52.75%] train loss: 1.6720459825592116e-05 \n",
      "epoch: 10 [469953/888800 52.88%] train loss: 1.6732985386624932e-05 \n",
      "epoch: 10 [471064/888800 53.00%] train loss: 1.5642990547348745e-05 \n",
      "epoch: 10 [472175/888800 53.12%] train loss: 1.6075220628408715e-05 \n",
      "epoch: 10 [473286/888800 53.25%] train loss: 1.5439927665283903e-05 \n",
      "epoch: 10 [474397/888800 53.38%] train loss: 1.6649846656946465e-05 \n",
      "epoch: 10 [475508/888800 53.50%] train loss: 1.8054352040053345e-05 \n",
      "epoch: 10 [476619/888800 53.62%] train loss: 1.5046786757011432e-05 \n",
      "epoch: 10 [477730/888800 53.75%] train loss: 1.6320922441082075e-05 \n",
      "epoch: 10 [478841/888800 53.88%] train loss: 1.6741272702347487e-05 \n",
      "epoch: 10 [479952/888800 54.00%] train loss: 1.644018993829377e-05 \n",
      "epoch: 10 [481063/888800 54.12%] train loss: 1.670729943725746e-05 \n",
      "epoch: 10 [482174/888800 54.25%] train loss: 1.8203894796897657e-05 \n",
      "epoch: 10 [483285/888800 54.38%] train loss: 1.6595937267993577e-05 \n",
      "epoch: 10 [484396/888800 54.50%] train loss: 1.7503329218016006e-05 \n",
      "epoch: 10 [485507/888800 54.62%] train loss: 1.6968053387245163e-05 \n",
      "epoch: 10 [486618/888800 54.75%] train loss: 1.672947473707609e-05 \n",
      "epoch: 10 [487729/888800 54.88%] train loss: 1.7298958482570015e-05 \n",
      "epoch: 10 [488840/888800 55.00%] train loss: 1.890287057904061e-05 \n",
      "epoch: 10 [489951/888800 55.12%] train loss: 1.6718013284844346e-05 \n",
      "epoch: 10 [491062/888800 55.25%] train loss: 1.7537437088321894e-05 \n",
      "epoch: 10 [492173/888800 55.38%] train loss: 1.6836171198519878e-05 \n",
      "epoch: 10 [493284/888800 55.50%] train loss: 1.6378618965973146e-05 \n",
      "epoch: 10 [494395/888800 55.62%] train loss: 1.5827681636437774e-05 \n",
      "epoch: 10 [495506/888800 55.75%] train loss: 1.795363459677901e-05 \n",
      "epoch: 10 [496617/888800 55.88%] train loss: 1.5980902389856055e-05 \n",
      "epoch: 10 [497728/888800 56.00%] train loss: 1.6219442841247655e-05 \n",
      "epoch: 10 [498839/888800 56.12%] train loss: 1.8250571883982047e-05 \n",
      "epoch: 10 [499950/888800 56.25%] train loss: 1.5108663319551852e-05 \n",
      "epoch: 10 [501061/888800 56.38%] train loss: 1.4356151041283738e-05 \n",
      "epoch: 10 [502172/888800 56.50%] train loss: 1.782750587153714e-05 \n",
      "epoch: 10 [503283/888800 56.62%] train loss: 1.4886909411870874e-05 \n",
      "epoch: 10 [504394/888800 56.75%] train loss: 1.531033376522828e-05 \n",
      "epoch: 10 [505505/888800 56.88%] train loss: 1.7195961845573038e-05 \n",
      "epoch: 10 [506616/888800 57.00%] train loss: 1.467701713409042e-05 \n",
      "epoch: 10 [507727/888800 57.12%] train loss: 1.9496910681482404e-05 \n",
      "epoch: 10 [508838/888800 57.25%] train loss: 1.6971394870779477e-05 \n",
      "epoch: 10 [509949/888800 57.38%] train loss: 1.662697468418628e-05 \n",
      "epoch: 10 [511060/888800 57.50%] train loss: 1.632625571801327e-05 \n",
      "epoch: 10 [512171/888800 57.62%] train loss: 1.8553841073298827e-05 \n",
      "epoch: 10 [513282/888800 57.75%] train loss: 1.560383680043742e-05 \n",
      "epoch: 10 [514393/888800 57.88%] train loss: 1.6990543372230604e-05 \n",
      "epoch: 10 [515504/888800 58.00%] train loss: 1.8949449440697208e-05 \n",
      "epoch: 10 [516615/888800 58.12%] train loss: 1.7700651369523257e-05 \n",
      "epoch: 10 [517726/888800 58.25%] train loss: 1.6464191503473558e-05 \n",
      "epoch: 10 [518837/888800 58.38%] train loss: 1.6496924217790365e-05 \n",
      "epoch: 10 [519948/888800 58.50%] train loss: 1.5938827345962636e-05 \n",
      "epoch: 10 [521059/888800 58.62%] train loss: 1.7114236470661126e-05 \n",
      "epoch: 10 [522170/888800 58.75%] train loss: 1.5414945664815605e-05 \n",
      "epoch: 10 [523281/888800 58.88%] train loss: 1.8116747014573775e-05 \n",
      "epoch: 10 [524392/888800 59.00%] train loss: 1.6502464859513566e-05 \n",
      "epoch: 10 [525503/888800 59.12%] train loss: 1.7052692783181556e-05 \n",
      "epoch: 10 [526614/888800 59.25%] train loss: 1.8611275663715787e-05 \n",
      "epoch: 10 [527725/888800 59.38%] train loss: 1.669772063905839e-05 \n",
      "epoch: 10 [528836/888800 59.50%] train loss: 1.6792371752671897e-05 \n",
      "epoch: 10 [529947/888800 59.62%] train loss: 1.6804055121610872e-05 \n",
      "epoch: 10 [531058/888800 59.75%] train loss: 1.5798455933691002e-05 \n",
      "epoch: 10 [532169/888800 59.88%] train loss: 1.7641010344959795e-05 \n",
      "epoch: 10 [533280/888800 60.00%] train loss: 1.7141424905275926e-05 \n",
      "epoch: 10 [534391/888800 60.12%] train loss: 1.5570372852380387e-05 \n",
      "epoch: 10 [535502/888800 60.25%] train loss: 1.6966387192951515e-05 \n",
      "epoch: 10 [536613/888800 60.38%] train loss: 1.7744645447237417e-05 \n",
      "epoch: 10 [537724/888800 60.50%] train loss: 1.7345877495245077e-05 \n",
      "epoch: 10 [538835/888800 60.62%] train loss: 1.4223161997506395e-05 \n",
      "epoch: 10 [539946/888800 60.75%] train loss: 1.6259722542599775e-05 \n",
      "epoch: 10 [541057/888800 60.88%] train loss: 1.7993772416957654e-05 \n",
      "epoch: 10 [542168/888800 61.00%] train loss: 1.5355430150520988e-05 \n",
      "epoch: 10 [543279/888800 61.12%] train loss: 1.5628802430001087e-05 \n",
      "epoch: 10 [544390/888800 61.25%] train loss: 1.6641612091916613e-05 \n",
      "epoch: 10 [545501/888800 61.38%] train loss: 1.665720446908381e-05 \n",
      "epoch: 10 [546612/888800 61.50%] train loss: 1.6250236512860283e-05 \n",
      "epoch: 10 [547723/888800 61.62%] train loss: 1.7994603695115075e-05 \n",
      "epoch: 10 [548834/888800 61.75%] train loss: 1.7445792764192447e-05 \n",
      "epoch: 10 [549945/888800 61.88%] train loss: 1.60754188982537e-05 \n",
      "epoch: 10 [551056/888800 62.00%] train loss: 1.6651370970066637e-05 \n",
      "epoch: 10 [552167/888800 62.12%] train loss: 1.5599222024320625e-05 \n",
      "epoch: 10 [553278/888800 62.25%] train loss: 1.5048885870783124e-05 \n",
      "epoch: 10 [554389/888800 62.38%] train loss: 1.5597248420817778e-05 \n",
      "epoch: 10 [555500/888800 62.50%] train loss: 1.954457547981292e-05 \n",
      "epoch: 10 [556611/888800 62.62%] train loss: 1.605906982149463e-05 \n",
      "epoch: 10 [557722/888800 62.75%] train loss: 1.7008533177431673e-05 \n",
      "epoch: 10 [558833/888800 62.88%] train loss: 1.744498877087608e-05 \n",
      "epoch: 10 [559944/888800 63.00%] train loss: 1.6824495105538517e-05 \n",
      "epoch: 10 [561055/888800 63.12%] train loss: 1.5808245734660886e-05 \n",
      "epoch: 10 [562166/888800 63.25%] train loss: 1.4293753338279203e-05 \n",
      "epoch: 10 [563277/888800 63.38%] train loss: 1.4610654034186155e-05 \n",
      "epoch: 10 [564388/888800 63.50%] train loss: 1.845347651396878e-05 \n",
      "epoch: 10 [565499/888800 63.62%] train loss: 1.474040254834108e-05 \n",
      "epoch: 10 [566610/888800 63.75%] train loss: 1.7220354493474588e-05 \n",
      "epoch: 10 [567721/888800 63.88%] train loss: 1.6788220818853006e-05 \n",
      "epoch: 10 [568832/888800 64.00%] train loss: 1.6196630895137787e-05 \n",
      "epoch: 10 [569943/888800 64.12%] train loss: 1.7916943761520088e-05 \n",
      "epoch: 10 [571054/888800 64.25%] train loss: 1.6825459169922397e-05 \n",
      "epoch: 10 [572165/888800 64.38%] train loss: 1.751411946315784e-05 \n",
      "epoch: 10 [573276/888800 64.50%] train loss: 1.7159482013084926e-05 \n",
      "epoch: 10 [574387/888800 64.62%] train loss: 1.8035923858406022e-05 \n",
      "epoch: 10 [575498/888800 64.75%] train loss: 1.638421781535726e-05 \n",
      "epoch: 10 [576609/888800 64.88%] train loss: 1.6188134395633824e-05 \n",
      "epoch: 10 [577720/888800 65.00%] train loss: 1.6294981833198108e-05 \n",
      "epoch: 10 [578831/888800 65.12%] train loss: 1.5951927707646973e-05 \n",
      "epoch: 10 [579942/888800 65.25%] train loss: 1.5922605598461814e-05 \n",
      "epoch: 10 [581053/888800 65.38%] train loss: 1.7263890185859054e-05 \n",
      "epoch: 10 [582164/888800 65.50%] train loss: 1.5764117051730864e-05 \n",
      "epoch: 10 [583275/888800 65.62%] train loss: 1.717720260785427e-05 \n",
      "epoch: 10 [584386/888800 65.75%] train loss: 1.8494471078156494e-05 \n",
      "epoch: 10 [585497/888800 65.88%] train loss: 1.720178079267498e-05 \n",
      "epoch: 10 [586608/888800 66.00%] train loss: 1.6348576536984183e-05 \n",
      "epoch: 10 [587719/888800 66.12%] train loss: 1.8436525351717137e-05 \n",
      "epoch: 10 [588830/888800 66.25%] train loss: 1.6855345165822655e-05 \n",
      "epoch: 10 [589941/888800 66.38%] train loss: 1.581801006977912e-05 \n",
      "epoch: 10 [591052/888800 66.50%] train loss: 1.5546420399914496e-05 \n",
      "epoch: 10 [592163/888800 66.62%] train loss: 1.5623856597812846e-05 \n",
      "epoch: 10 [593274/888800 66.75%] train loss: 1.477576279285131e-05 \n",
      "epoch: 10 [594385/888800 66.88%] train loss: 1.4688731425849255e-05 \n",
      "epoch: 10 [595496/888800 67.00%] train loss: 1.5873876691330224e-05 \n",
      "epoch: 10 [596607/888800 67.12%] train loss: 1.5384801372420043e-05 \n",
      "epoch: 10 [597718/888800 67.25%] train loss: 1.822580634325277e-05 \n",
      "epoch: 10 [598829/888800 67.38%] train loss: 1.7140609998023137e-05 \n",
      "epoch: 10 [599940/888800 67.50%] train loss: 1.6578986105741933e-05 \n",
      "epoch: 10 [601051/888800 67.62%] train loss: 1.4999968698248267e-05 \n",
      "epoch: 10 [602162/888800 67.75%] train loss: 1.8594793800730258e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [603273/888800 67.88%] train loss: 1.8016691683442332e-05 \n",
      "epoch: 10 [604384/888800 68.00%] train loss: 1.6729030903661624e-05 \n",
      "epoch: 10 [605495/888800 68.12%] train loss: 1.7561249478603713e-05 \n",
      "epoch: 10 [606606/888800 68.25%] train loss: 1.639376932871528e-05 \n",
      "epoch: 10 [607717/888800 68.38%] train loss: 1.667386641202029e-05 \n",
      "epoch: 10 [608828/888800 68.50%] train loss: 1.5323945262935013e-05 \n",
      "epoch: 10 [609939/888800 68.62%] train loss: 1.6672001947881654e-05 \n",
      "epoch: 10 [611050/888800 68.75%] train loss: 1.6004547433112748e-05 \n",
      "epoch: 10 [612161/888800 68.88%] train loss: 1.4806561011937447e-05 \n",
      "epoch: 10 [613272/888800 69.00%] train loss: 1.5913561583147384e-05 \n",
      "epoch: 10 [614383/888800 69.12%] train loss: 1.530795998405665e-05 \n",
      "epoch: 10 [615494/888800 69.25%] train loss: 1.5171437553362921e-05 \n",
      "epoch: 10 [616605/888800 69.38%] train loss: 1.6403155314037576e-05 \n",
      "epoch: 10 [617716/888800 69.50%] train loss: 1.6571080777794123e-05 \n",
      "epoch: 10 [618827/888800 69.62%] train loss: 1.6867830709088594e-05 \n",
      "epoch: 10 [619938/888800 69.75%] train loss: 1.628171776246745e-05 \n",
      "epoch: 10 [621049/888800 69.88%] train loss: 1.7601987565285526e-05 \n",
      "epoch: 10 [622160/888800 70.00%] train loss: 1.5602736311848275e-05 \n",
      "epoch: 10 [623271/888800 70.12%] train loss: 1.529378096165601e-05 \n",
      "epoch: 10 [624382/888800 70.25%] train loss: 1.6023486750782467e-05 \n",
      "epoch: 10 [625493/888800 70.38%] train loss: 1.682308538875077e-05 \n",
      "epoch: 10 [626604/888800 70.50%] train loss: 1.454818448110018e-05 \n",
      "epoch: 10 [627715/888800 70.62%] train loss: 1.725631591398269e-05 \n",
      "epoch: 10 [628826/888800 70.75%] train loss: 1.6467125533381477e-05 \n",
      "epoch: 10 [629937/888800 70.88%] train loss: 1.8212018403573893e-05 \n",
      "epoch: 10 [631048/888800 71.00%] train loss: 1.6909654732444324e-05 \n",
      "epoch: 10 [632159/888800 71.12%] train loss: 1.5377107047243044e-05 \n",
      "epoch: 10 [633270/888800 71.25%] train loss: 1.4387797818926629e-05 \n",
      "epoch: 10 [634381/888800 71.38%] train loss: 1.6712625438231044e-05 \n",
      "epoch: 10 [635492/888800 71.50%] train loss: 1.8348115190747194e-05 \n",
      "epoch: 10 [636603/888800 71.62%] train loss: 1.4373300473380368e-05 \n",
      "epoch: 10 [637714/888800 71.75%] train loss: 1.6745374523452483e-05 \n",
      "epoch: 10 [638825/888800 71.88%] train loss: 1.6107140254462138e-05 \n",
      "epoch: 10 [639936/888800 72.00%] train loss: 1.64131197379902e-05 \n",
      "epoch: 10 [641047/888800 72.12%] train loss: 1.6818834410514683e-05 \n",
      "epoch: 10 [642158/888800 72.25%] train loss: 1.7188845959026366e-05 \n",
      "epoch: 10 [643269/888800 72.38%] train loss: 1.577914008521475e-05 \n",
      "epoch: 10 [644380/888800 72.50%] train loss: 1.6404294001404196e-05 \n",
      "epoch: 10 [645491/888800 72.62%] train loss: 1.5530738892266527e-05 \n",
      "epoch: 10 [646602/888800 72.75%] train loss: 1.619194881641306e-05 \n",
      "epoch: 10 [647713/888800 72.88%] train loss: 1.629848156881053e-05 \n",
      "epoch: 10 [648824/888800 73.00%] train loss: 1.7407433915650472e-05 \n",
      "epoch: 10 [649935/888800 73.12%] train loss: 1.699998574622441e-05 \n",
      "epoch: 10 [651046/888800 73.25%] train loss: 1.633921783650294e-05 \n",
      "epoch: 10 [652157/888800 73.38%] train loss: 1.567239814903587e-05 \n",
      "epoch: 10 [653268/888800 73.50%] train loss: 1.4805021237407345e-05 \n",
      "epoch: 10 [654379/888800 73.62%] train loss: 1.621667070139665e-05 \n",
      "epoch: 10 [655490/888800 73.75%] train loss: 1.5667172192479484e-05 \n",
      "epoch: 10 [656601/888800 73.88%] train loss: 1.6022007912397385e-05 \n",
      "epoch: 10 [657712/888800 74.00%] train loss: 1.6039992260630243e-05 \n",
      "epoch: 10 [658823/888800 74.12%] train loss: 1.6337469787686132e-05 \n",
      "epoch: 10 [659934/888800 74.25%] train loss: 1.5319334124797024e-05 \n",
      "epoch: 10 [661045/888800 74.38%] train loss: 1.6725574823794886e-05 \n",
      "epoch: 10 [662156/888800 74.50%] train loss: 1.6486577806062996e-05 \n",
      "epoch: 10 [663267/888800 74.62%] train loss: 1.6268950275843963e-05 \n",
      "epoch: 10 [664378/888800 74.75%] train loss: 1.559631527925376e-05 \n",
      "epoch: 10 [665489/888800 74.88%] train loss: 1.55273392010713e-05 \n",
      "epoch: 10 [666600/888800 75.00%] train loss: 1.698480082268361e-05 \n",
      "epoch: 10 [667711/888800 75.12%] train loss: 1.636286106077023e-05 \n",
      "epoch: 10 [668822/888800 75.25%] train loss: 1.4981674212322105e-05 \n",
      "epoch: 10 [669933/888800 75.38%] train loss: 1.6374186088796705e-05 \n",
      "epoch: 10 [671044/888800 75.50%] train loss: 1.6583107935730368e-05 \n",
      "epoch: 10 [672155/888800 75.62%] train loss: 1.4914664461684879e-05 \n",
      "epoch: 10 [673266/888800 75.75%] train loss: 1.82811727427179e-05 \n",
      "epoch: 10 [674377/888800 75.88%] train loss: 1.8283446479472332e-05 \n",
      "epoch: 10 [675488/888800 76.00%] train loss: 1.5334944691858254e-05 \n",
      "epoch: 10 [676599/888800 76.12%] train loss: 1.7879492588690482e-05 \n",
      "epoch: 10 [677710/888800 76.25%] train loss: 1.764849730534479e-05 \n",
      "epoch: 10 [678821/888800 76.38%] train loss: 1.6264741134364158e-05 \n",
      "epoch: 10 [679932/888800 76.50%] train loss: 1.6541234799660742e-05 \n",
      "epoch: 10 [681043/888800 76.62%] train loss: 1.7310527255176567e-05 \n",
      "epoch: 10 [682154/888800 76.75%] train loss: 1.645901647862047e-05 \n",
      "epoch: 10 [683265/888800 76.88%] train loss: 1.7848118659458123e-05 \n",
      "epoch: 10 [684376/888800 77.00%] train loss: 1.6408896044595167e-05 \n",
      "epoch: 10 [685487/888800 77.12%] train loss: 1.5745521523058414e-05 \n",
      "epoch: 10 [686598/888800 77.25%] train loss: 1.6477173630846664e-05 \n",
      "epoch: 10 [687709/888800 77.38%] train loss: 1.5825780792511068e-05 \n",
      "epoch: 10 [688820/888800 77.50%] train loss: 1.504896590631688e-05 \n",
      "epoch: 10 [689931/888800 77.62%] train loss: 1.5512270692852326e-05 \n",
      "epoch: 10 [691042/888800 77.75%] train loss: 1.4948452189855743e-05 \n",
      "epoch: 10 [692153/888800 77.88%] train loss: 1.7073441995307803e-05 \n",
      "epoch: 10 [693264/888800 78.00%] train loss: 1.7030182789312676e-05 \n",
      "epoch: 10 [694375/888800 78.12%] train loss: 1.5923751561786048e-05 \n",
      "epoch: 10 [695486/888800 78.25%] train loss: 1.7084124920074828e-05 \n",
      "epoch: 10 [696597/888800 78.38%] train loss: 1.723854074953124e-05 \n",
      "epoch: 10 [697708/888800 78.50%] train loss: 1.414643156749662e-05 \n",
      "epoch: 10 [698819/888800 78.62%] train loss: 1.7369487977703102e-05 \n",
      "epoch: 10 [699930/888800 78.75%] train loss: 1.6688320101820864e-05 \n",
      "epoch: 10 [701041/888800 78.88%] train loss: 1.609912760613952e-05 \n",
      "epoch: 10 [702152/888800 79.00%] train loss: 1.7720185496727936e-05 \n",
      "epoch: 10 [703263/888800 79.12%] train loss: 1.6784661056590267e-05 \n",
      "epoch: 10 [704374/888800 79.25%] train loss: 1.8209926565759815e-05 \n",
      "epoch: 10 [705485/888800 79.38%] train loss: 1.871503991424106e-05 \n",
      "epoch: 10 [706596/888800 79.50%] train loss: 1.6871990737854503e-05 \n",
      "epoch: 10 [707707/888800 79.62%] train loss: 1.7040674720192328e-05 \n",
      "epoch: 10 [708818/888800 79.75%] train loss: 1.4889804333506618e-05 \n",
      "epoch: 10 [709929/888800 79.88%] train loss: 1.4817800547461957e-05 \n",
      "epoch: 10 [711040/888800 80.00%] train loss: 1.579899253556505e-05 \n",
      "epoch: 10 [712151/888800 80.12%] train loss: 1.6018975657061674e-05 \n",
      "epoch: 10 [713262/888800 80.25%] train loss: 1.7024251064867713e-05 \n",
      "epoch: 10 [714373/888800 80.38%] train loss: 1.5514051483478397e-05 \n",
      "epoch: 10 [715484/888800 80.50%] train loss: 1.89741713256808e-05 \n",
      "epoch: 10 [716595/888800 80.62%] train loss: 1.7337688404950313e-05 \n",
      "epoch: 10 [717706/888800 80.75%] train loss: 1.5835013982723467e-05 \n",
      "epoch: 10 [718817/888800 80.88%] train loss: 1.8018736227531917e-05 \n",
      "epoch: 10 [719928/888800 81.00%] train loss: 1.6535255781491287e-05 \n",
      "epoch: 10 [721039/888800 81.12%] train loss: 1.6122188753797673e-05 \n",
      "epoch: 10 [722150/888800 81.25%] train loss: 1.6850406609592028e-05 \n",
      "epoch: 10 [723261/888800 81.38%] train loss: 1.7458638467360288e-05 \n",
      "epoch: 10 [724372/888800 81.50%] train loss: 1.5829858966753818e-05 \n",
      "epoch: 10 [725483/888800 81.62%] train loss: 1.7371947251376696e-05 \n",
      "epoch: 10 [726594/888800 81.75%] train loss: 1.8190177797805518e-05 \n",
      "epoch: 10 [727705/888800 81.88%] train loss: 1.719649117148947e-05 \n",
      "epoch: 10 [728816/888800 82.00%] train loss: 1.6162306565092877e-05 \n",
      "epoch: 10 [729927/888800 82.12%] train loss: 1.5861713109188713e-05 \n",
      "epoch: 10 [731038/888800 82.25%] train loss: 1.795436764950864e-05 \n",
      "epoch: 10 [732149/888800 82.38%] train loss: 1.5723975593573414e-05 \n",
      "epoch: 10 [733260/888800 82.50%] train loss: 1.6207783119170927e-05 \n",
      "epoch: 10 [734371/888800 82.62%] train loss: 1.733177123242058e-05 \n",
      "epoch: 10 [735482/888800 82.75%] train loss: 1.4842859854979906e-05 \n",
      "epoch: 10 [736593/888800 82.88%] train loss: 1.85966109711444e-05 \n",
      "epoch: 10 [737704/888800 83.00%] train loss: 1.6757639969000593e-05 \n",
      "epoch: 10 [738815/888800 83.12%] train loss: 1.6680221960996278e-05 \n",
      "epoch: 10 [739926/888800 83.25%] train loss: 1.6785055777290836e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [741037/888800 83.38%] train loss: 1.5650199202354997e-05 \n",
      "epoch: 10 [742148/888800 83.50%] train loss: 1.5851828720769845e-05 \n",
      "epoch: 10 [743259/888800 83.62%] train loss: 1.6302530639222823e-05 \n",
      "epoch: 10 [744370/888800 83.75%] train loss: 1.604439239599742e-05 \n",
      "epoch: 10 [745481/888800 83.88%] train loss: 1.6011255866033025e-05 \n",
      "epoch: 10 [746592/888800 84.00%] train loss: 1.851582419476472e-05 \n",
      "epoch: 10 [747703/888800 84.12%] train loss: 1.4762817954760976e-05 \n",
      "epoch: 10 [748814/888800 84.25%] train loss: 1.6122487068059854e-05 \n",
      "epoch: 10 [749925/888800 84.38%] train loss: 1.5608944522682577e-05 \n",
      "epoch: 10 [751036/888800 84.50%] train loss: 1.7286236470681615e-05 \n",
      "epoch: 10 [752147/888800 84.62%] train loss: 1.62998512678314e-05 \n",
      "epoch: 10 [753258/888800 84.75%] train loss: 1.814545066736173e-05 \n",
      "epoch: 10 [754369/888800 84.88%] train loss: 1.657138273003511e-05 \n",
      "epoch: 10 [755480/888800 85.00%] train loss: 1.4386692782863975e-05 \n",
      "epoch: 10 [756591/888800 85.12%] train loss: 1.7364456653012894e-05 \n",
      "epoch: 10 [757702/888800 85.25%] train loss: 1.453444201615639e-05 \n",
      "epoch: 10 [758813/888800 85.38%] train loss: 1.6060384950833395e-05 \n",
      "epoch: 10 [759924/888800 85.50%] train loss: 1.524292747490108e-05 \n",
      "epoch: 10 [761035/888800 85.62%] train loss: 1.758086909831036e-05 \n",
      "epoch: 10 [762146/888800 85.75%] train loss: 1.4493599337583873e-05 \n",
      "epoch: 10 [763257/888800 85.88%] train loss: 1.5347246517194435e-05 \n",
      "epoch: 10 [764368/888800 86.00%] train loss: 1.5118764167709742e-05 \n",
      "epoch: 10 [765479/888800 86.12%] train loss: 1.592682565387804e-05 \n",
      "epoch: 10 [766590/888800 86.25%] train loss: 1.5588351743645035e-05 \n",
      "epoch: 10 [767701/888800 86.38%] train loss: 1.895782224892173e-05 \n",
      "epoch: 10 [768812/888800 86.50%] train loss: 1.577297371113673e-05 \n",
      "epoch: 10 [769923/888800 86.62%] train loss: 1.5977802831912413e-05 \n",
      "epoch: 10 [771034/888800 86.75%] train loss: 1.7304124412476085e-05 \n",
      "epoch: 10 [772145/888800 86.88%] train loss: 1.5561681721010245e-05 \n",
      "epoch: 10 [773256/888800 87.00%] train loss: 1.4849591025267728e-05 \n",
      "epoch: 10 [774367/888800 87.12%] train loss: 1.5850588169996627e-05 \n",
      "epoch: 10 [775478/888800 87.25%] train loss: 1.8901617295341566e-05 \n",
      "epoch: 10 [776589/888800 87.38%] train loss: 1.4251683751353994e-05 \n",
      "epoch: 10 [777700/888800 87.50%] train loss: 1.7339209080091678e-05 \n",
      "epoch: 10 [778811/888800 87.62%] train loss: 1.6574769688304514e-05 \n",
      "epoch: 10 [779922/888800 87.75%] train loss: 1.6921070709940977e-05 \n",
      "epoch: 10 [781033/888800 87.88%] train loss: 1.6380146917072125e-05 \n",
      "epoch: 10 [782144/888800 88.00%] train loss: 1.4159089005261194e-05 \n",
      "epoch: 10 [783255/888800 88.12%] train loss: 1.6931458958424628e-05 \n",
      "epoch: 10 [784366/888800 88.25%] train loss: 1.5590982002322562e-05 \n",
      "epoch: 10 [785477/888800 88.38%] train loss: 1.5189849364105612e-05 \n",
      "epoch: 10 [786588/888800 88.50%] train loss: 1.5112247638171539e-05 \n",
      "epoch: 10 [787699/888800 88.62%] train loss: 1.700226857792586e-05 \n",
      "epoch: 10 [788810/888800 88.75%] train loss: 1.579685340402648e-05 \n",
      "epoch: 10 [789921/888800 88.88%] train loss: 1.6508434782736003e-05 \n",
      "epoch: 10 [791032/888800 89.00%] train loss: 1.3904163097322453e-05 \n",
      "epoch: 10 [792143/888800 89.12%] train loss: 1.552726280351635e-05 \n",
      "epoch: 10 [793254/888800 89.25%] train loss: 1.638862340769265e-05 \n",
      "epoch: 10 [794365/888800 89.38%] train loss: 1.6354244507965632e-05 \n",
      "epoch: 10 [795476/888800 89.50%] train loss: 1.6390047676395625e-05 \n",
      "epoch: 10 [796587/888800 89.62%] train loss: 1.509589947090717e-05 \n",
      "epoch: 10 [797698/888800 89.75%] train loss: 1.781725586624816e-05 \n",
      "epoch: 10 [798809/888800 89.88%] train loss: 1.5409970728796907e-05 \n",
      "epoch: 10 [799920/888800 90.00%] train loss: 1.487398458266398e-05 \n",
      "epoch: 10 [801031/888800 90.12%] train loss: 1.603562486707233e-05 \n",
      "epoch: 10 [802142/888800 90.25%] train loss: 1.5856059690122493e-05 \n",
      "epoch: 10 [803253/888800 90.38%] train loss: 1.536904528620653e-05 \n",
      "epoch: 10 [804364/888800 90.50%] train loss: 1.603138298378326e-05 \n",
      "epoch: 10 [805475/888800 90.62%] train loss: 1.618363785382826e-05 \n",
      "epoch: 10 [806586/888800 90.75%] train loss: 1.554162190586794e-05 \n",
      "epoch: 10 [807697/888800 90.88%] train loss: 1.7307849702774547e-05 \n",
      "epoch: 10 [808808/888800 91.00%] train loss: 1.5090216038515791e-05 \n",
      "epoch: 10 [809919/888800 91.12%] train loss: 1.6604948541498743e-05 \n",
      "epoch: 10 [811030/888800 91.25%] train loss: 1.596097536094021e-05 \n",
      "epoch: 10 [812141/888800 91.38%] train loss: 1.5077725947776344e-05 \n",
      "epoch: 10 [813252/888800 91.50%] train loss: 1.7220563677255996e-05 \n",
      "epoch: 10 [814363/888800 91.62%] train loss: 1.74930664798012e-05 \n",
      "epoch: 10 [815474/888800 91.75%] train loss: 1.6043188225012273e-05 \n",
      "epoch: 10 [816585/888800 91.88%] train loss: 1.540588345960714e-05 \n",
      "epoch: 10 [817696/888800 92.00%] train loss: 1.5785490177222528e-05 \n",
      "epoch: 10 [818807/888800 92.12%] train loss: 1.7057478544302285e-05 \n",
      "epoch: 10 [819918/888800 92.25%] train loss: 1.7388090782333165e-05 \n",
      "epoch: 10 [821029/888800 92.38%] train loss: 1.656562199059408e-05 \n",
      "epoch: 10 [822140/888800 92.50%] train loss: 1.7209698853548616e-05 \n",
      "epoch: 10 [823251/888800 92.62%] train loss: 1.4660080523754004e-05 \n",
      "epoch: 10 [824362/888800 92.75%] train loss: 1.4883347830618732e-05 \n",
      "epoch: 10 [825473/888800 92.88%] train loss: 1.571703796798829e-05 \n",
      "epoch: 10 [826584/888800 93.00%] train loss: 1.7615966498851776e-05 \n",
      "epoch: 10 [827695/888800 93.12%] train loss: 1.5365427316282876e-05 \n",
      "epoch: 10 [828806/888800 93.25%] train loss: 1.4156945326249115e-05 \n",
      "epoch: 10 [829917/888800 93.38%] train loss: 1.6838141164043918e-05 \n",
      "epoch: 10 [831028/888800 93.50%] train loss: 1.6168829461093992e-05 \n",
      "epoch: 10 [832139/888800 93.62%] train loss: 1.4709978131577373e-05 \n",
      "epoch: 10 [833250/888800 93.75%] train loss: 1.6875337678357027e-05 \n",
      "epoch: 10 [834361/888800 93.88%] train loss: 1.5264839021256194e-05 \n",
      "epoch: 10 [835472/888800 94.00%] train loss: 1.593413071532268e-05 \n",
      "epoch: 10 [836583/888800 94.12%] train loss: 1.6412710465374403e-05 \n",
      "epoch: 10 [837694/888800 94.25%] train loss: 1.491541934228735e-05 \n",
      "epoch: 10 [838805/888800 94.38%] train loss: 1.7531030607642606e-05 \n",
      "epoch: 10 [839916/888800 94.50%] train loss: 1.5939112927298993e-05 \n",
      "epoch: 10 [841027/888800 94.62%] train loss: 1.6304345990647562e-05 \n",
      "epoch: 10 [842138/888800 94.75%] train loss: 1.646998498472385e-05 \n",
      "epoch: 10 [843249/888800 94.88%] train loss: 1.572287146700546e-05 \n",
      "epoch: 10 [844360/888800 95.00%] train loss: 1.711062759568449e-05 \n",
      "epoch: 10 [845471/888800 95.12%] train loss: 1.5168829122558236e-05 \n",
      "epoch: 10 [846582/888800 95.25%] train loss: 1.5391569831990637e-05 \n",
      "epoch: 10 [847693/888800 95.38%] train loss: 1.7366293832310475e-05 \n",
      "epoch: 10 [848804/888800 95.50%] train loss: 1.5573519704048522e-05 \n",
      "epoch: 10 [849915/888800 95.62%] train loss: 1.6032374333008192e-05 \n",
      "epoch: 10 [851026/888800 95.75%] train loss: 1.533355680294335e-05 \n",
      "epoch: 10 [852137/888800 95.88%] train loss: 1.4915382053004578e-05 \n",
      "epoch: 10 [853248/888800 96.00%] train loss: 1.788658664736431e-05 \n",
      "epoch: 10 [854359/888800 96.12%] train loss: 1.661855094425846e-05 \n",
      "epoch: 10 [855470/888800 96.25%] train loss: 1.8083288523484953e-05 \n",
      "epoch: 10 [856581/888800 96.38%] train loss: 1.5574598364764825e-05 \n",
      "epoch: 10 [857692/888800 96.50%] train loss: 1.6094509192043915e-05 \n",
      "epoch: 10 [858803/888800 96.62%] train loss: 1.5432633517775685e-05 \n",
      "epoch: 10 [859914/888800 96.75%] train loss: 1.637884088268038e-05 \n",
      "epoch: 10 [861025/888800 96.88%] train loss: 1.6693562429281883e-05 \n",
      "epoch: 10 [862136/888800 97.00%] train loss: 1.6709449482732452e-05 \n",
      "epoch: 10 [863247/888800 97.12%] train loss: 1.6792955648270436e-05 \n",
      "epoch: 10 [864358/888800 97.25%] train loss: 1.4450964954448864e-05 \n",
      "epoch: 10 [865469/888800 97.38%] train loss: 1.521885769761866e-05 \n",
      "epoch: 10 [866580/888800 97.50%] train loss: 1.5411707863677293e-05 \n",
      "epoch: 10 [867691/888800 97.62%] train loss: 1.6702631910447963e-05 \n",
      "epoch: 10 [868802/888800 97.75%] train loss: 1.638068351894617e-05 \n",
      "epoch: 10 [869913/888800 97.88%] train loss: 1.9089135093963705e-05 \n",
      "epoch: 10 [871024/888800 98.00%] train loss: 1.5689802239648998e-05 \n",
      "epoch: 10 [872135/888800 98.12%] train loss: 1.5145461475185584e-05 \n",
      "epoch: 10 [873246/888800 98.25%] train loss: 1.4488102351606358e-05 \n",
      "epoch: 10 [874357/888800 98.38%] train loss: 1.47314349305816e-05 \n",
      "epoch: 10 [875468/888800 98.50%] train loss: 1.637614332139492e-05 \n",
      "epoch: 10 [876579/888800 98.62%] train loss: 1.5246734619722702e-05 \n",
      "epoch: 10 [877690/888800 98.75%] train loss: 1.794783747754991e-05 \n",
      "epoch: 10 [878801/888800 98.88%] train loss: 1.582588447490707e-05 \n",
      "epoch: 10 [879912/888800 99.00%] train loss: 1.495038486609701e-05 \n",
      "epoch: 10 [881023/888800 99.12%] train loss: 1.6000969480955973e-05 \n",
      "epoch: 10 [882134/888800 99.25%] train loss: 1.7869249859359115e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 [883245/888800 99.38%] train loss: 1.7927817680174485e-05 \n",
      "epoch: 10 [884356/888800 99.50%] train loss: 1.8896587789640762e-05 \n",
      "epoch: 10 [885467/888800 99.62%] train loss: 1.739017534418963e-05 \n",
      "epoch: 10 [886578/888800 99.75%] train loss: 1.608155798749067e-05 \n",
      "epoch: 10 [887689/888800 99.88%] train loss: 1.4859335351502523e-05 \n",
      "epoch: 11 [0/888800 0.00%] train loss: 1.5598548998241313e-05 \n",
      "epoch: 11 [1111/888800 0.12%] train loss: 1.4949672731745522e-05 \n",
      "epoch: 11 [2222/888800 0.25%] train loss: 1.5330742826336063e-05 \n",
      "epoch: 11 [3333/888800 0.38%] train loss: 1.5763251212774776e-05 \n",
      "epoch: 11 [4444/888800 0.50%] train loss: 1.4649719560111407e-05 \n",
      "epoch: 11 [5555/888800 0.62%] train loss: 1.6074141967692412e-05 \n",
      "epoch: 11 [6666/888800 0.75%] train loss: 1.5784007700858638e-05 \n",
      "epoch: 11 [7777/888800 0.88%] train loss: 1.6289459381368943e-05 \n",
      "epoch: 11 [8888/888800 1.00%] train loss: 1.538950346002821e-05 \n",
      "epoch: 11 [9999/888800 1.12%] train loss: 1.5413883375003934e-05 \n",
      "epoch: 11 [11110/888800 1.25%] train loss: 1.7227910575456917e-05 \n",
      "epoch: 11 [12221/888800 1.38%] train loss: 1.689508462732192e-05 \n",
      "epoch: 11 [13332/888800 1.50%] train loss: 1.4085397197050042e-05 \n",
      "epoch: 11 [14443/888800 1.62%] train loss: 1.7154232409666292e-05 \n",
      "epoch: 11 [15554/888800 1.75%] train loss: 1.5824054571567103e-05 \n",
      "epoch: 11 [16665/888800 1.88%] train loss: 1.511684968136251e-05 \n",
      "epoch: 11 [17776/888800 2.00%] train loss: 1.56438909471035e-05 \n",
      "epoch: 11 [18887/888800 2.12%] train loss: 1.700551547401119e-05 \n",
      "epoch: 11 [19998/888800 2.25%] train loss: 1.5394996808026917e-05 \n",
      "epoch: 11 [21109/888800 2.38%] train loss: 1.5879262718954124e-05 \n",
      "epoch: 11 [22220/888800 2.50%] train loss: 1.7170663340948522e-05 \n",
      "epoch: 11 [23331/888800 2.62%] train loss: 1.65319797815755e-05 \n",
      "epoch: 11 [24442/888800 2.75%] train loss: 1.6356238120351918e-05 \n",
      "epoch: 11 [25553/888800 2.88%] train loss: 1.601491021574475e-05 \n",
      "epoch: 11 [26664/888800 3.00%] train loss: 1.3002012565266341e-05 \n",
      "epoch: 11 [27775/888800 3.12%] train loss: 1.732987402647268e-05 \n",
      "epoch: 11 [28886/888800 3.25%] train loss: 1.6050704289227724e-05 \n",
      "epoch: 11 [29997/888800 3.38%] train loss: 1.556393181090243e-05 \n",
      "epoch: 11 [31108/888800 3.50%] train loss: 1.5553467164863832e-05 \n",
      "epoch: 11 [32219/888800 3.62%] train loss: 1.7642349121160805e-05 \n",
      "epoch: 11 [33330/888800 3.75%] train loss: 1.567883555253502e-05 \n",
      "epoch: 11 [34441/888800 3.88%] train loss: 1.4305287550087087e-05 \n",
      "epoch: 11 [35552/888800 4.00%] train loss: 1.6989764844765887e-05 \n",
      "epoch: 11 [36663/888800 4.12%] train loss: 1.611643710930366e-05 \n",
      "epoch: 11 [37774/888800 4.25%] train loss: 1.6447493180749007e-05 \n",
      "epoch: 11 [38885/888800 4.38%] train loss: 1.4846434169157874e-05 \n",
      "epoch: 11 [39996/888800 4.50%] train loss: 1.5068399079609662e-05 \n",
      "epoch: 11 [41107/888800 4.62%] train loss: 1.5235277714964468e-05 \n",
      "epoch: 11 [42218/888800 4.75%] train loss: 1.5024252206785604e-05 \n",
      "epoch: 11 [43329/888800 4.88%] train loss: 1.6602340110694058e-05 \n",
      "epoch: 11 [44440/888800 5.00%] train loss: 1.410910135746235e-05 \n",
      "epoch: 11 [45551/888800 5.12%] train loss: 1.6592843167018145e-05 \n",
      "epoch: 11 [46662/888800 5.25%] train loss: 1.6394002159358934e-05 \n",
      "epoch: 11 [47773/888800 5.38%] train loss: 1.918887755891774e-05 \n",
      "epoch: 11 [48884/888800 5.50%] train loss: 1.770878952811472e-05 \n",
      "epoch: 11 [49995/888800 5.62%] train loss: 1.5034074749564752e-05 \n",
      "epoch: 11 [51106/888800 5.75%] train loss: 1.5936191630316898e-05 \n",
      "epoch: 11 [52217/888800 5.88%] train loss: 1.5216221981972922e-05 \n",
      "epoch: 11 [53328/888800 6.00%] train loss: 1.62463984452188e-05 \n",
      "epoch: 11 [54439/888800 6.12%] train loss: 1.6987147319014184e-05 \n",
      "epoch: 11 [55550/888800 6.25%] train loss: 1.5826384696993046e-05 \n",
      "epoch: 11 [56661/888800 6.38%] train loss: 1.6286068785120733e-05 \n",
      "epoch: 11 [57772/888800 6.50%] train loss: 1.5899653590167873e-05 \n",
      "epoch: 11 [58883/888800 6.62%] train loss: 1.551329296489712e-05 \n",
      "epoch: 11 [59994/888800 6.75%] train loss: 1.4682046639791224e-05 \n",
      "epoch: 11 [61105/888800 6.88%] train loss: 1.540081575512886e-05 \n",
      "epoch: 11 [62216/888800 7.00%] train loss: 1.4750755326531362e-05 \n",
      "epoch: 11 [63327/888800 7.12%] train loss: 1.597072150616441e-05 \n",
      "epoch: 11 [64438/888800 7.25%] train loss: 1.54516219481593e-05 \n",
      "epoch: 11 [65549/888800 7.38%] train loss: 1.3963112905912567e-05 \n",
      "epoch: 11 [66660/888800 7.50%] train loss: 1.446581882191822e-05 \n",
      "epoch: 11 [67771/888800 7.62%] train loss: 1.70954481291119e-05 \n",
      "epoch: 11 [68882/888800 7.75%] train loss: 1.515838630439248e-05 \n",
      "epoch: 11 [69993/888800 7.88%] train loss: 1.5616878954460844e-05 \n",
      "epoch: 11 [71104/888800 8.00%] train loss: 1.7994419977185316e-05 \n",
      "epoch: 11 [72215/888800 8.12%] train loss: 1.714594691293314e-05 \n",
      "epoch: 11 [73326/888800 8.25%] train loss: 1.532941314508207e-05 \n",
      "epoch: 11 [74437/888800 8.38%] train loss: 1.6093441445264034e-05 \n",
      "epoch: 11 [75548/888800 8.50%] train loss: 1.5046222870296333e-05 \n",
      "epoch: 11 [76659/888800 8.62%] train loss: 1.562430952617433e-05 \n",
      "epoch: 11 [77770/888800 8.75%] train loss: 1.5905250620562583e-05 \n",
      "epoch: 11 [78881/888800 8.88%] train loss: 1.5255724974849727e-05 \n",
      "epoch: 11 [79992/888800 9.00%] train loss: 1.5850355339352973e-05 \n",
      "epoch: 11 [81103/888800 9.12%] train loss: 1.564796366437804e-05 \n",
      "epoch: 11 [82214/888800 9.25%] train loss: 1.7583584849489853e-05 \n",
      "epoch: 11 [83325/888800 9.38%] train loss: 1.5139911738515366e-05 \n",
      "epoch: 11 [84436/888800 9.50%] train loss: 1.4272131011239253e-05 \n",
      "epoch: 11 [85547/888800 9.62%] train loss: 1.660666566749569e-05 \n",
      "epoch: 11 [86658/888800 9.75%] train loss: 1.5367093510576524e-05 \n",
      "epoch: 11 [87769/888800 9.88%] train loss: 1.5440655261045322e-05 \n",
      "epoch: 11 [88880/888800 10.00%] train loss: 1.5735060514998622e-05 \n",
      "epoch: 11 [89991/888800 10.12%] train loss: 1.722893830446992e-05 \n",
      "epoch: 11 [91102/888800 10.25%] train loss: 1.567039726069197e-05 \n",
      "epoch: 11 [92213/888800 10.38%] train loss: 1.3840533938491717e-05 \n",
      "epoch: 11 [93324/888800 10.50%] train loss: 1.6983945897663943e-05 \n",
      "epoch: 11 [94435/888800 10.62%] train loss: 1.57041667989688e-05 \n",
      "epoch: 11 [95546/888800 10.75%] train loss: 1.7190164726343937e-05 \n",
      "epoch: 11 [96657/888800 10.88%] train loss: 1.5535328202531673e-05 \n",
      "epoch: 11 [97768/888800 11.00%] train loss: 1.5160881048359443e-05 \n",
      "epoch: 11 [98879/888800 11.12%] train loss: 1.6347885321010835e-05 \n",
      "epoch: 11 [99990/888800 11.25%] train loss: 1.4463857041846495e-05 \n",
      "epoch: 11 [101101/888800 11.38%] train loss: 1.701149085420184e-05 \n",
      "epoch: 11 [102212/888800 11.50%] train loss: 1.5976660506566986e-05 \n",
      "epoch: 11 [103323/888800 11.62%] train loss: 1.4159724742057733e-05 \n",
      "epoch: 11 [104434/888800 11.75%] train loss: 1.5228380107146222e-05 \n",
      "epoch: 11 [105545/888800 11.88%] train loss: 1.5162543604674283e-05 \n",
      "epoch: 11 [106656/888800 12.00%] train loss: 1.3937637959315907e-05 \n",
      "epoch: 11 [107767/888800 12.12%] train loss: 1.6349522411474027e-05 \n",
      "epoch: 11 [108878/888800 12.25%] train loss: 1.6801865058369003e-05 \n",
      "epoch: 11 [109989/888800 12.38%] train loss: 1.6044732547015883e-05 \n",
      "epoch: 11 [111100/888800 12.50%] train loss: 1.3370504348131362e-05 \n",
      "epoch: 11 [112211/888800 12.62%] train loss: 1.4623900824517477e-05 \n",
      "epoch: 11 [113322/888800 12.75%] train loss: 1.6704019799362868e-05 \n",
      "epoch: 11 [114433/888800 12.88%] train loss: 1.6001642507035285e-05 \n",
      "epoch: 11 [115544/888800 13.00%] train loss: 1.689606870058924e-05 \n",
      "epoch: 11 [116655/888800 13.12%] train loss: 1.4330932572192978e-05 \n",
      "epoch: 11 [117766/888800 13.25%] train loss: 1.4846933481749147e-05 \n",
      "epoch: 11 [118877/888800 13.38%] train loss: 1.5960864402586594e-05 \n",
      "epoch: 11 [119988/888800 13.50%] train loss: 1.5662022633478045e-05 \n",
      "epoch: 11 [121099/888800 13.62%] train loss: 1.495675587648293e-05 \n",
      "epoch: 11 [122210/888800 13.75%] train loss: 1.4946775081625674e-05 \n",
      "epoch: 11 [123321/888800 13.88%] train loss: 1.5990544852684252e-05 \n",
      "epoch: 11 [124432/888800 14.00%] train loss: 1.4531556189467665e-05 \n",
      "epoch: 11 [125543/888800 14.12%] train loss: 1.7003583707264625e-05 \n",
      "epoch: 11 [126654/888800 14.25%] train loss: 1.7245134586119093e-05 \n",
      "epoch: 11 [127765/888800 14.38%] train loss: 1.5892548617557622e-05 \n",
      "epoch: 11 [128876/888800 14.50%] train loss: 1.546599014545791e-05 \n",
      "epoch: 11 [129987/888800 14.62%] train loss: 1.5515552149736322e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [131098/888800 14.75%] train loss: 1.77001602423843e-05 \n",
      "epoch: 11 [132209/888800 14.88%] train loss: 1.5505289411521517e-05 \n",
      "epoch: 11 [133320/888800 15.00%] train loss: 1.6816296920296736e-05 \n",
      "epoch: 11 [134431/888800 15.12%] train loss: 1.3856654732080642e-05 \n",
      "epoch: 11 [135542/888800 15.25%] train loss: 1.4083264431974385e-05 \n",
      "epoch: 11 [136653/888800 15.38%] train loss: 1.5661156794521958e-05 \n",
      "epoch: 11 [137764/888800 15.50%] train loss: 1.5907176930340938e-05 \n",
      "epoch: 11 [138875/888800 15.62%] train loss: 1.632620842428878e-05 \n",
      "epoch: 11 [139986/888800 15.75%] train loss: 1.4634271792601794e-05 \n",
      "epoch: 11 [141097/888800 15.88%] train loss: 1.6499310731887817e-05 \n",
      "epoch: 11 [142208/888800 16.00%] train loss: 1.3778400898445398e-05 \n",
      "epoch: 11 [143319/888800 16.12%] train loss: 1.545396662550047e-05 \n",
      "epoch: 11 [144430/888800 16.25%] train loss: 1.617236739548389e-05 \n",
      "epoch: 11 [145541/888800 16.38%] train loss: 1.4801849829382263e-05 \n",
      "epoch: 11 [146652/888800 16.50%] train loss: 1.3839553503203206e-05 \n",
      "epoch: 11 [147763/888800 16.62%] train loss: 1.6115494872792624e-05 \n",
      "epoch: 11 [148874/888800 16.75%] train loss: 1.7593583834241144e-05 \n",
      "epoch: 11 [149985/888800 16.88%] train loss: 1.4911319340171758e-05 \n",
      "epoch: 11 [151096/888800 17.00%] train loss: 1.4873936379444785e-05 \n",
      "epoch: 11 [152207/888800 17.12%] train loss: 1.5306750356103294e-05 \n",
      "epoch: 11 [153318/888800 17.25%] train loss: 1.477205387345748e-05 \n",
      "epoch: 11 [154429/888800 17.38%] train loss: 1.4039338566362858e-05 \n",
      "epoch: 11 [155540/888800 17.50%] train loss: 1.7000567822833546e-05 \n",
      "epoch: 11 [156651/888800 17.62%] train loss: 1.6351577869500034e-05 \n",
      "epoch: 11 [157762/888800 17.75%] train loss: 1.542193967907224e-05 \n",
      "epoch: 11 [158873/888800 17.88%] train loss: 1.4310258848126978e-05 \n",
      "epoch: 11 [159984/888800 18.00%] train loss: 1.3392514119914267e-05 \n",
      "epoch: 11 [161095/888800 18.12%] train loss: 1.4933329111954663e-05 \n",
      "epoch: 11 [162206/888800 18.25%] train loss: 1.5419906048919074e-05 \n",
      "epoch: 11 [163317/888800 18.38%] train loss: 1.3771827070740983e-05 \n",
      "epoch: 11 [164428/888800 18.50%] train loss: 1.4441198800341226e-05 \n",
      "epoch: 11 [165539/888800 18.62%] train loss: 1.6870653780642897e-05 \n",
      "epoch: 11 [166650/888800 18.75%] train loss: 1.636679189687129e-05 \n",
      "epoch: 11 [167761/888800 18.88%] train loss: 1.5663283193134703e-05 \n",
      "epoch: 11 [168872/888800 19.00%] train loss: 1.6077769032563083e-05 \n",
      "epoch: 11 [169983/888800 19.12%] train loss: 1.3894022231397685e-05 \n",
      "epoch: 11 [171094/888800 19.25%] train loss: 1.4741815903107636e-05 \n",
      "epoch: 11 [172205/888800 19.38%] train loss: 1.6822647012304515e-05 \n",
      "epoch: 11 [173316/888800 19.50%] train loss: 1.5217874533846043e-05 \n",
      "epoch: 11 [174427/888800 19.62%] train loss: 1.634135696804151e-05 \n",
      "epoch: 11 [175538/888800 19.75%] train loss: 1.4821540389675647e-05 \n",
      "epoch: 11 [176649/888800 19.88%] train loss: 1.3579227925220039e-05 \n",
      "epoch: 11 [177760/888800 20.00%] train loss: 1.4581453797291033e-05 \n",
      "epoch: 11 [178871/888800 20.12%] train loss: 1.7061474864021875e-05 \n",
      "epoch: 11 [179982/888800 20.25%] train loss: 1.5110408639884554e-05 \n",
      "epoch: 11 [181093/888800 20.38%] train loss: 1.4505154467769898e-05 \n",
      "epoch: 11 [182204/888800 20.50%] train loss: 1.5118933333724272e-05 \n",
      "epoch: 11 [183315/888800 20.62%] train loss: 1.426967264706036e-05 \n",
      "epoch: 11 [184426/888800 20.75%] train loss: 1.4375658793142065e-05 \n",
      "epoch: 11 [185537/888800 20.88%] train loss: 1.4374457350641023e-05 \n",
      "epoch: 11 [186648/888800 21.00%] train loss: 1.439074276277097e-05 \n",
      "epoch: 11 [187759/888800 21.12%] train loss: 1.6065523595898412e-05 \n",
      "epoch: 11 [188870/888800 21.25%] train loss: 1.6822355973999947e-05 \n",
      "epoch: 11 [189981/888800 21.38%] train loss: 1.4775816453038715e-05 \n",
      "epoch: 11 [191092/888800 21.50%] train loss: 1.585269819770474e-05 \n",
      "epoch: 11 [192203/888800 21.62%] train loss: 1.5781703041284345e-05 \n",
      "epoch: 11 [193314/888800 21.75%] train loss: 1.5827461538719945e-05 \n",
      "epoch: 11 [194425/888800 21.88%] train loss: 1.3593370567832608e-05 \n",
      "epoch: 11 [195536/888800 22.00%] train loss: 1.611387233424466e-05 \n",
      "epoch: 11 [196647/888800 22.12%] train loss: 1.5155963410506956e-05 \n",
      "epoch: 11 [197758/888800 22.25%] train loss: 1.6026364392018877e-05 \n",
      "epoch: 11 [198869/888800 22.38%] train loss: 1.6152122043422423e-05 \n",
      "epoch: 11 [199980/888800 22.50%] train loss: 1.6471776689286344e-05 \n",
      "epoch: 11 [201091/888800 22.62%] train loss: 1.5903302482911386e-05 \n",
      "epoch: 11 [202202/888800 22.75%] train loss: 1.3841514373780228e-05 \n",
      "epoch: 11 [203313/888800 22.88%] train loss: 1.5663270460208878e-05 \n",
      "epoch: 11 [204424/888800 23.00%] train loss: 1.5204511328192893e-05 \n",
      "epoch: 11 [205535/888800 23.12%] train loss: 1.4849651051918045e-05 \n",
      "epoch: 11 [206646/888800 23.25%] train loss: 1.654537300055381e-05 \n",
      "epoch: 11 [207757/888800 23.38%] train loss: 1.6436397345387377e-05 \n",
      "epoch: 11 [208868/888800 23.50%] train loss: 1.450811032555066e-05 \n",
      "epoch: 11 [209979/888800 23.62%] train loss: 1.6301566574838944e-05 \n",
      "epoch: 11 [211090/888800 23.75%] train loss: 1.4773745533602778e-05 \n",
      "epoch: 11 [212201/888800 23.88%] train loss: 1.676414285611827e-05 \n",
      "epoch: 11 [213312/888800 24.00%] train loss: 1.566111131978687e-05 \n",
      "epoch: 11 [214423/888800 24.12%] train loss: 1.4109096809988841e-05 \n",
      "epoch: 11 [215534/888800 24.25%] train loss: 1.5232099030981772e-05 \n",
      "epoch: 11 [216645/888800 24.38%] train loss: 1.567473191244062e-05 \n",
      "epoch: 11 [217756/888800 24.50%] train loss: 1.6668220268911682e-05 \n",
      "epoch: 11 [218867/888800 24.62%] train loss: 1.5252041521307547e-05 \n",
      "epoch: 11 [219978/888800 24.75%] train loss: 1.510433776275022e-05 \n",
      "epoch: 11 [221089/888800 24.88%] train loss: 1.7390852008247748e-05 \n",
      "epoch: 11 [222200/888800 25.00%] train loss: 1.681348840065766e-05 \n",
      "epoch: 11 [223311/888800 25.12%] train loss: 1.4340768757392652e-05 \n",
      "epoch: 11 [224422/888800 25.25%] train loss: 1.4754393305338454e-05 \n",
      "epoch: 11 [225533/888800 25.38%] train loss: 1.6514462913619354e-05 \n",
      "epoch: 11 [226644/888800 25.50%] train loss: 1.3383427358348854e-05 \n",
      "epoch: 11 [227755/888800 25.62%] train loss: 1.5424328012159094e-05 \n",
      "epoch: 11 [228866/888800 25.75%] train loss: 1.6923397197388113e-05 \n",
      "epoch: 11 [229977/888800 25.88%] train loss: 1.426217204425484e-05 \n",
      "epoch: 11 [231088/888800 26.00%] train loss: 1.3945962564321235e-05 \n",
      "epoch: 11 [232199/888800 26.12%] train loss: 1.5140287359827198e-05 \n",
      "epoch: 11 [233310/888800 26.25%] train loss: 1.4533504327118862e-05 \n",
      "epoch: 11 [234421/888800 26.38%] train loss: 1.5739859009045176e-05 \n",
      "epoch: 11 [235532/888800 26.50%] train loss: 1.6520603821845725e-05 \n",
      "epoch: 11 [236643/888800 26.62%] train loss: 1.4513054338749498e-05 \n",
      "epoch: 11 [237754/888800 26.75%] train loss: 1.5487246855627745e-05 \n",
      "epoch: 11 [238865/888800 26.88%] train loss: 1.5578008969896473e-05 \n",
      "epoch: 11 [239976/888800 27.00%] train loss: 1.4742281564394943e-05 \n",
      "epoch: 11 [241087/888800 27.12%] train loss: 1.4653170183009934e-05 \n",
      "epoch: 11 [242198/888800 27.25%] train loss: 1.3702704563911539e-05 \n",
      "epoch: 11 [243309/888800 27.38%] train loss: 1.4965849914005958e-05 \n",
      "epoch: 11 [244420/888800 27.50%] train loss: 1.6072532162070274e-05 \n",
      "epoch: 11 [245531/888800 27.62%] train loss: 1.5046403859741986e-05 \n",
      "epoch: 11 [246642/888800 27.75%] train loss: 1.5405665180878714e-05 \n",
      "epoch: 11 [247753/888800 27.88%] train loss: 1.4964236470405012e-05 \n",
      "epoch: 11 [248864/888800 28.00%] train loss: 1.5613986761309206e-05 \n",
      "epoch: 11 [249975/888800 28.12%] train loss: 1.534296643512789e-05 \n",
      "epoch: 11 [251086/888800 28.25%] train loss: 1.4276583897299133e-05 \n",
      "epoch: 11 [252197/888800 28.38%] train loss: 1.4036756510904524e-05 \n",
      "epoch: 11 [253308/888800 28.50%] train loss: 1.5321149476221763e-05 \n",
      "epoch: 11 [254419/888800 28.62%] train loss: 1.4868287507852074e-05 \n",
      "epoch: 11 [255530/888800 28.75%] train loss: 1.5694424291723408e-05 \n",
      "epoch: 11 [256641/888800 28.88%] train loss: 1.508597779320553e-05 \n",
      "epoch: 11 [257752/888800 29.00%] train loss: 1.4018030924489722e-05 \n",
      "epoch: 11 [258863/888800 29.12%] train loss: 1.435864032828249e-05 \n",
      "epoch: 11 [259974/888800 29.25%] train loss: 1.6542173398192972e-05 \n",
      "epoch: 11 [261085/888800 29.38%] train loss: 1.363771934848046e-05 \n",
      "epoch: 11 [262196/888800 29.50%] train loss: 1.626162338652648e-05 \n",
      "epoch: 11 [263307/888800 29.62%] train loss: 1.477276146033546e-05 \n",
      "epoch: 11 [264418/888800 29.75%] train loss: 1.3924584891356062e-05 \n",
      "epoch: 11 [265529/888800 29.88%] train loss: 1.4962210116209462e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [266640/888800 30.00%] train loss: 1.557200630486477e-05 \n",
      "epoch: 11 [267751/888800 30.12%] train loss: 1.5487268683500588e-05 \n",
      "epoch: 11 [268862/888800 30.25%] train loss: 1.4938713320589159e-05 \n",
      "epoch: 11 [269973/888800 30.38%] train loss: 1.4998012375144754e-05 \n",
      "epoch: 11 [271084/888800 30.50%] train loss: 1.5003880434960593e-05 \n",
      "epoch: 11 [272195/888800 30.62%] train loss: 1.4858067515888251e-05 \n",
      "epoch: 11 [273306/888800 30.75%] train loss: 1.5074432667461224e-05 \n",
      "epoch: 11 [274417/888800 30.88%] train loss: 1.4580793504137546e-05 \n",
      "epoch: 11 [275528/888800 31.00%] train loss: 1.6247611711150967e-05 \n",
      "epoch: 11 [276639/888800 31.12%] train loss: 1.518882709206082e-05 \n",
      "epoch: 11 [277750/888800 31.25%] train loss: 1.5780302419443615e-05 \n",
      "epoch: 11 [278861/888800 31.38%] train loss: 1.4388845556823071e-05 \n",
      "epoch: 11 [279972/888800 31.50%] train loss: 1.6112457160488702e-05 \n",
      "epoch: 11 [281083/888800 31.62%] train loss: 1.616964436834678e-05 \n",
      "epoch: 11 [282194/888800 31.75%] train loss: 1.632964631426148e-05 \n",
      "epoch: 11 [283305/888800 31.88%] train loss: 1.4796744835621212e-05 \n",
      "epoch: 11 [284416/888800 32.00%] train loss: 1.5084952792676631e-05 \n",
      "epoch: 11 [285527/888800 32.12%] train loss: 1.5475054169655778e-05 \n",
      "epoch: 11 [286638/888800 32.25%] train loss: 1.4763249964744318e-05 \n",
      "epoch: 11 [287749/888800 32.38%] train loss: 1.582456025062129e-05 \n",
      "epoch: 11 [288860/888800 32.50%] train loss: 1.5855322999414057e-05 \n",
      "epoch: 11 [289971/888800 32.62%] train loss: 1.487206645833794e-05 \n",
      "epoch: 11 [291082/888800 32.75%] train loss: 1.4437718164117541e-05 \n",
      "epoch: 11 [292193/888800 32.88%] train loss: 1.4367742551257834e-05 \n",
      "epoch: 11 [293304/888800 33.00%] train loss: 1.5092227840796113e-05 \n",
      "epoch: 11 [294415/888800 33.12%] train loss: 1.5878293197602034e-05 \n",
      "epoch: 11 [295526/888800 33.25%] train loss: 1.6515077732037753e-05 \n",
      "epoch: 11 [296637/888800 33.38%] train loss: 1.5986615835572593e-05 \n",
      "epoch: 11 [297748/888800 33.50%] train loss: 1.5097993127710652e-05 \n",
      "epoch: 11 [298859/888800 33.62%] train loss: 1.3439663234748878e-05 \n",
      "epoch: 11 [299970/888800 33.75%] train loss: 1.4836280570307281e-05 \n",
      "epoch: 11 [301081/888800 33.88%] train loss: 1.4272189218900166e-05 \n",
      "epoch: 11 [302192/888800 34.00%] train loss: 1.4911076505086385e-05 \n",
      "epoch: 11 [303303/888800 34.12%] train loss: 1.449110459361691e-05 \n",
      "epoch: 11 [304414/888800 34.25%] train loss: 1.5256871847668663e-05 \n",
      "epoch: 11 [305525/888800 34.38%] train loss: 1.4685527276014909e-05 \n",
      "epoch: 11 [306636/888800 34.50%] train loss: 1.4657947758678347e-05 \n",
      "epoch: 11 [307747/888800 34.62%] train loss: 1.4821142940490972e-05 \n",
      "epoch: 11 [308858/888800 34.75%] train loss: 1.4399164683709387e-05 \n",
      "epoch: 11 [309969/888800 34.88%] train loss: 1.3825426322000567e-05 \n",
      "epoch: 11 [311080/888800 35.00%] train loss: 1.5916311895125546e-05 \n",
      "epoch: 11 [312191/888800 35.12%] train loss: 1.4708029993926175e-05 \n",
      "epoch: 11 [313302/888800 35.25%] train loss: 1.552817047922872e-05 \n",
      "epoch: 11 [314413/888800 35.38%] train loss: 1.460829207644565e-05 \n",
      "epoch: 11 [315524/888800 35.50%] train loss: 1.5534089470747858e-05 \n",
      "epoch: 11 [316635/888800 35.62%] train loss: 1.5881038052611984e-05 \n",
      "epoch: 11 [317746/888800 35.75%] train loss: 1.691387478786055e-05 \n",
      "epoch: 11 [318857/888800 35.88%] train loss: 1.5305140550481156e-05 \n",
      "epoch: 11 [319968/888800 36.00%] train loss: 1.5112926121219061e-05 \n",
      "epoch: 11 [321079/888800 36.12%] train loss: 1.6100480934255756e-05 \n",
      "epoch: 11 [322190/888800 36.25%] train loss: 1.4901848771842197e-05 \n",
      "epoch: 11 [323301/888800 36.38%] train loss: 1.6054505977081135e-05 \n",
      "epoch: 11 [324412/888800 36.50%] train loss: 1.4066958101466298e-05 \n",
      "epoch: 11 [325523/888800 36.62%] train loss: 1.5254560821631458e-05 \n",
      "epoch: 11 [326634/888800 36.75%] train loss: 1.4055061001272406e-05 \n",
      "epoch: 11 [327745/888800 36.88%] train loss: 1.5305113265640102e-05 \n",
      "epoch: 11 [328856/888800 37.00%] train loss: 1.4247832041291986e-05 \n",
      "epoch: 11 [329967/888800 37.12%] train loss: 1.5247526789607946e-05 \n",
      "epoch: 11 [331078/888800 37.25%] train loss: 1.6839863747009076e-05 \n",
      "epoch: 11 [332189/888800 37.38%] train loss: 1.5215256098599639e-05 \n",
      "epoch: 11 [333300/888800 37.50%] train loss: 1.4681124412163626e-05 \n",
      "epoch: 11 [334411/888800 37.62%] train loss: 1.6575380868744105e-05 \n",
      "epoch: 11 [335522/888800 37.75%] train loss: 1.6146983398357406e-05 \n",
      "epoch: 11 [336633/888800 37.88%] train loss: 1.687429175944999e-05 \n",
      "epoch: 11 [337744/888800 38.00%] train loss: 1.5892601368250325e-05 \n",
      "epoch: 11 [338855/888800 38.12%] train loss: 1.7676878997008316e-05 \n",
      "epoch: 11 [339966/888800 38.25%] train loss: 1.5714125765953213e-05 \n",
      "epoch: 11 [341077/888800 38.38%] train loss: 1.6170617527677678e-05 \n",
      "epoch: 11 [342188/888800 38.50%] train loss: 1.5156511835812125e-05 \n",
      "epoch: 11 [343299/888800 38.62%] train loss: 1.6367142961826175e-05 \n",
      "epoch: 11 [344410/888800 38.75%] train loss: 1.4114842088019941e-05 \n",
      "epoch: 11 [345521/888800 38.88%] train loss: 1.619574504729826e-05 \n",
      "epoch: 11 [346632/888800 39.00%] train loss: 1.4663944966741838e-05 \n",
      "epoch: 11 [347743/888800 39.12%] train loss: 1.4619348803535104e-05 \n",
      "epoch: 11 [348854/888800 39.25%] train loss: 1.3817859326081816e-05 \n",
      "epoch: 11 [349965/888800 39.38%] train loss: 1.4859228031127714e-05 \n",
      "epoch: 11 [351076/888800 39.50%] train loss: 1.666861862759106e-05 \n",
      "epoch: 11 [352187/888800 39.62%] train loss: 1.4109192306932528e-05 \n",
      "epoch: 11 [353298/888800 39.75%] train loss: 1.3583331565314438e-05 \n",
      "epoch: 11 [354409/888800 39.88%] train loss: 1.578179217176512e-05 \n",
      "epoch: 11 [355520/888800 40.00%] train loss: 1.5262203305610456e-05 \n",
      "epoch: 11 [356631/888800 40.12%] train loss: 1.598072594788391e-05 \n",
      "epoch: 11 [357742/888800 40.25%] train loss: 1.6460624465253204e-05 \n",
      "epoch: 11 [358853/888800 40.38%] train loss: 1.5757706933072768e-05 \n",
      "epoch: 11 [359964/888800 40.50%] train loss: 1.5349534805864096e-05 \n",
      "epoch: 11 [361075/888800 40.62%] train loss: 1.4344604096550029e-05 \n",
      "epoch: 11 [362186/888800 40.75%] train loss: 1.4686324902868364e-05 \n",
      "epoch: 11 [363297/888800 40.88%] train loss: 1.4951384400774259e-05 \n",
      "epoch: 11 [364408/888800 41.00%] train loss: 1.5651517969672568e-05 \n",
      "epoch: 11 [365519/888800 41.12%] train loss: 1.574927955516614e-05 \n",
      "epoch: 11 [366630/888800 41.25%] train loss: 1.4920924513717182e-05 \n",
      "epoch: 11 [367741/888800 41.38%] train loss: 1.4871711755404249e-05 \n",
      "epoch: 11 [368852/888800 41.50%] train loss: 1.5005852219474036e-05 \n",
      "epoch: 11 [369963/888800 41.62%] train loss: 1.5452638763235882e-05 \n",
      "epoch: 11 [371074/888800 41.75%] train loss: 1.4718027159688063e-05 \n",
      "epoch: 11 [372185/888800 41.88%] train loss: 1.3769392353424337e-05 \n",
      "epoch: 11 [373296/888800 42.00%] train loss: 1.483195046603214e-05 \n",
      "epoch: 11 [374407/888800 42.12%] train loss: 1.3005302207602654e-05 \n",
      "epoch: 11 [375518/888800 42.25%] train loss: 1.6289759514620528e-05 \n",
      "epoch: 11 [376629/888800 42.38%] train loss: 1.477214118494885e-05 \n",
      "epoch: 11 [377740/888800 42.50%] train loss: 1.54597273649415e-05 \n",
      "epoch: 11 [378851/888800 42.62%] train loss: 1.4144679880701005e-05 \n",
      "epoch: 11 [379962/888800 42.75%] train loss: 1.5830759366508573e-05 \n",
      "epoch: 11 [381073/888800 42.88%] train loss: 1.5243816051224712e-05 \n",
      "epoch: 11 [382184/888800 43.00%] train loss: 1.4073142665438354e-05 \n",
      "epoch: 11 [383295/888800 43.12%] train loss: 1.5417163012898527e-05 \n",
      "epoch: 11 [384406/888800 43.25%] train loss: 1.5302635802072473e-05 \n",
      "epoch: 11 [385517/888800 43.38%] train loss: 1.357306246063672e-05 \n",
      "epoch: 11 [386628/888800 43.50%] train loss: 1.613150925550144e-05 \n",
      "epoch: 11 [387739/888800 43.62%] train loss: 1.655190862948075e-05 \n",
      "epoch: 11 [388850/888800 43.75%] train loss: 1.499168502050452e-05 \n",
      "epoch: 11 [389961/888800 43.88%] train loss: 1.579661329742521e-05 \n",
      "epoch: 11 [391072/888800 44.00%] train loss: 1.504442570876563e-05 \n",
      "epoch: 11 [392183/888800 44.12%] train loss: 1.5160463590291329e-05 \n",
      "epoch: 11 [393294/888800 44.25%] train loss: 1.5117570001166314e-05 \n",
      "epoch: 11 [394405/888800 44.38%] train loss: 1.5700315998401493e-05 \n",
      "epoch: 11 [395516/888800 44.50%] train loss: 1.4983220353315119e-05 \n",
      "epoch: 11 [396627/888800 44.62%] train loss: 1.5933890608721413e-05 \n",
      "epoch: 11 [397738/888800 44.75%] train loss: 1.6497549950145185e-05 \n",
      "epoch: 11 [398849/888800 44.88%] train loss: 1.4119525985734072e-05 \n",
      "epoch: 11 [399960/888800 45.00%] train loss: 1.4886144526826683e-05 \n",
      "epoch: 11 [401071/888800 45.12%] train loss: 1.5673780580982566e-05 \n",
      "epoch: 11 [402182/888800 45.25%] train loss: 1.5172628081927542e-05 \n",
      "epoch: 11 [403293/888800 45.38%] train loss: 1.58953589561861e-05 \n",
      "epoch: 11 [404404/888800 45.50%] train loss: 1.4464420928561594e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [405515/888800 45.62%] train loss: 1.4327988537843339e-05 \n",
      "epoch: 11 [406626/888800 45.75%] train loss: 1.378277829644503e-05 \n",
      "epoch: 11 [407737/888800 45.88%] train loss: 1.4862269381410442e-05 \n",
      "epoch: 11 [408848/888800 46.00%] train loss: 1.4717166777700186e-05 \n",
      "epoch: 11 [409959/888800 46.12%] train loss: 1.528153552499134e-05 \n",
      "epoch: 11 [411070/888800 46.25%] train loss: 1.5088864529388957e-05 \n",
      "epoch: 11 [412181/888800 46.38%] train loss: 1.5234821148624178e-05 \n",
      "epoch: 11 [413292/888800 46.50%] train loss: 1.5248555428115651e-05 \n",
      "epoch: 11 [414403/888800 46.62%] train loss: 1.5574849385302514e-05 \n",
      "epoch: 11 [415514/888800 46.75%] train loss: 1.6056870663305745e-05 \n",
      "epoch: 11 [416625/888800 46.88%] train loss: 1.4265935533330776e-05 \n",
      "epoch: 11 [417736/888800 47.00%] train loss: 1.4587529221898876e-05 \n",
      "epoch: 11 [418847/888800 47.12%] train loss: 1.5408206309075467e-05 \n",
      "epoch: 11 [419958/888800 47.25%] train loss: 1.5274210454663262e-05 \n",
      "epoch: 11 [421069/888800 47.38%] train loss: 1.5261693988577463e-05 \n",
      "epoch: 11 [422180/888800 47.50%] train loss: 1.548133514006622e-05 \n",
      "epoch: 11 [423291/888800 47.62%] train loss: 1.582176446390804e-05 \n",
      "epoch: 11 [424402/888800 47.75%] train loss: 1.5740864910185337e-05 \n",
      "epoch: 11 [425513/888800 47.88%] train loss: 1.575158785271924e-05 \n",
      "epoch: 11 [426624/888800 48.00%] train loss: 1.4843428289168514e-05 \n",
      "epoch: 11 [427735/888800 48.12%] train loss: 1.5600739061483182e-05 \n",
      "epoch: 11 [428846/888800 48.25%] train loss: 1.5275229088729247e-05 \n",
      "epoch: 11 [429957/888800 48.38%] train loss: 1.774539668986108e-05 \n",
      "epoch: 11 [431068/888800 48.50%] train loss: 1.5843908840906806e-05 \n",
      "epoch: 11 [432179/888800 48.62%] train loss: 1.4630492842115927e-05 \n",
      "epoch: 11 [433290/888800 48.75%] train loss: 1.48291601362871e-05 \n",
      "epoch: 11 [434401/888800 48.88%] train loss: 1.590522879268974e-05 \n",
      "epoch: 11 [435512/888800 49.00%] train loss: 1.4641165762441233e-05 \n",
      "epoch: 11 [436623/888800 49.12%] train loss: 1.545677332615014e-05 \n",
      "epoch: 11 [437734/888800 49.25%] train loss: 1.5901752703939565e-05 \n",
      "epoch: 11 [438845/888800 49.38%] train loss: 1.5283527318388224e-05 \n",
      "epoch: 11 [439956/888800 49.50%] train loss: 1.4964126421546098e-05 \n",
      "epoch: 11 [441067/888800 49.62%] train loss: 1.5547133443760686e-05 \n",
      "epoch: 11 [442178/888800 49.75%] train loss: 1.3325448890100233e-05 \n",
      "epoch: 11 [443289/888800 49.88%] train loss: 1.513571260147728e-05 \n",
      "epoch: 11 [444400/888800 50.00%] train loss: 1.500712642155122e-05 \n",
      "epoch: 11 [445511/888800 50.12%] train loss: 1.648431680223439e-05 \n",
      "epoch: 11 [446622/888800 50.25%] train loss: 1.4975752492318861e-05 \n",
      "epoch: 11 [447733/888800 50.38%] train loss: 1.5602012354065664e-05 \n",
      "epoch: 11 [448844/888800 50.50%] train loss: 1.59596365847392e-05 \n",
      "epoch: 11 [449955/888800 50.62%] train loss: 1.389155750075588e-05 \n",
      "epoch: 11 [451066/888800 50.75%] train loss: 1.5375429939012975e-05 \n",
      "epoch: 11 [452177/888800 50.88%] train loss: 1.674145823926665e-05 \n",
      "epoch: 11 [453288/888800 51.00%] train loss: 1.551967579871416e-05 \n",
      "epoch: 11 [454399/888800 51.12%] train loss: 1.632434577913955e-05 \n",
      "epoch: 11 [455510/888800 51.25%] train loss: 1.4097088751441333e-05 \n",
      "epoch: 11 [456621/888800 51.38%] train loss: 1.530832923890557e-05 \n",
      "epoch: 11 [457732/888800 51.50%] train loss: 1.5994213754311204e-05 \n",
      "epoch: 11 [458843/888800 51.62%] train loss: 1.601976873644162e-05 \n",
      "epoch: 11 [459954/888800 51.75%] train loss: 1.530616827949416e-05 \n",
      "epoch: 11 [461065/888800 51.88%] train loss: 1.6749099813750945e-05 \n",
      "epoch: 11 [462176/888800 52.00%] train loss: 1.6272266293526627e-05 \n",
      "epoch: 11 [463287/888800 52.12%] train loss: 1.2669082025240641e-05 \n",
      "epoch: 11 [464398/888800 52.25%] train loss: 1.6170535673154518e-05 \n",
      "epoch: 11 [465509/888800 52.38%] train loss: 1.5520017768722028e-05 \n",
      "epoch: 11 [466620/888800 52.50%] train loss: 1.3749147001362871e-05 \n",
      "epoch: 11 [467731/888800 52.62%] train loss: 1.4787354302825406e-05 \n",
      "epoch: 11 [468842/888800 52.75%] train loss: 1.6031950508477166e-05 \n",
      "epoch: 11 [469953/888800 52.88%] train loss: 1.488377256464446e-05 \n",
      "epoch: 11 [471064/888800 53.00%] train loss: 1.434442037862027e-05 \n",
      "epoch: 11 [472175/888800 53.12%] train loss: 1.3520491847884841e-05 \n",
      "epoch: 11 [473286/888800 53.25%] train loss: 1.5044761312310584e-05 \n",
      "epoch: 11 [474397/888800 53.38%] train loss: 1.3289706657815259e-05 \n",
      "epoch: 11 [475508/888800 53.50%] train loss: 1.634182990528643e-05 \n",
      "epoch: 11 [476619/888800 53.62%] train loss: 1.4014949556440115e-05 \n",
      "epoch: 11 [477730/888800 53.75%] train loss: 1.3965319340059068e-05 \n",
      "epoch: 11 [478841/888800 53.88%] train loss: 1.781065293471329e-05 \n",
      "epoch: 11 [479952/888800 54.00%] train loss: 1.6278416296700016e-05 \n",
      "epoch: 11 [481063/888800 54.12%] train loss: 1.4362734873429872e-05 \n",
      "epoch: 11 [482174/888800 54.25%] train loss: 1.38493487611413e-05 \n",
      "epoch: 11 [483285/888800 54.38%] train loss: 1.7992049833992496e-05 \n",
      "epoch: 11 [484396/888800 54.50%] train loss: 1.4503541024168953e-05 \n",
      "epoch: 11 [485507/888800 54.62%] train loss: 1.4378083506016992e-05 \n",
      "epoch: 11 [486618/888800 54.75%] train loss: 1.5154454558796715e-05 \n",
      "epoch: 11 [487729/888800 54.88%] train loss: 1.428384621249279e-05 \n",
      "epoch: 11 [488840/888800 55.00%] train loss: 1.5248912859533448e-05 \n",
      "epoch: 11 [489951/888800 55.12%] train loss: 1.4993734112067614e-05 \n",
      "epoch: 11 [491062/888800 55.25%] train loss: 1.4268113773141522e-05 \n",
      "epoch: 11 [492173/888800 55.38%] train loss: 1.3947411389381159e-05 \n",
      "epoch: 11 [493284/888800 55.50%] train loss: 1.5815843653399497e-05 \n",
      "epoch: 11 [494395/888800 55.62%] train loss: 1.4306439879874233e-05 \n",
      "epoch: 11 [495506/888800 55.75%] train loss: 1.617447196622379e-05 \n",
      "epoch: 11 [496617/888800 55.88%] train loss: 1.4437307982007042e-05 \n",
      "epoch: 11 [497728/888800 56.00%] train loss: 1.5053137758513913e-05 \n",
      "epoch: 11 [498839/888800 56.12%] train loss: 1.5276458725566044e-05 \n",
      "epoch: 11 [499950/888800 56.25%] train loss: 1.4869468031974975e-05 \n",
      "epoch: 11 [501061/888800 56.38%] train loss: 1.507923752797069e-05 \n",
      "epoch: 11 [502172/888800 56.50%] train loss: 1.4011435268912464e-05 \n",
      "epoch: 11 [503283/888800 56.62%] train loss: 1.4646678209828679e-05 \n",
      "epoch: 11 [504394/888800 56.75%] train loss: 1.4340631423692685e-05 \n",
      "epoch: 11 [505505/888800 56.88%] train loss: 1.4568866390618496e-05 \n",
      "epoch: 11 [506616/888800 57.00%] train loss: 1.6023717762436718e-05 \n",
      "epoch: 11 [507727/888800 57.12%] train loss: 1.6086634786915965e-05 \n",
      "epoch: 11 [508838/888800 57.25%] train loss: 1.4543062206939794e-05 \n",
      "epoch: 11 [509949/888800 57.38%] train loss: 1.4337282664200757e-05 \n",
      "epoch: 11 [511060/888800 57.50%] train loss: 1.4512122106680181e-05 \n",
      "epoch: 11 [512171/888800 57.62%] train loss: 1.5396422895719297e-05 \n",
      "epoch: 11 [513282/888800 57.75%] train loss: 1.5167141100391746e-05 \n",
      "epoch: 11 [514393/888800 57.88%] train loss: 1.457664529880276e-05 \n",
      "epoch: 11 [515504/888800 58.00%] train loss: 1.5163407624640968e-05 \n",
      "epoch: 11 [516615/888800 58.12%] train loss: 1.4587712030333932e-05 \n",
      "epoch: 11 [517726/888800 58.25%] train loss: 1.4446812201640569e-05 \n",
      "epoch: 11 [518837/888800 58.38%] train loss: 1.5087729480001144e-05 \n",
      "epoch: 11 [519948/888800 58.50%] train loss: 1.4574808119505178e-05 \n",
      "epoch: 11 [521059/888800 58.62%] train loss: 1.5802690541022457e-05 \n",
      "epoch: 11 [522170/888800 58.75%] train loss: 1.444417102902662e-05 \n",
      "epoch: 11 [523281/888800 58.88%] train loss: 1.732774580887053e-05 \n",
      "epoch: 11 [524392/888800 59.00%] train loss: 1.5500621884712018e-05 \n",
      "epoch: 11 [525503/888800 59.12%] train loss: 1.4398984603758436e-05 \n",
      "epoch: 11 [526614/888800 59.25%] train loss: 1.4403751265490428e-05 \n",
      "epoch: 11 [527725/888800 59.38%] train loss: 1.5543253539362922e-05 \n",
      "epoch: 11 [528836/888800 59.50%] train loss: 1.41375976454583e-05 \n",
      "epoch: 11 [529947/888800 59.62%] train loss: 1.4452561117650475e-05 \n",
      "epoch: 11 [531058/888800 59.75%] train loss: 1.4637058484368026e-05 \n",
      "epoch: 11 [532169/888800 59.88%] train loss: 1.6951542420429178e-05 \n",
      "epoch: 11 [533280/888800 60.00%] train loss: 1.6329298887285404e-05 \n",
      "epoch: 11 [534391/888800 60.12%] train loss: 1.360084115731297e-05 \n",
      "epoch: 11 [535502/888800 60.25%] train loss: 1.4063767594052479e-05 \n",
      "epoch: 11 [536613/888800 60.38%] train loss: 1.4215476767276414e-05 \n",
      "epoch: 11 [537724/888800 60.50%] train loss: 1.5702891687396914e-05 \n",
      "epoch: 11 [538835/888800 60.62%] train loss: 1.535320552648045e-05 \n",
      "epoch: 11 [539946/888800 60.75%] train loss: 1.335444176220335e-05 \n",
      "epoch: 11 [541057/888800 60.88%] train loss: 1.667702235863544e-05 \n",
      "epoch: 11 [542168/888800 61.00%] train loss: 1.3260362720757257e-05 \n",
      "epoch: 11 [543279/888800 61.12%] train loss: 1.6214056813623756e-05 \n",
      "epoch: 11 [544390/888800 61.25%] train loss: 1.4339673725771718e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [545501/888800 61.38%] train loss: 1.6585378034505993e-05 \n",
      "epoch: 11 [546612/888800 61.50%] train loss: 1.4463224943028763e-05 \n",
      "epoch: 11 [547723/888800 61.62%] train loss: 1.697741936368402e-05 \n",
      "epoch: 11 [548834/888800 61.75%] train loss: 1.4387279406946618e-05 \n",
      "epoch: 11 [549945/888800 61.88%] train loss: 1.5026490473246668e-05 \n",
      "epoch: 11 [551056/888800 62.00%] train loss: 1.546066596347373e-05 \n",
      "epoch: 11 [552167/888800 62.12%] train loss: 1.552561661810614e-05 \n",
      "epoch: 11 [553278/888800 62.25%] train loss: 1.5323719708248973e-05 \n",
      "epoch: 11 [554389/888800 62.38%] train loss: 1.5714895198470913e-05 \n",
      "epoch: 11 [555500/888800 62.50%] train loss: 1.5501178495469503e-05 \n",
      "epoch: 11 [556611/888800 62.62%] train loss: 1.51848671521293e-05 \n",
      "epoch: 11 [557722/888800 62.75%] train loss: 1.4740511687705293e-05 \n",
      "epoch: 11 [558833/888800 62.88%] train loss: 1.6817963114590384e-05 \n",
      "epoch: 11 [559944/888800 63.00%] train loss: 1.4543681572831701e-05 \n",
      "epoch: 11 [561055/888800 63.12%] train loss: 1.515885378466919e-05 \n",
      "epoch: 11 [562166/888800 63.25%] train loss: 1.568010338814929e-05 \n",
      "epoch: 11 [563277/888800 63.38%] train loss: 1.5525065464316867e-05 \n",
      "epoch: 11 [564388/888800 63.50%] train loss: 1.430794145562686e-05 \n",
      "epoch: 11 [565499/888800 63.62%] train loss: 1.5884972526691854e-05 \n",
      "epoch: 11 [566610/888800 63.75%] train loss: 1.4386877410288434e-05 \n",
      "epoch: 11 [567721/888800 63.88%] train loss: 1.3450930964609142e-05 \n",
      "epoch: 11 [568832/888800 64.00%] train loss: 1.5167836863838602e-05 \n",
      "epoch: 11 [569943/888800 64.12%] train loss: 1.4259901945479214e-05 \n",
      "epoch: 11 [571054/888800 64.25%] train loss: 1.587210499565117e-05 \n",
      "epoch: 11 [572165/888800 64.38%] train loss: 1.4639539585914463e-05 \n",
      "epoch: 11 [573276/888800 64.50%] train loss: 1.5130091014725622e-05 \n",
      "epoch: 11 [574387/888800 64.62%] train loss: 1.338007587037282e-05 \n",
      "epoch: 11 [575498/888800 64.75%] train loss: 1.4946104784030467e-05 \n",
      "epoch: 11 [576609/888800 64.88%] train loss: 1.5536805221927352e-05 \n",
      "epoch: 11 [577720/888800 65.00%] train loss: 1.4351803656609263e-05 \n",
      "epoch: 11 [578831/888800 65.12%] train loss: 1.548450927657541e-05 \n",
      "epoch: 11 [579942/888800 65.25%] train loss: 1.62257747433614e-05 \n",
      "epoch: 11 [581053/888800 65.38%] train loss: 1.5602176063111983e-05 \n",
      "epoch: 11 [582164/888800 65.50%] train loss: 1.5309988157241605e-05 \n",
      "epoch: 11 [583275/888800 65.62%] train loss: 1.5361287296400405e-05 \n",
      "epoch: 11 [584386/888800 65.75%] train loss: 1.6375895938836038e-05 \n",
      "epoch: 11 [585497/888800 65.88%] train loss: 1.4187729902914725e-05 \n",
      "epoch: 11 [586608/888800 66.00%] train loss: 1.612388041394297e-05 \n",
      "epoch: 11 [587719/888800 66.12%] train loss: 1.3779268556390889e-05 \n",
      "epoch: 11 [588830/888800 66.25%] train loss: 1.3496020983438939e-05 \n",
      "epoch: 11 [589941/888800 66.38%] train loss: 1.4631697922595777e-05 \n",
      "epoch: 11 [591052/888800 66.50%] train loss: 1.4325293705041986e-05 \n",
      "epoch: 11 [592163/888800 66.62%] train loss: 1.5745856217108667e-05 \n",
      "epoch: 11 [593274/888800 66.75%] train loss: 1.514487485110294e-05 \n",
      "epoch: 11 [594385/888800 66.88%] train loss: 1.630936276342254e-05 \n",
      "epoch: 11 [595496/888800 67.00%] train loss: 1.430920292477822e-05 \n",
      "epoch: 11 [596607/888800 67.12%] train loss: 1.4996208847151138e-05 \n",
      "epoch: 11 [597718/888800 67.25%] train loss: 1.3566052075475454e-05 \n",
      "epoch: 11 [598829/888800 67.38%] train loss: 1.5620864360244013e-05 \n",
      "epoch: 11 [599940/888800 67.50%] train loss: 1.4866007404634729e-05 \n",
      "epoch: 11 [601051/888800 67.62%] train loss: 1.2966250324097928e-05 \n",
      "epoch: 11 [602162/888800 67.75%] train loss: 1.432209501217585e-05 \n",
      "epoch: 11 [603273/888800 67.88%] train loss: 1.4504181308439001e-05 \n",
      "epoch: 11 [604384/888800 68.00%] train loss: 1.567722938489169e-05 \n",
      "epoch: 11 [605495/888800 68.12%] train loss: 1.5111253560462501e-05 \n",
      "epoch: 11 [606606/888800 68.25%] train loss: 1.53332239278825e-05 \n",
      "epoch: 11 [607717/888800 68.38%] train loss: 1.4168466805131175e-05 \n",
      "epoch: 11 [608828/888800 68.50%] train loss: 1.3695465895580128e-05 \n",
      "epoch: 11 [609939/888800 68.62%] train loss: 1.3904499610362109e-05 \n",
      "epoch: 11 [611050/888800 68.75%] train loss: 1.38456553031574e-05 \n",
      "epoch: 11 [612161/888800 68.88%] train loss: 1.6511979993083514e-05 \n",
      "epoch: 11 [613272/888800 69.00%] train loss: 1.4863404430798255e-05 \n",
      "epoch: 11 [614383/888800 69.12%] train loss: 1.3919942830398213e-05 \n",
      "epoch: 11 [615494/888800 69.25%] train loss: 1.4738023310201243e-05 \n",
      "epoch: 11 [616605/888800 69.38%] train loss: 1.3323370694706682e-05 \n",
      "epoch: 11 [617716/888800 69.50%] train loss: 1.4009197911946103e-05 \n",
      "epoch: 11 [618827/888800 69.62%] train loss: 1.5140038158278912e-05 \n",
      "epoch: 11 [619938/888800 69.75%] train loss: 1.4595144421036821e-05 \n",
      "epoch: 11 [621049/888800 69.88%] train loss: 1.4148495210974943e-05 \n",
      "epoch: 11 [622160/888800 70.00%] train loss: 1.519531178928446e-05 \n",
      "epoch: 11 [623271/888800 70.12%] train loss: 1.800704194465652e-05 \n",
      "epoch: 11 [624382/888800 70.25%] train loss: 1.302609143749578e-05 \n",
      "epoch: 11 [625493/888800 70.38%] train loss: 1.385107225360116e-05 \n",
      "epoch: 11 [626604/888800 70.50%] train loss: 1.377274929836858e-05 \n",
      "epoch: 11 [627715/888800 70.62%] train loss: 1.6210942703764886e-05 \n",
      "epoch: 11 [628826/888800 70.75%] train loss: 1.5557776350760832e-05 \n",
      "epoch: 11 [629937/888800 70.88%] train loss: 1.7662554455455393e-05 \n",
      "epoch: 11 [631048/888800 71.00%] train loss: 1.3515098544303328e-05 \n",
      "epoch: 11 [632159/888800 71.12%] train loss: 1.4114439181867056e-05 \n",
      "epoch: 11 [633270/888800 71.25%] train loss: 1.5097178220457863e-05 \n",
      "epoch: 11 [634381/888800 71.38%] train loss: 1.650737613090314e-05 \n",
      "epoch: 11 [635492/888800 71.50%] train loss: 1.4545961676049046e-05 \n",
      "epoch: 11 [636603/888800 71.62%] train loss: 1.6122436136356555e-05 \n",
      "epoch: 11 [637714/888800 71.75%] train loss: 1.5947989595588297e-05 \n",
      "epoch: 11 [638825/888800 71.88%] train loss: 1.4980849300627597e-05 \n",
      "epoch: 11 [639936/888800 72.00%] train loss: 1.4808577361691277e-05 \n",
      "epoch: 11 [641047/888800 72.12%] train loss: 1.5539442756562494e-05 \n",
      "epoch: 11 [642158/888800 72.25%] train loss: 1.4687791008327622e-05 \n",
      "epoch: 11 [643269/888800 72.38%] train loss: 1.5190020349109545e-05 \n",
      "epoch: 11 [644380/888800 72.50%] train loss: 1.4334441402752418e-05 \n",
      "epoch: 11 [645491/888800 72.62%] train loss: 1.5210010133159813e-05 \n",
      "epoch: 11 [646602/888800 72.75%] train loss: 1.532524765934795e-05 \n",
      "epoch: 11 [647713/888800 72.88%] train loss: 1.4396429833141156e-05 \n",
      "epoch: 11 [648824/888800 73.00%] train loss: 1.4331346392282285e-05 \n",
      "epoch: 11 [649935/888800 73.12%] train loss: 1.3380667041928973e-05 \n",
      "epoch: 11 [651046/888800 73.25%] train loss: 1.4355376151797827e-05 \n",
      "epoch: 11 [652157/888800 73.38%] train loss: 1.5501036614296027e-05 \n",
      "epoch: 11 [653268/888800 73.50%] train loss: 1.6299361959681846e-05 \n",
      "epoch: 11 [654379/888800 73.62%] train loss: 1.3440092516248114e-05 \n",
      "epoch: 11 [655490/888800 73.75%] train loss: 1.6991971278912388e-05 \n",
      "epoch: 11 [656601/888800 73.88%] train loss: 1.6400652384618297e-05 \n",
      "epoch: 11 [657712/888800 74.00%] train loss: 1.4812720110057853e-05 \n",
      "epoch: 11 [658823/888800 74.12%] train loss: 1.4330742487800308e-05 \n",
      "epoch: 11 [659934/888800 74.25%] train loss: 1.650504236749839e-05 \n",
      "epoch: 11 [661045/888800 74.38%] train loss: 1.427107235940639e-05 \n",
      "epoch: 11 [662156/888800 74.50%] train loss: 1.3777073036180809e-05 \n",
      "epoch: 11 [663267/888800 74.62%] train loss: 1.5587007510475814e-05 \n",
      "epoch: 11 [664378/888800 74.75%] train loss: 1.5305489796446636e-05 \n",
      "epoch: 11 [665489/888800 74.88%] train loss: 1.5712432286818512e-05 \n",
      "epoch: 11 [666600/888800 75.00%] train loss: 1.5390600310638547e-05 \n",
      "epoch: 11 [667711/888800 75.12%] train loss: 1.4063976777833886e-05 \n",
      "epoch: 11 [668822/888800 75.25%] train loss: 1.3950426364317536e-05 \n",
      "epoch: 11 [669933/888800 75.38%] train loss: 1.6065236195572652e-05 \n",
      "epoch: 11 [671044/888800 75.50%] train loss: 1.5267836715793237e-05 \n",
      "epoch: 11 [672155/888800 75.62%] train loss: 1.4534520232700743e-05 \n",
      "epoch: 11 [673266/888800 75.75%] train loss: 1.5530469681834802e-05 \n",
      "epoch: 11 [674377/888800 75.88%] train loss: 1.6234047507168725e-05 \n",
      "epoch: 11 [675488/888800 76.00%] train loss: 1.5001912288425956e-05 \n",
      "epoch: 11 [676599/888800 76.12%] train loss: 1.5197320863080677e-05 \n",
      "epoch: 11 [677710/888800 76.25%] train loss: 1.3578810467151925e-05 \n",
      "epoch: 11 [678821/888800 76.38%] train loss: 1.6680522094247863e-05 \n",
      "epoch: 11 [679932/888800 76.50%] train loss: 1.541280471428763e-05 \n",
      "epoch: 11 [681043/888800 76.62%] train loss: 1.5637035176041536e-05 \n",
      "epoch: 11 [682154/888800 76.75%] train loss: 1.4423178072320297e-05 \n",
      "epoch: 11 [683265/888800 76.88%] train loss: 1.462061936763348e-05 \n",
      "epoch: 11 [684376/888800 77.00%] train loss: 1.506522221461637e-05 \n",
      "epoch: 11 [685487/888800 77.12%] train loss: 1.5886163964751177e-05 \n",
      "epoch: 11 [686598/888800 77.25%] train loss: 1.504614465375198e-05 \n",
      "epoch: 11 [687709/888800 77.38%] train loss: 1.548667023598682e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [688820/888800 77.50%] train loss: 1.4426752386498265e-05 \n",
      "epoch: 11 [689931/888800 77.62%] train loss: 1.3694177141587716e-05 \n",
      "epoch: 11 [691042/888800 77.75%] train loss: 1.3892400602344424e-05 \n",
      "epoch: 11 [692153/888800 77.88%] train loss: 1.445920679543633e-05 \n",
      "epoch: 11 [693264/888800 78.00%] train loss: 1.5280802472261712e-05 \n",
      "epoch: 11 [694375/888800 78.12%] train loss: 1.628389145480469e-05 \n",
      "epoch: 11 [695486/888800 78.25%] train loss: 1.596072434040252e-05 \n",
      "epoch: 11 [696597/888800 78.38%] train loss: 1.661261558183469e-05 \n",
      "epoch: 11 [697708/888800 78.50%] train loss: 1.5284242181223817e-05 \n",
      "epoch: 11 [698819/888800 78.62%] train loss: 1.51694257510826e-05 \n",
      "epoch: 11 [699930/888800 78.75%] train loss: 1.4683136214443948e-05 \n",
      "epoch: 11 [701041/888800 78.88%] train loss: 1.580392381583806e-05 \n",
      "epoch: 11 [702152/888800 79.00%] train loss: 1.5179766705841757e-05 \n",
      "epoch: 11 [703263/888800 79.12%] train loss: 1.500637699791696e-05 \n",
      "epoch: 11 [704374/888800 79.25%] train loss: 1.2875767424702644e-05 \n",
      "epoch: 11 [705485/888800 79.38%] train loss: 1.5124109268072061e-05 \n",
      "epoch: 11 [706596/888800 79.50%] train loss: 1.4526433005812578e-05 \n",
      "epoch: 11 [707707/888800 79.62%] train loss: 1.504076317360159e-05 \n",
      "epoch: 11 [708818/888800 79.75%] train loss: 1.7052636394510046e-05 \n",
      "epoch: 11 [709929/888800 79.88%] train loss: 1.448749299015617e-05 \n",
      "epoch: 11 [711040/888800 80.00%] train loss: 1.4955588994780555e-05 \n",
      "epoch: 11 [712151/888800 80.12%] train loss: 1.6037063687690534e-05 \n",
      "epoch: 11 [713262/888800 80.25%] train loss: 1.5468587662326172e-05 \n",
      "epoch: 11 [714373/888800 80.38%] train loss: 1.5870602510403842e-05 \n",
      "epoch: 11 [715484/888800 80.50%] train loss: 1.444178087695036e-05 \n",
      "epoch: 11 [716595/888800 80.62%] train loss: 1.6422221960965544e-05 \n",
      "epoch: 11 [717706/888800 80.75%] train loss: 1.522809725429397e-05 \n",
      "epoch: 11 [718817/888800 80.88%] train loss: 1.43786519402056e-05 \n",
      "epoch: 11 [719928/888800 81.00%] train loss: 1.4486168765870389e-05 \n",
      "epoch: 11 [721039/888800 81.12%] train loss: 1.408971547789406e-05 \n",
      "epoch: 11 [722150/888800 81.25%] train loss: 1.4036642824066803e-05 \n",
      "epoch: 11 [723261/888800 81.38%] train loss: 1.458488895877963e-05 \n",
      "epoch: 11 [724372/888800 81.50%] train loss: 1.3929261513112579e-05 \n",
      "epoch: 11 [725483/888800 81.62%] train loss: 1.4769469089515042e-05 \n",
      "epoch: 11 [726594/888800 81.75%] train loss: 1.529775545350276e-05 \n",
      "epoch: 11 [727705/888800 81.88%] train loss: 1.5192129467322957e-05 \n",
      "epoch: 11 [728816/888800 82.00%] train loss: 1.4671772987639997e-05 \n",
      "epoch: 11 [729927/888800 82.12%] train loss: 1.4750648006156553e-05 \n",
      "epoch: 11 [731038/888800 82.25%] train loss: 1.3772531019640155e-05 \n",
      "epoch: 11 [732149/888800 82.38%] train loss: 1.4955327060306445e-05 \n",
      "epoch: 11 [733260/888800 82.50%] train loss: 1.4516674127662554e-05 \n",
      "epoch: 11 [734371/888800 82.62%] train loss: 1.5253743185894564e-05 \n",
      "epoch: 11 [735482/888800 82.75%] train loss: 1.7016114725265652e-05 \n",
      "epoch: 11 [736593/888800 82.88%] train loss: 1.589374187460635e-05 \n",
      "epoch: 11 [737704/888800 83.00%] train loss: 1.653725848882459e-05 \n",
      "epoch: 11 [738815/888800 83.12%] train loss: 1.3782729183731135e-05 \n",
      "epoch: 11 [739926/888800 83.25%] train loss: 1.4890507372911088e-05 \n",
      "epoch: 11 [741037/888800 83.38%] train loss: 1.6999787476379424e-05 \n",
      "epoch: 11 [742148/888800 83.50%] train loss: 1.602283191459719e-05 \n",
      "epoch: 11 [743259/888800 83.62%] train loss: 1.4892297258484177e-05 \n",
      "epoch: 11 [744370/888800 83.75%] train loss: 1.3632631635118742e-05 \n",
      "epoch: 11 [745481/888800 83.88%] train loss: 1.557752511871513e-05 \n",
      "epoch: 11 [746592/888800 84.00%] train loss: 1.6198549928958528e-05 \n",
      "epoch: 11 [747703/888800 84.12%] train loss: 1.5709438230260275e-05 \n",
      "epoch: 11 [748814/888800 84.25%] train loss: 1.571271423017606e-05 \n",
      "epoch: 11 [749925/888800 84.38%] train loss: 1.5445986718987115e-05 \n",
      "epoch: 11 [751036/888800 84.50%] train loss: 1.449366936867591e-05 \n",
      "epoch: 11 [752147/888800 84.62%] train loss: 1.5247078408719972e-05 \n",
      "epoch: 11 [753258/888800 84.75%] train loss: 1.3726647011935711e-05 \n",
      "epoch: 11 [754369/888800 84.88%] train loss: 1.4434628610615619e-05 \n",
      "epoch: 11 [755480/888800 85.00%] train loss: 1.4092077435634565e-05 \n",
      "epoch: 11 [756591/888800 85.12%] train loss: 1.3460251466312911e-05 \n",
      "epoch: 11 [757702/888800 85.25%] train loss: 1.4682038454338908e-05 \n",
      "epoch: 11 [758813/888800 85.38%] train loss: 1.432216686225729e-05 \n",
      "epoch: 11 [759924/888800 85.50%] train loss: 1.4438883226830512e-05 \n",
      "epoch: 11 [761035/888800 85.62%] train loss: 1.4266694961406756e-05 \n",
      "epoch: 11 [762146/888800 85.75%] train loss: 1.559080192237161e-05 \n",
      "epoch: 11 [763257/888800 85.88%] train loss: 1.3403443517745472e-05 \n",
      "epoch: 11 [764368/888800 86.00%] train loss: 1.532307760498952e-05 \n",
      "epoch: 11 [765479/888800 86.12%] train loss: 1.55616071424447e-05 \n",
      "epoch: 11 [766590/888800 86.25%] train loss: 1.3285488421388436e-05 \n",
      "epoch: 11 [767701/888800 86.38%] train loss: 1.3848776688973885e-05 \n",
      "epoch: 11 [768812/888800 86.50%] train loss: 1.3774107173958328e-05 \n",
      "epoch: 11 [769923/888800 86.62%] train loss: 1.4745093722012825e-05 \n",
      "epoch: 11 [771034/888800 86.75%] train loss: 1.56569712999044e-05 \n",
      "epoch: 11 [772145/888800 86.88%] train loss: 1.5298275684472173e-05 \n",
      "epoch: 11 [773256/888800 87.00%] train loss: 1.3413777196547017e-05 \n",
      "epoch: 11 [774367/888800 87.12%] train loss: 1.2696416888502426e-05 \n",
      "epoch: 11 [775478/888800 87.25%] train loss: 1.5653939044568688e-05 \n",
      "epoch: 11 [776589/888800 87.38%] train loss: 1.3923013284511399e-05 \n",
      "epoch: 11 [777700/888800 87.50%] train loss: 1.4621988157159649e-05 \n",
      "epoch: 11 [778811/888800 87.62%] train loss: 1.4855375411571003e-05 \n",
      "epoch: 11 [779922/888800 87.75%] train loss: 1.428318955731811e-05 \n",
      "epoch: 11 [781033/888800 87.88%] train loss: 1.3408691302174702e-05 \n",
      "epoch: 11 [782144/888800 88.00%] train loss: 1.364314175589243e-05 \n",
      "epoch: 11 [783255/888800 88.12%] train loss: 1.5506246199947782e-05 \n",
      "epoch: 11 [784366/888800 88.25%] train loss: 1.5918687495286576e-05 \n",
      "epoch: 11 [785477/888800 88.38%] train loss: 1.535491355753038e-05 \n",
      "epoch: 11 [786588/888800 88.50%] train loss: 1.5070929293869995e-05 \n",
      "epoch: 11 [787699/888800 88.62%] train loss: 1.590693682373967e-05 \n",
      "epoch: 11 [788810/888800 88.75%] train loss: 1.5129775420064107e-05 \n",
      "epoch: 11 [789921/888800 88.88%] train loss: 1.599825372977648e-05 \n",
      "epoch: 11 [791032/888800 89.00%] train loss: 1.619119029783178e-05 \n",
      "epoch: 11 [792143/888800 89.12%] train loss: 1.2493414942582604e-05 \n",
      "epoch: 11 [793254/888800 89.25%] train loss: 1.4334409570437856e-05 \n",
      "epoch: 11 [794365/888800 89.38%] train loss: 1.3781528650724795e-05 \n",
      "epoch: 11 [795476/888800 89.50%] train loss: 1.438242725271266e-05 \n",
      "epoch: 11 [796587/888800 89.62%] train loss: 1.5552961485809647e-05 \n",
      "epoch: 11 [797698/888800 89.75%] train loss: 1.522983075119555e-05 \n",
      "epoch: 11 [798809/888800 89.88%] train loss: 1.4405894035007805e-05 \n",
      "epoch: 11 [799920/888800 90.00%] train loss: 1.4519589058181737e-05 \n",
      "epoch: 11 [801031/888800 90.12%] train loss: 1.4250776075641625e-05 \n",
      "epoch: 11 [802142/888800 90.25%] train loss: 1.5475554391741753e-05 \n",
      "epoch: 11 [803253/888800 90.38%] train loss: 1.536594754725229e-05 \n",
      "epoch: 11 [804364/888800 90.50%] train loss: 1.4226738130673766e-05 \n",
      "epoch: 11 [805475/888800 90.62%] train loss: 1.4315709449874703e-05 \n",
      "epoch: 11 [806586/888800 90.75%] train loss: 1.4433493561227806e-05 \n",
      "epoch: 11 [807697/888800 90.88%] train loss: 1.5042829545564018e-05 \n",
      "epoch: 11 [808808/888800 91.00%] train loss: 1.4747093700862024e-05 \n",
      "epoch: 11 [809919/888800 91.12%] train loss: 1.482199331803713e-05 \n",
      "epoch: 11 [811030/888800 91.25%] train loss: 1.5735891793156043e-05 \n",
      "epoch: 11 [812141/888800 91.38%] train loss: 1.4574776287190616e-05 \n",
      "epoch: 11 [813252/888800 91.50%] train loss: 1.515414896857692e-05 \n",
      "epoch: 11 [814363/888800 91.62%] train loss: 1.4880506569170393e-05 \n",
      "epoch: 11 [815474/888800 91.75%] train loss: 1.362156581308227e-05 \n",
      "epoch: 11 [816585/888800 91.88%] train loss: 1.341695951850852e-05 \n",
      "epoch: 11 [817696/888800 92.00%] train loss: 1.48698909470113e-05 \n",
      "epoch: 11 [818807/888800 92.12%] train loss: 1.5023447303974535e-05 \n",
      "epoch: 11 [819918/888800 92.25%] train loss: 1.596576657902915e-05 \n",
      "epoch: 11 [821029/888800 92.38%] train loss: 1.434831847291207e-05 \n",
      "epoch: 11 [822140/888800 92.50%] train loss: 1.37819934025174e-05 \n",
      "epoch: 11 [823251/888800 92.62%] train loss: 1.528740904177539e-05 \n",
      "epoch: 11 [824362/888800 92.75%] train loss: 1.3386140381044243e-05 \n",
      "epoch: 11 [825473/888800 92.88%] train loss: 1.5138571143324953e-05 \n",
      "epoch: 11 [826584/888800 93.00%] train loss: 1.4376650142366998e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 [827695/888800 93.12%] train loss: 1.4495810319203883e-05 \n",
      "epoch: 11 [828806/888800 93.25%] train loss: 1.4708214621350635e-05 \n",
      "epoch: 11 [829917/888800 93.38%] train loss: 1.502959548815852e-05 \n",
      "epoch: 11 [831028/888800 93.50%] train loss: 1.4136810023046564e-05 \n",
      "epoch: 11 [832139/888800 93.62%] train loss: 1.608322600077372e-05 \n",
      "epoch: 11 [833250/888800 93.75%] train loss: 1.4045227544556838e-05 \n",
      "epoch: 11 [834361/888800 93.88%] train loss: 1.5005436580395326e-05 \n",
      "epoch: 11 [835472/888800 94.00%] train loss: 1.642399001866579e-05 \n",
      "epoch: 11 [836583/888800 94.12%] train loss: 1.5639829143765382e-05 \n",
      "epoch: 11 [837694/888800 94.25%] train loss: 1.4062767149880528e-05 \n",
      "epoch: 11 [838805/888800 94.38%] train loss: 1.4943933820177335e-05 \n",
      "epoch: 11 [839916/888800 94.50%] train loss: 1.4412727978196926e-05 \n",
      "epoch: 11 [841027/888800 94.62%] train loss: 1.4926034964446444e-05 \n",
      "epoch: 11 [842138/888800 94.75%] train loss: 1.3666648555954453e-05 \n",
      "epoch: 11 [843249/888800 94.88%] train loss: 1.3815228157909587e-05 \n",
      "epoch: 11 [844360/888800 95.00%] train loss: 1.526314008515328e-05 \n",
      "epoch: 11 [845471/888800 95.12%] train loss: 1.4738156096427701e-05 \n",
      "epoch: 11 [846582/888800 95.25%] train loss: 1.4734375326952431e-05 \n",
      "epoch: 11 [847693/888800 95.38%] train loss: 1.4232093235477805e-05 \n",
      "epoch: 11 [848804/888800 95.50%] train loss: 1.3139038856024854e-05 \n",
      "epoch: 11 [849915/888800 95.62%] train loss: 1.3860387298336718e-05 \n",
      "epoch: 11 [851026/888800 95.75%] train loss: 1.5279849321814254e-05 \n",
      "epoch: 11 [852137/888800 95.88%] train loss: 1.5730553059256636e-05 \n",
      "epoch: 11 [853248/888800 96.00%] train loss: 1.3569898328569252e-05 \n",
      "epoch: 11 [854359/888800 96.12%] train loss: 1.6129602954606526e-05 \n",
      "epoch: 11 [855470/888800 96.25%] train loss: 1.5967647414072417e-05 \n",
      "epoch: 11 [856581/888800 96.38%] train loss: 1.584799974807538e-05 \n",
      "epoch: 11 [857692/888800 96.50%] train loss: 1.556383358547464e-05 \n",
      "epoch: 11 [858803/888800 96.62%] train loss: 1.6128700735862367e-05 \n",
      "epoch: 11 [859914/888800 96.75%] train loss: 1.4197326891007833e-05 \n",
      "epoch: 11 [861025/888800 96.88%] train loss: 1.5091924069565721e-05 \n",
      "epoch: 11 [862136/888800 97.00%] train loss: 1.5140835785132367e-05 \n",
      "epoch: 11 [863247/888800 97.12%] train loss: 1.3326100088306703e-05 \n",
      "epoch: 11 [864358/888800 97.25%] train loss: 1.6202471670112573e-05 \n",
      "epoch: 11 [865469/888800 97.38%] train loss: 1.4329680197988637e-05 \n",
      "epoch: 11 [866580/888800 97.50%] train loss: 1.538467222417239e-05 \n",
      "epoch: 11 [867691/888800 97.62%] train loss: 1.4056203326617833e-05 \n",
      "epoch: 11 [868802/888800 97.75%] train loss: 1.708391027932521e-05 \n",
      "epoch: 11 [869913/888800 97.88%] train loss: 1.3978517017676495e-05 \n",
      "epoch: 11 [871024/888800 98.00%] train loss: 1.48736362461932e-05 \n",
      "epoch: 11 [872135/888800 98.12%] train loss: 1.3603164916276e-05 \n",
      "epoch: 11 [873246/888800 98.25%] train loss: 1.3875717741029803e-05 \n",
      "epoch: 11 [874357/888800 98.38%] train loss: 1.5802326743141748e-05 \n",
      "epoch: 11 [875468/888800 98.50%] train loss: 1.4029681551619433e-05 \n",
      "epoch: 11 [876579/888800 98.62%] train loss: 1.4429223483602982e-05 \n",
      "epoch: 11 [877690/888800 98.75%] train loss: 1.5693836758146062e-05 \n",
      "epoch: 11 [878801/888800 98.88%] train loss: 1.4450661183218472e-05 \n",
      "epoch: 11 [879912/888800 99.00%] train loss: 1.5591214832966216e-05 \n",
      "epoch: 11 [881023/888800 99.12%] train loss: 1.5802001144038513e-05 \n",
      "epoch: 11 [882134/888800 99.25%] train loss: 1.5035696378618013e-05 \n",
      "epoch: 11 [883245/888800 99.38%] train loss: 1.3604848390968982e-05 \n",
      "epoch: 11 [884356/888800 99.50%] train loss: 1.5030037502583582e-05 \n",
      "epoch: 11 [885467/888800 99.62%] train loss: 1.4987111171649303e-05 \n",
      "epoch: 11 [886578/888800 99.75%] train loss: 1.3032507013122085e-05 \n",
      "epoch: 11 [887689/888800 99.88%] train loss: 1.5214315681078006e-05 \n",
      "epoch: 12 [0/888800 0.00%] train loss: 1.4680565072922036e-05 \n",
      "epoch: 12 [1111/888800 0.12%] train loss: 1.4205034858605359e-05 \n",
      "epoch: 12 [2222/888800 0.25%] train loss: 1.4474912859441247e-05 \n",
      "epoch: 12 [3333/888800 0.38%] train loss: 1.3680941265192814e-05 \n",
      "epoch: 12 [4444/888800 0.50%] train loss: 1.5169157450145576e-05 \n",
      "epoch: 12 [5555/888800 0.62%] train loss: 1.4386384464160074e-05 \n",
      "epoch: 12 [6666/888800 0.75%] train loss: 1.522726051916834e-05 \n",
      "epoch: 12 [7777/888800 0.88%] train loss: 1.3884460713597946e-05 \n",
      "epoch: 12 [8888/888800 1.00%] train loss: 1.4166873370413668e-05 \n",
      "epoch: 12 [9999/888800 1.12%] train loss: 1.4966428352636285e-05 \n",
      "epoch: 12 [11110/888800 1.25%] train loss: 1.3668495739693753e-05 \n",
      "epoch: 12 [12221/888800 1.38%] train loss: 1.4432609532377683e-05 \n",
      "epoch: 12 [13332/888800 1.50%] train loss: 1.5625333617208526e-05 \n",
      "epoch: 12 [14443/888800 1.62%] train loss: 1.4625988114858046e-05 \n",
      "epoch: 12 [15554/888800 1.75%] train loss: 1.4124570952844806e-05 \n",
      "epoch: 12 [16665/888800 1.88%] train loss: 1.4192373782861978e-05 \n",
      "epoch: 12 [17776/888800 2.00%] train loss: 1.563800651638303e-05 \n",
      "epoch: 12 [18887/888800 2.12%] train loss: 1.58709408424329e-05 \n",
      "epoch: 12 [19998/888800 2.25%] train loss: 1.4140738130663522e-05 \n",
      "epoch: 12 [21109/888800 2.38%] train loss: 1.5352890841313638e-05 \n",
      "epoch: 12 [22220/888800 2.50%] train loss: 1.4484160601568874e-05 \n",
      "epoch: 12 [23331/888800 2.62%] train loss: 1.4343434486363549e-05 \n",
      "epoch: 12 [24442/888800 2.75%] train loss: 1.5660109056625515e-05 \n",
      "epoch: 12 [25553/888800 2.88%] train loss: 1.5171039194683544e-05 \n",
      "epoch: 12 [26664/888800 3.00%] train loss: 1.4923090930096805e-05 \n",
      "epoch: 12 [27775/888800 3.12%] train loss: 1.3555140867538285e-05 \n",
      "epoch: 12 [28886/888800 3.25%] train loss: 1.4870423910906538e-05 \n",
      "epoch: 12 [29997/888800 3.38%] train loss: 1.2971235264558345e-05 \n",
      "epoch: 12 [31108/888800 3.50%] train loss: 1.5138017261051573e-05 \n",
      "epoch: 12 [32219/888800 3.62%] train loss: 1.3895592928747647e-05 \n",
      "epoch: 12 [33330/888800 3.75%] train loss: 1.4909016499586869e-05 \n",
      "epoch: 12 [34441/888800 3.88%] train loss: 1.4364126400323585e-05 \n",
      "epoch: 12 [35552/888800 4.00%] train loss: 1.4772355825698469e-05 \n",
      "epoch: 12 [36663/888800 4.12%] train loss: 1.4093558093009051e-05 \n",
      "epoch: 12 [37774/888800 4.25%] train loss: 1.394052742398344e-05 \n",
      "epoch: 12 [38885/888800 4.38%] train loss: 1.557339601276908e-05 \n",
      "epoch: 12 [39996/888800 4.50%] train loss: 1.558169606141746e-05 \n",
      "epoch: 12 [41107/888800 4.62%] train loss: 1.5612225979566574e-05 \n",
      "epoch: 12 [42218/888800 4.75%] train loss: 1.5398898540297523e-05 \n",
      "epoch: 12 [43329/888800 4.88%] train loss: 1.4160756109049544e-05 \n",
      "epoch: 12 [44440/888800 5.00%] train loss: 1.4747473869647365e-05 \n",
      "epoch: 12 [45551/888800 5.12%] train loss: 1.501338010712061e-05 \n",
      "epoch: 12 [46662/888800 5.25%] train loss: 1.3228155694378074e-05 \n",
      "epoch: 12 [47773/888800 5.38%] train loss: 1.3854254575562663e-05 \n",
      "epoch: 12 [48884/888800 5.50%] train loss: 1.3530906471714843e-05 \n",
      "epoch: 12 [49995/888800 5.62%] train loss: 1.3642928934132215e-05 \n",
      "epoch: 12 [51106/888800 5.75%] train loss: 1.3966806363896467e-05 \n",
      "epoch: 12 [52217/888800 5.88%] train loss: 1.3597201359516475e-05 \n",
      "epoch: 12 [53328/888800 6.00%] train loss: 1.4539654330292251e-05 \n",
      "epoch: 12 [54439/888800 6.12%] train loss: 1.445646739739459e-05 \n",
      "epoch: 12 [55550/888800 6.25%] train loss: 1.4292358173406683e-05 \n",
      "epoch: 12 [56661/888800 6.38%] train loss: 1.5216657629935071e-05 \n",
      "epoch: 12 [57772/888800 6.50%] train loss: 1.54337703861529e-05 \n",
      "epoch: 12 [58883/888800 6.62%] train loss: 1.4764418665436096e-05 \n",
      "epoch: 12 [59994/888800 6.75%] train loss: 1.45490157592576e-05 \n",
      "epoch: 12 [61105/888800 6.88%] train loss: 1.4920921785233077e-05 \n",
      "epoch: 12 [62216/888800 7.00%] train loss: 1.579836316523142e-05 \n",
      "epoch: 12 [63327/888800 7.12%] train loss: 1.5920015357551165e-05 \n",
      "epoch: 12 [64438/888800 7.25%] train loss: 1.4758601537323557e-05 \n",
      "epoch: 12 [65549/888800 7.38%] train loss: 1.6612930267001502e-05 \n",
      "epoch: 12 [66660/888800 7.50%] train loss: 1.4766615095140878e-05 \n",
      "epoch: 12 [67771/888800 7.62%] train loss: 1.5140411960601341e-05 \n",
      "epoch: 12 [68882/888800 7.75%] train loss: 1.6344361938536167e-05 \n",
      "epoch: 12 [69993/888800 7.88%] train loss: 1.591419095348101e-05 \n",
      "epoch: 12 [71104/888800 8.00%] train loss: 1.6052781575126573e-05 \n",
      "epoch: 12 [72215/888800 8.12%] train loss: 1.4707177797390614e-05 \n",
      "epoch: 12 [73326/888800 8.25%] train loss: 1.4938994354452007e-05 \n",
      "epoch: 12 [74437/888800 8.38%] train loss: 1.3679768017027527e-05 \n",
      "epoch: 12 [75548/888800 8.50%] train loss: 1.447292379452847e-05 \n",
      "epoch: 12 [76659/888800 8.62%] train loss: 1.540356970508583e-05 \n",
      "epoch: 12 [77770/888800 8.75%] train loss: 1.4045714124222286e-05 \n",
      "epoch: 12 [78881/888800 8.88%] train loss: 1.6408428564318456e-05 \n",
      "epoch: 12 [79992/888800 9.00%] train loss: 1.3457856766763143e-05 \n",
      "epoch: 12 [81103/888800 9.12%] train loss: 1.463265380152734e-05 \n",
      "epoch: 12 [82214/888800 9.25%] train loss: 1.4150963579595555e-05 \n",
      "epoch: 12 [83325/888800 9.38%] train loss: 1.5186181371973362e-05 \n",
      "epoch: 12 [84436/888800 9.50%] train loss: 1.4098331121203955e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [85547/888800 9.62%] train loss: 1.4680702406622004e-05 \n",
      "epoch: 12 [86658/888800 9.75%] train loss: 1.4605398064304609e-05 \n",
      "epoch: 12 [87769/888800 9.88%] train loss: 1.4726221706951037e-05 \n",
      "epoch: 12 [88880/888800 10.00%] train loss: 1.403269652655581e-05 \n",
      "epoch: 12 [89991/888800 10.12%] train loss: 1.5333600458689034e-05 \n",
      "epoch: 12 [91102/888800 10.25%] train loss: 1.4605200703954324e-05 \n",
      "epoch: 12 [92213/888800 10.38%] train loss: 1.538417927804403e-05 \n",
      "epoch: 12 [93324/888800 10.50%] train loss: 1.4845201803836972e-05 \n",
      "epoch: 12 [94435/888800 10.62%] train loss: 1.3653539099323098e-05 \n",
      "epoch: 12 [95546/888800 10.75%] train loss: 1.3552643395087216e-05 \n",
      "epoch: 12 [96657/888800 10.88%] train loss: 1.2672078810282983e-05 \n",
      "epoch: 12 [97768/888800 11.00%] train loss: 1.3748129276791587e-05 \n",
      "epoch: 12 [98879/888800 11.12%] train loss: 1.566437458677683e-05 \n",
      "epoch: 12 [99990/888800 11.25%] train loss: 1.577127113705501e-05 \n",
      "epoch: 12 [101101/888800 11.38%] train loss: 1.3273925105750095e-05 \n",
      "epoch: 12 [102212/888800 11.50%] train loss: 1.3851527910446748e-05 \n",
      "epoch: 12 [103323/888800 11.62%] train loss: 1.3633506569021847e-05 \n",
      "epoch: 12 [104434/888800 11.75%] train loss: 1.6641150068608113e-05 \n",
      "epoch: 12 [105545/888800 11.88%] train loss: 1.363793035125127e-05 \n",
      "epoch: 12 [106656/888800 12.00%] train loss: 1.5128635823202785e-05 \n",
      "epoch: 12 [107767/888800 12.12%] train loss: 1.4803939848206937e-05 \n",
      "epoch: 12 [108878/888800 12.25%] train loss: 1.7072754417313263e-05 \n",
      "epoch: 12 [109989/888800 12.38%] train loss: 1.50797040987527e-05 \n",
      "epoch: 12 [111100/888800 12.50%] train loss: 1.6809377484605648e-05 \n",
      "epoch: 12 [112211/888800 12.62%] train loss: 1.362966031592805e-05 \n",
      "epoch: 12 [113322/888800 12.75%] train loss: 1.606173100299202e-05 \n",
      "epoch: 12 [114433/888800 12.88%] train loss: 1.3964133358967956e-05 \n",
      "epoch: 12 [115544/888800 13.00%] train loss: 1.6333091480191797e-05 \n",
      "epoch: 12 [116655/888800 13.12%] train loss: 1.4543523320753593e-05 \n",
      "epoch: 12 [117766/888800 13.25%] train loss: 1.4768797882425133e-05 \n",
      "epoch: 12 [118877/888800 13.38%] train loss: 1.658285327721387e-05 \n",
      "epoch: 12 [119988/888800 13.50%] train loss: 1.5444069504155777e-05 \n",
      "epoch: 12 [121099/888800 13.62%] train loss: 1.4160318642097991e-05 \n",
      "epoch: 12 [122210/888800 13.75%] train loss: 1.5283532775356434e-05 \n",
      "epoch: 12 [123321/888800 13.88%] train loss: 1.416970553691499e-05 \n",
      "epoch: 12 [124432/888800 14.00%] train loss: 1.4465355889115017e-05 \n",
      "epoch: 12 [125543/888800 14.12%] train loss: 1.4112927601672709e-05 \n",
      "epoch: 12 [126654/888800 14.25%] train loss: 1.4848313185211737e-05 \n",
      "epoch: 12 [127765/888800 14.38%] train loss: 1.5208154763968196e-05 \n",
      "epoch: 12 [128876/888800 14.50%] train loss: 1.4644429938925896e-05 \n",
      "epoch: 12 [129987/888800 14.62%] train loss: 1.3745747310167644e-05 \n",
      "epoch: 12 [131098/888800 14.75%] train loss: 1.5144048120419029e-05 \n",
      "epoch: 12 [132209/888800 14.88%] train loss: 1.51272070070263e-05 \n",
      "epoch: 12 [133320/888800 15.00%] train loss: 1.4969074982218444e-05 \n",
      "epoch: 12 [134431/888800 15.12%] train loss: 1.546621206216514e-05 \n",
      "epoch: 12 [135542/888800 15.25%] train loss: 1.5040294783830177e-05 \n",
      "epoch: 12 [136653/888800 15.38%] train loss: 1.5310650269384496e-05 \n",
      "epoch: 12 [137764/888800 15.50%] train loss: 1.4486244253930636e-05 \n",
      "epoch: 12 [138875/888800 15.62%] train loss: 1.5024186723167077e-05 \n",
      "epoch: 12 [139986/888800 15.75%] train loss: 1.472995245421771e-05 \n",
      "epoch: 12 [141097/888800 15.88%] train loss: 1.5248361705744173e-05 \n",
      "epoch: 12 [142208/888800 16.00%] train loss: 1.2968002010893542e-05 \n",
      "epoch: 12 [143319/888800 16.12%] train loss: 1.5497578715439886e-05 \n",
      "epoch: 12 [144430/888800 16.25%] train loss: 1.4037152141099796e-05 \n",
      "epoch: 12 [145541/888800 16.38%] train loss: 1.4200384612195194e-05 \n",
      "epoch: 12 [146652/888800 16.50%] train loss: 1.4536893104377668e-05 \n",
      "epoch: 12 [147763/888800 16.62%] train loss: 1.4649733202531934e-05 \n",
      "epoch: 12 [148874/888800 16.75%] train loss: 1.496301956649404e-05 \n",
      "epoch: 12 [149985/888800 16.88%] train loss: 1.4203925275069196e-05 \n",
      "epoch: 12 [151096/888800 17.00%] train loss: 1.337897811026778e-05 \n",
      "epoch: 12 [152207/888800 17.12%] train loss: 1.4431989256991073e-05 \n",
      "epoch: 12 [153318/888800 17.25%] train loss: 1.5465588148799725e-05 \n",
      "epoch: 12 [154429/888800 17.38%] train loss: 1.4361121429828927e-05 \n",
      "epoch: 12 [155540/888800 17.50%] train loss: 1.3923326150688808e-05 \n",
      "epoch: 12 [156651/888800 17.62%] train loss: 1.3851129551767372e-05 \n",
      "epoch: 12 [157762/888800 17.75%] train loss: 1.3960738215246238e-05 \n",
      "epoch: 12 [158873/888800 17.88%] train loss: 1.525269999547163e-05 \n",
      "epoch: 12 [159984/888800 18.00%] train loss: 1.607694139238447e-05 \n",
      "epoch: 12 [161095/888800 18.12%] train loss: 1.5238528249028604e-05 \n",
      "epoch: 12 [162206/888800 18.25%] train loss: 1.5144417375267949e-05 \n",
      "epoch: 12 [163317/888800 18.38%] train loss: 1.3594903975899797e-05 \n",
      "epoch: 12 [164428/888800 18.50%] train loss: 1.5585730579914525e-05 \n",
      "epoch: 12 [165539/888800 18.62%] train loss: 1.6349109500879422e-05 \n",
      "epoch: 12 [166650/888800 18.75%] train loss: 1.3784629118163139e-05 \n",
      "epoch: 12 [167761/888800 18.88%] train loss: 1.5366253137472086e-05 \n",
      "epoch: 12 [168872/888800 19.00%] train loss: 1.3056949683232233e-05 \n",
      "epoch: 12 [169983/888800 19.12%] train loss: 1.4708934941154439e-05 \n",
      "epoch: 12 [171094/888800 19.25%] train loss: 1.3721078175876755e-05 \n",
      "epoch: 12 [172205/888800 19.38%] train loss: 1.3348464563023299e-05 \n",
      "epoch: 12 [173316/888800 19.50%] train loss: 1.3962225239083637e-05 \n",
      "epoch: 12 [174427/888800 19.62%] train loss: 1.3400007446762174e-05 \n",
      "epoch: 12 [175538/888800 19.75%] train loss: 1.572388100612443e-05 \n",
      "epoch: 12 [176649/888800 19.88%] train loss: 1.4410225048777647e-05 \n",
      "epoch: 12 [177760/888800 20.00%] train loss: 1.3221750123193488e-05 \n",
      "epoch: 12 [178871/888800 20.12%] train loss: 1.4981240383349359e-05 \n",
      "epoch: 12 [179982/888800 20.25%] train loss: 1.471861560276011e-05 \n",
      "epoch: 12 [181093/888800 20.38%] train loss: 1.4273203305492643e-05 \n",
      "epoch: 12 [182204/888800 20.50%] train loss: 1.3309765563462861e-05 \n",
      "epoch: 12 [183315/888800 20.62%] train loss: 1.3406875950749964e-05 \n",
      "epoch: 12 [184426/888800 20.75%] train loss: 1.3302110346558038e-05 \n",
      "epoch: 12 [185537/888800 20.88%] train loss: 1.4332338651001919e-05 \n",
      "epoch: 12 [186648/888800 21.00%] train loss: 1.5231777069857344e-05 \n",
      "epoch: 12 [187759/888800 21.12%] train loss: 1.3931710782344453e-05 \n",
      "epoch: 12 [188870/888800 21.25%] train loss: 1.308888204221148e-05 \n",
      "epoch: 12 [189981/888800 21.38%] train loss: 1.4894761989125982e-05 \n",
      "epoch: 12 [191092/888800 21.50%] train loss: 1.5797775631654076e-05 \n",
      "epoch: 12 [192203/888800 21.62%] train loss: 1.4498696145892609e-05 \n",
      "epoch: 12 [193314/888800 21.75%] train loss: 1.4374344573298004e-05 \n",
      "epoch: 12 [194425/888800 21.88%] train loss: 1.44090208777925e-05 \n",
      "epoch: 12 [195536/888800 22.00%] train loss: 1.4130534509604331e-05 \n",
      "epoch: 12 [196647/888800 22.12%] train loss: 1.5108445040823426e-05 \n",
      "epoch: 12 [197758/888800 22.25%] train loss: 1.3387453691393603e-05 \n",
      "epoch: 12 [198869/888800 22.38%] train loss: 1.3777454114460852e-05 \n",
      "epoch: 12 [199980/888800 22.50%] train loss: 1.4575559362128843e-05 \n",
      "epoch: 12 [201091/888800 22.62%] train loss: 1.4661029126727954e-05 \n",
      "epoch: 12 [202202/888800 22.75%] train loss: 1.5489918951061554e-05 \n",
      "epoch: 12 [203313/888800 22.88%] train loss: 1.4227739484340418e-05 \n",
      "epoch: 12 [204424/888800 23.00%] train loss: 1.4045171155885328e-05 \n",
      "epoch: 12 [205535/888800 23.12%] train loss: 1.369157325825654e-05 \n",
      "epoch: 12 [206646/888800 23.25%] train loss: 1.4658112377219368e-05 \n",
      "epoch: 12 [207757/888800 23.38%] train loss: 1.2850540770159569e-05 \n",
      "epoch: 12 [208868/888800 23.50%] train loss: 1.6011552361305803e-05 \n",
      "epoch: 12 [209979/888800 23.62%] train loss: 1.3948582818557043e-05 \n",
      "epoch: 12 [211090/888800 23.75%] train loss: 1.460224848415237e-05 \n",
      "epoch: 12 [212201/888800 23.88%] train loss: 1.5651687135687098e-05 \n",
      "epoch: 12 [213312/888800 24.00%] train loss: 1.5170418919296935e-05 \n",
      "epoch: 12 [214423/888800 24.12%] train loss: 1.4394540812645573e-05 \n",
      "epoch: 12 [215534/888800 24.25%] train loss: 1.4217421266948804e-05 \n",
      "epoch: 12 [216645/888800 24.38%] train loss: 1.5172142411756795e-05 \n",
      "epoch: 12 [217756/888800 24.50%] train loss: 1.3878488971386105e-05 \n",
      "epoch: 12 [218867/888800 24.62%] train loss: 1.3468122233462054e-05 \n",
      "epoch: 12 [219978/888800 24.75%] train loss: 1.3171543287171517e-05 \n",
      "epoch: 12 [221089/888800 24.88%] train loss: 1.4449821719608735e-05 \n",
      "epoch: 12 [222200/888800 25.00%] train loss: 1.4325072697829455e-05 \n",
      "epoch: 12 [223311/888800 25.12%] train loss: 1.5884505046415143e-05 \n",
      "epoch: 12 [224422/888800 25.25%] train loss: 1.4893244951963425e-05 \n",
      "epoch: 12 [225533/888800 25.38%] train loss: 1.5905152395134792e-05 \n",
      "epoch: 12 [226644/888800 25.50%] train loss: 1.4703131455462426e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [227755/888800 25.62%] train loss: 1.5132500266190618e-05 \n",
      "epoch: 12 [228866/888800 25.75%] train loss: 1.4315449334389996e-05 \n",
      "epoch: 12 [229977/888800 25.88%] train loss: 1.4359190572577063e-05 \n",
      "epoch: 12 [231088/888800 26.00%] train loss: 1.4081061635806691e-05 \n",
      "epoch: 12 [232199/888800 26.12%] train loss: 1.5242454537656158e-05 \n",
      "epoch: 12 [233310/888800 26.25%] train loss: 1.578112096467521e-05 \n",
      "epoch: 12 [234421/888800 26.38%] train loss: 1.3982114069222007e-05 \n",
      "epoch: 12 [235532/888800 26.50%] train loss: 1.543724829389248e-05 \n",
      "epoch: 12 [236643/888800 26.62%] train loss: 1.3800504348182585e-05 \n",
      "epoch: 12 [237754/888800 26.75%] train loss: 1.6013778804335743e-05 \n",
      "epoch: 12 [238865/888800 26.88%] train loss: 1.5200535926851444e-05 \n",
      "epoch: 12 [239976/888800 27.00%] train loss: 1.518838598713046e-05 \n",
      "epoch: 12 [241087/888800 27.12%] train loss: 1.3652899724547751e-05 \n",
      "epoch: 12 [242198/888800 27.25%] train loss: 1.4987625945650507e-05 \n",
      "epoch: 12 [243309/888800 27.38%] train loss: 1.4601666407543235e-05 \n",
      "epoch: 12 [244420/888800 27.50%] train loss: 1.3999750080984086e-05 \n",
      "epoch: 12 [245531/888800 27.62%] train loss: 1.2940087799506728e-05 \n",
      "epoch: 12 [246642/888800 27.75%] train loss: 1.5176588021859061e-05 \n",
      "epoch: 12 [247753/888800 27.88%] train loss: 1.4540992196998559e-05 \n",
      "epoch: 12 [248864/888800 28.00%] train loss: 1.5200764210021589e-05 \n",
      "epoch: 12 [249975/888800 28.12%] train loss: 1.3869388567400165e-05 \n",
      "epoch: 12 [251086/888800 28.25%] train loss: 1.4275188732426614e-05 \n",
      "epoch: 12 [252197/888800 28.38%] train loss: 1.6694855730747804e-05 \n",
      "epoch: 12 [253308/888800 28.50%] train loss: 1.5013587471912615e-05 \n",
      "epoch: 12 [254419/888800 28.62%] train loss: 1.6163417967618443e-05 \n",
      "epoch: 12 [255530/888800 28.75%] train loss: 1.5181897651928011e-05 \n",
      "epoch: 12 [256641/888800 28.88%] train loss: 1.5091130990185775e-05 \n",
      "epoch: 12 [257752/888800 29.00%] train loss: 1.4729529539181385e-05 \n",
      "epoch: 12 [258863/888800 29.12%] train loss: 1.4700776773679536e-05 \n",
      "epoch: 12 [259974/888800 29.25%] train loss: 1.3945655155112036e-05 \n",
      "epoch: 12 [261085/888800 29.38%] train loss: 1.5707195416325703e-05 \n",
      "epoch: 12 [262196/888800 29.50%] train loss: 1.4404289686353877e-05 \n",
      "epoch: 12 [263307/888800 29.62%] train loss: 1.2573497770063113e-05 \n",
      "epoch: 12 [264418/888800 29.75%] train loss: 1.5684307072660886e-05 \n",
      "epoch: 12 [265529/888800 29.88%] train loss: 1.6484031220898032e-05 \n",
      "epoch: 12 [266640/888800 30.00%] train loss: 1.4499477401841432e-05 \n",
      "epoch: 12 [267751/888800 30.12%] train loss: 1.4595697393815499e-05 \n",
      "epoch: 12 [268862/888800 30.25%] train loss: 1.382593109156005e-05 \n",
      "epoch: 12 [269973/888800 30.38%] train loss: 1.5919524230412208e-05 \n",
      "epoch: 12 [271084/888800 30.50%] train loss: 1.3789172044198494e-05 \n",
      "epoch: 12 [272195/888800 30.62%] train loss: 1.758194230205845e-05 \n",
      "epoch: 12 [273306/888800 30.75%] train loss: 1.3615870557259768e-05 \n",
      "epoch: 12 [274417/888800 30.88%] train loss: 1.816426811274141e-05 \n",
      "epoch: 12 [275528/888800 31.00%] train loss: 1.551124114484992e-05 \n",
      "epoch: 12 [276639/888800 31.12%] train loss: 1.691880970611237e-05 \n",
      "epoch: 12 [277750/888800 31.25%] train loss: 1.3616536307381466e-05 \n",
      "epoch: 12 [278861/888800 31.38%] train loss: 1.4583097254217137e-05 \n",
      "epoch: 12 [279972/888800 31.50%] train loss: 1.4807497791480273e-05 \n",
      "epoch: 12 [281083/888800 31.62%] train loss: 1.504623651271686e-05 \n",
      "epoch: 12 [282194/888800 31.75%] train loss: 1.4160405953589361e-05 \n",
      "epoch: 12 [283305/888800 31.88%] train loss: 1.603897544555366e-05 \n",
      "epoch: 12 [284416/888800 32.00%] train loss: 1.3554725228459574e-05 \n",
      "epoch: 12 [285527/888800 32.12%] train loss: 1.5293024262064137e-05 \n",
      "epoch: 12 [286638/888800 32.25%] train loss: 1.4574482520401943e-05 \n",
      "epoch: 12 [287749/888800 32.38%] train loss: 1.4158162230160087e-05 \n",
      "epoch: 12 [288860/888800 32.50%] train loss: 1.5567438822472468e-05 \n",
      "epoch: 12 [289971/888800 32.62%] train loss: 1.4554247172782198e-05 \n",
      "epoch: 12 [291082/888800 32.75%] train loss: 1.440860523871379e-05 \n",
      "epoch: 12 [292193/888800 32.88%] train loss: 1.5619645637343638e-05 \n",
      "epoch: 12 [293304/888800 33.00%] train loss: 1.5151728803175502e-05 \n",
      "epoch: 12 [294415/888800 33.12%] train loss: 1.3719227354158647e-05 \n",
      "epoch: 12 [295526/888800 33.25%] train loss: 1.3834532182954717e-05 \n",
      "epoch: 12 [296637/888800 33.38%] train loss: 1.4366754840011708e-05 \n",
      "epoch: 12 [297748/888800 33.50%] train loss: 1.5002470718172844e-05 \n",
      "epoch: 12 [298859/888800 33.62%] train loss: 1.3378581570577808e-05 \n",
      "epoch: 12 [299970/888800 33.75%] train loss: 1.362379225611221e-05 \n",
      "epoch: 12 [301081/888800 33.88%] train loss: 1.4631978046963923e-05 \n",
      "epoch: 12 [302192/888800 34.00%] train loss: 1.4931597434042487e-05 \n",
      "epoch: 12 [303303/888800 34.12%] train loss: 1.3943948033556808e-05 \n",
      "epoch: 12 [304414/888800 34.25%] train loss: 1.4305654985946603e-05 \n",
      "epoch: 12 [305525/888800 34.38%] train loss: 1.5200875168375205e-05 \n",
      "epoch: 12 [306636/888800 34.50%] train loss: 1.337037974735722e-05 \n",
      "epoch: 12 [307747/888800 34.62%] train loss: 1.368705943605164e-05 \n",
      "epoch: 12 [308858/888800 34.75%] train loss: 1.4568418919225223e-05 \n",
      "epoch: 12 [309969/888800 34.88%] train loss: 1.405684815836139e-05 \n",
      "epoch: 12 [311080/888800 35.00%] train loss: 1.584928213560488e-05 \n",
      "epoch: 12 [312191/888800 35.12%] train loss: 1.5346113286796026e-05 \n",
      "epoch: 12 [313302/888800 35.25%] train loss: 1.3584008229372557e-05 \n",
      "epoch: 12 [314413/888800 35.38%] train loss: 1.5370735127362423e-05 \n",
      "epoch: 12 [315524/888800 35.50%] train loss: 1.5628786059096456e-05 \n",
      "epoch: 12 [316635/888800 35.62%] train loss: 1.471486029913649e-05 \n",
      "epoch: 12 [317746/888800 35.75%] train loss: 1.4731093870068435e-05 \n",
      "epoch: 12 [318857/888800 35.88%] train loss: 1.5136533875192981e-05 \n",
      "epoch: 12 [319968/888800 36.00%] train loss: 1.5263209206750616e-05 \n",
      "epoch: 12 [321079/888800 36.12%] train loss: 1.4456940334639512e-05 \n",
      "epoch: 12 [322190/888800 36.25%] train loss: 1.3871795999875758e-05 \n",
      "epoch: 12 [323301/888800 36.38%] train loss: 1.4070762517803814e-05 \n",
      "epoch: 12 [324412/888800 36.50%] train loss: 1.395634808432078e-05 \n",
      "epoch: 12 [325523/888800 36.62%] train loss: 1.536294621473644e-05 \n",
      "epoch: 12 [326634/888800 36.75%] train loss: 1.3538877283281181e-05 \n",
      "epoch: 12 [327745/888800 36.88%] train loss: 1.4311754057416692e-05 \n",
      "epoch: 12 [328856/888800 37.00%] train loss: 1.4585752978746314e-05 \n",
      "epoch: 12 [329967/888800 37.12%] train loss: 1.493077252234798e-05 \n",
      "epoch: 12 [331078/888800 37.25%] train loss: 1.584399797138758e-05 \n",
      "epoch: 12 [332189/888800 37.38%] train loss: 1.3351348570722621e-05 \n",
      "epoch: 12 [333300/888800 37.50%] train loss: 1.4194412869983353e-05 \n",
      "epoch: 12 [334411/888800 37.62%] train loss: 1.4411290976568125e-05 \n",
      "epoch: 12 [335522/888800 37.75%] train loss: 1.4192182788974606e-05 \n",
      "epoch: 12 [336633/888800 37.88%] train loss: 1.45102339956793e-05 \n",
      "epoch: 12 [337744/888800 38.00%] train loss: 1.4428066606342327e-05 \n",
      "epoch: 12 [338855/888800 38.12%] train loss: 1.5220354725897778e-05 \n",
      "epoch: 12 [339966/888800 38.25%] train loss: 1.3301129001774825e-05 \n",
      "epoch: 12 [341077/888800 38.38%] train loss: 1.3461188245855737e-05 \n",
      "epoch: 12 [342188/888800 38.50%] train loss: 1.5658006304875016e-05 \n",
      "epoch: 12 [343299/888800 38.62%] train loss: 1.4417149031942245e-05 \n",
      "epoch: 12 [344410/888800 38.75%] train loss: 1.3373936781135853e-05 \n",
      "epoch: 12 [345521/888800 38.88%] train loss: 1.5300447557820007e-05 \n",
      "epoch: 12 [346632/888800 39.00%] train loss: 1.4356483006849885e-05 \n",
      "epoch: 12 [347743/888800 39.12%] train loss: 1.6380268789362162e-05 \n",
      "epoch: 12 [348854/888800 39.25%] train loss: 1.2998573765798938e-05 \n",
      "epoch: 12 [349965/888800 39.38%] train loss: 1.5797775631654076e-05 \n",
      "epoch: 12 [351076/888800 39.50%] train loss: 1.4828034181846306e-05 \n",
      "epoch: 12 [352187/888800 39.62%] train loss: 1.580697971803602e-05 \n",
      "epoch: 12 [353298/888800 39.75%] train loss: 1.4211214875103906e-05 \n",
      "epoch: 12 [354409/888800 39.88%] train loss: 1.5646090105292387e-05 \n",
      "epoch: 12 [355520/888800 40.00%] train loss: 1.6066493117250502e-05 \n",
      "epoch: 12 [356631/888800 40.12%] train loss: 1.537103707960341e-05 \n",
      "epoch: 12 [357742/888800 40.25%] train loss: 1.5241222172335256e-05 \n",
      "epoch: 12 [358853/888800 40.38%] train loss: 1.4909768651705235e-05 \n",
      "epoch: 12 [359964/888800 40.50%] train loss: 1.7083497368730605e-05 \n",
      "epoch: 12 [361075/888800 40.62%] train loss: 1.6593172404100187e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [362186/888800 40.75%] train loss: 1.602777592779603e-05 \n",
      "epoch: 12 [363297/888800 40.88%] train loss: 1.6265423255390488e-05 \n",
      "epoch: 12 [364408/888800 41.00%] train loss: 1.643206451262813e-05 \n",
      "epoch: 12 [365519/888800 41.12%] train loss: 1.4414457837119699e-05 \n",
      "epoch: 12 [366630/888800 41.25%] train loss: 1.5109782907529734e-05 \n",
      "epoch: 12 [367741/888800 41.38%] train loss: 1.3452749954012688e-05 \n",
      "epoch: 12 [368852/888800 41.50%] train loss: 1.4994577213656157e-05 \n",
      "epoch: 12 [369963/888800 41.62%] train loss: 1.5694920875830576e-05 \n",
      "epoch: 12 [371074/888800 41.75%] train loss: 1.5476345652132295e-05 \n",
      "epoch: 12 [372185/888800 41.88%] train loss: 1.3900028534408193e-05 \n",
      "epoch: 12 [373296/888800 42.00%] train loss: 1.4648190699517727e-05 \n",
      "epoch: 12 [374407/888800 42.12%] train loss: 1.5200871530396398e-05 \n",
      "epoch: 12 [375518/888800 42.25%] train loss: 1.6062738723121583e-05 \n",
      "epoch: 12 [376629/888800 42.38%] train loss: 1.542068275739439e-05 \n",
      "epoch: 12 [377740/888800 42.50%] train loss: 1.5024456843093503e-05 \n",
      "epoch: 12 [378851/888800 42.62%] train loss: 1.448010607418837e-05 \n",
      "epoch: 12 [379962/888800 42.75%] train loss: 1.4325281881610863e-05 \n",
      "epoch: 12 [381073/888800 42.88%] train loss: 1.6407864677603357e-05 \n",
      "epoch: 12 [382184/888800 43.00%] train loss: 1.4570687199011445e-05 \n",
      "epoch: 12 [383295/888800 43.12%] train loss: 1.4115836165728979e-05 \n",
      "epoch: 12 [384406/888800 43.25%] train loss: 1.4849386388959829e-05 \n",
      "epoch: 12 [385517/888800 43.38%] train loss: 1.5257766790455207e-05 \n",
      "epoch: 12 [386628/888800 43.50%] train loss: 1.5031360817374662e-05 \n",
      "epoch: 12 [387739/888800 43.62%] train loss: 1.6215457435464486e-05 \n",
      "epoch: 12 [388850/888800 43.75%] train loss: 1.392537888023071e-05 \n",
      "epoch: 12 [389961/888800 43.88%] train loss: 1.3971278349345084e-05 \n",
      "epoch: 12 [391072/888800 44.00%] train loss: 1.4419785657082684e-05 \n",
      "epoch: 12 [392183/888800 44.12%] train loss: 1.4431127965508495e-05 \n",
      "epoch: 12 [393294/888800 44.25%] train loss: 1.3626853615278378e-05 \n",
      "epoch: 12 [394405/888800 44.38%] train loss: 1.509335470473161e-05 \n",
      "epoch: 12 [395516/888800 44.50%] train loss: 1.3593271432910115e-05 \n",
      "epoch: 12 [396627/888800 44.62%] train loss: 1.4270823157858104e-05 \n",
      "epoch: 12 [397738/888800 44.75%] train loss: 1.2388263712637126e-05 \n",
      "epoch: 12 [398849/888800 44.88%] train loss: 1.4122909306024667e-05 \n",
      "epoch: 12 [399960/888800 45.00%] train loss: 1.5287438145605847e-05 \n",
      "epoch: 12 [401071/888800 45.12%] train loss: 1.4793808986723889e-05 \n",
      "epoch: 12 [402182/888800 45.25%] train loss: 1.3026062333665323e-05 \n",
      "epoch: 12 [403293/888800 45.38%] train loss: 1.419129239366157e-05 \n",
      "epoch: 12 [404404/888800 45.50%] train loss: 1.3917954674980137e-05 \n",
      "epoch: 12 [405515/888800 45.62%] train loss: 1.609978062333539e-05 \n",
      "epoch: 12 [406626/888800 45.75%] train loss: 1.373275608784752e-05 \n",
      "epoch: 12 [407737/888800 45.88%] train loss: 1.4711979929415975e-05 \n",
      "epoch: 12 [408848/888800 46.00%] train loss: 1.548598811496049e-05 \n",
      "epoch: 12 [409959/888800 46.12%] train loss: 1.5537703802692704e-05 \n",
      "epoch: 12 [411070/888800 46.25%] train loss: 1.6004069038899615e-05 \n",
      "epoch: 12 [412181/888800 46.38%] train loss: 1.4873748114041518e-05 \n",
      "epoch: 12 [413292/888800 46.50%] train loss: 1.5139325114432722e-05 \n",
      "epoch: 12 [414403/888800 46.62%] train loss: 1.4689749150420539e-05 \n",
      "epoch: 12 [415514/888800 46.75%] train loss: 1.545197665109299e-05 \n",
      "epoch: 12 [416625/888800 46.88%] train loss: 1.4102000932325609e-05 \n",
      "epoch: 12 [417736/888800 47.00%] train loss: 1.4652975551143754e-05 \n",
      "epoch: 12 [418847/888800 47.12%] train loss: 1.3830236639478244e-05 \n",
      "epoch: 12 [419958/888800 47.25%] train loss: 1.3163273251848295e-05 \n",
      "epoch: 12 [421069/888800 47.38%] train loss: 1.552345565869473e-05 \n",
      "epoch: 12 [422180/888800 47.50%] train loss: 1.4253088011173531e-05 \n",
      "epoch: 12 [423291/888800 47.62%] train loss: 1.4109397852735128e-05 \n",
      "epoch: 12 [424402/888800 47.75%] train loss: 1.3612271686724853e-05 \n",
      "epoch: 12 [425513/888800 47.88%] train loss: 1.4277537957241293e-05 \n",
      "epoch: 12 [426624/888800 48.00%] train loss: 1.437641549273394e-05 \n",
      "epoch: 12 [427735/888800 48.12%] train loss: 1.321748368354747e-05 \n",
      "epoch: 12 [428846/888800 48.25%] train loss: 1.4532754903484602e-05 \n",
      "epoch: 12 [429957/888800 48.38%] train loss: 1.4519401702273171e-05 \n",
      "epoch: 12 [431068/888800 48.50%] train loss: 1.6623202100163326e-05 \n",
      "epoch: 12 [432179/888800 48.62%] train loss: 1.5088878171809483e-05 \n",
      "epoch: 12 [433290/888800 48.75%] train loss: 1.3738674169871956e-05 \n",
      "epoch: 12 [434401/888800 48.88%] train loss: 1.3372845387493726e-05 \n",
      "epoch: 12 [435512/888800 49.00%] train loss: 1.4810103493800852e-05 \n",
      "epoch: 12 [436623/888800 49.12%] train loss: 1.349218928226037e-05 \n",
      "epoch: 12 [437734/888800 49.25%] train loss: 1.5209190678433515e-05 \n",
      "epoch: 12 [438845/888800 49.38%] train loss: 1.55945926962886e-05 \n",
      "epoch: 12 [439956/888800 49.50%] train loss: 1.391664227412548e-05 \n",
      "epoch: 12 [441067/888800 49.62%] train loss: 1.5647978216293268e-05 \n",
      "epoch: 12 [442178/888800 49.75%] train loss: 1.425997197657125e-05 \n",
      "epoch: 12 [443289/888800 49.88%] train loss: 1.6152254829648882e-05 \n",
      "epoch: 12 [444400/888800 50.00%] train loss: 1.4220408957044128e-05 \n",
      "epoch: 12 [445511/888800 50.12%] train loss: 1.5063101272971835e-05 \n",
      "epoch: 12 [446622/888800 50.25%] train loss: 1.4229291082301643e-05 \n",
      "epoch: 12 [447733/888800 50.38%] train loss: 1.5385465303552337e-05 \n",
      "epoch: 12 [448844/888800 50.50%] train loss: 1.3603292245534249e-05 \n",
      "epoch: 12 [449955/888800 50.62%] train loss: 1.526422238384839e-05 \n",
      "epoch: 12 [451066/888800 50.75%] train loss: 1.3546142326958943e-05 \n",
      "epoch: 12 [452177/888800 50.88%] train loss: 1.4778215700061992e-05 \n",
      "epoch: 12 [453288/888800 51.00%] train loss: 1.4032120816409588e-05 \n",
      "epoch: 12 [454399/888800 51.12%] train loss: 1.3965132893645205e-05 \n",
      "epoch: 12 [455510/888800 51.25%] train loss: 1.4938089407223742e-05 \n",
      "epoch: 12 [456621/888800 51.38%] train loss: 1.4582145922759082e-05 \n",
      "epoch: 12 [457732/888800 51.50%] train loss: 1.2926342606078833e-05 \n",
      "epoch: 12 [458843/888800 51.62%] train loss: 1.3759440662397537e-05 \n",
      "epoch: 12 [459954/888800 51.75%] train loss: 1.4939319953555241e-05 \n",
      "epoch: 12 [461065/888800 51.88%] train loss: 1.4351736354001332e-05 \n",
      "epoch: 12 [462176/888800 52.00%] train loss: 1.4303101124824025e-05 \n",
      "epoch: 12 [463287/888800 52.12%] train loss: 1.518056342320051e-05 \n",
      "epoch: 12 [464398/888800 52.25%] train loss: 1.4659229236713145e-05 \n",
      "epoch: 12 [465509/888800 52.38%] train loss: 1.5677385817980394e-05 \n",
      "epoch: 12 [466620/888800 52.50%] train loss: 1.4716258192493115e-05 \n",
      "epoch: 12 [467731/888800 52.62%] train loss: 1.3279079212225042e-05 \n",
      "epoch: 12 [468842/888800 52.75%] train loss: 1.5000475286797155e-05 \n",
      "epoch: 12 [469953/888800 52.88%] train loss: 1.4884032680129167e-05 \n",
      "epoch: 12 [471064/888800 53.00%] train loss: 1.3953026609669905e-05 \n",
      "epoch: 12 [472175/888800 53.12%] train loss: 1.4228708096197806e-05 \n",
      "epoch: 12 [473286/888800 53.25%] train loss: 1.490372324042255e-05 \n",
      "epoch: 12 [474397/888800 53.38%] train loss: 1.4795441529713571e-05 \n",
      "epoch: 12 [475508/888800 53.50%] train loss: 1.4397008271771483e-05 \n",
      "epoch: 12 [476619/888800 53.62%] train loss: 1.386158328386955e-05 \n",
      "epoch: 12 [477730/888800 53.75%] train loss: 1.5045204236230347e-05 \n",
      "epoch: 12 [478841/888800 53.88%] train loss: 1.4245068086893298e-05 \n",
      "epoch: 12 [479952/888800 54.00%] train loss: 1.4841631127637811e-05 \n",
      "epoch: 12 [481063/888800 54.12%] train loss: 1.3655037037096918e-05 \n",
      "epoch: 12 [482174/888800 54.25%] train loss: 1.4122113498160616e-05 \n",
      "epoch: 12 [483285/888800 54.38%] train loss: 1.376913223793963e-05 \n",
      "epoch: 12 [484396/888800 54.50%] train loss: 1.4672304132545833e-05 \n",
      "epoch: 12 [485507/888800 54.62%] train loss: 1.4948661373637151e-05 \n",
      "epoch: 12 [486618/888800 54.75%] train loss: 1.4288392776506953e-05 \n",
      "epoch: 12 [487729/888800 54.88%] train loss: 1.5654348317184485e-05 \n",
      "epoch: 12 [488840/888800 55.00%] train loss: 1.3810892596666235e-05 \n",
      "epoch: 12 [489951/888800 55.12%] train loss: 1.477026307838969e-05 \n",
      "epoch: 12 [491062/888800 55.25%] train loss: 1.3584656699094921e-05 \n",
      "epoch: 12 [492173/888800 55.38%] train loss: 1.3703881450055633e-05 \n",
      "epoch: 12 [493284/888800 55.50%] train loss: 1.5349602108472027e-05 \n",
      "epoch: 12 [494395/888800 55.62%] train loss: 1.4621746231568977e-05 \n",
      "epoch: 12 [495506/888800 55.75%] train loss: 1.3296926226757932e-05 \n",
      "epoch: 12 [496617/888800 55.88%] train loss: 1.4599771930079442e-05 \n",
      "epoch: 12 [497728/888800 56.00%] train loss: 1.6420815882156603e-05 \n",
      "epoch: 12 [498839/888800 56.12%] train loss: 1.4166636901791207e-05 \n",
      "epoch: 12 [499950/888800 56.25%] train loss: 1.5158300811890513e-05 \n",
      "epoch: 12 [501061/888800 56.38%] train loss: 1.4475541320280172e-05 \n",
      "epoch: 12 [502172/888800 56.50%] train loss: 1.3934750313637778e-05 \n",
      "epoch: 12 [503283/888800 56.62%] train loss: 1.439948482584441e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [504394/888800 56.75%] train loss: 1.2726111890515313e-05 \n",
      "epoch: 12 [505505/888800 56.88%] train loss: 1.436183629266452e-05 \n",
      "epoch: 12 [506616/888800 57.00%] train loss: 1.4878610272717196e-05 \n",
      "epoch: 12 [507727/888800 57.12%] train loss: 1.4458160876529291e-05 \n",
      "epoch: 12 [508838/888800 57.25%] train loss: 1.4018460205988958e-05 \n",
      "epoch: 12 [509949/888800 57.38%] train loss: 1.305849764321465e-05 \n",
      "epoch: 12 [511060/888800 57.50%] train loss: 1.3632607078761794e-05 \n",
      "epoch: 12 [512171/888800 57.62%] train loss: 1.442976645193994e-05 \n",
      "epoch: 12 [513282/888800 57.75%] train loss: 1.3643658348883037e-05 \n",
      "epoch: 12 [514393/888800 57.88%] train loss: 1.4633534192398656e-05 \n",
      "epoch: 12 [515504/888800 58.00%] train loss: 1.5138594790187199e-05 \n",
      "epoch: 12 [516615/888800 58.12%] train loss: 1.3237421626399737e-05 \n",
      "epoch: 12 [517726/888800 58.25%] train loss: 1.2559352398966439e-05 \n",
      "epoch: 12 [518837/888800 58.38%] train loss: 1.4114830264588818e-05 \n",
      "epoch: 12 [519948/888800 58.50%] train loss: 1.4026472854311578e-05 \n",
      "epoch: 12 [521059/888800 58.62%] train loss: 1.4150825336400885e-05 \n",
      "epoch: 12 [522170/888800 58.75%] train loss: 1.4108192772255279e-05 \n",
      "epoch: 12 [523281/888800 58.88%] train loss: 1.4175082469591871e-05 \n",
      "epoch: 12 [524392/888800 59.00%] train loss: 1.5559106032014824e-05 \n",
      "epoch: 12 [525503/888800 59.12%] train loss: 1.533633803774137e-05 \n",
      "epoch: 12 [526614/888800 59.25%] train loss: 1.464922297600424e-05 \n",
      "epoch: 12 [527725/888800 59.38%] train loss: 1.4753145478607621e-05 \n",
      "epoch: 12 [528836/888800 59.50%] train loss: 1.380318462906871e-05 \n",
      "epoch: 12 [529947/888800 59.62%] train loss: 1.3679989024240058e-05 \n",
      "epoch: 12 [531058/888800 59.75%] train loss: 1.4733453099324834e-05 \n",
      "epoch: 12 [532169/888800 59.88%] train loss: 1.5231483303068671e-05 \n",
      "epoch: 12 [533280/888800 60.00%] train loss: 1.5600013284711167e-05 \n",
      "epoch: 12 [534391/888800 60.12%] train loss: 1.5234200873237569e-05 \n",
      "epoch: 12 [535502/888800 60.25%] train loss: 1.4814383575867396e-05 \n",
      "epoch: 12 [536613/888800 60.38%] train loss: 1.3469983969116583e-05 \n",
      "epoch: 12 [537724/888800 60.50%] train loss: 1.5006780813564546e-05 \n",
      "epoch: 12 [538835/888800 60.62%] train loss: 1.3520259017241187e-05 \n",
      "epoch: 12 [539946/888800 60.75%] train loss: 1.4218663636711426e-05 \n",
      "epoch: 12 [541057/888800 60.88%] train loss: 1.432260796718765e-05 \n",
      "epoch: 12 [542168/888800 61.00%] train loss: 1.3392173968895804e-05 \n",
      "epoch: 12 [543279/888800 61.12%] train loss: 1.4469752386503387e-05 \n",
      "epoch: 12 [544390/888800 61.25%] train loss: 1.2840664567193016e-05 \n",
      "epoch: 12 [545501/888800 61.38%] train loss: 1.348890600638697e-05 \n",
      "epoch: 12 [546612/888800 61.50%] train loss: 1.4209558685251977e-05 \n",
      "epoch: 12 [547723/888800 61.62%] train loss: 1.4173838280839846e-05 \n",
      "epoch: 12 [548834/888800 61.75%] train loss: 1.5260919099091552e-05 \n",
      "epoch: 12 [549945/888800 61.88%] train loss: 1.4282114534580614e-05 \n",
      "epoch: 12 [551056/888800 62.00%] train loss: 1.5348430679296143e-05 \n",
      "epoch: 12 [552167/888800 62.12%] train loss: 1.3989290891913697e-05 \n",
      "epoch: 12 [553278/888800 62.25%] train loss: 1.6784233594080433e-05 \n",
      "epoch: 12 [554389/888800 62.38%] train loss: 1.3701381249120459e-05 \n",
      "epoch: 12 [555500/888800 62.50%] train loss: 1.495927426731214e-05 \n",
      "epoch: 12 [556611/888800 62.62%] train loss: 1.479267575632548e-05 \n",
      "epoch: 12 [557722/888800 62.75%] train loss: 1.4102903151069768e-05 \n",
      "epoch: 12 [558833/888800 62.88%] train loss: 1.5340761819970794e-05 \n",
      "epoch: 12 [559944/888800 63.00%] train loss: 1.3770250006928109e-05 \n",
      "epoch: 12 [561055/888800 63.12%] train loss: 1.4715305951540358e-05 \n",
      "epoch: 12 [562166/888800 63.25%] train loss: 1.4186268344928976e-05 \n",
      "epoch: 12 [563277/888800 63.38%] train loss: 1.3702288015338127e-05 \n",
      "epoch: 12 [564388/888800 63.50%] train loss: 1.2990989489480853e-05 \n",
      "epoch: 12 [565499/888800 63.62%] train loss: 1.4274112800194416e-05 \n",
      "epoch: 12 [566610/888800 63.75%] train loss: 1.480549599364167e-05 \n",
      "epoch: 12 [567721/888800 63.88%] train loss: 1.458008227928076e-05 \n",
      "epoch: 12 [568832/888800 64.00%] train loss: 1.4808887499384582e-05 \n",
      "epoch: 12 [569943/888800 64.12%] train loss: 1.4871962775941938e-05 \n",
      "epoch: 12 [571054/888800 64.25%] train loss: 1.4319236470328178e-05 \n",
      "epoch: 12 [572165/888800 64.38%] train loss: 1.5872332369326614e-05 \n",
      "epoch: 12 [573276/888800 64.50%] train loss: 1.4742760868102778e-05 \n",
      "epoch: 12 [574387/888800 64.62%] train loss: 1.3124285032972693e-05 \n",
      "epoch: 12 [575498/888800 64.75%] train loss: 1.3483885595633183e-05 \n",
      "epoch: 12 [576609/888800 64.88%] train loss: 1.3974431567476131e-05 \n",
      "epoch: 12 [577720/888800 65.00%] train loss: 1.2464169230952393e-05 \n",
      "epoch: 12 [578831/888800 65.12%] train loss: 1.5165078366408125e-05 \n",
      "epoch: 12 [579942/888800 65.25%] train loss: 1.4696283869852778e-05 \n",
      "epoch: 12 [581053/888800 65.38%] train loss: 1.4719778846483678e-05 \n",
      "epoch: 12 [582164/888800 65.50%] train loss: 1.4820167962170672e-05 \n",
      "epoch: 12 [583275/888800 65.62%] train loss: 1.4636712876381353e-05 \n",
      "epoch: 12 [584386/888800 65.75%] train loss: 1.3348245374800172e-05 \n",
      "epoch: 12 [585497/888800 65.88%] train loss: 1.2625831914192531e-05 \n",
      "epoch: 12 [586608/888800 66.00%] train loss: 1.4430148439714685e-05 \n",
      "epoch: 12 [587719/888800 66.12%] train loss: 1.3743603631155565e-05 \n",
      "epoch: 12 [588830/888800 66.25%] train loss: 1.3646626939589623e-05 \n",
      "epoch: 12 [589941/888800 66.38%] train loss: 1.6745063476264477e-05 \n",
      "epoch: 12 [591052/888800 66.50%] train loss: 1.3588237379735801e-05 \n",
      "epoch: 12 [592163/888800 66.62%] train loss: 1.4865943740005605e-05 \n",
      "epoch: 12 [593274/888800 66.75%] train loss: 1.4507276318909135e-05 \n",
      "epoch: 12 [594385/888800 66.88%] train loss: 1.3553323697124142e-05 \n",
      "epoch: 12 [595496/888800 67.00%] train loss: 1.4790515706408769e-05 \n",
      "epoch: 12 [596607/888800 67.12%] train loss: 1.43138095154427e-05 \n",
      "epoch: 12 [597718/888800 67.25%] train loss: 1.4714544704474974e-05 \n",
      "epoch: 12 [598829/888800 67.38%] train loss: 1.5049733519845176e-05 \n",
      "epoch: 12 [599940/888800 67.50%] train loss: 1.4775522686250042e-05 \n",
      "epoch: 12 [601051/888800 67.62%] train loss: 1.4694285709992982e-05 \n",
      "epoch: 12 [602162/888800 67.75%] train loss: 1.3921339814260136e-05 \n",
      "epoch: 12 [603273/888800 67.88%] train loss: 1.173735836346168e-05 \n",
      "epoch: 12 [604384/888800 68.00%] train loss: 1.4755532902199775e-05 \n",
      "epoch: 12 [605495/888800 68.12%] train loss: 1.3538393432099838e-05 \n",
      "epoch: 12 [606606/888800 68.25%] train loss: 1.5210184756142553e-05 \n",
      "epoch: 12 [607717/888800 68.38%] train loss: 1.5351175534306094e-05 \n",
      "epoch: 12 [608828/888800 68.50%] train loss: 1.4608362107537687e-05 \n",
      "epoch: 12 [609939/888800 68.62%] train loss: 1.4087660019868053e-05 \n",
      "epoch: 12 [611050/888800 68.75%] train loss: 1.4984281733632088e-05 \n",
      "epoch: 12 [612161/888800 68.88%] train loss: 1.4200569239619654e-05 \n",
      "epoch: 12 [613272/888800 69.00%] train loss: 1.5102191355254035e-05 \n",
      "epoch: 12 [614383/888800 69.12%] train loss: 1.3985182704345789e-05 \n",
      "epoch: 12 [615494/888800 69.25%] train loss: 1.3856045370630454e-05 \n",
      "epoch: 12 [616605/888800 69.38%] train loss: 1.3946946637588553e-05 \n",
      "epoch: 12 [617716/888800 69.50%] train loss: 1.456900736229727e-05 \n",
      "epoch: 12 [618827/888800 69.62%] train loss: 1.3292839867062867e-05 \n",
      "epoch: 12 [619938/888800 69.75%] train loss: 1.5817340681678616e-05 \n",
      "epoch: 12 [621049/888800 69.88%] train loss: 1.2906751180707943e-05 \n",
      "epoch: 12 [622160/888800 70.00%] train loss: 1.338381480309181e-05 \n",
      "epoch: 12 [623271/888800 70.12%] train loss: 1.4417749298445415e-05 \n",
      "epoch: 12 [624382/888800 70.25%] train loss: 1.4789624401601031e-05 \n",
      "epoch: 12 [625493/888800 70.38%] train loss: 1.4139153790893033e-05 \n",
      "epoch: 12 [626604/888800 70.50%] train loss: 1.528421853436157e-05 \n",
      "epoch: 12 [627715/888800 70.62%] train loss: 1.3571893759944942e-05 \n",
      "epoch: 12 [628826/888800 70.75%] train loss: 1.3920455785410013e-05 \n",
      "epoch: 12 [629937/888800 70.88%] train loss: 1.2414762750267982e-05 \n",
      "epoch: 12 [631048/888800 71.00%] train loss: 1.452017568226438e-05 \n",
      "epoch: 12 [632159/888800 71.12%] train loss: 1.3340229997993447e-05 \n",
      "epoch: 12 [633270/888800 71.25%] train loss: 1.4517775525746401e-05 \n",
      "epoch: 12 [634381/888800 71.38%] train loss: 1.2854141459683888e-05 \n",
      "epoch: 12 [635492/888800 71.50%] train loss: 1.365119624097133e-05 \n",
      "epoch: 12 [636603/888800 71.62%] train loss: 1.3577776371676009e-05 \n",
      "epoch: 12 [637714/888800 71.75%] train loss: 1.3610113455797546e-05 \n",
      "epoch: 12 [638825/888800 71.88%] train loss: 1.4261917385738343e-05 \n",
      "epoch: 12 [639936/888800 72.00%] train loss: 1.3341870726435445e-05 \n",
      "epoch: 12 [641047/888800 72.12%] train loss: 1.4092009223531932e-05 \n",
      "epoch: 12 [642158/888800 72.25%] train loss: 1.3504560229193885e-05 \n",
      "epoch: 12 [643269/888800 72.38%] train loss: 1.305174100707518e-05 \n",
      "epoch: 12 [644380/888800 72.50%] train loss: 1.4744246982445475e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [645491/888800 72.62%] train loss: 1.378536853735568e-05 \n",
      "epoch: 12 [646602/888800 72.75%] train loss: 1.410635195497889e-05 \n",
      "epoch: 12 [647713/888800 72.88%] train loss: 1.3396444046520628e-05 \n",
      "epoch: 12 [648824/888800 73.00%] train loss: 1.468610753363464e-05 \n",
      "epoch: 12 [649935/888800 73.12%] train loss: 1.5207986507448368e-05 \n",
      "epoch: 12 [651046/888800 73.25%] train loss: 1.4650033335783519e-05 \n",
      "epoch: 12 [652157/888800 73.38%] train loss: 1.462794443796156e-05 \n",
      "epoch: 12 [653268/888800 73.50%] train loss: 1.4161094441078603e-05 \n",
      "epoch: 12 [654379/888800 73.62%] train loss: 1.4910547179169953e-05 \n",
      "epoch: 12 [655490/888800 73.75%] train loss: 1.5190035810519475e-05 \n",
      "epoch: 12 [656601/888800 73.88%] train loss: 1.3823722838424146e-05 \n",
      "epoch: 12 [657712/888800 74.00%] train loss: 1.4810391803621314e-05 \n",
      "epoch: 12 [658823/888800 74.12%] train loss: 1.5033860108815134e-05 \n",
      "epoch: 12 [659934/888800 74.25%] train loss: 1.4183959137881175e-05 \n",
      "epoch: 12 [661045/888800 74.38%] train loss: 1.33452331283479e-05 \n",
      "epoch: 12 [662156/888800 74.50%] train loss: 1.4585853023163509e-05 \n",
      "epoch: 12 [663267/888800 74.62%] train loss: 1.4758007637283299e-05 \n",
      "epoch: 12 [664378/888800 74.75%] train loss: 1.4689946510770824e-05 \n",
      "epoch: 12 [665489/888800 74.88%] train loss: 1.3898964425607119e-05 \n",
      "epoch: 12 [666600/888800 75.00%] train loss: 1.3527798728318885e-05 \n",
      "epoch: 12 [667711/888800 75.12%] train loss: 1.3306436812854372e-05 \n",
      "epoch: 12 [668822/888800 75.25%] train loss: 1.4486095096799545e-05 \n",
      "epoch: 12 [669933/888800 75.38%] train loss: 1.4735875993210357e-05 \n",
      "epoch: 12 [671044/888800 75.50%] train loss: 1.3932351066614501e-05 \n",
      "epoch: 12 [672155/888800 75.62%] train loss: 1.4101944543654099e-05 \n",
      "epoch: 12 [673266/888800 75.75%] train loss: 1.3798971849610098e-05 \n",
      "epoch: 12 [674377/888800 75.88%] train loss: 1.440817413822515e-05 \n",
      "epoch: 12 [675488/888800 76.00%] train loss: 1.6132466043927707e-05 \n",
      "epoch: 12 [676599/888800 76.12%] train loss: 1.5277955753845163e-05 \n",
      "epoch: 12 [677710/888800 76.25%] train loss: 1.4839053619652987e-05 \n",
      "epoch: 12 [678821/888800 76.38%] train loss: 1.377533408231102e-05 \n",
      "epoch: 12 [679932/888800 76.50%] train loss: 1.4903156625223346e-05 \n",
      "epoch: 12 [681043/888800 76.62%] train loss: 1.442911434423877e-05 \n",
      "epoch: 12 [682154/888800 76.75%] train loss: 1.5508083379245363e-05 \n",
      "epoch: 12 [683265/888800 76.88%] train loss: 1.4742082385055255e-05 \n",
      "epoch: 12 [684376/888800 77.00%] train loss: 1.5331246686400846e-05 \n",
      "epoch: 12 [685487/888800 77.12%] train loss: 1.4183774510456715e-05 \n",
      "epoch: 12 [686598/888800 77.25%] train loss: 1.6072213838924654e-05 \n",
      "epoch: 12 [687709/888800 77.38%] train loss: 1.5640789570170455e-05 \n",
      "epoch: 12 [688820/888800 77.50%] train loss: 1.5825618902454153e-05 \n",
      "epoch: 12 [689931/888800 77.62%] train loss: 1.4028390069142915e-05 \n",
      "epoch: 12 [691042/888800 77.75%] train loss: 1.4611947335652076e-05 \n",
      "epoch: 12 [692153/888800 77.88%] train loss: 1.4850288607703988e-05 \n",
      "epoch: 12 [693264/888800 78.00%] train loss: 1.4289489627117291e-05 \n",
      "epoch: 12 [694375/888800 78.12%] train loss: 1.4304102478490677e-05 \n",
      "epoch: 12 [695486/888800 78.25%] train loss: 1.380693993269233e-05 \n",
      "epoch: 12 [696597/888800 78.38%] train loss: 1.5884434105828404e-05 \n",
      "epoch: 12 [697708/888800 78.50%] train loss: 1.3992901585879736e-05 \n",
      "epoch: 12 [698819/888800 78.62%] train loss: 1.4986303540354129e-05 \n",
      "epoch: 12 [699930/888800 78.75%] train loss: 1.4625560652348213e-05 \n",
      "epoch: 12 [701041/888800 78.88%] train loss: 1.3995237168273889e-05 \n",
      "epoch: 12 [702152/888800 79.00%] train loss: 1.4941021618142258e-05 \n",
      "epoch: 12 [703263/888800 79.12%] train loss: 1.470715506002307e-05 \n",
      "epoch: 12 [704374/888800 79.25%] train loss: 1.4494722563540563e-05 \n",
      "epoch: 12 [705485/888800 79.38%] train loss: 1.480027367506409e-05 \n",
      "epoch: 12 [706596/888800 79.50%] train loss: 1.5579840692225844e-05 \n",
      "epoch: 12 [707707/888800 79.62%] train loss: 1.3725303688261192e-05 \n",
      "epoch: 12 [708818/888800 79.75%] train loss: 1.406277806381695e-05 \n",
      "epoch: 12 [709929/888800 79.88%] train loss: 1.5002262443886138e-05 \n",
      "epoch: 12 [711040/888800 80.00%] train loss: 1.3490326637111139e-05 \n",
      "epoch: 12 [712151/888800 80.12%] train loss: 1.523728951724479e-05 \n",
      "epoch: 12 [713262/888800 80.25%] train loss: 1.4958493011363316e-05 \n",
      "epoch: 12 [714373/888800 80.38%] train loss: 1.5470872313017026e-05 \n",
      "epoch: 12 [715484/888800 80.50%] train loss: 1.3178941117075738e-05 \n",
      "epoch: 12 [716595/888800 80.62%] train loss: 1.418322335666744e-05 \n",
      "epoch: 12 [717706/888800 80.75%] train loss: 1.5027526387711987e-05 \n",
      "epoch: 12 [718817/888800 80.88%] train loss: 1.3362837307795417e-05 \n",
      "epoch: 12 [719928/888800 81.00%] train loss: 1.4422542335523758e-05 \n",
      "epoch: 12 [721039/888800 81.12%] train loss: 1.330707709712442e-05 \n",
      "epoch: 12 [722150/888800 81.25%] train loss: 1.513758525106823e-05 \n",
      "epoch: 12 [723261/888800 81.38%] train loss: 1.515722760814242e-05 \n",
      "epoch: 12 [724372/888800 81.50%] train loss: 1.5056470147101209e-05 \n",
      "epoch: 12 [725483/888800 81.62%] train loss: 1.4819160242041107e-05 \n",
      "epoch: 12 [726594/888800 81.75%] train loss: 1.361405065836152e-05 \n",
      "epoch: 12 [727705/888800 81.88%] train loss: 1.4358238331624307e-05 \n",
      "epoch: 12 [728816/888800 82.00%] train loss: 1.3699438568437472e-05 \n",
      "epoch: 12 [729927/888800 82.12%] train loss: 1.4110397387412377e-05 \n",
      "epoch: 12 [731038/888800 82.25%] train loss: 1.4743026440555695e-05 \n",
      "epoch: 12 [732149/888800 82.38%] train loss: 1.565106686030049e-05 \n",
      "epoch: 12 [733260/888800 82.50%] train loss: 1.4146379726298619e-05 \n",
      "epoch: 12 [734371/888800 82.62%] train loss: 1.3586751265393104e-05 \n",
      "epoch: 12 [735482/888800 82.75%] train loss: 1.4521946468448732e-05 \n",
      "epoch: 12 [736593/888800 82.88%] train loss: 1.495350352342939e-05 \n",
      "epoch: 12 [737704/888800 83.00%] train loss: 1.55268262460595e-05 \n",
      "epoch: 12 [738815/888800 83.12%] train loss: 1.5955263734213077e-05 \n",
      "epoch: 12 [739926/888800 83.25%] train loss: 1.54816825670423e-05 \n",
      "epoch: 12 [741037/888800 83.38%] train loss: 1.6028458048822358e-05 \n",
      "epoch: 12 [742148/888800 83.50%] train loss: 1.4233041838451754e-05 \n",
      "epoch: 12 [743259/888800 83.62%] train loss: 1.6256473827525042e-05 \n",
      "epoch: 12 [744370/888800 83.75%] train loss: 1.4837524759059306e-05 \n",
      "epoch: 12 [745481/888800 83.88%] train loss: 1.4824665413470939e-05 \n",
      "epoch: 12 [746592/888800 84.00%] train loss: 1.4424643268284854e-05 \n",
      "epoch: 12 [747703/888800 84.12%] train loss: 1.5233627891575452e-05 \n",
      "epoch: 12 [748814/888800 84.25%] train loss: 1.4202758393366821e-05 \n",
      "epoch: 12 [749925/888800 84.38%] train loss: 1.3510927601600997e-05 \n",
      "epoch: 12 [751036/888800 84.50%] train loss: 1.531069938209839e-05 \n",
      "epoch: 12 [752147/888800 84.62%] train loss: 1.4463954357779585e-05 \n",
      "epoch: 12 [753258/888800 84.75%] train loss: 1.536127456347458e-05 \n",
      "epoch: 12 [754369/888800 84.88%] train loss: 1.5358020391431637e-05 \n",
      "epoch: 12 [755480/888800 85.00%] train loss: 1.3676710295840167e-05 \n",
      "epoch: 12 [756591/888800 85.12%] train loss: 1.445750331185991e-05 \n",
      "epoch: 12 [757702/888800 85.25%] train loss: 1.5062966667755973e-05 \n",
      "epoch: 12 [758813/888800 85.38%] train loss: 1.3427847989078145e-05 \n",
      "epoch: 12 [759924/888800 85.50%] train loss: 1.4726760127814487e-05 \n",
      "epoch: 12 [761035/888800 85.62%] train loss: 1.543511461932212e-05 \n",
      "epoch: 12 [762146/888800 85.75%] train loss: 1.3475114428729285e-05 \n",
      "epoch: 12 [763257/888800 85.88%] train loss: 1.6137415514094755e-05 \n",
      "epoch: 12 [764368/888800 86.00%] train loss: 1.3700226190849207e-05 \n",
      "epoch: 12 [765479/888800 86.12%] train loss: 1.4857309906801675e-05 \n",
      "epoch: 12 [766590/888800 86.25%] train loss: 1.3977723028801847e-05 \n",
      "epoch: 12 [767701/888800 86.38%] train loss: 1.7204050891450606e-05 \n",
      "epoch: 12 [768812/888800 86.50%] train loss: 1.44277446452179e-05 \n",
      "epoch: 12 [769923/888800 86.62%] train loss: 1.482036714151036e-05 \n",
      "epoch: 12 [771034/888800 86.75%] train loss: 1.39554349516402e-05 \n",
      "epoch: 12 [772145/888800 86.88%] train loss: 1.3624779967358336e-05 \n",
      "epoch: 12 [773256/888800 87.00%] train loss: 1.3503185073204804e-05 \n",
      "epoch: 12 [774367/888800 87.12%] train loss: 1.4608952369599137e-05 \n",
      "epoch: 12 [775478/888800 87.25%] train loss: 1.3381256394495722e-05 \n",
      "epoch: 12 [776589/888800 87.38%] train loss: 1.3287986803334206e-05 \n",
      "epoch: 12 [777700/888800 87.50%] train loss: 1.4846551493974403e-05 \n",
      "epoch: 12 [778811/888800 87.62%] train loss: 1.5552817785646766e-05 \n",
      "epoch: 12 [779922/888800 87.75%] train loss: 1.3587405192083679e-05 \n",
      "epoch: 12 [781033/888800 87.88%] train loss: 1.4597629160562064e-05 \n",
      "epoch: 12 [782144/888800 88.00%] train loss: 1.4400676263903733e-05 \n",
      "epoch: 12 [783255/888800 88.12%] train loss: 1.385051291435957e-05 \n",
      "epoch: 12 [784366/888800 88.25%] train loss: 1.3662691344507039e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 [785477/888800 88.38%] train loss: 1.3637826668855269e-05 \n",
      "epoch: 12 [786588/888800 88.50%] train loss: 1.520721343695186e-05 \n",
      "epoch: 12 [787699/888800 88.62%] train loss: 1.5133668966882396e-05 \n",
      "epoch: 12 [788810/888800 88.75%] train loss: 1.3791307537758257e-05 \n",
      "epoch: 12 [789921/888800 88.88%] train loss: 1.3762388334725983e-05 \n",
      "epoch: 12 [791032/888800 89.00%] train loss: 1.4272539374360349e-05 \n",
      "epoch: 12 [792143/888800 89.12%] train loss: 1.4197635209711734e-05 \n",
      "epoch: 12 [793254/888800 89.25%] train loss: 1.412411165802041e-05 \n",
      "epoch: 12 [794365/888800 89.38%] train loss: 1.285458893107716e-05 \n",
      "epoch: 12 [795476/888800 89.50%] train loss: 1.5004001397755928e-05 \n",
      "epoch: 12 [796587/888800 89.62%] train loss: 1.4231447494239546e-05 \n",
      "epoch: 12 [797698/888800 89.75%] train loss: 1.5034531315905042e-05 \n",
      "epoch: 12 [798809/888800 89.88%] train loss: 1.4238925359677523e-05 \n",
      "epoch: 12 [799920/888800 90.00%] train loss: 1.5650974091840908e-05 \n",
      "epoch: 12 [801031/888800 90.12%] train loss: 1.487408735556528e-05 \n",
      "epoch: 12 [802142/888800 90.25%] train loss: 1.5298410289688036e-05 \n",
      "epoch: 12 [803253/888800 90.38%] train loss: 1.4414707948162686e-05 \n",
      "epoch: 12 [804364/888800 90.50%] train loss: 1.578632691234816e-05 \n",
      "epoch: 12 [805475/888800 90.62%] train loss: 1.638088360778056e-05 \n",
      "epoch: 12 [806586/888800 90.75%] train loss: 1.5527841242146678e-05 \n",
      "epoch: 12 [807697/888800 90.88%] train loss: 1.4143203770800028e-05 \n",
      "epoch: 12 [808808/888800 91.00%] train loss: 1.4194270079315174e-05 \n",
      "epoch: 12 [809919/888800 91.12%] train loss: 1.387095562677132e-05 \n",
      "epoch: 12 [811030/888800 91.25%] train loss: 1.4439175174629781e-05 \n",
      "epoch: 12 [812141/888800 91.38%] train loss: 1.3530965588870458e-05 \n",
      "epoch: 12 [813252/888800 91.50%] train loss: 1.248302032763604e-05 \n",
      "epoch: 12 [814363/888800 91.62%] train loss: 1.3767850759904832e-05 \n",
      "epoch: 12 [815474/888800 91.75%] train loss: 1.5474772226298228e-05 \n",
      "epoch: 12 [816585/888800 91.88%] train loss: 1.3132384083291981e-05 \n",
      "epoch: 12 [817696/888800 92.00%] train loss: 1.4960773114580661e-05 \n",
      "epoch: 12 [818807/888800 92.12%] train loss: 1.5083292964845896e-05 \n",
      "epoch: 12 [819918/888800 92.25%] train loss: 1.5438286936841905e-05 \n",
      "epoch: 12 [821029/888800 92.38%] train loss: 1.4101849956205115e-05 \n",
      "epoch: 12 [822140/888800 92.50%] train loss: 1.4684153939015232e-05 \n",
      "epoch: 12 [823251/888800 92.62%] train loss: 1.4260881471273024e-05 \n",
      "epoch: 12 [824362/888800 92.75%] train loss: 1.4328315046441276e-05 \n",
      "epoch: 12 [825473/888800 92.88%] train loss: 1.4540738447976764e-05 \n",
      "epoch: 12 [826584/888800 93.00%] train loss: 1.35632544697728e-05 \n",
      "epoch: 12 [827695/888800 93.12%] train loss: 1.5158002497628331e-05 \n",
      "epoch: 12 [828806/888800 93.25%] train loss: 1.2739341400447302e-05 \n",
      "epoch: 12 [829917/888800 93.38%] train loss: 1.4361339708557352e-05 \n",
      "epoch: 12 [831028/888800 93.50%] train loss: 1.3537342056224588e-05 \n",
      "epoch: 12 [832139/888800 93.62%] train loss: 1.3877016499463934e-05 \n",
      "epoch: 12 [833250/888800 93.75%] train loss: 1.369412257190561e-05 \n",
      "epoch: 12 [834361/888800 93.88%] train loss: 1.3808599760523066e-05 \n",
      "epoch: 12 [835472/888800 94.00%] train loss: 1.4397985978575889e-05 \n",
      "epoch: 12 [836583/888800 94.12%] train loss: 1.4286500118032563e-05 \n",
      "epoch: 12 [837694/888800 94.25%] train loss: 1.4635977095167618e-05 \n",
      "epoch: 12 [838805/888800 94.38%] train loss: 1.412058736605104e-05 \n",
      "epoch: 12 [839916/888800 94.50%] train loss: 1.351390983472811e-05 \n",
      "epoch: 12 [841027/888800 94.62%] train loss: 1.4599590940633789e-05 \n",
      "epoch: 12 [842138/888800 94.75%] train loss: 1.3809046322421636e-05 \n",
      "epoch: 12 [843249/888800 94.88%] train loss: 1.4097390703682322e-05 \n",
      "epoch: 12 [844360/888800 95.00%] train loss: 1.4619078683608677e-05 \n",
      "epoch: 12 [845471/888800 95.12%] train loss: 1.5377907402580604e-05 \n",
      "epoch: 12 [846582/888800 95.25%] train loss: 1.4842009477433749e-05 \n",
      "epoch: 12 [847693/888800 95.38%] train loss: 1.4922547961759847e-05 \n",
      "epoch: 12 [848804/888800 95.50%] train loss: 1.5447270925506018e-05 \n",
      "epoch: 12 [849915/888800 95.62%] train loss: 1.3937029507360421e-05 \n",
      "epoch: 12 [851026/888800 95.75%] train loss: 1.3855041288479697e-05 \n",
      "epoch: 12 [852137/888800 95.88%] train loss: 1.3051595487922896e-05 \n",
      "epoch: 12 [853248/888800 96.00%] train loss: 1.3126908925187308e-05 \n",
      "epoch: 12 [854359/888800 96.12%] train loss: 1.4378695595951285e-05 \n",
      "epoch: 12 [855470/888800 96.25%] train loss: 1.4171613656799309e-05 \n",
      "epoch: 12 [856581/888800 96.38%] train loss: 1.3563928405346815e-05 \n",
      "epoch: 12 [857692/888800 96.50%] train loss: 1.4619615285482723e-05 \n",
      "epoch: 12 [858803/888800 96.62%] train loss: 1.4367682524607517e-05 \n",
      "epoch: 12 [859914/888800 96.75%] train loss: 1.5053985407575965e-05 \n",
      "epoch: 12 [861025/888800 96.88%] train loss: 1.3934390153735876e-05 \n",
      "epoch: 12 [862136/888800 97.00%] train loss: 1.4341435417009052e-05 \n",
      "epoch: 12 [863247/888800 97.12%] train loss: 1.424490983481519e-05 \n",
      "epoch: 12 [864358/888800 97.25%] train loss: 1.3186951036914252e-05 \n",
      "epoch: 12 [865469/888800 97.38%] train loss: 1.4675068996439222e-05 \n",
      "epoch: 12 [866580/888800 97.50%] train loss: 1.3818877960147802e-05 \n",
      "epoch: 12 [867691/888800 97.62%] train loss: 1.3977716662338935e-05 \n",
      "epoch: 12 [868802/888800 97.75%] train loss: 1.3893973118683789e-05 \n",
      "epoch: 12 [869913/888800 97.88%] train loss: 1.3514954844140448e-05 \n",
      "epoch: 12 [871024/888800 98.00%] train loss: 1.4178668607200962e-05 \n",
      "epoch: 12 [872135/888800 98.12%] train loss: 1.4843975804978982e-05 \n",
      "epoch: 12 [873246/888800 98.25%] train loss: 1.4589987586077768e-05 \n",
      "epoch: 12 [874357/888800 98.38%] train loss: 1.4166568689688575e-05 \n",
      "epoch: 12 [875468/888800 98.50%] train loss: 1.4103429748502094e-05 \n",
      "epoch: 12 [876579/888800 98.62%] train loss: 1.4225163795344997e-05 \n",
      "epoch: 12 [877690/888800 98.75%] train loss: 1.470000461267773e-05 \n",
      "epoch: 12 [878801/888800 98.88%] train loss: 1.381108995701652e-05 \n",
      "epoch: 12 [879912/888800 99.00%] train loss: 1.4629305951530114e-05 \n",
      "epoch: 12 [881023/888800 99.12%] train loss: 1.3403871889750008e-05 \n",
      "epoch: 12 [882134/888800 99.25%] train loss: 1.4248646948544774e-05 \n",
      "epoch: 12 [883245/888800 99.38%] train loss: 1.4574539818568155e-05 \n",
      "epoch: 12 [884356/888800 99.50%] train loss: 1.42985227284953e-05 \n",
      "epoch: 12 [885467/888800 99.62%] train loss: 1.3449046491587069e-05 \n",
      "epoch: 12 [886578/888800 99.75%] train loss: 1.433445777365705e-05 \n",
      "epoch: 12 [887689/888800 99.88%] train loss: 1.4820774595136754e-05 \n",
      "epoch: 13 [0/888800 0.00%] train loss: 1.3535021025745664e-05 \n",
      "epoch: 13 [1111/888800 0.12%] train loss: 1.466655703552533e-05 \n",
      "epoch: 13 [2222/888800 0.25%] train loss: 1.3841261534253135e-05 \n",
      "epoch: 13 [3333/888800 0.38%] train loss: 1.6104686437756754e-05 \n",
      "epoch: 13 [4444/888800 0.50%] train loss: 1.4455055861617438e-05 \n",
      "epoch: 13 [5555/888800 0.62%] train loss: 1.3673099601874128e-05 \n",
      "epoch: 13 [6666/888800 0.75%] train loss: 1.5443765732925385e-05 \n",
      "epoch: 13 [7777/888800 0.88%] train loss: 1.5345614883699454e-05 \n",
      "epoch: 13 [8888/888800 1.00%] train loss: 1.4548025319527369e-05 \n",
      "epoch: 13 [9999/888800 1.12%] train loss: 1.389647150062956e-05 \n",
      "epoch: 13 [11110/888800 1.25%] train loss: 1.4423192624235526e-05 \n",
      "epoch: 13 [12221/888800 1.38%] train loss: 1.4223408470570575e-05 \n",
      "epoch: 13 [13332/888800 1.50%] train loss: 1.4880402886774391e-05 \n",
      "epoch: 13 [14443/888800 1.62%] train loss: 1.484185668232385e-05 \n",
      "epoch: 13 [15554/888800 1.75%] train loss: 1.6692625649739057e-05 \n",
      "epoch: 13 [16665/888800 1.88%] train loss: 1.3653112546307966e-05 \n",
      "epoch: 13 [17776/888800 2.00%] train loss: 1.4598980669688899e-05 \n",
      "epoch: 13 [18887/888800 2.12%] train loss: 1.4211413144948892e-05 \n",
      "epoch: 13 [19998/888800 2.25%] train loss: 1.3279061022331007e-05 \n",
      "epoch: 13 [21109/888800 2.38%] train loss: 1.4324764379125554e-05 \n",
      "epoch: 13 [22220/888800 2.50%] train loss: 1.353716379526304e-05 \n",
      "epoch: 13 [23331/888800 2.62%] train loss: 1.3140396731614601e-05 \n",
      "epoch: 13 [24442/888800 2.75%] train loss: 1.4290755643742159e-05 \n",
      "epoch: 13 [25553/888800 2.88%] train loss: 1.459389750380069e-05 \n",
      "epoch: 13 [26664/888800 3.00%] train loss: 1.5163541320362128e-05 \n",
      "epoch: 13 [27775/888800 3.12%] train loss: 1.4437324352911673e-05 \n",
      "epoch: 13 [28886/888800 3.25%] train loss: 1.5023184460005723e-05 \n",
      "epoch: 13 [29997/888800 3.38%] train loss: 1.5658744814572856e-05 \n",
      "epoch: 13 [31108/888800 3.50%] train loss: 1.4303659554570913e-05 \n",
      "epoch: 13 [32219/888800 3.62%] train loss: 1.3377952200244181e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [33330/888800 3.75%] train loss: 1.3688611034012865e-05 \n",
      "epoch: 13 [34441/888800 3.88%] train loss: 1.3965936886961572e-05 \n",
      "epoch: 13 [35552/888800 4.00%] train loss: 1.4356989595398773e-05 \n",
      "epoch: 13 [36663/888800 4.12%] train loss: 1.4741798622708302e-05 \n",
      "epoch: 13 [37774/888800 4.25%] train loss: 1.4988680959504563e-05 \n",
      "epoch: 13 [38885/888800 4.38%] train loss: 1.5048070963530336e-05 \n",
      "epoch: 13 [39996/888800 4.50%] train loss: 1.4125057532510255e-05 \n",
      "epoch: 13 [41107/888800 4.62%] train loss: 1.341120878350921e-05 \n",
      "epoch: 13 [42218/888800 4.75%] train loss: 1.4944446775189135e-05 \n",
      "epoch: 13 [43329/888800 4.88%] train loss: 1.3512691111827735e-05 \n",
      "epoch: 13 [44440/888800 5.00%] train loss: 1.4011159692017827e-05 \n",
      "epoch: 13 [45551/888800 5.12%] train loss: 1.5310504750232212e-05 \n",
      "epoch: 13 [46662/888800 5.25%] train loss: 1.445354337192839e-05 \n",
      "epoch: 13 [47773/888800 5.38%] train loss: 1.4671809367428068e-05 \n",
      "epoch: 13 [48884/888800 5.50%] train loss: 1.5485986295971088e-05 \n",
      "epoch: 13 [49995/888800 5.62%] train loss: 1.556923962198198e-05 \n",
      "epoch: 13 [51106/888800 5.75%] train loss: 1.3566411325882655e-05 \n",
      "epoch: 13 [52217/888800 5.88%] train loss: 1.3535645848605782e-05 \n",
      "epoch: 13 [53328/888800 6.00%] train loss: 1.3985222722112667e-05 \n",
      "epoch: 13 [54439/888800 6.12%] train loss: 1.3802437024423853e-05 \n",
      "epoch: 13 [55550/888800 6.25%] train loss: 1.4687435395899229e-05 \n",
      "epoch: 13 [56661/888800 6.38%] train loss: 1.3957578630652279e-05 \n",
      "epoch: 13 [57772/888800 6.50%] train loss: 1.538886863272637e-05 \n",
      "epoch: 13 [58883/888800 6.62%] train loss: 1.421959950675955e-05 \n",
      "epoch: 13 [59994/888800 6.75%] train loss: 1.4529564396070782e-05 \n",
      "epoch: 13 [61105/888800 6.88%] train loss: 1.500238158769207e-05 \n",
      "epoch: 13 [62216/888800 7.00%] train loss: 1.4486737200058997e-05 \n",
      "epoch: 13 [63327/888800 7.12%] train loss: 1.2806774066120852e-05 \n",
      "epoch: 13 [64438/888800 7.25%] train loss: 1.4998862752690911e-05 \n",
      "epoch: 13 [65549/888800 7.38%] train loss: 1.4638609172834549e-05 \n",
      "epoch: 13 [66660/888800 7.50%] train loss: 1.4052270671527367e-05 \n",
      "epoch: 13 [67771/888800 7.62%] train loss: 1.4031657883606385e-05 \n",
      "epoch: 13 [68882/888800 7.75%] train loss: 1.3850386494596023e-05 \n",
      "epoch: 13 [69993/888800 7.88%] train loss: 1.4254979760153219e-05 \n",
      "epoch: 13 [71104/888800 8.00%] train loss: 1.4261521755543072e-05 \n",
      "epoch: 13 [72215/888800 8.12%] train loss: 1.4932517842680681e-05 \n",
      "epoch: 13 [73326/888800 8.25%] train loss: 1.3794650840281975e-05 \n",
      "epoch: 13 [74437/888800 8.38%] train loss: 1.391712521581212e-05 \n",
      "epoch: 13 [75548/888800 8.50%] train loss: 1.3424368262349162e-05 \n",
      "epoch: 13 [76659/888800 8.62%] train loss: 1.46745960591943e-05 \n",
      "epoch: 13 [77770/888800 8.75%] train loss: 1.4089182513998821e-05 \n",
      "epoch: 13 [78881/888800 8.88%] train loss: 1.4499652024824172e-05 \n",
      "epoch: 13 [79992/888800 9.00%] train loss: 1.537500247650314e-05 \n",
      "epoch: 13 [81103/888800 9.12%] train loss: 1.4290260878624395e-05 \n",
      "epoch: 13 [82214/888800 9.25%] train loss: 1.4769276276638266e-05 \n",
      "epoch: 13 [83325/888800 9.38%] train loss: 1.3068045518593863e-05 \n",
      "epoch: 13 [84436/888800 9.50%] train loss: 1.5073152098921128e-05 \n",
      "epoch: 13 [85547/888800 9.62%] train loss: 1.5193756553344429e-05 \n",
      "epoch: 13 [86658/888800 9.75%] train loss: 1.3790311641059816e-05 \n",
      "epoch: 13 [87769/888800 9.88%] train loss: 1.4435801858780906e-05 \n",
      "epoch: 13 [88880/888800 10.00%] train loss: 1.38807945404551e-05 \n",
      "epoch: 13 [89991/888800 10.12%] train loss: 1.40657793963328e-05 \n",
      "epoch: 13 [91102/888800 10.25%] train loss: 1.395167510054307e-05 \n",
      "epoch: 13 [92213/888800 10.38%] train loss: 1.4151905816106591e-05 \n",
      "epoch: 13 [93324/888800 10.50%] train loss: 1.438460731151281e-05 \n",
      "epoch: 13 [94435/888800 10.62%] train loss: 1.4801778888795525e-05 \n",
      "epoch: 13 [95546/888800 10.75%] train loss: 1.4798357369727455e-05 \n",
      "epoch: 13 [96657/888800 10.88%] train loss: 1.3779732398688793e-05 \n",
      "epoch: 13 [97768/888800 11.00%] train loss: 1.4410849871637765e-05 \n",
      "epoch: 13 [98879/888800 11.12%] train loss: 1.404830163664883e-05 \n",
      "epoch: 13 [99990/888800 11.25%] train loss: 1.328791131527396e-05 \n",
      "epoch: 13 [101101/888800 11.38%] train loss: 1.4022958566783927e-05 \n",
      "epoch: 13 [102212/888800 11.50%] train loss: 1.4942810594220646e-05 \n",
      "epoch: 13 [103323/888800 11.62%] train loss: 1.5173597603279632e-05 \n",
      "epoch: 13 [104434/888800 11.75%] train loss: 1.5338582670665346e-05 \n",
      "epoch: 13 [105545/888800 11.88%] train loss: 1.3294296877575107e-05 \n",
      "epoch: 13 [106656/888800 12.00%] train loss: 1.4718782040290534e-05 \n",
      "epoch: 13 [107767/888800 12.12%] train loss: 1.4481015568890143e-05 \n",
      "epoch: 13 [108878/888800 12.25%] train loss: 1.5318231817218475e-05 \n",
      "epoch: 13 [109989/888800 12.38%] train loss: 1.3381803000811487e-05 \n",
      "epoch: 13 [111100/888800 12.50%] train loss: 1.4629490578954574e-05 \n",
      "epoch: 13 [112211/888800 12.62%] train loss: 1.3534356185118668e-05 \n",
      "epoch: 13 [113322/888800 12.75%] train loss: 1.4627129530708771e-05 \n",
      "epoch: 13 [114433/888800 12.88%] train loss: 1.5372974303318188e-05 \n",
      "epoch: 13 [115544/888800 13.00%] train loss: 1.4881549759593327e-05 \n",
      "epoch: 13 [116655/888800 13.12%] train loss: 1.541797973914072e-05 \n",
      "epoch: 13 [117766/888800 13.25%] train loss: 1.3609788766189013e-05 \n",
      "epoch: 13 [118877/888800 13.38%] train loss: 1.650606827752199e-05 \n",
      "epoch: 13 [119988/888800 13.50%] train loss: 1.2986532055947464e-05 \n",
      "epoch: 13 [121099/888800 13.62%] train loss: 1.6647323718643747e-05 \n",
      "epoch: 13 [122210/888800 13.75%] train loss: 1.3763636161456816e-05 \n",
      "epoch: 13 [123321/888800 13.88%] train loss: 1.4458551049756352e-05 \n",
      "epoch: 13 [124432/888800 14.00%] train loss: 1.5389146938105114e-05 \n",
      "epoch: 13 [125543/888800 14.12%] train loss: 1.4443292457144707e-05 \n",
      "epoch: 13 [126654/888800 14.25%] train loss: 1.574335510667879e-05 \n",
      "epoch: 13 [127765/888800 14.38%] train loss: 1.3235847291070968e-05 \n",
      "epoch: 13 [128876/888800 14.50%] train loss: 1.7356871467200108e-05 \n",
      "epoch: 13 [129987/888800 14.62%] train loss: 1.3050723282503895e-05 \n",
      "epoch: 13 [131098/888800 14.75%] train loss: 1.566534956509713e-05 \n",
      "epoch: 13 [132209/888800 14.88%] train loss: 1.5148918464547023e-05 \n",
      "epoch: 13 [133320/888800 15.00%] train loss: 1.479044931329554e-05 \n",
      "epoch: 13 [134431/888800 15.12%] train loss: 1.4572432519344147e-05 \n",
      "epoch: 13 [135542/888800 15.25%] train loss: 1.3948259947937913e-05 \n",
      "epoch: 13 [136653/888800 15.38%] train loss: 1.466489538870519e-05 \n",
      "epoch: 13 [137764/888800 15.50%] train loss: 1.3685599697055295e-05 \n",
      "epoch: 13 [138875/888800 15.62%] train loss: 1.4762702448933851e-05 \n",
      "epoch: 13 [139986/888800 15.75%] train loss: 1.4109653420746326e-05 \n",
      "epoch: 13 [141097/888800 15.88%] train loss: 1.4208012544258963e-05 \n",
      "epoch: 13 [142208/888800 16.00%] train loss: 1.3638657037517987e-05 \n",
      "epoch: 13 [143319/888800 16.12%] train loss: 1.4108077266428154e-05 \n",
      "epoch: 13 [144430/888800 16.25%] train loss: 1.4302619092632085e-05 \n",
      "epoch: 13 [145541/888800 16.38%] train loss: 1.4827485756541137e-05 \n",
      "epoch: 13 [146652/888800 16.50%] train loss: 1.452173000870971e-05 \n",
      "epoch: 13 [147763/888800 16.62%] train loss: 1.4542185454047285e-05 \n",
      "epoch: 13 [148874/888800 16.75%] train loss: 1.6438509192084894e-05 \n",
      "epoch: 13 [149985/888800 16.88%] train loss: 1.3766014490101952e-05 \n",
      "epoch: 13 [151096/888800 17.00%] train loss: 1.373763006995432e-05 \n",
      "epoch: 13 [152207/888800 17.12%] train loss: 1.5046927728690207e-05 \n",
      "epoch: 13 [153318/888800 17.25%] train loss: 1.4503145393973682e-05 \n",
      "epoch: 13 [154429/888800 17.38%] train loss: 1.3738108464167453e-05 \n",
      "epoch: 13 [155540/888800 17.50%] train loss: 1.289427927986253e-05 \n",
      "epoch: 13 [156651/888800 17.62%] train loss: 1.3965777725388762e-05 \n",
      "epoch: 13 [157762/888800 17.75%] train loss: 1.2738039913529065e-05 \n",
      "epoch: 13 [158873/888800 17.88%] train loss: 1.514539235358825e-05 \n",
      "epoch: 13 [159984/888800 18.00%] train loss: 1.585589961905498e-05 \n",
      "epoch: 13 [161095/888800 18.12%] train loss: 1.454620451113442e-05 \n",
      "epoch: 13 [162206/888800 18.25%] train loss: 1.3843970009475015e-05 \n",
      "epoch: 13 [163317/888800 18.38%] train loss: 1.4004543118062429e-05 \n",
      "epoch: 13 [164428/888800 18.50%] train loss: 1.393063666910166e-05 \n",
      "epoch: 13 [165539/888800 18.62%] train loss: 1.5158843780227471e-05 \n",
      "epoch: 13 [166650/888800 18.75%] train loss: 1.2995561519346666e-05 \n",
      "epoch: 13 [167761/888800 18.88%] train loss: 1.4227264728106093e-05 \n",
      "epoch: 13 [168872/888800 19.00%] train loss: 1.4888114492350724e-05 \n",
      "epoch: 13 [169983/888800 19.12%] train loss: 1.5002041436673608e-05 \n",
      "epoch: 13 [171094/888800 19.25%] train loss: 1.5523550246143714e-05 \n",
      "epoch: 13 [172205/888800 19.38%] train loss: 1.36428698169766e-05 \n",
      "epoch: 13 [173316/888800 19.50%] train loss: 1.5767825971124694e-05 \n",
      "epoch: 13 [174427/888800 19.62%] train loss: 1.3740700524067506e-05 \n",
      "epoch: 13 [175538/888800 19.75%] train loss: 1.414416965417331e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [176649/888800 19.88%] train loss: 1.4648878277512267e-05 \n",
      "epoch: 13 [177760/888800 20.00%] train loss: 1.5309269656427205e-05 \n",
      "epoch: 13 [178871/888800 20.12%] train loss: 1.5086085113580339e-05 \n",
      "epoch: 13 [179982/888800 20.25%] train loss: 1.3659532669407781e-05 \n",
      "epoch: 13 [181093/888800 20.38%] train loss: 1.3643714737554546e-05 \n",
      "epoch: 13 [182204/888800 20.50%] train loss: 1.3311980183061678e-05 \n",
      "epoch: 13 [183315/888800 20.62%] train loss: 1.4106400158198085e-05 \n",
      "epoch: 13 [184426/888800 20.75%] train loss: 1.4268982340581715e-05 \n",
      "epoch: 13 [185537/888800 20.88%] train loss: 1.4627146811108105e-05 \n",
      "epoch: 13 [186648/888800 21.00%] train loss: 1.3927458894613665e-05 \n",
      "epoch: 13 [187759/888800 21.12%] train loss: 1.6005295037757605e-05 \n",
      "epoch: 13 [188870/888800 21.25%] train loss: 1.3463517461786978e-05 \n",
      "epoch: 13 [189981/888800 21.38%] train loss: 1.4265816389524844e-05 \n",
      "epoch: 13 [191092/888800 21.50%] train loss: 1.403648275299929e-05 \n",
      "epoch: 13 [192203/888800 21.62%] train loss: 1.4290789295046125e-05 \n",
      "epoch: 13 [193314/888800 21.75%] train loss: 1.3539254723582417e-05 \n",
      "epoch: 13 [194425/888800 21.88%] train loss: 1.536735908302944e-05 \n",
      "epoch: 13 [195536/888800 22.00%] train loss: 1.4086073861108162e-05 \n",
      "epoch: 13 [196647/888800 22.12%] train loss: 1.4923204616934527e-05 \n",
      "epoch: 13 [197758/888800 22.25%] train loss: 1.401097142661456e-05 \n",
      "epoch: 13 [198869/888800 22.38%] train loss: 1.4874632142891642e-05 \n",
      "epoch: 13 [199980/888800 22.50%] train loss: 1.4651667697762605e-05 \n",
      "epoch: 13 [201091/888800 22.62%] train loss: 1.4429605471377727e-05 \n",
      "epoch: 13 [202202/888800 22.75%] train loss: 1.447737668058835e-05 \n",
      "epoch: 13 [203313/888800 22.88%] train loss: 1.3869070244254544e-05 \n",
      "epoch: 13 [204424/888800 23.00%] train loss: 1.4926410585758276e-05 \n",
      "epoch: 13 [205535/888800 23.12%] train loss: 1.4163497326080687e-05 \n",
      "epoch: 13 [206646/888800 23.25%] train loss: 1.3727044461120386e-05 \n",
      "epoch: 13 [207757/888800 23.38%] train loss: 1.3197950465837494e-05 \n",
      "epoch: 13 [208868/888800 23.50%] train loss: 1.410872118867701e-05 \n",
      "epoch: 13 [209979/888800 23.62%] train loss: 1.4021275092090946e-05 \n",
      "epoch: 13 [211090/888800 23.75%] train loss: 1.498499568697298e-05 \n",
      "epoch: 13 [212201/888800 23.88%] train loss: 1.4879153241054155e-05 \n",
      "epoch: 13 [213312/888800 24.00%] train loss: 1.4878836736897938e-05 \n",
      "epoch: 13 [214423/888800 24.12%] train loss: 1.425202026439365e-05 \n",
      "epoch: 13 [215534/888800 24.25%] train loss: 1.3551074516726658e-05 \n",
      "epoch: 13 [216645/888800 24.38%] train loss: 1.4302283489087131e-05 \n",
      "epoch: 13 [217756/888800 24.50%] train loss: 1.4113777069724165e-05 \n",
      "epoch: 13 [218867/888800 24.62%] train loss: 1.392669764754828e-05 \n",
      "epoch: 13 [219978/888800 24.75%] train loss: 1.4935909348423593e-05 \n",
      "epoch: 13 [221089/888800 24.88%] train loss: 1.4313936844700947e-05 \n",
      "epoch: 13 [222200/888800 25.00%] train loss: 1.3248255527287256e-05 \n",
      "epoch: 13 [223311/888800 25.12%] train loss: 1.597798109287396e-05 \n",
      "epoch: 13 [224422/888800 25.25%] train loss: 1.5155053006310482e-05 \n",
      "epoch: 13 [225533/888800 25.38%] train loss: 1.3704417142434977e-05 \n",
      "epoch: 13 [226644/888800 25.50%] train loss: 1.3903231774747837e-05 \n",
      "epoch: 13 [227755/888800 25.62%] train loss: 1.4289626960817259e-05 \n",
      "epoch: 13 [228866/888800 25.75%] train loss: 1.475154931540601e-05 \n",
      "epoch: 13 [229977/888800 25.88%] train loss: 1.3376867173064966e-05 \n",
      "epoch: 13 [231088/888800 26.00%] train loss: 1.5961870303726755e-05 \n",
      "epoch: 13 [232199/888800 26.12%] train loss: 1.4333304534375202e-05 \n",
      "epoch: 13 [233310/888800 26.25%] train loss: 1.5549889212707058e-05 \n",
      "epoch: 13 [234421/888800 26.38%] train loss: 1.517079545010347e-05 \n",
      "epoch: 13 [235532/888800 26.50%] train loss: 1.4394086065294687e-05 \n",
      "epoch: 13 [236643/888800 26.62%] train loss: 1.4478880984825082e-05 \n",
      "epoch: 13 [237754/888800 26.75%] train loss: 1.3622757251141593e-05 \n",
      "epoch: 13 [238865/888800 26.88%] train loss: 1.4018833098816685e-05 \n",
      "epoch: 13 [239976/888800 27.00%] train loss: 1.4473233022727072e-05 \n",
      "epoch: 13 [241087/888800 27.12%] train loss: 1.4621887203247752e-05 \n",
      "epoch: 13 [242198/888800 27.25%] train loss: 1.472024723625509e-05 \n",
      "epoch: 13 [243309/888800 27.38%] train loss: 1.4005458069732413e-05 \n",
      "epoch: 13 [244420/888800 27.50%] train loss: 1.4050252502784133e-05 \n",
      "epoch: 13 [245531/888800 27.62%] train loss: 1.5550140233244747e-05 \n",
      "epoch: 13 [246642/888800 27.75%] train loss: 1.4900487258273643e-05 \n",
      "epoch: 13 [247753/888800 27.88%] train loss: 1.6167683497769758e-05 \n",
      "epoch: 13 [248864/888800 28.00%] train loss: 1.4405615729629062e-05 \n",
      "epoch: 13 [249975/888800 28.12%] train loss: 1.532487294753082e-05 \n",
      "epoch: 13 [251086/888800 28.25%] train loss: 1.453089225833537e-05 \n",
      "epoch: 13 [252197/888800 28.38%] train loss: 1.4462952094618231e-05 \n",
      "epoch: 13 [253308/888800 28.50%] train loss: 1.5571868061670102e-05 \n",
      "epoch: 13 [254419/888800 28.62%] train loss: 1.4358608495967928e-05 \n",
      "epoch: 13 [255530/888800 28.75%] train loss: 1.3352392670640256e-05 \n",
      "epoch: 13 [256641/888800 28.88%] train loss: 1.466545927542029e-05 \n",
      "epoch: 13 [257752/888800 29.00%] train loss: 1.432754743291298e-05 \n",
      "epoch: 13 [258863/888800 29.12%] train loss: 1.3718487934966106e-05 \n",
      "epoch: 13 [259974/888800 29.25%] train loss: 1.4898955669195857e-05 \n",
      "epoch: 13 [261085/888800 29.38%] train loss: 1.4152820767776575e-05 \n",
      "epoch: 13 [262196/888800 29.50%] train loss: 1.4992328942753375e-05 \n",
      "epoch: 13 [263307/888800 29.62%] train loss: 1.3512440091290046e-05 \n",
      "epoch: 13 [264418/888800 29.75%] train loss: 1.4130304407444783e-05 \n",
      "epoch: 13 [265529/888800 29.88%] train loss: 1.4766499589313753e-05 \n",
      "epoch: 13 [266640/888800 30.00%] train loss: 1.4160596947476733e-05 \n",
      "epoch: 13 [267751/888800 30.12%] train loss: 1.4172550436342135e-05 \n",
      "epoch: 13 [268862/888800 30.25%] train loss: 1.571770553709939e-05 \n",
      "epoch: 13 [269973/888800 30.38%] train loss: 1.3437757843348663e-05 \n",
      "epoch: 13 [271084/888800 30.50%] train loss: 1.410002096235985e-05 \n",
      "epoch: 13 [272195/888800 30.62%] train loss: 1.4380425454874057e-05 \n",
      "epoch: 13 [273306/888800 30.75%] train loss: 1.5012406947789714e-05 \n",
      "epoch: 13 [274417/888800 30.88%] train loss: 1.313781103817746e-05 \n",
      "epoch: 13 [275528/888800 31.00%] train loss: 1.540756056783721e-05 \n",
      "epoch: 13 [276639/888800 31.12%] train loss: 1.5117837392608635e-05 \n",
      "epoch: 13 [277750/888800 31.25%] train loss: 1.355134736513719e-05 \n",
      "epoch: 13 [278861/888800 31.38%] train loss: 1.341573351965053e-05 \n",
      "epoch: 13 [279972/888800 31.50%] train loss: 1.4569053746527061e-05 \n",
      "epoch: 13 [281083/888800 31.62%] train loss: 1.6034853615565225e-05 \n",
      "epoch: 13 [282194/888800 31.75%] train loss: 1.3637122719956096e-05 \n",
      "epoch: 13 [283305/888800 31.88%] train loss: 1.3877061974199023e-05 \n",
      "epoch: 13 [284416/888800 32.00%] train loss: 1.3359030162973795e-05 \n",
      "epoch: 13 [285527/888800 32.12%] train loss: 1.47763730637962e-05 \n",
      "epoch: 13 [286638/888800 32.25%] train loss: 1.4596307664760388e-05 \n",
      "epoch: 13 [287749/888800 32.38%] train loss: 1.4316894521471113e-05 \n",
      "epoch: 13 [288860/888800 32.50%] train loss: 1.5247602277668193e-05 \n",
      "epoch: 13 [289971/888800 32.62%] train loss: 1.4327632925414946e-05 \n",
      "epoch: 13 [291082/888800 32.75%] train loss: 1.5160178008954972e-05 \n",
      "epoch: 13 [292193/888800 32.88%] train loss: 1.3561599189415574e-05 \n",
      "epoch: 13 [293304/888800 33.00%] train loss: 1.329765836999286e-05 \n",
      "epoch: 13 [294415/888800 33.12%] train loss: 1.5177160094026476e-05 \n",
      "epoch: 13 [295526/888800 33.25%] train loss: 1.4222997378965374e-05 \n",
      "epoch: 13 [296637/888800 33.38%] train loss: 1.3562687854573596e-05 \n",
      "epoch: 13 [297748/888800 33.50%] train loss: 1.290908403461799e-05 \n",
      "epoch: 13 [298859/888800 33.62%] train loss: 1.2986192814423703e-05 \n",
      "epoch: 13 [299970/888800 33.75%] train loss: 1.426567087037256e-05 \n",
      "epoch: 13 [301081/888800 33.88%] train loss: 1.5182419701886829e-05 \n",
      "epoch: 13 [302192/888800 34.00%] train loss: 1.6556250557187013e-05 \n",
      "epoch: 13 [303303/888800 34.12%] train loss: 1.4868875041429419e-05 \n",
      "epoch: 13 [304414/888800 34.25%] train loss: 1.353495281364303e-05 \n",
      "epoch: 13 [305525/888800 34.38%] train loss: 1.472644362365827e-05 \n",
      "epoch: 13 [306636/888800 34.50%] train loss: 1.4120079868007451e-05 \n",
      "epoch: 13 [307747/888800 34.62%] train loss: 1.5636915122740902e-05 \n",
      "epoch: 13 [308858/888800 34.75%] train loss: 1.3784137991024181e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [309969/888800 34.88%] train loss: 1.5267913113348186e-05 \n",
      "epoch: 13 [311080/888800 35.00%] train loss: 1.5888595953583717e-05 \n",
      "epoch: 13 [312191/888800 35.12%] train loss: 1.3669172403751872e-05 \n",
      "epoch: 13 [313302/888800 35.25%] train loss: 1.659693407418672e-05 \n",
      "epoch: 13 [314413/888800 35.38%] train loss: 1.4373568774317391e-05 \n",
      "epoch: 13 [315524/888800 35.50%] train loss: 1.4670729797217064e-05 \n",
      "epoch: 13 [316635/888800 35.62%] train loss: 1.50081423271331e-05 \n",
      "epoch: 13 [317746/888800 35.75%] train loss: 1.4020843991602305e-05 \n",
      "epoch: 13 [318857/888800 35.88%] train loss: 1.5940126104396768e-05 \n",
      "epoch: 13 [319968/888800 36.00%] train loss: 1.4967878087190911e-05 \n",
      "epoch: 13 [321079/888800 36.12%] train loss: 1.2998320926271845e-05 \n",
      "epoch: 13 [322190/888800 36.25%] train loss: 1.4639885193901137e-05 \n",
      "epoch: 13 [323301/888800 36.38%] train loss: 1.4203254977473989e-05 \n",
      "epoch: 13 [324412/888800 36.50%] train loss: 1.4272115549829323e-05 \n",
      "epoch: 13 [325523/888800 36.62%] train loss: 1.6018340829759836e-05 \n",
      "epoch: 13 [326634/888800 36.75%] train loss: 1.3823770132148638e-05 \n",
      "epoch: 13 [327745/888800 36.88%] train loss: 1.4574456145055592e-05 \n",
      "epoch: 13 [328856/888800 37.00%] train loss: 1.4632367310696281e-05 \n",
      "epoch: 13 [329967/888800 37.12%] train loss: 1.381273159495322e-05 \n",
      "epoch: 13 [331078/888800 37.25%] train loss: 1.612802043382544e-05 \n",
      "epoch: 13 [332189/888800 37.38%] train loss: 1.4778944205318112e-05 \n",
      "epoch: 13 [333300/888800 37.50%] train loss: 1.3779309483652469e-05 \n",
      "epoch: 13 [334411/888800 37.62%] train loss: 1.4254292182158679e-05 \n",
      "epoch: 13 [335522/888800 37.75%] train loss: 1.5090809029061347e-05 \n",
      "epoch: 13 [336633/888800 37.88%] train loss: 1.3574907825386617e-05 \n",
      "epoch: 13 [337744/888800 38.00%] train loss: 1.4729243048350327e-05 \n",
      "epoch: 13 [338855/888800 38.12%] train loss: 1.525917832623236e-05 \n",
      "epoch: 13 [339966/888800 38.25%] train loss: 1.4551192180078942e-05 \n",
      "epoch: 13 [341077/888800 38.38%] train loss: 1.3326633052201942e-05 \n",
      "epoch: 13 [342188/888800 38.50%] train loss: 1.3724643395107705e-05 \n",
      "epoch: 13 [343299/888800 38.62%] train loss: 1.400332803314086e-05 \n",
      "epoch: 13 [344410/888800 38.75%] train loss: 1.4079079846851528e-05 \n",
      "epoch: 13 [345521/888800 38.88%] train loss: 1.3126958037901204e-05 \n",
      "epoch: 13 [346632/888800 39.00%] train loss: 1.3735440006712452e-05 \n",
      "epoch: 13 [347743/888800 39.12%] train loss: 1.3876811863156036e-05 \n",
      "epoch: 13 [348854/888800 39.25%] train loss: 1.3723660231335089e-05 \n",
      "epoch: 13 [349965/888800 39.38%] train loss: 1.5121070646273438e-05 \n",
      "epoch: 13 [351076/888800 39.50%] train loss: 1.4331983038573526e-05 \n",
      "epoch: 13 [352187/888800 39.62%] train loss: 1.4338297660287935e-05 \n",
      "epoch: 13 [353298/888800 39.75%] train loss: 1.3981403753859922e-05 \n",
      "epoch: 13 [354409/888800 39.88%] train loss: 1.5149924365687184e-05 \n",
      "epoch: 13 [355520/888800 40.00%] train loss: 1.4426347661355976e-05 \n",
      "epoch: 13 [356631/888800 40.12%] train loss: 1.3826527720084414e-05 \n",
      "epoch: 13 [357742/888800 40.25%] train loss: 1.5183220966719091e-05 \n",
      "epoch: 13 [358853/888800 40.38%] train loss: 1.480820901633706e-05 \n",
      "epoch: 13 [359964/888800 40.50%] train loss: 1.4498119526251685e-05 \n",
      "epoch: 13 [361075/888800 40.62%] train loss: 1.3774324543192051e-05 \n",
      "epoch: 13 [362186/888800 40.75%] train loss: 1.4179813661030494e-05 \n",
      "epoch: 13 [363297/888800 40.88%] train loss: 1.3558219507103786e-05 \n",
      "epoch: 13 [364408/888800 41.00%] train loss: 1.3847692571289372e-05 \n",
      "epoch: 13 [365519/888800 41.12%] train loss: 1.4223223843146116e-05 \n",
      "epoch: 13 [366630/888800 41.25%] train loss: 1.4287797966971993e-05 \n",
      "epoch: 13 [367741/888800 41.38%] train loss: 1.3667552593688015e-05 \n",
      "epoch: 13 [368852/888800 41.50%] train loss: 1.3958570889371913e-05 \n",
      "epoch: 13 [369963/888800 41.62%] train loss: 1.42511735248263e-05 \n",
      "epoch: 13 [371074/888800 41.75%] train loss: 1.572864130139351e-05 \n",
      "epoch: 13 [372185/888800 41.88%] train loss: 1.4081499102758244e-05 \n",
      "epoch: 13 [373296/888800 42.00%] train loss: 1.46140628203284e-05 \n",
      "epoch: 13 [374407/888800 42.12%] train loss: 1.4417697457247414e-05 \n",
      "epoch: 13 [375518/888800 42.25%] train loss: 1.4117692444415297e-05 \n",
      "epoch: 13 [376629/888800 42.38%] train loss: 1.417453859176021e-05 \n",
      "epoch: 13 [377740/888800 42.50%] train loss: 1.3190153367759194e-05 \n",
      "epoch: 13 [378851/888800 42.62%] train loss: 1.4815283975622151e-05 \n",
      "epoch: 13 [379962/888800 42.75%] train loss: 1.4453700714511797e-05 \n",
      "epoch: 13 [381073/888800 42.88%] train loss: 1.5139557945076376e-05 \n",
      "epoch: 13 [382184/888800 43.00%] train loss: 1.3349269465834368e-05 \n",
      "epoch: 13 [383295/888800 43.12%] train loss: 1.708502895780839e-05 \n",
      "epoch: 13 [384406/888800 43.25%] train loss: 1.621923547645565e-05 \n",
      "epoch: 13 [385517/888800 43.38%] train loss: 1.456893551221583e-05 \n",
      "epoch: 13 [386628/888800 43.50%] train loss: 1.4680698768643197e-05 \n",
      "epoch: 13 [387739/888800 43.62%] train loss: 1.4730888324265834e-05 \n",
      "epoch: 13 [388850/888800 43.75%] train loss: 1.611637526366394e-05 \n",
      "epoch: 13 [389961/888800 43.88%] train loss: 1.4722178093506955e-05 \n",
      "epoch: 13 [391072/888800 44.00%] train loss: 1.4827896848146338e-05 \n",
      "epoch: 13 [392183/888800 44.12%] train loss: 1.3711284736928064e-05 \n",
      "epoch: 13 [393294/888800 44.25%] train loss: 1.3909677363699302e-05 \n",
      "epoch: 13 [394405/888800 44.38%] train loss: 1.3850775758328382e-05 \n",
      "epoch: 13 [395516/888800 44.50%] train loss: 1.440557389287278e-05 \n",
      "epoch: 13 [396627/888800 44.62%] train loss: 1.2845613127865363e-05 \n",
      "epoch: 13 [397738/888800 44.75%] train loss: 1.4153216397971846e-05 \n",
      "epoch: 13 [398849/888800 44.88%] train loss: 1.4541414202540182e-05 \n",
      "epoch: 13 [399960/888800 45.00%] train loss: 1.4575790373783093e-05 \n",
      "epoch: 13 [401071/888800 45.12%] train loss: 1.3828220289724413e-05 \n",
      "epoch: 13 [402182/888800 45.25%] train loss: 1.671698373684194e-05 \n",
      "epoch: 13 [403293/888800 45.38%] train loss: 1.3773178579867817e-05 \n",
      "epoch: 13 [404404/888800 45.50%] train loss: 1.3637408301292453e-05 \n",
      "epoch: 13 [405515/888800 45.62%] train loss: 1.4268581253418233e-05 \n",
      "epoch: 13 [406626/888800 45.75%] train loss: 1.354666437691776e-05 \n",
      "epoch: 13 [407737/888800 45.88%] train loss: 1.4664283298770897e-05 \n",
      "epoch: 13 [408848/888800 46.00%] train loss: 1.4425414519791957e-05 \n",
      "epoch: 13 [409959/888800 46.12%] train loss: 1.5004723536549136e-05 \n",
      "epoch: 13 [411070/888800 46.25%] train loss: 1.3048839718976524e-05 \n",
      "epoch: 13 [412181/888800 46.38%] train loss: 1.4504071259580087e-05 \n",
      "epoch: 13 [413292/888800 46.50%] train loss: 1.4786016436119098e-05 \n",
      "epoch: 13 [414403/888800 46.62%] train loss: 1.4484677194559481e-05 \n",
      "epoch: 13 [415514/888800 46.75%] train loss: 1.4639998880738858e-05 \n",
      "epoch: 13 [416625/888800 46.88%] train loss: 1.385104678774951e-05 \n",
      "epoch: 13 [417736/888800 47.00%] train loss: 1.5400957636302337e-05 \n",
      "epoch: 13 [418847/888800 47.12%] train loss: 1.407464333169628e-05 \n",
      "epoch: 13 [419958/888800 47.25%] train loss: 1.3746421245741658e-05 \n",
      "epoch: 13 [421069/888800 47.38%] train loss: 1.3448850040731486e-05 \n",
      "epoch: 13 [422180/888800 47.50%] train loss: 1.4562916476279497e-05 \n",
      "epoch: 13 [423291/888800 47.62%] train loss: 1.4091800949245226e-05 \n",
      "epoch: 13 [424402/888800 47.75%] train loss: 1.341442020930117e-05 \n",
      "epoch: 13 [425513/888800 47.88%] train loss: 1.4446372915699612e-05 \n",
      "epoch: 13 [426624/888800 48.00%] train loss: 1.3673055946128443e-05 \n",
      "epoch: 13 [427735/888800 48.12%] train loss: 1.4477906915999483e-05 \n",
      "epoch: 13 [428846/888800 48.25%] train loss: 1.4389321222552098e-05 \n",
      "epoch: 13 [429957/888800 48.38%] train loss: 1.4539476069330703e-05 \n",
      "epoch: 13 [431068/888800 48.50%] train loss: 1.5871250070631504e-05 \n",
      "epoch: 13 [432179/888800 48.62%] train loss: 1.4443934560404159e-05 \n",
      "epoch: 13 [433290/888800 48.75%] train loss: 1.5838597391848452e-05 \n",
      "epoch: 13 [434401/888800 48.88%] train loss: 1.4745662156201433e-05 \n",
      "epoch: 13 [435512/888800 49.00%] train loss: 1.286472524952842e-05 \n",
      "epoch: 13 [436623/888800 49.12%] train loss: 1.2749659617838915e-05 \n",
      "epoch: 13 [437734/888800 49.25%] train loss: 1.4138717233436182e-05 \n",
      "epoch: 13 [438845/888800 49.38%] train loss: 1.2801156117348e-05 \n",
      "epoch: 13 [439956/888800 49.50%] train loss: 1.4122775610303506e-05 \n",
      "epoch: 13 [441067/888800 49.62%] train loss: 1.4206262676452752e-05 \n",
      "epoch: 13 [442178/888800 49.75%] train loss: 1.3696189853362739e-05 \n",
      "epoch: 13 [443289/888800 49.88%] train loss: 1.5338408047682606e-05 \n",
      "epoch: 13 [444400/888800 50.00%] train loss: 1.5282563254004344e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [445511/888800 50.12%] train loss: 1.5218122825899627e-05 \n",
      "epoch: 13 [446622/888800 50.25%] train loss: 1.4108369214227423e-05 \n",
      "epoch: 13 [447733/888800 50.38%] train loss: 1.3872706404072233e-05 \n",
      "epoch: 13 [448844/888800 50.50%] train loss: 1.3557143574871588e-05 \n",
      "epoch: 13 [449955/888800 50.62%] train loss: 1.5277935744961724e-05 \n",
      "epoch: 13 [451066/888800 50.75%] train loss: 1.4293902495410293e-05 \n",
      "epoch: 13 [452177/888800 50.88%] train loss: 1.4518370335281361e-05 \n",
      "epoch: 13 [453288/888800 51.00%] train loss: 1.598964081495069e-05 \n",
      "epoch: 13 [454399/888800 51.12%] train loss: 1.4696911421197001e-05 \n",
      "epoch: 13 [455510/888800 51.25%] train loss: 1.3593155017588288e-05 \n",
      "epoch: 13 [456621/888800 51.38%] train loss: 1.456429254176328e-05 \n",
      "epoch: 13 [457732/888800 51.50%] train loss: 1.393521779391449e-05 \n",
      "epoch: 13 [458843/888800 51.62%] train loss: 1.4067028132558335e-05 \n",
      "epoch: 13 [459954/888800 51.75%] train loss: 1.4171966540743597e-05 \n",
      "epoch: 13 [461065/888800 51.88%] train loss: 1.3419971764960792e-05 \n",
      "epoch: 13 [462176/888800 52.00%] train loss: 1.4546474631060846e-05 \n",
      "epoch: 13 [463287/888800 52.12%] train loss: 1.4708982234878931e-05 \n",
      "epoch: 13 [464398/888800 52.25%] train loss: 1.3748264791502152e-05 \n",
      "epoch: 13 [465509/888800 52.38%] train loss: 1.462741602153983e-05 \n",
      "epoch: 13 [466620/888800 52.50%] train loss: 1.3555213627114426e-05 \n",
      "epoch: 13 [467731/888800 52.62%] train loss: 1.3788207979814615e-05 \n",
      "epoch: 13 [468842/888800 52.75%] train loss: 1.5086940038600005e-05 \n",
      "epoch: 13 [469953/888800 52.88%] train loss: 1.3897582903155126e-05 \n",
      "epoch: 13 [471064/888800 53.00%] train loss: 1.4614889551012311e-05 \n",
      "epoch: 13 [472175/888800 53.12%] train loss: 1.4321622074930929e-05 \n",
      "epoch: 13 [473286/888800 53.25%] train loss: 1.4299756912805606e-05 \n",
      "epoch: 13 [474397/888800 53.38%] train loss: 1.4790851309953723e-05 \n",
      "epoch: 13 [475508/888800 53.50%] train loss: 1.4427633686864283e-05 \n",
      "epoch: 13 [476619/888800 53.62%] train loss: 1.4371174074767623e-05 \n",
      "epoch: 13 [477730/888800 53.75%] train loss: 1.4513362657453399e-05 \n",
      "epoch: 13 [478841/888800 53.88%] train loss: 1.4077724699745886e-05 \n",
      "epoch: 13 [479952/888800 54.00%] train loss: 1.3817613762512337e-05 \n",
      "epoch: 13 [481063/888800 54.12%] train loss: 1.3895567462895997e-05 \n",
      "epoch: 13 [482174/888800 54.25%] train loss: 1.4921588444849476e-05 \n",
      "epoch: 13 [483285/888800 54.38%] train loss: 1.5139446077228058e-05 \n",
      "epoch: 13 [484396/888800 54.50%] train loss: 1.560211785545107e-05 \n",
      "epoch: 13 [485507/888800 54.62%] train loss: 1.2369660908007063e-05 \n",
      "epoch: 13 [486618/888800 54.75%] train loss: 1.3803782167087775e-05 \n",
      "epoch: 13 [487729/888800 54.88%] train loss: 1.4444107364397496e-05 \n",
      "epoch: 13 [488840/888800 55.00%] train loss: 1.3838118320563808e-05 \n",
      "epoch: 13 [489951/888800 55.12%] train loss: 1.4201384146872442e-05 \n",
      "epoch: 13 [491062/888800 55.25%] train loss: 1.4120721971266903e-05 \n",
      "epoch: 13 [492173/888800 55.38%] train loss: 1.3340842997422442e-05 \n",
      "epoch: 13 [493284/888800 55.50%] train loss: 1.5364181308541447e-05 \n",
      "epoch: 13 [494395/888800 55.62%] train loss: 1.3427638805296738e-05 \n",
      "epoch: 13 [495506/888800 55.75%] train loss: 1.5262874512700364e-05 \n",
      "epoch: 13 [496617/888800 55.88%] train loss: 1.2266511475900188e-05 \n",
      "epoch: 13 [497728/888800 56.00%] train loss: 1.4108930372458417e-05 \n",
      "epoch: 13 [498839/888800 56.12%] train loss: 1.3018721801927313e-05 \n",
      "epoch: 13 [499950/888800 56.25%] train loss: 1.5123157027119305e-05 \n",
      "epoch: 13 [501061/888800 56.38%] train loss: 1.6031768609536812e-05 \n",
      "epoch: 13 [502172/888800 56.50%] train loss: 1.369138317386387e-05 \n",
      "epoch: 13 [503283/888800 56.62%] train loss: 1.4000992450746708e-05 \n",
      "epoch: 13 [504394/888800 56.75%] train loss: 1.480382798035862e-05 \n",
      "epoch: 13 [505505/888800 56.88%] train loss: 1.4115530575509183e-05 \n",
      "epoch: 13 [506616/888800 57.00%] train loss: 1.3975340152683202e-05 \n",
      "epoch: 13 [507727/888800 57.12%] train loss: 1.546722160128411e-05 \n",
      "epoch: 13 [508838/888800 57.25%] train loss: 1.4295193068392109e-05 \n",
      "epoch: 13 [509949/888800 57.38%] train loss: 1.4835190995654557e-05 \n",
      "epoch: 13 [511060/888800 57.50%] train loss: 1.2956898899574298e-05 \n",
      "epoch: 13 [512171/888800 57.62%] train loss: 1.3179128472984303e-05 \n",
      "epoch: 13 [513282/888800 57.75%] train loss: 1.3530786418414209e-05 \n",
      "epoch: 13 [514393/888800 57.88%] train loss: 1.4753675714018755e-05 \n",
      "epoch: 13 [515504/888800 58.00%] train loss: 1.406867795594735e-05 \n",
      "epoch: 13 [516615/888800 58.12%] train loss: 1.437429637007881e-05 \n",
      "epoch: 13 [517726/888800 58.25%] train loss: 1.5005186469352338e-05 \n",
      "epoch: 13 [518837/888800 58.38%] train loss: 1.3718138689000625e-05 \n",
      "epoch: 13 [519948/888800 58.50%] train loss: 1.5598223399138078e-05 \n",
      "epoch: 13 [521059/888800 58.62%] train loss: 1.3749523532169405e-05 \n",
      "epoch: 13 [522170/888800 58.75%] train loss: 1.4059134628041647e-05 \n",
      "epoch: 13 [523281/888800 58.88%] train loss: 1.405662715114886e-05 \n",
      "epoch: 13 [524392/888800 59.00%] train loss: 1.4840985386399552e-05 \n",
      "epoch: 13 [525503/888800 59.12%] train loss: 1.4712955817230977e-05 \n",
      "epoch: 13 [526614/888800 59.25%] train loss: 1.4326918972074054e-05 \n",
      "epoch: 13 [527725/888800 59.38%] train loss: 1.4262450349633582e-05 \n",
      "epoch: 13 [528836/888800 59.50%] train loss: 1.4035145795787685e-05 \n",
      "epoch: 13 [529947/888800 59.62%] train loss: 1.3238476640253793e-05 \n",
      "epoch: 13 [531058/888800 59.75%] train loss: 1.4973457837186288e-05 \n",
      "epoch: 13 [532169/888800 59.88%] train loss: 1.3904355000704527e-05 \n",
      "epoch: 13 [533280/888800 60.00%] train loss: 1.4395402104128152e-05 \n",
      "epoch: 13 [534391/888800 60.12%] train loss: 1.4195778931025416e-05 \n",
      "epoch: 13 [535502/888800 60.25%] train loss: 1.3187998774810694e-05 \n",
      "epoch: 13 [536613/888800 60.38%] train loss: 1.3265156667330302e-05 \n",
      "epoch: 13 [537724/888800 60.50%] train loss: 1.530227018520236e-05 \n",
      "epoch: 13 [538835/888800 60.62%] train loss: 1.355079348286381e-05 \n",
      "epoch: 13 [539946/888800 60.75%] train loss: 1.277420324186096e-05 \n",
      "epoch: 13 [541057/888800 60.88%] train loss: 1.4608413039240986e-05 \n",
      "epoch: 13 [542168/888800 61.00%] train loss: 1.5122980585147161e-05 \n",
      "epoch: 13 [543279/888800 61.12%] train loss: 1.423472713213414e-05 \n",
      "epoch: 13 [544390/888800 61.25%] train loss: 1.3773478713119403e-05 \n",
      "epoch: 13 [545501/888800 61.38%] train loss: 1.3513081285054795e-05 \n",
      "epoch: 13 [546612/888800 61.50%] train loss: 1.4803871636104304e-05 \n",
      "epoch: 13 [547723/888800 61.62%] train loss: 1.3559894796344452e-05 \n",
      "epoch: 13 [548834/888800 61.75%] train loss: 1.515644271421479e-05 \n",
      "epoch: 13 [549945/888800 61.88%] train loss: 1.3826429494656622e-05 \n",
      "epoch: 13 [551056/888800 62.00%] train loss: 1.3441005648928694e-05 \n",
      "epoch: 13 [552167/888800 62.12%] train loss: 1.6645441064611077e-05 \n",
      "epoch: 13 [553278/888800 62.25%] train loss: 1.3811169992550276e-05 \n",
      "epoch: 13 [554389/888800 62.38%] train loss: 1.5181698472588323e-05 \n",
      "epoch: 13 [555500/888800 62.50%] train loss: 1.4078684216656256e-05 \n",
      "epoch: 13 [556611/888800 62.62%] train loss: 1.4636927517130971e-05 \n",
      "epoch: 13 [557722/888800 62.75%] train loss: 1.2817917195206974e-05 \n",
      "epoch: 13 [558833/888800 62.88%] train loss: 1.3762170055997558e-05 \n",
      "epoch: 13 [559944/888800 63.00%] train loss: 1.413699283148162e-05 \n",
      "epoch: 13 [561055/888800 63.12%] train loss: 1.3705272976949345e-05 \n",
      "epoch: 13 [562166/888800 63.25%] train loss: 1.526318010292016e-05 \n",
      "epoch: 13 [563277/888800 63.38%] train loss: 1.4898602785251569e-05 \n",
      "epoch: 13 [564388/888800 63.50%] train loss: 1.3548915376304649e-05 \n",
      "epoch: 13 [565499/888800 63.62%] train loss: 1.3664626749232411e-05 \n",
      "epoch: 13 [566610/888800 63.75%] train loss: 1.511512073193444e-05 \n",
      "epoch: 13 [567721/888800 63.88%] train loss: 1.4626751180912834e-05 \n",
      "epoch: 13 [568832/888800 64.00%] train loss: 1.5031593648018315e-05 \n",
      "epoch: 13 [569943/888800 64.12%] train loss: 1.4240967175283004e-05 \n",
      "epoch: 13 [571054/888800 64.25%] train loss: 1.4698849554406479e-05 \n",
      "epoch: 13 [572165/888800 64.38%] train loss: 1.3571507224696688e-05 \n",
      "epoch: 13 [573276/888800 64.50%] train loss: 1.4631435078626964e-05 \n",
      "epoch: 13 [574387/888800 64.62%] train loss: 1.5862333384575322e-05 \n",
      "epoch: 13 [575498/888800 64.75%] train loss: 1.3938523807155434e-05 \n",
      "epoch: 13 [576609/888800 64.88%] train loss: 1.3904948900744785e-05 \n",
      "epoch: 13 [577720/888800 65.00%] train loss: 1.4648717296950053e-05 \n",
      "epoch: 13 [578831/888800 65.12%] train loss: 1.5007900401542429e-05 \n",
      "epoch: 13 [579942/888800 65.25%] train loss: 1.399268330715131e-05 \n",
      "epoch: 13 [581053/888800 65.38%] train loss: 1.3911936548538506e-05 \n",
      "epoch: 13 [582164/888800 65.50%] train loss: 1.5108473235159181e-05 \n",
      "epoch: 13 [583275/888800 65.62%] train loss: 1.4902834664098918e-05 \n",
      "epoch: 13 [584386/888800 65.75%] train loss: 1.4804066267970484e-05 \n",
      "epoch: 13 [585497/888800 65.88%] train loss: 1.3600489182863384e-05 \n",
      "epoch: 13 [586608/888800 66.00%] train loss: 1.4729293980053626e-05 \n",
      "epoch: 13 [587719/888800 66.12%] train loss: 1.4072410522203427e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [588830/888800 66.25%] train loss: 1.6118443454615772e-05 \n",
      "epoch: 13 [589941/888800 66.38%] train loss: 1.4539656149281655e-05 \n",
      "epoch: 13 [591052/888800 66.50%] train loss: 1.4994518096500542e-05 \n",
      "epoch: 13 [592163/888800 66.62%] train loss: 1.413305744790705e-05 \n",
      "epoch: 13 [593274/888800 66.75%] train loss: 1.2301613423915114e-05 \n",
      "epoch: 13 [594385/888800 66.88%] train loss: 1.5074178008944727e-05 \n",
      "epoch: 13 [595496/888800 67.00%] train loss: 1.3648515050590504e-05 \n",
      "epoch: 13 [596607/888800 67.12%] train loss: 1.6620677342871204e-05 \n",
      "epoch: 13 [597718/888800 67.25%] train loss: 1.4311526683741249e-05 \n",
      "epoch: 13 [598829/888800 67.38%] train loss: 1.40518259286182e-05 \n",
      "epoch: 13 [599940/888800 67.50%] train loss: 1.4381969776877668e-05 \n",
      "epoch: 13 [601051/888800 67.62%] train loss: 1.3411119653028436e-05 \n",
      "epoch: 13 [602162/888800 67.75%] train loss: 1.3974824469187297e-05 \n",
      "epoch: 13 [603273/888800 67.88%] train loss: 1.4131492207525298e-05 \n",
      "epoch: 13 [604384/888800 68.00%] train loss: 1.3331672562344465e-05 \n",
      "epoch: 13 [605495/888800 68.12%] train loss: 1.7429936633561738e-05 \n",
      "epoch: 13 [606606/888800 68.25%] train loss: 1.4344012924993876e-05 \n",
      "epoch: 13 [607717/888800 68.38%] train loss: 1.6430311006843112e-05 \n",
      "epoch: 13 [608828/888800 68.50%] train loss: 1.5184689800662454e-05 \n",
      "epoch: 13 [609939/888800 68.62%] train loss: 1.557577525090892e-05 \n",
      "epoch: 13 [611050/888800 68.75%] train loss: 1.4333881154016126e-05 \n",
      "epoch: 13 [612161/888800 68.88%] train loss: 1.6702844732208177e-05 \n",
      "epoch: 13 [613272/888800 69.00%] train loss: 1.592404987604823e-05 \n",
      "epoch: 13 [614383/888800 69.12%] train loss: 1.4552744687534869e-05 \n",
      "epoch: 13 [615494/888800 69.25%] train loss: 1.6217349184444174e-05 \n",
      "epoch: 13 [616605/888800 69.38%] train loss: 1.3598151781479828e-05 \n",
      "epoch: 13 [617716/888800 69.50%] train loss: 1.5165752301982138e-05 \n",
      "epoch: 13 [618827/888800 69.62%] train loss: 1.339871232630685e-05 \n",
      "epoch: 13 [619938/888800 69.75%] train loss: 1.6040812624851242e-05 \n",
      "epoch: 13 [621049/888800 69.88%] train loss: 1.408525258739246e-05 \n",
      "epoch: 13 [622160/888800 70.00%] train loss: 1.4596967048419174e-05 \n",
      "epoch: 13 [623271/888800 70.12%] train loss: 1.4235037269827444e-05 \n",
      "epoch: 13 [624382/888800 70.25%] train loss: 1.3936471077613533e-05 \n",
      "epoch: 13 [625493/888800 70.38%] train loss: 1.3635812138090841e-05 \n",
      "epoch: 13 [626604/888800 70.50%] train loss: 1.4134338925941847e-05 \n",
      "epoch: 13 [627715/888800 70.62%] train loss: 1.5967414583428763e-05 \n",
      "epoch: 13 [628826/888800 70.75%] train loss: 1.361602062388556e-05 \n",
      "epoch: 13 [629937/888800 70.88%] train loss: 1.4737019228050485e-05 \n",
      "epoch: 13 [631048/888800 71.00%] train loss: 1.408929438184714e-05 \n",
      "epoch: 13 [632159/888800 71.12%] train loss: 1.4884160009387415e-05 \n",
      "epoch: 13 [633270/888800 71.25%] train loss: 1.407411491527455e-05 \n",
      "epoch: 13 [634381/888800 71.38%] train loss: 1.4445695342146792e-05 \n",
      "epoch: 13 [635492/888800 71.50%] train loss: 1.3589039554062765e-05 \n",
      "epoch: 13 [636603/888800 71.62%] train loss: 1.5419933333760127e-05 \n",
      "epoch: 13 [637714/888800 71.75%] train loss: 1.4920453395461664e-05 \n",
      "epoch: 13 [638825/888800 71.88%] train loss: 1.3590516573458444e-05 \n",
      "epoch: 13 [639936/888800 72.00%] train loss: 1.2741324098897167e-05 \n",
      "epoch: 13 [641047/888800 72.12%] train loss: 1.51526000990998e-05 \n",
      "epoch: 13 [642158/888800 72.25%] train loss: 1.4079820175538771e-05 \n",
      "epoch: 13 [643269/888800 72.38%] train loss: 1.422540663043037e-05 \n",
      "epoch: 13 [644380/888800 72.50%] train loss: 1.4319633919512853e-05 \n",
      "epoch: 13 [645491/888800 72.62%] train loss: 1.5166468983807135e-05 \n",
      "epoch: 13 [646602/888800 72.75%] train loss: 1.5015223652881104e-05 \n",
      "epoch: 13 [647713/888800 72.88%] train loss: 1.4486423424386885e-05 \n",
      "epoch: 13 [648824/888800 73.00%] train loss: 1.2890163816337008e-05 \n",
      "epoch: 13 [649935/888800 73.12%] train loss: 1.3779713299300056e-05 \n",
      "epoch: 13 [651046/888800 73.25%] train loss: 1.573062763782218e-05 \n",
      "epoch: 13 [652157/888800 73.38%] train loss: 1.4456237295235042e-05 \n",
      "epoch: 13 [653268/888800 73.50%] train loss: 1.2867787518189289e-05 \n",
      "epoch: 13 [654379/888800 73.62%] train loss: 1.655986488913186e-05 \n",
      "epoch: 13 [655490/888800 73.75%] train loss: 1.6848412997205742e-05 \n",
      "epoch: 13 [656601/888800 73.88%] train loss: 1.3828786904923618e-05 \n",
      "epoch: 13 [657712/888800 74.00%] train loss: 1.796093965822365e-05 \n",
      "epoch: 13 [658823/888800 74.12%] train loss: 1.4436752280744258e-05 \n",
      "epoch: 13 [659934/888800 74.25%] train loss: 1.5804393115104176e-05 \n",
      "epoch: 13 [661045/888800 74.38%] train loss: 1.4081597328186035e-05 \n",
      "epoch: 13 [662156/888800 74.50%] train loss: 1.57120157382451e-05 \n",
      "epoch: 13 [663267/888800 74.62%] train loss: 1.4981904314481653e-05 \n",
      "epoch: 13 [664378/888800 74.75%] train loss: 1.566304126754403e-05 \n",
      "epoch: 13 [665489/888800 74.88%] train loss: 1.54338722495595e-05 \n",
      "epoch: 13 [666600/888800 75.00%] train loss: 1.5620269550709054e-05 \n",
      "epoch: 13 [667711/888800 75.12%] train loss: 1.540039011160843e-05 \n",
      "epoch: 13 [668822/888800 75.25%] train loss: 1.3709915037907194e-05 \n",
      "epoch: 13 [669933/888800 75.38%] train loss: 1.726751906971913e-05 \n",
      "epoch: 13 [671044/888800 75.50%] train loss: 1.3040276826359332e-05 \n",
      "epoch: 13 [672155/888800 75.62%] train loss: 1.6534966562176123e-05 \n",
      "epoch: 13 [673266/888800 75.75%] train loss: 1.3378045878198463e-05 \n",
      "epoch: 13 [674377/888800 75.88%] train loss: 1.6777861674199812e-05 \n",
      "epoch: 13 [675488/888800 76.00%] train loss: 1.5671321307308972e-05 \n",
      "epoch: 13 [676599/888800 76.12%] train loss: 1.4186630323820282e-05 \n",
      "epoch: 13 [677710/888800 76.25%] train loss: 1.584581332281232e-05 \n",
      "epoch: 13 [678821/888800 76.38%] train loss: 1.409738433721941e-05 \n",
      "epoch: 13 [679932/888800 76.50%] train loss: 1.6343874449376017e-05 \n",
      "epoch: 13 [681043/888800 76.62%] train loss: 1.4973004908824805e-05 \n",
      "epoch: 13 [682154/888800 76.75%] train loss: 1.5122248441912234e-05 \n",
      "epoch: 13 [683265/888800 76.88%] train loss: 1.4324907169793732e-05 \n",
      "epoch: 13 [684376/888800 77.00%] train loss: 1.4494665265374351e-05 \n",
      "epoch: 13 [685487/888800 77.12%] train loss: 1.4367754374688957e-05 \n",
      "epoch: 13 [686598/888800 77.25%] train loss: 1.3697138456336688e-05 \n",
      "epoch: 13 [687709/888800 77.38%] train loss: 1.3880495316698216e-05 \n",
      "epoch: 13 [688820/888800 77.50%] train loss: 1.4895759704813827e-05 \n",
      "epoch: 13 [689931/888800 77.62%] train loss: 1.3956925613456406e-05 \n",
      "epoch: 13 [691042/888800 77.75%] train loss: 1.3369348380365409e-05 \n",
      "epoch: 13 [692153/888800 77.88%] train loss: 1.3388090337684844e-05 \n",
      "epoch: 13 [693264/888800 78.00%] train loss: 1.378914384986274e-05 \n",
      "epoch: 13 [694375/888800 78.12%] train loss: 1.4454939446295612e-05 \n",
      "epoch: 13 [695486/888800 78.25%] train loss: 1.5009697563073132e-05 \n",
      "epoch: 13 [696597/888800 78.38%] train loss: 1.476341458328534e-05 \n",
      "epoch: 13 [697708/888800 78.50%] train loss: 1.4268975064624101e-05 \n",
      "epoch: 13 [698819/888800 78.62%] train loss: 1.3609183042717632e-05 \n",
      "epoch: 13 [699930/888800 78.75%] train loss: 1.4546658348990604e-05 \n",
      "epoch: 13 [701041/888800 78.88%] train loss: 1.3588553883892018e-05 \n",
      "epoch: 13 [702152/888800 79.00%] train loss: 1.5053050447022542e-05 \n",
      "epoch: 13 [703263/888800 79.12%] train loss: 1.4752196875633672e-05 \n",
      "epoch: 13 [704374/888800 79.25%] train loss: 1.4781828213017434e-05 \n",
      "epoch: 13 [705485/888800 79.38%] train loss: 1.4566013305739034e-05 \n",
      "epoch: 13 [706596/888800 79.50%] train loss: 1.2805740880139638e-05 \n",
      "epoch: 13 [707707/888800 79.62%] train loss: 1.3935522474639583e-05 \n",
      "epoch: 13 [708818/888800 79.75%] train loss: 1.4751719390915241e-05 \n",
      "epoch: 13 [709929/888800 79.88%] train loss: 1.32044688143651e-05 \n",
      "epoch: 13 [711040/888800 80.00%] train loss: 1.4323057257570326e-05 \n",
      "epoch: 13 [712151/888800 80.12%] train loss: 1.4790120076213498e-05 \n",
      "epoch: 13 [713262/888800 80.25%] train loss: 1.4559318515239283e-05 \n",
      "epoch: 13 [714373/888800 80.38%] train loss: 1.5186788004939444e-05 \n",
      "epoch: 13 [715484/888800 80.50%] train loss: 1.4630159057560377e-05 \n",
      "epoch: 13 [716595/888800 80.62%] train loss: 1.5053796232677996e-05 \n",
      "epoch: 13 [717706/888800 80.75%] train loss: 1.3648584172187839e-05 \n",
      "epoch: 13 [718817/888800 80.88%] train loss: 1.543913094792515e-05 \n",
      "epoch: 13 [719928/888800 81.00%] train loss: 1.5230029930535238e-05 \n",
      "epoch: 13 [721039/888800 81.12%] train loss: 1.5202635040623136e-05 \n",
      "epoch: 13 [722150/888800 81.25%] train loss: 1.658858855080325e-05 \n",
      "epoch: 13 [723261/888800 81.38%] train loss: 1.4020146409166045e-05 \n",
      "epoch: 13 [724372/888800 81.50%] train loss: 1.5803920177859254e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [725483/888800 81.62%] train loss: 1.407352010573959e-05 \n",
      "epoch: 13 [726594/888800 81.75%] train loss: 1.4626576557930093e-05 \n",
      "epoch: 13 [727705/888800 81.88%] train loss: 1.5272338714567013e-05 \n",
      "epoch: 13 [728816/888800 82.00%] train loss: 1.3565411791205406e-05 \n",
      "epoch: 13 [729927/888800 82.12%] train loss: 1.3751462574873585e-05 \n",
      "epoch: 13 [731038/888800 82.25%] train loss: 1.4271676263888367e-05 \n",
      "epoch: 13 [732149/888800 82.38%] train loss: 1.415830683981767e-05 \n",
      "epoch: 13 [733260/888800 82.50%] train loss: 1.6225209037656896e-05 \n",
      "epoch: 13 [734371/888800 82.62%] train loss: 1.2661836990446318e-05 \n",
      "epoch: 13 [735482/888800 82.75%] train loss: 1.459113718738081e-05 \n",
      "epoch: 13 [736593/888800 82.88%] train loss: 1.4802382793277502e-05 \n",
      "epoch: 13 [737704/888800 83.00%] train loss: 1.6212128684855998e-05 \n",
      "epoch: 13 [738815/888800 83.12%] train loss: 1.4317514796857722e-05 \n",
      "epoch: 13 [739926/888800 83.25%] train loss: 1.4528822248394135e-05 \n",
      "epoch: 13 [741037/888800 83.38%] train loss: 1.4233789443096612e-05 \n",
      "epoch: 13 [742148/888800 83.50%] train loss: 1.569367668707855e-05 \n",
      "epoch: 13 [743259/888800 83.62%] train loss: 1.3115702131472062e-05 \n",
      "epoch: 13 [744370/888800 83.75%] train loss: 1.4218407159205526e-05 \n",
      "epoch: 13 [745481/888800 83.88%] train loss: 1.4483694030786864e-05 \n",
      "epoch: 13 [746592/888800 84.00%] train loss: 1.5086829080246389e-05 \n",
      "epoch: 13 [747703/888800 84.12%] train loss: 1.4599750102206599e-05 \n",
      "epoch: 13 [748814/888800 84.25%] train loss: 1.3543410204874817e-05 \n",
      "epoch: 13 [749925/888800 84.38%] train loss: 1.3914712326368317e-05 \n",
      "epoch: 13 [751036/888800 84.50%] train loss: 1.4455223208642565e-05 \n",
      "epoch: 13 [752147/888800 84.62%] train loss: 1.3904250408813823e-05 \n",
      "epoch: 13 [753258/888800 84.75%] train loss: 1.4093092431721743e-05 \n",
      "epoch: 13 [754369/888800 84.88%] train loss: 1.4107689821685199e-05 \n",
      "epoch: 13 [755480/888800 85.00%] train loss: 1.3455769476422574e-05 \n",
      "epoch: 13 [756591/888800 85.12%] train loss: 1.5407988030347042e-05 \n",
      "epoch: 13 [757702/888800 85.25%] train loss: 1.50405630847672e-05 \n",
      "epoch: 13 [758813/888800 85.38%] train loss: 1.5057888958835974e-05 \n",
      "epoch: 13 [759924/888800 85.50%] train loss: 1.4220275261322968e-05 \n",
      "epoch: 13 [761035/888800 85.62%] train loss: 1.4327262761071324e-05 \n",
      "epoch: 13 [762146/888800 85.75%] train loss: 1.456203062843997e-05 \n",
      "epoch: 13 [763257/888800 85.88%] train loss: 1.4204480066837277e-05 \n",
      "epoch: 13 [764368/888800 86.00%] train loss: 1.4277236005000304e-05 \n",
      "epoch: 13 [765479/888800 86.12%] train loss: 1.483974756411044e-05 \n",
      "epoch: 13 [766590/888800 86.25%] train loss: 1.4634684703196399e-05 \n",
      "epoch: 13 [767701/888800 86.38%] train loss: 1.4486266081803478e-05 \n",
      "epoch: 13 [768812/888800 86.50%] train loss: 1.407602849212708e-05 \n",
      "epoch: 13 [769923/888800 86.62%] train loss: 1.4533434296026826e-05 \n",
      "epoch: 13 [771034/888800 86.75%] train loss: 1.3258605576993432e-05 \n",
      "epoch: 13 [772145/888800 86.88%] train loss: 1.4370865756063722e-05 \n",
      "epoch: 13 [773256/888800 87.00%] train loss: 1.5685824109823443e-05 \n",
      "epoch: 13 [774367/888800 87.12%] train loss: 1.3604845662484877e-05 \n",
      "epoch: 13 [775478/888800 87.25%] train loss: 1.5048154637042899e-05 \n",
      "epoch: 13 [776589/888800 87.38%] train loss: 1.4505274521070533e-05 \n",
      "epoch: 13 [777700/888800 87.50%] train loss: 1.364561467198655e-05 \n",
      "epoch: 13 [778811/888800 87.62%] train loss: 1.4210932931746356e-05 \n",
      "epoch: 13 [779922/888800 87.75%] train loss: 1.3509463315131143e-05 \n",
      "epoch: 13 [781033/888800 87.88%] train loss: 1.5054518371471204e-05 \n",
      "epoch: 13 [782144/888800 88.00%] train loss: 1.4484242456092034e-05 \n",
      "epoch: 13 [783255/888800 88.12%] train loss: 1.4666694369225297e-05 \n",
      "epoch: 13 [784366/888800 88.25%] train loss: 1.3507826224667951e-05 \n",
      "epoch: 13 [785477/888800 88.38%] train loss: 1.5494986655539833e-05 \n",
      "epoch: 13 [786588/888800 88.50%] train loss: 1.380227149638813e-05 \n",
      "epoch: 13 [787699/888800 88.62%] train loss: 1.5235569662763737e-05 \n",
      "epoch: 13 [788810/888800 88.75%] train loss: 1.4487548469332978e-05 \n",
      "epoch: 13 [789921/888800 88.88%] train loss: 1.3103243873047177e-05 \n",
      "epoch: 13 [791032/888800 89.00%] train loss: 1.3398177543422207e-05 \n",
      "epoch: 13 [792143/888800 89.12%] train loss: 1.4123759683570825e-05 \n",
      "epoch: 13 [793254/888800 89.25%] train loss: 1.4032476428837981e-05 \n",
      "epoch: 13 [794365/888800 89.38%] train loss: 1.6372134268749505e-05 \n",
      "epoch: 13 [795476/888800 89.50%] train loss: 1.3756532098341268e-05 \n",
      "epoch: 13 [796587/888800 89.62%] train loss: 1.4156165889289696e-05 \n",
      "epoch: 13 [797698/888800 89.75%] train loss: 1.465431705582887e-05 \n",
      "epoch: 13 [798809/888800 89.88%] train loss: 1.4152840776660014e-05 \n",
      "epoch: 13 [799920/888800 90.00%] train loss: 1.3949308595329057e-05 \n",
      "epoch: 13 [801031/888800 90.12%] train loss: 1.4824160643911455e-05 \n",
      "epoch: 13 [802142/888800 90.25%] train loss: 1.66127756529022e-05 \n",
      "epoch: 13 [803253/888800 90.38%] train loss: 1.3825794667354785e-05 \n",
      "epoch: 13 [804364/888800 90.50%] train loss: 1.4409121831704397e-05 \n",
      "epoch: 13 [805475/888800 90.62%] train loss: 1.4683197150588967e-05 \n",
      "epoch: 13 [806586/888800 90.75%] train loss: 1.4414825272979215e-05 \n",
      "epoch: 13 [807697/888800 90.88%] train loss: 1.2988402886549011e-05 \n",
      "epoch: 13 [808808/888800 91.00%] train loss: 1.4485568499367218e-05 \n",
      "epoch: 13 [809919/888800 91.12%] train loss: 1.2740003512590192e-05 \n",
      "epoch: 13 [811030/888800 91.25%] train loss: 1.4554892004525755e-05 \n",
      "epoch: 13 [812141/888800 91.38%] train loss: 1.618337228137534e-05 \n",
      "epoch: 13 [813252/888800 91.50%] train loss: 1.3530131582228933e-05 \n",
      "epoch: 13 [814363/888800 91.62%] train loss: 1.4717478734382894e-05 \n",
      "epoch: 13 [815474/888800 91.75%] train loss: 1.393200182064902e-05 \n",
      "epoch: 13 [816585/888800 91.88%] train loss: 1.4175520846038125e-05 \n",
      "epoch: 13 [817696/888800 92.00%] train loss: 1.2816078196919989e-05 \n",
      "epoch: 13 [818807/888800 92.12%] train loss: 1.4575322893506382e-05 \n",
      "epoch: 13 [819918/888800 92.25%] train loss: 1.3485278032021597e-05 \n",
      "epoch: 13 [821029/888800 92.38%] train loss: 1.3410209248831961e-05 \n",
      "epoch: 13 [822140/888800 92.50%] train loss: 1.6068079276010394e-05 \n",
      "epoch: 13 [823251/888800 92.62%] train loss: 1.3568126632890198e-05 \n",
      "epoch: 13 [824362/888800 92.75%] train loss: 1.3346910236577969e-05 \n",
      "epoch: 13 [825473/888800 92.88%] train loss: 1.4273079614213202e-05 \n",
      "epoch: 13 [826584/888800 93.00%] train loss: 1.4118947547103744e-05 \n",
      "epoch: 13 [827695/888800 93.12%] train loss: 1.432768658560235e-05 \n",
      "epoch: 13 [828806/888800 93.25%] train loss: 1.472324765927624e-05 \n",
      "epoch: 13 [829917/888800 93.38%] train loss: 1.3975956790091004e-05 \n",
      "epoch: 13 [831028/888800 93.50%] train loss: 1.3034355106356088e-05 \n",
      "epoch: 13 [832139/888800 93.62%] train loss: 1.4503870261250995e-05 \n",
      "epoch: 13 [833250/888800 93.75%] train loss: 1.4450464732362889e-05 \n",
      "epoch: 13 [834361/888800 93.88%] train loss: 1.4466526408796199e-05 \n",
      "epoch: 13 [835472/888800 94.00%] train loss: 1.362349939881824e-05 \n",
      "epoch: 13 [836583/888800 94.12%] train loss: 1.3307038898346946e-05 \n",
      "epoch: 13 [837694/888800 94.25%] train loss: 1.4515193470288068e-05 \n",
      "epoch: 13 [838805/888800 94.38%] train loss: 1.4595398170058616e-05 \n",
      "epoch: 13 [839916/888800 94.50%] train loss: 1.409795368090272e-05 \n",
      "epoch: 13 [841027/888800 94.62%] train loss: 1.460434214095585e-05 \n",
      "epoch: 13 [842138/888800 94.75%] train loss: 1.3408191080088727e-05 \n",
      "epoch: 13 [843249/888800 94.88%] train loss: 1.4814869246038143e-05 \n",
      "epoch: 13 [844360/888800 95.00%] train loss: 1.378726119583007e-05 \n",
      "epoch: 13 [845471/888800 95.12%] train loss: 1.3906755157222506e-05 \n",
      "epoch: 13 [846582/888800 95.25%] train loss: 1.4054571693122853e-05 \n",
      "epoch: 13 [847693/888800 95.38%] train loss: 1.512001017545117e-05 \n",
      "epoch: 13 [848804/888800 95.50%] train loss: 1.4588163139706012e-05 \n",
      "epoch: 13 [849915/888800 95.62%] train loss: 1.3944541933597066e-05 \n",
      "epoch: 13 [851026/888800 95.75%] train loss: 1.4505707440548576e-05 \n",
      "epoch: 13 [852137/888800 95.88%] train loss: 1.5616047676303424e-05 \n",
      "epoch: 13 [853248/888800 96.00%] train loss: 1.5179422007349785e-05 \n",
      "epoch: 13 [854359/888800 96.12%] train loss: 1.476211673434591e-05 \n",
      "epoch: 13 [855470/888800 96.25%] train loss: 1.4393284800462425e-05 \n",
      "epoch: 13 [856581/888800 96.38%] train loss: 1.4716975783812813e-05 \n",
      "epoch: 13 [857692/888800 96.50%] train loss: 1.5224084563669749e-05 \n",
      "epoch: 13 [858803/888800 96.62%] train loss: 1.3792383469990455e-05 \n",
      "epoch: 13 [859914/888800 96.75%] train loss: 1.4122560969553888e-05 \n",
      "epoch: 13 [861025/888800 96.88%] train loss: 1.539939512440469e-05 \n",
      "epoch: 13 [862136/888800 97.00%] train loss: 1.493345553171821e-05 \n",
      "epoch: 13 [863247/888800 97.12%] train loss: 1.42974968184717e-05 \n",
      "epoch: 13 [864358/888800 97.25%] train loss: 1.4404635294340551e-05 \n",
      "epoch: 13 [865469/888800 97.38%] train loss: 1.3857267731509637e-05 \n",
      "epoch: 13 [866580/888800 97.50%] train loss: 1.4811731489317026e-05 \n",
      "epoch: 13 [867691/888800 97.62%] train loss: 1.5135196008486673e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 [868802/888800 97.75%] train loss: 1.3848701200913638e-05 \n",
      "epoch: 13 [869913/888800 97.88%] train loss: 1.398239783156896e-05 \n",
      "epoch: 13 [871024/888800 98.00%] train loss: 1.3238502106105443e-05 \n",
      "epoch: 13 [872135/888800 98.12%] train loss: 1.552613866806496e-05 \n",
      "epoch: 13 [873246/888800 98.25%] train loss: 1.4524830476148054e-05 \n",
      "epoch: 13 [874357/888800 98.38%] train loss: 1.3976457921671681e-05 \n",
      "epoch: 13 [875468/888800 98.50%] train loss: 1.4288297279563267e-05 \n",
      "epoch: 13 [876579/888800 98.62%] train loss: 1.3635710274684243e-05 \n",
      "epoch: 13 [877690/888800 98.75%] train loss: 1.4231300156097859e-05 \n",
      "epoch: 13 [878801/888800 98.88%] train loss: 1.4814279893471394e-05 \n",
      "epoch: 13 [879912/888800 99.00%] train loss: 1.408125081070466e-05 \n",
      "epoch: 13 [881023/888800 99.12%] train loss: 1.4104234651313163e-05 \n",
      "epoch: 13 [882134/888800 99.25%] train loss: 1.362298644380644e-05 \n",
      "epoch: 13 [883245/888800 99.38%] train loss: 1.392859576299088e-05 \n",
      "epoch: 13 [884356/888800 99.50%] train loss: 1.4336896128952503e-05 \n",
      "epoch: 13 [885467/888800 99.62%] train loss: 1.4611090591643006e-05 \n",
      "epoch: 13 [886578/888800 99.75%] train loss: 1.549826811242383e-05 \n",
      "epoch: 13 [887689/888800 99.88%] train loss: 1.3345853403734509e-05 \n",
      "epoch: 14 [0/888800 0.00%] train loss: 1.3584690350398887e-05 \n",
      "epoch: 14 [1111/888800 0.12%] train loss: 1.4605680007662158e-05 \n",
      "epoch: 14 [2222/888800 0.25%] train loss: 1.3894060430175159e-05 \n",
      "epoch: 14 [3333/888800 0.38%] train loss: 1.4643231224908959e-05 \n",
      "epoch: 14 [4444/888800 0.50%] train loss: 1.4160204045765568e-05 \n",
      "epoch: 14 [5555/888800 0.62%] train loss: 1.4656186067441013e-05 \n",
      "epoch: 14 [6666/888800 0.75%] train loss: 1.332855117652798e-05 \n",
      "epoch: 14 [7777/888800 0.88%] train loss: 1.5993779015843756e-05 \n",
      "epoch: 14 [8888/888800 1.00%] train loss: 1.4304428077593911e-05 \n",
      "epoch: 14 [9999/888800 1.12%] train loss: 1.5066999367263634e-05 \n",
      "epoch: 14 [11110/888800 1.25%] train loss: 1.4759017176402267e-05 \n",
      "epoch: 14 [12221/888800 1.38%] train loss: 1.6095544197014533e-05 \n",
      "epoch: 14 [13332/888800 1.50%] train loss: 1.3024574400333222e-05 \n",
      "epoch: 14 [14443/888800 1.62%] train loss: 1.4515253496938385e-05 \n",
      "epoch: 14 [15554/888800 1.75%] train loss: 1.3918341210228391e-05 \n",
      "epoch: 14 [16665/888800 1.88%] train loss: 1.3977702110423706e-05 \n",
      "epoch: 14 [17776/888800 2.00%] train loss: 1.4600926988350693e-05 \n",
      "epoch: 14 [18887/888800 2.12%] train loss: 1.4304460819403175e-05 \n",
      "epoch: 14 [19998/888800 2.25%] train loss: 1.4546762940881308e-05 \n",
      "epoch: 14 [21109/888800 2.38%] train loss: 1.5202440408756956e-05 \n",
      "epoch: 14 [22220/888800 2.50%] train loss: 1.719919964671135e-05 \n",
      "epoch: 14 [23331/888800 2.62%] train loss: 1.370805057376856e-05 \n",
      "epoch: 14 [24442/888800 2.75%] train loss: 1.3559558283304796e-05 \n",
      "epoch: 14 [25553/888800 2.88%] train loss: 1.4042500879440922e-05 \n",
      "epoch: 14 [26664/888800 3.00%] train loss: 1.46769043567474e-05 \n",
      "epoch: 14 [27775/888800 3.12%] train loss: 1.5196176718745846e-05 \n",
      "epoch: 14 [28886/888800 3.25%] train loss: 1.3767323252977803e-05 \n",
      "epoch: 14 [29997/888800 3.38%] train loss: 1.5001439351181034e-05 \n",
      "epoch: 14 [31108/888800 3.50%] train loss: 1.4275644389272202e-05 \n",
      "epoch: 14 [32219/888800 3.62%] train loss: 1.5721474483143538e-05 \n",
      "epoch: 14 [33330/888800 3.75%] train loss: 1.4876693967380561e-05 \n",
      "epoch: 14 [34441/888800 3.88%] train loss: 1.3435951586870942e-05 \n",
      "epoch: 14 [35552/888800 4.00%] train loss: 1.502736904512858e-05 \n",
      "epoch: 14 [36663/888800 4.12%] train loss: 1.5879493730608374e-05 \n",
      "epoch: 14 [37774/888800 4.25%] train loss: 1.3009130270802416e-05 \n",
      "epoch: 14 [38885/888800 4.38%] train loss: 1.5014674318081234e-05 \n",
      "epoch: 14 [39996/888800 4.50%] train loss: 1.4704294699185994e-05 \n",
      "epoch: 14 [41107/888800 4.62%] train loss: 1.4844599718344398e-05 \n",
      "epoch: 14 [42218/888800 4.75%] train loss: 1.3917961950937752e-05 \n",
      "epoch: 14 [43329/888800 4.88%] train loss: 1.5214694940368645e-05 \n",
      "epoch: 14 [44440/888800 5.00%] train loss: 1.483223240938969e-05 \n",
      "epoch: 14 [45551/888800 5.12%] train loss: 1.4252880646381527e-05 \n",
      "epoch: 14 [46662/888800 5.25%] train loss: 1.7946731531992555e-05 \n",
      "epoch: 14 [47773/888800 5.38%] train loss: 1.3795697668683715e-05 \n",
      "epoch: 14 [48884/888800 5.50%] train loss: 1.4940989785827696e-05 \n",
      "epoch: 14 [49995/888800 5.62%] train loss: 1.428982795914635e-05 \n",
      "epoch: 14 [51106/888800 5.75%] train loss: 1.5188939869403839e-05 \n",
      "epoch: 14 [52217/888800 5.88%] train loss: 1.736141712171957e-05 \n",
      "epoch: 14 [53328/888800 6.00%] train loss: 1.5054490177135449e-05 \n",
      "epoch: 14 [54439/888800 6.12%] train loss: 1.876900569186546e-05 \n",
      "epoch: 14 [55550/888800 6.25%] train loss: 1.3684117220691405e-05 \n",
      "epoch: 14 [56661/888800 6.38%] train loss: 1.4667785762867425e-05 \n",
      "epoch: 14 [57772/888800 6.50%] train loss: 1.3513563317246735e-05 \n",
      "epoch: 14 [58883/888800 6.62%] train loss: 1.6180381862795912e-05 \n",
      "epoch: 14 [59994/888800 6.75%] train loss: 1.6174484699149616e-05 \n",
      "epoch: 14 [61105/888800 6.88%] train loss: 1.3976756235933863e-05 \n",
      "epoch: 14 [62216/888800 7.00%] train loss: 1.3779083019471727e-05 \n",
      "epoch: 14 [63327/888800 7.12%] train loss: 1.4641777852375526e-05 \n",
      "epoch: 14 [64438/888800 7.25%] train loss: 1.5192758837656584e-05 \n",
      "epoch: 14 [65549/888800 7.38%] train loss: 1.4220742741599679e-05 \n",
      "epoch: 14 [66660/888800 7.50%] train loss: 1.4617456145060714e-05 \n",
      "epoch: 14 [67771/888800 7.62%] train loss: 1.473791417083703e-05 \n",
      "epoch: 14 [68882/888800 7.75%] train loss: 1.5253705896611791e-05 \n",
      "epoch: 14 [69993/888800 7.88%] train loss: 1.4552888387697749e-05 \n",
      "epoch: 14 [71104/888800 8.00%] train loss: 1.2957352737430483e-05 \n",
      "epoch: 14 [72215/888800 8.12%] train loss: 1.550190609123092e-05 \n",
      "epoch: 14 [73326/888800 8.25%] train loss: 1.573787994857412e-05 \n",
      "epoch: 14 [74437/888800 8.38%] train loss: 1.4980894775362685e-05 \n",
      "epoch: 14 [75548/888800 8.50%] train loss: 1.3518663763534278e-05 \n",
      "epoch: 14 [76659/888800 8.62%] train loss: 1.579564377607312e-05 \n",
      "epoch: 14 [77770/888800 8.75%] train loss: 1.7802174625103362e-05 \n",
      "epoch: 14 [78881/888800 8.88%] train loss: 1.3228567695477977e-05 \n",
      "epoch: 14 [79992/888800 9.00%] train loss: 1.674557279329747e-05 \n",
      "epoch: 14 [81103/888800 9.12%] train loss: 1.421572142135119e-05 \n",
      "epoch: 14 [82214/888800 9.25%] train loss: 1.3956135262560565e-05 \n",
      "epoch: 14 [83325/888800 9.38%] train loss: 1.3340029909159057e-05 \n",
      "epoch: 14 [84436/888800 9.50%] train loss: 1.3342989404918626e-05 \n",
      "epoch: 14 [85547/888800 9.62%] train loss: 1.4484200619335752e-05 \n",
      "epoch: 14 [86658/888800 9.75%] train loss: 1.4211137568054255e-05 \n",
      "epoch: 14 [87769/888800 9.88%] train loss: 1.3733164450968616e-05 \n",
      "epoch: 14 [88880/888800 10.00%] train loss: 1.3370678061619401e-05 \n",
      "epoch: 14 [89991/888800 10.12%] train loss: 1.40593665491906e-05 \n",
      "epoch: 14 [91102/888800 10.25%] train loss: 1.340231392532587e-05 \n",
      "epoch: 14 [92213/888800 10.38%] train loss: 1.3755849067820236e-05 \n",
      "epoch: 14 [93324/888800 10.50%] train loss: 1.345699820376467e-05 \n",
      "epoch: 14 [94435/888800 10.62%] train loss: 1.4192643902788404e-05 \n",
      "epoch: 14 [95546/888800 10.75%] train loss: 1.4995588571764529e-05 \n",
      "epoch: 14 [96657/888800 10.88%] train loss: 1.4041472240933217e-05 \n",
      "epoch: 14 [97768/888800 11.00%] train loss: 1.510727270215284e-05 \n",
      "epoch: 14 [98879/888800 11.12%] train loss: 1.446208989364095e-05 \n",
      "epoch: 14 [99990/888800 11.25%] train loss: 1.4968941286497284e-05 \n",
      "epoch: 14 [101101/888800 11.38%] train loss: 1.4160416867525782e-05 \n",
      "epoch: 14 [102212/888800 11.50%] train loss: 1.4507276318909135e-05 \n",
      "epoch: 14 [103323/888800 11.62%] train loss: 1.3443085663311649e-05 \n",
      "epoch: 14 [104434/888800 11.75%] train loss: 1.4735367585672066e-05 \n",
      "epoch: 14 [105545/888800 11.88%] train loss: 1.3599067642644513e-05 \n",
      "epoch: 14 [106656/888800 12.00%] train loss: 1.2518680705397855e-05 \n",
      "epoch: 14 [107767/888800 12.12%] train loss: 1.3688487342733424e-05 \n",
      "epoch: 14 [108878/888800 12.25%] train loss: 1.3132493222656194e-05 \n",
      "epoch: 14 [109989/888800 12.38%] train loss: 1.441649510525167e-05 \n",
      "epoch: 14 [111100/888800 12.50%] train loss: 1.390681882185163e-05 \n",
      "epoch: 14 [112211/888800 12.62%] train loss: 1.5160897419264074e-05 \n",
      "epoch: 14 [113322/888800 12.75%] train loss: 1.3248535651655402e-05 \n",
      "epoch: 14 [114433/888800 12.88%] train loss: 1.4460279999184422e-05 \n",
      "epoch: 14 [115544/888800 13.00%] train loss: 1.4679100786452182e-05 \n",
      "epoch: 14 [116655/888800 13.12%] train loss: 1.4021958122611977e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [117766/888800 13.25%] train loss: 1.539538789074868e-05 \n",
      "epoch: 14 [118877/888800 13.38%] train loss: 1.2998735655855853e-05 \n",
      "epoch: 14 [119988/888800 13.50%] train loss: 1.3433550520858262e-05 \n",
      "epoch: 14 [121099/888800 13.62%] train loss: 1.4641917005064897e-05 \n",
      "epoch: 14 [122210/888800 13.75%] train loss: 1.3602342733065598e-05 \n",
      "epoch: 14 [123321/888800 13.88%] train loss: 1.4973454199207481e-05 \n",
      "epoch: 14 [124432/888800 14.00%] train loss: 1.4591975741495844e-05 \n",
      "epoch: 14 [125543/888800 14.12%] train loss: 1.3591482456831727e-05 \n",
      "epoch: 14 [126654/888800 14.25%] train loss: 1.590214014868252e-05 \n",
      "epoch: 14 [127765/888800 14.38%] train loss: 1.4580686183762737e-05 \n",
      "epoch: 14 [128876/888800 14.50%] train loss: 1.2971036994713359e-05 \n",
      "epoch: 14 [129987/888800 14.62%] train loss: 1.3811244571115822e-05 \n",
      "epoch: 14 [131098/888800 14.75%] train loss: 1.4540290976583492e-05 \n",
      "epoch: 14 [132209/888800 14.88%] train loss: 1.5136649381020106e-05 \n",
      "epoch: 14 [133320/888800 15.00%] train loss: 1.3883138308301568e-05 \n",
      "epoch: 14 [134431/888800 15.12%] train loss: 1.441836229787441e-05 \n",
      "epoch: 14 [135542/888800 15.25%] train loss: 1.4903826922818553e-05 \n",
      "epoch: 14 [136653/888800 15.38%] train loss: 1.5223940863506868e-05 \n",
      "epoch: 14 [137764/888800 15.50%] train loss: 1.452956803404959e-05 \n",
      "epoch: 14 [138875/888800 15.62%] train loss: 1.4806698345637415e-05 \n",
      "epoch: 14 [139986/888800 15.75%] train loss: 1.3872683666704688e-05 \n",
      "epoch: 14 [141097/888800 15.88%] train loss: 1.373173017782392e-05 \n",
      "epoch: 14 [142208/888800 16.00%] train loss: 1.5216746760415845e-05 \n",
      "epoch: 14 [143319/888800 16.12%] train loss: 1.5911684386082925e-05 \n",
      "epoch: 14 [144430/888800 16.25%] train loss: 1.4827750419499353e-05 \n",
      "epoch: 14 [145541/888800 16.38%] train loss: 1.4577694855688605e-05 \n",
      "epoch: 14 [146652/888800 16.50%] train loss: 1.3791373021376785e-05 \n",
      "epoch: 14 [147763/888800 16.62%] train loss: 1.4691113392473198e-05 \n",
      "epoch: 14 [148874/888800 16.75%] train loss: 1.5508921933360398e-05 \n",
      "epoch: 14 [149985/888800 16.88%] train loss: 1.4386790098797064e-05 \n",
      "epoch: 14 [151096/888800 17.00%] train loss: 1.5680039723520167e-05 \n",
      "epoch: 14 [152207/888800 17.12%] train loss: 1.3765959920419846e-05 \n",
      "epoch: 14 [153318/888800 17.25%] train loss: 1.4679591004096437e-05 \n",
      "epoch: 14 [154429/888800 17.38%] train loss: 1.3608035260403994e-05 \n",
      "epoch: 14 [155540/888800 17.50%] train loss: 1.4205942534317728e-05 \n",
      "epoch: 14 [156651/888800 17.62%] train loss: 1.3074426533421502e-05 \n",
      "epoch: 14 [157762/888800 17.75%] train loss: 1.6000594769138843e-05 \n",
      "epoch: 14 [158873/888800 17.88%] train loss: 1.3285656677908264e-05 \n",
      "epoch: 14 [159984/888800 18.00%] train loss: 1.4847508282400668e-05 \n",
      "epoch: 14 [161095/888800 18.12%] train loss: 1.384983625030145e-05 \n",
      "epoch: 14 [162206/888800 18.25%] train loss: 1.480386436014669e-05 \n",
      "epoch: 14 [163317/888800 18.38%] train loss: 1.2764486200467218e-05 \n",
      "epoch: 14 [164428/888800 18.50%] train loss: 1.526197411294561e-05 \n",
      "epoch: 14 [165539/888800 18.62%] train loss: 1.40601878229063e-05 \n",
      "epoch: 14 [166650/888800 18.75%] train loss: 1.3866942936147097e-05 \n",
      "epoch: 14 [167761/888800 18.88%] train loss: 1.4569353879778646e-05 \n",
      "epoch: 14 [168872/888800 19.00%] train loss: 1.3755447980656754e-05 \n",
      "epoch: 14 [169983/888800 19.12%] train loss: 1.4128459042694885e-05 \n",
      "epoch: 14 [171094/888800 19.25%] train loss: 1.3579035112343263e-05 \n",
      "epoch: 14 [172205/888800 19.38%] train loss: 1.3941111319581978e-05 \n",
      "epoch: 14 [173316/888800 19.50%] train loss: 1.4001032468513586e-05 \n",
      "epoch: 14 [174427/888800 19.62%] train loss: 1.4502508747682441e-05 \n",
      "epoch: 14 [175538/888800 19.75%] train loss: 1.3907379070587922e-05 \n",
      "epoch: 14 [176649/888800 19.88%] train loss: 1.442155826225644e-05 \n",
      "epoch: 14 [177760/888800 20.00%] train loss: 1.4076655133976601e-05 \n",
      "epoch: 14 [178871/888800 20.12%] train loss: 1.3135524568497203e-05 \n",
      "epoch: 14 [179982/888800 20.25%] train loss: 1.4675466445623897e-05 \n",
      "epoch: 14 [181093/888800 20.38%] train loss: 1.3671835404238664e-05 \n",
      "epoch: 14 [182204/888800 20.50%] train loss: 1.4327356439025607e-05 \n",
      "epoch: 14 [183315/888800 20.62%] train loss: 1.4391819604497869e-05 \n",
      "epoch: 14 [184426/888800 20.75%] train loss: 1.4402240594790783e-05 \n",
      "epoch: 14 [185537/888800 20.88%] train loss: 1.3867647794540972e-05 \n",
      "epoch: 14 [186648/888800 21.00%] train loss: 1.449694264010759e-05 \n",
      "epoch: 14 [187759/888800 21.12%] train loss: 1.454206994822016e-05 \n",
      "epoch: 14 [188870/888800 21.25%] train loss: 1.3901618331146892e-05 \n",
      "epoch: 14 [189981/888800 21.38%] train loss: 1.3395445421338081e-05 \n",
      "epoch: 14 [191092/888800 21.50%] train loss: 1.3670851330971345e-05 \n",
      "epoch: 14 [192203/888800 21.62%] train loss: 1.2997766134503763e-05 \n",
      "epoch: 14 [193314/888800 21.75%] train loss: 1.4658407053502742e-05 \n",
      "epoch: 14 [194425/888800 21.88%] train loss: 1.4223423931980506e-05 \n",
      "epoch: 14 [195536/888800 22.00%] train loss: 1.3641883015225176e-05 \n",
      "epoch: 14 [196647/888800 22.12%] train loss: 1.3468608813127503e-05 \n",
      "epoch: 14 [197758/888800 22.25%] train loss: 1.318116392212687e-05 \n",
      "epoch: 14 [198869/888800 22.38%] train loss: 1.4581250979972538e-05 \n",
      "epoch: 14 [199980/888800 22.50%] train loss: 1.3850756658939645e-05 \n",
      "epoch: 14 [201091/888800 22.62%] train loss: 1.4334954357764218e-05 \n",
      "epoch: 14 [202202/888800 22.75%] train loss: 1.3365170161705464e-05 \n",
      "epoch: 14 [203313/888800 22.88%] train loss: 1.4263184311857913e-05 \n",
      "epoch: 14 [204424/888800 23.00%] train loss: 1.367581444355892e-05 \n",
      "epoch: 14 [205535/888800 23.12%] train loss: 1.516647171229124e-05 \n",
      "epoch: 14 [206646/888800 23.25%] train loss: 1.3668539395439439e-05 \n",
      "epoch: 14 [207757/888800 23.38%] train loss: 1.4535169611917809e-05 \n",
      "epoch: 14 [208868/888800 23.50%] train loss: 1.4132967407931574e-05 \n",
      "epoch: 14 [209979/888800 23.62%] train loss: 1.4021838978806045e-05 \n",
      "epoch: 14 [211090/888800 23.75%] train loss: 1.3426802070171107e-05 \n",
      "epoch: 14 [212201/888800 23.88%] train loss: 1.3341987141757272e-05 \n",
      "epoch: 14 [213312/888800 24.00%] train loss: 1.4338803339342121e-05 \n",
      "epoch: 14 [214423/888800 24.12%] train loss: 1.5253216588462237e-05 \n",
      "epoch: 14 [215534/888800 24.25%] train loss: 1.4004980585013982e-05 \n",
      "epoch: 14 [216645/888800 24.38%] train loss: 1.4285013094195165e-05 \n",
      "epoch: 14 [217756/888800 24.50%] train loss: 1.4367114090418909e-05 \n",
      "epoch: 14 [218867/888800 24.62%] train loss: 1.3332042726688087e-05 \n",
      "epoch: 14 [219978/888800 24.75%] train loss: 1.4274754903453868e-05 \n",
      "epoch: 14 [221089/888800 24.88%] train loss: 1.3645041690324433e-05 \n",
      "epoch: 14 [222200/888800 25.00%] train loss: 1.4537065908371005e-05 \n",
      "epoch: 14 [223311/888800 25.12%] train loss: 1.503833664173726e-05 \n",
      "epoch: 14 [224422/888800 25.25%] train loss: 1.4615229702030774e-05 \n",
      "epoch: 14 [225533/888800 25.38%] train loss: 1.4152890798868611e-05 \n",
      "epoch: 14 [226644/888800 25.50%] train loss: 1.4509975699183997e-05 \n",
      "epoch: 14 [227755/888800 25.62%] train loss: 1.4678505976917222e-05 \n",
      "epoch: 14 [228866/888800 25.75%] train loss: 1.3569698239734862e-05 \n",
      "epoch: 14 [229977/888800 25.88%] train loss: 1.2770558896590956e-05 \n",
      "epoch: 14 [231088/888800 26.00%] train loss: 1.5091770364961121e-05 \n",
      "epoch: 14 [232199/888800 26.12%] train loss: 1.477618843637174e-05 \n",
      "epoch: 14 [233310/888800 26.25%] train loss: 1.5138171875150874e-05 \n",
      "epoch: 14 [234421/888800 26.38%] train loss: 1.5104355952644255e-05 \n",
      "epoch: 14 [235532/888800 26.50%] train loss: 1.3731254512094893e-05 \n",
      "epoch: 14 [236643/888800 26.62%] train loss: 1.3802579815092031e-05 \n",
      "epoch: 14 [237754/888800 26.75%] train loss: 1.4209425899025518e-05 \n",
      "epoch: 14 [238865/888800 26.88%] train loss: 1.5509873264818452e-05 \n",
      "epoch: 14 [239976/888800 27.00%] train loss: 1.4701883628731593e-05 \n",
      "epoch: 14 [241087/888800 27.12%] train loss: 1.4970312804507557e-05 \n",
      "epoch: 14 [242198/888800 27.25%] train loss: 1.6272870198008604e-05 \n",
      "epoch: 14 [243309/888800 27.38%] train loss: 1.4164338608679827e-05 \n",
      "epoch: 14 [244420/888800 27.50%] train loss: 1.3989325452712364e-05 \n",
      "epoch: 14 [245531/888800 27.62%] train loss: 1.4694214769406244e-05 \n",
      "epoch: 14 [246642/888800 27.75%] train loss: 1.5918132703518495e-05 \n",
      "epoch: 14 [247753/888800 27.88%] train loss: 1.4000407645653468e-05 \n",
      "epoch: 14 [248864/888800 28.00%] train loss: 1.4218426258594263e-05 \n",
      "epoch: 14 [249975/888800 28.12%] train loss: 1.4479390301858075e-05 \n",
      "epoch: 14 [251086/888800 28.25%] train loss: 1.3810804375680164e-05 \n",
      "epoch: 14 [252197/888800 28.38%] train loss: 1.271108521905262e-05 \n",
      "epoch: 14 [253308/888800 28.50%] train loss: 1.3743476301897317e-05 \n",
      "epoch: 14 [254419/888800 28.62%] train loss: 1.3333057722775266e-05 \n",
      "epoch: 14 [255530/888800 28.75%] train loss: 1.5114426787476987e-05 \n",
      "epoch: 14 [256641/888800 28.88%] train loss: 1.362278180749854e-05 \n",
      "epoch: 14 [257752/888800 29.00%] train loss: 1.5371537301689386e-05 \n",
      "epoch: 14 [258863/888800 29.12%] train loss: 1.457424514228478e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [259974/888800 29.25%] train loss: 1.367666573059978e-05 \n",
      "epoch: 14 [261085/888800 29.38%] train loss: 1.4293553249444813e-05 \n",
      "epoch: 14 [262196/888800 29.50%] train loss: 1.3688879334949888e-05 \n",
      "epoch: 14 [263307/888800 29.62%] train loss: 1.397751930198865e-05 \n",
      "epoch: 14 [264418/888800 29.75%] train loss: 1.3535394828068092e-05 \n",
      "epoch: 14 [265529/888800 29.88%] train loss: 1.4528592146234587e-05 \n",
      "epoch: 14 [266640/888800 30.00%] train loss: 1.431843156751711e-05 \n",
      "epoch: 14 [267751/888800 30.12%] train loss: 1.3770464647677727e-05 \n",
      "epoch: 14 [268862/888800 30.25%] train loss: 1.472892654419411e-05 \n",
      "epoch: 14 [269973/888800 30.38%] train loss: 1.4553420442098286e-05 \n",
      "epoch: 14 [271084/888800 30.50%] train loss: 1.4279547940532211e-05 \n",
      "epoch: 14 [272195/888800 30.62%] train loss: 1.3730407772527542e-05 \n",
      "epoch: 14 [273306/888800 30.75%] train loss: 1.358522513328353e-05 \n",
      "epoch: 14 [274417/888800 30.88%] train loss: 1.4262122022046242e-05 \n",
      "epoch: 14 [275528/888800 31.00%] train loss: 1.2768662600137759e-05 \n",
      "epoch: 14 [276639/888800 31.12%] train loss: 1.4711758922203444e-05 \n",
      "epoch: 14 [277750/888800 31.25%] train loss: 1.3314231182448566e-05 \n",
      "epoch: 14 [278861/888800 31.38%] train loss: 1.3969168321636971e-05 \n",
      "epoch: 14 [279972/888800 31.50%] train loss: 1.3982959899294656e-05 \n",
      "epoch: 14 [281083/888800 31.62%] train loss: 1.4002204807184171e-05 \n",
      "epoch: 14 [282194/888800 31.75%] train loss: 1.54035551531706e-05 \n",
      "epoch: 14 [283305/888800 31.88%] train loss: 1.5404166333610192e-05 \n",
      "epoch: 14 [284416/888800 32.00%] train loss: 1.4864666809444316e-05 \n",
      "epoch: 14 [285527/888800 32.12%] train loss: 1.4274464774644002e-05 \n",
      "epoch: 14 [286638/888800 32.25%] train loss: 1.4406146874534898e-05 \n",
      "epoch: 14 [287749/888800 32.38%] train loss: 1.4827859558863565e-05 \n",
      "epoch: 14 [288860/888800 32.50%] train loss: 1.524507206340786e-05 \n",
      "epoch: 14 [289971/888800 32.62%] train loss: 1.4897855180606712e-05 \n",
      "epoch: 14 [291082/888800 32.75%] train loss: 1.4243706573324744e-05 \n",
      "epoch: 14 [292193/888800 32.88%] train loss: 1.4340494999487419e-05 \n",
      "epoch: 14 [293304/888800 33.00%] train loss: 1.43585939440527e-05 \n",
      "epoch: 14 [294415/888800 33.12%] train loss: 1.502817394793965e-05 \n",
      "epoch: 14 [295526/888800 33.25%] train loss: 1.4074569662625436e-05 \n",
      "epoch: 14 [296637/888800 33.38%] train loss: 1.4244950762076769e-05 \n",
      "epoch: 14 [297748/888800 33.50%] train loss: 1.4294751053967047e-05 \n",
      "epoch: 14 [298859/888800 33.62%] train loss: 1.5243951565935276e-05 \n",
      "epoch: 14 [299970/888800 33.75%] train loss: 1.604311546543613e-05 \n",
      "epoch: 14 [301081/888800 33.88%] train loss: 1.3954668247606605e-05 \n",
      "epoch: 14 [302192/888800 34.00%] train loss: 1.401559893565718e-05 \n",
      "epoch: 14 [303303/888800 34.12%] train loss: 1.3271617717691697e-05 \n",
      "epoch: 14 [304414/888800 34.25%] train loss: 1.457631697121542e-05 \n",
      "epoch: 14 [305525/888800 34.38%] train loss: 1.4076189472689293e-05 \n",
      "epoch: 14 [306636/888800 34.50%] train loss: 1.439963853044901e-05 \n",
      "epoch: 14 [307747/888800 34.62%] train loss: 1.5500882000196725e-05 \n",
      "epoch: 14 [308858/888800 34.75%] train loss: 1.527645690657664e-05 \n",
      "epoch: 14 [309969/888800 34.88%] train loss: 1.3518632840714417e-05 \n",
      "epoch: 14 [311080/888800 35.00%] train loss: 1.3754744941252284e-05 \n",
      "epoch: 14 [312191/888800 35.12%] train loss: 1.2678473467531148e-05 \n",
      "epoch: 14 [313302/888800 35.25%] train loss: 1.3103572200634517e-05 \n",
      "epoch: 14 [314413/888800 35.38%] train loss: 1.4968491996114608e-05 \n",
      "epoch: 14 [315524/888800 35.50%] train loss: 1.3259031220513862e-05 \n",
      "epoch: 14 [316635/888800 35.62%] train loss: 1.499928293924313e-05 \n",
      "epoch: 14 [317746/888800 35.75%] train loss: 1.450267245672876e-05 \n",
      "epoch: 14 [318857/888800 35.88%] train loss: 1.3546346963266842e-05 \n",
      "epoch: 14 [319968/888800 36.00%] train loss: 1.4576628927898128e-05 \n",
      "epoch: 14 [321079/888800 36.12%] train loss: 1.4521706361847464e-05 \n",
      "epoch: 14 [322190/888800 36.25%] train loss: 1.5152540072449483e-05 \n",
      "epoch: 14 [323301/888800 36.38%] train loss: 1.5031712791824248e-05 \n",
      "epoch: 14 [324412/888800 36.50%] train loss: 1.4585993994842283e-05 \n",
      "epoch: 14 [325523/888800 36.62%] train loss: 1.4001995623402763e-05 \n",
      "epoch: 14 [326634/888800 36.75%] train loss: 1.441993208572967e-05 \n",
      "epoch: 14 [327745/888800 36.88%] train loss: 1.3882608982385136e-05 \n",
      "epoch: 14 [328856/888800 37.00%] train loss: 1.608720594958868e-05 \n",
      "epoch: 14 [329967/888800 37.12%] train loss: 1.4235618436941877e-05 \n",
      "epoch: 14 [331078/888800 37.25%] train loss: 1.5644251107005402e-05 \n",
      "epoch: 14 [332189/888800 37.38%] train loss: 1.4458258192462381e-05 \n",
      "epoch: 14 [333300/888800 37.50%] train loss: 1.4887811630615033e-05 \n",
      "epoch: 14 [334411/888800 37.62%] train loss: 1.544039696455002e-05 \n",
      "epoch: 14 [335522/888800 37.75%] train loss: 1.4244524209061638e-05 \n",
      "epoch: 14 [336633/888800 37.88%] train loss: 1.2393973520374857e-05 \n",
      "epoch: 14 [337744/888800 38.00%] train loss: 1.4872372048557736e-05 \n",
      "epoch: 14 [338855/888800 38.12%] train loss: 1.5037354387459345e-05 \n",
      "epoch: 14 [339966/888800 38.25%] train loss: 1.2905817129649222e-05 \n",
      "epoch: 14 [341077/888800 38.38%] train loss: 1.7238764485227875e-05 \n",
      "epoch: 14 [342188/888800 38.50%] train loss: 1.462250202166615e-05 \n",
      "epoch: 14 [343299/888800 38.62%] train loss: 1.653581603022758e-05 \n",
      "epoch: 14 [344410/888800 38.75%] train loss: 1.522870206827065e-05 \n",
      "epoch: 14 [345521/888800 38.88%] train loss: 1.4114581972535234e-05 \n",
      "epoch: 14 [346632/888800 39.00%] train loss: 1.5459074347745627e-05 \n",
      "epoch: 14 [347743/888800 39.12%] train loss: 1.4433646356337704e-05 \n",
      "epoch: 14 [348854/888800 39.25%] train loss: 1.7207283235620707e-05 \n",
      "epoch: 14 [349965/888800 39.38%] train loss: 1.4335920241137501e-05 \n",
      "epoch: 14 [351076/888800 39.50%] train loss: 1.649953264859505e-05 \n",
      "epoch: 14 [352187/888800 39.62%] train loss: 1.4623181414208375e-05 \n",
      "epoch: 14 [353298/888800 39.75%] train loss: 1.4985696907388046e-05 \n",
      "epoch: 14 [354409/888800 39.88%] train loss: 1.3891191883885767e-05 \n",
      "epoch: 14 [355520/888800 40.00%] train loss: 1.4745772205060348e-05 \n",
      "epoch: 14 [356631/888800 40.12%] train loss: 1.5485362382605672e-05 \n",
      "epoch: 14 [357742/888800 40.25%] train loss: 1.4983091205067467e-05 \n",
      "epoch: 14 [358853/888800 40.38%] train loss: 1.3074265552859288e-05 \n",
      "epoch: 14 [359964/888800 40.50%] train loss: 1.4360937711899169e-05 \n",
      "epoch: 14 [361075/888800 40.62%] train loss: 1.4608161109208595e-05 \n",
      "epoch: 14 [362186/888800 40.75%] train loss: 1.596732545294799e-05 \n",
      "epoch: 14 [363297/888800 40.88%] train loss: 1.3168280929676257e-05 \n",
      "epoch: 14 [364408/888800 41.00%] train loss: 1.4552736502082553e-05 \n",
      "epoch: 14 [365519/888800 41.12%] train loss: 1.3515631508198567e-05 \n",
      "epoch: 14 [366630/888800 41.25%] train loss: 1.5585890650982037e-05 \n",
      "epoch: 14 [367741/888800 41.38%] train loss: 1.4315747648652177e-05 \n",
      "epoch: 14 [368852/888800 41.50%] train loss: 1.4367567928275093e-05 \n",
      "epoch: 14 [369963/888800 41.62%] train loss: 1.3424910321191419e-05 \n",
      "epoch: 14 [371074/888800 41.75%] train loss: 1.4372391888173297e-05 \n",
      "epoch: 14 [372185/888800 41.88%] train loss: 1.377192347717937e-05 \n",
      "epoch: 14 [373296/888800 42.00%] train loss: 1.3998822396388277e-05 \n",
      "epoch: 14 [374407/888800 42.12%] train loss: 1.2543704542622436e-05 \n",
      "epoch: 14 [375518/888800 42.25%] train loss: 1.3442343515635002e-05 \n",
      "epoch: 14 [376629/888800 42.38%] train loss: 1.3905578271078411e-05 \n",
      "epoch: 14 [377740/888800 42.50%] train loss: 1.3080803000775632e-05 \n",
      "epoch: 14 [378851/888800 42.62%] train loss: 1.4738291611138266e-05 \n",
      "epoch: 14 [379962/888800 42.75%] train loss: 1.3539598512579687e-05 \n",
      "epoch: 14 [381073/888800 42.88%] train loss: 1.3912052963860333e-05 \n",
      "epoch: 14 [382184/888800 43.00%] train loss: 1.338118363491958e-05 \n",
      "epoch: 14 [383295/888800 43.12%] train loss: 1.2942660760018043e-05 \n",
      "epoch: 14 [384406/888800 43.25%] train loss: 1.3575881894212216e-05 \n",
      "epoch: 14 [385517/888800 43.38%] train loss: 1.3439504073176067e-05 \n",
      "epoch: 14 [386628/888800 43.50%] train loss: 1.4745664884685539e-05 \n",
      "epoch: 14 [387739/888800 43.62%] train loss: 1.4783233382331673e-05 \n",
      "epoch: 14 [388850/888800 43.75%] train loss: 1.4747264685865957e-05 \n",
      "epoch: 14 [389961/888800 43.88%] train loss: 1.4235371963877697e-05 \n",
      "epoch: 14 [391072/888800 44.00%] train loss: 1.3690871128346771e-05 \n",
      "epoch: 14 [392183/888800 44.12%] train loss: 1.50320984175778e-05 \n",
      "epoch: 14 [393294/888800 44.25%] train loss: 1.4190797628543805e-05 \n",
      "epoch: 14 [394405/888800 44.38%] train loss: 1.2926749150210526e-05 \n",
      "epoch: 14 [395516/888800 44.50%] train loss: 1.4362756701302715e-05 \n",
      "epoch: 14 [396627/888800 44.62%] train loss: 1.4312381608760916e-05 \n",
      "epoch: 14 [397738/888800 44.75%] train loss: 1.4851984815322794e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [398849/888800 44.88%] train loss: 1.4862423086015042e-05 \n",
      "epoch: 14 [399960/888800 45.00%] train loss: 1.3033937648287974e-05 \n",
      "epoch: 14 [401071/888800 45.12%] train loss: 1.5325582353398204e-05 \n",
      "epoch: 14 [402182/888800 45.25%] train loss: 1.4858568647468928e-05 \n",
      "epoch: 14 [403293/888800 45.38%] train loss: 1.3397328984865453e-05 \n",
      "epoch: 14 [404404/888800 45.50%] train loss: 1.3982538803247735e-05 \n",
      "epoch: 14 [405515/888800 45.62%] train loss: 1.2906726624350995e-05 \n",
      "epoch: 14 [406626/888800 45.75%] train loss: 1.3173848856240511e-05 \n",
      "epoch: 14 [407737/888800 45.88%] train loss: 1.3746734111919068e-05 \n",
      "epoch: 14 [408848/888800 46.00%] train loss: 1.3707215657632332e-05 \n",
      "epoch: 14 [409959/888800 46.12%] train loss: 1.4690167517983355e-05 \n",
      "epoch: 14 [411070/888800 46.25%] train loss: 1.4952138371882029e-05 \n",
      "epoch: 14 [412181/888800 46.38%] train loss: 1.497339235356776e-05 \n",
      "epoch: 14 [413292/888800 46.50%] train loss: 1.4087854651734233e-05 \n",
      "epoch: 14 [414403/888800 46.62%] train loss: 1.5708554201410152e-05 \n",
      "epoch: 14 [415514/888800 46.75%] train loss: 1.4784148334001657e-05 \n",
      "epoch: 14 [416625/888800 46.88%] train loss: 1.4688404007756617e-05 \n",
      "epoch: 14 [417736/888800 47.00%] train loss: 1.4950113836675882e-05 \n",
      "epoch: 14 [418847/888800 47.12%] train loss: 1.3413267879514024e-05 \n",
      "epoch: 14 [419958/888800 47.25%] train loss: 1.3429454156721476e-05 \n",
      "epoch: 14 [421069/888800 47.38%] train loss: 1.5103666555660311e-05 \n",
      "epoch: 14 [422180/888800 47.50%] train loss: 1.4968552022764925e-05 \n",
      "epoch: 14 [423291/888800 47.62%] train loss: 1.2740116289933212e-05 \n",
      "epoch: 14 [424402/888800 47.75%] train loss: 1.500736743764719e-05 \n",
      "epoch: 14 [425513/888800 47.88%] train loss: 1.4374192687682807e-05 \n",
      "epoch: 14 [426624/888800 48.00%] train loss: 1.3744545867666602e-05 \n",
      "epoch: 14 [427735/888800 48.12%] train loss: 1.4482538972515613e-05 \n",
      "epoch: 14 [428846/888800 48.25%] train loss: 1.533982685941737e-05 \n",
      "epoch: 14 [429957/888800 48.38%] train loss: 1.2564382814161945e-05 \n",
      "epoch: 14 [431068/888800 48.50%] train loss: 1.4264123819884844e-05 \n",
      "epoch: 14 [432179/888800 48.62%] train loss: 1.4965007721912116e-05 \n",
      "epoch: 14 [433290/888800 48.75%] train loss: 1.4985451343818568e-05 \n",
      "epoch: 14 [434401/888800 48.88%] train loss: 1.4199066754372325e-05 \n",
      "epoch: 14 [435512/888800 49.00%] train loss: 1.3735898392042145e-05 \n",
      "epoch: 14 [436623/888800 49.12%] train loss: 1.3557476449932437e-05 \n",
      "epoch: 14 [437734/888800 49.25%] train loss: 1.4128329894447234e-05 \n",
      "epoch: 14 [438845/888800 49.38%] train loss: 1.3348523680178914e-05 \n",
      "epoch: 14 [439956/888800 49.50%] train loss: 1.4361772628035396e-05 \n",
      "epoch: 14 [441067/888800 49.62%] train loss: 1.6133133613038808e-05 \n",
      "epoch: 14 [442178/888800 49.75%] train loss: 1.537733078293968e-05 \n",
      "epoch: 14 [443289/888800 49.88%] train loss: 1.4016712157172151e-05 \n",
      "epoch: 14 [444400/888800 50.00%] train loss: 1.4177397133607883e-05 \n",
      "epoch: 14 [445511/888800 50.12%] train loss: 1.3939844393462408e-05 \n",
      "epoch: 14 [446622/888800 50.25%] train loss: 1.3550954463426024e-05 \n",
      "epoch: 14 [447733/888800 50.38%] train loss: 1.5535862985416315e-05 \n",
      "epoch: 14 [448844/888800 50.50%] train loss: 1.4506782463286072e-05 \n",
      "epoch: 14 [449955/888800 50.62%] train loss: 1.3904789739171974e-05 \n",
      "epoch: 14 [451066/888800 50.75%] train loss: 1.4446917703025974e-05 \n",
      "epoch: 14 [452177/888800 50.88%] train loss: 1.3321795449883211e-05 \n",
      "epoch: 14 [453288/888800 51.00%] train loss: 1.5144185454118997e-05 \n",
      "epoch: 14 [454399/888800 51.12%] train loss: 1.3732250408793334e-05 \n",
      "epoch: 14 [455510/888800 51.25%] train loss: 1.5820305634406395e-05 \n",
      "epoch: 14 [456621/888800 51.38%] train loss: 1.4125125744612888e-05 \n",
      "epoch: 14 [457732/888800 51.50%] train loss: 1.3822289474774152e-05 \n",
      "epoch: 14 [458843/888800 51.62%] train loss: 1.4632234524469823e-05 \n",
      "epoch: 14 [459954/888800 51.75%] train loss: 1.3092706467432436e-05 \n",
      "epoch: 14 [461065/888800 51.88%] train loss: 1.654851803323254e-05 \n",
      "epoch: 14 [462176/888800 52.00%] train loss: 1.5563025954179466e-05 \n",
      "epoch: 14 [463287/888800 52.12%] train loss: 1.4254191228246782e-05 \n",
      "epoch: 14 [464398/888800 52.25%] train loss: 1.3865388609701768e-05 \n",
      "epoch: 14 [465509/888800 52.38%] train loss: 1.4330127669381909e-05 \n",
      "epoch: 14 [466620/888800 52.50%] train loss: 1.3640547877002973e-05 \n",
      "epoch: 14 [467731/888800 52.62%] train loss: 1.3641566511068959e-05 \n",
      "epoch: 14 [468842/888800 52.75%] train loss: 1.3812148608849384e-05 \n",
      "epoch: 14 [469953/888800 52.88%] train loss: 1.3564585970016196e-05 \n",
      "epoch: 14 [471064/888800 53.00%] train loss: 1.4835282854619436e-05 \n",
      "epoch: 14 [472175/888800 53.12%] train loss: 1.4416803423955571e-05 \n",
      "epoch: 14 [473286/888800 53.25%] train loss: 1.4352410289575346e-05 \n",
      "epoch: 14 [474397/888800 53.38%] train loss: 1.4279242350312416e-05 \n",
      "epoch: 14 [475508/888800 53.50%] train loss: 1.3476534149958752e-05 \n",
      "epoch: 14 [476619/888800 53.62%] train loss: 1.4021296010469086e-05 \n",
      "epoch: 14 [477730/888800 53.75%] train loss: 1.4217235730029643e-05 \n",
      "epoch: 14 [478841/888800 53.88%] train loss: 1.461963893234497e-05 \n",
      "epoch: 14 [479952/888800 54.00%] train loss: 1.3860374565410893e-05 \n",
      "epoch: 14 [481063/888800 54.12%] train loss: 1.403827263857238e-05 \n",
      "epoch: 14 [482174/888800 54.25%] train loss: 1.4539318726747297e-05 \n",
      "epoch: 14 [483285/888800 54.38%] train loss: 1.4088793250266463e-05 \n",
      "epoch: 14 [484396/888800 54.50%] train loss: 1.4052996448299382e-05 \n",
      "epoch: 14 [485507/888800 54.62%] train loss: 1.5134612112888135e-05 \n",
      "epoch: 14 [486618/888800 54.75%] train loss: 1.5041418009786867e-05 \n",
      "epoch: 14 [487729/888800 54.88%] train loss: 1.3907190805184655e-05 \n",
      "epoch: 14 [488840/888800 55.00%] train loss: 1.5366038496722467e-05 \n",
      "epoch: 14 [489951/888800 55.12%] train loss: 1.3889626643504016e-05 \n",
      "epoch: 14 [491062/888800 55.25%] train loss: 1.4546661986969411e-05 \n",
      "epoch: 14 [492173/888800 55.38%] train loss: 1.4463240404438693e-05 \n",
      "epoch: 14 [493284/888800 55.50%] train loss: 1.412774327036459e-05 \n",
      "epoch: 14 [494395/888800 55.62%] train loss: 1.5083604921528604e-05 \n",
      "epoch: 14 [495506/888800 55.75%] train loss: 1.4659191947430372e-05 \n",
      "epoch: 14 [496617/888800 55.88%] train loss: 1.2925687769893557e-05 \n",
      "epoch: 14 [497728/888800 56.00%] train loss: 1.4092693163547665e-05 \n",
      "epoch: 14 [498839/888800 56.12%] train loss: 1.2884617717645597e-05 \n",
      "epoch: 14 [499950/888800 56.25%] train loss: 1.5118899682420306e-05 \n",
      "epoch: 14 [501061/888800 56.38%] train loss: 1.3025122825638391e-05 \n",
      "epoch: 14 [502172/888800 56.50%] train loss: 1.3802234207105357e-05 \n",
      "epoch: 14 [503283/888800 56.62%] train loss: 1.5091392924659885e-05 \n",
      "epoch: 14 [504394/888800 56.75%] train loss: 1.3578199286712334e-05 \n",
      "epoch: 14 [505505/888800 56.88%] train loss: 1.4126737369224429e-05 \n",
      "epoch: 14 [506616/888800 57.00%] train loss: 1.4008892321726307e-05 \n",
      "epoch: 14 [507727/888800 57.12%] train loss: 1.3902657883591019e-05 \n",
      "epoch: 14 [508838/888800 57.25%] train loss: 1.4387446753971744e-05 \n",
      "epoch: 14 [509949/888800 57.38%] train loss: 1.4261394426284824e-05 \n",
      "epoch: 14 [511060/888800 57.50%] train loss: 1.3915240742790047e-05 \n",
      "epoch: 14 [512171/888800 57.62%] train loss: 1.4703025044582319e-05 \n",
      "epoch: 14 [513282/888800 57.75%] train loss: 1.392186459270306e-05 \n",
      "epoch: 14 [514393/888800 57.88%] train loss: 1.5280320440069772e-05 \n",
      "epoch: 14 [515504/888800 58.00%] train loss: 1.4208721950126346e-05 \n",
      "epoch: 14 [516615/888800 58.12%] train loss: 1.2872852494183462e-05 \n",
      "epoch: 14 [517726/888800 58.25%] train loss: 1.4043353075976484e-05 \n",
      "epoch: 14 [518837/888800 58.38%] train loss: 1.4014215594215784e-05 \n",
      "epoch: 14 [519948/888800 58.50%] train loss: 1.4814966561971232e-05 \n",
      "epoch: 14 [521059/888800 58.62%] train loss: 1.5732066458440386e-05 \n",
      "epoch: 14 [522170/888800 58.75%] train loss: 1.3541330190491863e-05 \n",
      "epoch: 14 [523281/888800 58.88%] train loss: 1.5058099961606786e-05 \n",
      "epoch: 14 [524392/888800 59.00%] train loss: 1.4148244190437254e-05 \n",
      "epoch: 14 [525503/888800 59.12%] train loss: 1.5090963643160649e-05 \n",
      "epoch: 14 [526614/888800 59.25%] train loss: 1.315405188506702e-05 \n",
      "epoch: 14 [527725/888800 59.38%] train loss: 1.3399131603364367e-05 \n",
      "epoch: 14 [528836/888800 59.50%] train loss: 1.3327802662388422e-05 \n",
      "epoch: 14 [529947/888800 59.62%] train loss: 1.473551856179256e-05 \n",
      "epoch: 14 [531058/888800 59.75%] train loss: 1.4889305020915344e-05 \n",
      "epoch: 14 [532169/888800 59.88%] train loss: 1.618809073988814e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [533280/888800 60.00%] train loss: 1.4286116311268415e-05 \n",
      "epoch: 14 [534391/888800 60.12%] train loss: 1.5131740838114638e-05 \n",
      "epoch: 14 [535502/888800 60.25%] train loss: 1.4370519238582347e-05 \n",
      "epoch: 14 [536613/888800 60.38%] train loss: 1.4535579794028308e-05 \n",
      "epoch: 14 [537724/888800 60.50%] train loss: 1.5371473637060262e-05 \n",
      "epoch: 14 [538835/888800 60.62%] train loss: 1.6239027900155634e-05 \n",
      "epoch: 14 [539946/888800 60.75%] train loss: 1.3653134374180809e-05 \n",
      "epoch: 14 [541057/888800 60.88%] train loss: 1.4227893188945018e-05 \n",
      "epoch: 14 [542168/888800 61.00%] train loss: 1.6434514691354707e-05 \n",
      "epoch: 14 [543279/888800 61.12%] train loss: 1.5594005162711255e-05 \n",
      "epoch: 14 [544390/888800 61.25%] train loss: 1.4242167708289344e-05 \n",
      "epoch: 14 [545501/888800 61.38%] train loss: 1.6235293514910154e-05 \n",
      "epoch: 14 [546612/888800 61.50%] train loss: 1.4969917174312286e-05 \n",
      "epoch: 14 [547723/888800 61.62%] train loss: 1.5024709682620596e-05 \n",
      "epoch: 14 [548834/888800 61.75%] train loss: 1.4654257938673254e-05 \n",
      "epoch: 14 [549945/888800 61.88%] train loss: 1.3449654943542555e-05 \n",
      "epoch: 14 [551056/888800 62.00%] train loss: 1.393298134644283e-05 \n",
      "epoch: 14 [552167/888800 62.12%] train loss: 1.370803056488512e-05 \n",
      "epoch: 14 [553278/888800 62.25%] train loss: 1.4334082152345218e-05 \n",
      "epoch: 14 [554389/888800 62.38%] train loss: 1.3826307622366585e-05 \n",
      "epoch: 14 [555500/888800 62.50%] train loss: 1.5320945749408565e-05 \n",
      "epoch: 14 [556611/888800 62.62%] train loss: 1.4801993529545143e-05 \n",
      "epoch: 14 [557722/888800 62.75%] train loss: 1.4579267372027971e-05 \n",
      "epoch: 14 [558833/888800 62.88%] train loss: 1.3977127309772186e-05 \n",
      "epoch: 14 [559944/888800 63.00%] train loss: 1.4372264558915049e-05 \n",
      "epoch: 14 [561055/888800 63.12%] train loss: 1.5390411135740578e-05 \n",
      "epoch: 14 [562166/888800 63.25%] train loss: 1.3997265341458842e-05 \n",
      "epoch: 14 [563277/888800 63.38%] train loss: 1.442447228328092e-05 \n",
      "epoch: 14 [564388/888800 63.50%] train loss: 1.3506369214155711e-05 \n",
      "epoch: 14 [565499/888800 63.62%] train loss: 1.477299247198971e-05 \n",
      "epoch: 14 [566610/888800 63.75%] train loss: 1.3158589354134165e-05 \n",
      "epoch: 14 [567721/888800 63.88%] train loss: 1.5265653928508982e-05 \n",
      "epoch: 14 [568832/888800 64.00%] train loss: 1.4681978427688591e-05 \n",
      "epoch: 14 [569943/888800 64.12%] train loss: 1.4083024325373117e-05 \n",
      "epoch: 14 [571054/888800 64.25%] train loss: 1.3910643247072585e-05 \n",
      "epoch: 14 [572165/888800 64.38%] train loss: 1.3664207472174894e-05 \n",
      "epoch: 14 [573276/888800 64.50%] train loss: 1.4174089301377535e-05 \n",
      "epoch: 14 [574387/888800 64.62%] train loss: 1.4677241779281758e-05 \n",
      "epoch: 14 [575498/888800 64.75%] train loss: 1.45239819175913e-05 \n",
      "epoch: 14 [576609/888800 64.88%] train loss: 1.4236468814488035e-05 \n",
      "epoch: 14 [577720/888800 65.00%] train loss: 1.5167413948802277e-05 \n",
      "epoch: 14 [578831/888800 65.12%] train loss: 1.483144751546206e-05 \n",
      "epoch: 14 [579942/888800 65.25%] train loss: 1.3826406757289078e-05 \n",
      "epoch: 14 [581053/888800 65.38%] train loss: 1.315607823926257e-05 \n",
      "epoch: 14 [582164/888800 65.50%] train loss: 1.3652374036610126e-05 \n",
      "epoch: 14 [583275/888800 65.62%] train loss: 1.3270743693283293e-05 \n",
      "epoch: 14 [584386/888800 65.75%] train loss: 1.5207230717351194e-05 \n",
      "epoch: 14 [585497/888800 65.88%] train loss: 1.356353095616214e-05 \n",
      "epoch: 14 [586608/888800 66.00%] train loss: 1.3932871297583915e-05 \n",
      "epoch: 14 [587719/888800 66.12%] train loss: 1.315702775173122e-05 \n",
      "epoch: 14 [588830/888800 66.25%] train loss: 1.3946763829153497e-05 \n",
      "epoch: 14 [589941/888800 66.38%] train loss: 1.4359586202772334e-05 \n",
      "epoch: 14 [591052/888800 66.50%] train loss: 1.3998610484122764e-05 \n",
      "epoch: 14 [592163/888800 66.62%] train loss: 1.4357580766954925e-05 \n",
      "epoch: 14 [593274/888800 66.75%] train loss: 1.3385647434915882e-05 \n",
      "epoch: 14 [594385/888800 66.88%] train loss: 1.3711715837416705e-05 \n",
      "epoch: 14 [595496/888800 67.00%] train loss: 1.506248281657463e-05 \n",
      "epoch: 14 [596607/888800 67.12%] train loss: 1.4245758393371943e-05 \n",
      "epoch: 14 [597718/888800 67.25%] train loss: 1.4113142242422327e-05 \n",
      "epoch: 14 [598829/888800 67.38%] train loss: 1.3411557119979989e-05 \n",
      "epoch: 14 [599940/888800 67.50%] train loss: 1.5479812645935453e-05 \n",
      "epoch: 14 [601051/888800 67.62%] train loss: 1.4632548300141934e-05 \n",
      "epoch: 14 [602162/888800 67.75%] train loss: 1.4295302207756322e-05 \n",
      "epoch: 14 [603273/888800 67.88%] train loss: 1.4690894204250071e-05 \n",
      "epoch: 14 [604384/888800 68.00%] train loss: 1.5245665053953417e-05 \n",
      "epoch: 14 [605495/888800 68.12%] train loss: 1.5327788787544705e-05 \n",
      "epoch: 14 [606606/888800 68.25%] train loss: 1.4764444131287746e-05 \n",
      "epoch: 14 [607717/888800 68.38%] train loss: 1.4958435713197105e-05 \n",
      "epoch: 14 [608828/888800 68.50%] train loss: 1.4089035175857134e-05 \n",
      "epoch: 14 [609939/888800 68.62%] train loss: 1.5088037798705045e-05 \n",
      "epoch: 14 [611050/888800 68.75%] train loss: 1.2617050742846914e-05 \n",
      "epoch: 14 [612161/888800 68.88%] train loss: 1.351603805233026e-05 \n",
      "epoch: 14 [613272/888800 69.00%] train loss: 1.5341038306360133e-05 \n",
      "epoch: 14 [614383/888800 69.12%] train loss: 1.5163259377004579e-05 \n",
      "epoch: 14 [615494/888800 69.25%] train loss: 1.4321855815069284e-05 \n",
      "epoch: 14 [616605/888800 69.38%] train loss: 1.4161411854729522e-05 \n",
      "epoch: 14 [617716/888800 69.50%] train loss: 1.4799176824453752e-05 \n",
      "epoch: 14 [618827/888800 69.62%] train loss: 1.4134963748801965e-05 \n",
      "epoch: 14 [619938/888800 69.75%] train loss: 1.4662617104477249e-05 \n",
      "epoch: 14 [621049/888800 69.88%] train loss: 1.4089400792727247e-05 \n",
      "epoch: 14 [622160/888800 70.00%] train loss: 1.4063607522984967e-05 \n",
      "epoch: 14 [623271/888800 70.12%] train loss: 1.5932353562675416e-05 \n",
      "epoch: 14 [624382/888800 70.25%] train loss: 1.3836658581567463e-05 \n",
      "epoch: 14 [625493/888800 70.38%] train loss: 1.571564826008398e-05 \n",
      "epoch: 14 [626604/888800 70.50%] train loss: 1.3792428035230841e-05 \n",
      "epoch: 14 [627715/888800 70.62%] train loss: 1.4034356354386546e-05 \n",
      "epoch: 14 [628826/888800 70.75%] train loss: 1.3773966202279553e-05 \n",
      "epoch: 14 [629937/888800 70.88%] train loss: 1.3851525181962643e-05 \n",
      "epoch: 14 [631048/888800 71.00%] train loss: 1.3909679182688706e-05 \n",
      "epoch: 14 [632159/888800 71.12%] train loss: 1.408595016982872e-05 \n",
      "epoch: 14 [633270/888800 71.25%] train loss: 1.5409035768243484e-05 \n",
      "epoch: 14 [634381/888800 71.38%] train loss: 1.4810832908551674e-05 \n",
      "epoch: 14 [635492/888800 71.50%] train loss: 1.4699488019687124e-05 \n",
      "epoch: 14 [636603/888800 71.62%] train loss: 1.4217186617315747e-05 \n",
      "epoch: 14 [637714/888800 71.75%] train loss: 1.472626900067553e-05 \n",
      "epoch: 14 [638825/888800 71.88%] train loss: 1.588290251675062e-05 \n",
      "epoch: 14 [639936/888800 72.00%] train loss: 1.4555742382071912e-05 \n",
      "epoch: 14 [641047/888800 72.12%] train loss: 1.5071931557031348e-05 \n",
      "epoch: 14 [642158/888800 72.25%] train loss: 1.4492965419776738e-05 \n",
      "epoch: 14 [643269/888800 72.38%] train loss: 1.3710098755836952e-05 \n",
      "epoch: 14 [644380/888800 72.50%] train loss: 1.3653414498548955e-05 \n",
      "epoch: 14 [645491/888800 72.62%] train loss: 1.507128126831958e-05 \n",
      "epoch: 14 [646602/888800 72.75%] train loss: 1.4974103578424547e-05 \n",
      "epoch: 14 [647713/888800 72.88%] train loss: 1.4989625924499705e-05 \n",
      "epoch: 14 [648824/888800 73.00%] train loss: 1.4861393538012635e-05 \n",
      "epoch: 14 [649935/888800 73.12%] train loss: 1.4770944289921317e-05 \n",
      "epoch: 14 [651046/888800 73.25%] train loss: 1.3198848137108143e-05 \n",
      "epoch: 14 [652157/888800 73.38%] train loss: 1.3279099221108481e-05 \n",
      "epoch: 14 [653268/888800 73.50%] train loss: 1.2682394299190491e-05 \n",
      "epoch: 14 [654379/888800 73.62%] train loss: 1.4833556633675471e-05 \n",
      "epoch: 14 [655490/888800 73.75%] train loss: 1.4741909581061918e-05 \n",
      "epoch: 14 [656601/888800 73.88%] train loss: 1.4123283108347096e-05 \n",
      "epoch: 14 [657712/888800 74.00%] train loss: 1.234134197147796e-05 \n",
      "epoch: 14 [658823/888800 74.12%] train loss: 1.4241607459553052e-05 \n",
      "epoch: 14 [659934/888800 74.25%] train loss: 1.4951408957131207e-05 \n",
      "epoch: 14 [661045/888800 74.38%] train loss: 1.3422049050859641e-05 \n",
      "epoch: 14 [662156/888800 74.50%] train loss: 1.4040881069377065e-05 \n",
      "epoch: 14 [663267/888800 74.62%] train loss: 1.2848261576436926e-05 \n",
      "epoch: 14 [664378/888800 74.75%] train loss: 1.588092891324777e-05 \n",
      "epoch: 14 [665489/888800 74.88%] train loss: 1.5318581063183956e-05 \n",
      "epoch: 14 [666600/888800 75.00%] train loss: 1.4058967281016521e-05 \n",
      "epoch: 14 [667711/888800 75.12%] train loss: 1.4456149983743671e-05 \n",
      "epoch: 14 [668822/888800 75.25%] train loss: 1.3623332961287815e-05 \n",
      "epoch: 14 [669933/888800 75.38%] train loss: 1.4623310562456027e-05 \n",
      "epoch: 14 [671044/888800 75.50%] train loss: 1.3717060937779024e-05 \n",
      "epoch: 14 [672155/888800 75.62%] train loss: 1.3283549378684256e-05 \n",
      "epoch: 14 [673266/888800 75.75%] train loss: 1.3829674571752548e-05 \n",
      "epoch: 14 [674377/888800 75.88%] train loss: 1.3353730537346564e-05 \n",
      "epoch: 14 [675488/888800 76.00%] train loss: 1.3609051165985875e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [676599/888800 76.12%] train loss: 1.4046709111426026e-05 \n",
      "epoch: 14 [677710/888800 76.25%] train loss: 1.4888993064232636e-05 \n",
      "epoch: 14 [678821/888800 76.38%] train loss: 1.4725078472110908e-05 \n",
      "epoch: 14 [679932/888800 76.50%] train loss: 1.4111546079220716e-05 \n",
      "epoch: 14 [681043/888800 76.62%] train loss: 1.5404253645101562e-05 \n",
      "epoch: 14 [682154/888800 76.75%] train loss: 1.378270644636359e-05 \n",
      "epoch: 14 [683265/888800 76.88%] train loss: 1.3428639249468688e-05 \n",
      "epoch: 14 [684376/888800 77.00%] train loss: 1.4909742276358884e-05 \n",
      "epoch: 14 [685487/888800 77.12%] train loss: 1.4909708625054918e-05 \n",
      "epoch: 14 [686598/888800 77.25%] train loss: 1.3975157344248146e-05 \n",
      "epoch: 14 [687709/888800 77.38%] train loss: 1.388030796078965e-05 \n",
      "epoch: 14 [688820/888800 77.50%] train loss: 1.4912350707163569e-05 \n",
      "epoch: 14 [689931/888800 77.62%] train loss: 1.4074408682063222e-05 \n",
      "epoch: 14 [691042/888800 77.75%] train loss: 1.431979126209626e-05 \n",
      "epoch: 14 [692153/888800 77.88%] train loss: 1.3508545634977054e-05 \n",
      "epoch: 14 [693264/888800 78.00%] train loss: 1.4158477824821603e-05 \n",
      "epoch: 14 [694375/888800 78.12%] train loss: 1.4124405424809083e-05 \n",
      "epoch: 14 [695486/888800 78.25%] train loss: 1.5241799701470882e-05 \n",
      "epoch: 14 [696597/888800 78.38%] train loss: 1.3841442523698788e-05 \n",
      "epoch: 14 [697708/888800 78.50%] train loss: 1.3320380276127253e-05 \n",
      "epoch: 14 [698819/888800 78.62%] train loss: 1.4008735888637602e-05 \n",
      "epoch: 14 [699930/888800 78.75%] train loss: 1.3965288417239208e-05 \n",
      "epoch: 14 [701041/888800 78.88%] train loss: 1.4957952771510463e-05 \n",
      "epoch: 14 [702152/888800 79.00%] train loss: 1.416512986907037e-05 \n",
      "epoch: 14 [703263/888800 79.12%] train loss: 1.5677955161663704e-05 \n",
      "epoch: 14 [704374/888800 79.25%] train loss: 1.3362699064600747e-05 \n",
      "epoch: 14 [705485/888800 79.38%] train loss: 1.4111858945398126e-05 \n",
      "epoch: 14 [706596/888800 79.50%] train loss: 1.3362498975766357e-05 \n",
      "epoch: 14 [707707/888800 79.62%] train loss: 1.5157752386585344e-05 \n",
      "epoch: 14 [708818/888800 79.75%] train loss: 1.3019503057876136e-05 \n",
      "epoch: 14 [709929/888800 79.88%] train loss: 1.385794621455716e-05 \n",
      "epoch: 14 [711040/888800 80.00%] train loss: 1.4493165508611128e-05 \n",
      "epoch: 14 [712151/888800 80.12%] train loss: 1.38477071232046e-05 \n",
      "epoch: 14 [713262/888800 80.25%] train loss: 1.3663034224009607e-05 \n",
      "epoch: 14 [714373/888800 80.38%] train loss: 1.5031070688564796e-05 \n",
      "epoch: 14 [715484/888800 80.50%] train loss: 1.3646706065628678e-05 \n",
      "epoch: 14 [716595/888800 80.62%] train loss: 1.4136378922557924e-05 \n",
      "epoch: 14 [717706/888800 80.75%] train loss: 1.3884241525374819e-05 \n",
      "epoch: 14 [718817/888800 80.88%] train loss: 1.473857628297992e-05 \n",
      "epoch: 14 [719928/888800 81.00%] train loss: 1.5099195479706395e-05 \n",
      "epoch: 14 [721039/888800 81.12%] train loss: 1.4404738976736553e-05 \n",
      "epoch: 14 [722150/888800 81.25%] train loss: 1.4402609849639703e-05 \n",
      "epoch: 14 [723261/888800 81.38%] train loss: 1.3302777006174438e-05 \n",
      "epoch: 14 [724372/888800 81.50%] train loss: 1.3878397112421226e-05 \n",
      "epoch: 14 [725483/888800 81.62%] train loss: 1.4233281945053022e-05 \n",
      "epoch: 14 [726594/888800 81.75%] train loss: 1.341655934083974e-05 \n",
      "epoch: 14 [727705/888800 81.88%] train loss: 1.4105729860602878e-05 \n",
      "epoch: 14 [728816/888800 82.00%] train loss: 1.28474785014987e-05 \n",
      "epoch: 14 [729927/888800 82.12%] train loss: 1.4835506590316072e-05 \n",
      "epoch: 14 [731038/888800 82.25%] train loss: 1.391343630530173e-05 \n",
      "epoch: 14 [732149/888800 82.38%] train loss: 1.3593374205811415e-05 \n",
      "epoch: 14 [733260/888800 82.50%] train loss: 1.4450163689616602e-05 \n",
      "epoch: 14 [734371/888800 82.62%] train loss: 1.4949629075999837e-05 \n",
      "epoch: 14 [735482/888800 82.75%] train loss: 1.6257461538771167e-05 \n",
      "epoch: 14 [736593/888800 82.88%] train loss: 1.4541704331350047e-05 \n",
      "epoch: 14 [737704/888800 83.00%] train loss: 1.3843356100551318e-05 \n",
      "epoch: 14 [738815/888800 83.12%] train loss: 1.4807107618253212e-05 \n",
      "epoch: 14 [739926/888800 83.25%] train loss: 1.3769796169071924e-05 \n",
      "epoch: 14 [741037/888800 83.38%] train loss: 1.5723077012808062e-05 \n",
      "epoch: 14 [742148/888800 83.50%] train loss: 1.499336303822929e-05 \n",
      "epoch: 14 [743259/888800 83.62%] train loss: 1.3926164683653042e-05 \n",
      "epoch: 14 [744370/888800 83.75%] train loss: 1.3823651897837408e-05 \n",
      "epoch: 14 [745481/888800 83.88%] train loss: 1.4060588910069782e-05 \n",
      "epoch: 14 [746592/888800 84.00%] train loss: 1.3756942280451767e-05 \n",
      "epoch: 14 [747703/888800 84.12%] train loss: 1.4660808119515423e-05 \n",
      "epoch: 14 [748814/888800 84.25%] train loss: 1.3507668882084545e-05 \n",
      "epoch: 14 [749925/888800 84.38%] train loss: 1.4237298273656052e-05 \n",
      "epoch: 14 [751036/888800 84.50%] train loss: 1.5273961253114976e-05 \n",
      "epoch: 14 [752147/888800 84.62%] train loss: 1.6199835954466835e-05 \n",
      "epoch: 14 [753258/888800 84.75%] train loss: 1.4446472050622106e-05 \n",
      "epoch: 14 [754369/888800 84.88%] train loss: 1.3809428310196381e-05 \n",
      "epoch: 14 [755480/888800 85.00%] train loss: 1.5606779925292358e-05 \n",
      "epoch: 14 [756591/888800 85.12%] train loss: 1.5133031411096454e-05 \n",
      "epoch: 14 [757702/888800 85.25%] train loss: 1.5102920770004857e-05 \n",
      "epoch: 14 [758813/888800 85.38%] train loss: 1.4615744476031978e-05 \n",
      "epoch: 14 [759924/888800 85.50%] train loss: 1.3815592865284998e-05 \n",
      "epoch: 14 [761035/888800 85.62%] train loss: 1.416074428561842e-05 \n",
      "epoch: 14 [762146/888800 85.75%] train loss: 1.3968338862468954e-05 \n",
      "epoch: 14 [763257/888800 85.88%] train loss: 1.463754233554937e-05 \n",
      "epoch: 14 [764368/888800 86.00%] train loss: 1.4166582332109101e-05 \n",
      "epoch: 14 [765479/888800 86.12%] train loss: 1.3350905646802858e-05 \n",
      "epoch: 14 [766590/888800 86.25%] train loss: 1.2868566955148708e-05 \n",
      "epoch: 14 [767701/888800 86.38%] train loss: 1.36680064315442e-05 \n",
      "epoch: 14 [768812/888800 86.50%] train loss: 1.4752391507499851e-05 \n",
      "epoch: 14 [769923/888800 86.62%] train loss: 1.4113717043073848e-05 \n",
      "epoch: 14 [771034/888800 86.75%] train loss: 1.4585024473490193e-05 \n",
      "epoch: 14 [772145/888800 86.88%] train loss: 1.543150210636668e-05 \n",
      "epoch: 14 [773256/888800 87.00%] train loss: 1.3582858628069516e-05 \n",
      "epoch: 14 [774367/888800 87.12%] train loss: 1.3929397027823143e-05 \n",
      "epoch: 14 [775478/888800 87.25%] train loss: 1.4220482626114972e-05 \n",
      "epoch: 14 [776589/888800 87.38%] train loss: 1.4064624338061549e-05 \n",
      "epoch: 14 [777700/888800 87.50%] train loss: 1.276677539863158e-05 \n",
      "epoch: 14 [778811/888800 87.62%] train loss: 1.4238906260288786e-05 \n",
      "epoch: 14 [779922/888800 87.75%] train loss: 1.4806664694333449e-05 \n",
      "epoch: 14 [781033/888800 87.88%] train loss: 1.3972418855701108e-05 \n",
      "epoch: 14 [782144/888800 88.00%] train loss: 1.3432104424282443e-05 \n",
      "epoch: 14 [783255/888800 88.12%] train loss: 1.4754669791727792e-05 \n",
      "epoch: 14 [784366/888800 88.25%] train loss: 1.4132474461803213e-05 \n",
      "epoch: 14 [785477/888800 88.38%] train loss: 1.2898455679533072e-05 \n",
      "epoch: 14 [786588/888800 88.50%] train loss: 1.448159400752047e-05 \n",
      "epoch: 14 [787699/888800 88.62%] train loss: 1.58686834765831e-05 \n",
      "epoch: 14 [788810/888800 88.75%] train loss: 1.3449231119011529e-05 \n",
      "epoch: 14 [789921/888800 88.88%] train loss: 1.4251638276618905e-05 \n",
      "epoch: 14 [791032/888800 89.00%] train loss: 1.439006064174464e-05 \n",
      "epoch: 14 [792143/888800 89.12%] train loss: 1.4638388165622018e-05 \n",
      "epoch: 14 [793254/888800 89.25%] train loss: 1.4096044651523698e-05 \n",
      "epoch: 14 [794365/888800 89.38%] train loss: 1.4050486242922489e-05 \n",
      "epoch: 14 [795476/888800 89.50%] train loss: 1.3577901881944854e-05 \n",
      "epoch: 14 [796587/888800 89.62%] train loss: 1.4606793229177129e-05 \n",
      "epoch: 14 [797698/888800 89.75%] train loss: 1.4655627637694124e-05 \n",
      "epoch: 14 [798809/888800 89.88%] train loss: 1.5506611816817895e-05 \n",
      "epoch: 14 [799920/888800 90.00%] train loss: 1.4059264685784001e-05 \n",
      "epoch: 14 [801031/888800 90.12%] train loss: 1.42409653562936e-05 \n",
      "epoch: 14 [802142/888800 90.25%] train loss: 1.3747678167419508e-05 \n",
      "epoch: 14 [803253/888800 90.38%] train loss: 1.3576317542174365e-05 \n",
      "epoch: 14 [804364/888800 90.50%] train loss: 1.4395851394510828e-05 \n",
      "epoch: 14 [805475/888800 90.62%] train loss: 1.4851922969683073e-05 \n",
      "epoch: 14 [806586/888800 90.75%] train loss: 1.3961885088065173e-05 \n",
      "epoch: 14 [807697/888800 90.88%] train loss: 1.5137963600864168e-05 \n",
      "epoch: 14 [808808/888800 91.00%] train loss: 1.498504752817098e-05 \n",
      "epoch: 14 [809919/888800 91.12%] train loss: 1.438694198441226e-05 \n",
      "epoch: 14 [811030/888800 91.25%] train loss: 1.3428350030153524e-05 \n",
      "epoch: 14 [812141/888800 91.38%] train loss: 1.412080746376887e-05 \n",
      "epoch: 14 [813252/888800 91.50%] train loss: 1.4583569281967357e-05 \n",
      "epoch: 14 [814363/888800 91.62%] train loss: 1.444426834495971e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 [815474/888800 91.75%] train loss: 1.4003644537297077e-05 \n",
      "epoch: 14 [816585/888800 91.88%] train loss: 1.3659426258527674e-05 \n",
      "epoch: 14 [817696/888800 92.00%] train loss: 1.4089061551203486e-05 \n",
      "epoch: 14 [818807/888800 92.12%] train loss: 1.2804417565348558e-05 \n",
      "epoch: 14 [819918/888800 92.25%] train loss: 1.4255100722948555e-05 \n",
      "epoch: 14 [821029/888800 92.38%] train loss: 1.3952386325399857e-05 \n",
      "epoch: 14 [822140/888800 92.50%] train loss: 1.3774281796941068e-05 \n",
      "epoch: 14 [823251/888800 92.62%] train loss: 1.4483499398920685e-05 \n",
      "epoch: 14 [824362/888800 92.75%] train loss: 1.5247654118866194e-05 \n",
      "epoch: 14 [825473/888800 92.88%] train loss: 1.4508795175061096e-05 \n",
      "epoch: 14 [826584/888800 93.00%] train loss: 1.5226187315420248e-05 \n",
      "epoch: 14 [827695/888800 93.12%] train loss: 1.4452627510763705e-05 \n",
      "epoch: 14 [828806/888800 93.25%] train loss: 1.4163641026243567e-05 \n",
      "epoch: 14 [829917/888800 93.38%] train loss: 1.6002231859602034e-05 \n",
      "epoch: 14 [831028/888800 93.50%] train loss: 1.3097183000354562e-05 \n",
      "epoch: 14 [832139/888800 93.62%] train loss: 1.4345647286972962e-05 \n",
      "epoch: 14 [833250/888800 93.75%] train loss: 1.4036843822395895e-05 \n",
      "epoch: 14 [834361/888800 93.88%] train loss: 1.4892986655468121e-05 \n",
      "epoch: 14 [835472/888800 94.00%] train loss: 1.5000833627709653e-05 \n",
      "epoch: 14 [836583/888800 94.12%] train loss: 1.3122890777594876e-05 \n",
      "epoch: 14 [837694/888800 94.25%] train loss: 1.4096468476054724e-05 \n",
      "epoch: 14 [838805/888800 94.38%] train loss: 1.3791905075777322e-05 \n",
      "epoch: 14 [839916/888800 94.50%] train loss: 1.3344414583116304e-05 \n",
      "epoch: 14 [841027/888800 94.62%] train loss: 1.3537690392695367e-05 \n",
      "epoch: 14 [842138/888800 94.75%] train loss: 1.3915805538999848e-05 \n",
      "epoch: 14 [843249/888800 94.88%] train loss: 1.4214236216503195e-05 \n",
      "epoch: 14 [844360/888800 95.00%] train loss: 1.4614024621550925e-05 \n",
      "epoch: 14 [845471/888800 95.12%] train loss: 1.3437608686217573e-05 \n",
      "epoch: 14 [846582/888800 95.25%] train loss: 1.4222891877579968e-05 \n",
      "epoch: 14 [847693/888800 95.38%] train loss: 1.2882222108601127e-05 \n",
      "epoch: 14 [848804/888800 95.50%] train loss: 1.2880856047559064e-05 \n",
      "epoch: 14 [849915/888800 95.62%] train loss: 1.4307126548374072e-05 \n",
      "epoch: 14 [851026/888800 95.75%] train loss: 1.4775971976632718e-05 \n",
      "epoch: 14 [852137/888800 95.88%] train loss: 1.4807616935286205e-05 \n",
      "epoch: 14 [853248/888800 96.00%] train loss: 1.5244541827996727e-05 \n",
      "epoch: 14 [854359/888800 96.12%] train loss: 1.4268953236751258e-05 \n",
      "epoch: 14 [855470/888800 96.25%] train loss: 1.408113803336164e-05 \n",
      "epoch: 14 [856581/888800 96.38%] train loss: 1.5981788237695582e-05 \n",
      "epoch: 14 [857692/888800 96.50%] train loss: 1.3893976756662596e-05 \n",
      "epoch: 14 [858803/888800 96.62%] train loss: 1.570374115544837e-05 \n",
      "epoch: 14 [859914/888800 96.75%] train loss: 1.6126725313370116e-05 \n",
      "epoch: 14 [861025/888800 96.88%] train loss: 1.4027883480594028e-05 \n",
      "epoch: 14 [862136/888800 97.00%] train loss: 1.6673524442012422e-05 \n",
      "epoch: 14 [863247/888800 97.12%] train loss: 1.4202420061337762e-05 \n",
      "epoch: 14 [864358/888800 97.25%] train loss: 1.4907295735611115e-05 \n",
      "epoch: 14 [865469/888800 97.38%] train loss: 1.4378199011844117e-05 \n",
      "epoch: 14 [866580/888800 97.50%] train loss: 1.6269161278614774e-05 \n",
      "epoch: 14 [867691/888800 97.62%] train loss: 1.6341678929165937e-05 \n",
      "epoch: 14 [868802/888800 97.75%] train loss: 1.3884848158340901e-05 \n",
      "epoch: 14 [869913/888800 97.88%] train loss: 1.4114633813733235e-05 \n",
      "epoch: 14 [871024/888800 98.00%] train loss: 1.3864637367078103e-05 \n",
      "epoch: 14 [872135/888800 98.12%] train loss: 1.5465440810658038e-05 \n",
      "epoch: 14 [873246/888800 98.25%] train loss: 1.3576446690422017e-05 \n",
      "epoch: 14 [874357/888800 98.38%] train loss: 1.4067722986510489e-05 \n",
      "epoch: 14 [875468/888800 98.50%] train loss: 1.416861869074637e-05 \n",
      "epoch: 14 [876579/888800 98.62%] train loss: 1.3643104466609657e-05 \n",
      "epoch: 14 [877690/888800 98.75%] train loss: 1.4719671526108868e-05 \n",
      "epoch: 14 [878801/888800 98.88%] train loss: 1.3690410014532972e-05 \n",
      "epoch: 14 [879912/888800 99.00%] train loss: 1.4156393262965139e-05 \n",
      "epoch: 14 [881023/888800 99.12%] train loss: 1.4546792954206467e-05 \n",
      "epoch: 14 [882134/888800 99.25%] train loss: 1.4180752259562723e-05 \n",
      "epoch: 14 [883245/888800 99.38%] train loss: 1.4302266208687797e-05 \n",
      "epoch: 14 [884356/888800 99.50%] train loss: 1.3969010069558863e-05 \n",
      "epoch: 14 [885467/888800 99.62%] train loss: 1.4445958186115604e-05 \n",
      "epoch: 14 [886578/888800 99.75%] train loss: 1.283729579881765e-05 \n",
      "epoch: 14 [887689/888800 99.88%] train loss: 1.3967610357212834e-05 \n",
      "epoch: 15 [0/888800 0.00%] train loss: 1.4045561329112388e-05 \n",
      "epoch: 15 [1111/888800 0.12%] train loss: 1.465986770199379e-05 \n",
      "epoch: 15 [2222/888800 0.25%] train loss: 1.4332370483316481e-05 \n",
      "epoch: 15 [3333/888800 0.38%] train loss: 1.3842764019500464e-05 \n",
      "epoch: 15 [4444/888800 0.50%] train loss: 1.3201451110944618e-05 \n",
      "epoch: 15 [5555/888800 0.62%] train loss: 1.4169411770126317e-05 \n",
      "epoch: 15 [6666/888800 0.75%] train loss: 1.4966808521421626e-05 \n",
      "epoch: 15 [7777/888800 0.88%] train loss: 1.340052858722629e-05 \n",
      "epoch: 15 [8888/888800 1.00%] train loss: 1.4704408386023715e-05 \n",
      "epoch: 15 [9999/888800 1.12%] train loss: 1.4035495951247867e-05 \n",
      "epoch: 15 [11110/888800 1.25%] train loss: 1.4455129530688282e-05 \n",
      "epoch: 15 [12221/888800 1.38%] train loss: 1.1909887689398602e-05 \n",
      "epoch: 15 [13332/888800 1.50%] train loss: 1.3843861779605504e-05 \n",
      "epoch: 15 [14443/888800 1.62%] train loss: 1.3317697266757023e-05 \n",
      "epoch: 15 [15554/888800 1.75%] train loss: 1.5012744370324071e-05 \n",
      "epoch: 15 [16665/888800 1.88%] train loss: 1.415880979038775e-05 \n",
      "epoch: 15 [17776/888800 2.00%] train loss: 1.5608449757564813e-05 \n",
      "epoch: 15 [18887/888800 2.12%] train loss: 1.4036106222192757e-05 \n",
      "epoch: 15 [19998/888800 2.25%] train loss: 1.4901741451467387e-05 \n",
      "epoch: 15 [21109/888800 2.38%] train loss: 1.5099004485819023e-05 \n",
      "epoch: 15 [22220/888800 2.50%] train loss: 1.4375992577697616e-05 \n",
      "epoch: 15 [23331/888800 2.62%] train loss: 1.5047656233946327e-05 \n",
      "epoch: 15 [24442/888800 2.75%] train loss: 1.5189149053185247e-05 \n",
      "epoch: 15 [25553/888800 2.88%] train loss: 1.410139611834893e-05 \n",
      "epoch: 15 [26664/888800 3.00%] train loss: 1.5344736311817542e-05 \n",
      "epoch: 15 [27775/888800 3.12%] train loss: 1.4431660929403733e-05 \n",
      "epoch: 15 [28886/888800 3.25%] train loss: 1.37736824399326e-05 \n",
      "epoch: 15 [29997/888800 3.38%] train loss: 1.554336085973773e-05 \n",
      "epoch: 15 [31108/888800 3.50%] train loss: 1.4074456885282416e-05 \n",
      "epoch: 15 [32219/888800 3.62%] train loss: 1.3688658327737357e-05 \n",
      "epoch: 15 [33330/888800 3.75%] train loss: 1.3756831322098151e-05 \n",
      "epoch: 15 [34441/888800 3.88%] train loss: 1.4980031664890703e-05 \n",
      "epoch: 15 [35552/888800 4.00%] train loss: 1.4006268429511692e-05 \n",
      "epoch: 15 [36663/888800 4.12%] train loss: 1.4545767044182867e-05 \n",
      "epoch: 15 [37774/888800 4.25%] train loss: 1.4233241927286144e-05 \n",
      "epoch: 15 [38885/888800 4.38%] train loss: 1.5923104001558386e-05 \n",
      "epoch: 15 [39996/888800 4.50%] train loss: 1.3315760043042246e-05 \n",
      "epoch: 15 [41107/888800 4.62%] train loss: 1.4412312339118216e-05 \n",
      "epoch: 15 [42218/888800 4.75%] train loss: 1.3976377886137925e-05 \n",
      "epoch: 15 [43329/888800 4.88%] train loss: 1.4680958884127904e-05 \n",
      "epoch: 15 [44440/888800 5.00%] train loss: 1.3886538908991497e-05 \n",
      "epoch: 15 [45551/888800 5.12%] train loss: 1.336054629064165e-05 \n",
      "epoch: 15 [46662/888800 5.25%] train loss: 1.4352574908116367e-05 \n",
      "epoch: 15 [47773/888800 5.38%] train loss: 1.5454379536095075e-05 \n",
      "epoch: 15 [48884/888800 5.50%] train loss: 1.4272980479290709e-05 \n",
      "epoch: 15 [49995/888800 5.62%] train loss: 1.4535962691297755e-05 \n",
      "epoch: 15 [51106/888800 5.75%] train loss: 1.3644042155647185e-05 \n",
      "epoch: 15 [52217/888800 5.88%] train loss: 1.3519469575840048e-05 \n",
      "epoch: 15 [53328/888800 6.00%] train loss: 1.3723181837121956e-05 \n",
      "epoch: 15 [54439/888800 6.12%] train loss: 1.5015401913842652e-05 \n",
      "epoch: 15 [55550/888800 6.25%] train loss: 1.3995209883432835e-05 \n",
      "epoch: 15 [56661/888800 6.38%] train loss: 1.3759953617409337e-05 \n",
      "epoch: 15 [57772/888800 6.50%] train loss: 1.4674371414002962e-05 \n",
      "epoch: 15 [58883/888800 6.62%] train loss: 1.4108047253102995e-05 \n",
      "epoch: 15 [59994/888800 6.75%] train loss: 1.4949875549064018e-05 \n",
      "epoch: 15 [61105/888800 6.88%] train loss: 1.3430995750240982e-05 \n",
      "epoch: 15 [62216/888800 7.00%] train loss: 1.3060668607067782e-05 \n",
      "epoch: 15 [63327/888800 7.12%] train loss: 1.4211424968380015e-05 \n",
      "epoch: 15 [64438/888800 7.25%] train loss: 1.3572424904850777e-05 \n",
      "epoch: 15 [65549/888800 7.38%] train loss: 1.4963598005124368e-05 \n",
      "epoch: 15 [66660/888800 7.50%] train loss: 1.4650420780526474e-05 \n",
      "epoch: 15 [67771/888800 7.62%] train loss: 1.3300262253324036e-05 \n",
      "epoch: 15 [68882/888800 7.75%] train loss: 1.349302056041779e-05 \n",
      "epoch: 15 [69993/888800 7.88%] train loss: 1.4837803064438049e-05 \n",
      "epoch: 15 [71104/888800 8.00%] train loss: 1.4341466339828912e-05 \n",
      "epoch: 15 [72215/888800 8.12%] train loss: 1.432666067557875e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [73326/888800 8.25%] train loss: 1.4941713743610308e-05 \n",
      "epoch: 15 [74437/888800 8.38%] train loss: 1.3238335668575019e-05 \n",
      "epoch: 15 [75548/888800 8.50%] train loss: 1.4488096894638147e-05 \n",
      "epoch: 15 [76659/888800 8.62%] train loss: 1.4299428585218266e-05 \n",
      "epoch: 15 [77770/888800 8.75%] train loss: 1.432561930414522e-05 \n",
      "epoch: 15 [78881/888800 8.88%] train loss: 1.4826253391220234e-05 \n",
      "epoch: 15 [79992/888800 9.00%] train loss: 1.5078443539096043e-05 \n",
      "epoch: 15 [81103/888800 9.12%] train loss: 1.3234650396043435e-05 \n",
      "epoch: 15 [82214/888800 9.25%] train loss: 1.5007245565357152e-05 \n",
      "epoch: 15 [83325/888800 9.38%] train loss: 1.4700879546580836e-05 \n",
      "epoch: 15 [84436/888800 9.50%] train loss: 1.3003737876715604e-05 \n",
      "epoch: 15 [85547/888800 9.62%] train loss: 1.4682953406008892e-05 \n",
      "epoch: 15 [86658/888800 9.75%] train loss: 1.4820017895544879e-05 \n",
      "epoch: 15 [87769/888800 9.88%] train loss: 1.4645306691818405e-05 \n",
      "epoch: 15 [88880/888800 10.00%] train loss: 1.3616521755466238e-05 \n",
      "epoch: 15 [89991/888800 10.12%] train loss: 1.454799985367572e-05 \n",
      "epoch: 15 [91102/888800 10.25%] train loss: 1.401413646817673e-05 \n",
      "epoch: 15 [92213/888800 10.38%] train loss: 1.5814874132047407e-05 \n",
      "epoch: 15 [93324/888800 10.50%] train loss: 1.3096954717184417e-05 \n",
      "epoch: 15 [94435/888800 10.62%] train loss: 1.4813658708590083e-05 \n",
      "epoch: 15 [95546/888800 10.75%] train loss: 1.4651315723313019e-05 \n",
      "epoch: 15 [96657/888800 10.88%] train loss: 1.4796689356444404e-05 \n",
      "epoch: 15 [97768/888800 11.00%] train loss: 1.571382745169103e-05 \n",
      "epoch: 15 [98879/888800 11.12%] train loss: 1.3945254067948554e-05 \n",
      "epoch: 15 [99990/888800 11.25%] train loss: 1.4813250345468987e-05 \n",
      "epoch: 15 [101101/888800 11.38%] train loss: 1.4012486644787714e-05 \n",
      "epoch: 15 [102212/888800 11.50%] train loss: 1.4607258890464436e-05 \n",
      "epoch: 15 [103323/888800 11.62%] train loss: 1.3868188034393825e-05 \n",
      "epoch: 15 [104434/888800 11.75%] train loss: 1.4438950529438443e-05 \n",
      "epoch: 15 [105545/888800 11.88%] train loss: 1.6318275811499916e-05 \n",
      "epoch: 15 [106656/888800 12.00%] train loss: 1.3581642633653246e-05 \n",
      "epoch: 15 [107767/888800 12.12%] train loss: 1.3892251445213333e-05 \n",
      "epoch: 15 [108878/888800 12.25%] train loss: 1.498205165262334e-05 \n",
      "epoch: 15 [109989/888800 12.38%] train loss: 1.5447809346369468e-05 \n",
      "epoch: 15 [111100/888800 12.50%] train loss: 1.3137924725015182e-05 \n",
      "epoch: 15 [112211/888800 12.62%] train loss: 1.3851737094228156e-05 \n",
      "epoch: 15 [113322/888800 12.75%] train loss: 1.4880627531965729e-05 \n",
      "epoch: 15 [114433/888800 12.88%] train loss: 1.3632256923301611e-05 \n",
      "epoch: 15 [115544/888800 13.00%] train loss: 1.3817405488225631e-05 \n",
      "epoch: 15 [116655/888800 13.12%] train loss: 1.3479952940542717e-05 \n",
      "epoch: 15 [117766/888800 13.25%] train loss: 1.3742463124799542e-05 \n",
      "epoch: 15 [118877/888800 13.38%] train loss: 1.3874830983695574e-05 \n",
      "epoch: 15 [119988/888800 13.50%] train loss: 1.3869066606275737e-05 \n",
      "epoch: 15 [121099/888800 13.62%] train loss: 1.3783150279778056e-05 \n",
      "epoch: 15 [122210/888800 13.75%] train loss: 1.4779029697820079e-05 \n",
      "epoch: 15 [123321/888800 13.88%] train loss: 1.455891106161289e-05 \n",
      "epoch: 15 [124432/888800 14.00%] train loss: 1.429160238330951e-05 \n",
      "epoch: 15 [125543/888800 14.12%] train loss: 1.3398766895988956e-05 \n",
      "epoch: 15 [126654/888800 14.25%] train loss: 1.5003974112914875e-05 \n",
      "epoch: 15 [127765/888800 14.38%] train loss: 1.399411939928541e-05 \n",
      "epoch: 15 [128876/888800 14.50%] train loss: 1.328474627371179e-05 \n",
      "epoch: 15 [129987/888800 14.62%] train loss: 1.4243602890928742e-05 \n",
      "epoch: 15 [131098/888800 14.75%] train loss: 1.3804776244796813e-05 \n",
      "epoch: 15 [132209/888800 14.88%] train loss: 1.4242467841540929e-05 \n",
      "epoch: 15 [133320/888800 15.00%] train loss: 1.4424116670852527e-05 \n",
      "epoch: 15 [134431/888800 15.12%] train loss: 1.358599456580123e-05 \n",
      "epoch: 15 [135542/888800 15.25%] train loss: 1.419867476215586e-05 \n",
      "epoch: 15 [136653/888800 15.38%] train loss: 1.3612605471280403e-05 \n",
      "epoch: 15 [137764/888800 15.50%] train loss: 1.3907061656937003e-05 \n",
      "epoch: 15 [138875/888800 15.62%] train loss: 1.3309118003235199e-05 \n",
      "epoch: 15 [139986/888800 15.75%] train loss: 1.4827326594968326e-05 \n",
      "epoch: 15 [141097/888800 15.88%] train loss: 1.4155030839901883e-05 \n",
      "epoch: 15 [142208/888800 16.00%] train loss: 1.4762231330678333e-05 \n",
      "epoch: 15 [143319/888800 16.12%] train loss: 1.4380422726389952e-05 \n",
      "epoch: 15 [144430/888800 16.25%] train loss: 1.4493502021650784e-05 \n",
      "epoch: 15 [145541/888800 16.38%] train loss: 1.4500405995931942e-05 \n",
      "epoch: 15 [146652/888800 16.50%] train loss: 1.3706760000786744e-05 \n",
      "epoch: 15 [147763/888800 16.62%] train loss: 1.4924323295417707e-05 \n",
      "epoch: 15 [148874/888800 16.75%] train loss: 1.4868775906506926e-05 \n",
      "epoch: 15 [149985/888800 16.88%] train loss: 1.3446501725411508e-05 \n",
      "epoch: 15 [151096/888800 17.00%] train loss: 1.3944732017989736e-05 \n",
      "epoch: 15 [152207/888800 17.12%] train loss: 1.4751999515283387e-05 \n",
      "epoch: 15 [153318/888800 17.25%] train loss: 1.323600190517027e-05 \n",
      "epoch: 15 [154429/888800 17.38%] train loss: 1.304322540818248e-05 \n",
      "epoch: 15 [155540/888800 17.50%] train loss: 1.4377449588209856e-05 \n",
      "epoch: 15 [156651/888800 17.62%] train loss: 1.4770944289921317e-05 \n",
      "epoch: 15 [157762/888800 17.75%] train loss: 1.4166856999509037e-05 \n",
      "epoch: 15 [158873/888800 17.88%] train loss: 1.4502693375106901e-05 \n",
      "epoch: 15 [159984/888800 18.00%] train loss: 1.448814418836264e-05 \n",
      "epoch: 15 [161095/888800 18.12%] train loss: 1.3404845958575606e-05 \n",
      "epoch: 15 [162206/888800 18.25%] train loss: 1.4949110664019827e-05 \n",
      "epoch: 15 [163317/888800 18.38%] train loss: 1.3546296941058245e-05 \n",
      "epoch: 15 [164428/888800 18.50%] train loss: 1.3823725566908251e-05 \n",
      "epoch: 15 [165539/888800 18.62%] train loss: 1.4389626812771894e-05 \n",
      "epoch: 15 [166650/888800 18.75%] train loss: 1.4760663361812476e-05 \n",
      "epoch: 15 [167761/888800 18.88%] train loss: 1.4058537090022583e-05 \n",
      "epoch: 15 [168872/888800 19.00%] train loss: 1.3427003068500198e-05 \n",
      "epoch: 15 [169983/888800 19.12%] train loss: 1.5134365639823955e-05 \n",
      "epoch: 15 [171094/888800 19.25%] train loss: 1.4767694665351883e-05 \n",
      "epoch: 15 [172205/888800 19.38%] train loss: 1.542823520139791e-05 \n",
      "epoch: 15 [173316/888800 19.50%] train loss: 1.4474758245341945e-05 \n",
      "epoch: 15 [174427/888800 19.62%] train loss: 1.3111665793985594e-05 \n",
      "epoch: 15 [175538/888800 19.75%] train loss: 1.3703145668841898e-05 \n",
      "epoch: 15 [176649/888800 19.88%] train loss: 1.4354984159581363e-05 \n",
      "epoch: 15 [177760/888800 20.00%] train loss: 1.3520697393687442e-05 \n",
      "epoch: 15 [178871/888800 20.12%] train loss: 1.4710023606312461e-05 \n",
      "epoch: 15 [179982/888800 20.25%] train loss: 1.2449661880964413e-05 \n",
      "epoch: 15 [181093/888800 20.38%] train loss: 1.4058197848498821e-05 \n",
      "epoch: 15 [182204/888800 20.50%] train loss: 1.5018481462902855e-05 \n",
      "epoch: 15 [183315/888800 20.62%] train loss: 1.4163390005705878e-05 \n",
      "epoch: 15 [184426/888800 20.75%] train loss: 1.4106457456364296e-05 \n",
      "epoch: 15 [185537/888800 20.88%] train loss: 1.2786998922820203e-05 \n",
      "epoch: 15 [186648/888800 21.00%] train loss: 1.4337143511511385e-05 \n",
      "epoch: 15 [187759/888800 21.12%] train loss: 1.4715562429046258e-05 \n",
      "epoch: 15 [188870/888800 21.25%] train loss: 1.533061367808841e-05 \n",
      "epoch: 15 [189981/888800 21.38%] train loss: 1.5052919479785487e-05 \n",
      "epoch: 15 [191092/888800 21.50%] train loss: 1.5253337551257573e-05 \n",
      "epoch: 15 [192203/888800 21.62%] train loss: 1.4027494216861669e-05 \n",
      "epoch: 15 [193314/888800 21.75%] train loss: 1.4063741218706127e-05 \n",
      "epoch: 15 [194425/888800 21.88%] train loss: 1.3824953384755645e-05 \n",
      "epoch: 15 [195536/888800 22.00%] train loss: 1.3762220078206155e-05 \n",
      "epoch: 15 [196647/888800 22.12%] train loss: 1.4377562365552876e-05 \n",
      "epoch: 15 [197758/888800 22.25%] train loss: 1.4457566976489034e-05 \n",
      "epoch: 15 [198869/888800 22.38%] train loss: 1.428881205356447e-05 \n",
      "epoch: 15 [199980/888800 22.50%] train loss: 1.3555691111832857e-05 \n",
      "epoch: 15 [201091/888800 22.62%] train loss: 1.415381302649621e-05 \n",
      "epoch: 15 [202202/888800 22.75%] train loss: 1.4392672710528132e-05 \n",
      "epoch: 15 [203313/888800 22.88%] train loss: 1.4069794815441128e-05 \n",
      "epoch: 15 [204424/888800 23.00%] train loss: 1.414161943102954e-05 \n",
      "epoch: 15 [205535/888800 23.12%] train loss: 1.394262017129222e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [206646/888800 23.25%] train loss: 1.4892701983626466e-05 \n",
      "epoch: 15 [207757/888800 23.38%] train loss: 1.5048063687572721e-05 \n",
      "epoch: 15 [208868/888800 23.50%] train loss: 1.4177484445099253e-05 \n",
      "epoch: 15 [209979/888800 23.62%] train loss: 1.4664465197711252e-05 \n",
      "epoch: 15 [211090/888800 23.75%] train loss: 1.4808733794779982e-05 \n",
      "epoch: 15 [212201/888800 23.88%] train loss: 1.3669954569195397e-05 \n",
      "epoch: 15 [213312/888800 24.00%] train loss: 1.5183098184934352e-05 \n",
      "epoch: 15 [214423/888800 24.12%] train loss: 1.4094007383391727e-05 \n",
      "epoch: 15 [215534/888800 24.25%] train loss: 1.2686326954280958e-05 \n",
      "epoch: 15 [216645/888800 24.38%] train loss: 1.3577805475506466e-05 \n",
      "epoch: 15 [217756/888800 24.50%] train loss: 1.544155202282127e-05 \n",
      "epoch: 15 [218867/888800 24.62%] train loss: 1.533866634417791e-05 \n",
      "epoch: 15 [219978/888800 24.75%] train loss: 1.4750061382073909e-05 \n",
      "epoch: 15 [221089/888800 24.88%] train loss: 1.4165465472615324e-05 \n",
      "epoch: 15 [222200/888800 25.00%] train loss: 1.3135947483533528e-05 \n",
      "epoch: 15 [223311/888800 25.12%] train loss: 1.539679942652583e-05 \n",
      "epoch: 15 [224422/888800 25.25%] train loss: 1.3249531548353843e-05 \n",
      "epoch: 15 [225533/888800 25.38%] train loss: 1.2822854841942899e-05 \n",
      "epoch: 15 [226644/888800 25.50%] train loss: 1.426458311470924e-05 \n",
      "epoch: 15 [227755/888800 25.62%] train loss: 1.398150016029831e-05 \n",
      "epoch: 15 [228866/888800 25.75%] train loss: 1.3870944712834898e-05 \n",
      "epoch: 15 [229977/888800 25.88%] train loss: 1.4492613445327152e-05 \n",
      "epoch: 15 [231088/888800 26.00%] train loss: 1.3770088116871193e-05 \n",
      "epoch: 15 [232199/888800 26.12%] train loss: 1.4683610970678274e-05 \n",
      "epoch: 15 [233310/888800 26.25%] train loss: 1.3619756828120444e-05 \n",
      "epoch: 15 [234421/888800 26.38%] train loss: 1.3166002645448316e-05 \n",
      "epoch: 15 [235532/888800 26.50%] train loss: 1.407170930178836e-05 \n",
      "epoch: 15 [236643/888800 26.62%] train loss: 1.4214259863365442e-05 \n",
      "epoch: 15 [237754/888800 26.75%] train loss: 1.4127675967756659e-05 \n",
      "epoch: 15 [238865/888800 26.88%] train loss: 1.426749713573372e-05 \n",
      "epoch: 15 [239976/888800 27.00%] train loss: 1.4157028999761678e-05 \n",
      "epoch: 15 [241087/888800 27.12%] train loss: 1.4391386685019825e-05 \n",
      "epoch: 15 [242198/888800 27.25%] train loss: 1.4013879081176128e-05 \n",
      "epoch: 15 [243309/888800 27.38%] train loss: 1.3340097211766988e-05 \n",
      "epoch: 15 [244420/888800 27.50%] train loss: 1.2950751624885015e-05 \n",
      "epoch: 15 [245531/888800 27.62%] train loss: 1.4865337107039522e-05 \n",
      "epoch: 15 [246642/888800 27.75%] train loss: 1.4435801858780906e-05 \n",
      "epoch: 15 [247753/888800 27.88%] train loss: 1.407640866091242e-05 \n",
      "epoch: 15 [248864/888800 28.00%] train loss: 1.2573914318636525e-05 \n",
      "epoch: 15 [249975/888800 28.12%] train loss: 1.4183226994646247e-05 \n",
      "epoch: 15 [251086/888800 28.25%] train loss: 1.4187062333803624e-05 \n",
      "epoch: 15 [252197/888800 28.38%] train loss: 1.4774747796764132e-05 \n",
      "epoch: 15 [253308/888800 28.50%] train loss: 1.4587232726626098e-05 \n",
      "epoch: 15 [254419/888800 28.62%] train loss: 1.4534772162733134e-05 \n",
      "epoch: 15 [255530/888800 28.75%] train loss: 1.3743133422394749e-05 \n",
      "epoch: 15 [256641/888800 28.88%] train loss: 1.3947056686447468e-05 \n",
      "epoch: 15 [257752/888800 29.00%] train loss: 1.3506038158084266e-05 \n",
      "epoch: 15 [258863/888800 29.12%] train loss: 1.2919391338073183e-05 \n",
      "epoch: 15 [259974/888800 29.25%] train loss: 1.5524172340519726e-05 \n",
      "epoch: 15 [261085/888800 29.38%] train loss: 1.3514225429389626e-05 \n",
      "epoch: 15 [262196/888800 29.50%] train loss: 1.4399327483261004e-05 \n",
      "epoch: 15 [263307/888800 29.62%] train loss: 1.4595203538192436e-05 \n",
      "epoch: 15 [264418/888800 29.75%] train loss: 1.4957751773181371e-05 \n",
      "epoch: 15 [265529/888800 29.88%] train loss: 1.4059035493119154e-05 \n",
      "epoch: 15 [266640/888800 30.00%] train loss: 1.4822925550106447e-05 \n",
      "epoch: 15 [267751/888800 30.12%] train loss: 1.4669164556835312e-05 \n",
      "epoch: 15 [268862/888800 30.25%] train loss: 1.316914949711645e-05 \n",
      "epoch: 15 [269973/888800 30.38%] train loss: 1.4317767636384815e-05 \n",
      "epoch: 15 [271084/888800 30.50%] train loss: 1.3736392247665208e-05 \n",
      "epoch: 15 [272195/888800 30.62%] train loss: 1.3722319636144675e-05 \n",
      "epoch: 15 [273306/888800 30.75%] train loss: 1.3709161066799425e-05 \n",
      "epoch: 15 [274417/888800 30.88%] train loss: 1.333920590695925e-05 \n",
      "epoch: 15 [275528/888800 31.00%] train loss: 1.3826216672896408e-05 \n",
      "epoch: 15 [276639/888800 31.12%] train loss: 1.4691884643980302e-05 \n",
      "epoch: 15 [277750/888800 31.25%] train loss: 1.3499365195457358e-05 \n",
      "epoch: 15 [278861/888800 31.38%] train loss: 1.5202336726360954e-05 \n",
      "epoch: 15 [279972/888800 31.50%] train loss: 1.5202497706923168e-05 \n",
      "epoch: 15 [281083/888800 31.62%] train loss: 1.336372133664554e-05 \n",
      "epoch: 15 [282194/888800 31.75%] train loss: 1.5302308383979835e-05 \n",
      "epoch: 15 [283305/888800 31.88%] train loss: 1.4947504496376496e-05 \n",
      "epoch: 15 [284416/888800 32.00%] train loss: 1.5247720511979423e-05 \n",
      "epoch: 15 [285527/888800 32.12%] train loss: 1.5374838767456822e-05 \n",
      "epoch: 15 [286638/888800 32.25%] train loss: 1.4715731595060788e-05 \n",
      "epoch: 15 [287749/888800 32.38%] train loss: 1.678115404502023e-05 \n",
      "epoch: 15 [288860/888800 32.50%] train loss: 1.4090602235228289e-05 \n",
      "epoch: 15 [289971/888800 32.62%] train loss: 1.7107131498050876e-05 \n",
      "epoch: 15 [291082/888800 32.75%] train loss: 1.5987207007128745e-05 \n",
      "epoch: 15 [292193/888800 32.88%] train loss: 1.5257128325174563e-05 \n",
      "epoch: 15 [293304/888800 33.00%] train loss: 1.736980448185932e-05 \n",
      "epoch: 15 [294415/888800 33.12%] train loss: 1.3810968994221184e-05 \n",
      "epoch: 15 [295526/888800 33.25%] train loss: 1.851852903200779e-05 \n",
      "epoch: 15 [296637/888800 33.38%] train loss: 1.3612542716145981e-05 \n",
      "epoch: 15 [297748/888800 33.50%] train loss: 1.586217331350781e-05 \n",
      "epoch: 15 [298859/888800 33.62%] train loss: 1.5663499652873725e-05 \n",
      "epoch: 15 [299970/888800 33.75%] train loss: 1.413178051734576e-05 \n",
      "epoch: 15 [301081/888800 33.88%] train loss: 1.4231229215511121e-05 \n",
      "epoch: 15 [302192/888800 34.00%] train loss: 1.2938306099385954e-05 \n",
      "epoch: 15 [303303/888800 34.12%] train loss: 1.4277005902840756e-05 \n",
      "epoch: 15 [304414/888800 34.25%] train loss: 1.4129816918284632e-05 \n",
      "epoch: 15 [305525/888800 34.38%] train loss: 1.4117395039647818e-05 \n",
      "epoch: 15 [306636/888800 34.50%] train loss: 1.5243350389937405e-05 \n",
      "epoch: 15 [307747/888800 34.62%] train loss: 1.3164856682124082e-05 \n",
      "epoch: 15 [308858/888800 34.75%] train loss: 1.4853866559860762e-05 \n",
      "epoch: 15 [309969/888800 34.88%] train loss: 1.3722199582844041e-05 \n",
      "epoch: 15 [311080/888800 35.00%] train loss: 1.3126239537086803e-05 \n",
      "epoch: 15 [312191/888800 35.12%] train loss: 1.4139515769784339e-05 \n",
      "epoch: 15 [313302/888800 35.25%] train loss: 1.4772882423130795e-05 \n",
      "epoch: 15 [314413/888800 35.38%] train loss: 1.3989870240038726e-05 \n",
      "epoch: 15 [315524/888800 35.50%] train loss: 1.5303057807614096e-05 \n",
      "epoch: 15 [316635/888800 35.62%] train loss: 1.4605481737817172e-05 \n",
      "epoch: 15 [317746/888800 35.75%] train loss: 1.5107358194654807e-05 \n",
      "epoch: 15 [318857/888800 35.88%] train loss: 1.3162096365704201e-05 \n",
      "epoch: 15 [319968/888800 36.00%] train loss: 1.3558231330534909e-05 \n",
      "epoch: 15 [321079/888800 36.12%] train loss: 1.4547386854246724e-05 \n",
      "epoch: 15 [322190/888800 36.25%] train loss: 1.3734270396525972e-05 \n",
      "epoch: 15 [323301/888800 36.38%] train loss: 1.307634465774754e-05 \n",
      "epoch: 15 [324412/888800 36.50%] train loss: 1.4283229575084988e-05 \n",
      "epoch: 15 [325523/888800 36.62%] train loss: 1.506606895418372e-05 \n",
      "epoch: 15 [326634/888800 36.75%] train loss: 1.4632786587753799e-05 \n",
      "epoch: 15 [327745/888800 36.88%] train loss: 1.3565653716796078e-05 \n",
      "epoch: 15 [328856/888800 37.00%] train loss: 1.535769843030721e-05 \n",
      "epoch: 15 [329967/888800 37.12%] train loss: 1.3750655853073113e-05 \n",
      "epoch: 15 [331078/888800 37.25%] train loss: 1.7512737031211145e-05 \n",
      "epoch: 15 [332189/888800 37.38%] train loss: 1.574876114318613e-05 \n",
      "epoch: 15 [333300/888800 37.50%] train loss: 1.4168585039442405e-05 \n",
      "epoch: 15 [334411/888800 37.62%] train loss: 1.3973802197142504e-05 \n",
      "epoch: 15 [335522/888800 37.75%] train loss: 1.3602066246676259e-05 \n",
      "epoch: 15 [336633/888800 37.88%] train loss: 1.608406273589935e-05 \n",
      "epoch: 15 [337744/888800 38.00%] train loss: 1.2751639587804675e-05 \n",
      "epoch: 15 [338855/888800 38.12%] train loss: 1.5161571354838088e-05 \n",
      "epoch: 15 [339966/888800 38.25%] train loss: 1.5750923921586946e-05 \n",
      "epoch: 15 [341077/888800 38.38%] train loss: 1.677686486800667e-05 \n",
      "epoch: 15 [342188/888800 38.50%] train loss: 1.5772577171446756e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [343299/888800 38.62%] train loss: 1.4670874406874646e-05 \n",
      "epoch: 15 [344410/888800 38.75%] train loss: 1.4284178178058937e-05 \n",
      "epoch: 15 [345521/888800 38.88%] train loss: 1.3571289855462965e-05 \n",
      "epoch: 15 [346632/888800 39.00%] train loss: 1.4530161934089847e-05 \n",
      "epoch: 15 [347743/888800 39.12%] train loss: 1.4609854588343296e-05 \n",
      "epoch: 15 [348854/888800 39.25%] train loss: 1.5177603927440941e-05 \n",
      "epoch: 15 [349965/888800 39.38%] train loss: 1.4073603779252153e-05 \n",
      "epoch: 15 [351076/888800 39.50%] train loss: 1.3306304936122615e-05 \n",
      "epoch: 15 [352187/888800 39.62%] train loss: 1.463146327296272e-05 \n",
      "epoch: 15 [353298/888800 39.75%] train loss: 1.4188103705237154e-05 \n",
      "epoch: 15 [354409/888800 39.88%] train loss: 1.3243244211480487e-05 \n",
      "epoch: 15 [355520/888800 40.00%] train loss: 1.499285008321749e-05 \n",
      "epoch: 15 [356631/888800 40.12%] train loss: 1.3359753211261705e-05 \n",
      "epoch: 15 [357742/888800 40.25%] train loss: 1.4970339179853909e-05 \n",
      "epoch: 15 [358853/888800 40.38%] train loss: 1.4017738976690453e-05 \n",
      "epoch: 15 [359964/888800 40.50%] train loss: 1.372704628010979e-05 \n",
      "epoch: 15 [361075/888800 40.62%] train loss: 1.5109291780390777e-05 \n",
      "epoch: 15 [362186/888800 40.75%] train loss: 1.3404775017988868e-05 \n",
      "epoch: 15 [363297/888800 40.88%] train loss: 1.4332244973047636e-05 \n",
      "epoch: 15 [364408/888800 41.00%] train loss: 1.422363129677251e-05 \n",
      "epoch: 15 [365519/888800 41.12%] train loss: 1.4503870261250995e-05 \n",
      "epoch: 15 [366630/888800 41.25%] train loss: 1.3858123566024005e-05 \n",
      "epoch: 15 [367741/888800 41.38%] train loss: 1.5126308426260948e-05 \n",
      "epoch: 15 [368852/888800 41.50%] train loss: 1.5921277736197226e-05 \n",
      "epoch: 15 [369963/888800 41.62%] train loss: 1.638134926906787e-05 \n",
      "epoch: 15 [371074/888800 41.75%] train loss: 1.6608795704087242e-05 \n",
      "epoch: 15 [372185/888800 41.88%] train loss: 1.2575287655636203e-05 \n",
      "epoch: 15 [373296/888800 42.00%] train loss: 1.5040463040350005e-05 \n",
      "epoch: 15 [374407/888800 42.12%] train loss: 1.4373978046933189e-05 \n",
      "epoch: 15 [375518/888800 42.25%] train loss: 1.4853443644824438e-05 \n",
      "epoch: 15 [376629/888800 42.38%] train loss: 1.4402286069525871e-05 \n",
      "epoch: 15 [377740/888800 42.50%] train loss: 1.469065773562761e-05 \n",
      "epoch: 15 [378851/888800 42.62%] train loss: 1.4644374459749088e-05 \n",
      "epoch: 15 [379962/888800 42.75%] train loss: 1.487493409513263e-05 \n",
      "epoch: 15 [381073/888800 42.88%] train loss: 1.400138353346847e-05 \n",
      "epoch: 15 [382184/888800 43.00%] train loss: 1.4354948689287994e-05 \n",
      "epoch: 15 [383295/888800 43.12%] train loss: 1.5203265320451465e-05 \n",
      "epoch: 15 [384406/888800 43.25%] train loss: 1.4782271136937197e-05 \n",
      "epoch: 15 [385517/888800 43.38%] train loss: 1.6268226318061352e-05 \n",
      "epoch: 15 [386628/888800 43.50%] train loss: 1.3565125300374348e-05 \n",
      "epoch: 15 [387739/888800 43.62%] train loss: 1.4419160834222566e-05 \n",
      "epoch: 15 [388850/888800 43.75%] train loss: 1.4470152564172167e-05 \n",
      "epoch: 15 [389961/888800 43.88%] train loss: 1.4259544514061417e-05 \n",
      "epoch: 15 [391072/888800 44.00%] train loss: 1.6903350115171634e-05 \n",
      "epoch: 15 [392183/888800 44.12%] train loss: 1.4220243429008406e-05 \n",
      "epoch: 15 [393294/888800 44.25%] train loss: 1.4023069525137544e-05 \n",
      "epoch: 15 [394405/888800 44.38%] train loss: 1.5120340322027914e-05 \n",
      "epoch: 15 [395516/888800 44.50%] train loss: 1.4269849089032505e-05 \n",
      "epoch: 15 [396627/888800 44.62%] train loss: 1.2987892660021316e-05 \n",
      "epoch: 15 [397738/888800 44.75%] train loss: 1.4513308997265995e-05 \n",
      "epoch: 15 [398849/888800 44.88%] train loss: 1.4329929399536923e-05 \n",
      "epoch: 15 [399960/888800 45.00%] train loss: 1.4274987734097522e-05 \n",
      "epoch: 15 [401071/888800 45.12%] train loss: 1.4026922144694254e-05 \n",
      "epoch: 15 [402182/888800 45.25%] train loss: 1.5908022760413587e-05 \n",
      "epoch: 15 [403293/888800 45.38%] train loss: 1.4363283298735041e-05 \n",
      "epoch: 15 [404404/888800 45.50%] train loss: 1.522141246823594e-05 \n",
      "epoch: 15 [405515/888800 45.62%] train loss: 1.4460172678809613e-05 \n",
      "epoch: 15 [406626/888800 45.75%] train loss: 1.4020388334756717e-05 \n",
      "epoch: 15 [407737/888800 45.88%] train loss: 1.47388218465494e-05 \n",
      "epoch: 15 [408848/888800 46.00%] train loss: 1.570905078551732e-05 \n",
      "epoch: 15 [409959/888800 46.12%] train loss: 1.4581891264242586e-05 \n",
      "epoch: 15 [411070/888800 46.25%] train loss: 1.690975477686152e-05 \n",
      "epoch: 15 [412181/888800 46.38%] train loss: 1.6638303350191563e-05 \n",
      "epoch: 15 [413292/888800 46.50%] train loss: 1.3962441698822659e-05 \n",
      "epoch: 15 [414403/888800 46.62%] train loss: 1.636452361708507e-05 \n",
      "epoch: 15 [415514/888800 46.75%] train loss: 1.3110249710734934e-05 \n",
      "epoch: 15 [416625/888800 46.88%] train loss: 1.8647733668331057e-05 \n",
      "epoch: 15 [417736/888800 47.00%] train loss: 1.4740598089701962e-05 \n",
      "epoch: 15 [418847/888800 47.12%] train loss: 1.774789961928036e-05 \n",
      "epoch: 15 [419958/888800 47.25%] train loss: 1.5521018212893978e-05 \n",
      "epoch: 15 [421069/888800 47.38%] train loss: 1.5249122043314856e-05 \n",
      "epoch: 15 [422180/888800 47.50%] train loss: 1.6287889593513682e-05 \n",
      "epoch: 15 [423291/888800 47.62%] train loss: 1.4871315215714276e-05 \n",
      "epoch: 15 [424402/888800 47.75%] train loss: 1.688148950051982e-05 \n",
      "epoch: 15 [425513/888800 47.88%] train loss: 1.3088787454762496e-05 \n",
      "epoch: 15 [426624/888800 48.00%] train loss: 1.664582123339642e-05 \n",
      "epoch: 15 [427735/888800 48.12%] train loss: 1.4299174836196471e-05 \n",
      "epoch: 15 [428846/888800 48.25%] train loss: 1.6695754311513156e-05 \n",
      "epoch: 15 [429957/888800 48.38%] train loss: 1.4726431800227147e-05 \n",
      "epoch: 15 [431068/888800 48.50%] train loss: 1.5503390386584215e-05 \n",
      "epoch: 15 [432179/888800 48.62%] train loss: 1.451315256417729e-05 \n",
      "epoch: 15 [433290/888800 48.75%] train loss: 1.6233760106842965e-05 \n",
      "epoch: 15 [434401/888800 48.88%] train loss: 1.4649434888269752e-05 \n",
      "epoch: 15 [435512/888800 49.00%] train loss: 1.5208771401375998e-05 \n",
      "epoch: 15 [436623/888800 49.12%] train loss: 1.5457935660379007e-05 \n",
      "epoch: 15 [437734/888800 49.25%] train loss: 1.4111728887655772e-05 \n",
      "epoch: 15 [438845/888800 49.38%] train loss: 1.575724672875367e-05 \n",
      "epoch: 15 [439956/888800 49.50%] train loss: 1.443078235752182e-05 \n",
      "epoch: 15 [441067/888800 49.62%] train loss: 1.5664860256947577e-05 \n",
      "epoch: 15 [442178/888800 49.75%] train loss: 1.3603996194433421e-05 \n",
      "epoch: 15 [443289/888800 49.88%] train loss: 1.4371932593348902e-05 \n",
      "epoch: 15 [444400/888800 50.00%] train loss: 1.2880323083663825e-05 \n",
      "epoch: 15 [445511/888800 50.12%] train loss: 1.5428746337420307e-05 \n",
      "epoch: 15 [446622/888800 50.25%] train loss: 1.383055769110797e-05 \n",
      "epoch: 15 [447733/888800 50.38%] train loss: 1.4993319382483605e-05 \n",
      "epoch: 15 [448844/888800 50.50%] train loss: 1.4667836694570724e-05 \n",
      "epoch: 15 [449955/888800 50.62%] train loss: 1.4830900909146294e-05 \n",
      "epoch: 15 [451066/888800 50.75%] train loss: 1.5584550055791624e-05 \n",
      "epoch: 15 [452177/888800 50.88%] train loss: 1.3807961295242421e-05 \n",
      "epoch: 15 [453288/888800 51.00%] train loss: 1.6329031495843083e-05 \n",
      "epoch: 15 [454399/888800 51.12%] train loss: 1.4613638995797373e-05 \n",
      "epoch: 15 [455510/888800 51.25%] train loss: 1.5902031009318307e-05 \n",
      "epoch: 15 [456621/888800 51.38%] train loss: 1.590057581779547e-05 \n",
      "epoch: 15 [457732/888800 51.50%] train loss: 1.626189441594761e-05 \n",
      "epoch: 15 [458843/888800 51.62%] train loss: 1.5985089703463018e-05 \n",
      "epoch: 15 [459954/888800 51.75%] train loss: 1.3380395103013143e-05 \n",
      "epoch: 15 [461065/888800 51.88%] train loss: 1.4937983905838337e-05 \n",
      "epoch: 15 [462176/888800 52.00%] train loss: 1.4283665223047137e-05 \n",
      "epoch: 15 [463287/888800 52.12%] train loss: 1.7053924239007756e-05 \n",
      "epoch: 15 [464398/888800 52.25%] train loss: 1.4559149349224754e-05 \n",
      "epoch: 15 [465509/888800 52.38%] train loss: 1.5170936421782244e-05 \n",
      "epoch: 15 [466620/888800 52.50%] train loss: 1.4281980838859454e-05 \n",
      "epoch: 15 [467731/888800 52.62%] train loss: 1.4885866221447941e-05 \n",
      "epoch: 15 [468842/888800 52.75%] train loss: 1.4659054613730405e-05 \n",
      "epoch: 15 [469953/888800 52.88%] train loss: 1.3317841876414604e-05 \n",
      "epoch: 15 [471064/888800 53.00%] train loss: 1.4047765944269486e-05 \n",
      "epoch: 15 [472175/888800 53.12%] train loss: 1.3570883311331272e-05 \n",
      "epoch: 15 [473286/888800 53.25%] train loss: 1.3016479897487443e-05 \n",
      "epoch: 15 [474397/888800 53.38%] train loss: 1.2981036888959352e-05 \n",
      "epoch: 15 [475508/888800 53.50%] train loss: 1.5706518752267584e-05 \n",
      "epoch: 15 [476619/888800 53.62%] train loss: 1.5301284292945638e-05 \n",
      "epoch: 15 [477730/888800 53.75%] train loss: 1.4049498531676363e-05 \n",
      "epoch: 15 [478841/888800 53.88%] train loss: 1.3363879588723648e-05 \n",
      "epoch: 15 [479952/888800 54.00%] train loss: 1.4362922229338437e-05 \n",
      "epoch: 15 [481063/888800 54.12%] train loss: 1.2903170500067063e-05 \n",
      "epoch: 15 [482174/888800 54.25%] train loss: 1.57696249516448e-05 \n",
      "epoch: 15 [483285/888800 54.38%] train loss: 1.4324184121505823e-05 \n",
      "epoch: 15 [484396/888800 54.50%] train loss: 1.5242225344991311e-05 \n",
      "epoch: 15 [485507/888800 54.62%] train loss: 1.3241864508017898e-05 \n",
      "epoch: 15 [486618/888800 54.75%] train loss: 1.4357953659782652e-05 \n",
      "epoch: 15 [487729/888800 54.88%] train loss: 1.445207090000622e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [488840/888800 55.00%] train loss: 1.4644557268184144e-05 \n",
      "epoch: 15 [489951/888800 55.12%] train loss: 1.4621246918977704e-05 \n",
      "epoch: 15 [491062/888800 55.25%] train loss: 1.2599255569512025e-05 \n",
      "epoch: 15 [492173/888800 55.38%] train loss: 1.4125503184914123e-05 \n",
      "epoch: 15 [493284/888800 55.50%] train loss: 1.5097728464752436e-05 \n",
      "epoch: 15 [494395/888800 55.62%] train loss: 1.3626020518131554e-05 \n",
      "epoch: 15 [495506/888800 55.75%] train loss: 1.3797131941828411e-05 \n",
      "epoch: 15 [496617/888800 55.88%] train loss: 1.4514734175463673e-05 \n",
      "epoch: 15 [497728/888800 56.00%] train loss: 1.5563415217911825e-05 \n",
      "epoch: 15 [498839/888800 56.12%] train loss: 1.3318913261173293e-05 \n",
      "epoch: 15 [499950/888800 56.25%] train loss: 1.5286917914636433e-05 \n",
      "epoch: 15 [501061/888800 56.38%] train loss: 1.3737667359237093e-05 \n",
      "epoch: 15 [502172/888800 56.50%] train loss: 1.3779264918412082e-05 \n",
      "epoch: 15 [503283/888800 56.62%] train loss: 1.377764783683233e-05 \n",
      "epoch: 15 [504394/888800 56.75%] train loss: 1.3387802937359083e-05 \n",
      "epoch: 15 [505505/888800 56.88%] train loss: 1.3689231309399474e-05 \n",
      "epoch: 15 [506616/888800 57.00%] train loss: 1.4149130947771482e-05 \n",
      "epoch: 15 [507727/888800 57.12%] train loss: 1.34582451210008e-05 \n",
      "epoch: 15 [508838/888800 57.25%] train loss: 1.5036354852782097e-05 \n",
      "epoch: 15 [509949/888800 57.38%] train loss: 1.3853754353476688e-05 \n",
      "epoch: 15 [511060/888800 57.50%] train loss: 1.3745453543378972e-05 \n",
      "epoch: 15 [512171/888800 57.62%] train loss: 1.4054923667572439e-05 \n",
      "epoch: 15 [513282/888800 57.75%] train loss: 1.4214208931662142e-05 \n",
      "epoch: 15 [514393/888800 57.88%] train loss: 1.371075904899044e-05 \n",
      "epoch: 15 [515504/888800 58.00%] train loss: 1.4320019545266405e-05 \n",
      "epoch: 15 [516615/888800 58.12%] train loss: 1.3583733561972622e-05 \n",
      "epoch: 15 [517726/888800 58.25%] train loss: 1.4563326658389997e-05 \n",
      "epoch: 15 [518837/888800 58.38%] train loss: 1.484833046561107e-05 \n",
      "epoch: 15 [519948/888800 58.50%] train loss: 1.4147137335385196e-05 \n",
      "epoch: 15 [521059/888800 58.62%] train loss: 1.4299411304818932e-05 \n",
      "epoch: 15 [522170/888800 58.75%] train loss: 1.4545572412316687e-05 \n",
      "epoch: 15 [523281/888800 58.88%] train loss: 1.4867006939311977e-05 \n",
      "epoch: 15 [524392/888800 59.00%] train loss: 1.3689779734704643e-05 \n",
      "epoch: 15 [525503/888800 59.12%] train loss: 1.412499386788113e-05 \n",
      "epoch: 15 [526614/888800 59.25%] train loss: 1.4776389434700832e-05 \n",
      "epoch: 15 [527725/888800 59.38%] train loss: 1.3419037713902071e-05 \n",
      "epoch: 15 [528836/888800 59.50%] train loss: 1.4998428014223464e-05 \n",
      "epoch: 15 [529947/888800 59.62%] train loss: 1.4715740690007806e-05 \n",
      "epoch: 15 [531058/888800 59.75%] train loss: 1.3698388102056924e-05 \n",
      "epoch: 15 [532169/888800 59.88%] train loss: 1.4240573364077136e-05 \n",
      "epoch: 15 [533280/888800 60.00%] train loss: 1.3421806215774268e-05 \n",
      "epoch: 15 [534391/888800 60.12%] train loss: 1.3341174053493887e-05 \n",
      "epoch: 15 [535502/888800 60.25%] train loss: 1.3306950677360874e-05 \n",
      "epoch: 15 [536613/888800 60.38%] train loss: 1.422115383320488e-05 \n",
      "epoch: 15 [537724/888800 60.50%] train loss: 1.356452139589237e-05 \n",
      "epoch: 15 [538835/888800 60.62%] train loss: 1.3138967005943414e-05 \n",
      "epoch: 15 [539946/888800 60.75%] train loss: 1.3758344721281901e-05 \n",
      "epoch: 15 [541057/888800 60.88%] train loss: 1.3968609891890083e-05 \n",
      "epoch: 15 [542168/888800 61.00%] train loss: 1.4513116184389219e-05 \n",
      "epoch: 15 [543279/888800 61.12%] train loss: 1.353926109004533e-05 \n",
      "epoch: 15 [544390/888800 61.25%] train loss: 1.4424645996768959e-05 \n",
      "epoch: 15 [545501/888800 61.38%] train loss: 1.581059768795967e-05 \n",
      "epoch: 15 [546612/888800 61.50%] train loss: 1.4213791473594029e-05 \n",
      "epoch: 15 [547723/888800 61.62%] train loss: 1.5456165783689357e-05 \n",
      "epoch: 15 [548834/888800 61.75%] train loss: 1.3885587577533443e-05 \n",
      "epoch: 15 [549945/888800 61.88%] train loss: 1.5515077393501997e-05 \n",
      "epoch: 15 [551056/888800 62.00%] train loss: 1.4209105756890494e-05 \n",
      "epoch: 15 [552167/888800 62.12%] train loss: 1.3345327715796884e-05 \n",
      "epoch: 15 [553278/888800 62.25%] train loss: 1.3706028767046519e-05 \n",
      "epoch: 15 [554389/888800 62.38%] train loss: 1.3836772268405184e-05 \n",
      "epoch: 15 [555500/888800 62.50%] train loss: 1.5042950508359354e-05 \n",
      "epoch: 15 [556611/888800 62.62%] train loss: 1.4523961908707861e-05 \n",
      "epoch: 15 [557722/888800 62.75%] train loss: 1.5408153558382764e-05 \n",
      "epoch: 15 [558833/888800 62.88%] train loss: 1.3473589206114411e-05 \n",
      "epoch: 15 [559944/888800 63.00%] train loss: 1.558911390020512e-05 \n",
      "epoch: 15 [561055/888800 63.12%] train loss: 1.3114631656208076e-05 \n",
      "epoch: 15 [562166/888800 63.25%] train loss: 1.6472578863613307e-05 \n",
      "epoch: 15 [563277/888800 63.38%] train loss: 1.5219859960780013e-05 \n",
      "epoch: 15 [564388/888800 63.50%] train loss: 1.6350993973901495e-05 \n",
      "epoch: 15 [565499/888800 63.62%] train loss: 1.4655991435574833e-05 \n",
      "epoch: 15 [566610/888800 63.75%] train loss: 1.3955698705103714e-05 \n",
      "epoch: 15 [567721/888800 63.88%] train loss: 1.4610151083616074e-05 \n",
      "epoch: 15 [568832/888800 64.00%] train loss: 1.413279642292764e-05 \n",
      "epoch: 15 [569943/888800 64.12%] train loss: 1.5300769518944435e-05 \n",
      "epoch: 15 [571054/888800 64.25%] train loss: 1.4998950973676983e-05 \n",
      "epoch: 15 [572165/888800 64.38%] train loss: 1.3821470929542556e-05 \n",
      "epoch: 15 [573276/888800 64.50%] train loss: 1.4114365512796212e-05 \n",
      "epoch: 15 [574387/888800 64.62%] train loss: 1.4377203115145676e-05 \n",
      "epoch: 15 [575498/888800 64.75%] train loss: 1.450851050321944e-05 \n",
      "epoch: 15 [576609/888800 64.88%] train loss: 1.3804859918309376e-05 \n",
      "epoch: 15 [577720/888800 65.00%] train loss: 1.4840926269243937e-05 \n",
      "epoch: 15 [578831/888800 65.12%] train loss: 1.4727786037838086e-05 \n",
      "epoch: 15 [579942/888800 65.25%] train loss: 1.3095373105898034e-05 \n",
      "epoch: 15 [581053/888800 65.38%] train loss: 1.6083371519926004e-05 \n",
      "epoch: 15 [582164/888800 65.50%] train loss: 1.45321382660768e-05 \n",
      "epoch: 15 [583275/888800 65.62%] train loss: 1.5083817743288819e-05 \n",
      "epoch: 15 [584386/888800 65.75%] train loss: 1.5287278074538335e-05 \n",
      "epoch: 15 [585497/888800 65.88%] train loss: 1.3405131539911963e-05 \n",
      "epoch: 15 [586608/888800 66.00%] train loss: 1.5256385268003214e-05 \n",
      "epoch: 15 [587719/888800 66.12%] train loss: 1.3798307918477803e-05 \n",
      "epoch: 15 [588830/888800 66.25%] train loss: 1.541574420116376e-05 \n",
      "epoch: 15 [589941/888800 66.38%] train loss: 1.4405639376491308e-05 \n",
      "epoch: 15 [591052/888800 66.50%] train loss: 1.4688616829516832e-05 \n",
      "epoch: 15 [592163/888800 66.62%] train loss: 1.4123390428721905e-05 \n",
      "epoch: 15 [593274/888800 66.75%] train loss: 1.512846938567236e-05 \n",
      "epoch: 15 [594385/888800 66.88%] train loss: 1.4437837307923473e-05 \n",
      "epoch: 15 [595496/888800 67.00%] train loss: 1.457973849028349e-05 \n",
      "epoch: 15 [596607/888800 67.12%] train loss: 1.4533685316564515e-05 \n",
      "epoch: 15 [597718/888800 67.25%] train loss: 1.4455984455707949e-05 \n",
      "epoch: 15 [598829/888800 67.38%] train loss: 1.4987886061135214e-05 \n",
      "epoch: 15 [599940/888800 67.50%] train loss: 1.5361378245870583e-05 \n",
      "epoch: 15 [601051/888800 67.62%] train loss: 1.4213061149348505e-05 \n",
      "epoch: 15 [602162/888800 67.75%] train loss: 1.53274777403567e-05 \n",
      "epoch: 15 [603273/888800 67.88%] train loss: 1.4019079571880866e-05 \n",
      "epoch: 15 [604384/888800 68.00%] train loss: 1.3820907042827457e-05 \n",
      "epoch: 15 [605495/888800 68.12%] train loss: 1.4231741261028219e-05 \n",
      "epoch: 15 [606606/888800 68.25%] train loss: 1.2928786418342497e-05 \n",
      "epoch: 15 [607717/888800 68.38%] train loss: 1.3902267710363958e-05 \n",
      "epoch: 15 [608828/888800 68.50%] train loss: 1.5622254068148322e-05 \n",
      "epoch: 15 [609939/888800 68.62%] train loss: 1.4055203791940585e-05 \n",
      "epoch: 15 [611050/888800 68.75%] train loss: 1.490897102485178e-05 \n",
      "epoch: 15 [612161/888800 68.88%] train loss: 1.3670172847923823e-05 \n",
      "epoch: 15 [613272/888800 69.00%] train loss: 1.4330429621622898e-05 \n",
      "epoch: 15 [614383/888800 69.12%] train loss: 1.3717190086026676e-05 \n",
      "epoch: 15 [615494/888800 69.25%] train loss: 1.4006634955876507e-05 \n",
      "epoch: 15 [616605/888800 69.38%] train loss: 1.4855805602564942e-05 \n",
      "epoch: 15 [617716/888800 69.50%] train loss: 1.4365128663484938e-05 \n",
      "epoch: 15 [618827/888800 69.62%] train loss: 1.4401821317733265e-05 \n",
      "epoch: 15 [619938/888800 69.75%] train loss: 1.5098346921149641e-05 \n",
      "epoch: 15 [621049/888800 69.88%] train loss: 1.447588874725625e-05 \n",
      "epoch: 15 [622160/888800 70.00%] train loss: 1.3972766282677185e-05 \n",
      "epoch: 15 [623271/888800 70.12%] train loss: 1.3788368050882127e-05 \n",
      "epoch: 15 [624382/888800 70.25%] train loss: 1.4792954061704222e-05 \n",
      "epoch: 15 [625493/888800 70.38%] train loss: 1.3521889741241466e-05 \n",
      "epoch: 15 [626604/888800 70.50%] train loss: 1.3527872397389729e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [627715/888800 70.62%] train loss: 1.4741519407834858e-05 \n",
      "epoch: 15 [628826/888800 70.75%] train loss: 1.372374299535295e-05 \n",
      "epoch: 15 [629937/888800 70.88%] train loss: 1.4043660485185683e-05 \n",
      "epoch: 15 [631048/888800 71.00%] train loss: 1.4558692782884464e-05 \n",
      "epoch: 15 [632159/888800 71.12%] train loss: 1.3460357877193019e-05 \n",
      "epoch: 15 [633270/888800 71.25%] train loss: 1.4876504792482592e-05 \n",
      "epoch: 15 [634381/888800 71.38%] train loss: 1.4710882169310935e-05 \n",
      "epoch: 15 [635492/888800 71.50%] train loss: 1.4713314158143476e-05 \n",
      "epoch: 15 [636603/888800 71.62%] train loss: 1.5273315511876717e-05 \n",
      "epoch: 15 [637714/888800 71.75%] train loss: 1.4426126654143445e-05 \n",
      "epoch: 15 [638825/888800 71.88%] train loss: 1.4841615666227881e-05 \n",
      "epoch: 15 [639936/888800 72.00%] train loss: 1.5384739526780322e-05 \n",
      "epoch: 15 [641047/888800 72.12%] train loss: 1.4259246199799236e-05 \n",
      "epoch: 15 [642158/888800 72.25%] train loss: 1.3609055713459384e-05 \n",
      "epoch: 15 [643269/888800 72.38%] train loss: 1.4191397895046975e-05 \n",
      "epoch: 15 [644380/888800 72.50%] train loss: 1.520799833087949e-05 \n",
      "epoch: 15 [645491/888800 72.62%] train loss: 1.3869021131540649e-05 \n",
      "epoch: 15 [646602/888800 72.75%] train loss: 1.3114242392475717e-05 \n",
      "epoch: 15 [647713/888800 72.88%] train loss: 1.3591464266937692e-05 \n",
      "epoch: 15 [648824/888800 73.00%] train loss: 1.424637230229564e-05 \n",
      "epoch: 15 [649935/888800 73.12%] train loss: 1.4000323062646203e-05 \n",
      "epoch: 15 [651046/888800 73.25%] train loss: 1.5060924852150492e-05 \n",
      "epoch: 15 [652157/888800 73.38%] train loss: 1.4380204447661527e-05 \n",
      "epoch: 15 [653268/888800 73.50%] train loss: 1.4409875802812167e-05 \n",
      "epoch: 15 [654379/888800 73.62%] train loss: 1.3746169315709267e-05 \n",
      "epoch: 15 [655490/888800 73.75%] train loss: 1.3629405657411553e-05 \n",
      "epoch: 15 [656601/888800 73.88%] train loss: 1.2953989426023327e-05 \n",
      "epoch: 15 [657712/888800 74.00%] train loss: 1.3205218237999361e-05 \n",
      "epoch: 15 [658823/888800 74.12%] train loss: 1.4491993169940542e-05 \n",
      "epoch: 15 [659934/888800 74.25%] train loss: 1.3988973478262778e-05 \n",
      "epoch: 15 [661045/888800 74.38%] train loss: 1.5580368199152872e-05 \n",
      "epoch: 15 [662156/888800 74.50%] train loss: 1.4311221093521453e-05 \n",
      "epoch: 15 [663267/888800 74.62%] train loss: 1.5000064195191953e-05 \n",
      "epoch: 15 [664378/888800 74.75%] train loss: 1.4809752428845968e-05 \n",
      "epoch: 15 [665489/888800 74.88%] train loss: 1.3163949915906414e-05 \n",
      "epoch: 15 [666600/888800 75.00%] train loss: 1.3730860700889025e-05 \n",
      "epoch: 15 [667711/888800 75.12%] train loss: 1.4487335647572763e-05 \n",
      "epoch: 15 [668822/888800 75.25%] train loss: 1.5066548257891554e-05 \n",
      "epoch: 15 [669933/888800 75.38%] train loss: 1.3779903383692726e-05 \n",
      "epoch: 15 [671044/888800 75.50%] train loss: 1.5051901755214203e-05 \n",
      "epoch: 15 [672155/888800 75.62%] train loss: 1.3142271200194955e-05 \n",
      "epoch: 15 [673266/888800 75.75%] train loss: 1.6420148313045502e-05 \n",
      "epoch: 15 [674377/888800 75.88%] train loss: 1.474383952881908e-05 \n",
      "epoch: 15 [675488/888800 76.00%] train loss: 1.4411555639526341e-05 \n",
      "epoch: 15 [676599/888800 76.12%] train loss: 1.4832215128990356e-05 \n",
      "epoch: 15 [677710/888800 76.25%] train loss: 1.4480869140243158e-05 \n",
      "epoch: 15 [678821/888800 76.38%] train loss: 1.4805164028075524e-05 \n",
      "epoch: 15 [679932/888800 76.50%] train loss: 1.4248930710891727e-05 \n",
      "epoch: 15 [681043/888800 76.62%] train loss: 1.33224048113334e-05 \n",
      "epoch: 15 [682154/888800 76.75%] train loss: 1.4639631444879342e-05 \n",
      "epoch: 15 [683265/888800 76.88%] train loss: 1.5662564692320302e-05 \n",
      "epoch: 15 [684376/888800 77.00%] train loss: 1.3460748959914781e-05 \n",
      "epoch: 15 [685487/888800 77.12%] train loss: 1.468954451411264e-05 \n",
      "epoch: 15 [686598/888800 77.25%] train loss: 1.4283848031482194e-05 \n",
      "epoch: 15 [687709/888800 77.38%] train loss: 1.4732289855601266e-05 \n",
      "epoch: 15 [688820/888800 77.50%] train loss: 1.3445883269014303e-05 \n",
      "epoch: 15 [689931/888800 77.62%] train loss: 1.4253417248255573e-05 \n",
      "epoch: 15 [691042/888800 77.75%] train loss: 1.4642885616922285e-05 \n",
      "epoch: 15 [692153/888800 77.88%] train loss: 1.5037179764476605e-05 \n",
      "epoch: 15 [693264/888800 78.00%] train loss: 1.3636113180837128e-05 \n",
      "epoch: 15 [694375/888800 78.12%] train loss: 1.4627355994889513e-05 \n",
      "epoch: 15 [695486/888800 78.25%] train loss: 1.2204121958347969e-05 \n",
      "epoch: 15 [696597/888800 78.38%] train loss: 1.5392601198982447e-05 \n",
      "epoch: 15 [697708/888800 78.50%] train loss: 1.4731954252056312e-05 \n",
      "epoch: 15 [698819/888800 78.62%] train loss: 1.4488786291622091e-05 \n",
      "epoch: 15 [699930/888800 78.75%] train loss: 1.5062246347952168e-05 \n",
      "epoch: 15 [701041/888800 78.88%] train loss: 1.361062368232524e-05 \n",
      "epoch: 15 [702152/888800 79.00%] train loss: 1.4611628103011753e-05 \n",
      "epoch: 15 [703263/888800 79.12%] train loss: 1.3468721590470523e-05 \n",
      "epoch: 15 [704374/888800 79.25%] train loss: 1.4414429642783944e-05 \n",
      "epoch: 15 [705485/888800 79.38%] train loss: 1.3781733287032694e-05 \n",
      "epoch: 15 [706596/888800 79.50%] train loss: 1.5085112863744143e-05 \n",
      "epoch: 15 [707707/888800 79.62%] train loss: 1.3451605809677858e-05 \n",
      "epoch: 15 [708818/888800 79.75%] train loss: 1.5685685866628774e-05 \n",
      "epoch: 15 [709929/888800 79.88%] train loss: 1.4384722817339934e-05 \n",
      "epoch: 15 [711040/888800 80.00%] train loss: 1.2982900443603285e-05 \n",
      "epoch: 15 [712151/888800 80.12%] train loss: 1.533726572233718e-05 \n",
      "epoch: 15 [713262/888800 80.25%] train loss: 1.3714905435335822e-05 \n",
      "epoch: 15 [714373/888800 80.38%] train loss: 1.4429172551899683e-05 \n",
      "epoch: 15 [715484/888800 80.50%] train loss: 1.3698819202545565e-05 \n",
      "epoch: 15 [716595/888800 80.62%] train loss: 1.4436974197451491e-05 \n",
      "epoch: 15 [717706/888800 80.75%] train loss: 1.3720720744458959e-05 \n",
      "epoch: 15 [718817/888800 80.88%] train loss: 1.4391032891580835e-05 \n",
      "epoch: 15 [719928/888800 81.00%] train loss: 1.4920679859642405e-05 \n",
      "epoch: 15 [721039/888800 81.12%] train loss: 1.5836250895517878e-05 \n",
      "epoch: 15 [722150/888800 81.25%] train loss: 1.4119128536549397e-05 \n",
      "epoch: 15 [723261/888800 81.38%] train loss: 1.439949483028613e-05 \n",
      "epoch: 15 [724372/888800 81.50%] train loss: 1.4342051144922152e-05 \n",
      "epoch: 15 [725483/888800 81.62%] train loss: 1.3677469723916147e-05 \n",
      "epoch: 15 [726594/888800 81.75%] train loss: 1.3636643416248262e-05 \n",
      "epoch: 15 [727705/888800 81.88%] train loss: 1.3759215107711498e-05 \n",
      "epoch: 15 [728816/888800 82.00%] train loss: 1.4415921214094851e-05 \n",
      "epoch: 15 [729927/888800 82.12%] train loss: 1.4345327144837938e-05 \n",
      "epoch: 15 [731038/888800 82.25%] train loss: 1.4332863429444842e-05 \n",
      "epoch: 15 [732149/888800 82.38%] train loss: 1.4955567166907713e-05 \n",
      "epoch: 15 [733260/888800 82.50%] train loss: 1.4812168956268579e-05 \n",
      "epoch: 15 [734371/888800 82.62%] train loss: 1.3829614545102231e-05 \n",
      "epoch: 15 [735482/888800 82.75%] train loss: 1.4201980775396805e-05 \n",
      "epoch: 15 [736593/888800 82.88%] train loss: 1.3939540622232016e-05 \n",
      "epoch: 15 [737704/888800 83.00%] train loss: 1.4853580978524406e-05 \n",
      "epoch: 15 [738815/888800 83.12%] train loss: 1.392983176629059e-05 \n",
      "epoch: 15 [739926/888800 83.25%] train loss: 1.2905876246804837e-05 \n",
      "epoch: 15 [741037/888800 83.38%] train loss: 1.4364203707373235e-05 \n",
      "epoch: 15 [742148/888800 83.50%] train loss: 1.5052090930112172e-05 \n",
      "epoch: 15 [743259/888800 83.62%] train loss: 1.6105794202303514e-05 \n",
      "epoch: 15 [744370/888800 83.75%] train loss: 1.4137265679892153e-05 \n",
      "epoch: 15 [745481/888800 83.88%] train loss: 1.4559851479134522e-05 \n",
      "epoch: 15 [746592/888800 84.00%] train loss: 1.5065013940329663e-05 \n",
      "epoch: 15 [747703/888800 84.12%] train loss: 1.4119016668701079e-05 \n",
      "epoch: 15 [748814/888800 84.25%] train loss: 1.4766519598197192e-05 \n",
      "epoch: 15 [749925/888800 84.38%] train loss: 1.4413020835490897e-05 \n",
      "epoch: 15 [751036/888800 84.50%] train loss: 1.2993695236218628e-05 \n",
      "epoch: 15 [752147/888800 84.62%] train loss: 1.3390356798481662e-05 \n",
      "epoch: 15 [753258/888800 84.75%] train loss: 1.3946147191745695e-05 \n",
      "epoch: 15 [754369/888800 84.88%] train loss: 1.3475426385411993e-05 \n",
      "epoch: 15 [755480/888800 85.00%] train loss: 1.4229988664737903e-05 \n",
      "epoch: 15 [756591/888800 85.12%] train loss: 1.3820889762428124e-05 \n",
      "epoch: 15 [757702/888800 85.25%] train loss: 1.4277136870077811e-05 \n",
      "epoch: 15 [758813/888800 85.38%] train loss: 1.4193919923854992e-05 \n",
      "epoch: 15 [759924/888800 85.50%] train loss: 1.4534694855683483e-05 \n",
      "epoch: 15 [761035/888800 85.62%] train loss: 1.60084218805423e-05 \n",
      "epoch: 15 [762146/888800 85.75%] train loss: 1.3034617040830199e-05 \n",
      "epoch: 15 [763257/888800 85.88%] train loss: 1.564058220537845e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 [764368/888800 86.00%] train loss: 1.399184202455217e-05 \n",
      "epoch: 15 [765479/888800 86.12%] train loss: 1.4481127436738461e-05 \n",
      "epoch: 15 [766590/888800 86.25%] train loss: 1.4283033124229405e-05 \n",
      "epoch: 15 [767701/888800 86.38%] train loss: 1.415570113749709e-05 \n",
      "epoch: 15 [768812/888800 86.50%] train loss: 1.2731015885947272e-05 \n",
      "epoch: 15 [769923/888800 86.62%] train loss: 1.5148868442338426e-05 \n",
      "epoch: 15 [771034/888800 86.75%] train loss: 1.3106372534821276e-05 \n",
      "epoch: 15 [772145/888800 86.88%] train loss: 1.3769946235697716e-05 \n",
      "epoch: 15 [773256/888800 87.00%] train loss: 1.4268354789237492e-05 \n",
      "epoch: 15 [774367/888800 87.12%] train loss: 1.4677865692647174e-05 \n",
      "epoch: 15 [775478/888800 87.25%] train loss: 1.4254506822908297e-05 \n",
      "epoch: 15 [776589/888800 87.38%] train loss: 1.4280808500188868e-05 \n",
      "epoch: 15 [777700/888800 87.50%] train loss: 1.4717730664415285e-05 \n",
      "epoch: 15 [778811/888800 87.62%] train loss: 1.3714406122744549e-05 \n",
      "epoch: 15 [779922/888800 87.75%] train loss: 1.543877624499146e-05 \n",
      "epoch: 15 [781033/888800 87.88%] train loss: 1.4088510397414211e-05 \n",
      "epoch: 15 [782144/888800 88.00%] train loss: 1.5254260688379873e-05 \n",
      "epoch: 15 [783255/888800 88.12%] train loss: 1.400706241838634e-05 \n",
      "epoch: 15 [784366/888800 88.25%] train loss: 1.3994290384289343e-05 \n",
      "epoch: 15 [785477/888800 88.38%] train loss: 1.4321681192086544e-05 \n",
      "epoch: 15 [786588/888800 88.50%] train loss: 1.38562227220973e-05 \n",
      "epoch: 15 [787699/888800 88.62%] train loss: 1.5118643204914406e-05 \n",
      "epoch: 15 [788810/888800 88.75%] train loss: 1.4760734302399214e-05 \n",
      "epoch: 15 [789921/888800 88.88%] train loss: 1.558486110297963e-05 \n",
      "epoch: 15 [791032/888800 89.00%] train loss: 1.510327638243325e-05 \n",
      "epoch: 15 [792143/888800 89.12%] train loss: 1.597433401911985e-05 \n",
      "epoch: 15 [793254/888800 89.25%] train loss: 1.4441812709264923e-05 \n",
      "epoch: 15 [794365/888800 89.38%] train loss: 1.3696021596842911e-05 \n",
      "epoch: 15 [795476/888800 89.50%] train loss: 1.4319007277663331e-05 \n",
      "epoch: 15 [796587/888800 89.62%] train loss: 1.3446571756503545e-05 \n",
      "epoch: 15 [797698/888800 89.75%] train loss: 1.4186086445988622e-05 \n",
      "epoch: 15 [798809/888800 89.88%] train loss: 1.3427425074041821e-05 \n",
      "epoch: 15 [799920/888800 90.00%] train loss: 1.5457304471055977e-05 \n",
      "epoch: 15 [801031/888800 90.12%] train loss: 1.4437421668844763e-05 \n",
      "epoch: 15 [802142/888800 90.25%] train loss: 1.496422009950038e-05 \n",
      "epoch: 15 [803253/888800 90.38%] train loss: 1.351995251752669e-05 \n",
      "epoch: 15 [804364/888800 90.50%] train loss: 1.663717375777196e-05 \n",
      "epoch: 15 [805475/888800 90.62%] train loss: 1.5023014384496491e-05 \n",
      "epoch: 15 [806586/888800 90.75%] train loss: 1.570613676449284e-05 \n",
      "epoch: 15 [807697/888800 90.88%] train loss: 1.3753367056779098e-05 \n",
      "epoch: 15 [808808/888800 91.00%] train loss: 1.609466562513262e-05 \n",
      "epoch: 15 [809919/888800 91.12%] train loss: 1.4533818102790974e-05 \n",
      "epoch: 15 [811030/888800 91.25%] train loss: 1.2870716091128998e-05 \n",
      "epoch: 15 [812141/888800 91.38%] train loss: 1.4015328815730754e-05 \n",
      "epoch: 15 [813252/888800 91.50%] train loss: 1.4069788448978215e-05 \n",
      "epoch: 15 [814363/888800 91.62%] train loss: 1.4415133591683116e-05 \n",
      "epoch: 15 [815474/888800 91.75%] train loss: 1.440804135199869e-05 \n",
      "epoch: 15 [816585/888800 91.88%] train loss: 1.4718065358465537e-05 \n",
      "epoch: 15 [817696/888800 92.00%] train loss: 1.3472462342178915e-05 \n",
      "epoch: 15 [818807/888800 92.12%] train loss: 1.427447932655923e-05 \n",
      "epoch: 15 [819918/888800 92.25%] train loss: 1.4022169125382788e-05 \n",
      "epoch: 15 [821029/888800 92.38%] train loss: 1.3845102330378722e-05 \n",
      "epoch: 15 [822140/888800 92.50%] train loss: 1.4748057765245903e-05 \n",
      "epoch: 15 [823251/888800 92.62%] train loss: 1.3172144463169388e-05 \n",
      "epoch: 15 [824362/888800 92.75%] train loss: 1.5153349522734061e-05 \n",
      "epoch: 15 [825473/888800 92.88%] train loss: 1.4775294403079897e-05 \n",
      "epoch: 15 [826584/888800 93.00%] train loss: 1.4370339158631396e-05 \n",
      "epoch: 15 [827695/888800 93.12%] train loss: 1.4628591998189222e-05 \n",
      "epoch: 15 [828806/888800 93.25%] train loss: 1.3390224921749905e-05 \n",
      "epoch: 15 [829917/888800 93.38%] train loss: 1.3836844118486624e-05 \n",
      "epoch: 15 [831028/888800 93.50%] train loss: 1.4199517863744404e-05 \n",
      "epoch: 15 [832139/888800 93.62%] train loss: 1.3645488252223004e-05 \n",
      "epoch: 15 [833250/888800 93.75%] train loss: 1.4067729352973402e-05 \n",
      "epoch: 15 [834361/888800 93.88%] train loss: 1.393685488437768e-05 \n",
      "epoch: 15 [835472/888800 94.00%] train loss: 1.4480586287390906e-05 \n",
      "epoch: 15 [836583/888800 94.12%] train loss: 1.5740648450446315e-05 \n",
      "epoch: 15 [837694/888800 94.25%] train loss: 1.5012623407528736e-05 \n",
      "epoch: 15 [838805/888800 94.38%] train loss: 1.4165787433739752e-05 \n",
      "epoch: 15 [839916/888800 94.50%] train loss: 1.5665353203075938e-05 \n",
      "epoch: 15 [841027/888800 94.62%] train loss: 1.4504525097436272e-05 \n",
      "epoch: 15 [842138/888800 94.75%] train loss: 1.527549284219276e-05 \n",
      "epoch: 15 [843249/888800 94.88%] train loss: 1.486644396209158e-05 \n",
      "epoch: 15 [844360/888800 95.00%] train loss: 1.4011145140102599e-05 \n",
      "epoch: 15 [845471/888800 95.12%] train loss: 1.4121781532594468e-05 \n",
      "epoch: 15 [846582/888800 95.25%] train loss: 1.5405199519591406e-05 \n",
      "epoch: 15 [847693/888800 95.38%] train loss: 1.5634612282156013e-05 \n",
      "epoch: 15 [848804/888800 95.50%] train loss: 1.3734268577536568e-05 \n",
      "epoch: 15 [849915/888800 95.62%] train loss: 1.4787870895816013e-05 \n",
      "epoch: 15 [851026/888800 95.75%] train loss: 1.4419470971915871e-05 \n",
      "epoch: 15 [852137/888800 95.88%] train loss: 1.5314552001655102e-05 \n",
      "epoch: 15 [853248/888800 96.00%] train loss: 1.4766588719794527e-05 \n",
      "epoch: 15 [854359/888800 96.12%] train loss: 1.3717939509660937e-05 \n",
      "epoch: 15 [855470/888800 96.25%] train loss: 1.438824983779341e-05 \n",
      "epoch: 15 [856581/888800 96.38%] train loss: 1.3232840501586907e-05 \n",
      "epoch: 15 [857692/888800 96.50%] train loss: 1.4397700397239532e-05 \n",
      "epoch: 15 [858803/888800 96.62%] train loss: 1.3815779311698861e-05 \n",
      "epoch: 15 [859914/888800 96.75%] train loss: 1.5559762687189505e-05 \n",
      "epoch: 15 [861025/888800 96.88%] train loss: 1.4531237866322044e-05 \n",
      "epoch: 15 [862136/888800 97.00%] train loss: 1.4912837286829017e-05 \n",
      "epoch: 15 [863247/888800 97.12%] train loss: 1.458660790376598e-05 \n",
      "epoch: 15 [864358/888800 97.25%] train loss: 1.4537608876707964e-05 \n",
      "epoch: 15 [865469/888800 97.38%] train loss: 1.448416878702119e-05 \n",
      "epoch: 15 [866580/888800 97.50%] train loss: 1.3672431123268325e-05 \n",
      "epoch: 15 [867691/888800 97.62%] train loss: 1.587189944984857e-05 \n",
      "epoch: 15 [868802/888800 97.75%] train loss: 1.4772954273212235e-05 \n",
      "epoch: 15 [869913/888800 97.88%] train loss: 1.4142805412120651e-05 \n",
      "epoch: 15 [871024/888800 98.00%] train loss: 1.4078472304390743e-05 \n",
      "epoch: 15 [872135/888800 98.12%] train loss: 1.4091619959799573e-05 \n",
      "epoch: 15 [873246/888800 98.25%] train loss: 1.4826288861513603e-05 \n",
      "epoch: 15 [874357/888800 98.38%] train loss: 1.390969646308804e-05 \n",
      "epoch: 15 [875468/888800 98.50%] train loss: 1.4757114513486158e-05 \n",
      "epoch: 15 [876579/888800 98.62%] train loss: 1.4278401067713276e-05 \n",
      "epoch: 15 [877690/888800 98.75%] train loss: 1.3566645975515712e-05 \n",
      "epoch: 15 [878801/888800 98.88%] train loss: 1.4426496818487067e-05 \n",
      "epoch: 15 [879912/888800 99.00%] train loss: 1.4672373254143167e-05 \n",
      "epoch: 15 [881023/888800 99.12%] train loss: 1.5475899999728426e-05 \n",
      "epoch: 15 [882134/888800 99.25%] train loss: 1.3470116755343042e-05 \n",
      "epoch: 15 [883245/888800 99.38%] train loss: 1.3068550288153347e-05 \n",
      "epoch: 15 [884356/888800 99.50%] train loss: 1.4232550711312797e-05 \n",
      "epoch: 15 [885467/888800 99.62%] train loss: 1.3188798220653553e-05 \n",
      "epoch: 15 [886578/888800 99.75%] train loss: 1.4360554814629722e-05 \n",
      "epoch: 15 [887689/888800 99.88%] train loss: 1.2573615094879642e-05 \n",
      "epoch: 16 [0/888800 0.00%] train loss: 1.4578024092770647e-05 \n",
      "epoch: 16 [1111/888800 0.12%] train loss: 1.4985357665864285e-05 \n",
      "epoch: 16 [2222/888800 0.25%] train loss: 1.5282850654330105e-05 \n",
      "epoch: 16 [3333/888800 0.38%] train loss: 1.5120574971660972e-05 \n",
      "epoch: 16 [4444/888800 0.50%] train loss: 1.3387997569225263e-05 \n",
      "epoch: 16 [5555/888800 0.62%] train loss: 1.3698424481844995e-05 \n",
      "epoch: 16 [6666/888800 0.75%] train loss: 1.451396292395657e-05 \n",
      "epoch: 16 [7777/888800 0.88%] train loss: 1.5449506463482976e-05 \n",
      "epoch: 16 [8888/888800 1.00%] train loss: 1.3540508916776162e-05 \n",
      "epoch: 16 [9999/888800 1.12%] train loss: 1.3027250133745838e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [11110/888800 1.25%] train loss: 1.5108496882021427e-05 \n",
      "epoch: 16 [12221/888800 1.38%] train loss: 1.3111533917253837e-05 \n",
      "epoch: 16 [13332/888800 1.50%] train loss: 1.3302560546435416e-05 \n",
      "epoch: 16 [14443/888800 1.62%] train loss: 1.445209636585787e-05 \n",
      "epoch: 16 [15554/888800 1.75%] train loss: 1.3215146282163914e-05 \n",
      "epoch: 16 [16665/888800 1.88%] train loss: 1.4504548744298518e-05 \n",
      "epoch: 16 [17776/888800 2.00%] train loss: 1.3460468835546635e-05 \n",
      "epoch: 16 [18887/888800 2.12%] train loss: 1.4116798411123455e-05 \n",
      "epoch: 16 [19998/888800 2.25%] train loss: 1.3843097804056015e-05 \n",
      "epoch: 16 [21109/888800 2.38%] train loss: 1.536535273771733e-05 \n",
      "epoch: 16 [22220/888800 2.50%] train loss: 1.3543330169341061e-05 \n",
      "epoch: 16 [23331/888800 2.62%] train loss: 1.4713079508510418e-05 \n",
      "epoch: 16 [24442/888800 2.75%] train loss: 1.4818544514128007e-05 \n",
      "epoch: 16 [25553/888800 2.88%] train loss: 1.447781778551871e-05 \n",
      "epoch: 16 [26664/888800 3.00%] train loss: 1.4555406778526958e-05 \n",
      "epoch: 16 [27775/888800 3.12%] train loss: 1.443525525246514e-05 \n",
      "epoch: 16 [28886/888800 3.25%] train loss: 1.618805981706828e-05 \n",
      "epoch: 16 [29997/888800 3.38%] train loss: 1.4321208254841622e-05 \n",
      "epoch: 16 [31108/888800 3.50%] train loss: 1.505223372078035e-05 \n",
      "epoch: 16 [32219/888800 3.62%] train loss: 1.5525327398790978e-05 \n",
      "epoch: 16 [33330/888800 3.75%] train loss: 1.3083305020700209e-05 \n",
      "epoch: 16 [34441/888800 3.88%] train loss: 1.4359552551468369e-05 \n",
      "epoch: 16 [35552/888800 4.00%] train loss: 1.3355264854908455e-05 \n",
      "epoch: 16 [36663/888800 4.12%] train loss: 1.535922274342738e-05 \n",
      "epoch: 16 [37774/888800 4.25%] train loss: 1.4258886039897334e-05 \n",
      "epoch: 16 [38885/888800 4.38%] train loss: 1.5339997844421305e-05 \n",
      "epoch: 16 [39996/888800 4.50%] train loss: 1.363290812150808e-05 \n",
      "epoch: 16 [41107/888800 4.62%] train loss: 1.4377483239513822e-05 \n",
      "epoch: 16 [42218/888800 4.75%] train loss: 1.4624628420278896e-05 \n",
      "epoch: 16 [43329/888800 4.88%] train loss: 1.5494493709411472e-05 \n",
      "epoch: 16 [44440/888800 5.00%] train loss: 1.2265603800187819e-05 \n",
      "epoch: 16 [45551/888800 5.12%] train loss: 1.4640750123362523e-05 \n",
      "epoch: 16 [46662/888800 5.25%] train loss: 1.3101624972478021e-05 \n",
      "epoch: 16 [47773/888800 5.38%] train loss: 1.3980240510136355e-05 \n",
      "epoch: 16 [48884/888800 5.50%] train loss: 1.3627482985612005e-05 \n",
      "epoch: 16 [49995/888800 5.62%] train loss: 1.4374374586623162e-05 \n",
      "epoch: 16 [51106/888800 5.75%] train loss: 1.5077420357556548e-05 \n",
      "epoch: 16 [52217/888800 5.88%] train loss: 1.4290770195657387e-05 \n",
      "epoch: 16 [53328/888800 6.00%] train loss: 1.5023858395579737e-05 \n",
      "epoch: 16 [54439/888800 6.12%] train loss: 1.4289787941379473e-05 \n",
      "epoch: 16 [55550/888800 6.25%] train loss: 1.3657742783834692e-05 \n",
      "epoch: 16 [56661/888800 6.38%] train loss: 1.4523451682180166e-05 \n",
      "epoch: 16 [57772/888800 6.50%] train loss: 1.4389594980457332e-05 \n",
      "epoch: 16 [58883/888800 6.62%] train loss: 1.5078917385835666e-05 \n",
      "epoch: 16 [59994/888800 6.75%] train loss: 1.409710785083007e-05 \n",
      "epoch: 16 [61105/888800 6.88%] train loss: 1.387121756124543e-05 \n",
      "epoch: 16 [62216/888800 7.00%] train loss: 1.447489921702072e-05 \n",
      "epoch: 16 [63327/888800 7.12%] train loss: 1.372034694213653e-05 \n",
      "epoch: 16 [64438/888800 7.25%] train loss: 1.3617011973110493e-05 \n",
      "epoch: 16 [65549/888800 7.38%] train loss: 1.3339582437765785e-05 \n",
      "epoch: 16 [66660/888800 7.50%] train loss: 1.2788474123226479e-05 \n",
      "epoch: 16 [67771/888800 7.62%] train loss: 1.4463029401667882e-05 \n",
      "epoch: 16 [68882/888800 7.75%] train loss: 1.4802359146415256e-05 \n",
      "epoch: 16 [69993/888800 7.88%] train loss: 1.4565445781045128e-05 \n",
      "epoch: 16 [71104/888800 8.00%] train loss: 1.336246441496769e-05 \n",
      "epoch: 16 [72215/888800 8.12%] train loss: 1.3143889191269409e-05 \n",
      "epoch: 16 [73326/888800 8.25%] train loss: 1.3520688298740424e-05 \n",
      "epoch: 16 [74437/888800 8.38%] train loss: 1.3124831639288459e-05 \n",
      "epoch: 16 [75548/888800 8.50%] train loss: 1.512858216301538e-05 \n",
      "epoch: 16 [76659/888800 8.62%] train loss: 1.4772956092201639e-05 \n",
      "epoch: 16 [77770/888800 8.75%] train loss: 1.3535541256715078e-05 \n",
      "epoch: 16 [78881/888800 8.88%] train loss: 1.3771794328931719e-05 \n",
      "epoch: 16 [79992/888800 9.00%] train loss: 1.4110709344095085e-05 \n",
      "epoch: 16 [81103/888800 9.12%] train loss: 1.5579405953758396e-05 \n",
      "epoch: 16 [82214/888800 9.25%] train loss: 1.5820234693819657e-05 \n",
      "epoch: 16 [83325/888800 9.38%] train loss: 1.4250026652007364e-05 \n",
      "epoch: 16 [84436/888800 9.50%] train loss: 1.556835741212126e-05 \n",
      "epoch: 16 [85547/888800 9.62%] train loss: 1.3491026948031504e-05 \n",
      "epoch: 16 [86658/888800 9.75%] train loss: 1.5485626136069186e-05 \n",
      "epoch: 16 [87769/888800 9.88%] train loss: 1.442214306734968e-05 \n",
      "epoch: 16 [88880/888800 10.00%] train loss: 1.5163590433076024e-05 \n",
      "epoch: 16 [89991/888800 10.12%] train loss: 1.4243601071939338e-05 \n",
      "epoch: 16 [91102/888800 10.25%] train loss: 1.3494170161720831e-05 \n",
      "epoch: 16 [92213/888800 10.38%] train loss: 1.4465007552644238e-05 \n",
      "epoch: 16 [93324/888800 10.50%] train loss: 1.3377270988712553e-05 \n",
      "epoch: 16 [94435/888800 10.62%] train loss: 1.4208602806320414e-05 \n",
      "epoch: 16 [95546/888800 10.75%] train loss: 1.3927826330473181e-05 \n",
      "epoch: 16 [96657/888800 10.88%] train loss: 1.3974090506962966e-05 \n",
      "epoch: 16 [97768/888800 11.00%] train loss: 1.483101641497342e-05 \n",
      "epoch: 16 [98879/888800 11.12%] train loss: 1.4639698747487273e-05 \n",
      "epoch: 16 [99990/888800 11.25%] train loss: 1.3674894034920726e-05 \n",
      "epoch: 16 [101101/888800 11.38%] train loss: 1.415875885868445e-05 \n",
      "epoch: 16 [102212/888800 11.50%] train loss: 1.3900579688197467e-05 \n",
      "epoch: 16 [103323/888800 11.62%] train loss: 1.3068133739579935e-05 \n",
      "epoch: 16 [104434/888800 11.75%] train loss: 1.4781587196921464e-05 \n",
      "epoch: 16 [105545/888800 11.88%] train loss: 1.4586791621695738e-05 \n",
      "epoch: 16 [106656/888800 12.00%] train loss: 1.3439588656183332e-05 \n",
      "epoch: 16 [107767/888800 12.12%] train loss: 1.5089578482729848e-05 \n",
      "epoch: 16 [108878/888800 12.25%] train loss: 1.3291341019794345e-05 \n",
      "epoch: 16 [109989/888800 12.38%] train loss: 1.4447690773522481e-05 \n",
      "epoch: 16 [111100/888800 12.50%] train loss: 1.3800554370391183e-05 \n",
      "epoch: 16 [112211/888800 12.62%] train loss: 1.4394981008081231e-05 \n",
      "epoch: 16 [113322/888800 12.75%] train loss: 1.3093782399664633e-05 \n",
      "epoch: 16 [114433/888800 12.88%] train loss: 1.42389135362464e-05 \n",
      "epoch: 16 [115544/888800 13.00%] train loss: 1.3968872735858895e-05 \n",
      "epoch: 16 [116655/888800 13.12%] train loss: 1.4943685528123751e-05 \n",
      "epoch: 16 [117766/888800 13.25%] train loss: 1.4188813111104537e-05 \n",
      "epoch: 16 [118877/888800 13.38%] train loss: 1.4490682588075288e-05 \n",
      "epoch: 16 [119988/888800 13.50%] train loss: 1.490658542024903e-05 \n",
      "epoch: 16 [121099/888800 13.62%] train loss: 1.380516005156096e-05 \n",
      "epoch: 16 [122210/888800 13.75%] train loss: 1.4394042409549002e-05 \n",
      "epoch: 16 [123321/888800 13.88%] train loss: 1.4251509128371254e-05 \n",
      "epoch: 16 [124432/888800 14.00%] train loss: 1.508788682258455e-05 \n",
      "epoch: 16 [125543/888800 14.12%] train loss: 1.4423208085645456e-05 \n",
      "epoch: 16 [126654/888800 14.25%] train loss: 1.3620177014672663e-05 \n",
      "epoch: 16 [127765/888800 14.38%] train loss: 1.576272006786894e-05 \n",
      "epoch: 16 [128876/888800 14.50%] train loss: 1.4612396626034752e-05 \n",
      "epoch: 16 [129987/888800 14.62%] train loss: 1.4757712960999925e-05 \n",
      "epoch: 16 [131098/888800 14.75%] train loss: 1.4383983398147393e-05 \n",
      "epoch: 16 [132209/888800 14.88%] train loss: 1.4013348845764995e-05 \n",
      "epoch: 16 [133320/888800 15.00%] train loss: 1.4748002286069095e-05 \n",
      "epoch: 16 [134431/888800 15.12%] train loss: 1.307556976826163e-05 \n",
      "epoch: 16 [135542/888800 15.25%] train loss: 1.3735504580836277e-05 \n",
      "epoch: 16 [136653/888800 15.38%] train loss: 1.286370479647303e-05 \n",
      "epoch: 16 [137764/888800 15.50%] train loss: 1.540801349619869e-05 \n",
      "epoch: 16 [138875/888800 15.62%] train loss: 1.5114358575374354e-05 \n",
      "epoch: 16 [139986/888800 15.75%] train loss: 1.5928393622743897e-05 \n",
      "epoch: 16 [141097/888800 15.88%] train loss: 1.3940792996436357e-05 \n",
      "epoch: 16 [142208/888800 16.00%] train loss: 1.3694283552467823e-05 \n",
      "epoch: 16 [143319/888800 16.12%] train loss: 1.4226650819182396e-05 \n",
      "epoch: 16 [144430/888800 16.25%] train loss: 1.5099468328116927e-05 \n",
      "epoch: 16 [145541/888800 16.38%] train loss: 1.5379882825072855e-05 \n",
      "epoch: 16 [146652/888800 16.50%] train loss: 1.4545898011419922e-05 \n",
      "epoch: 16 [147763/888800 16.62%] train loss: 1.328077632933855e-05 \n",
      "epoch: 16 [148874/888800 16.75%] train loss: 1.5460427675861865e-05 \n",
      "epoch: 16 [149985/888800 16.88%] train loss: 1.424146284989547e-05 \n",
      "epoch: 16 [151096/888800 17.00%] train loss: 1.4946289411454927e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [152207/888800 17.12%] train loss: 1.4847891179670114e-05 \n",
      "epoch: 16 [153318/888800 17.25%] train loss: 1.502273153164424e-05 \n",
      "epoch: 16 [154429/888800 17.38%] train loss: 1.482010065956274e-05 \n",
      "epoch: 16 [155540/888800 17.50%] train loss: 1.4290801118477248e-05 \n",
      "epoch: 16 [156651/888800 17.62%] train loss: 1.3490714991348796e-05 \n",
      "epoch: 16 [157762/888800 17.75%] train loss: 1.4412759810511488e-05 \n",
      "epoch: 16 [158873/888800 17.88%] train loss: 1.5106458704394754e-05 \n",
      "epoch: 16 [159984/888800 18.00%] train loss: 1.394134869769914e-05 \n",
      "epoch: 16 [161095/888800 18.12%] train loss: 1.4179082427290268e-05 \n",
      "epoch: 16 [162206/888800 18.25%] train loss: 1.3255984413262922e-05 \n",
      "epoch: 16 [163317/888800 18.38%] train loss: 1.4378397281689104e-05 \n",
      "epoch: 16 [164428/888800 18.50%] train loss: 1.3397897419054061e-05 \n",
      "epoch: 16 [165539/888800 18.62%] train loss: 1.5165880540735088e-05 \n",
      "epoch: 16 [166650/888800 18.75%] train loss: 1.4896799257257953e-05 \n",
      "epoch: 16 [167761/888800 18.88%] train loss: 1.364759464195231e-05 \n",
      "epoch: 16 [168872/888800 19.00%] train loss: 1.5214555787679274e-05 \n",
      "epoch: 16 [169983/888800 19.12%] train loss: 1.3548733477364294e-05 \n",
      "epoch: 16 [171094/888800 19.25%] train loss: 1.5196317690424621e-05 \n",
      "epoch: 16 [172205/888800 19.38%] train loss: 1.3326690350368153e-05 \n",
      "epoch: 16 [173316/888800 19.50%] train loss: 1.3306334039953072e-05 \n",
      "epoch: 16 [174427/888800 19.62%] train loss: 1.3364548067329451e-05 \n",
      "epoch: 16 [175538/888800 19.75%] train loss: 1.4953428035369143e-05 \n",
      "epoch: 16 [176649/888800 19.88%] train loss: 1.3727668374485802e-05 \n",
      "epoch: 16 [177760/888800 20.00%] train loss: 1.471075120207388e-05 \n",
      "epoch: 16 [178871/888800 20.12%] train loss: 1.392964168189792e-05 \n",
      "epoch: 16 [179982/888800 20.25%] train loss: 1.388200053042965e-05 \n",
      "epoch: 16 [181093/888800 20.38%] train loss: 1.3388701518124435e-05 \n",
      "epoch: 16 [182204/888800 20.50%] train loss: 1.451660500606522e-05 \n",
      "epoch: 16 [183315/888800 20.62%] train loss: 1.4233831279852893e-05 \n",
      "epoch: 16 [184426/888800 20.75%] train loss: 1.4139113773126155e-05 \n",
      "epoch: 16 [185537/888800 20.88%] train loss: 1.4527871826430783e-05 \n",
      "epoch: 16 [186648/888800 21.00%] train loss: 1.4250397725845687e-05 \n",
      "epoch: 16 [187759/888800 21.12%] train loss: 1.4498877135338262e-05 \n",
      "epoch: 16 [188870/888800 21.25%] train loss: 1.3845851754012983e-05 \n",
      "epoch: 16 [189981/888800 21.38%] train loss: 1.5393743524327874e-05 \n",
      "epoch: 16 [191092/888800 21.50%] train loss: 1.4638969332736451e-05 \n",
      "epoch: 16 [192203/888800 21.62%] train loss: 1.3867148481949698e-05 \n",
      "epoch: 16 [193314/888800 21.75%] train loss: 1.4612983250117395e-05 \n",
      "epoch: 16 [194425/888800 21.88%] train loss: 1.4740601727680769e-05 \n",
      "epoch: 16 [195536/888800 22.00%] train loss: 1.5207877368084155e-05 \n",
      "epoch: 16 [196647/888800 22.12%] train loss: 1.454859557270538e-05 \n",
      "epoch: 16 [197758/888800 22.25%] train loss: 1.4614567589887884e-05 \n",
      "epoch: 16 [198869/888800 22.38%] train loss: 1.542201243864838e-05 \n",
      "epoch: 16 [199980/888800 22.50%] train loss: 1.3452583516482264e-05 \n",
      "epoch: 16 [201091/888800 22.62%] train loss: 1.5289708244381472e-05 \n",
      "epoch: 16 [202202/888800 22.75%] train loss: 1.5964466001605615e-05 \n",
      "epoch: 16 [203313/888800 22.88%] train loss: 1.5082872778293677e-05 \n",
      "epoch: 16 [204424/888800 23.00%] train loss: 1.4986578207754064e-05 \n",
      "epoch: 16 [205535/888800 23.12%] train loss: 1.5050731235533021e-05 \n",
      "epoch: 16 [206646/888800 23.25%] train loss: 1.4357012332766317e-05 \n",
      "epoch: 16 [207757/888800 23.38%] train loss: 1.517998316558078e-05 \n",
      "epoch: 16 [208868/888800 23.50%] train loss: 1.4190831279847771e-05 \n",
      "epoch: 16 [209979/888800 23.62%] train loss: 1.4713985365233384e-05 \n",
      "epoch: 16 [211090/888800 23.75%] train loss: 1.5062495549500454e-05 \n",
      "epoch: 16 [212201/888800 23.88%] train loss: 1.3987688362249173e-05 \n",
      "epoch: 16 [213312/888800 24.00%] train loss: 1.578997034812346e-05 \n",
      "epoch: 16 [214423/888800 24.12%] train loss: 1.4302114323072601e-05 \n",
      "epoch: 16 [215534/888800 24.25%] train loss: 1.3699142982659396e-05 \n",
      "epoch: 16 [216645/888800 24.38%] train loss: 1.5636440366506577e-05 \n",
      "epoch: 16 [217756/888800 24.50%] train loss: 1.4325092706712894e-05 \n",
      "epoch: 16 [218867/888800 24.62%] train loss: 1.5678637282690033e-05 \n",
      "epoch: 16 [219978/888800 24.75%] train loss: 1.5224076378217433e-05 \n",
      "epoch: 16 [221089/888800 24.88%] train loss: 1.3937763469584752e-05 \n",
      "epoch: 16 [222200/888800 25.00%] train loss: 1.5114116649783682e-05 \n",
      "epoch: 16 [223311/888800 25.12%] train loss: 1.463828175474191e-05 \n",
      "epoch: 16 [224422/888800 25.25%] train loss: 1.4960840417188592e-05 \n",
      "epoch: 16 [225533/888800 25.38%] train loss: 1.3298937119543552e-05 \n",
      "epoch: 16 [226644/888800 25.50%] train loss: 1.3753149687545374e-05 \n",
      "epoch: 16 [227755/888800 25.62%] train loss: 1.403576425218489e-05 \n",
      "epoch: 16 [228866/888800 25.75%] train loss: 1.4712886695633642e-05 \n",
      "epoch: 16 [229977/888800 25.88%] train loss: 1.3631673027703073e-05 \n",
      "epoch: 16 [231088/888800 26.00%] train loss: 1.4670387827209197e-05 \n",
      "epoch: 16 [232199/888800 26.12%] train loss: 1.375543524773093e-05 \n",
      "epoch: 16 [233310/888800 26.25%] train loss: 1.4868624930386432e-05 \n",
      "epoch: 16 [234421/888800 26.38%] train loss: 1.4536364687955938e-05 \n",
      "epoch: 16 [235532/888800 26.50%] train loss: 1.4703590750286821e-05 \n",
      "epoch: 16 [236643/888800 26.62%] train loss: 1.4271024156187195e-05 \n",
      "epoch: 16 [237754/888800 26.75%] train loss: 1.2595023690664675e-05 \n",
      "epoch: 16 [238865/888800 26.88%] train loss: 1.4336254025693052e-05 \n",
      "epoch: 16 [239976/888800 27.00%] train loss: 1.623232128622476e-05 \n",
      "epoch: 16 [241087/888800 27.12%] train loss: 1.538600008643698e-05 \n",
      "epoch: 16 [242198/888800 27.25%] train loss: 1.3991991181683261e-05 \n",
      "epoch: 16 [243309/888800 27.38%] train loss: 1.394483660988044e-05 \n",
      "epoch: 16 [244420/888800 27.50%] train loss: 1.277431147173047e-05 \n",
      "epoch: 16 [245531/888800 27.62%] train loss: 1.4165775610308629e-05 \n",
      "epoch: 16 [246642/888800 27.75%] train loss: 1.4026987628312781e-05 \n",
      "epoch: 16 [247753/888800 27.88%] train loss: 1.3826627764501609e-05 \n",
      "epoch: 16 [248864/888800 28.00%] train loss: 1.4903247574693523e-05 \n",
      "epoch: 16 [249975/888800 28.12%] train loss: 1.4344136616273317e-05 \n",
      "epoch: 16 [251086/888800 28.25%] train loss: 1.4213644135452341e-05 \n",
      "epoch: 16 [252197/888800 28.38%] train loss: 1.5166069715633057e-05 \n",
      "epoch: 16 [253308/888800 28.50%] train loss: 1.3610709174827207e-05 \n",
      "epoch: 16 [254419/888800 28.62%] train loss: 1.409567084920127e-05 \n",
      "epoch: 16 [255530/888800 28.75%] train loss: 1.45302919918322e-05 \n",
      "epoch: 16 [256641/888800 28.88%] train loss: 1.409092601534212e-05 \n",
      "epoch: 16 [257752/888800 29.00%] train loss: 1.3682414646609686e-05 \n",
      "epoch: 16 [258863/888800 29.12%] train loss: 1.3884261534258258e-05 \n",
      "epoch: 16 [259974/888800 29.25%] train loss: 1.4204279068508185e-05 \n",
      "epoch: 16 [261085/888800 29.38%] train loss: 1.5344065104727633e-05 \n",
      "epoch: 16 [262196/888800 29.50%] train loss: 1.4717629710503388e-05 \n",
      "epoch: 16 [263307/888800 29.62%] train loss: 1.4405520232685376e-05 \n",
      "epoch: 16 [264418/888800 29.75%] train loss: 1.522587535873754e-05 \n",
      "epoch: 16 [265529/888800 29.88%] train loss: 1.3916415809944738e-05 \n",
      "epoch: 16 [266640/888800 30.00%] train loss: 1.4292542800831143e-05 \n",
      "epoch: 16 [267751/888800 30.12%] train loss: 1.319882085226709e-05 \n",
      "epoch: 16 [268862/888800 30.25%] train loss: 1.4775923773413524e-05 \n",
      "epoch: 16 [269973/888800 30.38%] train loss: 1.5047769011289347e-05 \n",
      "epoch: 16 [271084/888800 30.50%] train loss: 1.3716593457502313e-05 \n",
      "epoch: 16 [272195/888800 30.62%] train loss: 1.4185165127855726e-05 \n",
      "epoch: 16 [273306/888800 30.75%] train loss: 1.4226426173991058e-05 \n",
      "epoch: 16 [274417/888800 30.88%] train loss: 1.4498186828859616e-05 \n",
      "epoch: 16 [275528/888800 31.00%] train loss: 1.436638649465749e-05 \n",
      "epoch: 16 [276639/888800 31.12%] train loss: 1.4102477507549338e-05 \n",
      "epoch: 16 [277750/888800 31.25%] train loss: 1.600639552634675e-05 \n",
      "epoch: 16 [278861/888800 31.38%] train loss: 1.4198981261870358e-05 \n",
      "epoch: 16 [279972/888800 31.50%] train loss: 1.4046209798834752e-05 \n",
      "epoch: 16 [281083/888800 31.62%] train loss: 1.4857920177746564e-05 \n",
      "epoch: 16 [282194/888800 31.75%] train loss: 1.452155538572697e-05 \n",
      "epoch: 16 [283305/888800 31.88%] train loss: 1.4112940334598534e-05 \n",
      "epoch: 16 [284416/888800 32.00%] train loss: 1.3651802873937413e-05 \n",
      "epoch: 16 [285527/888800 32.12%] train loss: 1.362918828817783e-05 \n",
      "epoch: 16 [286638/888800 32.25%] train loss: 1.3791427591058891e-05 \n",
      "epoch: 16 [287749/888800 32.38%] train loss: 1.386034182360163e-05 \n",
      "epoch: 16 [288860/888800 32.50%] train loss: 1.4338927940116264e-05 \n",
      "epoch: 16 [289971/888800 32.62%] train loss: 1.3706059689866379e-05 \n",
      "epoch: 16 [291082/888800 32.75%] train loss: 1.4084715985518415e-05 \n",
      "epoch: 16 [292193/888800 32.88%] train loss: 1.55251327669248e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [293304/888800 33.00%] train loss: 1.4306312550615985e-05 \n",
      "epoch: 16 [294415/888800 33.12%] train loss: 1.3370664419198874e-05 \n",
      "epoch: 16 [295526/888800 33.25%] train loss: 1.4095496226218529e-05 \n",
      "epoch: 16 [296637/888800 33.38%] train loss: 1.4461342288996093e-05 \n",
      "epoch: 16 [297748/888800 33.50%] train loss: 1.5251836884999648e-05 \n",
      "epoch: 16 [298859/888800 33.62%] train loss: 1.4789980923524126e-05 \n",
      "epoch: 16 [299970/888800 33.75%] train loss: 1.449138653697446e-05 \n",
      "epoch: 16 [301081/888800 33.88%] train loss: 1.4546149031957611e-05 \n",
      "epoch: 16 [302192/888800 34.00%] train loss: 1.6002566553652287e-05 \n",
      "epoch: 16 [303303/888800 34.12%] train loss: 1.4336850654217415e-05 \n",
      "epoch: 16 [304414/888800 34.25%] train loss: 1.4178472156345379e-05 \n",
      "epoch: 16 [305525/888800 34.38%] train loss: 1.308552691625664e-05 \n",
      "epoch: 16 [306636/888800 34.50%] train loss: 1.4216467207006644e-05 \n",
      "epoch: 16 [307747/888800 34.62%] train loss: 1.4689292584080249e-05 \n",
      "epoch: 16 [308858/888800 34.75%] train loss: 1.4942047528165858e-05 \n",
      "epoch: 16 [309969/888800 34.88%] train loss: 1.363278988719685e-05 \n",
      "epoch: 16 [311080/888800 35.00%] train loss: 1.4843814824416768e-05 \n",
      "epoch: 16 [312191/888800 35.12%] train loss: 1.464167235099012e-05 \n",
      "epoch: 16 [313302/888800 35.25%] train loss: 1.3541008229367435e-05 \n",
      "epoch: 16 [314413/888800 35.38%] train loss: 1.3987169040774461e-05 \n",
      "epoch: 16 [315524/888800 35.50%] train loss: 1.5136602996790316e-05 \n",
      "epoch: 16 [316635/888800 35.62%] train loss: 1.3679504263564013e-05 \n",
      "epoch: 16 [317746/888800 35.75%] train loss: 1.4899595953465905e-05 \n",
      "epoch: 16 [318857/888800 35.88%] train loss: 1.4186100088409148e-05 \n",
      "epoch: 16 [319968/888800 36.00%] train loss: 1.514065297669731e-05 \n",
      "epoch: 16 [321079/888800 36.12%] train loss: 1.4521188859362155e-05 \n",
      "epoch: 16 [322190/888800 36.25%] train loss: 1.3458924513543025e-05 \n",
      "epoch: 16 [323301/888800 36.38%] train loss: 1.4109888070379384e-05 \n",
      "epoch: 16 [324412/888800 36.50%] train loss: 1.4016767636348959e-05 \n",
      "epoch: 16 [325523/888800 36.62%] train loss: 1.55577090481529e-05 \n",
      "epoch: 16 [326634/888800 36.75%] train loss: 1.4714164535689633e-05 \n",
      "epoch: 16 [327745/888800 36.88%] train loss: 1.411237917636754e-05 \n",
      "epoch: 16 [328856/888800 37.00%] train loss: 1.4708043636346702e-05 \n",
      "epoch: 16 [329967/888800 37.12%] train loss: 1.4044061572349165e-05 \n",
      "epoch: 16 [331078/888800 37.25%] train loss: 1.522910770290764e-05 \n",
      "epoch: 16 [332189/888800 37.38%] train loss: 1.605341640242841e-05 \n",
      "epoch: 16 [333300/888800 37.50%] train loss: 1.3881802260584664e-05 \n",
      "epoch: 16 [334411/888800 37.62%] train loss: 1.5067568710946944e-05 \n",
      "epoch: 16 [335522/888800 37.75%] train loss: 1.3899812074669171e-05 \n",
      "epoch: 16 [336633/888800 37.88%] train loss: 1.583257835591212e-05 \n",
      "epoch: 16 [337744/888800 38.00%] train loss: 1.4725821529282257e-05 \n",
      "epoch: 16 [338855/888800 38.12%] train loss: 1.547943611512892e-05 \n",
      "epoch: 16 [339966/888800 38.25%] train loss: 1.6039193724282086e-05 \n",
      "epoch: 16 [341077/888800 38.38%] train loss: 1.5185742086032405e-05 \n",
      "epoch: 16 [342188/888800 38.50%] train loss: 1.5243754205584992e-05 \n",
      "epoch: 16 [343299/888800 38.62%] train loss: 1.5271996744559146e-05 \n",
      "epoch: 16 [344410/888800 38.75%] train loss: 1.4291155821410939e-05 \n",
      "epoch: 16 [345521/888800 38.88%] train loss: 1.4066629773878958e-05 \n",
      "epoch: 16 [346632/888800 39.00%] train loss: 1.507808792666765e-05 \n",
      "epoch: 16 [347743/888800 39.12%] train loss: 1.279350726690609e-05 \n",
      "epoch: 16 [348854/888800 39.25%] train loss: 1.3708377082366496e-05 \n",
      "epoch: 16 [349965/888800 39.38%] train loss: 1.3768951248493977e-05 \n",
      "epoch: 16 [351076/888800 39.50%] train loss: 1.316647194471443e-05 \n",
      "epoch: 16 [352187/888800 39.62%] train loss: 1.3836018297297414e-05 \n",
      "epoch: 16 [353298/888800 39.75%] train loss: 1.3818387742503546e-05 \n",
      "epoch: 16 [354409/888800 39.88%] train loss: 1.3447970559354872e-05 \n",
      "epoch: 16 [355520/888800 40.00%] train loss: 1.4338174878503196e-05 \n",
      "epoch: 16 [356631/888800 40.12%] train loss: 1.4591963918064721e-05 \n",
      "epoch: 16 [357742/888800 40.25%] train loss: 1.4500419638352469e-05 \n",
      "epoch: 16 [358853/888800 40.38%] train loss: 1.3701113857678138e-05 \n",
      "epoch: 16 [359964/888800 40.50%] train loss: 1.2440075806807727e-05 \n",
      "epoch: 16 [361075/888800 40.62%] train loss: 1.311678352067247e-05 \n",
      "epoch: 16 [362186/888800 40.75%] train loss: 1.4301688679552171e-05 \n",
      "epoch: 16 [363297/888800 40.88%] train loss: 1.3815457350574434e-05 \n",
      "epoch: 16 [364408/888800 41.00%] train loss: 1.459422583138803e-05 \n",
      "epoch: 16 [365519/888800 41.12%] train loss: 1.4329837540572044e-05 \n",
      "epoch: 16 [366630/888800 41.25%] train loss: 1.3769719771516975e-05 \n",
      "epoch: 16 [367741/888800 41.38%] train loss: 1.3784117982140742e-05 \n",
      "epoch: 16 [368852/888800 41.50%] train loss: 1.4206010746420361e-05 \n",
      "epoch: 16 [369963/888800 41.62%] train loss: 1.5055970834509935e-05 \n",
      "epoch: 16 [371074/888800 41.75%] train loss: 1.333294676442165e-05 \n",
      "epoch: 16 [372185/888800 41.88%] train loss: 1.4939366337785032e-05 \n",
      "epoch: 16 [373296/888800 42.00%] train loss: 1.3361307537707034e-05 \n",
      "epoch: 16 [374407/888800 42.12%] train loss: 1.3697433132620063e-05 \n",
      "epoch: 16 [375518/888800 42.25%] train loss: 1.4459506928687915e-05 \n",
      "epoch: 16 [376629/888800 42.38%] train loss: 1.4531631677527912e-05 \n",
      "epoch: 16 [377740/888800 42.50%] train loss: 1.4032005310582463e-05 \n",
      "epoch: 16 [378851/888800 42.62%] train loss: 1.4754604308109265e-05 \n",
      "epoch: 16 [379962/888800 42.75%] train loss: 1.3959175703348592e-05 \n",
      "epoch: 16 [381073/888800 42.88%] train loss: 1.4825785910943523e-05 \n",
      "epoch: 16 [382184/888800 43.00%] train loss: 1.625546246941667e-05 \n",
      "epoch: 16 [383295/888800 43.12%] train loss: 1.3949579624750186e-05 \n",
      "epoch: 16 [384406/888800 43.25%] train loss: 1.5200299458228983e-05 \n",
      "epoch: 16 [385517/888800 43.38%] train loss: 1.4450572052737698e-05 \n",
      "epoch: 16 [386628/888800 43.50%] train loss: 1.4421660125663038e-05 \n",
      "epoch: 16 [387739/888800 43.62%] train loss: 1.412855908711208e-05 \n",
      "epoch: 16 [388850/888800 43.75%] train loss: 1.523128230473958e-05 \n",
      "epoch: 16 [389961/888800 43.88%] train loss: 1.2905202311230823e-05 \n",
      "epoch: 16 [391072/888800 44.00%] train loss: 1.4072569683776237e-05 \n",
      "epoch: 16 [392183/888800 44.12%] train loss: 1.4729263057233766e-05 \n",
      "epoch: 16 [393294/888800 44.25%] train loss: 1.574355519551318e-05 \n",
      "epoch: 16 [394405/888800 44.38%] train loss: 1.3657729141414165e-05 \n",
      "epoch: 16 [395516/888800 44.50%] train loss: 1.49246789078461e-05 \n",
      "epoch: 16 [396627/888800 44.62%] train loss: 1.5022429579403251e-05 \n",
      "epoch: 16 [397738/888800 44.75%] train loss: 1.3208143172960263e-05 \n",
      "epoch: 16 [398849/888800 44.88%] train loss: 1.4628813005401753e-05 \n",
      "epoch: 16 [399960/888800 45.00%] train loss: 1.3182007933210116e-05 \n",
      "epoch: 16 [401071/888800 45.12%] train loss: 1.408105072187027e-05 \n",
      "epoch: 16 [402182/888800 45.25%] train loss: 1.5694062312832102e-05 \n",
      "epoch: 16 [403293/888800 45.38%] train loss: 1.3761452464677859e-05 \n",
      "epoch: 16 [404404/888800 45.50%] train loss: 1.565746970300097e-05 \n",
      "epoch: 16 [405515/888800 45.62%] train loss: 1.4183173334458843e-05 \n",
      "epoch: 16 [406626/888800 45.75%] train loss: 1.4638724678661674e-05 \n",
      "epoch: 16 [407737/888800 45.88%] train loss: 1.351386345049832e-05 \n",
      "epoch: 16 [408848/888800 46.00%] train loss: 1.5025745597085916e-05 \n",
      "epoch: 16 [409959/888800 46.12%] train loss: 1.4718500096932985e-05 \n",
      "epoch: 16 [411070/888800 46.25%] train loss: 1.524326125945663e-05 \n",
      "epoch: 16 [412181/888800 46.38%] train loss: 1.5606481611030176e-05 \n",
      "epoch: 16 [413292/888800 46.50%] train loss: 1.4555213965650182e-05 \n",
      "epoch: 16 [414403/888800 46.62%] train loss: 1.3451848644763231e-05 \n",
      "epoch: 16 [415514/888800 46.75%] train loss: 1.5473451639991254e-05 \n",
      "epoch: 16 [416625/888800 46.88%] train loss: 1.5259663996403106e-05 \n",
      "epoch: 16 [417736/888800 47.00%] train loss: 1.59498376888223e-05 \n",
      "epoch: 16 [418847/888800 47.12%] train loss: 1.5016412362456322e-05 \n",
      "epoch: 16 [419958/888800 47.25%] train loss: 1.4464524610957596e-05 \n",
      "epoch: 16 [421069/888800 47.38%] train loss: 1.4059683053346816e-05 \n",
      "epoch: 16 [422180/888800 47.50%] train loss: 1.4663342881249264e-05 \n",
      "epoch: 16 [423291/888800 47.62%] train loss: 1.2966404938197229e-05 \n",
      "epoch: 16 [424402/888800 47.75%] train loss: 1.2725418855552562e-05 \n",
      "epoch: 16 [425513/888800 47.88%] train loss: 1.5107357285160106e-05 \n",
      "epoch: 16 [426624/888800 48.00%] train loss: 1.443732253392227e-05 \n",
      "epoch: 16 [427735/888800 48.12%] train loss: 1.433070792700164e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [428846/888800 48.25%] train loss: 1.4964381080062594e-05 \n",
      "epoch: 16 [429957/888800 48.38%] train loss: 1.514833184046438e-05 \n",
      "epoch: 16 [431068/888800 48.50%] train loss: 1.3592155482911039e-05 \n",
      "epoch: 16 [432179/888800 48.62%] train loss: 1.403614896844374e-05 \n",
      "epoch: 16 [433290/888800 48.75%] train loss: 1.4262547665566672e-05 \n",
      "epoch: 16 [434401/888800 48.88%] train loss: 1.5051744412630796e-05 \n",
      "epoch: 16 [435512/888800 49.00%] train loss: 1.3004596439714078e-05 \n",
      "epoch: 16 [436623/888800 49.12%] train loss: 1.530814370198641e-05 \n",
      "epoch: 16 [437734/888800 49.25%] train loss: 1.327311747445492e-05 \n",
      "epoch: 16 [438845/888800 49.38%] train loss: 1.3772929378319532e-05 \n",
      "epoch: 16 [439956/888800 49.50%] train loss: 1.4144198758003768e-05 \n",
      "epoch: 16 [441067/888800 49.62%] train loss: 1.445928410248598e-05 \n",
      "epoch: 16 [442178/888800 49.75%] train loss: 1.3983861208544113e-05 \n",
      "epoch: 16 [443289/888800 49.88%] train loss: 1.2738768418785185e-05 \n",
      "epoch: 16 [444400/888800 50.00%] train loss: 1.4178472156345379e-05 \n",
      "epoch: 16 [445511/888800 50.12%] train loss: 1.468712343921652e-05 \n",
      "epoch: 16 [446622/888800 50.25%] train loss: 1.5299845472327434e-05 \n",
      "epoch: 16 [447733/888800 50.38%] train loss: 1.4149447451927699e-05 \n",
      "epoch: 16 [448844/888800 50.50%] train loss: 1.4159845704853069e-05 \n",
      "epoch: 16 [449955/888800 50.62%] train loss: 1.4462935723713599e-05 \n",
      "epoch: 16 [451066/888800 50.75%] train loss: 1.4977335922594648e-05 \n",
      "epoch: 16 [452177/888800 50.88%] train loss: 1.3550510630011559e-05 \n",
      "epoch: 16 [453288/888800 51.00%] train loss: 1.3261202184366994e-05 \n",
      "epoch: 16 [454399/888800 51.12%] train loss: 1.4352182915899903e-05 \n",
      "epoch: 16 [455510/888800 51.25%] train loss: 1.3241611668490805e-05 \n",
      "epoch: 16 [456621/888800 51.38%] train loss: 1.3464322364598047e-05 \n",
      "epoch: 16 [457732/888800 51.50%] train loss: 1.369254277960863e-05 \n",
      "epoch: 16 [458843/888800 51.62%] train loss: 1.418560896127019e-05 \n",
      "epoch: 16 [459954/888800 51.75%] train loss: 1.3444059732137248e-05 \n",
      "epoch: 16 [461065/888800 51.88%] train loss: 1.3290487913764082e-05 \n",
      "epoch: 16 [462176/888800 52.00%] train loss: 1.4034661944606341e-05 \n",
      "epoch: 16 [463287/888800 52.12%] train loss: 1.3992080312164035e-05 \n",
      "epoch: 16 [464398/888800 52.25%] train loss: 1.5367895684903488e-05 \n",
      "epoch: 16 [465509/888800 52.38%] train loss: 1.544333281344734e-05 \n",
      "epoch: 16 [466620/888800 52.50%] train loss: 1.4532943168887869e-05 \n",
      "epoch: 16 [467731/888800 52.62%] train loss: 1.3929240594734438e-05 \n",
      "epoch: 16 [468842/888800 52.75%] train loss: 1.441750100639183e-05 \n",
      "epoch: 16 [469953/888800 52.88%] train loss: 1.4600503163819667e-05 \n",
      "epoch: 16 [471064/888800 53.00%] train loss: 1.3279080121719744e-05 \n",
      "epoch: 16 [472175/888800 53.12%] train loss: 1.3697565918846522e-05 \n",
      "epoch: 16 [473286/888800 53.25%] train loss: 1.4811057553743012e-05 \n",
      "epoch: 16 [474397/888800 53.38%] train loss: 1.3140434020897374e-05 \n",
      "epoch: 16 [475508/888800 53.50%] train loss: 1.553130459797103e-05 \n",
      "epoch: 16 [476619/888800 53.62%] train loss: 1.4937562809791416e-05 \n",
      "epoch: 16 [477730/888800 53.75%] train loss: 1.4363935406436212e-05 \n",
      "epoch: 16 [478841/888800 53.88%] train loss: 1.3226082046458032e-05 \n",
      "epoch: 16 [479952/888800 54.00%] train loss: 1.4441195162362419e-05 \n",
      "epoch: 16 [481063/888800 54.12%] train loss: 1.3089582353131846e-05 \n",
      "epoch: 16 [482174/888800 54.25%] train loss: 1.5667834304622374e-05 \n",
      "epoch: 16 [483285/888800 54.38%] train loss: 1.4431801901082508e-05 \n",
      "epoch: 16 [484396/888800 54.50%] train loss: 1.280308515561046e-05 \n",
      "epoch: 16 [485507/888800 54.62%] train loss: 1.3906532331020571e-05 \n",
      "epoch: 16 [486618/888800 54.75%] train loss: 1.4041593203728553e-05 \n",
      "epoch: 16 [487729/888800 54.88%] train loss: 1.3279915947350673e-05 \n",
      "epoch: 16 [488840/888800 55.00%] train loss: 1.4340691450343002e-05 \n",
      "epoch: 16 [489951/888800 55.12%] train loss: 1.4388149793376215e-05 \n",
      "epoch: 16 [491062/888800 55.25%] train loss: 1.4164861568133347e-05 \n",
      "epoch: 16 [492173/888800 55.38%] train loss: 1.3022503480897285e-05 \n",
      "epoch: 16 [493284/888800 55.50%] train loss: 1.351155970041873e-05 \n",
      "epoch: 16 [494395/888800 55.62%] train loss: 1.3505038623407017e-05 \n",
      "epoch: 16 [495506/888800 55.75%] train loss: 1.3453695828502532e-05 \n",
      "epoch: 16 [496617/888800 55.88%] train loss: 1.3786939234705642e-05 \n",
      "epoch: 16 [497728/888800 56.00%] train loss: 1.4155365533952136e-05 \n",
      "epoch: 16 [498839/888800 56.12%] train loss: 1.4219303920981474e-05 \n",
      "epoch: 16 [499950/888800 56.25%] train loss: 1.3201938600104768e-05 \n",
      "epoch: 16 [501061/888800 56.38%] train loss: 1.2673713172262069e-05 \n",
      "epoch: 16 [502172/888800 56.50%] train loss: 1.3667574421560857e-05 \n",
      "epoch: 16 [503283/888800 56.62%] train loss: 1.3633231901621912e-05 \n",
      "epoch: 16 [504394/888800 56.75%] train loss: 1.4846744306851178e-05 \n",
      "epoch: 16 [505505/888800 56.88%] train loss: 1.4947417184885126e-05 \n",
      "epoch: 16 [506616/888800 57.00%] train loss: 1.4016966815688647e-05 \n",
      "epoch: 16 [507727/888800 57.12%] train loss: 1.3855187717126682e-05 \n",
      "epoch: 16 [508838/888800 57.25%] train loss: 1.4217847819963936e-05 \n",
      "epoch: 16 [509949/888800 57.38%] train loss: 1.3648747881234158e-05 \n",
      "epoch: 16 [511060/888800 57.50%] train loss: 1.509833055024501e-05 \n",
      "epoch: 16 [512171/888800 57.62%] train loss: 1.5719981092843227e-05 \n",
      "epoch: 16 [513282/888800 57.75%] train loss: 1.494321804784704e-05 \n",
      "epoch: 16 [514393/888800 57.88%] train loss: 1.284403151657898e-05 \n",
      "epoch: 16 [515504/888800 58.00%] train loss: 1.4613307939725928e-05 \n",
      "epoch: 16 [516615/888800 58.12%] train loss: 1.5465602700714953e-05 \n",
      "epoch: 16 [517726/888800 58.25%] train loss: 1.4565466699423268e-05 \n",
      "epoch: 16 [518837/888800 58.38%] train loss: 1.351495575363515e-05 \n",
      "epoch: 16 [519948/888800 58.50%] train loss: 1.5063853425090201e-05 \n",
      "epoch: 16 [521059/888800 58.62%] train loss: 1.4215144801710267e-05 \n",
      "epoch: 16 [522170/888800 58.75%] train loss: 1.4017175999470055e-05 \n",
      "epoch: 16 [523281/888800 58.88%] train loss: 1.2705994777206797e-05 \n",
      "epoch: 16 [524392/888800 59.00%] train loss: 1.6394556951127015e-05 \n",
      "epoch: 16 [525503/888800 59.12%] train loss: 1.3509176824300084e-05 \n",
      "epoch: 16 [526614/888800 59.25%] train loss: 1.4357346117321867e-05 \n",
      "epoch: 16 [527725/888800 59.38%] train loss: 1.4340128473122604e-05 \n",
      "epoch: 16 [528836/888800 59.50%] train loss: 1.4338010259962175e-05 \n",
      "epoch: 16 [529947/888800 59.62%] train loss: 1.5393698049592786e-05 \n",
      "epoch: 16 [531058/888800 59.75%] train loss: 1.2354742466413882e-05 \n",
      "epoch: 16 [532169/888800 59.88%] train loss: 1.3937679796072189e-05 \n",
      "epoch: 16 [533280/888800 60.00%] train loss: 1.4496169569611084e-05 \n",
      "epoch: 16 [534391/888800 60.12%] train loss: 1.2653448720811866e-05 \n",
      "epoch: 16 [535502/888800 60.25%] train loss: 1.4166354048938956e-05 \n",
      "epoch: 16 [536613/888800 60.38%] train loss: 1.289697229367448e-05 \n",
      "epoch: 16 [537724/888800 60.50%] train loss: 1.3362770914682187e-05 \n",
      "epoch: 16 [538835/888800 60.62%] train loss: 1.4059078239370137e-05 \n",
      "epoch: 16 [539946/888800 60.75%] train loss: 1.3667113307747059e-05 \n",
      "epoch: 16 [541057/888800 60.88%] train loss: 1.4085195289226249e-05 \n",
      "epoch: 16 [542168/888800 61.00%] train loss: 1.4537342394760344e-05 \n",
      "epoch: 16 [543279/888800 61.12%] train loss: 1.4580384231521748e-05 \n",
      "epoch: 16 [544390/888800 61.25%] train loss: 1.6007099475245923e-05 \n",
      "epoch: 16 [545501/888800 61.38%] train loss: 1.4626688425778411e-05 \n",
      "epoch: 16 [546612/888800 61.50%] train loss: 1.4036329957889393e-05 \n",
      "epoch: 16 [547723/888800 61.62%] train loss: 1.6369978766306303e-05 \n",
      "epoch: 16 [548834/888800 61.75%] train loss: 1.3914820556237828e-05 \n",
      "epoch: 16 [549945/888800 61.88%] train loss: 1.4170615941111464e-05 \n",
      "epoch: 16 [551056/888800 62.00%] train loss: 1.3887722161598504e-05 \n",
      "epoch: 16 [552167/888800 62.12%] train loss: 1.3569947441283148e-05 \n",
      "epoch: 16 [553278/888800 62.25%] train loss: 1.3491159734257963e-05 \n",
      "epoch: 16 [554389/888800 62.38%] train loss: 1.4139636732579675e-05 \n",
      "epoch: 16 [555500/888800 62.50%] train loss: 1.5149502360145561e-05 \n",
      "epoch: 16 [556611/888800 62.62%] train loss: 1.38722789415624e-05 \n",
      "epoch: 16 [557722/888800 62.75%] train loss: 1.4703316992381588e-05 \n",
      "epoch: 16 [558833/888800 62.88%] train loss: 1.5637479009456e-05 \n",
      "epoch: 16 [559944/888800 63.00%] train loss: 1.5807949239388108e-05 \n",
      "epoch: 16 [561055/888800 63.12%] train loss: 1.4845352779957466e-05 \n",
      "epoch: 16 [562166/888800 63.25%] train loss: 1.368607445328962e-05 \n",
      "epoch: 16 [563277/888800 63.38%] train loss: 1.4770475900149904e-05 \n",
      "epoch: 16 [564388/888800 63.50%] train loss: 1.4697987353429198e-05 \n",
      "epoch: 16 [565499/888800 63.62%] train loss: 1.412895380781265e-05 \n",
      "epoch: 16 [566610/888800 63.75%] train loss: 1.4135508536128327e-05 \n",
      "epoch: 16 [567721/888800 63.88%] train loss: 1.3698112525162287e-05 \n",
      "epoch: 16 [568832/888800 64.00%] train loss: 1.3452395251078997e-05 \n",
      "epoch: 16 [569943/888800 64.12%] train loss: 1.4031802493263967e-05 \n",
      "epoch: 16 [571054/888800 64.25%] train loss: 1.4090832337387837e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [572165/888800 64.38%] train loss: 1.386852454743348e-05 \n",
      "epoch: 16 [573276/888800 64.50%] train loss: 1.3719611160922796e-05 \n",
      "epoch: 16 [574387/888800 64.62%] train loss: 1.3760243746219203e-05 \n",
      "epoch: 16 [575498/888800 64.75%] train loss: 1.4238931726140436e-05 \n",
      "epoch: 16 [576609/888800 64.88%] train loss: 1.3087110346532427e-05 \n",
      "epoch: 16 [577720/888800 65.00%] train loss: 1.3455426596920006e-05 \n",
      "epoch: 16 [578831/888800 65.12%] train loss: 1.4785227904212661e-05 \n",
      "epoch: 16 [579942/888800 65.25%] train loss: 1.4970943084335886e-05 \n",
      "epoch: 16 [581053/888800 65.38%] train loss: 1.3821275388181675e-05 \n",
      "epoch: 16 [582164/888800 65.50%] train loss: 1.506632543168962e-05 \n",
      "epoch: 16 [583275/888800 65.62%] train loss: 1.3822865184920374e-05 \n",
      "epoch: 16 [584386/888800 65.75%] train loss: 1.3474940715241246e-05 \n",
      "epoch: 16 [585497/888800 65.88%] train loss: 1.3785314877168275e-05 \n",
      "epoch: 16 [586608/888800 66.00%] train loss: 1.5047222404973581e-05 \n",
      "epoch: 16 [587719/888800 66.12%] train loss: 1.4428639588004444e-05 \n",
      "epoch: 16 [588830/888800 66.25%] train loss: 1.3898522411182057e-05 \n",
      "epoch: 16 [589941/888800 66.38%] train loss: 1.4137019206827972e-05 \n",
      "epoch: 16 [591052/888800 66.50%] train loss: 1.3971490261610597e-05 \n",
      "epoch: 16 [592163/888800 66.62%] train loss: 1.3934410162619315e-05 \n",
      "epoch: 16 [593274/888800 66.75%] train loss: 1.3635261893796269e-05 \n",
      "epoch: 16 [594385/888800 66.88%] train loss: 1.620513285160996e-05 \n",
      "epoch: 16 [595496/888800 67.00%] train loss: 1.4310577171272598e-05 \n",
      "epoch: 16 [596607/888800 67.12%] train loss: 1.3260934792924672e-05 \n",
      "epoch: 16 [597718/888800 67.25%] train loss: 1.4165770153340418e-05 \n",
      "epoch: 16 [598829/888800 67.38%] train loss: 1.3210236829763744e-05 \n",
      "epoch: 16 [599940/888800 67.50%] train loss: 1.2845520359405782e-05 \n",
      "epoch: 16 [601051/888800 67.62%] train loss: 1.5252461707859766e-05 \n",
      "epoch: 16 [602162/888800 67.75%] train loss: 1.505345426267013e-05 \n",
      "epoch: 16 [603273/888800 67.88%] train loss: 1.4455998098128475e-05 \n",
      "epoch: 16 [604384/888800 68.00%] train loss: 1.4668447875010315e-05 \n",
      "epoch: 16 [605495/888800 68.12%] train loss: 1.4015079614182469e-05 \n",
      "epoch: 16 [606606/888800 68.25%] train loss: 1.3373370165936649e-05 \n",
      "epoch: 16 [607717/888800 68.38%] train loss: 1.4793867194384802e-05 \n",
      "epoch: 16 [608828/888800 68.50%] train loss: 1.4440059203479905e-05 \n",
      "epoch: 16 [609939/888800 68.62%] train loss: 1.4415592886507511e-05 \n",
      "epoch: 16 [611050/888800 68.75%] train loss: 1.4119070328888483e-05 \n",
      "epoch: 16 [612161/888800 68.88%] train loss: 1.3644735190609936e-05 \n",
      "epoch: 16 [613272/888800 69.00%] train loss: 1.3665337974089198e-05 \n",
      "epoch: 16 [614383/888800 69.12%] train loss: 1.4124419976724312e-05 \n",
      "epoch: 16 [615494/888800 69.25%] train loss: 1.4108130926615559e-05 \n",
      "epoch: 16 [616605/888800 69.38%] train loss: 1.4223787729861215e-05 \n",
      "epoch: 16 [617716/888800 69.50%] train loss: 1.4170256690704264e-05 \n",
      "epoch: 16 [618827/888800 69.62%] train loss: 1.4533748071698938e-05 \n",
      "epoch: 16 [619938/888800 69.75%] train loss: 1.3757760825683363e-05 \n",
      "epoch: 16 [621049/888800 69.88%] train loss: 1.4785340681555681e-05 \n",
      "epoch: 16 [622160/888800 70.00%] train loss: 1.3712696272705216e-05 \n",
      "epoch: 16 [623271/888800 70.12%] train loss: 1.3437367670121603e-05 \n",
      "epoch: 16 [624382/888800 70.25%] train loss: 1.4054964594834018e-05 \n",
      "epoch: 16 [625493/888800 70.38%] train loss: 1.3426560144580435e-05 \n",
      "epoch: 16 [626604/888800 70.50%] train loss: 1.4634570106863976e-05 \n",
      "epoch: 16 [627715/888800 70.62%] train loss: 1.3331270565686282e-05 \n",
      "epoch: 16 [628826/888800 70.75%] train loss: 1.3909106201026589e-05 \n",
      "epoch: 16 [629937/888800 70.88%] train loss: 1.4851827472739387e-05 \n",
      "epoch: 16 [631048/888800 71.00%] train loss: 1.4657170140708331e-05 \n",
      "epoch: 16 [632159/888800 71.12%] train loss: 1.3793377547699492e-05 \n",
      "epoch: 16 [633270/888800 71.25%] train loss: 1.3355261216929648e-05 \n",
      "epoch: 16 [634381/888800 71.38%] train loss: 1.447994691261556e-05 \n",
      "epoch: 16 [635492/888800 71.50%] train loss: 1.3964922800369095e-05 \n",
      "epoch: 16 [636603/888800 71.62%] train loss: 1.4575207387679256e-05 \n",
      "epoch: 16 [637714/888800 71.75%] train loss: 1.6075860912678763e-05 \n",
      "epoch: 16 [638825/888800 71.88%] train loss: 1.4421862942981534e-05 \n",
      "epoch: 16 [639936/888800 72.00%] train loss: 1.4268994164012838e-05 \n",
      "epoch: 16 [641047/888800 72.12%] train loss: 1.4774414921703283e-05 \n",
      "epoch: 16 [642158/888800 72.25%] train loss: 1.4811432265560143e-05 \n",
      "epoch: 16 [643269/888800 72.38%] train loss: 1.4671638382424135e-05 \n",
      "epoch: 16 [644380/888800 72.50%] train loss: 1.3656758710567374e-05 \n",
      "epoch: 16 [645491/888800 72.62%] train loss: 1.6068175682448782e-05 \n",
      "epoch: 16 [646602/888800 72.75%] train loss: 1.4304466276371386e-05 \n",
      "epoch: 16 [647713/888800 72.88%] train loss: 1.485371649323497e-05 \n",
      "epoch: 16 [648824/888800 73.00%] train loss: 1.540376979392022e-05 \n",
      "epoch: 16 [649935/888800 73.12%] train loss: 1.37872257255367e-05 \n",
      "epoch: 16 [651046/888800 73.25%] train loss: 1.3820871572534088e-05 \n",
      "epoch: 16 [652157/888800 73.38%] train loss: 1.3674929505214095e-05 \n",
      "epoch: 16 [653268/888800 73.50%] train loss: 1.7325368389720097e-05 \n",
      "epoch: 16 [654379/888800 73.62%] train loss: 1.3442831004795153e-05 \n",
      "epoch: 16 [655490/888800 73.75%] train loss: 1.5118736882868689e-05 \n",
      "epoch: 16 [656601/888800 73.88%] train loss: 1.3957474038761575e-05 \n",
      "epoch: 16 [657712/888800 74.00%] train loss: 1.5297708159778267e-05 \n",
      "epoch: 16 [658823/888800 74.12%] train loss: 1.5410842024721205e-05 \n",
      "epoch: 16 [659934/888800 74.25%] train loss: 1.4549933439411689e-05 \n",
      "epoch: 16 [661045/888800 74.38%] train loss: 1.5198937035165727e-05 \n",
      "epoch: 16 [662156/888800 74.50%] train loss: 1.4335700143419672e-05 \n",
      "epoch: 16 [663267/888800 74.62%] train loss: 1.3851545190846082e-05 \n",
      "epoch: 16 [664378/888800 74.75%] train loss: 1.3343473256099969e-05 \n",
      "epoch: 16 [665489/888800 74.88%] train loss: 1.4270449355535675e-05 \n",
      "epoch: 16 [666600/888800 75.00%] train loss: 1.4481677681033034e-05 \n",
      "epoch: 16 [667711/888800 75.12%] train loss: 1.5215707207971718e-05 \n",
      "epoch: 16 [668822/888800 75.25%] train loss: 1.3685585145140067e-05 \n",
      "epoch: 16 [669933/888800 75.38%] train loss: 1.4572851796401665e-05 \n",
      "epoch: 16 [671044/888800 75.50%] train loss: 1.3054768714937381e-05 \n",
      "epoch: 16 [672155/888800 75.62%] train loss: 1.5445852113771252e-05 \n",
      "epoch: 16 [673266/888800 75.75%] train loss: 1.3971069165563677e-05 \n",
      "epoch: 16 [674377/888800 75.88%] train loss: 1.4142728105071e-05 \n",
      "epoch: 16 [675488/888800 76.00%] train loss: 1.5903677194728516e-05 \n",
      "epoch: 16 [676599/888800 76.12%] train loss: 1.3174959349271376e-05 \n",
      "epoch: 16 [677710/888800 76.25%] train loss: 1.4959190593799576e-05 \n",
      "epoch: 16 [678821/888800 76.38%] train loss: 1.4878922229399905e-05 \n",
      "epoch: 16 [679932/888800 76.50%] train loss: 1.533802060293965e-05 \n",
      "epoch: 16 [681043/888800 76.62%] train loss: 1.544583574286662e-05 \n",
      "epoch: 16 [682154/888800 76.75%] train loss: 1.5095245544216596e-05 \n",
      "epoch: 16 [683265/888800 76.88%] train loss: 1.423822595825186e-05 \n",
      "epoch: 16 [684376/888800 77.00%] train loss: 1.4375174941960722e-05 \n",
      "epoch: 16 [685487/888800 77.12%] train loss: 1.4463188563240692e-05 \n",
      "epoch: 16 [686598/888800 77.25%] train loss: 1.3782590031041764e-05 \n",
      "epoch: 16 [687709/888800 77.38%] train loss: 1.5496269043069333e-05 \n",
      "epoch: 16 [688820/888800 77.50%] train loss: 1.4157480109133758e-05 \n",
      "epoch: 16 [689931/888800 77.62%] train loss: 1.378061824652832e-05 \n",
      "epoch: 16 [691042/888800 77.75%] train loss: 1.4789226952416357e-05 \n",
      "epoch: 16 [692153/888800 77.88%] train loss: 1.2370104741421528e-05 \n",
      "epoch: 16 [693264/888800 78.00%] train loss: 1.6280915588140488e-05 \n",
      "epoch: 16 [694375/888800 78.12%] train loss: 1.4815372196608223e-05 \n",
      "epoch: 16 [695486/888800 78.25%] train loss: 1.5142121810640674e-05 \n",
      "epoch: 16 [696597/888800 78.38%] train loss: 1.4803559679421596e-05 \n",
      "epoch: 16 [697708/888800 78.50%] train loss: 1.4496087715087924e-05 \n",
      "epoch: 16 [698819/888800 78.62%] train loss: 1.5663494195905514e-05 \n",
      "epoch: 16 [699930/888800 78.75%] train loss: 1.4982745597080793e-05 \n",
      "epoch: 16 [701041/888800 78.88%] train loss: 1.8520337107474916e-05 \n",
      "epoch: 16 [702152/888800 79.00%] train loss: 1.4411049050977454e-05 \n",
      "epoch: 16 [703263/888800 79.12%] train loss: 1.696022809483111e-05 \n",
      "epoch: 16 [704374/888800 79.25%] train loss: 1.6424992281827144e-05 \n",
      "epoch: 16 [705485/888800 79.38%] train loss: 1.3077315088594332e-05 \n",
      "epoch: 16 [706596/888800 79.50%] train loss: 1.5288151189452037e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [707707/888800 79.62%] train loss: 1.3147889148967806e-05 \n",
      "epoch: 16 [708818/888800 79.75%] train loss: 1.6303274605888873e-05 \n",
      "epoch: 16 [709929/888800 79.88%] train loss: 1.4763090803171508e-05 \n",
      "epoch: 16 [711040/888800 80.00%] train loss: 1.6667579984641634e-05 \n",
      "epoch: 16 [712151/888800 80.12%] train loss: 1.603551208972931e-05 \n",
      "epoch: 16 [713262/888800 80.25%] train loss: 1.5088065083546098e-05 \n",
      "epoch: 16 [714373/888800 80.38%] train loss: 1.6581720046815462e-05 \n",
      "epoch: 16 [715484/888800 80.50%] train loss: 1.3693795153812971e-05 \n",
      "epoch: 16 [716595/888800 80.62%] train loss: 1.5955867638695054e-05 \n",
      "epoch: 16 [717706/888800 80.75%] train loss: 1.3009176655032206e-05 \n",
      "epoch: 16 [718817/888800 80.88%] train loss: 1.544658880447969e-05 \n",
      "epoch: 16 [719928/888800 81.00%] train loss: 1.6034418877097778e-05 \n",
      "epoch: 16 [721039/888800 81.12%] train loss: 1.417262956238119e-05 \n",
      "epoch: 16 [722150/888800 81.25%] train loss: 1.4789937267778441e-05 \n",
      "epoch: 16 [723261/888800 81.38%] train loss: 1.3590097296400927e-05 \n",
      "epoch: 16 [724372/888800 81.50%] train loss: 1.4825384823780041e-05 \n",
      "epoch: 16 [725483/888800 81.62%] train loss: 1.44291298056487e-05 \n",
      "epoch: 16 [726594/888800 81.75%] train loss: 1.5347337466664612e-05 \n",
      "epoch: 16 [727705/888800 81.88%] train loss: 1.5247040209942497e-05 \n",
      "epoch: 16 [728816/888800 82.00%] train loss: 1.441486347175669e-05 \n",
      "epoch: 16 [729927/888800 82.12%] train loss: 1.4677949366159737e-05 \n",
      "epoch: 16 [731038/888800 82.25%] train loss: 1.6292666259687394e-05 \n",
      "epoch: 16 [732149/888800 82.38%] train loss: 1.3578842299466487e-05 \n",
      "epoch: 16 [733260/888800 82.50%] train loss: 1.3239029613032471e-05 \n",
      "epoch: 16 [734371/888800 82.62%] train loss: 1.3681111340702046e-05 \n",
      "epoch: 16 [735482/888800 82.75%] train loss: 1.445044472347945e-05 \n",
      "epoch: 16 [736593/888800 82.88%] train loss: 1.4835839465376921e-05 \n",
      "epoch: 16 [737704/888800 83.00%] train loss: 1.4845973055344075e-05 \n",
      "epoch: 16 [738815/888800 83.12%] train loss: 1.4538351933879312e-05 \n",
      "epoch: 16 [739926/888800 83.25%] train loss: 1.5011503819550853e-05 \n",
      "epoch: 16 [741037/888800 83.38%] train loss: 1.574872476339806e-05 \n",
      "epoch: 16 [742148/888800 83.50%] train loss: 1.4764905245101545e-05 \n",
      "epoch: 16 [743259/888800 83.62%] train loss: 1.491273633291712e-05 \n",
      "epoch: 16 [744370/888800 83.75%] train loss: 1.4788958651479334e-05 \n",
      "epoch: 16 [745481/888800 83.88%] train loss: 1.2678547136601992e-05 \n",
      "epoch: 16 [746592/888800 84.00%] train loss: 1.4230887245503254e-05 \n",
      "epoch: 16 [747703/888800 84.12%] train loss: 1.52650991367409e-05 \n",
      "epoch: 16 [748814/888800 84.25%] train loss: 1.3815421880281065e-05 \n",
      "epoch: 16 [749925/888800 84.38%] train loss: 1.3856779332854785e-05 \n",
      "epoch: 16 [751036/888800 84.50%] train loss: 1.2178871656942647e-05 \n",
      "epoch: 16 [752147/888800 84.62%] train loss: 1.3934896742284764e-05 \n",
      "epoch: 16 [753258/888800 84.75%] train loss: 1.3182766451791395e-05 \n",
      "epoch: 16 [754369/888800 84.88%] train loss: 1.4029058547748718e-05 \n",
      "epoch: 16 [755480/888800 85.00%] train loss: 1.4152284165902529e-05 \n",
      "epoch: 16 [756591/888800 85.12%] train loss: 1.4953238860471174e-05 \n",
      "epoch: 16 [757702/888800 85.25%] train loss: 1.465272180212196e-05 \n",
      "epoch: 16 [758813/888800 85.38%] train loss: 1.4832322449365165e-05 \n",
      "epoch: 16 [759924/888800 85.50%] train loss: 1.4757816643395927e-05 \n",
      "epoch: 16 [761035/888800 85.62%] train loss: 1.5534349586232565e-05 \n",
      "epoch: 16 [762146/888800 85.75%] train loss: 1.2935362974531017e-05 \n",
      "epoch: 16 [763257/888800 85.88%] train loss: 1.3919685443397611e-05 \n",
      "epoch: 16 [764368/888800 86.00%] train loss: 1.3983139979245607e-05 \n",
      "epoch: 16 [765479/888800 86.12%] train loss: 1.341141887678532e-05 \n",
      "epoch: 16 [766590/888800 86.25%] train loss: 1.549645276099909e-05 \n",
      "epoch: 16 [767701/888800 86.38%] train loss: 1.4383154848474078e-05 \n",
      "epoch: 16 [768812/888800 86.50%] train loss: 1.504122519691009e-05 \n",
      "epoch: 16 [769923/888800 86.62%] train loss: 1.5001667634351179e-05 \n",
      "epoch: 16 [771034/888800 86.75%] train loss: 1.3899176337872632e-05 \n",
      "epoch: 16 [772145/888800 86.88%] train loss: 1.4410633411898743e-05 \n",
      "epoch: 16 [773256/888800 87.00%] train loss: 1.3548365132010076e-05 \n",
      "epoch: 16 [774367/888800 87.12%] train loss: 1.4531388842442539e-05 \n",
      "epoch: 16 [775478/888800 87.25%] train loss: 1.3266322639537975e-05 \n",
      "epoch: 16 [776589/888800 87.38%] train loss: 1.3732476872974075e-05 \n",
      "epoch: 16 [777700/888800 87.50%] train loss: 1.4101065971772186e-05 \n",
      "epoch: 16 [778811/888800 87.62%] train loss: 1.4236611605156213e-05 \n",
      "epoch: 16 [779922/888800 87.75%] train loss: 1.4012814972375054e-05 \n",
      "epoch: 16 [781033/888800 87.88%] train loss: 1.725410584185738e-05 \n",
      "epoch: 16 [782144/888800 88.00%] train loss: 1.474846158089349e-05 \n",
      "epoch: 16 [783255/888800 88.12%] train loss: 1.3998255781189073e-05 \n",
      "epoch: 16 [784366/888800 88.25%] train loss: 1.5034168427519035e-05 \n",
      "epoch: 16 [785477/888800 88.38%] train loss: 1.3498742191586643e-05 \n",
      "epoch: 16 [786588/888800 88.50%] train loss: 1.3464802577800583e-05 \n",
      "epoch: 16 [787699/888800 88.62%] train loss: 1.461154442949919e-05 \n",
      "epoch: 16 [788810/888800 88.75%] train loss: 1.4755906704522204e-05 \n",
      "epoch: 16 [789921/888800 88.88%] train loss: 1.3623332961287815e-05 \n",
      "epoch: 16 [791032/888800 89.00%] train loss: 1.5100185009941924e-05 \n",
      "epoch: 16 [792143/888800 89.12%] train loss: 1.513088045612676e-05 \n",
      "epoch: 16 [793254/888800 89.25%] train loss: 1.470616552978754e-05 \n",
      "epoch: 16 [794365/888800 89.38%] train loss: 1.4073932106839493e-05 \n",
      "epoch: 16 [795476/888800 89.50%] train loss: 1.5944779079291038e-05 \n",
      "epoch: 16 [796587/888800 89.62%] train loss: 1.4341303540277295e-05 \n",
      "epoch: 16 [797698/888800 89.75%] train loss: 1.511349000793416e-05 \n",
      "epoch: 16 [798809/888800 89.88%] train loss: 1.5283896573237143e-05 \n",
      "epoch: 16 [799920/888800 90.00%] train loss: 1.3665134247276e-05 \n",
      "epoch: 16 [801031/888800 90.12%] train loss: 1.3921280697104521e-05 \n",
      "epoch: 16 [802142/888800 90.25%] train loss: 1.4699172425025608e-05 \n",
      "epoch: 16 [803253/888800 90.38%] train loss: 1.6119995052576996e-05 \n",
      "epoch: 16 [804364/888800 90.50%] train loss: 1.4509347238345072e-05 \n",
      "epoch: 16 [805475/888800 90.62%] train loss: 1.550058186694514e-05 \n",
      "epoch: 16 [806586/888800 90.75%] train loss: 1.2450192116375547e-05 \n",
      "epoch: 16 [807697/888800 90.88%] train loss: 1.6293548469548114e-05 \n",
      "epoch: 16 [808808/888800 91.00%] train loss: 1.3913899238104932e-05 \n",
      "epoch: 16 [809919/888800 91.12%] train loss: 1.598495146026835e-05 \n",
      "epoch: 16 [811030/888800 91.25%] train loss: 1.3830141142534558e-05 \n",
      "epoch: 16 [812141/888800 91.38%] train loss: 1.306030299019767e-05 \n",
      "epoch: 16 [813252/888800 91.50%] train loss: 1.5339130186475813e-05 \n",
      "epoch: 16 [814363/888800 91.62%] train loss: 1.491370585426921e-05 \n",
      "epoch: 16 [815474/888800 91.75%] train loss: 1.5088868167367764e-05 \n",
      "epoch: 16 [816585/888800 91.88%] train loss: 1.4691700016555842e-05 \n",
      "epoch: 16 [817696/888800 92.00%] train loss: 1.4279767128755338e-05 \n",
      "epoch: 16 [818807/888800 92.12%] train loss: 1.3906004824093543e-05 \n",
      "epoch: 16 [819918/888800 92.25%] train loss: 1.4479978744930122e-05 \n",
      "epoch: 16 [821029/888800 92.38%] train loss: 1.474563487136038e-05 \n",
      "epoch: 16 [822140/888800 92.50%] train loss: 1.4299163012765348e-05 \n",
      "epoch: 16 [823251/888800 92.62%] train loss: 1.6245270671788603e-05 \n",
      "epoch: 16 [824362/888800 92.75%] train loss: 1.3268932889332063e-05 \n",
      "epoch: 16 [825473/888800 92.88%] train loss: 1.6191819668165408e-05 \n",
      "epoch: 16 [826584/888800 93.00%] train loss: 1.4160686987452209e-05 \n",
      "epoch: 16 [827695/888800 93.12%] train loss: 1.4911529433447868e-05 \n",
      "epoch: 16 [828806/888800 93.25%] train loss: 1.4034098967385944e-05 \n",
      "epoch: 16 [829917/888800 93.38%] train loss: 1.3547361049859319e-05 \n",
      "epoch: 16 [831028/888800 93.50%] train loss: 1.4762668797629885e-05 \n",
      "epoch: 16 [832139/888800 93.62%] train loss: 1.3673001376446337e-05 \n",
      "epoch: 16 [833250/888800 93.75%] train loss: 1.4863790966046508e-05 \n",
      "epoch: 16 [834361/888800 93.88%] train loss: 1.4095247934164945e-05 \n",
      "epoch: 16 [835472/888800 94.00%] train loss: 1.348016485280823e-05 \n",
      "epoch: 16 [836583/888800 94.12%] train loss: 1.5707702914369293e-05 \n",
      "epoch: 16 [837694/888800 94.25%] train loss: 1.4519951037073042e-05 \n",
      "epoch: 16 [838805/888800 94.38%] train loss: 1.4747341992915608e-05 \n",
      "epoch: 16 [839916/888800 94.50%] train loss: 1.574959787831176e-05 \n",
      "epoch: 16 [841027/888800 94.62%] train loss: 1.4779136108700186e-05 \n",
      "epoch: 16 [842138/888800 94.75%] train loss: 1.4473378541879356e-05 \n",
      "epoch: 16 [843249/888800 94.88%] train loss: 1.5600935512338765e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 [844360/888800 95.00%] train loss: 1.3496619430952705e-05 \n",
      "epoch: 16 [845471/888800 95.12%] train loss: 1.451366097171558e-05 \n",
      "epoch: 16 [846582/888800 95.25%] train loss: 1.5101408280315809e-05 \n",
      "epoch: 16 [847693/888800 95.38%] train loss: 1.4248127627070062e-05 \n",
      "epoch: 16 [848804/888800 95.50%] train loss: 1.3570524970418774e-05 \n",
      "epoch: 16 [849915/888800 95.62%] train loss: 1.4760968952032272e-05 \n",
      "epoch: 16 [851026/888800 95.75%] train loss: 1.4835085494269151e-05 \n",
      "epoch: 16 [852137/888800 95.88%] train loss: 1.3993551874591503e-05 \n",
      "epoch: 16 [853248/888800 96.00%] train loss: 1.3629241038870532e-05 \n",
      "epoch: 16 [854359/888800 96.12%] train loss: 1.29278641907149e-05 \n",
      "epoch: 16 [855470/888800 96.25%] train loss: 1.2944248737767339e-05 \n",
      "epoch: 16 [856581/888800 96.38%] train loss: 1.3586607565230224e-05 \n",
      "epoch: 16 [857692/888800 96.50%] train loss: 1.2973213415534701e-05 \n",
      "epoch: 16 [858803/888800 96.62%] train loss: 1.51954345710692e-05 \n",
      "epoch: 16 [859914/888800 96.75%] train loss: 1.299722589465091e-05 \n",
      "epoch: 16 [861025/888800 96.88%] train loss: 1.3206337825977243e-05 \n",
      "epoch: 16 [862136/888800 97.00%] train loss: 1.5114736925170291e-05 \n",
      "epoch: 16 [863247/888800 97.12%] train loss: 1.5274690667865798e-05 \n",
      "epoch: 16 [864358/888800 97.25%] train loss: 1.301067095482722e-05 \n",
      "epoch: 16 [865469/888800 97.38%] train loss: 1.5123992852750234e-05 \n",
      "epoch: 16 [866580/888800 97.50%] train loss: 1.4482884580502287e-05 \n",
      "epoch: 16 [867691/888800 97.62%] train loss: 1.5021514627733268e-05 \n",
      "epoch: 16 [868802/888800 97.75%] train loss: 1.3691549611394294e-05 \n",
      "epoch: 16 [869913/888800 97.88%] train loss: 1.3233267054602038e-05 \n",
      "epoch: 16 [871024/888800 98.00%] train loss: 1.5180048649199307e-05 \n",
      "epoch: 16 [872135/888800 98.12%] train loss: 1.4627912605646998e-05 \n",
      "epoch: 16 [873246/888800 98.25%] train loss: 1.3981717529532034e-05 \n",
      "epoch: 16 [874357/888800 98.38%] train loss: 1.4772302165511064e-05 \n",
      "epoch: 16 [875468/888800 98.50%] train loss: 1.3719396520173177e-05 \n",
      "epoch: 16 [876579/888800 98.62%] train loss: 1.3438069800031371e-05 \n",
      "epoch: 16 [877690/888800 98.75%] train loss: 1.3698568182007875e-05 \n",
      "epoch: 16 [878801/888800 98.88%] train loss: 1.4422500498767477e-05 \n",
      "epoch: 16 [879912/888800 99.00%] train loss: 1.4796008144912776e-05 \n",
      "epoch: 16 [881023/888800 99.12%] train loss: 1.533705653855577e-05 \n",
      "epoch: 16 [882134/888800 99.25%] train loss: 1.5054565665195696e-05 \n",
      "epoch: 16 [883245/888800 99.38%] train loss: 1.5111993889149744e-05 \n",
      "epoch: 16 [884356/888800 99.50%] train loss: 1.3929597116657533e-05 \n",
      "epoch: 16 [885467/888800 99.62%] train loss: 1.4867164281895384e-05 \n",
      "epoch: 16 [886578/888800 99.75%] train loss: 1.3483892871590797e-05 \n",
      "epoch: 16 [887689/888800 99.88%] train loss: 1.5125554455153178e-05 \n",
      "epoch: 17 [0/888800 0.00%] train loss: 1.3481589121511206e-05 \n",
      "epoch: 17 [1111/888800 0.12%] train loss: 1.5649402484996244e-05 \n",
      "epoch: 17 [2222/888800 0.25%] train loss: 1.4125771485851146e-05 \n",
      "epoch: 17 [3333/888800 0.38%] train loss: 1.4062504305911716e-05 \n",
      "epoch: 17 [4444/888800 0.50%] train loss: 1.3600347301689908e-05 \n",
      "epoch: 17 [5555/888800 0.62%] train loss: 1.4173088857205585e-05 \n",
      "epoch: 17 [6666/888800 0.75%] train loss: 1.3712276995647699e-05 \n",
      "epoch: 17 [7777/888800 0.88%] train loss: 1.4630862096964847e-05 \n",
      "epoch: 17 [8888/888800 1.00%] train loss: 1.3821623724652454e-05 \n",
      "epoch: 17 [9999/888800 1.12%] train loss: 1.4809161257289816e-05 \n",
      "epoch: 17 [11110/888800 1.25%] train loss: 1.3918152944825124e-05 \n",
      "epoch: 17 [12221/888800 1.38%] train loss: 1.4317947716335766e-05 \n",
      "epoch: 17 [13332/888800 1.50%] train loss: 1.439581137674395e-05 \n",
      "epoch: 17 [14443/888800 1.62%] train loss: 1.3053889233560767e-05 \n",
      "epoch: 17 [15554/888800 1.75%] train loss: 1.3617458535009064e-05 \n",
      "epoch: 17 [16665/888800 1.88%] train loss: 1.5196217646007426e-05 \n",
      "epoch: 17 [17776/888800 2.00%] train loss: 1.4774701412534341e-05 \n",
      "epoch: 17 [18887/888800 2.12%] train loss: 1.41365717354347e-05 \n",
      "epoch: 17 [19998/888800 2.25%] train loss: 1.3457977729558479e-05 \n",
      "epoch: 17 [21109/888800 2.38%] train loss: 1.4216047020454425e-05 \n",
      "epoch: 17 [22220/888800 2.50%] train loss: 1.4727958841831423e-05 \n",
      "epoch: 17 [23331/888800 2.62%] train loss: 1.3969923202239443e-05 \n",
      "epoch: 17 [24442/888800 2.75%] train loss: 1.4614174688176718e-05 \n",
      "epoch: 17 [25553/888800 2.88%] train loss: 1.3745247088081669e-05 \n",
      "epoch: 17 [26664/888800 3.00%] train loss: 1.3424331882561091e-05 \n",
      "epoch: 17 [27775/888800 3.12%] train loss: 1.5456522305612452e-05 \n",
      "epoch: 17 [28886/888800 3.25%] train loss: 1.4974575606174767e-05 \n",
      "epoch: 17 [29997/888800 3.38%] train loss: 1.4010281120135915e-05 \n",
      "epoch: 17 [31108/888800 3.50%] train loss: 1.3793772268400062e-05 \n",
      "epoch: 17 [32219/888800 3.62%] train loss: 1.5164825526881032e-05 \n",
      "epoch: 17 [33330/888800 3.75%] train loss: 1.3631218280352186e-05 \n",
      "epoch: 17 [34441/888800 3.88%] train loss: 1.3775480510958005e-05 \n",
      "epoch: 17 [35552/888800 4.00%] train loss: 1.4135741366771981e-05 \n",
      "epoch: 17 [36663/888800 4.12%] train loss: 1.4924615243216977e-05 \n",
      "epoch: 17 [37774/888800 4.25%] train loss: 1.313353277510032e-05 \n",
      "epoch: 17 [38885/888800 4.38%] train loss: 1.3659930118592456e-05 \n",
      "epoch: 17 [39996/888800 4.50%] train loss: 1.4312367966340389e-05 \n",
      "epoch: 17 [41107/888800 4.62%] train loss: 1.4966556591389235e-05 \n",
      "epoch: 17 [42218/888800 4.75%] train loss: 1.359315592708299e-05 \n",
      "epoch: 17 [43329/888800 4.88%] train loss: 1.460890234739054e-05 \n",
      "epoch: 17 [44440/888800 5.00%] train loss: 1.4754192307009362e-05 \n",
      "epoch: 17 [45551/888800 5.12%] train loss: 1.3798987311020028e-05 \n",
      "epoch: 17 [46662/888800 5.25%] train loss: 1.3700969248020556e-05 \n",
      "epoch: 17 [47773/888800 5.38%] train loss: 1.2666025213547982e-05 \n",
      "epoch: 17 [48884/888800 5.50%] train loss: 1.372302449453855e-05 \n",
      "epoch: 17 [49995/888800 5.62%] train loss: 1.551057539472822e-05 \n",
      "epoch: 17 [51106/888800 5.75%] train loss: 1.4705914509249851e-05 \n",
      "epoch: 17 [52217/888800 5.88%] train loss: 1.5948209693306126e-05 \n",
      "epoch: 17 [53328/888800 6.00%] train loss: 1.3929895430919714e-05 \n",
      "epoch: 17 [54439/888800 6.12%] train loss: 1.663195507717319e-05 \n",
      "epoch: 17 [55550/888800 6.25%] train loss: 1.3584139196609613e-05 \n",
      "epoch: 17 [56661/888800 6.38%] train loss: 1.3670884982275311e-05 \n",
      "epoch: 17 [57772/888800 6.50%] train loss: 1.2676844562520273e-05 \n",
      "epoch: 17 [58883/888800 6.62%] train loss: 1.5186897144303657e-05 \n",
      "epoch: 17 [59994/888800 6.75%] train loss: 1.5217949112411588e-05 \n",
      "epoch: 17 [61105/888800 6.88%] train loss: 1.2930859156767838e-05 \n",
      "epoch: 17 [62216/888800 7.00%] train loss: 1.4029763406142592e-05 \n",
      "epoch: 17 [63327/888800 7.12%] train loss: 1.3837383448844776e-05 \n",
      "epoch: 17 [64438/888800 7.25%] train loss: 1.3231817320047412e-05 \n",
      "epoch: 17 [65549/888800 7.38%] train loss: 1.3785085684503429e-05 \n",
      "epoch: 17 [66660/888800 7.50%] train loss: 1.395017170580104e-05 \n",
      "epoch: 17 [67771/888800 7.62%] train loss: 1.3880900951335207e-05 \n",
      "epoch: 17 [68882/888800 7.75%] train loss: 1.4729586837347597e-05 \n",
      "epoch: 17 [69993/888800 7.88%] train loss: 1.3655086149810813e-05 \n",
      "epoch: 17 [71104/888800 8.00%] train loss: 1.4412746168090962e-05 \n",
      "epoch: 17 [72215/888800 8.12%] train loss: 1.3175917956687044e-05 \n",
      "epoch: 17 [73326/888800 8.25%] train loss: 1.3506574759958312e-05 \n",
      "epoch: 17 [74437/888800 8.38%] train loss: 1.4887470570101868e-05 \n",
      "epoch: 17 [75548/888800 8.50%] train loss: 1.4391350305231754e-05 \n",
      "epoch: 17 [76659/888800 8.62%] train loss: 1.3176997526898049e-05 \n",
      "epoch: 17 [77770/888800 8.75%] train loss: 1.3062020116194617e-05 \n",
      "epoch: 17 [78881/888800 8.88%] train loss: 1.3588969522970729e-05 \n",
      "epoch: 17 [79992/888800 9.00%] train loss: 1.345360760751646e-05 \n",
      "epoch: 17 [81103/888800 9.12%] train loss: 1.5697194612585008e-05 \n",
      "epoch: 17 [82214/888800 9.25%] train loss: 1.3524349924409762e-05 \n",
      "epoch: 17 [83325/888800 9.38%] train loss: 1.4299520444183145e-05 \n",
      "epoch: 17 [84436/888800 9.50%] train loss: 1.4080729670240544e-05 \n",
      "epoch: 17 [85547/888800 9.62%] train loss: 1.3492223843059037e-05 \n",
      "epoch: 17 [86658/888800 9.75%] train loss: 1.4916998225089628e-05 \n",
      "epoch: 17 [87769/888800 9.88%] train loss: 1.4411911251954734e-05 \n",
      "epoch: 17 [88880/888800 10.00%] train loss: 1.4208302673068829e-05 \n",
      "epoch: 17 [89991/888800 10.12%] train loss: 1.3739720998273697e-05 \n",
      "epoch: 17 [91102/888800 10.25%] train loss: 1.4382397239387501e-05 \n",
      "epoch: 17 [92213/888800 10.38%] train loss: 1.3647232663061004e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [93324/888800 10.50%] train loss: 1.4730278053320944e-05 \n",
      "epoch: 17 [94435/888800 10.62%] train loss: 1.3238342944532633e-05 \n",
      "epoch: 17 [95546/888800 10.75%] train loss: 1.552385583636351e-05 \n",
      "epoch: 17 [96657/888800 10.88%] train loss: 1.397716005158145e-05 \n",
      "epoch: 17 [97768/888800 11.00%] train loss: 1.3981957636133302e-05 \n",
      "epoch: 17 [98879/888800 11.12%] train loss: 1.3690363630303182e-05 \n",
      "epoch: 17 [99990/888800 11.25%] train loss: 1.5403164070448838e-05 \n",
      "epoch: 17 [101101/888800 11.38%] train loss: 1.3792299796477892e-05 \n",
      "epoch: 17 [102212/888800 11.50%] train loss: 1.4494189599645324e-05 \n",
      "epoch: 17 [103323/888800 11.62%] train loss: 1.6784675608505495e-05 \n",
      "epoch: 17 [104434/888800 11.75%] train loss: 1.3194550774642266e-05 \n",
      "epoch: 17 [105545/888800 11.88%] train loss: 1.608173261047341e-05 \n",
      "epoch: 17 [106656/888800 12.00%] train loss: 1.600496398168616e-05 \n",
      "epoch: 17 [107767/888800 12.12%] train loss: 1.6381925888708793e-05 \n",
      "epoch: 17 [108878/888800 12.25%] train loss: 1.4921833098924253e-05 \n",
      "epoch: 17 [109989/888800 12.38%] train loss: 1.4847790225758217e-05 \n",
      "epoch: 17 [111100/888800 12.50%] train loss: 1.6371506717405282e-05 \n",
      "epoch: 17 [112211/888800 12.62%] train loss: 1.5232930309139192e-05 \n",
      "epoch: 17 [113322/888800 12.75%] train loss: 1.4168573216011282e-05 \n",
      "epoch: 17 [114433/888800 12.88%] train loss: 1.41017399073462e-05 \n",
      "epoch: 17 [115544/888800 13.00%] train loss: 1.5744117263238877e-05 \n",
      "epoch: 17 [116655/888800 13.12%] train loss: 1.4968542018323205e-05 \n",
      "epoch: 17 [117766/888800 13.25%] train loss: 1.5502431779168546e-05 \n",
      "epoch: 17 [118877/888800 13.38%] train loss: 1.585280551807955e-05 \n",
      "epoch: 17 [119988/888800 13.50%] train loss: 1.4740249753231183e-05 \n",
      "epoch: 17 [121099/888800 13.62%] train loss: 1.4428716895054094e-05 \n",
      "epoch: 17 [122210/888800 13.75%] train loss: 1.341964798484696e-05 \n",
      "epoch: 17 [123321/888800 13.88%] train loss: 1.4596623259421904e-05 \n",
      "epoch: 17 [124432/888800 14.00%] train loss: 1.4627397831645794e-05 \n",
      "epoch: 17 [125543/888800 14.12%] train loss: 1.4436890523938928e-05 \n",
      "epoch: 17 [126654/888800 14.25%] train loss: 1.528126267658081e-05 \n",
      "epoch: 17 [127765/888800 14.38%] train loss: 1.41527825689991e-05 \n",
      "epoch: 17 [128876/888800 14.50%] train loss: 1.3123126336722635e-05 \n",
      "epoch: 17 [129987/888800 14.62%] train loss: 1.5638132026651874e-05 \n",
      "epoch: 17 [131098/888800 14.75%] train loss: 1.4774411283724476e-05 \n",
      "epoch: 17 [132209/888800 14.88%] train loss: 1.3954966561868787e-05 \n",
      "epoch: 17 [133320/888800 15.00%] train loss: 1.5520048691541888e-05 \n",
      "epoch: 17 [134431/888800 15.12%] train loss: 1.497306857345393e-05 \n",
      "epoch: 17 [135542/888800 15.25%] train loss: 1.3740824215346947e-05 \n",
      "epoch: 17 [136653/888800 15.38%] train loss: 1.4634892067988403e-05 \n",
      "epoch: 17 [137764/888800 15.50%] train loss: 1.5231254110403825e-05 \n",
      "epoch: 17 [138875/888800 15.62%] train loss: 1.5688776329625398e-05 \n",
      "epoch: 17 [139986/888800 15.75%] train loss: 1.5224479284370318e-05 \n",
      "epoch: 17 [141097/888800 15.88%] train loss: 1.4551164895237889e-05 \n",
      "epoch: 17 [142208/888800 16.00%] train loss: 1.3382063116296194e-05 \n",
      "epoch: 17 [143319/888800 16.12%] train loss: 1.4570675375580322e-05 \n",
      "epoch: 17 [144430/888800 16.25%] train loss: 1.2997642443224322e-05 \n",
      "epoch: 17 [145541/888800 16.38%] train loss: 1.3986818885314278e-05 \n",
      "epoch: 17 [146652/888800 16.50%] train loss: 1.4661241038993467e-05 \n",
      "epoch: 17 [147763/888800 16.62%] train loss: 1.3858162674296182e-05 \n",
      "epoch: 17 [148874/888800 16.75%] train loss: 1.4709061360917985e-05 \n",
      "epoch: 17 [149985/888800 16.88%] train loss: 1.4223096513887867e-05 \n",
      "epoch: 17 [151096/888800 17.00%] train loss: 1.412371602782514e-05 \n",
      "epoch: 17 [152207/888800 17.12%] train loss: 1.5665807950426824e-05 \n",
      "epoch: 17 [153318/888800 17.25%] train loss: 1.4180903235683218e-05 \n",
      "epoch: 17 [154429/888800 17.38%] train loss: 1.4518107491312549e-05 \n",
      "epoch: 17 [155540/888800 17.50%] train loss: 1.3126573321642354e-05 \n",
      "epoch: 17 [156651/888800 17.62%] train loss: 1.4254808775149286e-05 \n",
      "epoch: 17 [157762/888800 17.75%] train loss: 1.3219581887824461e-05 \n",
      "epoch: 17 [158873/888800 17.88%] train loss: 1.5688334315200336e-05 \n",
      "epoch: 17 [159984/888800 18.00%] train loss: 1.4609906429541297e-05 \n",
      "epoch: 17 [161095/888800 18.12%] train loss: 1.543677171866875e-05 \n",
      "epoch: 17 [162206/888800 18.25%] train loss: 1.4067975826037582e-05 \n",
      "epoch: 17 [163317/888800 18.38%] train loss: 1.5315383279812522e-05 \n",
      "epoch: 17 [164428/888800 18.50%] train loss: 1.4601458133256529e-05 \n",
      "epoch: 17 [165539/888800 18.62%] train loss: 1.3324375686352141e-05 \n",
      "epoch: 17 [166650/888800 18.75%] train loss: 1.549139415146783e-05 \n",
      "epoch: 17 [167761/888800 18.88%] train loss: 1.502838495071046e-05 \n",
      "epoch: 17 [168872/888800 19.00%] train loss: 1.3719571143155918e-05 \n",
      "epoch: 17 [169983/888800 19.12%] train loss: 1.4091754565015435e-05 \n",
      "epoch: 17 [171094/888800 19.25%] train loss: 1.4777415344724432e-05 \n",
      "epoch: 17 [172205/888800 19.38%] train loss: 1.5273781173164025e-05 \n",
      "epoch: 17 [173316/888800 19.50%] train loss: 1.3774638318864163e-05 \n",
      "epoch: 17 [174427/888800 19.62%] train loss: 1.4538684808940161e-05 \n",
      "epoch: 17 [175538/888800 19.75%] train loss: 1.4497700249194168e-05 \n",
      "epoch: 17 [176649/888800 19.88%] train loss: 1.3511121323972475e-05 \n",
      "epoch: 17 [177760/888800 20.00%] train loss: 1.3113237400830258e-05 \n",
      "epoch: 17 [178871/888800 20.12%] train loss: 1.3834678611601703e-05 \n",
      "epoch: 17 [179982/888800 20.25%] train loss: 1.4287191334005911e-05 \n",
      "epoch: 17 [181093/888800 20.38%] train loss: 1.3622947335534263e-05 \n",
      "epoch: 17 [182204/888800 20.50%] train loss: 1.479098864365369e-05 \n",
      "epoch: 17 [183315/888800 20.62%] train loss: 1.3804547052131966e-05 \n",
      "epoch: 17 [184426/888800 20.75%] train loss: 1.4438592188525945e-05 \n",
      "epoch: 17 [185537/888800 20.88%] train loss: 1.580391290190164e-05 \n",
      "epoch: 17 [186648/888800 21.00%] train loss: 1.4385364920599386e-05 \n",
      "epoch: 17 [187759/888800 21.12%] train loss: 1.4437632671615575e-05 \n",
      "epoch: 17 [188870/888800 21.25%] train loss: 1.3460364243655931e-05 \n",
      "epoch: 17 [189981/888800 21.38%] train loss: 1.5200011148408521e-05 \n",
      "epoch: 17 [191092/888800 21.50%] train loss: 1.514600262453314e-05 \n",
      "epoch: 17 [192203/888800 21.62%] train loss: 1.422749392077094e-05 \n",
      "epoch: 17 [193314/888800 21.75%] train loss: 1.477559817431029e-05 \n",
      "epoch: 17 [194425/888800 21.88%] train loss: 1.4487416592601221e-05 \n",
      "epoch: 17 [195536/888800 22.00%] train loss: 1.580122989253141e-05 \n",
      "epoch: 17 [196647/888800 22.12%] train loss: 1.4524645848723594e-05 \n",
      "epoch: 17 [197758/888800 22.25%] train loss: 1.5411796994158067e-05 \n",
      "epoch: 17 [198869/888800 22.38%] train loss: 1.4189783541951329e-05 \n",
      "epoch: 17 [199980/888800 22.50%] train loss: 1.6201047401409596e-05 \n",
      "epoch: 17 [201091/888800 22.62%] train loss: 1.3504972230293788e-05 \n",
      "epoch: 17 [202202/888800 22.75%] train loss: 1.4581591130991e-05 \n",
      "epoch: 17 [203313/888800 22.88%] train loss: 1.3612238944915589e-05 \n",
      "epoch: 17 [204424/888800 23.00%] train loss: 1.4260959687817376e-05 \n",
      "epoch: 17 [205535/888800 23.12%] train loss: 1.3872405361325946e-05 \n",
      "epoch: 17 [206646/888800 23.25%] train loss: 1.3784273505734745e-05 \n",
      "epoch: 17 [207757/888800 23.38%] train loss: 1.5296876881620847e-05 \n",
      "epoch: 17 [208868/888800 23.50%] train loss: 1.383046583214309e-05 \n",
      "epoch: 17 [209979/888800 23.62%] train loss: 1.3052265785518102e-05 \n",
      "epoch: 17 [211090/888800 23.75%] train loss: 1.4176547665556427e-05 \n",
      "epoch: 17 [212201/888800 23.88%] train loss: 1.390413126500789e-05 \n",
      "epoch: 17 [213312/888800 24.00%] train loss: 1.3419896276900545e-05 \n",
      "epoch: 17 [214423/888800 24.12%] train loss: 1.3602941180579364e-05 \n",
      "epoch: 17 [215534/888800 24.25%] train loss: 1.3866144399798941e-05 \n",
      "epoch: 17 [216645/888800 24.38%] train loss: 1.4403052773559466e-05 \n",
      "epoch: 17 [217756/888800 24.50%] train loss: 1.4867332538415212e-05 \n",
      "epoch: 17 [218867/888800 24.62%] train loss: 1.4374554666574113e-05 \n",
      "epoch: 17 [219978/888800 24.75%] train loss: 1.4317222849058453e-05 \n",
      "epoch: 17 [221089/888800 24.88%] train loss: 1.4722993000759743e-05 \n",
      "epoch: 17 [222200/888800 25.00%] train loss: 1.4201970770955086e-05 \n",
      "epoch: 17 [223311/888800 25.12%] train loss: 1.4911519429006148e-05 \n",
      "epoch: 17 [224422/888800 25.25%] train loss: 1.3578521247836761e-05 \n",
      "epoch: 17 [225533/888800 25.38%] train loss: 1.4488415217783768e-05 \n",
      "epoch: 17 [226644/888800 25.50%] train loss: 1.4572637155652046e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [227755/888800 25.62%] train loss: 1.4246903447201476e-05 \n",
      "epoch: 17 [228866/888800 25.75%] train loss: 1.3552084965340327e-05 \n",
      "epoch: 17 [229977/888800 25.88%] train loss: 1.3786774616164621e-05 \n",
      "epoch: 17 [231088/888800 26.00%] train loss: 1.4413614735531155e-05 \n",
      "epoch: 17 [232199/888800 26.12%] train loss: 1.4800434655626304e-05 \n",
      "epoch: 17 [233310/888800 26.25%] train loss: 1.4011608982400503e-05 \n",
      "epoch: 17 [234421/888800 26.38%] train loss: 1.5245819668052718e-05 \n",
      "epoch: 17 [235532/888800 26.50%] train loss: 1.2903714377898723e-05 \n",
      "epoch: 17 [236643/888800 26.62%] train loss: 1.3838945960742421e-05 \n",
      "epoch: 17 [237754/888800 26.75%] train loss: 1.4756750715605449e-05 \n",
      "epoch: 17 [238865/888800 26.88%] train loss: 1.327324025623966e-05 \n",
      "epoch: 17 [239976/888800 27.00%] train loss: 1.3008914720558096e-05 \n",
      "epoch: 17 [241087/888800 27.12%] train loss: 1.4122572792985011e-05 \n",
      "epoch: 17 [242198/888800 27.25%] train loss: 1.4346361240313854e-05 \n",
      "epoch: 17 [243309/888800 27.38%] train loss: 1.4108883078733925e-05 \n",
      "epoch: 17 [244420/888800 27.50%] train loss: 1.4100817679718602e-05 \n",
      "epoch: 17 [245531/888800 27.62%] train loss: 1.5802443158463575e-05 \n",
      "epoch: 17 [246642/888800 27.75%] train loss: 1.528383290860802e-05 \n",
      "epoch: 17 [247753/888800 27.88%] train loss: 1.3990488696435932e-05 \n",
      "epoch: 17 [248864/888800 28.00%] train loss: 1.4696934158564545e-05 \n",
      "epoch: 17 [249975/888800 28.12%] train loss: 1.3786392628389876e-05 \n",
      "epoch: 17 [251086/888800 28.25%] train loss: 1.3635347386298236e-05 \n",
      "epoch: 17 [252197/888800 28.38%] train loss: 1.439006064174464e-05 \n",
      "epoch: 17 [253308/888800 28.50%] train loss: 1.4494504284812137e-05 \n",
      "epoch: 17 [254419/888800 28.62%] train loss: 1.5117308976186905e-05 \n",
      "epoch: 17 [255530/888800 28.75%] train loss: 1.409874403179856e-05 \n",
      "epoch: 17 [256641/888800 28.88%] train loss: 1.3864891116099898e-05 \n",
      "epoch: 17 [257752/888800 29.00%] train loss: 1.4837087292107753e-05 \n",
      "epoch: 17 [258863/888800 29.12%] train loss: 1.353265452053165e-05 \n",
      "epoch: 17 [259974/888800 29.25%] train loss: 1.4842935343040153e-05 \n",
      "epoch: 17 [261085/888800 29.38%] train loss: 1.4194593859429006e-05 \n",
      "epoch: 17 [262196/888800 29.50%] train loss: 1.3878480785933789e-05 \n",
      "epoch: 17 [263307/888800 29.62%] train loss: 1.3481222595146392e-05 \n",
      "epoch: 17 [264418/888800 29.75%] train loss: 1.3139005204720888e-05 \n",
      "epoch: 17 [265529/888800 29.88%] train loss: 1.461069314245833e-05 \n",
      "epoch: 17 [266640/888800 30.00%] train loss: 1.4799438758927863e-05 \n",
      "epoch: 17 [267751/888800 30.12%] train loss: 1.4992378964961972e-05 \n",
      "epoch: 17 [268862/888800 30.25%] train loss: 1.4596090295526665e-05 \n",
      "epoch: 17 [269973/888800 30.38%] train loss: 1.3314036550582387e-05 \n",
      "epoch: 17 [271084/888800 30.50%] train loss: 1.4273196939029731e-05 \n",
      "epoch: 17 [272195/888800 30.62%] train loss: 1.349160447716713e-05 \n",
      "epoch: 17 [273306/888800 30.75%] train loss: 1.392442482028855e-05 \n",
      "epoch: 17 [274417/888800 30.88%] train loss: 1.4044097952137236e-05 \n",
      "epoch: 17 [275528/888800 31.00%] train loss: 1.3905174455430824e-05 \n",
      "epoch: 17 [276639/888800 31.12%] train loss: 1.3699856936000288e-05 \n",
      "epoch: 17 [277750/888800 31.25%] train loss: 1.4129842384136282e-05 \n",
      "epoch: 17 [278861/888800 31.38%] train loss: 1.397751384502044e-05 \n",
      "epoch: 17 [279972/888800 31.50%] train loss: 1.4181871847540606e-05 \n",
      "epoch: 17 [281083/888800 31.62%] train loss: 1.335971501248423e-05 \n",
      "epoch: 17 [282194/888800 31.75%] train loss: 1.4238345102057792e-05 \n",
      "epoch: 17 [283305/888800 31.88%] train loss: 1.4543296856572852e-05 \n",
      "epoch: 17 [284416/888800 32.00%] train loss: 1.524063918623142e-05 \n",
      "epoch: 17 [285527/888800 32.12%] train loss: 1.5665516912122257e-05 \n",
      "epoch: 17 [286638/888800 32.25%] train loss: 1.5384724974865094e-05 \n",
      "epoch: 17 [287749/888800 32.38%] train loss: 1.445405086997198e-05 \n",
      "epoch: 17 [288860/888800 32.50%] train loss: 1.2078636245860253e-05 \n",
      "epoch: 17 [289971/888800 32.62%] train loss: 1.3300133105076384e-05 \n",
      "epoch: 17 [291082/888800 32.75%] train loss: 1.3430088984023314e-05 \n",
      "epoch: 17 [292193/888800 32.88%] train loss: 1.3244299225334544e-05 \n",
      "epoch: 17 [293304/888800 33.00%] train loss: 1.3491357094608247e-05 \n",
      "epoch: 17 [294415/888800 33.12%] train loss: 1.375011106574675e-05 \n",
      "epoch: 17 [295526/888800 33.25%] train loss: 1.3377307368500624e-05 \n",
      "epoch: 17 [296637/888800 33.38%] train loss: 1.417026487615658e-05 \n",
      "epoch: 17 [297748/888800 33.50%] train loss: 1.4946864212106448e-05 \n",
      "epoch: 17 [298859/888800 33.62%] train loss: 1.49523284562747e-05 \n",
      "epoch: 17 [299970/888800 33.75%] train loss: 1.5226522918965202e-05 \n",
      "epoch: 17 [301081/888800 33.88%] train loss: 1.3813597433909308e-05 \n",
      "epoch: 17 [302192/888800 34.00%] train loss: 1.362657712888904e-05 \n",
      "epoch: 17 [303303/888800 34.12%] train loss: 1.4599875612475444e-05 \n",
      "epoch: 17 [304414/888800 34.25%] train loss: 1.3957494957139716e-05 \n",
      "epoch: 17 [305525/888800 34.38%] train loss: 1.5040056496218313e-05 \n",
      "epoch: 17 [306636/888800 34.50%] train loss: 1.3155504348105751e-05 \n",
      "epoch: 17 [307747/888800 34.62%] train loss: 1.4452181858359836e-05 \n",
      "epoch: 17 [308858/888800 34.75%] train loss: 1.3397474504017737e-05 \n",
      "epoch: 17 [309969/888800 34.88%] train loss: 1.4452963114308659e-05 \n",
      "epoch: 17 [311080/888800 35.00%] train loss: 1.3570631381298881e-05 \n",
      "epoch: 17 [312191/888800 35.12%] train loss: 1.5124431229196489e-05 \n",
      "epoch: 17 [313302/888800 35.25%] train loss: 1.3679182302439585e-05 \n",
      "epoch: 17 [314413/888800 35.38%] train loss: 1.5074335351528134e-05 \n",
      "epoch: 17 [315524/888800 35.50%] train loss: 1.4822273442405276e-05 \n",
      "epoch: 17 [316635/888800 35.62%] train loss: 1.5439172784681432e-05 \n",
      "epoch: 17 [317746/888800 35.75%] train loss: 1.3895976735511795e-05 \n",
      "epoch: 17 [318857/888800 35.88%] train loss: 1.4880009985063225e-05 \n",
      "epoch: 17 [319968/888800 36.00%] train loss: 1.4777631804463454e-05 \n",
      "epoch: 17 [321079/888800 36.12%] train loss: 1.5491947124246508e-05 \n",
      "epoch: 17 [322190/888800 36.25%] train loss: 1.2634635822905693e-05 \n",
      "epoch: 17 [323301/888800 36.38%] train loss: 1.5344005078077316e-05 \n",
      "epoch: 17 [324412/888800 36.50%] train loss: 1.3389464584179223e-05 \n",
      "epoch: 17 [325523/888800 36.62%] train loss: 1.5305777196772397e-05 \n",
      "epoch: 17 [326634/888800 36.75%] train loss: 1.5491767044295557e-05 \n",
      "epoch: 17 [327745/888800 36.88%] train loss: 1.4147982255963143e-05 \n",
      "epoch: 17 [328856/888800 37.00%] train loss: 1.4551617823599372e-05 \n",
      "epoch: 17 [329967/888800 37.12%] train loss: 1.4621324226027355e-05 \n",
      "epoch: 17 [331078/888800 37.25%] train loss: 1.4181890037434641e-05 \n",
      "epoch: 17 [332189/888800 37.38%] train loss: 1.3417266018223017e-05 \n",
      "epoch: 17 [333300/888800 37.50%] train loss: 1.3902817045163829e-05 \n",
      "epoch: 17 [334411/888800 37.62%] train loss: 1.5923591490718536e-05 \n",
      "epoch: 17 [335522/888800 37.75%] train loss: 1.321931995335035e-05 \n",
      "epoch: 17 [336633/888800 37.88%] train loss: 1.6096053514047526e-05 \n",
      "epoch: 17 [337744/888800 38.00%] train loss: 1.1931228073081002e-05 \n",
      "epoch: 17 [338855/888800 38.12%] train loss: 1.392573813063791e-05 \n",
      "epoch: 17 [339966/888800 38.25%] train loss: 1.3163129551685415e-05 \n",
      "epoch: 17 [341077/888800 38.38%] train loss: 1.3848133676219732e-05 \n",
      "epoch: 17 [342188/888800 38.50%] train loss: 1.4100177395448554e-05 \n",
      "epoch: 17 [343299/888800 38.62%] train loss: 1.5033233466965612e-05 \n",
      "epoch: 17 [344410/888800 38.75%] train loss: 1.3962247976451181e-05 \n",
      "epoch: 17 [345521/888800 38.88%] train loss: 1.4061278307053726e-05 \n",
      "epoch: 17 [346632/888800 39.00%] train loss: 1.4005168850417249e-05 \n",
      "epoch: 17 [347743/888800 39.12%] train loss: 1.2610080375452526e-05 \n",
      "epoch: 17 [348854/888800 39.25%] train loss: 1.4181620827002916e-05 \n",
      "epoch: 17 [349965/888800 39.38%] train loss: 1.4952747733332217e-05 \n",
      "epoch: 17 [351076/888800 39.50%] train loss: 1.5013833944976795e-05 \n",
      "epoch: 17 [352187/888800 39.62%] train loss: 1.438912204321241e-05 \n",
      "epoch: 17 [353298/888800 39.75%] train loss: 1.3450950973492581e-05 \n",
      "epoch: 17 [354409/888800 39.88%] train loss: 1.4365758943313267e-05 \n",
      "epoch: 17 [355520/888800 40.00%] train loss: 1.5686455299146473e-05 \n",
      "epoch: 17 [356631/888800 40.12%] train loss: 1.3277665857458487e-05 \n",
      "epoch: 17 [357742/888800 40.25%] train loss: 1.3470881640387233e-05 \n",
      "epoch: 17 [358853/888800 40.38%] train loss: 1.486658766225446e-05 \n",
      "epoch: 17 [359964/888800 40.50%] train loss: 1.4035112144483719e-05 \n",
      "epoch: 17 [361075/888800 40.62%] train loss: 1.4622833987232298e-05 \n",
      "epoch: 17 [362186/888800 40.75%] train loss: 1.4137230209598783e-05 \n",
      "epoch: 17 [363297/888800 40.88%] train loss: 1.3015328477194998e-05 \n",
      "epoch: 17 [364408/888800 41.00%] train loss: 1.4262529475672636e-05 \n",
      "epoch: 17 [365519/888800 41.12%] train loss: 1.423556841473328e-05 \n",
      "epoch: 17 [366630/888800 41.25%] train loss: 1.4081490007811226e-05 \n",
      "epoch: 17 [367741/888800 41.38%] train loss: 1.447148770239437e-05 \n",
      "epoch: 17 [368852/888800 41.50%] train loss: 1.3650491382577457e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [369963/888800 41.62%] train loss: 1.2937159226567019e-05 \n",
      "epoch: 17 [371074/888800 41.75%] train loss: 1.4113667930359952e-05 \n",
      "epoch: 17 [372185/888800 41.88%] train loss: 1.3962103366793599e-05 \n",
      "epoch: 17 [373296/888800 42.00%] train loss: 1.42036706165527e-05 \n",
      "epoch: 17 [374407/888800 42.12%] train loss: 1.5292362149921246e-05 \n",
      "epoch: 17 [375518/888800 42.25%] train loss: 1.4470074347627815e-05 \n",
      "epoch: 17 [376629/888800 42.38%] train loss: 1.3720792594540399e-05 \n",
      "epoch: 17 [377740/888800 42.50%] train loss: 1.452163269277662e-05 \n",
      "epoch: 17 [378851/888800 42.62%] train loss: 1.379759851261042e-05 \n",
      "epoch: 17 [379962/888800 42.75%] train loss: 1.571658685861621e-05 \n",
      "epoch: 17 [381073/888800 42.88%] train loss: 1.3304215826792642e-05 \n",
      "epoch: 17 [382184/888800 43.00%] train loss: 1.4069075405132025e-05 \n",
      "epoch: 17 [383295/888800 43.12%] train loss: 1.4502095837087836e-05 \n",
      "epoch: 17 [384406/888800 43.25%] train loss: 1.4804476450080983e-05 \n",
      "epoch: 17 [385517/888800 43.38%] train loss: 1.3034982657700311e-05 \n",
      "epoch: 17 [386628/888800 43.50%] train loss: 1.5422610886162147e-05 \n",
      "epoch: 17 [387739/888800 43.62%] train loss: 1.3975749425299e-05 \n",
      "epoch: 17 [388850/888800 43.75%] train loss: 1.4082248526392505e-05 \n",
      "epoch: 17 [389961/888800 43.88%] train loss: 1.2872980732936412e-05 \n",
      "epoch: 17 [391072/888800 44.00%] train loss: 1.4298802852863446e-05 \n",
      "epoch: 17 [392183/888800 44.12%] train loss: 1.3773789760307409e-05 \n",
      "epoch: 17 [393294/888800 44.25%] train loss: 1.4398773600987624e-05 \n",
      "epoch: 17 [394405/888800 44.38%] train loss: 1.3829715499014128e-05 \n",
      "epoch: 17 [395516/888800 44.50%] train loss: 1.372921633446822e-05 \n",
      "epoch: 17 [396627/888800 44.62%] train loss: 1.3499831766239367e-05 \n",
      "epoch: 17 [397738/888800 44.75%] train loss: 1.3261555977805983e-05 \n",
      "epoch: 17 [398849/888800 44.88%] train loss: 1.4435215234698262e-05 \n",
      "epoch: 17 [399960/888800 45.00%] train loss: 1.4237919458537363e-05 \n",
      "epoch: 17 [401071/888800 45.12%] train loss: 1.5076768249855377e-05 \n",
      "epoch: 17 [402182/888800 45.25%] train loss: 1.4885408745612949e-05 \n",
      "epoch: 17 [403293/888800 45.38%] train loss: 1.3417884474620223e-05 \n",
      "epoch: 17 [404404/888800 45.50%] train loss: 1.3982108612253796e-05 \n",
      "epoch: 17 [405515/888800 45.62%] train loss: 1.4007943718752358e-05 \n",
      "epoch: 17 [406626/888800 45.75%] train loss: 1.5005171007942408e-05 \n",
      "epoch: 17 [407737/888800 45.88%] train loss: 1.420223998138681e-05 \n",
      "epoch: 17 [408848/888800 46.00%] train loss: 1.4671162716695108e-05 \n",
      "epoch: 17 [409959/888800 46.12%] train loss: 1.3413202395895496e-05 \n",
      "epoch: 17 [411070/888800 46.25%] train loss: 1.1881619684572797e-05 \n",
      "epoch: 17 [412181/888800 46.38%] train loss: 1.3133231732354034e-05 \n",
      "epoch: 17 [413292/888800 46.50%] train loss: 1.3614397175842896e-05 \n",
      "epoch: 17 [414403/888800 46.62%] train loss: 1.4954217476770282e-05 \n",
      "epoch: 17 [415514/888800 46.75%] train loss: 1.395638446410885e-05 \n",
      "epoch: 17 [416625/888800 46.88%] train loss: 1.4012866813573055e-05 \n",
      "epoch: 17 [417736/888800 47.00%] train loss: 1.3518842024495825e-05 \n",
      "epoch: 17 [418847/888800 47.12%] train loss: 1.3911999303672928e-05 \n",
      "epoch: 17 [419958/888800 47.25%] train loss: 1.5444453310919926e-05 \n",
      "epoch: 17 [421069/888800 47.38%] train loss: 1.3374406080401968e-05 \n",
      "epoch: 17 [422180/888800 47.50%] train loss: 1.4798023585171904e-05 \n",
      "epoch: 17 [423291/888800 47.62%] train loss: 1.5122251170396339e-05 \n",
      "epoch: 17 [424402/888800 47.75%] train loss: 1.4584596101485658e-05 \n",
      "epoch: 17 [425513/888800 47.88%] train loss: 1.3812615179631393e-05 \n",
      "epoch: 17 [426624/888800 48.00%] train loss: 1.3250139090814628e-05 \n",
      "epoch: 17 [427735/888800 48.12%] train loss: 1.377160970150726e-05 \n",
      "epoch: 17 [428846/888800 48.25%] train loss: 1.3869252143194899e-05 \n",
      "epoch: 17 [429957/888800 48.38%] train loss: 1.37925608214573e-05 \n",
      "epoch: 17 [431068/888800 48.50%] train loss: 1.4663779438706115e-05 \n",
      "epoch: 17 [432179/888800 48.62%] train loss: 1.4648304386355449e-05 \n",
      "epoch: 17 [433290/888800 48.75%] train loss: 1.402237012371188e-05 \n",
      "epoch: 17 [434401/888800 48.88%] train loss: 1.3621403923025355e-05 \n",
      "epoch: 17 [435512/888800 49.00%] train loss: 1.4098834071774036e-05 \n",
      "epoch: 17 [436623/888800 49.12%] train loss: 1.3955172107671387e-05 \n",
      "epoch: 17 [437734/888800 49.25%] train loss: 1.4085054317547474e-05 \n",
      "epoch: 17 [438845/888800 49.38%] train loss: 1.3230016520537902e-05 \n",
      "epoch: 17 [439956/888800 49.50%] train loss: 1.4535905393131543e-05 \n",
      "epoch: 17 [441067/888800 49.62%] train loss: 1.3809148185828235e-05 \n",
      "epoch: 17 [442178/888800 49.75%] train loss: 1.3444914657156914e-05 \n",
      "epoch: 17 [443289/888800 49.88%] train loss: 1.4714981261931825e-05 \n",
      "epoch: 17 [444400/888800 50.00%] train loss: 1.4082527741265949e-05 \n",
      "epoch: 17 [445511/888800 50.12%] train loss: 1.291234639211325e-05 \n",
      "epoch: 17 [446622/888800 50.25%] train loss: 1.4824235222477e-05 \n",
      "epoch: 17 [447733/888800 50.38%] train loss: 1.4365571587404702e-05 \n",
      "epoch: 17 [448844/888800 50.50%] train loss: 1.5678628187743016e-05 \n",
      "epoch: 17 [449955/888800 50.62%] train loss: 1.2752363545587286e-05 \n",
      "epoch: 17 [451066/888800 50.75%] train loss: 1.340167727903463e-05 \n",
      "epoch: 17 [452177/888800 50.88%] train loss: 1.4973265024309512e-05 \n",
      "epoch: 17 [453288/888800 51.00%] train loss: 1.3819546438753605e-05 \n",
      "epoch: 17 [454399/888800 51.12%] train loss: 1.3304446838446893e-05 \n",
      "epoch: 17 [455510/888800 51.25%] train loss: 1.4354093764268328e-05 \n",
      "epoch: 17 [456621/888800 51.38%] train loss: 1.3353412214200944e-05 \n",
      "epoch: 17 [457732/888800 51.50%] train loss: 1.5526597053394653e-05 \n",
      "epoch: 17 [458843/888800 51.62%] train loss: 1.3696691894438118e-05 \n",
      "epoch: 17 [459954/888800 51.75%] train loss: 1.3918580407334957e-05 \n",
      "epoch: 17 [461065/888800 51.88%] train loss: 1.3830462194164284e-05 \n",
      "epoch: 17 [462176/888800 52.00%] train loss: 1.4157741134113166e-05 \n",
      "epoch: 17 [463287/888800 52.12%] train loss: 1.477020668971818e-05 \n",
      "epoch: 17 [464398/888800 52.25%] train loss: 1.459226587030571e-05 \n",
      "epoch: 17 [465509/888800 52.38%] train loss: 1.3977435628476087e-05 \n",
      "epoch: 17 [466620/888800 52.50%] train loss: 1.3368025975069031e-05 \n",
      "epoch: 17 [467731/888800 52.62%] train loss: 1.3470554222294595e-05 \n",
      "epoch: 17 [468842/888800 52.75%] train loss: 1.4909433957654983e-05 \n",
      "epoch: 17 [469953/888800 52.88%] train loss: 1.4053181985218544e-05 \n",
      "epoch: 17 [471064/888800 53.00%] train loss: 1.330224949924741e-05 \n",
      "epoch: 17 [472175/888800 53.12%] train loss: 1.4766090316697955e-05 \n",
      "epoch: 17 [473286/888800 53.25%] train loss: 1.547326428408269e-05 \n",
      "epoch: 17 [474397/888800 53.38%] train loss: 1.396718744217651e-05 \n",
      "epoch: 17 [475508/888800 53.50%] train loss: 1.4705240573675837e-05 \n",
      "epoch: 17 [476619/888800 53.62%] train loss: 1.4304511751106475e-05 \n",
      "epoch: 17 [477730/888800 53.75%] train loss: 1.5138710296014324e-05 \n",
      "epoch: 17 [478841/888800 53.88%] train loss: 1.4680311323900241e-05 \n",
      "epoch: 17 [479952/888800 54.00%] train loss: 1.3887572094972711e-05 \n",
      "epoch: 17 [481063/888800 54.12%] train loss: 1.4214135262591299e-05 \n",
      "epoch: 17 [482174/888800 54.25%] train loss: 1.4470992937276606e-05 \n",
      "epoch: 17 [483285/888800 54.38%] train loss: 1.4924522474757396e-05 \n",
      "epoch: 17 [484396/888800 54.50%] train loss: 1.45504009196884e-05 \n",
      "epoch: 17 [485507/888800 54.62%] train loss: 1.484918720962014e-05 \n",
      "epoch: 17 [486618/888800 54.75%] train loss: 1.4800069038756192e-05 \n",
      "epoch: 17 [487729/888800 54.88%] train loss: 1.400840665155556e-05 \n",
      "epoch: 17 [488840/888800 55.00%] train loss: 1.606715341040399e-05 \n",
      "epoch: 17 [489951/888800 55.12%] train loss: 1.4945522707421333e-05 \n",
      "epoch: 17 [491062/888800 55.25%] train loss: 1.4134216144157108e-05 \n",
      "epoch: 17 [492173/888800 55.38%] train loss: 1.3508715710486285e-05 \n",
      "epoch: 17 [493284/888800 55.50%] train loss: 1.4427798305405304e-05 \n",
      "epoch: 17 [494395/888800 55.62%] train loss: 1.2924097063660156e-05 \n",
      "epoch: 17 [495506/888800 55.75%] train loss: 1.5479674402740784e-05 \n",
      "epoch: 17 [496617/888800 55.88%] train loss: 1.3813842997478787e-05 \n",
      "epoch: 17 [497728/888800 56.00%] train loss: 1.3653097084898036e-05 \n",
      "epoch: 17 [498839/888800 56.12%] train loss: 1.3914921510149725e-05 \n",
      "epoch: 17 [499950/888800 56.25%] train loss: 1.3618621778732631e-05 \n",
      "epoch: 17 [501061/888800 56.38%] train loss: 1.5863641237956472e-05 \n",
      "epoch: 17 [502172/888800 56.50%] train loss: 1.5834824807825498e-05 \n",
      "epoch: 17 [503283/888800 56.62%] train loss: 1.4280261893873103e-05 \n",
      "epoch: 17 [504394/888800 56.75%] train loss: 1.4847028978692833e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [505505/888800 56.88%] train loss: 1.4362814908963628e-05 \n",
      "epoch: 17 [506616/888800 57.00%] train loss: 1.3289009075378999e-05 \n",
      "epoch: 17 [507727/888800 57.12%] train loss: 1.4660957276646513e-05 \n",
      "epoch: 17 [508838/888800 57.25%] train loss: 1.42959579534363e-05 \n",
      "epoch: 17 [509949/888800 57.38%] train loss: 1.4607423509005457e-05 \n",
      "epoch: 17 [511060/888800 57.50%] train loss: 1.4842906239209697e-05 \n",
      "epoch: 17 [512171/888800 57.62%] train loss: 1.3664155630976893e-05 \n",
      "epoch: 17 [513282/888800 57.75%] train loss: 1.6492344002472237e-05 \n",
      "epoch: 17 [514393/888800 57.88%] train loss: 1.4390293472388294e-05 \n",
      "epoch: 17 [515504/888800 58.00%] train loss: 1.4667421964986715e-05 \n",
      "epoch: 17 [516615/888800 58.12%] train loss: 1.4306281627796125e-05 \n",
      "epoch: 17 [517726/888800 58.25%] train loss: 1.432564931747038e-05 \n",
      "epoch: 17 [518837/888800 58.38%] train loss: 1.4136255231278483e-05 \n",
      "epoch: 17 [519948/888800 58.50%] train loss: 1.3875246622774284e-05 \n",
      "epoch: 17 [521059/888800 58.62%] train loss: 1.5162787349254359e-05 \n",
      "epoch: 17 [522170/888800 58.75%] train loss: 1.5428815459017642e-05 \n",
      "epoch: 17 [523281/888800 58.88%] train loss: 1.454196262784535e-05 \n",
      "epoch: 17 [524392/888800 59.00%] train loss: 1.546428211440798e-05 \n",
      "epoch: 17 [525503/888800 59.12%] train loss: 1.4062165064387955e-05 \n",
      "epoch: 17 [526614/888800 59.25%] train loss: 1.3527782357414253e-05 \n",
      "epoch: 17 [527725/888800 59.38%] train loss: 1.4771138921787497e-05 \n",
      "epoch: 17 [528836/888800 59.50%] train loss: 1.4211352208803874e-05 \n",
      "epoch: 17 [529947/888800 59.62%] train loss: 1.499227528256597e-05 \n",
      "epoch: 17 [531058/888800 59.75%] train loss: 1.3490227502188645e-05 \n",
      "epoch: 17 [532169/888800 59.88%] train loss: 1.3532422599382699e-05 \n",
      "epoch: 17 [533280/888800 60.00%] train loss: 1.4055757674213964e-05 \n",
      "epoch: 17 [534391/888800 60.12%] train loss: 1.2715864613710437e-05 \n",
      "epoch: 17 [535502/888800 60.25%] train loss: 1.508196692157071e-05 \n",
      "epoch: 17 [536613/888800 60.38%] train loss: 1.4343702787300572e-05 \n",
      "epoch: 17 [537724/888800 60.50%] train loss: 1.4941326298867352e-05 \n",
      "epoch: 17 [538835/888800 60.62%] train loss: 1.4157567420625128e-05 \n",
      "epoch: 17 [539946/888800 60.75%] train loss: 1.510716447228333e-05 \n",
      "epoch: 17 [541057/888800 60.88%] train loss: 1.533621980343014e-05 \n",
      "epoch: 17 [542168/888800 61.00%] train loss: 1.4015373380971141e-05 \n",
      "epoch: 17 [543279/888800 61.12%] train loss: 1.3554164979723282e-05 \n",
      "epoch: 17 [544390/888800 61.25%] train loss: 1.4086286682868376e-05 \n",
      "epoch: 17 [545501/888800 61.38%] train loss: 1.4347035175887868e-05 \n",
      "epoch: 17 [546612/888800 61.50%] train loss: 1.3964579011371825e-05 \n",
      "epoch: 17 [547723/888800 61.62%] train loss: 1.441813128622016e-05 \n",
      "epoch: 17 [548834/888800 61.75%] train loss: 1.4636994819738902e-05 \n",
      "epoch: 17 [549945/888800 61.88%] train loss: 1.4477050171990413e-05 \n",
      "epoch: 17 [551056/888800 62.00%] train loss: 1.5146537407417782e-05 \n",
      "epoch: 17 [552167/888800 62.12%] train loss: 1.3396710528468248e-05 \n",
      "epoch: 17 [553278/888800 62.25%] train loss: 1.4136959180177655e-05 \n",
      "epoch: 17 [554389/888800 62.38%] train loss: 1.4899037523719016e-05 \n",
      "epoch: 17 [555500/888800 62.50%] train loss: 1.422363129677251e-05 \n",
      "epoch: 17 [556611/888800 62.62%] train loss: 1.3920476703788154e-05 \n",
      "epoch: 17 [557722/888800 62.75%] train loss: 1.3131370906194206e-05 \n",
      "epoch: 17 [558833/888800 62.88%] train loss: 1.6258594769169576e-05 \n",
      "epoch: 17 [559944/888800 63.00%] train loss: 1.301565771427704e-05 \n",
      "epoch: 17 [561055/888800 63.12%] train loss: 1.4373766134667676e-05 \n",
      "epoch: 17 [562166/888800 63.25%] train loss: 1.486482779000653e-05 \n",
      "epoch: 17 [563277/888800 63.38%] train loss: 1.3803655747324228e-05 \n",
      "epoch: 17 [564388/888800 63.50%] train loss: 1.5272915334207937e-05 \n",
      "epoch: 17 [565499/888800 63.62%] train loss: 1.3864737411495298e-05 \n",
      "epoch: 17 [566610/888800 63.75%] train loss: 1.4891082173562609e-05 \n",
      "epoch: 17 [567721/888800 63.88%] train loss: 1.580554453539662e-05 \n",
      "epoch: 17 [568832/888800 64.00%] train loss: 1.427073402737733e-05 \n",
      "epoch: 17 [569943/888800 64.12%] train loss: 1.5615458323736675e-05 \n",
      "epoch: 17 [571054/888800 64.25%] train loss: 1.4665190974483266e-05 \n",
      "epoch: 17 [572165/888800 64.38%] train loss: 1.4434237527893856e-05 \n",
      "epoch: 17 [573276/888800 64.50%] train loss: 1.4322923561849166e-05 \n",
      "epoch: 17 [574387/888800 64.62%] train loss: 1.4204843864717986e-05 \n",
      "epoch: 17 [575498/888800 64.75%] train loss: 1.4575386558135506e-05 \n",
      "epoch: 17 [576609/888800 64.88%] train loss: 1.3987832971906755e-05 \n",
      "epoch: 17 [577720/888800 65.00%] train loss: 1.3289778507896699e-05 \n",
      "epoch: 17 [578831/888800 65.12%] train loss: 1.3222833331383299e-05 \n",
      "epoch: 17 [579942/888800 65.25%] train loss: 1.5361041732830927e-05 \n",
      "epoch: 17 [581053/888800 65.38%] train loss: 1.3173409570299555e-05 \n",
      "epoch: 17 [582164/888800 65.50%] train loss: 1.474257715017302e-05 \n",
      "epoch: 17 [583275/888800 65.62%] train loss: 1.3911900168750435e-05 \n",
      "epoch: 17 [584386/888800 65.75%] train loss: 1.3252801181806717e-05 \n",
      "epoch: 17 [585497/888800 65.88%] train loss: 1.2473145943658892e-05 \n",
      "epoch: 17 [586608/888800 66.00%] train loss: 1.2829438674089033e-05 \n",
      "epoch: 17 [587719/888800 66.12%] train loss: 1.4798610209254548e-05 \n",
      "epoch: 17 [588830/888800 66.25%] train loss: 1.3418922208074946e-05 \n",
      "epoch: 17 [589941/888800 66.38%] train loss: 1.4301685041573364e-05 \n",
      "epoch: 17 [591052/888800 66.50%] train loss: 1.441633594367886e-05 \n",
      "epoch: 17 [592163/888800 66.62%] train loss: 1.3803029105474707e-05 \n",
      "epoch: 17 [593274/888800 66.75%] train loss: 1.3161759852664545e-05 \n",
      "epoch: 17 [594385/888800 66.88%] train loss: 1.430892098142067e-05 \n",
      "epoch: 17 [595496/888800 67.00%] train loss: 1.3035858501098119e-05 \n",
      "epoch: 17 [596607/888800 67.12%] train loss: 1.5205136151053011e-05 \n",
      "epoch: 17 [597718/888800 67.25%] train loss: 1.5381005141534843e-05 \n",
      "epoch: 17 [598829/888800 67.38%] train loss: 1.3791757737635635e-05 \n",
      "epoch: 17 [599940/888800 67.50%] train loss: 1.488315683673136e-05 \n",
      "epoch: 17 [601051/888800 67.62%] train loss: 1.4275319699663669e-05 \n",
      "epoch: 17 [602162/888800 67.75%] train loss: 1.5592218915116973e-05 \n",
      "epoch: 17 [603273/888800 67.88%] train loss: 1.4862788702885155e-05 \n",
      "epoch: 17 [604384/888800 68.00%] train loss: 1.6220581528614275e-05 \n",
      "epoch: 17 [605495/888800 68.12%] train loss: 1.5757237633806653e-05 \n",
      "epoch: 17 [606606/888800 68.25%] train loss: 1.4685869246022776e-05 \n",
      "epoch: 17 [607717/888800 68.38%] train loss: 1.4370436474564485e-05 \n",
      "epoch: 17 [608828/888800 68.50%] train loss: 1.4289092177932616e-05 \n",
      "epoch: 17 [609939/888800 68.62%] train loss: 1.5733634427306242e-05 \n",
      "epoch: 17 [611050/888800 68.75%] train loss: 1.4894471860316116e-05 \n",
      "epoch: 17 [612161/888800 68.88%] train loss: 1.4786291103519034e-05 \n",
      "epoch: 17 [613272/888800 69.00%] train loss: 1.392638478137087e-05 \n",
      "epoch: 17 [614383/888800 69.12%] train loss: 1.4935956642148085e-05 \n",
      "epoch: 17 [615494/888800 69.25%] train loss: 1.4589008060283959e-05 \n",
      "epoch: 17 [616605/888800 69.38%] train loss: 1.3522208973881789e-05 \n",
      "epoch: 17 [617716/888800 69.50%] train loss: 1.4149069102131762e-05 \n",
      "epoch: 17 [618827/888800 69.62%] train loss: 1.3745591786573641e-05 \n",
      "epoch: 17 [619938/888800 69.75%] train loss: 1.4748294233868364e-05 \n",
      "epoch: 17 [621049/888800 69.88%] train loss: 1.3520061656890903e-05 \n",
      "epoch: 17 [622160/888800 70.00%] train loss: 1.51526000990998e-05 \n",
      "epoch: 17 [623271/888800 70.12%] train loss: 1.4486155123449862e-05 \n",
      "epoch: 17 [624382/888800 70.25%] train loss: 1.4766517779207788e-05 \n",
      "epoch: 17 [625493/888800 70.38%] train loss: 1.4632122656621505e-05 \n",
      "epoch: 17 [626604/888800 70.50%] train loss: 1.5495183106395416e-05 \n",
      "epoch: 17 [627715/888800 70.62%] train loss: 1.3989010767545551e-05 \n",
      "epoch: 17 [628826/888800 70.75%] train loss: 1.4919311979610939e-05 \n",
      "epoch: 17 [629937/888800 70.88%] train loss: 1.381660422339337e-05 \n",
      "epoch: 17 [631048/888800 71.00%] train loss: 1.3370068700169213e-05 \n",
      "epoch: 17 [632159/888800 71.12%] train loss: 1.3806603419652674e-05 \n",
      "epoch: 17 [633270/888800 71.25%] train loss: 1.3120238691044506e-05 \n",
      "epoch: 17 [634381/888800 71.38%] train loss: 1.3734233107243199e-05 \n",
      "epoch: 17 [635492/888800 71.50%] train loss: 1.4537495189870242e-05 \n",
      "epoch: 17 [636603/888800 71.62%] train loss: 1.4021214155945927e-05 \n",
      "epoch: 17 [637714/888800 71.75%] train loss: 1.3223897440184373e-05 \n",
      "epoch: 17 [638825/888800 71.88%] train loss: 1.4284967619460076e-05 \n",
      "epoch: 17 [639936/888800 72.00%] train loss: 1.494346452091122e-05 \n",
      "epoch: 17 [641047/888800 72.12%] train loss: 1.440701544197509e-05 \n",
      "epoch: 17 [642158/888800 72.25%] train loss: 1.3411779946181923e-05 \n",
      "epoch: 17 [643269/888800 72.38%] train loss: 1.4469034795183688e-05 \n",
      "epoch: 17 [644380/888800 72.50%] train loss: 1.3841337931808084e-05 \n",
      "epoch: 17 [645491/888800 72.62%] train loss: 1.2799820069631096e-05 \n",
      "epoch: 17 [646602/888800 72.75%] train loss: 1.4177565390127711e-05 \n",
      "epoch: 17 [647713/888800 72.88%] train loss: 1.4099895452091005e-05 \n",
      "epoch: 17 [648824/888800 73.00%] train loss: 1.4205925253918394e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [649935/888800 73.12%] train loss: 1.4843823919363786e-05 \n",
      "epoch: 17 [651046/888800 73.25%] train loss: 1.443681503587868e-05 \n",
      "epoch: 17 [652157/888800 73.38%] train loss: 1.57231479533948e-05 \n",
      "epoch: 17 [653268/888800 73.50%] train loss: 1.3891467460780405e-05 \n",
      "epoch: 17 [654379/888800 73.62%] train loss: 1.5256395272444934e-05 \n",
      "epoch: 17 [655490/888800 73.75%] train loss: 1.550809247419238e-05 \n",
      "epoch: 17 [656601/888800 73.88%] train loss: 1.4246325008571148e-05 \n",
      "epoch: 17 [657712/888800 74.00%] train loss: 1.683415030129254e-05 \n",
      "epoch: 17 [658823/888800 74.12%] train loss: 1.3511051292880438e-05 \n",
      "epoch: 17 [659934/888800 74.25%] train loss: 1.6100428183563054e-05 \n",
      "epoch: 17 [661045/888800 74.38%] train loss: 1.593159140611533e-05 \n",
      "epoch: 17 [662156/888800 74.50%] train loss: 1.47152759382152e-05 \n",
      "epoch: 17 [663267/888800 74.62%] train loss: 1.6366388081223704e-05 \n",
      "epoch: 17 [664378/888800 74.75%] train loss: 1.605106626811903e-05 \n",
      "epoch: 17 [665489/888800 74.88%] train loss: 1.627385245228652e-05 \n",
      "epoch: 17 [666600/888800 75.00%] train loss: 1.3967504855827428e-05 \n",
      "epoch: 17 [667711/888800 75.12%] train loss: 1.5515444829361513e-05 \n",
      "epoch: 17 [668822/888800 75.25%] train loss: 1.3526691873266827e-05 \n",
      "epoch: 17 [669933/888800 75.38%] train loss: 1.4639760593126994e-05 \n",
      "epoch: 17 [671044/888800 75.50%] train loss: 1.4037182154424954e-05 \n",
      "epoch: 17 [672155/888800 75.62%] train loss: 1.4925959476386197e-05 \n",
      "epoch: 17 [673266/888800 75.75%] train loss: 1.54856843437301e-05 \n",
      "epoch: 17 [674377/888800 75.88%] train loss: 1.4020260096003767e-05 \n",
      "epoch: 17 [675488/888800 76.00%] train loss: 1.5054210052767303e-05 \n",
      "epoch: 17 [676599/888800 76.12%] train loss: 1.3545470210374333e-05 \n",
      "epoch: 17 [677710/888800 76.25%] train loss: 1.4205244951881468e-05 \n",
      "epoch: 17 [678821/888800 76.38%] train loss: 1.3407766346063e-05 \n",
      "epoch: 17 [679932/888800 76.50%] train loss: 1.4066870789974928e-05 \n",
      "epoch: 17 [681043/888800 76.62%] train loss: 1.538112701382488e-05 \n",
      "epoch: 17 [682154/888800 76.75%] train loss: 1.5030884242150933e-05 \n",
      "epoch: 17 [683265/888800 76.88%] train loss: 1.3729255442740396e-05 \n",
      "epoch: 17 [684376/888800 77.00%] train loss: 1.4871658095216844e-05 \n",
      "epoch: 17 [685487/888800 77.12%] train loss: 1.4411434676731005e-05 \n",
      "epoch: 17 [686598/888800 77.25%] train loss: 1.5795203580637462e-05 \n",
      "epoch: 17 [687709/888800 77.38%] train loss: 1.4963579815230332e-05 \n",
      "epoch: 17 [688820/888800 77.50%] train loss: 1.5059927136462647e-05 \n",
      "epoch: 17 [689931/888800 77.62%] train loss: 1.4001713680045214e-05 \n",
      "epoch: 17 [691042/888800 77.75%] train loss: 1.4081032531976234e-05 \n",
      "epoch: 17 [692153/888800 77.88%] train loss: 1.6361493180738762e-05 \n",
      "epoch: 17 [693264/888800 78.00%] train loss: 1.424776746716816e-05 \n",
      "epoch: 17 [694375/888800 78.12%] train loss: 1.5488250937778503e-05 \n",
      "epoch: 17 [695486/888800 78.25%] train loss: 1.594562127138488e-05 \n",
      "epoch: 17 [696597/888800 78.38%] train loss: 1.3956265320302919e-05 \n",
      "epoch: 17 [697708/888800 78.50%] train loss: 1.5370495020761155e-05 \n",
      "epoch: 17 [698819/888800 78.62%] train loss: 1.2767489351972472e-05 \n",
      "epoch: 17 [699930/888800 78.75%] train loss: 1.6210540707106702e-05 \n",
      "epoch: 17 [701041/888800 78.88%] train loss: 1.5254997379088309e-05 \n",
      "epoch: 17 [702152/888800 79.00%] train loss: 1.3811540156893898e-05 \n",
      "epoch: 17 [703263/888800 79.12%] train loss: 1.8351387552684173e-05 \n",
      "epoch: 17 [704374/888800 79.25%] train loss: 1.3990203115099575e-05 \n",
      "epoch: 17 [705485/888800 79.38%] train loss: 1.6547201084904373e-05 \n",
      "epoch: 17 [706596/888800 79.50%] train loss: 1.5323219486162998e-05 \n",
      "epoch: 17 [707707/888800 79.62%] train loss: 1.5281475498341024e-05 \n",
      "epoch: 17 [708818/888800 79.75%] train loss: 1.6945748939178884e-05 \n",
      "epoch: 17 [709929/888800 79.88%] train loss: 1.4321796697913669e-05 \n",
      "epoch: 17 [711040/888800 80.00%] train loss: 1.5345593055826612e-05 \n",
      "epoch: 17 [712151/888800 80.12%] train loss: 1.329971019004006e-05 \n",
      "epoch: 17 [713262/888800 80.25%] train loss: 1.5427202015416697e-05 \n",
      "epoch: 17 [714373/888800 80.38%] train loss: 1.394737591908779e-05 \n",
      "epoch: 17 [715484/888800 80.50%] train loss: 1.5457892004633322e-05 \n",
      "epoch: 17 [716595/888800 80.62%] train loss: 1.406591218255926e-05 \n",
      "epoch: 17 [717706/888800 80.75%] train loss: 1.3768926692137029e-05 \n",
      "epoch: 17 [718817/888800 80.88%] train loss: 1.6043815776356496e-05 \n",
      "epoch: 17 [719928/888800 81.00%] train loss: 1.394393893860979e-05 \n",
      "epoch: 17 [721039/888800 81.12%] train loss: 1.425521077180747e-05 \n",
      "epoch: 17 [722150/888800 81.25%] train loss: 1.4597198060073424e-05 \n",
      "epoch: 17 [723261/888800 81.38%] train loss: 1.3610455425805412e-05 \n",
      "epoch: 17 [724372/888800 81.50%] train loss: 1.3585129636339843e-05 \n",
      "epoch: 17 [725483/888800 81.62%] train loss: 1.4486582585959695e-05 \n",
      "epoch: 17 [726594/888800 81.75%] train loss: 1.3361958735913504e-05 \n",
      "epoch: 17 [727705/888800 81.88%] train loss: 1.4800521967117675e-05 \n",
      "epoch: 17 [728816/888800 82.00%] train loss: 1.3911241694586352e-05 \n",
      "epoch: 17 [729927/888800 82.12%] train loss: 1.5235775208566338e-05 \n",
      "epoch: 17 [731038/888800 82.25%] train loss: 1.3773029422736727e-05 \n",
      "epoch: 17 [732149/888800 82.38%] train loss: 1.613494532648474e-05 \n",
      "epoch: 17 [733260/888800 82.50%] train loss: 1.3033553841523826e-05 \n",
      "epoch: 17 [734371/888800 82.62%] train loss: 1.4370780263561755e-05 \n",
      "epoch: 17 [735482/888800 82.75%] train loss: 1.466089361201739e-05 \n",
      "epoch: 17 [736593/888800 82.88%] train loss: 1.4558488146576565e-05 \n",
      "epoch: 17 [737704/888800 83.00%] train loss: 1.4086798728385475e-05 \n",
      "epoch: 17 [738815/888800 83.12%] train loss: 1.394150694977725e-05 \n",
      "epoch: 17 [739926/888800 83.25%] train loss: 1.402908492309507e-05 \n",
      "epoch: 17 [741037/888800 83.38%] train loss: 1.4046990145288873e-05 \n",
      "epoch: 17 [742148/888800 83.50%] train loss: 1.2936736311530694e-05 \n",
      "epoch: 17 [743259/888800 83.62%] train loss: 1.5464846001123078e-05 \n",
      "epoch: 17 [744370/888800 83.75%] train loss: 1.4857983842375688e-05 \n",
      "epoch: 17 [745481/888800 83.88%] train loss: 1.4946816918381955e-05 \n",
      "epoch: 17 [746592/888800 84.00%] train loss: 1.4317343811853789e-05 \n",
      "epoch: 17 [747703/888800 84.12%] train loss: 1.3943029443908017e-05 \n",
      "epoch: 17 [748814/888800 84.25%] train loss: 1.4738368918187916e-05 \n",
      "epoch: 17 [749925/888800 84.38%] train loss: 1.4152280527923722e-05 \n",
      "epoch: 17 [751036/888800 84.50%] train loss: 1.514910672995029e-05 \n",
      "epoch: 17 [752147/888800 84.62%] train loss: 1.372962742607342e-05 \n",
      "epoch: 17 [753258/888800 84.75%] train loss: 1.361884187645046e-05 \n",
      "epoch: 17 [754369/888800 84.88%] train loss: 1.4139978702587541e-05 \n",
      "epoch: 17 [755480/888800 85.00%] train loss: 1.4720728358952329e-05 \n",
      "epoch: 17 [756591/888800 85.12%] train loss: 1.4564971934305504e-05 \n",
      "epoch: 17 [757702/888800 85.25%] train loss: 1.3085091268294491e-05 \n",
      "epoch: 17 [758813/888800 85.38%] train loss: 1.306487865804229e-05 \n",
      "epoch: 17 [759924/888800 85.50%] train loss: 1.4951821867725812e-05 \n",
      "epoch: 17 [761035/888800 85.62%] train loss: 1.5163966963882558e-05 \n",
      "epoch: 17 [762146/888800 85.75%] train loss: 1.3448178833641578e-05 \n",
      "epoch: 17 [763257/888800 85.88%] train loss: 1.542731661174912e-05 \n",
      "epoch: 17 [764368/888800 86.00%] train loss: 1.454955963708926e-05 \n",
      "epoch: 17 [765479/888800 86.12%] train loss: 1.3890819900552742e-05 \n",
      "epoch: 17 [766590/888800 86.25%] train loss: 1.4535084119415842e-05 \n",
      "epoch: 17 [767701/888800 86.38%] train loss: 1.4208049833541736e-05 \n",
      "epoch: 17 [768812/888800 86.50%] train loss: 1.4065350114833564e-05 \n",
      "epoch: 17 [769923/888800 86.62%] train loss: 1.4476530850515701e-05 \n",
      "epoch: 17 [771034/888800 86.75%] train loss: 1.3924480299465358e-05 \n",
      "epoch: 17 [772145/888800 86.88%] train loss: 1.473965312470682e-05 \n",
      "epoch: 17 [773256/888800 87.00%] train loss: 1.493180388933979e-05 \n",
      "epoch: 17 [774367/888800 87.12%] train loss: 1.3827370821672957e-05 \n",
      "epoch: 17 [775478/888800 87.25%] train loss: 1.402711495757103e-05 \n",
      "epoch: 17 [776589/888800 87.38%] train loss: 1.4586996258003637e-05 \n",
      "epoch: 17 [777700/888800 87.50%] train loss: 1.4184463907440659e-05 \n",
      "epoch: 17 [778811/888800 87.62%] train loss: 1.324327149632154e-05 \n",
      "epoch: 17 [779922/888800 87.75%] train loss: 1.3667198800249025e-05 \n",
      "epoch: 17 [781033/888800 87.88%] train loss: 1.3720919923798647e-05 \n",
      "epoch: 17 [782144/888800 88.00%] train loss: 1.4487848602584563e-05 \n",
      "epoch: 17 [783255/888800 88.12%] train loss: 1.4886674762237817e-05 \n",
      "epoch: 17 [784366/888800 88.25%] train loss: 1.3489832781488076e-05 \n",
      "epoch: 17 [785477/888800 88.38%] train loss: 1.4599728274333756e-05 \n",
      "epoch: 17 [786588/888800 88.50%] train loss: 1.4105991795076989e-05 \n",
      "epoch: 17 [787699/888800 88.62%] train loss: 1.386025451211026e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 [788810/888800 88.75%] train loss: 1.4210782865120564e-05 \n",
      "epoch: 17 [789921/888800 88.88%] train loss: 1.4068514246901032e-05 \n",
      "epoch: 17 [791032/888800 89.00%] train loss: 1.4516018381982576e-05 \n",
      "epoch: 17 [792143/888800 89.12%] train loss: 1.3201790352468379e-05 \n",
      "epoch: 17 [793254/888800 89.25%] train loss: 1.4914114217390306e-05 \n",
      "epoch: 17 [794365/888800 89.38%] train loss: 1.4729918802913744e-05 \n",
      "epoch: 17 [795476/888800 89.50%] train loss: 1.4156744327920023e-05 \n",
      "epoch: 17 [796587/888800 89.62%] train loss: 1.4076672414375935e-05 \n",
      "epoch: 17 [797698/888800 89.75%] train loss: 1.5685987818869762e-05 \n",
      "epoch: 17 [798809/888800 89.88%] train loss: 1.6962523659458384e-05 \n",
      "epoch: 17 [799920/888800 90.00%] train loss: 1.4909001038176939e-05 \n",
      "epoch: 17 [801031/888800 90.12%] train loss: 1.6355030311387964e-05 \n",
      "epoch: 17 [802142/888800 90.25%] train loss: 1.364735362585634e-05 \n",
      "epoch: 17 [803253/888800 90.38%] train loss: 1.54378740262473e-05 \n",
      "epoch: 17 [804364/888800 90.50%] train loss: 1.4587670193577651e-05 \n",
      "epoch: 17 [805475/888800 90.62%] train loss: 1.5684337995480746e-05 \n",
      "epoch: 17 [806586/888800 90.75%] train loss: 1.3816813407174777e-05 \n",
      "epoch: 17 [807697/888800 90.88%] train loss: 1.587778388056904e-05 \n",
      "epoch: 17 [808808/888800 91.00%] train loss: 1.7441359887016006e-05 \n",
      "epoch: 17 [809919/888800 91.12%] train loss: 1.3961797776573803e-05 \n",
      "epoch: 17 [811030/888800 91.25%] train loss: 1.3741971997660585e-05 \n",
      "epoch: 17 [812141/888800 91.38%] train loss: 1.4122153515927494e-05 \n",
      "epoch: 17 [813252/888800 91.50%] train loss: 1.45234180308762e-05 \n",
      "epoch: 17 [814363/888800 91.62%] train loss: 1.2996139957976993e-05 \n",
      "epoch: 17 [815474/888800 91.75%] train loss: 1.4658704458270222e-05 \n",
      "epoch: 17 [816585/888800 91.88%] train loss: 1.4605807336920407e-05 \n",
      "epoch: 17 [817696/888800 92.00%] train loss: 1.4261116120906081e-05 \n",
      "epoch: 17 [818807/888800 92.12%] train loss: 1.4356745850818697e-05 \n",
      "epoch: 17 [819918/888800 92.25%] train loss: 1.4319415640784428e-05 \n",
      "epoch: 17 [821029/888800 92.38%] train loss: 1.3174100786272902e-05 \n",
      "epoch: 17 [822140/888800 92.50%] train loss: 1.4402365195564926e-05 \n",
      "epoch: 17 [823251/888800 92.62%] train loss: 1.432007320545381e-05 \n",
      "epoch: 17 [824362/888800 92.75%] train loss: 1.4588882550015114e-05 \n",
      "epoch: 17 [825473/888800 92.88%] train loss: 1.320664341619704e-05 \n",
      "epoch: 17 [826584/888800 93.00%] train loss: 1.4913825907569844e-05 \n",
      "epoch: 17 [827695/888800 93.12%] train loss: 1.4795258721278515e-05 \n",
      "epoch: 17 [828806/888800 93.25%] train loss: 1.453809454687871e-05 \n",
      "epoch: 17 [829917/888800 93.38%] train loss: 1.3857572412234731e-05 \n",
      "epoch: 17 [831028/888800 93.50%] train loss: 1.4938103049644269e-05 \n",
      "epoch: 17 [832139/888800 93.62%] train loss: 1.3249993571662344e-05 \n",
      "epoch: 17 [833250/888800 93.75%] train loss: 1.4146809007797856e-05 \n",
      "epoch: 17 [834361/888800 93.88%] train loss: 1.3303323612490203e-05 \n",
      "epoch: 17 [835472/888800 94.00%] train loss: 1.4265042409533635e-05 \n",
      "epoch: 17 [836583/888800 94.12%] train loss: 1.4456654753303155e-05 \n",
      "epoch: 17 [837694/888800 94.25%] train loss: 1.4392642697202973e-05 \n",
      "epoch: 17 [838805/888800 94.38%] train loss: 1.5721381714683957e-05 \n",
      "epoch: 17 [839916/888800 94.50%] train loss: 1.4686960639664903e-05 \n",
      "epoch: 17 [841027/888800 94.62%] train loss: 1.2975577192264609e-05 \n",
      "epoch: 17 [842138/888800 94.75%] train loss: 1.4427800124394707e-05 \n",
      "epoch: 17 [843249/888800 94.88%] train loss: 1.4720758372277487e-05 \n",
      "epoch: 17 [844360/888800 95.00%] train loss: 1.4134148841549177e-05 \n",
      "epoch: 17 [845471/888800 95.12%] train loss: 1.3840647625329439e-05 \n",
      "epoch: 17 [846582/888800 95.25%] train loss: 1.4114731129666325e-05 \n",
      "epoch: 17 [847693/888800 95.38%] train loss: 1.477298246754799e-05 \n",
      "epoch: 17 [848804/888800 95.50%] train loss: 1.3891591152059846e-05 \n",
      "epoch: 17 [849915/888800 95.62%] train loss: 1.365812659059884e-05 \n",
      "epoch: 17 [851026/888800 95.75%] train loss: 1.3910879715695046e-05 \n",
      "epoch: 17 [852137/888800 95.88%] train loss: 1.5392313798656687e-05 \n",
      "epoch: 17 [853248/888800 96.00%] train loss: 1.5400273696286604e-05 \n",
      "epoch: 17 [854359/888800 96.12%] train loss: 1.3985544683237094e-05 \n",
      "epoch: 17 [855470/888800 96.25%] train loss: 1.36042417580029e-05 \n",
      "epoch: 17 [856581/888800 96.38%] train loss: 1.3898909855925012e-05 \n",
      "epoch: 17 [857692/888800 96.50%] train loss: 1.4560760064341594e-05 \n",
      "epoch: 17 [858803/888800 96.62%] train loss: 1.3012319868721534e-05 \n",
      "epoch: 17 [859914/888800 96.75%] train loss: 1.3831493561156094e-05 \n",
      "epoch: 17 [861025/888800 96.88%] train loss: 1.496909862908069e-05 \n",
      "epoch: 17 [862136/888800 97.00%] train loss: 1.4152842595649417e-05 \n",
      "epoch: 17 [863247/888800 97.12%] train loss: 1.3306594155437779e-05 \n",
      "epoch: 17 [864358/888800 97.25%] train loss: 1.589967723703012e-05 \n",
      "epoch: 17 [865469/888800 97.38%] train loss: 1.4459364138019737e-05 \n",
      "epoch: 17 [866580/888800 97.50%] train loss: 1.5239031199598685e-05 \n",
      "epoch: 17 [867691/888800 97.62%] train loss: 1.4509118955174927e-05 \n",
      "epoch: 17 [868802/888800 97.75%] train loss: 1.5335632269852795e-05 \n",
      "epoch: 17 [869913/888800 97.88%] train loss: 1.3690196283278055e-05 \n",
      "epoch: 17 [871024/888800 98.00%] train loss: 1.5477324268431403e-05 \n",
      "epoch: 17 [872135/888800 98.12%] train loss: 1.4850945262878668e-05 \n",
      "epoch: 17 [873246/888800 98.25%] train loss: 1.4323629329737742e-05 \n",
      "epoch: 17 [874357/888800 98.38%] train loss: 1.2717995559796691e-05 \n",
      "epoch: 17 [875468/888800 98.50%] train loss: 1.4761579222977161e-05 \n",
      "epoch: 17 [876579/888800 98.62%] train loss: 1.435127342119813e-05 \n",
      "epoch: 17 [877690/888800 98.75%] train loss: 1.4379983440448996e-05 \n",
      "epoch: 17 [878801/888800 98.88%] train loss: 1.4548365470545832e-05 \n",
      "epoch: 17 [879912/888800 99.00%] train loss: 1.3133182619640138e-05 \n",
      "epoch: 17 [881023/888800 99.12%] train loss: 1.2986260117031634e-05 \n",
      "epoch: 17 [882134/888800 99.25%] train loss: 1.3247881724964827e-05 \n",
      "epoch: 17 [883245/888800 99.38%] train loss: 1.5627421817043796e-05 \n",
      "epoch: 17 [884356/888800 99.50%] train loss: 1.56960104504833e-05 \n",
      "epoch: 17 [885467/888800 99.62%] train loss: 1.564108970342204e-05 \n",
      "epoch: 17 [886578/888800 99.75%] train loss: 1.5100402379175648e-05 \n",
      "epoch: 17 [887689/888800 99.88%] train loss: 1.4993692275311332e-05 \n",
      "epoch: 18 [0/888800 0.00%] train loss: 1.4103121429798193e-05 \n",
      "epoch: 18 [1111/888800 0.12%] train loss: 1.4474605450232048e-05 \n",
      "epoch: 18 [2222/888800 0.25%] train loss: 1.4530838598147966e-05 \n",
      "epoch: 18 [3333/888800 0.38%] train loss: 1.6029543985496275e-05 \n",
      "epoch: 18 [4444/888800 0.50%] train loss: 1.3997676433064044e-05 \n",
      "epoch: 18 [5555/888800 0.62%] train loss: 1.6087826224975288e-05 \n",
      "epoch: 18 [6666/888800 0.75%] train loss: 1.4152055882732384e-05 \n",
      "epoch: 18 [7777/888800 0.88%] train loss: 1.3130255865689833e-05 \n",
      "epoch: 18 [8888/888800 1.00%] train loss: 1.3831090655003209e-05 \n",
      "epoch: 18 [9999/888800 1.12%] train loss: 1.3350687368074432e-05 \n",
      "epoch: 18 [11110/888800 1.25%] train loss: 1.3688272701983806e-05 \n",
      "epoch: 18 [12221/888800 1.38%] train loss: 1.3396211215876974e-05 \n",
      "epoch: 18 [13332/888800 1.50%] train loss: 1.5018517842690926e-05 \n",
      "epoch: 18 [14443/888800 1.62%] train loss: 1.3439221220323816e-05 \n",
      "epoch: 18 [15554/888800 1.75%] train loss: 1.4756357813894283e-05 \n",
      "epoch: 18 [16665/888800 1.88%] train loss: 1.5001258361735381e-05 \n",
      "epoch: 18 [17776/888800 2.00%] train loss: 1.4120829291641712e-05 \n",
      "epoch: 18 [18887/888800 2.12%] train loss: 1.3683189536095597e-05 \n",
      "epoch: 18 [19998/888800 2.25%] train loss: 1.4343011571327224e-05 \n",
      "epoch: 18 [21109/888800 2.38%] train loss: 1.409743617841741e-05 \n",
      "epoch: 18 [22220/888800 2.50%] train loss: 1.4310590813693125e-05 \n",
      "epoch: 18 [23331/888800 2.62%] train loss: 1.558134135848377e-05 \n",
      "epoch: 18 [24442/888800 2.75%] train loss: 1.5010653442004696e-05 \n",
      "epoch: 18 [25553/888800 2.88%] train loss: 1.463883563701529e-05 \n",
      "epoch: 18 [26664/888800 3.00%] train loss: 1.2829264960600995e-05 \n",
      "epoch: 18 [27775/888800 3.12%] train loss: 1.5671790606575087e-05 \n",
      "epoch: 18 [28886/888800 3.25%] train loss: 1.434184468962485e-05 \n",
      "epoch: 18 [29997/888800 3.38%] train loss: 1.5931142115732655e-05 \n",
      "epoch: 18 [31108/888800 3.50%] train loss: 1.3927694453741424e-05 \n",
      "epoch: 18 [32219/888800 3.62%] train loss: 1.5407887985929847e-05 \n",
      "epoch: 18 [33330/888800 3.75%] train loss: 1.3238219253253192e-05 \n",
      "epoch: 18 [34441/888800 3.88%] train loss: 1.4660140550404321e-05 \n",
      "epoch: 18 [35552/888800 4.00%] train loss: 1.4387450391950551e-05 \n",
      "epoch: 18 [36663/888800 4.12%] train loss: 1.5646899555576965e-05 \n",
      "epoch: 18 [37774/888800 4.25%] train loss: 1.4821009244769812e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [38885/888800 4.38%] train loss: 1.6022104318835773e-05 \n",
      "epoch: 18 [39996/888800 4.50%] train loss: 1.2985667126486078e-05 \n",
      "epoch: 18 [41107/888800 4.62%] train loss: 1.7024687622324564e-05 \n",
      "epoch: 18 [42218/888800 4.75%] train loss: 1.2899892681161873e-05 \n",
      "epoch: 18 [43329/888800 4.88%] train loss: 1.3400182979239617e-05 \n",
      "epoch: 18 [44440/888800 5.00%] train loss: 1.4604068383050617e-05 \n",
      "epoch: 18 [45551/888800 5.12%] train loss: 1.3499471606337465e-05 \n",
      "epoch: 18 [46662/888800 5.25%] train loss: 1.4653635844297241e-05 \n",
      "epoch: 18 [47773/888800 5.38%] train loss: 1.4550659216183703e-05 \n",
      "epoch: 18 [48884/888800 5.50%] train loss: 1.4659864064014982e-05 \n",
      "epoch: 18 [49995/888800 5.62%] train loss: 1.4477264812740032e-05 \n",
      "epoch: 18 [51106/888800 5.75%] train loss: 1.4426404959522188e-05 \n",
      "epoch: 18 [52217/888800 5.88%] train loss: 1.384248480462702e-05 \n",
      "epoch: 18 [53328/888800 6.00%] train loss: 1.424020592821762e-05 \n",
      "epoch: 18 [54439/888800 6.12%] train loss: 1.4627394193666987e-05 \n",
      "epoch: 18 [55550/888800 6.25%] train loss: 1.3317770935827866e-05 \n",
      "epoch: 18 [56661/888800 6.38%] train loss: 1.3573917385656387e-05 \n",
      "epoch: 18 [57772/888800 6.50%] train loss: 1.5063008504512254e-05 \n",
      "epoch: 18 [58883/888800 6.62%] train loss: 1.4485105566564016e-05 \n",
      "epoch: 18 [59994/888800 6.75%] train loss: 1.591405634826515e-05 \n",
      "epoch: 18 [61105/888800 6.88%] train loss: 1.3636730727739632e-05 \n",
      "epoch: 18 [62216/888800 7.00%] train loss: 1.4671306416857988e-05 \n",
      "epoch: 18 [63327/888800 7.12%] train loss: 1.3552478776546195e-05 \n",
      "epoch: 18 [64438/888800 7.25%] train loss: 1.548450018162839e-05 \n",
      "epoch: 18 [65549/888800 7.38%] train loss: 1.3974784451420419e-05 \n",
      "epoch: 18 [66660/888800 7.50%] train loss: 1.4434457625611685e-05 \n",
      "epoch: 18 [67771/888800 7.62%] train loss: 1.2959673767909408e-05 \n",
      "epoch: 18 [68882/888800 7.75%] train loss: 1.4154464224702679e-05 \n",
      "epoch: 18 [69993/888800 7.88%] train loss: 1.3890808077121619e-05 \n",
      "epoch: 18 [71104/888800 8.00%] train loss: 1.3436891094897874e-05 \n",
      "epoch: 18 [72215/888800 8.12%] train loss: 1.4722350897500291e-05 \n",
      "epoch: 18 [73326/888800 8.25%] train loss: 1.3776101695839316e-05 \n",
      "epoch: 18 [74437/888800 8.38%] train loss: 1.5231906218104996e-05 \n",
      "epoch: 18 [75548/888800 8.50%] train loss: 1.3847459740645718e-05 \n",
      "epoch: 18 [76659/888800 8.62%] train loss: 1.455225810786942e-05 \n",
      "epoch: 18 [77770/888800 8.75%] train loss: 1.4564306184183806e-05 \n",
      "epoch: 18 [78881/888800 8.88%] train loss: 1.3643661077367142e-05 \n",
      "epoch: 18 [79992/888800 9.00%] train loss: 1.384253573633032e-05 \n",
      "epoch: 18 [81103/888800 9.12%] train loss: 1.3489692719304003e-05 \n",
      "epoch: 18 [82214/888800 9.25%] train loss: 1.3584803127741907e-05 \n",
      "epoch: 18 [83325/888800 9.38%] train loss: 1.4437729987548664e-05 \n",
      "epoch: 18 [84436/888800 9.50%] train loss: 1.3926099200034514e-05 \n",
      "epoch: 18 [85547/888800 9.62%] train loss: 1.3967098311695736e-05 \n",
      "epoch: 18 [86658/888800 9.75%] train loss: 1.5244434507621918e-05 \n",
      "epoch: 18 [87769/888800 9.88%] train loss: 1.4100287444307469e-05 \n",
      "epoch: 18 [88880/888800 10.00%] train loss: 1.4062556147109717e-05 \n",
      "epoch: 18 [89991/888800 10.12%] train loss: 1.4851519154035486e-05 \n",
      "epoch: 18 [91102/888800 10.25%] train loss: 1.4666065908386372e-05 \n",
      "epoch: 18 [92213/888800 10.38%] train loss: 1.3049606423010118e-05 \n",
      "epoch: 18 [93324/888800 10.50%] train loss: 1.4441850908042397e-05 \n",
      "epoch: 18 [94435/888800 10.62%] train loss: 1.3808328731101938e-05 \n",
      "epoch: 18 [95546/888800 10.75%] train loss: 1.552728281239979e-05 \n",
      "epoch: 18 [96657/888800 10.88%] train loss: 1.5019016245787498e-05 \n",
      "epoch: 18 [97768/888800 11.00%] train loss: 1.4820425349171273e-05 \n",
      "epoch: 18 [98879/888800 11.12%] train loss: 1.4379280401044525e-05 \n",
      "epoch: 18 [99990/888800 11.25%] train loss: 1.6040312402765267e-05 \n",
      "epoch: 18 [101101/888800 11.38%] train loss: 1.733645513013471e-05 \n",
      "epoch: 18 [102212/888800 11.50%] train loss: 1.4931098121451214e-05 \n",
      "epoch: 18 [103323/888800 11.62%] train loss: 1.6172165487660095e-05 \n",
      "epoch: 18 [104434/888800 11.75%] train loss: 1.41979771797196e-05 \n",
      "epoch: 18 [105545/888800 11.88%] train loss: 1.559559314046055e-05 \n",
      "epoch: 18 [106656/888800 12.00%] train loss: 1.3834145647706464e-05 \n",
      "epoch: 18 [107767/888800 12.12%] train loss: 1.6345089534297585e-05 \n",
      "epoch: 18 [108878/888800 12.25%] train loss: 1.4195287803886458e-05 \n",
      "epoch: 18 [109989/888800 12.38%] train loss: 1.5463383533642627e-05 \n",
      "epoch: 18 [111100/888800 12.50%] train loss: 1.3583354302681983e-05 \n",
      "epoch: 18 [112211/888800 12.62%] train loss: 1.4574298802472185e-05 \n",
      "epoch: 18 [113322/888800 12.75%] train loss: 1.5066279956954531e-05 \n",
      "epoch: 18 [114433/888800 12.88%] train loss: 1.5750645616208203e-05 \n",
      "epoch: 18 [115544/888800 13.00%] train loss: 1.5473122402909212e-05 \n",
      "epoch: 18 [116655/888800 13.12%] train loss: 1.3825554560753517e-05 \n",
      "epoch: 18 [117766/888800 13.25%] train loss: 1.7189231584779918e-05 \n",
      "epoch: 18 [118877/888800 13.38%] train loss: 1.3859429600415751e-05 \n",
      "epoch: 18 [119988/888800 13.50%] train loss: 1.4541225027642213e-05 \n",
      "epoch: 18 [121099/888800 13.62%] train loss: 1.3113629393046722e-05 \n",
      "epoch: 18 [122210/888800 13.75%] train loss: 1.5176267879724037e-05 \n",
      "epoch: 18 [123321/888800 13.88%] train loss: 1.5212895959848538e-05 \n",
      "epoch: 18 [124432/888800 14.00%] train loss: 1.4307374840427656e-05 \n",
      "epoch: 18 [125543/888800 14.12%] train loss: 1.4216166164260358e-05 \n",
      "epoch: 18 [126654/888800 14.25%] train loss: 1.4647855095972773e-05 \n",
      "epoch: 18 [127765/888800 14.38%] train loss: 1.5669107597204857e-05 \n",
      "epoch: 18 [128876/888800 14.50%] train loss: 1.4386575458047446e-05 \n",
      "epoch: 18 [129987/888800 14.62%] train loss: 1.4109709809417836e-05 \n",
      "epoch: 18 [131098/888800 14.75%] train loss: 1.3001158549741376e-05 \n",
      "epoch: 18 [132209/888800 14.88%] train loss: 1.4009333426656667e-05 \n",
      "epoch: 18 [133320/888800 15.00%] train loss: 1.471141331421677e-05 \n",
      "epoch: 18 [134431/888800 15.12%] train loss: 1.4766974345548078e-05 \n",
      "epoch: 18 [135542/888800 15.25%] train loss: 1.5033077033876907e-05 \n",
      "epoch: 18 [136653/888800 15.38%] train loss: 1.3151610801287461e-05 \n",
      "epoch: 18 [137764/888800 15.50%] train loss: 1.5408550098072737e-05 \n",
      "epoch: 18 [138875/888800 15.62%] train loss: 1.413306290487526e-05 \n",
      "epoch: 18 [139986/888800 15.75%] train loss: 1.5038791389088146e-05 \n",
      "epoch: 18 [141097/888800 15.88%] train loss: 1.5222082765831146e-05 \n",
      "epoch: 18 [142208/888800 16.00%] train loss: 1.4772767826798372e-05 \n",
      "epoch: 18 [143319/888800 16.12%] train loss: 1.461852571083e-05 \n",
      "epoch: 18 [144430/888800 16.25%] train loss: 1.399423763359664e-05 \n",
      "epoch: 18 [145541/888800 16.38%] train loss: 1.4191067748470232e-05 \n",
      "epoch: 18 [146652/888800 16.50%] train loss: 1.4782424841541797e-05 \n",
      "epoch: 18 [147763/888800 16.62%] train loss: 1.3097834198561031e-05 \n",
      "epoch: 18 [148874/888800 16.75%] train loss: 1.3425542420009151e-05 \n",
      "epoch: 18 [149985/888800 16.88%] train loss: 1.3739244423049968e-05 \n",
      "epoch: 18 [151096/888800 17.00%] train loss: 1.375057763652876e-05 \n",
      "epoch: 18 [152207/888800 17.12%] train loss: 1.3280588973429985e-05 \n",
      "epoch: 18 [153318/888800 17.25%] train loss: 1.3245199625089299e-05 \n",
      "epoch: 18 [154429/888800 17.38%] train loss: 1.4783358892600518e-05 \n",
      "epoch: 18 [155540/888800 17.50%] train loss: 1.3814607882522978e-05 \n",
      "epoch: 18 [156651/888800 17.62%] train loss: 1.3917674550611991e-05 \n",
      "epoch: 18 [157762/888800 17.75%] train loss: 1.5467330740648322e-05 \n",
      "epoch: 18 [158873/888800 17.88%] train loss: 1.4943723726901226e-05 \n",
      "epoch: 18 [159984/888800 18.00%] train loss: 1.4173306226439308e-05 \n",
      "epoch: 18 [161095/888800 18.12%] train loss: 1.4121008462097961e-05 \n",
      "epoch: 18 [162206/888800 18.25%] train loss: 1.3886467058910057e-05 \n",
      "epoch: 18 [163317/888800 18.38%] train loss: 1.525620882603107e-05 \n",
      "epoch: 18 [164428/888800 18.50%] train loss: 1.335466731688939e-05 \n",
      "epoch: 18 [165539/888800 18.62%] train loss: 1.464354954805458e-05 \n",
      "epoch: 18 [166650/888800 18.75%] train loss: 1.3918837794335559e-05 \n",
      "epoch: 18 [167761/888800 18.88%] train loss: 1.503424300608458e-05 \n",
      "epoch: 18 [168872/888800 19.00%] train loss: 1.4619296962337103e-05 \n",
      "epoch: 18 [169983/888800 19.12%] train loss: 1.3481137102644425e-05 \n",
      "epoch: 18 [171094/888800 19.25%] train loss: 1.4253363588068169e-05 \n",
      "epoch: 18 [172205/888800 19.38%] train loss: 1.4457958059210796e-05 \n",
      "epoch: 18 [173316/888800 19.50%] train loss: 1.4747772183909547e-05 \n",
      "epoch: 18 [174427/888800 19.62%] train loss: 1.46122674777871e-05 \n",
      "epoch: 18 [175538/888800 19.75%] train loss: 1.4880419257679023e-05 \n",
      "epoch: 18 [176649/888800 19.88%] train loss: 1.3695894267584663e-05 \n",
      "epoch: 18 [177760/888800 20.00%] train loss: 1.4530877706420142e-05 \n",
      "epoch: 18 [178871/888800 20.12%] train loss: 1.3583044164988678e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [179982/888800 20.25%] train loss: 1.3370285159908235e-05 \n",
      "epoch: 18 [181093/888800 20.38%] train loss: 1.4577798538084608e-05 \n",
      "epoch: 18 [182204/888800 20.50%] train loss: 1.3851417861587834e-05 \n",
      "epoch: 18 [183315/888800 20.62%] train loss: 1.4307302990346216e-05 \n",
      "epoch: 18 [184426/888800 20.75%] train loss: 1.424956280970946e-05 \n",
      "epoch: 18 [185537/888800 20.88%] train loss: 1.5135422472667415e-05 \n",
      "epoch: 18 [186648/888800 21.00%] train loss: 1.3834392120770644e-05 \n",
      "epoch: 18 [187759/888800 21.12%] train loss: 1.384273582516471e-05 \n",
      "epoch: 18 [188870/888800 21.25%] train loss: 1.3888082321500406e-05 \n",
      "epoch: 18 [189981/888800 21.38%] train loss: 1.4520614968205336e-05 \n",
      "epoch: 18 [191092/888800 21.50%] train loss: 1.4649031982116867e-05 \n",
      "epoch: 18 [192203/888800 21.62%] train loss: 1.352706294710515e-05 \n",
      "epoch: 18 [193314/888800 21.75%] train loss: 1.391594014421571e-05 \n",
      "epoch: 18 [194425/888800 21.88%] train loss: 1.3890591617382597e-05 \n",
      "epoch: 18 [195536/888800 22.00%] train loss: 1.530750341771636e-05 \n",
      "epoch: 18 [196647/888800 22.12%] train loss: 1.4485063729807734e-05 \n",
      "epoch: 18 [197758/888800 22.25%] train loss: 1.4919345630914904e-05 \n",
      "epoch: 18 [198869/888800 22.38%] train loss: 1.4047435797692742e-05 \n",
      "epoch: 18 [199980/888800 22.50%] train loss: 1.552591311337892e-05 \n",
      "epoch: 18 [201091/888800 22.62%] train loss: 1.4555846064467914e-05 \n",
      "epoch: 18 [202202/888800 22.75%] train loss: 1.5797226296854205e-05 \n",
      "epoch: 18 [203313/888800 22.88%] train loss: 1.4155025382933673e-05 \n",
      "epoch: 18 [204424/888800 23.00%] train loss: 1.4710924006067216e-05 \n",
      "epoch: 18 [205535/888800 23.12%] train loss: 1.505268483015243e-05 \n",
      "epoch: 18 [206646/888800 23.25%] train loss: 1.3844194654666353e-05 \n",
      "epoch: 18 [207757/888800 23.38%] train loss: 1.5719468137831427e-05 \n",
      "epoch: 18 [208868/888800 23.50%] train loss: 1.3038678844168317e-05 \n",
      "epoch: 18 [209979/888800 23.62%] train loss: 1.4123334949545097e-05 \n",
      "epoch: 18 [211090/888800 23.75%] train loss: 1.5446757970494218e-05 \n",
      "epoch: 18 [212201/888800 23.88%] train loss: 1.4295878827397246e-05 \n",
      "epoch: 18 [213312/888800 24.00%] train loss: 1.4494929018837865e-05 \n",
      "epoch: 18 [214423/888800 24.12%] train loss: 1.445540056010941e-05 \n",
      "epoch: 18 [215534/888800 24.25%] train loss: 1.415744009136688e-05 \n",
      "epoch: 18 [216645/888800 24.38%] train loss: 1.358853933197679e-05 \n",
      "epoch: 18 [217756/888800 24.50%] train loss: 1.4369672499014996e-05 \n",
      "epoch: 18 [218867/888800 24.62%] train loss: 1.4007971003593411e-05 \n",
      "epoch: 18 [219978/888800 24.75%] train loss: 1.52232905747951e-05 \n",
      "epoch: 18 [221089/888800 24.88%] train loss: 1.2987148693355266e-05 \n",
      "epoch: 18 [222200/888800 25.00%] train loss: 1.4135356650513131e-05 \n",
      "epoch: 18 [223311/888800 25.12%] train loss: 1.2763915947289206e-05 \n",
      "epoch: 18 [224422/888800 25.25%] train loss: 1.3072385627310723e-05 \n",
      "epoch: 18 [225533/888800 25.38%] train loss: 1.3884330655855592e-05 \n",
      "epoch: 18 [226644/888800 25.50%] train loss: 1.4661247405456379e-05 \n",
      "epoch: 18 [227755/888800 25.62%] train loss: 1.443633209419204e-05 \n",
      "epoch: 18 [228866/888800 25.75%] train loss: 1.4994087905506603e-05 \n",
      "epoch: 18 [229977/888800 25.88%] train loss: 1.4455865311902016e-05 \n",
      "epoch: 18 [231088/888800 26.00%] train loss: 1.495481137681054e-05 \n",
      "epoch: 18 [232199/888800 26.12%] train loss: 1.4129043847788125e-05 \n",
      "epoch: 18 [233310/888800 26.25%] train loss: 1.4694059245812241e-05 \n",
      "epoch: 18 [234421/888800 26.38%] train loss: 1.4604529496864416e-05 \n",
      "epoch: 18 [235532/888800 26.50%] train loss: 1.4352031939779408e-05 \n",
      "epoch: 18 [236643/888800 26.62%] train loss: 1.529624751128722e-05 \n",
      "epoch: 18 [237754/888800 26.75%] train loss: 1.2858546142524574e-05 \n",
      "epoch: 18 [238865/888800 26.88%] train loss: 1.3587893590738531e-05 \n",
      "epoch: 18 [239976/888800 27.00%] train loss: 1.3842281987308525e-05 \n",
      "epoch: 18 [241087/888800 27.12%] train loss: 1.3896305972593836e-05 \n",
      "epoch: 18 [242198/888800 27.25%] train loss: 1.4552669199474622e-05 \n",
      "epoch: 18 [243309/888800 27.38%] train loss: 1.54136614582967e-05 \n",
      "epoch: 18 [244420/888800 27.50%] train loss: 1.4874268345010933e-05 \n",
      "epoch: 18 [245531/888800 27.62%] train loss: 1.4050321624381468e-05 \n",
      "epoch: 18 [246642/888800 27.75%] train loss: 1.440078722225735e-05 \n",
      "epoch: 18 [247753/888800 27.88%] train loss: 1.3324517567525618e-05 \n",
      "epoch: 18 [248864/888800 28.00%] train loss: 1.4179285244608764e-05 \n",
      "epoch: 18 [249975/888800 28.12%] train loss: 1.45804106068681e-05 \n",
      "epoch: 18 [251086/888800 28.25%] train loss: 1.2653225894609932e-05 \n",
      "epoch: 18 [252197/888800 28.38%] train loss: 1.4655798622698057e-05 \n",
      "epoch: 18 [253308/888800 28.50%] train loss: 1.3563609172706492e-05 \n",
      "epoch: 18 [254419/888800 28.62%] train loss: 1.3698873772227671e-05 \n",
      "epoch: 18 [255530/888800 28.75%] train loss: 1.4499750250251964e-05 \n",
      "epoch: 18 [256641/888800 28.88%] train loss: 1.6300780771416612e-05 \n",
      "epoch: 18 [257752/888800 29.00%] train loss: 1.3597931683761999e-05 \n",
      "epoch: 18 [258863/888800 29.12%] train loss: 1.4834025932941586e-05 \n",
      "epoch: 18 [259974/888800 29.25%] train loss: 1.359855286864331e-05 \n",
      "epoch: 18 [261085/888800 29.38%] train loss: 1.3539663086703513e-05 \n",
      "epoch: 18 [262196/888800 29.50%] train loss: 1.3671557098859921e-05 \n",
      "epoch: 18 [263307/888800 29.62%] train loss: 1.4956282939238008e-05 \n",
      "epoch: 18 [264418/888800 29.75%] train loss: 1.3920413948653731e-05 \n",
      "epoch: 18 [265529/888800 29.88%] train loss: 1.388930013490608e-05 \n",
      "epoch: 18 [266640/888800 30.00%] train loss: 1.4902023394824937e-05 \n",
      "epoch: 18 [267751/888800 30.12%] train loss: 1.450157469662372e-05 \n",
      "epoch: 18 [268862/888800 30.25%] train loss: 1.4165674656396732e-05 \n",
      "epoch: 18 [269973/888800 30.38%] train loss: 1.5009540220489725e-05 \n",
      "epoch: 18 [271084/888800 30.50%] train loss: 1.3068124644632917e-05 \n",
      "epoch: 18 [272195/888800 30.62%] train loss: 1.331876774202101e-05 \n",
      "epoch: 18 [273306/888800 30.75%] train loss: 1.3738231245952193e-05 \n",
      "epoch: 18 [274417/888800 30.88%] train loss: 1.3737985682382714e-05 \n",
      "epoch: 18 [275528/888800 31.00%] train loss: 1.3898730685468763e-05 \n",
      "epoch: 18 [276639/888800 31.12%] train loss: 1.3297665645950474e-05 \n",
      "epoch: 18 [277750/888800 31.25%] train loss: 1.4153164556773845e-05 \n",
      "epoch: 18 [278861/888800 31.38%] train loss: 1.4455481505137868e-05 \n",
      "epoch: 18 [279972/888800 31.50%] train loss: 1.4088707757764496e-05 \n",
      "epoch: 18 [281083/888800 31.62%] train loss: 1.4732760973856784e-05 \n",
      "epoch: 18 [282194/888800 31.75%] train loss: 1.2406388123054057e-05 \n",
      "epoch: 18 [283305/888800 31.88%] train loss: 1.4479338460660074e-05 \n",
      "epoch: 18 [284416/888800 32.00%] train loss: 1.3978915376355872e-05 \n",
      "epoch: 18 [285527/888800 32.12%] train loss: 1.4522850506182294e-05 \n",
      "epoch: 18 [286638/888800 32.25%] train loss: 1.5489738871110603e-05 \n",
      "epoch: 18 [287749/888800 32.38%] train loss: 1.555195740365889e-05 \n",
      "epoch: 18 [288860/888800 32.50%] train loss: 1.3500691238732543e-05 \n",
      "epoch: 18 [289971/888800 32.62%] train loss: 1.6711306670913473e-05 \n",
      "epoch: 18 [291082/888800 32.75%] train loss: 1.3884849977330305e-05 \n",
      "epoch: 18 [292193/888800 32.88%] train loss: 1.4608325727749616e-05 \n",
      "epoch: 18 [293304/888800 33.00%] train loss: 1.3481176210916601e-05 \n",
      "epoch: 18 [294415/888800 33.12%] train loss: 1.4324021321954206e-05 \n",
      "epoch: 18 [295526/888800 33.25%] train loss: 1.3926774954597931e-05 \n",
      "epoch: 18 [296637/888800 33.38%] train loss: 1.3595671589428093e-05 \n",
      "epoch: 18 [297748/888800 33.50%] train loss: 1.4073893908062018e-05 \n",
      "epoch: 18 [298859/888800 33.62%] train loss: 1.4502226804324891e-05 \n",
      "epoch: 18 [299970/888800 33.75%] train loss: 1.4223468497220892e-05 \n",
      "epoch: 18 [301081/888800 33.88%] train loss: 1.3728079466091003e-05 \n",
      "epoch: 18 [302192/888800 34.00%] train loss: 1.6103344023576938e-05 \n",
      "epoch: 18 [303303/888800 34.12%] train loss: 1.3867185771232471e-05 \n",
      "epoch: 18 [304414/888800 34.25%] train loss: 1.5119350791792385e-05 \n",
      "epoch: 18 [305525/888800 34.38%] train loss: 1.392730791849317e-05 \n",
      "epoch: 18 [306636/888800 34.50%] train loss: 1.3850881259713788e-05 \n",
      "epoch: 18 [307747/888800 34.62%] train loss: 1.4838699826213997e-05 \n",
      "epoch: 18 [308858/888800 34.75%] train loss: 1.4860488590784371e-05 \n",
      "epoch: 18 [309969/888800 34.88%] train loss: 1.3931039575254545e-05 \n",
      "epoch: 18 [311080/888800 35.00%] train loss: 1.3196142390370369e-05 \n",
      "epoch: 18 [312191/888800 35.12%] train loss: 1.384614279231755e-05 \n",
      "epoch: 18 [313302/888800 35.25%] train loss: 1.4523488971462939e-05 \n",
      "epoch: 18 [314413/888800 35.38%] train loss: 1.3971932276035659e-05 \n",
      "epoch: 18 [315524/888800 35.50%] train loss: 1.4122917491476983e-05 \n",
      "epoch: 18 [316635/888800 35.62%] train loss: 1.451605658076005e-05 \n",
      "epoch: 18 [317746/888800 35.75%] train loss: 1.4102266504778527e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [318857/888800 35.88%] train loss: 1.332492411165731e-05 \n",
      "epoch: 18 [319968/888800 36.00%] train loss: 1.5014491509646177e-05 \n",
      "epoch: 18 [321079/888800 36.12%] train loss: 1.5205990166577976e-05 \n",
      "epoch: 18 [322190/888800 36.25%] train loss: 1.4975181329646148e-05 \n",
      "epoch: 18 [323301/888800 36.38%] train loss: 1.482952939113602e-05 \n",
      "epoch: 18 [324412/888800 36.50%] train loss: 1.4531637134496123e-05 \n",
      "epoch: 18 [325523/888800 36.62%] train loss: 1.5549683666904457e-05 \n",
      "epoch: 18 [326634/888800 36.75%] train loss: 1.3404982382780872e-05 \n",
      "epoch: 18 [327745/888800 36.88%] train loss: 1.4191938134899829e-05 \n",
      "epoch: 18 [328856/888800 37.00%] train loss: 1.5203171642497182e-05 \n",
      "epoch: 18 [329967/888800 37.12%] train loss: 1.430212432751432e-05 \n",
      "epoch: 18 [331078/888800 37.25%] train loss: 1.5872692529228516e-05 \n",
      "epoch: 18 [332189/888800 37.38%] train loss: 1.461696683691116e-05 \n",
      "epoch: 18 [333300/888800 37.50%] train loss: 1.3621035577671137e-05 \n",
      "epoch: 18 [334411/888800 37.62%] train loss: 1.4044107956578955e-05 \n",
      "epoch: 18 [335522/888800 37.75%] train loss: 1.5646528481738642e-05 \n",
      "epoch: 18 [336633/888800 37.88%] train loss: 1.5671108485548757e-05 \n",
      "epoch: 18 [337744/888800 38.00%] train loss: 1.4683299013995565e-05 \n",
      "epoch: 18 [338855/888800 38.12%] train loss: 1.4373464182426687e-05 \n",
      "epoch: 18 [339966/888800 38.25%] train loss: 1.4170927897794172e-05 \n",
      "epoch: 18 [341077/888800 38.38%] train loss: 1.55070247274125e-05 \n",
      "epoch: 18 [342188/888800 38.50%] train loss: 1.4160975297272671e-05 \n",
      "epoch: 18 [343299/888800 38.62%] train loss: 1.3979922186990734e-05 \n",
      "epoch: 18 [344410/888800 38.75%] train loss: 1.4079567336011678e-05 \n",
      "epoch: 18 [345521/888800 38.88%] train loss: 1.4087272575125098e-05 \n",
      "epoch: 18 [346632/888800 39.00%] train loss: 1.529005567135755e-05 \n",
      "epoch: 18 [347743/888800 39.12%] train loss: 1.3913362636230886e-05 \n",
      "epoch: 18 [348854/888800 39.25%] train loss: 1.5196736967482138e-05 \n",
      "epoch: 18 [349965/888800 39.38%] train loss: 1.5316210919991136e-05 \n",
      "epoch: 18 [351076/888800 39.50%] train loss: 1.2770349712809548e-05 \n",
      "epoch: 18 [352187/888800 39.62%] train loss: 1.3900629710406065e-05 \n",
      "epoch: 18 [353298/888800 39.75%] train loss: 1.4568510778190102e-05 \n",
      "epoch: 18 [354409/888800 39.88%] train loss: 1.4571655810868833e-05 \n",
      "epoch: 18 [355520/888800 40.00%] train loss: 1.4437207028095145e-05 \n",
      "epoch: 18 [356631/888800 40.12%] train loss: 1.2695625628111884e-05 \n",
      "epoch: 18 [357742/888800 40.25%] train loss: 1.4602655937778763e-05 \n",
      "epoch: 18 [358853/888800 40.38%] train loss: 1.4122951142780948e-05 \n",
      "epoch: 18 [359964/888800 40.50%] train loss: 1.4054577150091063e-05 \n",
      "epoch: 18 [361075/888800 40.62%] train loss: 1.3954640962765552e-05 \n",
      "epoch: 18 [362186/888800 40.75%] train loss: 1.3523373127100058e-05 \n",
      "epoch: 18 [363297/888800 40.88%] train loss: 1.3584115549747366e-05 \n",
      "epoch: 18 [364408/888800 41.00%] train loss: 1.320537649007747e-05 \n",
      "epoch: 18 [365519/888800 41.12%] train loss: 1.4276174624683335e-05 \n",
      "epoch: 18 [366630/888800 41.25%] train loss: 1.4900256246619392e-05 \n",
      "epoch: 18 [367741/888800 41.38%] train loss: 1.3580519407696556e-05 \n",
      "epoch: 18 [368852/888800 41.50%] train loss: 1.37645511131268e-05 \n",
      "epoch: 18 [369963/888800 41.62%] train loss: 1.4786472092964686e-05 \n",
      "epoch: 18 [371074/888800 41.75%] train loss: 1.3857786143489648e-05 \n",
      "epoch: 18 [372185/888800 41.88%] train loss: 1.4828100574959535e-05 \n",
      "epoch: 18 [373296/888800 42.00%] train loss: 1.4728296264365781e-05 \n",
      "epoch: 18 [374407/888800 42.12%] train loss: 1.5306544810300693e-05 \n",
      "epoch: 18 [375518/888800 42.25%] train loss: 1.6237863746937364e-05 \n",
      "epoch: 18 [376629/888800 42.38%] train loss: 1.3789666809316259e-05 \n",
      "epoch: 18 [377740/888800 42.50%] train loss: 1.4526749509968795e-05 \n",
      "epoch: 18 [378851/888800 42.62%] train loss: 1.443753262719838e-05 \n",
      "epoch: 18 [379962/888800 42.75%] train loss: 1.44000950967893e-05 \n",
      "epoch: 18 [381073/888800 42.88%] train loss: 1.437606624676846e-05 \n",
      "epoch: 18 [382184/888800 43.00%] train loss: 1.4308831850939896e-05 \n",
      "epoch: 18 [383295/888800 43.12%] train loss: 1.3709981431020424e-05 \n",
      "epoch: 18 [384406/888800 43.25%] train loss: 1.4963795365474652e-05 \n",
      "epoch: 18 [385517/888800 43.38%] train loss: 1.3232186574896332e-05 \n",
      "epoch: 18 [386628/888800 43.50%] train loss: 1.4305980585049838e-05 \n",
      "epoch: 18 [387739/888800 43.62%] train loss: 1.4483248378382996e-05 \n",
      "epoch: 18 [388850/888800 43.75%] train loss: 1.4933782040316146e-05 \n",
      "epoch: 18 [389961/888800 43.88%] train loss: 1.4890217244101223e-05 \n",
      "epoch: 18 [391072/888800 44.00%] train loss: 1.400808287144173e-05 \n",
      "epoch: 18 [392183/888800 44.12%] train loss: 1.419372892996762e-05 \n",
      "epoch: 18 [393294/888800 44.25%] train loss: 1.4795991774008144e-05 \n",
      "epoch: 18 [394405/888800 44.38%] train loss: 1.4843947610643227e-05 \n",
      "epoch: 18 [395516/888800 44.50%] train loss: 1.4184963220031932e-05 \n",
      "epoch: 18 [396627/888800 44.62%] train loss: 1.4512180314341094e-05 \n",
      "epoch: 18 [397738/888800 44.75%] train loss: 1.4724189895787276e-05 \n",
      "epoch: 18 [398849/888800 44.88%] train loss: 1.2776149560522754e-05 \n",
      "epoch: 18 [399960/888800 45.00%] train loss: 1.5775571228004992e-05 \n",
      "epoch: 18 [401071/888800 45.12%] train loss: 1.3962294360680971e-05 \n",
      "epoch: 18 [402182/888800 45.25%] train loss: 1.4322245988296345e-05 \n",
      "epoch: 18 [403293/888800 45.38%] train loss: 1.6141781088663265e-05 \n",
      "epoch: 18 [404404/888800 45.50%] train loss: 1.3157623470760882e-05 \n",
      "epoch: 18 [405515/888800 45.62%] train loss: 1.4169713722367305e-05 \n",
      "epoch: 18 [406626/888800 45.75%] train loss: 1.3354732800507918e-05 \n",
      "epoch: 18 [407737/888800 45.88%] train loss: 1.4690533134853467e-05 \n",
      "epoch: 18 [408848/888800 46.00%] train loss: 1.3591936294687912e-05 \n",
      "epoch: 18 [409959/888800 46.12%] train loss: 1.3103012861392926e-05 \n",
      "epoch: 18 [411070/888800 46.25%] train loss: 1.3707126527151559e-05 \n",
      "epoch: 18 [412181/888800 46.38%] train loss: 1.4266242942539975e-05 \n",
      "epoch: 18 [413292/888800 46.50%] train loss: 1.5533114492427558e-05 \n",
      "epoch: 18 [414403/888800 46.62%] train loss: 1.3463162758853287e-05 \n",
      "epoch: 18 [415514/888800 46.75%] train loss: 1.577622606419027e-05 \n",
      "epoch: 18 [416625/888800 46.88%] train loss: 1.3116918125888333e-05 \n",
      "epoch: 18 [417736/888800 47.00%] train loss: 1.5345134670496918e-05 \n",
      "epoch: 18 [418847/888800 47.12%] train loss: 1.3680495612788945e-05 \n",
      "epoch: 18 [419958/888800 47.25%] train loss: 1.5834470104891807e-05 \n",
      "epoch: 18 [421069/888800 47.38%] train loss: 1.520115984021686e-05 \n",
      "epoch: 18 [422180/888800 47.50%] train loss: 1.4085946531849913e-05 \n",
      "epoch: 18 [423291/888800 47.62%] train loss: 1.3692021639144514e-05 \n",
      "epoch: 18 [424402/888800 47.75%] train loss: 1.4989527699071914e-05 \n",
      "epoch: 18 [425513/888800 47.88%] train loss: 1.563499608892016e-05 \n",
      "epoch: 18 [426624/888800 48.00%] train loss: 1.3913124348619021e-05 \n",
      "epoch: 18 [427735/888800 48.12%] train loss: 1.5945517588988878e-05 \n",
      "epoch: 18 [428846/888800 48.25%] train loss: 1.330003397015389e-05 \n",
      "epoch: 18 [429957/888800 48.38%] train loss: 1.5375444490928203e-05 \n",
      "epoch: 18 [431068/888800 48.50%] train loss: 1.4118602848611772e-05 \n",
      "epoch: 18 [432179/888800 48.62%] train loss: 1.559492011438124e-05 \n",
      "epoch: 18 [433290/888800 48.75%] train loss: 1.4147743968351278e-05 \n",
      "epoch: 18 [434401/888800 48.88%] train loss: 1.3698470866074786e-05 \n",
      "epoch: 18 [435512/888800 49.00%] train loss: 1.5052044545882381e-05 \n",
      "epoch: 18 [436623/888800 49.12%] train loss: 1.3562575077230576e-05 \n",
      "epoch: 18 [437734/888800 49.25%] train loss: 1.6646690710331313e-05 \n",
      "epoch: 18 [438845/888800 49.38%] train loss: 1.513354254711885e-05 \n",
      "epoch: 18 [439956/888800 49.50%] train loss: 1.4927245501894504e-05 \n",
      "epoch: 18 [441067/888800 49.62%] train loss: 1.484533913753694e-05 \n",
      "epoch: 18 [442178/888800 49.75%] train loss: 1.399466873408528e-05 \n",
      "epoch: 18 [443289/888800 49.88%] train loss: 1.434090609109262e-05 \n",
      "epoch: 18 [444400/888800 50.00%] train loss: 1.4147653928375803e-05 \n",
      "epoch: 18 [445511/888800 50.12%] train loss: 1.5986652215360664e-05 \n",
      "epoch: 18 [446622/888800 50.25%] train loss: 1.3666000086232089e-05 \n",
      "epoch: 18 [447733/888800 50.38%] train loss: 1.563066507515032e-05 \n",
      "epoch: 18 [448844/888800 50.50%] train loss: 1.5438929040101357e-05 \n",
      "epoch: 18 [449955/888800 50.62%] train loss: 1.497012453910429e-05 \n",
      "epoch: 18 [451066/888800 50.75%] train loss: 1.394256378262071e-05 \n",
      "epoch: 18 [452177/888800 50.88%] train loss: 1.4469130292127375e-05 \n",
      "epoch: 18 [453288/888800 51.00%] train loss: 1.5445371900568716e-05 \n",
      "epoch: 18 [454399/888800 51.12%] train loss: 1.4288572856457904e-05 \n",
      "epoch: 18 [455510/888800 51.25%] train loss: 1.3226545888755936e-05 \n",
      "epoch: 18 [456621/888800 51.38%] train loss: 1.476684701628983e-05 \n",
      "epoch: 18 [457732/888800 51.50%] train loss: 1.3146109267836437e-05 \n",
      "epoch: 18 [458843/888800 51.62%] train loss: 1.3769298675470054e-05 \n",
      "epoch: 18 [459954/888800 51.75%] train loss: 1.4094359357841313e-05 \n",
      "epoch: 18 [461065/888800 51.88%] train loss: 1.4291367733676452e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [462176/888800 52.00%] train loss: 1.4213352187653072e-05 \n",
      "epoch: 18 [463287/888800 52.12%] train loss: 1.3201367437432054e-05 \n",
      "epoch: 18 [464398/888800 52.25%] train loss: 1.472662825108273e-05 \n",
      "epoch: 18 [465509/888800 52.38%] train loss: 1.4836938134976663e-05 \n",
      "epoch: 18 [466620/888800 52.50%] train loss: 1.3214777027314994e-05 \n",
      "epoch: 18 [467731/888800 52.62%] train loss: 1.429901567462366e-05 \n",
      "epoch: 18 [468842/888800 52.75%] train loss: 1.4013988220540341e-05 \n",
      "epoch: 18 [469953/888800 52.88%] train loss: 1.515969506726833e-05 \n",
      "epoch: 18 [471064/888800 53.00%] train loss: 1.444084136892343e-05 \n",
      "epoch: 18 [472175/888800 53.12%] train loss: 1.4807682418904733e-05 \n",
      "epoch: 18 [473286/888800 53.25%] train loss: 1.4072567864786834e-05 \n",
      "epoch: 18 [474397/888800 53.38%] train loss: 1.445417910872493e-05 \n",
      "epoch: 18 [475508/888800 53.50%] train loss: 1.3164104530005716e-05 \n",
      "epoch: 18 [476619/888800 53.62%] train loss: 1.5209747289191e-05 \n",
      "epoch: 18 [477730/888800 53.75%] train loss: 1.3169425074011087e-05 \n",
      "epoch: 18 [478841/888800 53.88%] train loss: 1.3870931070414372e-05 \n",
      "epoch: 18 [479952/888800 54.00%] train loss: 1.4276030015025754e-05 \n",
      "epoch: 18 [481063/888800 54.12%] train loss: 1.4595470020140056e-05 \n",
      "epoch: 18 [482174/888800 54.25%] train loss: 1.3820804269926157e-05 \n",
      "epoch: 18 [483285/888800 54.38%] train loss: 1.2602390597749036e-05 \n",
      "epoch: 18 [484396/888800 54.50%] train loss: 1.5329405869124457e-05 \n",
      "epoch: 18 [485507/888800 54.62%] train loss: 1.498943856859114e-05 \n",
      "epoch: 18 [486618/888800 54.75%] train loss: 1.4276994079409633e-05 \n",
      "epoch: 18 [487729/888800 54.88%] train loss: 1.4585938515665475e-05 \n",
      "epoch: 18 [488840/888800 55.00%] train loss: 1.5576828445773572e-05 \n",
      "epoch: 18 [489951/888800 55.12%] train loss: 1.5932419046293944e-05 \n",
      "epoch: 18 [491062/888800 55.25%] train loss: 1.3913907423557248e-05 \n",
      "epoch: 18 [492173/888800 55.38%] train loss: 1.5047550732560921e-05 \n",
      "epoch: 18 [493284/888800 55.50%] train loss: 1.3627703083329834e-05 \n",
      "epoch: 18 [494395/888800 55.62%] train loss: 1.6516140021849424e-05 \n",
      "epoch: 18 [495506/888800 55.75%] train loss: 1.4614721294492483e-05 \n",
      "epoch: 18 [496617/888800 55.88%] train loss: 1.5963292753440328e-05 \n",
      "epoch: 18 [497728/888800 56.00%] train loss: 1.4663859474239871e-05 \n",
      "epoch: 18 [498839/888800 56.12%] train loss: 1.4444191947404761e-05 \n",
      "epoch: 18 [499950/888800 56.25%] train loss: 1.4152683434076607e-05 \n",
      "epoch: 18 [501061/888800 56.38%] train loss: 1.5512732716160826e-05 \n",
      "epoch: 18 [502172/888800 56.50%] train loss: 1.4001127965457272e-05 \n",
      "epoch: 18 [503283/888800 56.62%] train loss: 1.4502837075269781e-05 \n",
      "epoch: 18 [504394/888800 56.75%] train loss: 1.5631590940756723e-05 \n",
      "epoch: 18 [505505/888800 56.88%] train loss: 1.4871644452796318e-05 \n",
      "epoch: 18 [506616/888800 57.00%] train loss: 1.4252928849600721e-05 \n",
      "epoch: 18 [507727/888800 57.12%] train loss: 1.432716817362234e-05 \n",
      "epoch: 18 [508838/888800 57.25%] train loss: 1.6014866559999064e-05 \n",
      "epoch: 18 [509949/888800 57.38%] train loss: 1.4456443750532344e-05 \n",
      "epoch: 18 [511060/888800 57.50%] train loss: 1.4464323612628505e-05 \n",
      "epoch: 18 [512171/888800 57.62%] train loss: 1.4762577848159708e-05 \n",
      "epoch: 18 [513282/888800 57.75%] train loss: 1.426304424967384e-05 \n",
      "epoch: 18 [514393/888800 57.88%] train loss: 1.3540856343752239e-05 \n",
      "epoch: 18 [515504/888800 58.00%] train loss: 1.3748939636570867e-05 \n",
      "epoch: 18 [516615/888800 58.12%] train loss: 1.4787276995775755e-05 \n",
      "epoch: 18 [517726/888800 58.25%] train loss: 1.3887495697417762e-05 \n",
      "epoch: 18 [518837/888800 58.38%] train loss: 1.388373948429944e-05 \n",
      "epoch: 18 [519948/888800 58.50%] train loss: 1.5692463421146385e-05 \n",
      "epoch: 18 [521059/888800 58.62%] train loss: 1.3955385838926304e-05 \n",
      "epoch: 18 [522170/888800 58.75%] train loss: 1.542408426757902e-05 \n",
      "epoch: 18 [523281/888800 58.88%] train loss: 1.395601429976523e-05 \n",
      "epoch: 18 [524392/888800 59.00%] train loss: 1.2510021406342275e-05 \n",
      "epoch: 18 [525503/888800 59.12%] train loss: 1.5395811715279706e-05 \n",
      "epoch: 18 [526614/888800 59.25%] train loss: 1.423309095116565e-05 \n",
      "epoch: 18 [527725/888800 59.38%] train loss: 1.398696349497186e-05 \n",
      "epoch: 18 [528836/888800 59.50%] train loss: 1.4729821486980654e-05 \n",
      "epoch: 18 [529947/888800 59.62%] train loss: 1.436947422917001e-05 \n",
      "epoch: 18 [531058/888800 59.75%] train loss: 1.493738000135636e-05 \n",
      "epoch: 18 [532169/888800 59.88%] train loss: 1.634697946428787e-05 \n",
      "epoch: 18 [533280/888800 60.00%] train loss: 1.4455627024290152e-05 \n",
      "epoch: 18 [534391/888800 60.12%] train loss: 1.7174272215925157e-05 \n",
      "epoch: 18 [535502/888800 60.25%] train loss: 1.355322001472814e-05 \n",
      "epoch: 18 [536613/888800 60.38%] train loss: 1.4458314581133891e-05 \n",
      "epoch: 18 [537724/888800 60.50%] train loss: 1.3534033314499538e-05 \n",
      "epoch: 18 [538835/888800 60.62%] train loss: 1.4062307855056133e-05 \n",
      "epoch: 18 [539946/888800 60.75%] train loss: 1.4462640137935523e-05 \n",
      "epoch: 18 [541057/888800 60.88%] train loss: 1.4165672837407328e-05 \n",
      "epoch: 18 [542168/888800 61.00%] train loss: 1.4549232218996622e-05 \n",
      "epoch: 18 [543279/888800 61.12%] train loss: 1.4384687347046565e-05 \n",
      "epoch: 18 [544390/888800 61.25%] train loss: 1.469213475502329e-05 \n",
      "epoch: 18 [545501/888800 61.38%] train loss: 1.4016269233252387e-05 \n",
      "epoch: 18 [546612/888800 61.50%] train loss: 1.3976295122120064e-05 \n",
      "epoch: 18 [547723/888800 61.62%] train loss: 1.4240225937101059e-05 \n",
      "epoch: 18 [548834/888800 61.75%] train loss: 1.3651725566887762e-05 \n",
      "epoch: 18 [549945/888800 61.88%] train loss: 1.4582107723981608e-05 \n",
      "epoch: 18 [551056/888800 62.00%] train loss: 1.3855298675480299e-05 \n",
      "epoch: 18 [552167/888800 62.12%] train loss: 1.3876887351216283e-05 \n",
      "epoch: 18 [553278/888800 62.25%] train loss: 1.4569979612133466e-05 \n",
      "epoch: 18 [554389/888800 62.38%] train loss: 1.3450907317746896e-05 \n",
      "epoch: 18 [555500/888800 62.50%] train loss: 1.4676054888695944e-05 \n",
      "epoch: 18 [556611/888800 62.62%] train loss: 1.49295519804582e-05 \n",
      "epoch: 18 [557722/888800 62.75%] train loss: 1.3703608601645101e-05 \n",
      "epoch: 18 [558833/888800 62.88%] train loss: 1.2926855561090633e-05 \n",
      "epoch: 18 [559944/888800 63.00%] train loss: 1.2864562449976802e-05 \n",
      "epoch: 18 [561055/888800 63.12%] train loss: 1.3086343642498832e-05 \n",
      "epoch: 18 [562166/888800 63.25%] train loss: 1.5093643014552072e-05 \n",
      "epoch: 18 [563277/888800 63.38%] train loss: 1.4684575035062153e-05 \n",
      "epoch: 18 [564388/888800 63.50%] train loss: 1.4403794921236113e-05 \n",
      "epoch: 18 [565499/888800 63.62%] train loss: 1.3708079677599017e-05 \n",
      "epoch: 18 [566610/888800 63.75%] train loss: 1.3837243386660703e-05 \n",
      "epoch: 18 [567721/888800 63.88%] train loss: 1.4303609532362316e-05 \n",
      "epoch: 18 [568832/888800 64.00%] train loss: 1.4250469575927127e-05 \n",
      "epoch: 18 [569943/888800 64.12%] train loss: 1.5291609088308178e-05 \n",
      "epoch: 18 [571054/888800 64.25%] train loss: 1.4784577615500893e-05 \n",
      "epoch: 18 [572165/888800 64.38%] train loss: 1.3803837646264583e-05 \n",
      "epoch: 18 [573276/888800 64.50%] train loss: 1.4465584172285162e-05 \n",
      "epoch: 18 [574387/888800 64.62%] train loss: 1.3454024156089872e-05 \n",
      "epoch: 18 [575498/888800 64.75%] train loss: 1.5239034837577492e-05 \n",
      "epoch: 18 [576609/888800 64.88%] train loss: 1.3666593076777644e-05 \n",
      "epoch: 18 [577720/888800 65.00%] train loss: 1.5616129530826584e-05 \n",
      "epoch: 18 [578831/888800 65.12%] train loss: 1.3492509424395394e-05 \n",
      "epoch: 18 [579942/888800 65.25%] train loss: 1.4379188542079646e-05 \n",
      "epoch: 18 [581053/888800 65.38%] train loss: 1.4836288755759597e-05 \n",
      "epoch: 18 [582164/888800 65.50%] train loss: 1.394182527292287e-05 \n",
      "epoch: 18 [583275/888800 65.62%] train loss: 1.4802440091443714e-05 \n",
      "epoch: 18 [584386/888800 65.75%] train loss: 1.2969117051397916e-05 \n",
      "epoch: 18 [585497/888800 65.88%] train loss: 1.4324442418001126e-05 \n",
      "epoch: 18 [586608/888800 66.00%] train loss: 1.5124767742236145e-05 \n",
      "epoch: 18 [587719/888800 66.12%] train loss: 1.4090778677200433e-05 \n",
      "epoch: 18 [588830/888800 66.25%] train loss: 1.3699876035389025e-05 \n",
      "epoch: 18 [589941/888800 66.38%] train loss: 1.3882474377169274e-05 \n",
      "epoch: 18 [591052/888800 66.50%] train loss: 1.4186894986778498e-05 \n",
      "epoch: 18 [592163/888800 66.62%] train loss: 1.4477179320238065e-05 \n",
      "epoch: 18 [593274/888800 66.75%] train loss: 1.4133633158053271e-05 \n",
      "epoch: 18 [594385/888800 66.88%] train loss: 1.4035835192771628e-05 \n",
      "epoch: 18 [595496/888800 67.00%] train loss: 1.4304692740552127e-05 \n",
      "epoch: 18 [596607/888800 67.12%] train loss: 1.3774941180599853e-05 \n",
      "epoch: 18 [597718/888800 67.25%] train loss: 1.503504881839035e-05 \n",
      "epoch: 18 [598829/888800 67.38%] train loss: 1.5578414604533464e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [599940/888800 67.50%] train loss: 1.4677144463348668e-05 \n",
      "epoch: 18 [601051/888800 67.62%] train loss: 1.5611314665875398e-05 \n",
      "epoch: 18 [602162/888800 67.75%] train loss: 1.4816208931733854e-05 \n",
      "epoch: 18 [603273/888800 67.88%] train loss: 1.3410624887910672e-05 \n",
      "epoch: 18 [604384/888800 68.00%] train loss: 1.5072509995661676e-05 \n",
      "epoch: 18 [605495/888800 68.12%] train loss: 1.606612750038039e-05 \n",
      "epoch: 18 [606606/888800 68.25%] train loss: 1.570820495544467e-05 \n",
      "epoch: 18 [607717/888800 68.38%] train loss: 1.4112949429545552e-05 \n",
      "epoch: 18 [608828/888800 68.50%] train loss: 1.7127031242125668e-05 \n",
      "epoch: 18 [609939/888800 68.62%] train loss: 1.3056103853159584e-05 \n",
      "epoch: 18 [611050/888800 68.75%] train loss: 1.5119647287065163e-05 \n",
      "epoch: 18 [612161/888800 68.88%] train loss: 1.684014750935603e-05 \n",
      "epoch: 18 [613272/888800 69.00%] train loss: 1.4148035916150548e-05 \n",
      "epoch: 18 [614383/888800 69.12%] train loss: 1.4932311387383379e-05 \n",
      "epoch: 18 [615494/888800 69.25%] train loss: 1.3305947504704818e-05 \n",
      "epoch: 18 [616605/888800 69.38%] train loss: 1.627583333174698e-05 \n",
      "epoch: 18 [617716/888800 69.50%] train loss: 1.4692019249196164e-05 \n",
      "epoch: 18 [618827/888800 69.62%] train loss: 1.6176983990590088e-05 \n",
      "epoch: 18 [619938/888800 69.75%] train loss: 1.4344929695653263e-05 \n",
      "epoch: 18 [621049/888800 69.88%] train loss: 1.594254354131408e-05 \n",
      "epoch: 18 [622160/888800 70.00%] train loss: 1.4798756637901533e-05 \n",
      "epoch: 18 [623271/888800 70.12%] train loss: 1.3454518921207637e-05 \n",
      "epoch: 18 [624382/888800 70.25%] train loss: 1.3127189959050156e-05 \n",
      "epoch: 18 [625493/888800 70.38%] train loss: 1.365665957564488e-05 \n",
      "epoch: 18 [626604/888800 70.50%] train loss: 1.469245853513712e-05 \n",
      "epoch: 18 [627715/888800 70.62%] train loss: 1.3499414308171254e-05 \n",
      "epoch: 18 [628826/888800 70.75%] train loss: 1.439392872271128e-05 \n",
      "epoch: 18 [629937/888800 70.88%] train loss: 1.5314926713472232e-05 \n",
      "epoch: 18 [631048/888800 71.00%] train loss: 1.460695784771815e-05 \n",
      "epoch: 18 [632159/888800 71.12%] train loss: 1.3058406693744473e-05 \n",
      "epoch: 18 [633270/888800 71.25%] train loss: 1.6635920474072918e-05 \n",
      "epoch: 18 [634381/888800 71.38%] train loss: 1.4726270819664933e-05 \n",
      "epoch: 18 [635492/888800 71.50%] train loss: 1.5705354599049315e-05 \n",
      "epoch: 18 [636603/888800 71.62%] train loss: 1.4443578038481064e-05 \n",
      "epoch: 18 [637714/888800 71.75%] train loss: 1.3746049262408633e-05 \n",
      "epoch: 18 [638825/888800 71.88%] train loss: 1.5491934391320683e-05 \n",
      "epoch: 18 [639936/888800 72.00%] train loss: 1.302314740314614e-05 \n",
      "epoch: 18 [641047/888800 72.12%] train loss: 1.4698503946419805e-05 \n",
      "epoch: 18 [642158/888800 72.25%] train loss: 1.397086543875048e-05 \n",
      "epoch: 18 [643269/888800 72.38%] train loss: 1.4355908206198364e-05 \n",
      "epoch: 18 [644380/888800 72.50%] train loss: 1.524840627098456e-05 \n",
      "epoch: 18 [645491/888800 72.62%] train loss: 1.4287722478911746e-05 \n",
      "epoch: 18 [646602/888800 72.75%] train loss: 1.3905359992349986e-05 \n",
      "epoch: 18 [647713/888800 72.88%] train loss: 1.551813147671055e-05 \n",
      "epoch: 18 [648824/888800 73.00%] train loss: 1.4194361028785352e-05 \n",
      "epoch: 18 [649935/888800 73.12%] train loss: 1.4070146789890714e-05 \n",
      "epoch: 18 [651046/888800 73.25%] train loss: 1.329403130512219e-05 \n",
      "epoch: 18 [652157/888800 73.38%] train loss: 1.5096859897312243e-05 \n",
      "epoch: 18 [653268/888800 73.50%] train loss: 1.378381966787856e-05 \n",
      "epoch: 18 [654379/888800 73.62%] train loss: 1.456165591662284e-05 \n",
      "epoch: 18 [655490/888800 73.75%] train loss: 1.5395566151710227e-05 \n",
      "epoch: 18 [656601/888800 73.88%] train loss: 1.4485065548797138e-05 \n",
      "epoch: 18 [657712/888800 74.00%] train loss: 1.4118537364993244e-05 \n",
      "epoch: 18 [658823/888800 74.12%] train loss: 1.3487307114701252e-05 \n",
      "epoch: 18 [659934/888800 74.25%] train loss: 1.460694784327643e-05 \n",
      "epoch: 18 [661045/888800 74.38%] train loss: 1.4640905646956526e-05 \n",
      "epoch: 18 [662156/888800 74.50%] train loss: 1.4518623174808454e-05 \n",
      "epoch: 18 [663267/888800 74.62%] train loss: 1.5138773960643448e-05 \n",
      "epoch: 18 [664378/888800 74.75%] train loss: 1.4105978152656462e-05 \n",
      "epoch: 18 [665489/888800 74.88%] train loss: 1.4405049114429858e-05 \n",
      "epoch: 18 [666600/888800 75.00%] train loss: 1.4228954569261987e-05 \n",
      "epoch: 18 [667711/888800 75.12%] train loss: 1.4430116607400123e-05 \n",
      "epoch: 18 [668822/888800 75.25%] train loss: 1.39997064252384e-05 \n",
      "epoch: 18 [669933/888800 75.38%] train loss: 1.6570373190916143e-05 \n",
      "epoch: 18 [671044/888800 75.50%] train loss: 1.3461431990435813e-05 \n",
      "epoch: 18 [672155/888800 75.62%] train loss: 1.3945538739790209e-05 \n",
      "epoch: 18 [673266/888800 75.75%] train loss: 1.4717911653860938e-05 \n",
      "epoch: 18 [674377/888800 75.88%] train loss: 1.3825323549099267e-05 \n",
      "epoch: 18 [675488/888800 76.00%] train loss: 1.492836145189358e-05 \n",
      "epoch: 18 [676599/888800 76.12%] train loss: 1.3984186807647347e-05 \n",
      "epoch: 18 [677710/888800 76.25%] train loss: 1.4264152014220599e-05 \n",
      "epoch: 18 [678821/888800 76.38%] train loss: 1.4551277672580909e-05 \n",
      "epoch: 18 [679932/888800 76.50%] train loss: 1.5311135939555243e-05 \n",
      "epoch: 18 [681043/888800 76.62%] train loss: 1.3815264537697658e-05 \n",
      "epoch: 18 [682154/888800 76.75%] train loss: 1.2559351489471737e-05 \n",
      "epoch: 18 [683265/888800 76.88%] train loss: 1.4039013876754325e-05 \n",
      "epoch: 18 [684376/888800 77.00%] train loss: 1.4252337678044569e-05 \n",
      "epoch: 18 [685487/888800 77.12%] train loss: 1.3302423212735448e-05 \n",
      "epoch: 18 [686598/888800 77.25%] train loss: 1.3534428035200108e-05 \n",
      "epoch: 18 [687709/888800 77.38%] train loss: 1.478709964430891e-05 \n",
      "epoch: 18 [688820/888800 77.50%] train loss: 1.3808543371851556e-05 \n",
      "epoch: 18 [689931/888800 77.62%] train loss: 1.4446557543124072e-05 \n",
      "epoch: 18 [691042/888800 77.75%] train loss: 1.5870276911300607e-05 \n",
      "epoch: 18 [692153/888800 77.88%] train loss: 1.4460252714343369e-05 \n",
      "epoch: 18 [693264/888800 78.00%] train loss: 1.5452074876520783e-05 \n",
      "epoch: 18 [694375/888800 78.12%] train loss: 1.4168511370371561e-05 \n",
      "epoch: 18 [695486/888800 78.25%] train loss: 1.5665680621168576e-05 \n",
      "epoch: 18 [696597/888800 78.38%] train loss: 1.5192245882644784e-05 \n",
      "epoch: 18 [697708/888800 78.50%] train loss: 1.4253653716878034e-05 \n",
      "epoch: 18 [698819/888800 78.62%] train loss: 1.482154220866505e-05 \n",
      "epoch: 18 [699930/888800 78.75%] train loss: 1.4844122233625967e-05 \n",
      "epoch: 18 [701041/888800 78.88%] train loss: 1.4541095879394561e-05 \n",
      "epoch: 18 [702152/888800 79.00%] train loss: 1.3514249985746574e-05 \n",
      "epoch: 18 [703263/888800 79.12%] train loss: 1.32956784000271e-05 \n",
      "epoch: 18 [704374/888800 79.25%] train loss: 1.4604908756155055e-05 \n",
      "epoch: 18 [705485/888800 79.38%] train loss: 1.5673047528252937e-05 \n",
      "epoch: 18 [706596/888800 79.50%] train loss: 1.4012989595357794e-05 \n",
      "epoch: 18 [707707/888800 79.62%] train loss: 1.443329074390931e-05 \n",
      "epoch: 18 [708818/888800 79.75%] train loss: 1.3394727830018383e-05 \n",
      "epoch: 18 [709929/888800 79.88%] train loss: 1.45612766573322e-05 \n",
      "epoch: 18 [711040/888800 80.00%] train loss: 1.467975653213216e-05 \n",
      "epoch: 18 [712151/888800 80.12%] train loss: 1.5157553207245655e-05 \n",
      "epoch: 18 [713262/888800 80.25%] train loss: 1.4323560208140407e-05 \n",
      "epoch: 18 [714373/888800 80.38%] train loss: 1.4316749911813531e-05 \n",
      "epoch: 18 [715484/888800 80.50%] train loss: 1.4897381333867088e-05 \n",
      "epoch: 18 [716595/888800 80.62%] train loss: 1.44148689287249e-05 \n",
      "epoch: 18 [717706/888800 80.75%] train loss: 1.4010537597641815e-05 \n",
      "epoch: 18 [718817/888800 80.88%] train loss: 1.497620360169094e-05 \n",
      "epoch: 18 [719928/888800 81.00%] train loss: 1.4010735867486801e-05 \n",
      "epoch: 18 [721039/888800 81.12%] train loss: 1.5164489013841376e-05 \n",
      "epoch: 18 [722150/888800 81.25%] train loss: 1.3584792213805486e-05 \n",
      "epoch: 18 [723261/888800 81.38%] train loss: 1.3909551853430457e-05 \n",
      "epoch: 18 [724372/888800 81.50%] train loss: 1.6410074749728665e-05 \n",
      "epoch: 18 [725483/888800 81.62%] train loss: 1.5682890079915524e-05 \n",
      "epoch: 18 [726594/888800 81.75%] train loss: 1.4142338841338642e-05 \n",
      "epoch: 18 [727705/888800 81.88%] train loss: 1.2761210200551432e-05 \n",
      "epoch: 18 [728816/888800 82.00%] train loss: 1.3717924957745709e-05 \n",
      "epoch: 18 [729927/888800 82.12%] train loss: 1.411079938407056e-05 \n",
      "epoch: 18 [731038/888800 82.25%] train loss: 1.2987733498448506e-05 \n",
      "epoch: 18 [732149/888800 82.38%] train loss: 1.4936274965293705e-05 \n",
      "epoch: 18 [733260/888800 82.50%] train loss: 1.4952511264709756e-05 \n",
      "epoch: 18 [734371/888800 82.62%] train loss: 1.3623041013488546e-05 \n",
      "epoch: 18 [735482/888800 82.75%] train loss: 1.3897857570555061e-05 \n",
      "epoch: 18 [736593/888800 82.88%] train loss: 1.4196367374097463e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [737704/888800 83.00%] train loss: 1.4374159036378842e-05 \n",
      "epoch: 18 [738815/888800 83.12%] train loss: 1.4158275007503107e-05 \n",
      "epoch: 18 [739926/888800 83.25%] train loss: 1.4897221262799576e-05 \n",
      "epoch: 18 [741037/888800 83.38%] train loss: 1.5160322618612554e-05 \n",
      "epoch: 18 [742148/888800 83.50%] train loss: 1.3770792975265067e-05 \n",
      "epoch: 18 [743259/888800 83.62%] train loss: 1.4877427929604892e-05 \n",
      "epoch: 18 [744370/888800 83.75%] train loss: 1.304005036217859e-05 \n",
      "epoch: 18 [745481/888800 83.88%] train loss: 1.53387136379024e-05 \n",
      "epoch: 18 [746592/888800 84.00%] train loss: 1.5853995137149468e-05 \n",
      "epoch: 18 [747703/888800 84.12%] train loss: 1.577314833411947e-05 \n",
      "epoch: 18 [748814/888800 84.25%] train loss: 1.3986653357278556e-05 \n",
      "epoch: 18 [749925/888800 84.38%] train loss: 1.4205326806404628e-05 \n",
      "epoch: 18 [751036/888800 84.50%] train loss: 1.4011070561537053e-05 \n",
      "epoch: 18 [752147/888800 84.62%] train loss: 1.3652456800627988e-05 \n",
      "epoch: 18 [753258/888800 84.75%] train loss: 1.484301537857391e-05 \n",
      "epoch: 18 [754369/888800 84.88%] train loss: 1.3792215213470627e-05 \n",
      "epoch: 18 [755480/888800 85.00%] train loss: 1.4454572919930797e-05 \n",
      "epoch: 18 [756591/888800 85.12%] train loss: 1.5525756680290215e-05 \n",
      "epoch: 18 [757702/888800 85.25%] train loss: 1.3894596122554503e-05 \n",
      "epoch: 18 [758813/888800 85.38%] train loss: 1.356190477963537e-05 \n",
      "epoch: 18 [759924/888800 85.50%] train loss: 1.5972680557752028e-05 \n",
      "epoch: 18 [761035/888800 85.62%] train loss: 1.3988441423862241e-05 \n",
      "epoch: 18 [762146/888800 85.75%] train loss: 1.4199985344021115e-05 \n",
      "epoch: 18 [763257/888800 85.88%] train loss: 1.4238116818887647e-05 \n",
      "epoch: 18 [764368/888800 86.00%] train loss: 1.4446102795773186e-05 \n",
      "epoch: 18 [765479/888800 86.12%] train loss: 1.571423672430683e-05 \n",
      "epoch: 18 [766590/888800 86.25%] train loss: 1.3537478480429854e-05 \n",
      "epoch: 18 [767701/888800 86.38%] train loss: 1.498971050750697e-05 \n",
      "epoch: 18 [768812/888800 86.50%] train loss: 1.3945440514362417e-05 \n",
      "epoch: 18 [769923/888800 86.62%] train loss: 1.534198054287117e-05 \n",
      "epoch: 18 [771034/888800 86.75%] train loss: 1.5400726624648087e-05 \n",
      "epoch: 18 [772145/888800 86.88%] train loss: 1.4609936442866456e-05 \n",
      "epoch: 18 [773256/888800 87.00%] train loss: 1.3851783478457946e-05 \n",
      "epoch: 18 [774367/888800 87.12%] train loss: 1.5178360627032816e-05 \n",
      "epoch: 18 [775478/888800 87.25%] train loss: 1.2803045137843583e-05 \n",
      "epoch: 18 [776589/888800 87.38%] train loss: 1.3844309250998776e-05 \n",
      "epoch: 18 [777700/888800 87.50%] train loss: 1.4206320884113666e-05 \n",
      "epoch: 18 [778811/888800 87.62%] train loss: 1.458032875234494e-05 \n",
      "epoch: 18 [779922/888800 87.75%] train loss: 1.3709570339415222e-05 \n",
      "epoch: 18 [781033/888800 87.88%] train loss: 1.559348493174184e-05 \n",
      "epoch: 18 [782144/888800 88.00%] train loss: 1.3386455066211056e-05 \n",
      "epoch: 18 [783255/888800 88.12%] train loss: 1.4354119230119977e-05 \n",
      "epoch: 18 [784366/888800 88.25%] train loss: 1.4692585864395369e-05 \n",
      "epoch: 18 [785477/888800 88.38%] train loss: 1.4167711924528703e-05 \n",
      "epoch: 18 [786588/888800 88.50%] train loss: 1.479786260460969e-05 \n",
      "epoch: 18 [787699/888800 88.62%] train loss: 1.4069281860429328e-05 \n",
      "epoch: 18 [788810/888800 88.75%] train loss: 1.3681416930921841e-05 \n",
      "epoch: 18 [789921/888800 88.88%] train loss: 1.4393740457308013e-05 \n",
      "epoch: 18 [791032/888800 89.00%] train loss: 1.3031504749960732e-05 \n",
      "epoch: 18 [792143/888800 89.12%] train loss: 1.4514457689074334e-05 \n",
      "epoch: 18 [793254/888800 89.25%] train loss: 1.4496097719529644e-05 \n",
      "epoch: 18 [794365/888800 89.38%] train loss: 1.530527697468642e-05 \n",
      "epoch: 18 [795476/888800 89.50%] train loss: 1.3710186976823024e-05 \n",
      "epoch: 18 [796587/888800 89.62%] train loss: 1.4739528523932677e-05 \n",
      "epoch: 18 [797698/888800 89.75%] train loss: 1.361694376100786e-05 \n",
      "epoch: 18 [798809/888800 89.88%] train loss: 1.4589520105801057e-05 \n",
      "epoch: 18 [799920/888800 90.00%] train loss: 1.3752216545981355e-05 \n",
      "epoch: 18 [801031/888800 90.12%] train loss: 1.3695271263713948e-05 \n",
      "epoch: 18 [802142/888800 90.25%] train loss: 1.5028844245534856e-05 \n",
      "epoch: 18 [803253/888800 90.38%] train loss: 1.608887941983994e-05 \n",
      "epoch: 18 [804364/888800 90.50%] train loss: 1.3740175745624583e-05 \n",
      "epoch: 18 [805475/888800 90.62%] train loss: 1.4548643775924575e-05 \n",
      "epoch: 18 [806586/888800 90.75%] train loss: 1.3907919310440775e-05 \n",
      "epoch: 18 [807697/888800 90.88%] train loss: 1.4300224393082317e-05 \n",
      "epoch: 18 [808808/888800 91.00%] train loss: 1.3714184206037316e-05 \n",
      "epoch: 18 [809919/888800 91.12%] train loss: 1.403456917614676e-05 \n",
      "epoch: 18 [811030/888800 91.25%] train loss: 1.5139479728532024e-05 \n",
      "epoch: 18 [812141/888800 91.38%] train loss: 1.5177644854702521e-05 \n",
      "epoch: 18 [813252/888800 91.50%] train loss: 1.564630656503141e-05 \n",
      "epoch: 18 [814363/888800 91.62%] train loss: 1.443391101929592e-05 \n",
      "epoch: 18 [815474/888800 91.75%] train loss: 1.4812225344940089e-05 \n",
      "epoch: 18 [816585/888800 91.88%] train loss: 1.4082737834542058e-05 \n",
      "epoch: 18 [817696/888800 92.00%] train loss: 1.4720880244567525e-05 \n",
      "epoch: 18 [818807/888800 92.12%] train loss: 1.4498006748908665e-05 \n",
      "epoch: 18 [819918/888800 92.25%] train loss: 1.4594617823604494e-05 \n",
      "epoch: 18 [821029/888800 92.38%] train loss: 1.3720846254727803e-05 \n",
      "epoch: 18 [822140/888800 92.50%] train loss: 1.4565089259122033e-05 \n",
      "epoch: 18 [823251/888800 92.62%] train loss: 1.4091365301283076e-05 \n",
      "epoch: 18 [824362/888800 92.75%] train loss: 1.5015280951047316e-05 \n",
      "epoch: 18 [825473/888800 92.88%] train loss: 1.547290594317019e-05 \n",
      "epoch: 18 [826584/888800 93.00%] train loss: 1.4738828213012312e-05 \n",
      "epoch: 18 [827695/888800 93.12%] train loss: 1.4400076906895265e-05 \n",
      "epoch: 18 [828806/888800 93.25%] train loss: 1.3381406461121514e-05 \n",
      "epoch: 18 [829917/888800 93.38%] train loss: 1.4007540812599473e-05 \n",
      "epoch: 18 [831028/888800 93.50%] train loss: 1.3723453776037786e-05 \n",
      "epoch: 18 [832139/888800 93.62%] train loss: 1.4437232493946794e-05 \n",
      "epoch: 18 [833250/888800 93.75%] train loss: 1.2993995369470213e-05 \n",
      "epoch: 18 [834361/888800 93.88%] train loss: 1.4373263184097596e-05 \n",
      "epoch: 18 [835472/888800 94.00%] train loss: 1.4021617971593514e-05 \n",
      "epoch: 18 [836583/888800 94.12%] train loss: 1.4620597539760638e-05 \n",
      "epoch: 18 [837694/888800 94.25%] train loss: 1.3946626495453529e-05 \n",
      "epoch: 18 [838805/888800 94.38%] train loss: 1.3855748875357676e-05 \n",
      "epoch: 18 [839916/888800 94.50%] train loss: 1.3869173926650546e-05 \n",
      "epoch: 18 [841027/888800 94.62%] train loss: 1.424441234121332e-05 \n",
      "epoch: 18 [842138/888800 94.75%] train loss: 1.4303571333584841e-05 \n",
      "epoch: 18 [843249/888800 94.88%] train loss: 1.401068948325701e-05 \n",
      "epoch: 18 [844360/888800 95.00%] train loss: 1.4577213732991368e-05 \n",
      "epoch: 18 [845471/888800 95.12%] train loss: 1.3007897905481514e-05 \n",
      "epoch: 18 [846582/888800 95.25%] train loss: 1.3092890185362194e-05 \n",
      "epoch: 18 [847693/888800 95.38%] train loss: 1.460864041291643e-05 \n",
      "epoch: 18 [848804/888800 95.50%] train loss: 1.3079724340059329e-05 \n",
      "epoch: 18 [849915/888800 95.62%] train loss: 1.4565781384590082e-05 \n",
      "epoch: 18 [851026/888800 95.75%] train loss: 1.493351737735793e-05 \n",
      "epoch: 18 [852137/888800 95.88%] train loss: 1.5051663467602339e-05 \n",
      "epoch: 18 [853248/888800 96.00%] train loss: 1.270683787879534e-05 \n",
      "epoch: 18 [854359/888800 96.12%] train loss: 1.40920446938253e-05 \n",
      "epoch: 18 [855470/888800 96.25%] train loss: 1.3666491213371046e-05 \n",
      "epoch: 18 [856581/888800 96.38%] train loss: 1.2431954928615596e-05 \n",
      "epoch: 18 [857692/888800 96.50%] train loss: 1.3621594916912727e-05 \n",
      "epoch: 18 [858803/888800 96.62%] train loss: 1.3935986316937488e-05 \n",
      "epoch: 18 [859914/888800 96.75%] train loss: 1.5462048395420425e-05 \n",
      "epoch: 18 [861025/888800 96.88%] train loss: 1.5417557733599097e-05 \n",
      "epoch: 18 [862136/888800 97.00%] train loss: 1.4789092347200494e-05 \n",
      "epoch: 18 [863247/888800 97.12%] train loss: 1.3937960829935037e-05 \n",
      "epoch: 18 [864358/888800 97.25%] train loss: 1.3525137546821497e-05 \n",
      "epoch: 18 [865469/888800 97.38%] train loss: 1.4565030141966417e-05 \n",
      "epoch: 18 [866580/888800 97.50%] train loss: 1.3480424058798235e-05 \n",
      "epoch: 18 [867691/888800 97.62%] train loss: 1.636319029785227e-05 \n",
      "epoch: 18 [868802/888800 97.75%] train loss: 1.4274769455369096e-05 \n",
      "epoch: 18 [869913/888800 97.88%] train loss: 1.3605224921775516e-05 \n",
      "epoch: 18 [871024/888800 98.00%] train loss: 1.3994142136652954e-05 \n",
      "epoch: 18 [872135/888800 98.12%] train loss: 1.4168570487527177e-05 \n",
      "epoch: 18 [873246/888800 98.25%] train loss: 1.5766207070555538e-05 \n",
      "epoch: 18 [874357/888800 98.38%] train loss: 1.542652717034798e-05 \n",
      "epoch: 18 [875468/888800 98.50%] train loss: 1.400772453052923e-05 \n",
      "epoch: 18 [876579/888800 98.62%] train loss: 1.5393108697026037e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 [877690/888800 98.75%] train loss: 1.4144719898467883e-05 \n",
      "epoch: 18 [878801/888800 98.88%] train loss: 1.4824187928752508e-05 \n",
      "epoch: 18 [879912/888800 99.00%] train loss: 1.4661126442661043e-05 \n",
      "epoch: 18 [881023/888800 99.12%] train loss: 1.3811184544465505e-05 \n",
      "epoch: 18 [882134/888800 99.25%] train loss: 1.5334380805143155e-05 \n",
      "epoch: 18 [883245/888800 99.38%] train loss: 1.5294281183741987e-05 \n",
      "epoch: 18 [884356/888800 99.50%] train loss: 1.5496978448936716e-05 \n",
      "epoch: 18 [885467/888800 99.62%] train loss: 1.4992402611824218e-05 \n",
      "epoch: 18 [886578/888800 99.75%] train loss: 1.3211985788075253e-05 \n",
      "epoch: 18 [887689/888800 99.88%] train loss: 1.5120072021090891e-05 \n",
      "epoch: 19 [0/888800 0.00%] train loss: 1.4207274944055825e-05 \n",
      "epoch: 19 [1111/888800 0.12%] train loss: 1.4843541976006236e-05 \n",
      "epoch: 19 [2222/888800 0.25%] train loss: 1.5010848073870875e-05 \n",
      "epoch: 19 [3333/888800 0.38%] train loss: 1.3974922694615088e-05 \n",
      "epoch: 19 [4444/888800 0.50%] train loss: 1.3397205293586012e-05 \n",
      "epoch: 19 [5555/888800 0.62%] train loss: 1.4770012057852e-05 \n",
      "epoch: 19 [6666/888800 0.75%] train loss: 1.3474999832396861e-05 \n",
      "epoch: 19 [7777/888800 0.88%] train loss: 1.529098517494276e-05 \n",
      "epoch: 19 [8888/888800 1.00%] train loss: 1.550746128486935e-05 \n",
      "epoch: 19 [9999/888800 1.12%] train loss: 1.5699628420406953e-05 \n",
      "epoch: 19 [11110/888800 1.25%] train loss: 1.379223249386996e-05 \n",
      "epoch: 19 [12221/888800 1.38%] train loss: 1.3677748938789591e-05 \n",
      "epoch: 19 [13332/888800 1.50%] train loss: 1.2347711162874475e-05 \n",
      "epoch: 19 [14443/888800 1.62%] train loss: 1.5091637578734662e-05 \n",
      "epoch: 19 [15554/888800 1.75%] train loss: 1.5607645764248446e-05 \n",
      "epoch: 19 [16665/888800 1.88%] train loss: 1.3824173038301524e-05 \n",
      "epoch: 19 [17776/888800 2.00%] train loss: 1.4754594303667545e-05 \n",
      "epoch: 19 [18887/888800 2.12%] train loss: 1.4194613868312445e-05 \n",
      "epoch: 19 [19998/888800 2.25%] train loss: 1.4296325389295816e-05 \n",
      "epoch: 19 [21109/888800 2.38%] train loss: 1.3240194675745443e-05 \n",
      "epoch: 19 [22220/888800 2.50%] train loss: 1.4608930541726295e-05 \n",
      "epoch: 19 [23331/888800 2.62%] train loss: 1.5365987565019168e-05 \n",
      "epoch: 19 [24442/888800 2.75%] train loss: 1.4084270333114546e-05 \n",
      "epoch: 19 [25553/888800 2.88%] train loss: 1.3405812751443591e-05 \n",
      "epoch: 19 [26664/888800 3.00%] train loss: 1.5223104128381237e-05 \n",
      "epoch: 19 [27775/888800 3.12%] train loss: 1.3596838471130468e-05 \n",
      "epoch: 19 [28886/888800 3.25%] train loss: 1.4908863704476971e-05 \n",
      "epoch: 19 [29997/888800 3.38%] train loss: 1.5155208529904485e-05 \n",
      "epoch: 19 [31108/888800 3.50%] train loss: 1.3863901585864369e-05 \n",
      "epoch: 19 [32219/888800 3.62%] train loss: 1.3956572729512118e-05 \n",
      "epoch: 19 [33330/888800 3.75%] train loss: 1.544447695778217e-05 \n",
      "epoch: 19 [34441/888800 3.88%] train loss: 1.4758657925995067e-05 \n",
      "epoch: 19 [35552/888800 4.00%] train loss: 1.5029575479275081e-05 \n",
      "epoch: 19 [36663/888800 4.12%] train loss: 1.7452630345360376e-05 \n",
      "epoch: 19 [37774/888800 4.25%] train loss: 1.4420298612094484e-05 \n",
      "epoch: 19 [38885/888800 4.38%] train loss: 1.5004938177298754e-05 \n",
      "epoch: 19 [39996/888800 4.50%] train loss: 1.4158993508317508e-05 \n",
      "epoch: 19 [41107/888800 4.62%] train loss: 1.343035910394974e-05 \n",
      "epoch: 19 [42218/888800 4.75%] train loss: 1.4222957361198496e-05 \n",
      "epoch: 19 [43329/888800 4.88%] train loss: 1.496092681918526e-05 \n",
      "epoch: 19 [44440/888800 5.00%] train loss: 1.4998654478404205e-05 \n",
      "epoch: 19 [45551/888800 5.12%] train loss: 1.4123223081696779e-05 \n",
      "epoch: 19 [46662/888800 5.25%] train loss: 1.5480649381061085e-05 \n",
      "epoch: 19 [47773/888800 5.38%] train loss: 1.466921457904391e-05 \n",
      "epoch: 19 [48884/888800 5.50%] train loss: 1.4242043107515201e-05 \n",
      "epoch: 19 [49995/888800 5.62%] train loss: 1.3966790902486537e-05 \n",
      "epoch: 19 [51106/888800 5.75%] train loss: 1.5117291695787571e-05 \n",
      "epoch: 19 [52217/888800 5.88%] train loss: 1.4296128938440233e-05 \n",
      "epoch: 19 [53328/888800 6.00%] train loss: 1.3450292499328498e-05 \n",
      "epoch: 19 [54439/888800 6.12%] train loss: 1.656609856581781e-05 \n",
      "epoch: 19 [55550/888800 6.25%] train loss: 1.3954610949440394e-05 \n",
      "epoch: 19 [56661/888800 6.38%] train loss: 1.356061693513766e-05 \n",
      "epoch: 19 [57772/888800 6.50%] train loss: 1.4750337868463248e-05 \n",
      "epoch: 19 [58883/888800 6.62%] train loss: 1.4923427443136461e-05 \n",
      "epoch: 19 [59994/888800 6.75%] train loss: 1.4378021660377271e-05 \n",
      "epoch: 19 [61105/888800 6.88%] train loss: 1.4414164070331026e-05 \n",
      "epoch: 19 [62216/888800 7.00%] train loss: 1.3872557246941142e-05 \n",
      "epoch: 19 [63327/888800 7.12%] train loss: 1.5114106645341963e-05 \n",
      "epoch: 19 [64438/888800 7.25%] train loss: 1.3547097296395805e-05 \n",
      "epoch: 19 [65549/888800 7.38%] train loss: 1.3982235941512045e-05 \n",
      "epoch: 19 [66660/888800 7.50%] train loss: 1.4310597180156037e-05 \n",
      "epoch: 19 [67771/888800 7.62%] train loss: 1.587105361977592e-05 \n",
      "epoch: 19 [68882/888800 7.75%] train loss: 1.291121770918835e-05 \n",
      "epoch: 19 [69993/888800 7.88%] train loss: 1.4569655832019635e-05 \n",
      "epoch: 19 [71104/888800 8.00%] train loss: 1.3980331459606532e-05 \n",
      "epoch: 19 [72215/888800 8.12%] train loss: 1.3743654562858865e-05 \n",
      "epoch: 19 [73326/888800 8.25%] train loss: 1.488350062572863e-05 \n",
      "epoch: 19 [74437/888800 8.38%] train loss: 1.361176236969186e-05 \n",
      "epoch: 19 [75548/888800 8.50%] train loss: 1.4579311027773656e-05 \n",
      "epoch: 19 [76659/888800 8.62%] train loss: 1.4088615898799617e-05 \n",
      "epoch: 19 [77770/888800 8.75%] train loss: 1.2681050975515973e-05 \n",
      "epoch: 19 [78881/888800 8.88%] train loss: 1.5884235835983418e-05 \n",
      "epoch: 19 [79992/888800 9.00%] train loss: 1.478426293033408e-05 \n",
      "epoch: 19 [81103/888800 9.12%] train loss: 1.3475745618052315e-05 \n",
      "epoch: 19 [82214/888800 9.25%] train loss: 1.4370688404596876e-05 \n",
      "epoch: 19 [83325/888800 9.38%] train loss: 1.3596703865914606e-05 \n",
      "epoch: 19 [84436/888800 9.50%] train loss: 1.4056718100619037e-05 \n",
      "epoch: 19 [85547/888800 9.62%] train loss: 1.3498036423698068e-05 \n",
      "epoch: 19 [86658/888800 9.75%] train loss: 1.5794403225299902e-05 \n",
      "epoch: 19 [87769/888800 9.88%] train loss: 1.3018406207265798e-05 \n",
      "epoch: 19 [88880/888800 10.00%] train loss: 1.5575789802824147e-05 \n",
      "epoch: 19 [89991/888800 10.12%] train loss: 1.3503981790563557e-05 \n",
      "epoch: 19 [91102/888800 10.25%] train loss: 1.3642610610986594e-05 \n",
      "epoch: 19 [92213/888800 10.38%] train loss: 1.5207153410301544e-05 \n",
      "epoch: 19 [93324/888800 10.50%] train loss: 1.5120732314244378e-05 \n",
      "epoch: 19 [94435/888800 10.62%] train loss: 1.3733368177781813e-05 \n",
      "epoch: 19 [95546/888800 10.75%] train loss: 1.3775690604234114e-05 \n",
      "epoch: 19 [96657/888800 10.88%] train loss: 1.3851764379069209e-05 \n",
      "epoch: 19 [97768/888800 11.00%] train loss: 1.5229751625156496e-05 \n",
      "epoch: 19 [98879/888800 11.12%] train loss: 1.3701404895982705e-05 \n",
      "epoch: 19 [99990/888800 11.25%] train loss: 1.4248585102905054e-05 \n",
      "epoch: 19 [101101/888800 11.38%] train loss: 1.4938950698706321e-05 \n",
      "epoch: 19 [102212/888800 11.50%] train loss: 1.4375151295098476e-05 \n",
      "epoch: 19 [103323/888800 11.62%] train loss: 1.4004479453433305e-05 \n",
      "epoch: 19 [104434/888800 11.75%] train loss: 1.5074325347086415e-05 \n",
      "epoch: 19 [105545/888800 11.88%] train loss: 1.472187796025537e-05 \n",
      "epoch: 19 [106656/888800 12.00%] train loss: 1.395602976117516e-05 \n",
      "epoch: 19 [107767/888800 12.12%] train loss: 1.424489983037347e-05 \n",
      "epoch: 19 [108878/888800 12.25%] train loss: 1.4885606105963234e-05 \n",
      "epoch: 19 [109989/888800 12.38%] train loss: 1.4283034943218809e-05 \n",
      "epoch: 19 [111100/888800 12.50%] train loss: 1.4818097042734735e-05 \n",
      "epoch: 19 [112211/888800 12.62%] train loss: 1.3333446986507624e-05 \n",
      "epoch: 19 [113322/888800 12.75%] train loss: 1.5240573702612892e-05 \n",
      "epoch: 19 [114433/888800 12.88%] train loss: 1.3228043826529756e-05 \n",
      "epoch: 19 [115544/888800 13.00%] train loss: 1.4738679055881221e-05 \n",
      "epoch: 19 [116655/888800 13.12%] train loss: 1.3888892681279685e-05 \n",
      "epoch: 19 [117766/888800 13.25%] train loss: 1.440595315216342e-05 \n",
      "epoch: 19 [118877/888800 13.38%] train loss: 1.4078577805776149e-05 \n",
      "epoch: 19 [119988/888800 13.50%] train loss: 1.5482142771361396e-05 \n",
      "epoch: 19 [121099/888800 13.62%] train loss: 1.5061285012052394e-05 \n",
      "epoch: 19 [122210/888800 13.75%] train loss: 1.4780490346311126e-05 \n",
      "epoch: 19 [123321/888800 13.88%] train loss: 1.5754443666082807e-05 \n",
      "epoch: 19 [124432/888800 14.00%] train loss: 1.2697415513684973e-05 \n",
      "epoch: 19 [125543/888800 14.12%] train loss: 1.3163808034732938e-05 \n",
      "epoch: 19 [126654/888800 14.25%] train loss: 1.3601250429928768e-05 \n",
      "epoch: 19 [127765/888800 14.38%] train loss: 1.5543171684839763e-05 \n",
      "epoch: 19 [128876/888800 14.50%] train loss: 1.3688332728634123e-05 \n",
      "epoch: 19 [129987/888800 14.62%] train loss: 1.4577145520888735e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [131098/888800 14.75%] train loss: 1.3113855857227463e-05 \n",
      "epoch: 19 [132209/888800 14.88%] train loss: 1.4247177205106709e-05 \n",
      "epoch: 19 [133320/888800 15.00%] train loss: 1.282458924833918e-05 \n",
      "epoch: 19 [134431/888800 15.12%] train loss: 1.4660992746939883e-05 \n",
      "epoch: 19 [135542/888800 15.25%] train loss: 1.5215594430628698e-05 \n",
      "epoch: 19 [136653/888800 15.38%] train loss: 1.3819641935697291e-05 \n",
      "epoch: 19 [137764/888800 15.50%] train loss: 1.3766052688879427e-05 \n",
      "epoch: 19 [138875/888800 15.62%] train loss: 1.4763823855901137e-05 \n",
      "epoch: 19 [139986/888800 15.75%] train loss: 1.3293431948113721e-05 \n",
      "epoch: 19 [141097/888800 15.88%] train loss: 1.407995296176523e-05 \n",
      "epoch: 19 [142208/888800 16.00%] train loss: 1.4712134543515276e-05 \n",
      "epoch: 19 [143319/888800 16.12%] train loss: 1.577122020535171e-05 \n",
      "epoch: 19 [144430/888800 16.25%] train loss: 1.5037639059301e-05 \n",
      "epoch: 19 [145541/888800 16.38%] train loss: 1.5053066817927174e-05 \n",
      "epoch: 19 [146652/888800 16.50%] train loss: 1.4266094694903586e-05 \n",
      "epoch: 19 [147763/888800 16.62%] train loss: 1.6017185771488585e-05 \n",
      "epoch: 19 [148874/888800 16.75%] train loss: 1.5368570529972203e-05 \n",
      "epoch: 19 [149985/888800 16.88%] train loss: 1.6386766219511628e-05 \n",
      "epoch: 19 [151096/888800 17.00%] train loss: 1.4402196029550396e-05 \n",
      "epoch: 19 [152207/888800 17.12%] train loss: 1.5019740203570109e-05 \n",
      "epoch: 19 [153318/888800 17.25%] train loss: 1.4506274055747781e-05 \n",
      "epoch: 19 [154429/888800 17.38%] train loss: 1.562946999911219e-05 \n",
      "epoch: 19 [155540/888800 17.50%] train loss: 1.3613369446829893e-05 \n",
      "epoch: 19 [156651/888800 17.62%] train loss: 1.3017420315009076e-05 \n",
      "epoch: 19 [157762/888800 17.75%] train loss: 1.421247907273937e-05 \n",
      "epoch: 19 [158873/888800 17.88%] train loss: 1.4768451364943758e-05 \n",
      "epoch: 19 [159984/888800 18.00%] train loss: 1.5355788491433486e-05 \n",
      "epoch: 19 [161095/888800 18.12%] train loss: 1.49964971569716e-05 \n",
      "epoch: 19 [162206/888800 18.25%] train loss: 1.5229260498017538e-05 \n",
      "epoch: 19 [163317/888800 18.38%] train loss: 1.4357215150084812e-05 \n",
      "epoch: 19 [164428/888800 18.50%] train loss: 1.3612845577881671e-05 \n",
      "epoch: 19 [165539/888800 18.62%] train loss: 1.56394798977999e-05 \n",
      "epoch: 19 [166650/888800 18.75%] train loss: 1.3958889212517533e-05 \n",
      "epoch: 19 [167761/888800 18.88%] train loss: 1.3872358067601454e-05 \n",
      "epoch: 19 [168872/888800 19.00%] train loss: 1.5037617231428158e-05 \n",
      "epoch: 19 [169983/888800 19.12%] train loss: 1.4228265172278043e-05 \n",
      "epoch: 19 [171094/888800 19.25%] train loss: 1.2738051736960188e-05 \n",
      "epoch: 19 [172205/888800 19.38%] train loss: 1.5798907043063082e-05 \n",
      "epoch: 19 [173316/888800 19.50%] train loss: 1.4032525541551877e-05 \n",
      "epoch: 19 [174427/888800 19.62%] train loss: 1.4427057067223359e-05 \n",
      "epoch: 19 [175538/888800 19.75%] train loss: 1.3428141755866818e-05 \n",
      "epoch: 19 [176649/888800 19.88%] train loss: 1.3694310837308876e-05 \n",
      "epoch: 19 [177760/888800 20.00%] train loss: 1.5653609807486646e-05 \n",
      "epoch: 19 [178871/888800 20.12%] train loss: 1.4206896594259888e-05 \n",
      "epoch: 19 [179982/888800 20.25%] train loss: 1.540416087664198e-05 \n",
      "epoch: 19 [181093/888800 20.38%] train loss: 1.4544687473971862e-05 \n",
      "epoch: 19 [182204/888800 20.50%] train loss: 1.3705684978049248e-05 \n",
      "epoch: 19 [183315/888800 20.62%] train loss: 1.4139597624307498e-05 \n",
      "epoch: 19 [184426/888800 20.75%] train loss: 1.4951149751141202e-05 \n",
      "epoch: 19 [185537/888800 20.88%] train loss: 1.5169962352956645e-05 \n",
      "epoch: 19 [186648/888800 21.00%] train loss: 1.5210574019874912e-05 \n",
      "epoch: 19 [187759/888800 21.12%] train loss: 1.4612669474445283e-05 \n",
      "epoch: 19 [188870/888800 21.25%] train loss: 1.2794208487321157e-05 \n",
      "epoch: 19 [189981/888800 21.38%] train loss: 1.355557469651103e-05 \n",
      "epoch: 19 [191092/888800 21.50%] train loss: 1.3781406778434757e-05 \n",
      "epoch: 19 [192203/888800 21.62%] train loss: 1.396713651047321e-05 \n",
      "epoch: 19 [193314/888800 21.75%] train loss: 1.4507025298371445e-05 \n",
      "epoch: 19 [194425/888800 21.88%] train loss: 1.4575002751371358e-05 \n",
      "epoch: 19 [195536/888800 22.00%] train loss: 1.4622237358707935e-05 \n",
      "epoch: 19 [196647/888800 22.12%] train loss: 1.377216904074885e-05 \n",
      "epoch: 19 [197758/888800 22.25%] train loss: 1.3751374353887513e-05 \n",
      "epoch: 19 [198869/888800 22.38%] train loss: 1.4493040907836985e-05 \n",
      "epoch: 19 [199980/888800 22.50%] train loss: 1.3363246580411214e-05 \n",
      "epoch: 19 [201091/888800 22.62%] train loss: 1.4010784070705995e-05 \n",
      "epoch: 19 [202202/888800 22.75%] train loss: 1.4398717212316114e-05 \n",
      "epoch: 19 [203313/888800 22.88%] train loss: 1.4610258403990883e-05 \n",
      "epoch: 19 [204424/888800 23.00%] train loss: 1.4072122212382965e-05 \n",
      "epoch: 19 [205535/888800 23.12%] train loss: 1.3572280295193195e-05 \n",
      "epoch: 19 [206646/888800 23.25%] train loss: 1.3532055163523182e-05 \n",
      "epoch: 19 [207757/888800 23.38%] train loss: 1.562240140629001e-05 \n",
      "epoch: 19 [208868/888800 23.50%] train loss: 1.3672523891727906e-05 \n",
      "epoch: 19 [209979/888800 23.62%] train loss: 1.43602865136927e-05 \n",
      "epoch: 19 [211090/888800 23.75%] train loss: 1.6058995242929086e-05 \n",
      "epoch: 19 [212201/888800 23.88%] train loss: 1.3232382116257213e-05 \n",
      "epoch: 19 [213312/888800 24.00%] train loss: 1.4836924492556136e-05 \n",
      "epoch: 19 [214423/888800 24.12%] train loss: 1.3961232980364002e-05 \n",
      "epoch: 19 [215534/888800 24.25%] train loss: 1.3553253666032106e-05 \n",
      "epoch: 19 [216645/888800 24.38%] train loss: 1.4570452549378388e-05 \n",
      "epoch: 19 [217756/888800 24.50%] train loss: 1.6266636521322653e-05 \n",
      "epoch: 19 [218867/888800 24.62%] train loss: 1.375992451357888e-05 \n",
      "epoch: 19 [219978/888800 24.75%] train loss: 1.484805852669524e-05 \n",
      "epoch: 19 [221089/888800 24.88%] train loss: 1.3953578672953881e-05 \n",
      "epoch: 19 [222200/888800 25.00%] train loss: 1.3306404071045108e-05 \n",
      "epoch: 19 [223311/888800 25.12%] train loss: 1.5010955394245684e-05 \n",
      "epoch: 19 [224422/888800 25.25%] train loss: 1.5304360204027034e-05 \n",
      "epoch: 19 [225533/888800 25.38%] train loss: 1.4265446225181222e-05 \n",
      "epoch: 19 [226644/888800 25.50%] train loss: 1.605158468009904e-05 \n",
      "epoch: 19 [227755/888800 25.62%] train loss: 1.5191747479548212e-05 \n",
      "epoch: 19 [228866/888800 25.75%] train loss: 1.5857327525736764e-05 \n",
      "epoch: 19 [229977/888800 25.88%] train loss: 1.3610180758405477e-05 \n",
      "epoch: 19 [231088/888800 26.00%] train loss: 1.491808143327944e-05 \n",
      "epoch: 19 [232199/888800 26.12%] train loss: 1.2740621968987398e-05 \n",
      "epoch: 19 [233310/888800 26.25%] train loss: 1.4553153960150667e-05 \n",
      "epoch: 19 [234421/888800 26.38%] train loss: 1.4410891708394047e-05 \n",
      "epoch: 19 [235532/888800 26.50%] train loss: 1.4892366380081512e-05 \n",
      "epoch: 19 [236643/888800 26.62%] train loss: 1.5694278772571124e-05 \n",
      "epoch: 19 [237754/888800 26.75%] train loss: 1.3786173440166749e-05 \n",
      "epoch: 19 [238865/888800 26.88%] train loss: 1.5241108485497534e-05 \n",
      "epoch: 19 [239976/888800 27.00%] train loss: 1.4210443623596802e-05 \n",
      "epoch: 19 [241087/888800 27.12%] train loss: 1.4219715012586676e-05 \n",
      "epoch: 19 [242198/888800 27.25%] train loss: 1.3275126548251137e-05 \n",
      "epoch: 19 [243309/888800 27.38%] train loss: 1.4169026144372765e-05 \n",
      "epoch: 19 [244420/888800 27.50%] train loss: 1.5100084056030028e-05 \n",
      "epoch: 19 [245531/888800 27.62%] train loss: 1.4512371308228467e-05 \n",
      "epoch: 19 [246642/888800 27.75%] train loss: 1.390143279422773e-05 \n",
      "epoch: 19 [247753/888800 27.88%] train loss: 1.3056015632173512e-05 \n",
      "epoch: 19 [248864/888800 28.00%] train loss: 1.3884059626434464e-05 \n",
      "epoch: 19 [249975/888800 28.12%] train loss: 1.3731957551499363e-05 \n",
      "epoch: 19 [251086/888800 28.25%] train loss: 1.4290650142356753e-05 \n",
      "epoch: 19 [252197/888800 28.38%] train loss: 1.4139595805318095e-05 \n",
      "epoch: 19 [253308/888800 28.50%] train loss: 1.4167439985612873e-05 \n",
      "epoch: 19 [254419/888800 28.62%] train loss: 1.527833956060931e-05 \n",
      "epoch: 19 [255530/888800 28.75%] train loss: 1.4491092770185787e-05 \n",
      "epoch: 19 [256641/888800 28.88%] train loss: 1.3894613402953837e-05 \n",
      "epoch: 19 [257752/888800 29.00%] train loss: 1.4223265679902397e-05 \n",
      "epoch: 19 [258863/888800 29.12%] train loss: 1.3233639037935063e-05 \n",
      "epoch: 19 [259974/888800 29.25%] train loss: 1.3882953680877108e-05 \n",
      "epoch: 19 [261085/888800 29.38%] train loss: 1.4427640962821897e-05 \n",
      "epoch: 19 [262196/888800 29.50%] train loss: 1.2656064427574165e-05 \n",
      "epoch: 19 [263307/888800 29.62%] train loss: 1.313602570007788e-05 \n",
      "epoch: 19 [264418/888800 29.75%] train loss: 1.4101741726335604e-05 \n",
      "epoch: 19 [265529/888800 29.88%] train loss: 1.3358871001400985e-05 \n",
      "epoch: 19 [266640/888800 30.00%] train loss: 1.4799142263655085e-05 \n",
      "epoch: 19 [267751/888800 30.12%] train loss: 1.4460890270129312e-05 \n",
      "epoch: 19 [268862/888800 30.25%] train loss: 1.3805218259221874e-05 \n",
      "epoch: 19 [269973/888800 30.38%] train loss: 1.3706745448871516e-05 \n",
      "epoch: 19 [271084/888800 30.50%] train loss: 1.506506305304356e-05 \n",
      "epoch: 19 [272195/888800 30.62%] train loss: 1.455769051972311e-05 \n",
      "epoch: 19 [273306/888800 30.75%] train loss: 1.4945218026696239e-05 \n",
      "epoch: 19 [274417/888800 30.88%] train loss: 1.3276347999635618e-05 \n",
      "epoch: 19 [275528/888800 31.00%] train loss: 1.3546908121497836e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [276639/888800 31.12%] train loss: 1.4976106285757851e-05 \n",
      "epoch: 19 [277750/888800 31.25%] train loss: 1.499004883953603e-05 \n",
      "epoch: 19 [278861/888800 31.38%] train loss: 1.3321583537617698e-05 \n",
      "epoch: 19 [279972/888800 31.50%] train loss: 1.3570057490142062e-05 \n",
      "epoch: 19 [281083/888800 31.62%] train loss: 1.3898735232942272e-05 \n",
      "epoch: 19 [282194/888800 31.75%] train loss: 1.3861538718629163e-05 \n",
      "epoch: 19 [283305/888800 31.88%] train loss: 1.4406866284844e-05 \n",
      "epoch: 19 [284416/888800 32.00%] train loss: 1.352976050839061e-05 \n",
      "epoch: 19 [285527/888800 32.12%] train loss: 1.4768090295547154e-05 \n",
      "epoch: 19 [286638/888800 32.25%] train loss: 1.3886467968404759e-05 \n",
      "epoch: 19 [287749/888800 32.38%] train loss: 1.5231727047648747e-05 \n",
      "epoch: 19 [288860/888800 32.50%] train loss: 1.3976915397506673e-05 \n",
      "epoch: 19 [289971/888800 32.62%] train loss: 1.494844036642462e-05 \n",
      "epoch: 19 [291082/888800 32.75%] train loss: 1.5059796169225592e-05 \n",
      "epoch: 19 [292193/888800 32.88%] train loss: 1.4337472748593427e-05 \n",
      "epoch: 19 [293304/888800 33.00%] train loss: 1.3763526112597901e-05 \n",
      "epoch: 19 [294415/888800 33.12%] train loss: 1.4708582966704853e-05 \n",
      "epoch: 19 [295526/888800 33.25%] train loss: 1.3903713806939777e-05 \n",
      "epoch: 19 [296637/888800 33.38%] train loss: 1.4647363968833815e-05 \n",
      "epoch: 19 [297748/888800 33.50%] train loss: 1.4466683751379605e-05 \n",
      "epoch: 19 [298859/888800 33.62%] train loss: 1.4945478142180946e-05 \n",
      "epoch: 19 [299970/888800 33.75%] train loss: 1.4945670955057722e-05 \n",
      "epoch: 19 [301081/888800 33.88%] train loss: 1.416076429450186e-05 \n",
      "epoch: 19 [302192/888800 34.00%] train loss: 1.3943074009148404e-05 \n",
      "epoch: 19 [303303/888800 34.12%] train loss: 1.4246537830331363e-05 \n",
      "epoch: 19 [304414/888800 34.25%] train loss: 1.4683348126709461e-05 \n",
      "epoch: 19 [305525/888800 34.38%] train loss: 1.630094448046293e-05 \n",
      "epoch: 19 [306636/888800 34.50%] train loss: 1.4215470400813501e-05 \n",
      "epoch: 19 [307747/888800 34.62%] train loss: 1.593235538166482e-05 \n",
      "epoch: 19 [308858/888800 34.75%] train loss: 1.4491243746306282e-05 \n",
      "epoch: 19 [309969/888800 34.88%] train loss: 1.4521041521220468e-05 \n",
      "epoch: 19 [311080/888800 35.00%] train loss: 1.4422198546526488e-05 \n",
      "epoch: 19 [312191/888800 35.12%] train loss: 1.541727215226274e-05 \n",
      "epoch: 19 [313302/888800 35.25%] train loss: 1.3789414879283868e-05 \n",
      "epoch: 19 [314413/888800 35.38%] train loss: 1.4326444215839729e-05 \n",
      "epoch: 19 [315524/888800 35.50%] train loss: 1.532695569039788e-05 \n",
      "epoch: 19 [316635/888800 35.62%] train loss: 1.4473346709564794e-05 \n",
      "epoch: 19 [317746/888800 35.75%] train loss: 1.636503111512866e-05 \n",
      "epoch: 19 [318857/888800 35.88%] train loss: 1.4587914847652428e-05 \n",
      "epoch: 19 [319968/888800 36.00%] train loss: 1.5482723028981127e-05 \n",
      "epoch: 19 [321079/888800 36.12%] train loss: 1.3316338481672574e-05 \n",
      "epoch: 19 [322190/888800 36.25%] train loss: 1.530143345007673e-05 \n",
      "epoch: 19 [323301/888800 36.38%] train loss: 1.5050691217766143e-05 \n",
      "epoch: 19 [324412/888800 36.50%] train loss: 1.3707744983548764e-05 \n",
      "epoch: 19 [325523/888800 36.62%] train loss: 1.5112666915229056e-05 \n",
      "epoch: 19 [326634/888800 36.75%] train loss: 1.5192470527836122e-05 \n",
      "epoch: 19 [327745/888800 36.88%] train loss: 1.4811596884101164e-05 \n",
      "epoch: 19 [328856/888800 37.00%] train loss: 1.5115355381567497e-05 \n",
      "epoch: 19 [329967/888800 37.12%] train loss: 1.4733099305885844e-05 \n",
      "epoch: 19 [331078/888800 37.25%] train loss: 1.381766105623683e-05 \n",
      "epoch: 19 [332189/888800 37.38%] train loss: 1.3962849152449053e-05 \n",
      "epoch: 19 [333300/888800 37.50%] train loss: 1.4101960914558731e-05 \n",
      "epoch: 19 [334411/888800 37.62%] train loss: 1.3221218978287652e-05 \n",
      "epoch: 19 [335522/888800 37.75%] train loss: 1.5200064808595926e-05 \n",
      "epoch: 19 [336633/888800 37.88%] train loss: 1.5057579730637372e-05 \n",
      "epoch: 19 [337744/888800 38.00%] train loss: 1.4705439753015526e-05 \n",
      "epoch: 19 [338855/888800 38.12%] train loss: 1.4143529369903263e-05 \n",
      "epoch: 19 [339966/888800 38.25%] train loss: 1.3054432201897725e-05 \n",
      "epoch: 19 [341077/888800 38.38%] train loss: 1.4611086953664199e-05 \n",
      "epoch: 19 [342188/888800 38.50%] train loss: 1.3208373275119811e-05 \n",
      "epoch: 19 [343299/888800 38.62%] train loss: 1.3860804756404832e-05 \n",
      "epoch: 19 [344410/888800 38.75%] train loss: 1.3193001905165147e-05 \n",
      "epoch: 19 [345521/888800 38.88%] train loss: 1.4045263924344908e-05 \n",
      "epoch: 19 [346632/888800 39.00%] train loss: 1.4556690985045861e-05 \n",
      "epoch: 19 [347743/888800 39.12%] train loss: 1.5212293874355964e-05 \n",
      "epoch: 19 [348854/888800 39.25%] train loss: 1.4105711670708843e-05 \n",
      "epoch: 19 [349965/888800 39.38%] train loss: 1.4559566807292867e-05 \n",
      "epoch: 19 [351076/888800 39.50%] train loss: 1.4580165952793323e-05 \n",
      "epoch: 19 [352187/888800 39.62%] train loss: 1.3947348634246737e-05 \n",
      "epoch: 19 [353298/888800 39.75%] train loss: 1.3721432878810447e-05 \n",
      "epoch: 19 [354409/888800 39.88%] train loss: 1.5192472346825525e-05 \n",
      "epoch: 19 [355520/888800 40.00%] train loss: 1.410345339536434e-05 \n",
      "epoch: 19 [356631/888800 40.12%] train loss: 1.4634597391705029e-05 \n",
      "epoch: 19 [357742/888800 40.25%] train loss: 1.2935147424286697e-05 \n",
      "epoch: 19 [358853/888800 40.38%] train loss: 1.460215116821928e-05 \n",
      "epoch: 19 [359964/888800 40.50%] train loss: 1.4192910384736024e-05 \n",
      "epoch: 19 [361075/888800 40.62%] train loss: 1.4657617612101603e-05 \n",
      "epoch: 19 [362186/888800 40.75%] train loss: 1.4764105799258687e-05 \n",
      "epoch: 19 [363297/888800 40.88%] train loss: 1.4733872376382351e-05 \n",
      "epoch: 19 [364408/888800 41.00%] train loss: 1.4601250768464524e-05 \n",
      "epoch: 19 [365519/888800 41.12%] train loss: 1.3652924280904699e-05 \n",
      "epoch: 19 [366630/888800 41.25%] train loss: 1.5592240742989816e-05 \n",
      "epoch: 19 [367741/888800 41.38%] train loss: 1.4218522665032651e-05 \n",
      "epoch: 19 [368852/888800 41.50%] train loss: 1.4304551768873353e-05 \n",
      "epoch: 19 [369963/888800 41.62%] train loss: 1.3709395716432482e-05 \n",
      "epoch: 19 [371074/888800 41.75%] train loss: 1.5229735254251864e-05 \n",
      "epoch: 19 [372185/888800 41.88%] train loss: 1.462822638131911e-05 \n",
      "epoch: 19 [373296/888800 42.00%] train loss: 1.320429419138236e-05 \n",
      "epoch: 19 [374407/888800 42.12%] train loss: 1.4794103663007263e-05 \n",
      "epoch: 19 [375518/888800 42.25%] train loss: 1.346505268884357e-05 \n",
      "epoch: 19 [376629/888800 42.38%] train loss: 1.447884369554231e-05 \n",
      "epoch: 19 [377740/888800 42.50%] train loss: 1.4009094229550101e-05 \n",
      "epoch: 19 [378851/888800 42.62%] train loss: 1.4716319128638133e-05 \n",
      "epoch: 19 [379962/888800 42.75%] train loss: 1.4668155017716344e-05 \n",
      "epoch: 19 [381073/888800 42.88%] train loss: 1.3198487977206241e-05 \n",
      "epoch: 19 [382184/888800 43.00%] train loss: 1.4915271094650961e-05 \n",
      "epoch: 19 [383295/888800 43.12%] train loss: 1.5057263226481155e-05 \n",
      "epoch: 19 [384406/888800 43.25%] train loss: 1.4178381206875201e-05 \n",
      "epoch: 19 [385517/888800 43.38%] train loss: 1.4181112419464625e-05 \n",
      "epoch: 19 [386628/888800 43.50%] train loss: 1.4320743503049016e-05 \n",
      "epoch: 19 [387739/888800 43.62%] train loss: 1.4304132491815835e-05 \n",
      "epoch: 19 [388850/888800 43.75%] train loss: 1.4758195902686566e-05 \n",
      "epoch: 19 [389961/888800 43.88%] train loss: 1.5243352208926808e-05 \n",
      "epoch: 19 [391072/888800 44.00%] train loss: 1.3348702850635163e-05 \n",
      "epoch: 19 [392183/888800 44.12%] train loss: 1.3698804650630336e-05 \n",
      "epoch: 19 [393294/888800 44.25%] train loss: 1.4596432265534531e-05 \n",
      "epoch: 19 [394405/888800 44.38%] train loss: 1.417783187207533e-05 \n",
      "epoch: 19 [395516/888800 44.50%] train loss: 1.4059448403713759e-05 \n",
      "epoch: 19 [396627/888800 44.62%] train loss: 1.3040844351053238e-05 \n",
      "epoch: 19 [397738/888800 44.75%] train loss: 1.4326712516776752e-05 \n",
      "epoch: 19 [398849/888800 44.88%] train loss: 1.4972358258091845e-05 \n",
      "epoch: 19 [399960/888800 45.00%] train loss: 1.390274610457709e-05 \n",
      "epoch: 19 [401071/888800 45.12%] train loss: 1.4767401808057912e-05 \n",
      "epoch: 19 [402182/888800 45.25%] train loss: 1.4093780919210985e-05 \n",
      "epoch: 19 [403293/888800 45.38%] train loss: 1.4791404282732401e-05 \n",
      "epoch: 19 [404404/888800 45.50%] train loss: 1.3536112419387791e-05 \n",
      "epoch: 19 [405515/888800 45.62%] train loss: 1.4287782505562063e-05 \n",
      "epoch: 19 [406626/888800 45.75%] train loss: 1.4736635421286337e-05 \n",
      "epoch: 19 [407737/888800 45.88%] train loss: 1.4146427929517813e-05 \n",
      "epoch: 19 [408848/888800 46.00%] train loss: 1.4166757864586543e-05 \n",
      "epoch: 19 [409959/888800 46.12%] train loss: 1.3420308278000448e-05 \n",
      "epoch: 19 [411070/888800 46.25%] train loss: 1.4854862456559204e-05 \n",
      "epoch: 19 [412181/888800 46.38%] train loss: 1.3970254258310888e-05 \n",
      "epoch: 19 [413292/888800 46.50%] train loss: 1.530892404844053e-05 \n",
      "epoch: 19 [414403/888800 46.62%] train loss: 1.2736808457702864e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [415514/888800 46.75%] train loss: 1.3697449503524695e-05 \n",
      "epoch: 19 [416625/888800 46.88%] train loss: 1.3728017620451283e-05 \n",
      "epoch: 19 [417736/888800 47.00%] train loss: 1.587277074577287e-05 \n",
      "epoch: 19 [418847/888800 47.12%] train loss: 1.5073508620844223e-05 \n",
      "epoch: 19 [419958/888800 47.25%] train loss: 1.4472870134341065e-05 \n",
      "epoch: 19 [421069/888800 47.38%] train loss: 1.5908730347291566e-05 \n",
      "epoch: 19 [422180/888800 47.50%] train loss: 1.3859866157872602e-05 \n",
      "epoch: 19 [423291/888800 47.62%] train loss: 1.4914446182956453e-05 \n",
      "epoch: 19 [424402/888800 47.75%] train loss: 1.4208480934030376e-05 \n",
      "epoch: 19 [425513/888800 47.88%] train loss: 1.4101404303801246e-05 \n",
      "epoch: 19 [426624/888800 48.00%] train loss: 1.6024214346543886e-05 \n",
      "epoch: 19 [427735/888800 48.12%] train loss: 1.416595114278607e-05 \n",
      "epoch: 19 [428846/888800 48.25%] train loss: 1.3803334695694502e-05 \n",
      "epoch: 19 [429957/888800 48.38%] train loss: 1.534383227408398e-05 \n",
      "epoch: 19 [431068/888800 48.50%] train loss: 1.381527090416057e-05 \n",
      "epoch: 19 [432179/888800 48.62%] train loss: 1.3642515114042908e-05 \n",
      "epoch: 19 [433290/888800 48.75%] train loss: 1.3962653611088172e-05 \n",
      "epoch: 19 [434401/888800 48.88%] train loss: 1.411280027241446e-05 \n",
      "epoch: 19 [435512/888800 49.00%] train loss: 1.280521337321261e-05 \n",
      "epoch: 19 [436623/888800 49.12%] train loss: 1.3566935194830876e-05 \n",
      "epoch: 19 [437734/888800 49.25%] train loss: 1.494355183240259e-05 \n",
      "epoch: 19 [438845/888800 49.38%] train loss: 1.3295255484990776e-05 \n",
      "epoch: 19 [439956/888800 49.50%] train loss: 1.3267579561215825e-05 \n",
      "epoch: 19 [441067/888800 49.62%] train loss: 1.4899920643074438e-05 \n",
      "epoch: 19 [442178/888800 49.75%] train loss: 1.4567486687155906e-05 \n",
      "epoch: 19 [443289/888800 49.88%] train loss: 1.400670862494735e-05 \n",
      "epoch: 19 [444400/888800 50.00%] train loss: 1.41296977744787e-05 \n",
      "epoch: 19 [445511/888800 50.12%] train loss: 1.4897928849677555e-05 \n",
      "epoch: 19 [446622/888800 50.25%] train loss: 1.4748366083949804e-05 \n",
      "epoch: 19 [447733/888800 50.38%] train loss: 1.3367980500333942e-05 \n",
      "epoch: 19 [448844/888800 50.50%] train loss: 1.3420199138636235e-05 \n",
      "epoch: 19 [449955/888800 50.62%] train loss: 1.3256283637019806e-05 \n",
      "epoch: 19 [451066/888800 50.75%] train loss: 1.521352260169806e-05 \n",
      "epoch: 19 [452177/888800 50.88%] train loss: 1.3043859325989615e-05 \n",
      "epoch: 19 [453288/888800 51.00%] train loss: 1.5016356883279514e-05 \n",
      "epoch: 19 [454399/888800 51.12%] train loss: 1.5263507521012798e-05 \n",
      "epoch: 19 [455510/888800 51.25%] train loss: 1.5269337382051162e-05 \n",
      "epoch: 19 [456621/888800 51.38%] train loss: 1.278080071642762e-05 \n",
      "epoch: 19 [457732/888800 51.50%] train loss: 1.448925740987761e-05 \n",
      "epoch: 19 [458843/888800 51.62%] train loss: 1.4594158528780099e-05 \n",
      "epoch: 19 [459954/888800 51.75%] train loss: 1.5000870916992426e-05 \n",
      "epoch: 19 [461065/888800 51.88%] train loss: 1.4373731573869009e-05 \n",
      "epoch: 19 [462176/888800 52.00%] train loss: 1.5014171367511153e-05 \n",
      "epoch: 19 [463287/888800 52.12%] train loss: 1.598690687387716e-05 \n",
      "epoch: 19 [464398/888800 52.25%] train loss: 1.3749006939178798e-05 \n",
      "epoch: 19 [465509/888800 52.38%] train loss: 1.5483938113902695e-05 \n",
      "epoch: 19 [466620/888800 52.50%] train loss: 1.3909941117162816e-05 \n",
      "epoch: 19 [467731/888800 52.62%] train loss: 1.579396121087484e-05 \n",
      "epoch: 19 [468842/888800 52.75%] train loss: 1.4192542039381806e-05 \n",
      "epoch: 19 [469953/888800 52.88%] train loss: 1.5475387044716626e-05 \n",
      "epoch: 19 [471064/888800 53.00%] train loss: 1.550445449538529e-05 \n",
      "epoch: 19 [472175/888800 53.12%] train loss: 1.4235501112125348e-05 \n",
      "epoch: 19 [473286/888800 53.25%] train loss: 1.6223606507992372e-05 \n",
      "epoch: 19 [474397/888800 53.38%] train loss: 1.4603648196498398e-05 \n",
      "epoch: 19 [475508/888800 53.50%] train loss: 1.546581734146457e-05 \n",
      "epoch: 19 [476619/888800 53.62%] train loss: 1.3400427633314393e-05 \n",
      "epoch: 19 [477730/888800 53.75%] train loss: 1.598110975464806e-05 \n",
      "epoch: 19 [478841/888800 53.88%] train loss: 1.5046786757011432e-05 \n",
      "epoch: 19 [479952/888800 54.00%] train loss: 1.5162441741267685e-05 \n",
      "epoch: 19 [481063/888800 54.12%] train loss: 1.3352891073736828e-05 \n",
      "epoch: 19 [482174/888800 54.25%] train loss: 1.4282813936006278e-05 \n",
      "epoch: 19 [483285/888800 54.38%] train loss: 1.5256586266332306e-05 \n",
      "epoch: 19 [484396/888800 54.50%] train loss: 1.4167600966175087e-05 \n",
      "epoch: 19 [485507/888800 54.62%] train loss: 1.5459811038454063e-05 \n",
      "epoch: 19 [486618/888800 54.75%] train loss: 1.2995529687032104e-05 \n",
      "epoch: 19 [487729/888800 54.88%] train loss: 1.4846995327388868e-05 \n",
      "epoch: 19 [488840/888800 55.00%] train loss: 1.365137541142758e-05 \n",
      "epoch: 19 [489951/888800 55.12%] train loss: 1.380880166834686e-05 \n",
      "epoch: 19 [491062/888800 55.25%] train loss: 1.3519497770175803e-05 \n",
      "epoch: 19 [492173/888800 55.38%] train loss: 1.3877051969757304e-05 \n",
      "epoch: 19 [493284/888800 55.50%] train loss: 1.4887779798300471e-05 \n",
      "epoch: 19 [494395/888800 55.62%] train loss: 1.3705209312320221e-05 \n",
      "epoch: 19 [495506/888800 55.75%] train loss: 1.3864480024494696e-05 \n",
      "epoch: 19 [496617/888800 55.88%] train loss: 1.2894950486952439e-05 \n",
      "epoch: 19 [497728/888800 56.00%] train loss: 1.4343770999403205e-05 \n",
      "epoch: 19 [498839/888800 56.12%] train loss: 1.4016847671882715e-05 \n",
      "epoch: 19 [499950/888800 56.25%] train loss: 1.37921506393468e-05 \n",
      "epoch: 19 [501061/888800 56.38%] train loss: 1.4022127288626507e-05 \n",
      "epoch: 19 [502172/888800 56.50%] train loss: 1.4828285202383995e-05 \n",
      "epoch: 19 [503283/888800 56.62%] train loss: 1.3783441318082623e-05 \n",
      "epoch: 19 [504394/888800 56.75%] train loss: 1.3671983651875053e-05 \n",
      "epoch: 19 [505505/888800 56.88%] train loss: 1.4270938663685229e-05 \n",
      "epoch: 19 [506616/888800 57.00%] train loss: 1.4285308679973241e-05 \n",
      "epoch: 19 [507727/888800 57.12%] train loss: 1.3895270058128517e-05 \n",
      "epoch: 19 [508838/888800 57.25%] train loss: 1.2750628229696304e-05 \n",
      "epoch: 19 [509949/888800 57.38%] train loss: 1.5239056665450335e-05 \n",
      "epoch: 19 [511060/888800 57.50%] train loss: 1.3295435564941727e-05 \n",
      "epoch: 19 [512171/888800 57.62%] train loss: 1.4009800906933378e-05 \n",
      "epoch: 19 [513282/888800 57.75%] train loss: 1.3769475117442198e-05 \n",
      "epoch: 19 [514393/888800 57.88%] train loss: 1.3788870091957506e-05 \n",
      "epoch: 19 [515504/888800 58.00%] train loss: 1.3057508112979122e-05 \n",
      "epoch: 19 [516615/888800 58.12%] train loss: 1.43198121804744e-05 \n",
      "epoch: 19 [517726/888800 58.25%] train loss: 1.4556298992829397e-05 \n",
      "epoch: 19 [518837/888800 58.38%] train loss: 1.329775113845244e-05 \n",
      "epoch: 19 [519948/888800 58.50%] train loss: 1.3605651474790648e-05 \n",
      "epoch: 19 [521059/888800 58.62%] train loss: 1.4373689737112727e-05 \n",
      "epoch: 19 [522170/888800 58.75%] train loss: 1.4674204066977836e-05 \n",
      "epoch: 19 [523281/888800 58.88%] train loss: 1.3161030437913723e-05 \n",
      "epoch: 19 [524392/888800 59.00%] train loss: 1.5745234122732654e-05 \n",
      "epoch: 19 [525503/888800 59.12%] train loss: 1.4671896678919438e-05 \n",
      "epoch: 19 [526614/888800 59.25%] train loss: 1.6070114725152962e-05 \n",
      "epoch: 19 [527725/888800 59.38%] train loss: 1.3792971913062502e-05 \n",
      "epoch: 19 [528836/888800 59.50%] train loss: 1.4178874153003562e-05 \n",
      "epoch: 19 [529947/888800 59.62%] train loss: 1.3612334441859275e-05 \n",
      "epoch: 19 [531058/888800 59.75%] train loss: 1.5504432667512447e-05 \n",
      "epoch: 19 [532169/888800 59.88%] train loss: 1.3785859664494637e-05 \n",
      "epoch: 19 [533280/888800 60.00%] train loss: 1.3521037544705905e-05 \n",
      "epoch: 19 [534391/888800 60.12%] train loss: 1.3993672837386839e-05 \n",
      "epoch: 19 [535502/888800 60.25%] train loss: 1.3959760508441832e-05 \n",
      "epoch: 19 [536613/888800 60.38%] train loss: 1.2547987353173085e-05 \n",
      "epoch: 19 [537724/888800 60.50%] train loss: 1.3898832548875362e-05 \n",
      "epoch: 19 [538835/888800 60.62%] train loss: 1.2333176528045442e-05 \n",
      "epoch: 19 [539946/888800 60.75%] train loss: 1.3362116987991612e-05 \n",
      "epoch: 19 [541057/888800 60.88%] train loss: 1.4306354387372267e-05 \n",
      "epoch: 19 [542168/888800 61.00%] train loss: 1.5376665032817982e-05 \n",
      "epoch: 19 [543279/888800 61.12%] train loss: 1.4388354429684114e-05 \n",
      "epoch: 19 [544390/888800 61.25%] train loss: 1.4227623069018591e-05 \n",
      "epoch: 19 [545501/888800 61.38%] train loss: 1.2972744116268586e-05 \n",
      "epoch: 19 [546612/888800 61.50%] train loss: 1.3844055501976982e-05 \n",
      "epoch: 19 [547723/888800 61.62%] train loss: 1.4039217603567522e-05 \n",
      "epoch: 19 [548834/888800 61.75%] train loss: 1.3820783351548016e-05 \n",
      "epoch: 19 [549945/888800 61.88%] train loss: 1.523092851130059e-05 \n",
      "epoch: 19 [551056/888800 62.00%] train loss: 1.432437238690909e-05 \n",
      "epoch: 19 [552167/888800 62.12%] train loss: 1.3883864994568285e-05 \n",
      "epoch: 19 [553278/888800 62.25%] train loss: 1.5562589396722615e-05 \n",
      "epoch: 19 [554389/888800 62.38%] train loss: 1.4394320714927744e-05 \n",
      "epoch: 19 [555500/888800 62.50%] train loss: 1.4312672647065483e-05 \n",
      "epoch: 19 [556611/888800 62.62%] train loss: 1.3448291610984597e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [557722/888800 62.75%] train loss: 1.363215415040031e-05 \n",
      "epoch: 19 [558833/888800 62.88%] train loss: 1.5389579857583158e-05 \n",
      "epoch: 19 [559944/888800 63.00%] train loss: 1.3617230251838919e-05 \n",
      "epoch: 19 [561055/888800 63.12%] train loss: 1.2718141078948975e-05 \n",
      "epoch: 19 [562166/888800 63.25%] train loss: 1.4228666259441525e-05 \n",
      "epoch: 19 [563277/888800 63.38%] train loss: 1.4140107850835193e-05 \n",
      "epoch: 19 [564388/888800 63.50%] train loss: 1.514846553618554e-05 \n",
      "epoch: 19 [565499/888800 63.62%] train loss: 1.439704738004366e-05 \n",
      "epoch: 19 [566610/888800 63.75%] train loss: 1.404342310706852e-05 \n",
      "epoch: 19 [567721/888800 63.88%] train loss: 1.4298680071078707e-05 \n",
      "epoch: 19 [568832/888800 64.00%] train loss: 1.4075964827497955e-05 \n",
      "epoch: 19 [569943/888800 64.12%] train loss: 1.2667548617173452e-05 \n",
      "epoch: 19 [571054/888800 64.25%] train loss: 1.3876642697141506e-05 \n",
      "epoch: 19 [572165/888800 64.38%] train loss: 1.4508804270008113e-05 \n",
      "epoch: 19 [573276/888800 64.50%] train loss: 1.452636206522584e-05 \n",
      "epoch: 19 [574387/888800 64.62%] train loss: 1.4123226719675586e-05 \n",
      "epoch: 19 [575498/888800 64.75%] train loss: 1.4341138921736274e-05 \n",
      "epoch: 19 [576609/888800 64.88%] train loss: 1.3584382031694986e-05 \n",
      "epoch: 19 [577720/888800 65.00%] train loss: 1.3583885447587818e-05 \n",
      "epoch: 19 [578831/888800 65.12%] train loss: 1.4394337995327078e-05 \n",
      "epoch: 19 [579942/888800 65.25%] train loss: 1.3378176845435519e-05 \n",
      "epoch: 19 [581053/888800 65.38%] train loss: 1.4406941772904247e-05 \n",
      "epoch: 19 [582164/888800 65.50%] train loss: 1.4709147762914654e-05 \n",
      "epoch: 19 [583275/888800 65.62%] train loss: 1.4869409824314062e-05 \n",
      "epoch: 19 [584386/888800 65.75%] train loss: 1.4114613804849796e-05 \n",
      "epoch: 19 [585497/888800 65.88%] train loss: 1.4428736903937533e-05 \n",
      "epoch: 19 [586608/888800 66.00%] train loss: 1.4949318938306533e-05 \n",
      "epoch: 19 [587719/888800 66.12%] train loss: 1.5590891052852385e-05 \n",
      "epoch: 19 [588830/888800 66.25%] train loss: 1.4524524885928258e-05 \n",
      "epoch: 19 [589941/888800 66.38%] train loss: 1.3597290489997249e-05 \n",
      "epoch: 19 [591052/888800 66.50%] train loss: 1.4161656508804299e-05 \n",
      "epoch: 19 [592163/888800 66.62%] train loss: 1.5002284271758981e-05 \n",
      "epoch: 19 [593274/888800 66.75%] train loss: 1.3526870134228375e-05 \n",
      "epoch: 19 [594385/888800 66.88%] train loss: 1.4967116840125527e-05 \n",
      "epoch: 19 [595496/888800 67.00%] train loss: 1.3665605365531519e-05 \n",
      "epoch: 19 [596607/888800 67.12%] train loss: 1.4348044715006836e-05 \n",
      "epoch: 19 [597718/888800 67.25%] train loss: 1.569595951878e-05 \n",
      "epoch: 19 [598829/888800 67.38%] train loss: 1.4364230082719587e-05 \n",
      "epoch: 19 [599940/888800 67.50%] train loss: 1.4576499779650476e-05 \n",
      "epoch: 19 [601051/888800 67.62%] train loss: 1.3247682545625139e-05 \n",
      "epoch: 19 [602162/888800 67.75%] train loss: 1.4998340702732094e-05 \n",
      "epoch: 19 [603273/888800 67.88%] train loss: 1.3694852896151133e-05 \n",
      "epoch: 19 [604384/888800 68.00%] train loss: 1.6190464521059766e-05 \n",
      "epoch: 19 [605495/888800 68.12%] train loss: 1.3650994333147537e-05 \n",
      "epoch: 19 [606606/888800 68.25%] train loss: 1.5076863746799063e-05 \n",
      "epoch: 19 [607717/888800 68.38%] train loss: 1.4951752746128477e-05 \n",
      "epoch: 19 [608828/888800 68.50%] train loss: 1.5443463780684397e-05 \n",
      "epoch: 19 [609939/888800 68.62%] train loss: 1.4486337022390217e-05 \n",
      "epoch: 19 [611050/888800 68.75%] train loss: 1.3282005056680646e-05 \n",
      "epoch: 19 [612161/888800 68.88%] train loss: 1.4446895875153132e-05 \n",
      "epoch: 19 [613272/888800 69.00%] train loss: 1.445132693334017e-05 \n",
      "epoch: 19 [614383/888800 69.12%] train loss: 1.5111719221749809e-05 \n",
      "epoch: 19 [615494/888800 69.25%] train loss: 1.3644224964082241e-05 \n",
      "epoch: 19 [616605/888800 69.38%] train loss: 1.46794182001031e-05 \n",
      "epoch: 19 [617716/888800 69.50%] train loss: 1.6511359717696905e-05 \n",
      "epoch: 19 [618827/888800 69.62%] train loss: 1.4420456864172593e-05 \n",
      "epoch: 19 [619938/888800 69.75%] train loss: 1.585515019542072e-05 \n",
      "epoch: 19 [621049/888800 69.88%] train loss: 1.401512690790696e-05 \n",
      "epoch: 19 [622160/888800 70.00%] train loss: 1.5129572602745611e-05 \n",
      "epoch: 19 [623271/888800 70.12%] train loss: 1.432185399607988e-05 \n",
      "epoch: 19 [624382/888800 70.25%] train loss: 1.3818797015119344e-05 \n",
      "epoch: 19 [625493/888800 70.38%] train loss: 1.4779317098145839e-05 \n",
      "epoch: 19 [626604/888800 70.50%] train loss: 1.385501218464924e-05 \n",
      "epoch: 19 [627715/888800 70.62%] train loss: 1.4867426216369495e-05 \n",
      "epoch: 19 [628826/888800 70.75%] train loss: 1.3543270142690744e-05 \n",
      "epoch: 19 [629937/888800 70.88%] train loss: 1.61586758622434e-05 \n",
      "epoch: 19 [631048/888800 71.00%] train loss: 1.4563105651177466e-05 \n",
      "epoch: 19 [632159/888800 71.12%] train loss: 1.655840787861962e-05 \n",
      "epoch: 19 [633270/888800 71.25%] train loss: 1.5221929061226547e-05 \n",
      "epoch: 19 [634381/888800 71.38%] train loss: 1.31888737087138e-05 \n",
      "epoch: 19 [635492/888800 71.50%] train loss: 1.4505063518299721e-05 \n",
      "epoch: 19 [636603/888800 71.62%] train loss: 1.434921159670921e-05 \n",
      "epoch: 19 [637714/888800 71.75%] train loss: 1.51742478919914e-05 \n",
      "epoch: 19 [638825/888800 71.88%] train loss: 1.4495173672912642e-05 \n",
      "epoch: 19 [639936/888800 72.00%] train loss: 1.5092938156158198e-05 \n",
      "epoch: 19 [641047/888800 72.12%] train loss: 1.4936127627152018e-05 \n",
      "epoch: 19 [642158/888800 72.25%] train loss: 1.6800064258859493e-05 \n",
      "epoch: 19 [643269/888800 72.38%] train loss: 1.2447568224160932e-05 \n",
      "epoch: 19 [644380/888800 72.50%] train loss: 1.5186382370302454e-05 \n",
      "epoch: 19 [645491/888800 72.62%] train loss: 1.548600266687572e-05 \n",
      "epoch: 19 [646602/888800 72.75%] train loss: 1.5257975064741913e-05 \n",
      "epoch: 19 [647713/888800 72.88%] train loss: 1.612513187865261e-05 \n",
      "epoch: 19 [648824/888800 73.00%] train loss: 1.4278548405854963e-05 \n",
      "epoch: 19 [649935/888800 73.12%] train loss: 1.7449789083912037e-05 \n",
      "epoch: 19 [651046/888800 73.25%] train loss: 1.4049085621081758e-05 \n",
      "epoch: 19 [652157/888800 73.38%] train loss: 1.6037960449466482e-05 \n",
      "epoch: 19 [653268/888800 73.50%] train loss: 1.3714709893974941e-05 \n",
      "epoch: 19 [654379/888800 73.62%] train loss: 1.3819422747474164e-05 \n",
      "epoch: 19 [655490/888800 73.75%] train loss: 1.4539766198140569e-05 \n",
      "epoch: 19 [656601/888800 73.88%] train loss: 1.4479807759926189e-05 \n",
      "epoch: 19 [657712/888800 74.00%] train loss: 1.5191147213045042e-05 \n",
      "epoch: 19 [658823/888800 74.12%] train loss: 1.3916962416260503e-05 \n",
      "epoch: 19 [659934/888800 74.25%] train loss: 1.4350804121932015e-05 \n",
      "epoch: 19 [661045/888800 74.38%] train loss: 1.3969785868539475e-05 \n",
      "epoch: 19 [662156/888800 74.50%] train loss: 1.4207022104528733e-05 \n",
      "epoch: 19 [663267/888800 74.62%] train loss: 1.4772122995054815e-05 \n",
      "epoch: 19 [664378/888800 74.75%] train loss: 1.4859822840662673e-05 \n",
      "epoch: 19 [665489/888800 74.88%] train loss: 1.4904327144904528e-05 \n",
      "epoch: 19 [666600/888800 75.00%] train loss: 1.428556970495265e-05 \n",
      "epoch: 19 [667711/888800 75.12%] train loss: 1.4331772035802715e-05 \n",
      "epoch: 19 [668822/888800 75.25%] train loss: 1.4547458704328164e-05 \n",
      "epoch: 19 [669933/888800 75.38%] train loss: 1.4871024177409708e-05 \n",
      "epoch: 19 [671044/888800 75.50%] train loss: 1.4372760233527515e-05 \n",
      "epoch: 19 [672155/888800 75.62%] train loss: 1.3286110515764449e-05 \n",
      "epoch: 19 [673266/888800 75.75%] train loss: 1.4917079170118086e-05 \n",
      "epoch: 19 [674377/888800 75.88%] train loss: 1.4973162251408212e-05 \n",
      "epoch: 19 [675488/888800 76.00%] train loss: 1.4157211808196735e-05 \n",
      "epoch: 19 [676599/888800 76.12%] train loss: 1.517477630841313e-05 \n",
      "epoch: 19 [677710/888800 76.25%] train loss: 1.4747256500413641e-05 \n",
      "epoch: 19 [678821/888800 76.38%] train loss: 1.543301550555043e-05 \n",
      "epoch: 19 [679932/888800 76.50%] train loss: 1.3680243682756554e-05 \n",
      "epoch: 19 [681043/888800 76.62%] train loss: 1.4675568309030496e-05 \n",
      "epoch: 19 [682154/888800 76.75%] train loss: 1.4301001101557631e-05 \n",
      "epoch: 19 [683265/888800 76.88%] train loss: 1.5450053979293443e-05 \n",
      "epoch: 19 [684376/888800 77.00%] train loss: 1.4053512131795287e-05 \n",
      "epoch: 19 [685487/888800 77.12%] train loss: 1.5386314771603793e-05 \n",
      "epoch: 19 [686598/888800 77.25%] train loss: 1.3758860404777806e-05 \n",
      "epoch: 19 [687709/888800 77.38%] train loss: 1.3464989024214447e-05 \n",
      "epoch: 19 [688820/888800 77.50%] train loss: 1.3525657777790911e-05 \n",
      "epoch: 19 [689931/888800 77.62%] train loss: 1.4673281839350238e-05 \n",
      "epoch: 19 [691042/888800 77.75%] train loss: 1.444043118681293e-05 \n",
      "epoch: 19 [692153/888800 77.88%] train loss: 1.4922299669706263e-05 \n",
      "epoch: 19 [693264/888800 78.00%] train loss: 1.405507828167174e-05 \n",
      "epoch: 19 [694375/888800 78.12%] train loss: 1.4239800293580629e-05 \n",
      "epoch: 19 [695486/888800 78.25%] train loss: 1.3462391507346183e-05 \n",
      "epoch: 19 [696597/888800 78.38%] train loss: 1.5331212125602178e-05 \n",
      "epoch: 19 [697708/888800 78.50%] train loss: 1.3971869520901237e-05 \n",
      "epoch: 19 [698819/888800 78.62%] train loss: 1.5924879335216247e-05 \n",
      "epoch: 19 [699930/888800 78.75%] train loss: 1.6125179172377102e-05 \n",
      "epoch: 19 [701041/888800 78.88%] train loss: 1.627410347282421e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [702152/888800 79.00%] train loss: 1.4788598491577432e-05 \n",
      "epoch: 19 [703263/888800 79.12%] train loss: 1.5191355487331748e-05 \n",
      "epoch: 19 [704374/888800 79.25%] train loss: 1.5323366824304685e-05 \n",
      "epoch: 19 [705485/888800 79.38%] train loss: 1.408689422532916e-05 \n",
      "epoch: 19 [706596/888800 79.50%] train loss: 1.6491532733198255e-05 \n",
      "epoch: 19 [707707/888800 79.62%] train loss: 1.5007612091721967e-05 \n",
      "epoch: 19 [708818/888800 79.75%] train loss: 1.633486863283906e-05 \n",
      "epoch: 19 [709929/888800 79.88%] train loss: 1.3710792700294405e-05 \n",
      "epoch: 19 [711040/888800 80.00%] train loss: 1.7392867448506877e-05 \n",
      "epoch: 19 [712151/888800 80.12%] train loss: 1.516395241196733e-05 \n",
      "epoch: 19 [713262/888800 80.25%] train loss: 1.603581949893851e-05 \n",
      "epoch: 19 [714373/888800 80.38%] train loss: 1.3042250429862179e-05 \n",
      "epoch: 19 [715484/888800 80.50%] train loss: 1.5020184946479276e-05 \n",
      "epoch: 19 [716595/888800 80.62%] train loss: 1.5072060705279e-05 \n",
      "epoch: 19 [717706/888800 80.75%] train loss: 1.4492704394797329e-05 \n",
      "epoch: 19 [718817/888800 80.88%] train loss: 1.4926896255929023e-05 \n",
      "epoch: 19 [719928/888800 81.00%] train loss: 1.4458046280196868e-05 \n",
      "epoch: 19 [721039/888800 81.12%] train loss: 1.4394508980331011e-05 \n",
      "epoch: 19 [722150/888800 81.25%] train loss: 1.3003975254832767e-05 \n",
      "epoch: 19 [723261/888800 81.38%] train loss: 1.3900439626013394e-05 \n",
      "epoch: 19 [724372/888800 81.50%] train loss: 1.4567493053618819e-05 \n",
      "epoch: 19 [725483/888800 81.62%] train loss: 1.4729848771821707e-05 \n",
      "epoch: 19 [726594/888800 81.75%] train loss: 1.538372271170374e-05 \n",
      "epoch: 19 [727705/888800 81.88%] train loss: 1.5571331459796056e-05 \n",
      "epoch: 19 [728816/888800 82.00%] train loss: 1.3890075933886692e-05 \n",
      "epoch: 19 [729927/888800 82.12%] train loss: 1.6729072740417905e-05 \n",
      "epoch: 19 [731038/888800 82.25%] train loss: 1.3846959518559743e-05 \n",
      "epoch: 19 [732149/888800 82.38%] train loss: 1.6564392353757285e-05 \n",
      "epoch: 19 [733260/888800 82.50%] train loss: 1.363213868899038e-05 \n",
      "epoch: 19 [734371/888800 82.62%] train loss: 1.7511130863567814e-05 \n",
      "epoch: 19 [735482/888800 82.75%] train loss: 1.3433917047223076e-05 \n",
      "epoch: 19 [736593/888800 82.88%] train loss: 1.8362130504101515e-05 \n",
      "epoch: 19 [737704/888800 83.00%] train loss: 1.4599907444790006e-05 \n",
      "epoch: 19 [738815/888800 83.12%] train loss: 1.6693211364327e-05 \n",
      "epoch: 19 [739926/888800 83.25%] train loss: 1.6659096218063496e-05 \n",
      "epoch: 19 [741037/888800 83.38%] train loss: 1.6925949239521287e-05 \n",
      "epoch: 19 [742148/888800 83.50%] train loss: 1.6862028132891282e-05 \n",
      "epoch: 19 [743259/888800 83.62%] train loss: 1.4085029761190526e-05 \n",
      "epoch: 19 [744370/888800 83.75%] train loss: 1.8217688193544745e-05 \n",
      "epoch: 19 [745481/888800 83.88%] train loss: 1.3543805835070089e-05 \n",
      "epoch: 19 [746592/888800 84.00%] train loss: 1.560430246172473e-05 \n",
      "epoch: 19 [747703/888800 84.12%] train loss: 1.4268995983002242e-05 \n",
      "epoch: 19 [748814/888800 84.25%] train loss: 1.4548476428899448e-05 \n",
      "epoch: 19 [749925/888800 84.38%] train loss: 1.4496036783384625e-05 \n",
      "epoch: 19 [751036/888800 84.50%] train loss: 1.3239815416454803e-05 \n",
      "epoch: 19 [752147/888800 84.62%] train loss: 1.3275489436637145e-05 \n",
      "epoch: 19 [753258/888800 84.75%] train loss: 1.6142090316861868e-05 \n",
      "epoch: 19 [754369/888800 84.88%] train loss: 1.4724537322763354e-05 \n",
      "epoch: 19 [755480/888800 85.00%] train loss: 1.395801064063562e-05 \n",
      "epoch: 19 [756591/888800 85.12%] train loss: 1.3838115592079703e-05 \n",
      "epoch: 19 [757702/888800 85.25%] train loss: 1.3698873772227671e-05 \n",
      "epoch: 19 [758813/888800 85.38%] train loss: 1.3691385902347974e-05 \n",
      "epoch: 19 [759924/888800 85.50%] train loss: 1.4087773706705775e-05 \n",
      "epoch: 19 [761035/888800 85.62%] train loss: 1.48134113260312e-05 \n",
      "epoch: 19 [762146/888800 85.75%] train loss: 1.4330729754874483e-05 \n",
      "epoch: 19 [763257/888800 85.88%] train loss: 1.4900160749675706e-05 \n",
      "epoch: 19 [764368/888800 86.00%] train loss: 1.4425176232180092e-05 \n",
      "epoch: 19 [765479/888800 86.12%] train loss: 1.680879904597532e-05 \n",
      "epoch: 19 [766590/888800 86.25%] train loss: 1.3532019693229813e-05 \n",
      "epoch: 19 [767701/888800 86.38%] train loss: 1.3744425814365968e-05 \n",
      "epoch: 19 [768812/888800 86.50%] train loss: 1.3496653991751373e-05 \n",
      "epoch: 19 [769923/888800 86.62%] train loss: 1.4422443200601265e-05 \n",
      "epoch: 19 [771034/888800 86.75%] train loss: 1.3634656170324888e-05 \n",
      "epoch: 19 [772145/888800 86.88%] train loss: 1.461966530769132e-05 \n",
      "epoch: 19 [773256/888800 87.00%] train loss: 1.3628415217681322e-05 \n",
      "epoch: 19 [774367/888800 87.12%] train loss: 1.4758416909899097e-05 \n",
      "epoch: 19 [775478/888800 87.25%] train loss: 1.4409040886675939e-05 \n",
      "epoch: 19 [776589/888800 87.38%] train loss: 1.3997477253724355e-05 \n",
      "epoch: 19 [777700/888800 87.50%] train loss: 1.3586552995548118e-05 \n",
      "epoch: 19 [778811/888800 87.62%] train loss: 1.3823663721268531e-05 \n",
      "epoch: 19 [779922/888800 87.75%] train loss: 1.4180718608258758e-05 \n",
      "epoch: 19 [781033/888800 87.88%] train loss: 1.3924781342211645e-05 \n",
      "epoch: 19 [782144/888800 88.00%] train loss: 1.6510819477844052e-05 \n",
      "epoch: 19 [783255/888800 88.12%] train loss: 1.3695951565750875e-05 \n",
      "epoch: 19 [784366/888800 88.25%] train loss: 1.313892880716594e-05 \n",
      "epoch: 19 [785477/888800 88.38%] train loss: 1.5645915482309647e-05 \n",
      "epoch: 19 [786588/888800 88.50%] train loss: 1.2150517250120174e-05 \n",
      "epoch: 19 [787699/888800 88.62%] train loss: 1.4592554180126172e-05 \n",
      "epoch: 19 [788810/888800 88.75%] train loss: 1.4181613551045302e-05 \n",
      "epoch: 19 [789921/888800 88.88%] train loss: 1.5011595678515732e-05 \n",
      "epoch: 19 [791032/888800 89.00%] train loss: 1.3953416782896966e-05 \n",
      "epoch: 19 [792143/888800 89.12%] train loss: 1.4398790881386958e-05 \n",
      "epoch: 19 [793254/888800 89.25%] train loss: 1.4596237633668352e-05 \n",
      "epoch: 19 [794365/888800 89.38%] train loss: 1.4023410585650709e-05 \n",
      "epoch: 19 [795476/888800 89.50%] train loss: 1.4062048649066128e-05 \n",
      "epoch: 19 [796587/888800 89.62%] train loss: 1.4199794350133743e-05 \n",
      "epoch: 19 [797698/888800 89.75%] train loss: 1.3812055840389803e-05 \n",
      "epoch: 19 [798809/888800 89.88%] train loss: 1.492258070356911e-05 \n",
      "epoch: 19 [799920/888800 90.00%] train loss: 1.43136048791348e-05 \n",
      "epoch: 19 [801031/888800 90.12%] train loss: 1.5033106137707364e-05 \n",
      "epoch: 19 [802142/888800 90.25%] train loss: 1.2984958630113397e-05 \n",
      "epoch: 19 [803253/888800 90.38%] train loss: 1.621906631044112e-05 \n",
      "epoch: 19 [804364/888800 90.50%] train loss: 1.4534915862896014e-05 \n",
      "epoch: 19 [805475/888800 90.62%] train loss: 1.6136449630721472e-05 \n",
      "epoch: 19 [806586/888800 90.75%] train loss: 1.5143634300329722e-05 \n",
      "epoch: 19 [807697/888800 90.88%] train loss: 1.4362792171596084e-05 \n",
      "epoch: 19 [808808/888800 91.00%] train loss: 1.374050225422252e-05 \n",
      "epoch: 19 [809919/888800 91.12%] train loss: 1.4402066881302744e-05 \n",
      "epoch: 19 [811030/888800 91.25%] train loss: 1.4427861970034428e-05 \n",
      "epoch: 19 [812141/888800 91.38%] train loss: 1.3409650819085073e-05 \n",
      "epoch: 19 [813252/888800 91.50%] train loss: 1.4147838555800263e-05 \n",
      "epoch: 19 [814363/888800 91.62%] train loss: 1.3575249795394484e-05 \n",
      "epoch: 19 [815474/888800 91.75%] train loss: 1.5415029338328168e-05 \n",
      "epoch: 19 [816585/888800 91.88%] train loss: 1.4620241017837543e-05 \n",
      "epoch: 19 [817696/888800 92.00%] train loss: 1.4019342415849678e-05 \n",
      "epoch: 19 [818807/888800 92.12%] train loss: 1.4359262422658503e-05 \n",
      "epoch: 19 [819918/888800 92.25%] train loss: 1.3835924619343132e-05 \n",
      "epoch: 19 [821029/888800 92.38%] train loss: 1.5039775462355465e-05 \n",
      "epoch: 19 [822140/888800 92.50%] train loss: 1.413225254509598e-05 \n",
      "epoch: 19 [823251/888800 92.62%] train loss: 1.4114945770415943e-05 \n",
      "epoch: 19 [824362/888800 92.75%] train loss: 1.4446035493165255e-05 \n",
      "epoch: 19 [825473/888800 92.88%] train loss: 1.3957370356365573e-05 \n",
      "epoch: 19 [826584/888800 93.00%] train loss: 1.4190683941706084e-05 \n",
      "epoch: 19 [827695/888800 93.12%] train loss: 1.3840172869095113e-05 \n",
      "epoch: 19 [828806/888800 93.25%] train loss: 1.4670693417428993e-05 \n",
      "epoch: 19 [829917/888800 93.38%] train loss: 1.4011854545969982e-05 \n",
      "epoch: 19 [831028/888800 93.50%] train loss: 1.581196738698054e-05 \n",
      "epoch: 19 [832139/888800 93.62%] train loss: 1.4938863387214951e-05 \n",
      "epoch: 19 [833250/888800 93.75%] train loss: 1.4567523066943977e-05 \n",
      "epoch: 19 [834361/888800 93.88%] train loss: 1.4622940398112405e-05 \n",
      "epoch: 19 [835472/888800 94.00%] train loss: 1.537613024993334e-05 \n",
      "epoch: 19 [836583/888800 94.12%] train loss: 1.4866656783851795e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 [837694/888800 94.25%] train loss: 1.537631942483131e-05 \n",
      "epoch: 19 [838805/888800 94.38%] train loss: 1.4915873180143535e-05 \n",
      "epoch: 19 [839916/888800 94.50%] train loss: 1.4078328604227863e-05 \n",
      "epoch: 19 [841027/888800 94.62%] train loss: 1.5355941286543384e-05 \n",
      "epoch: 19 [842138/888800 94.75%] train loss: 1.3216938896221109e-05 \n",
      "epoch: 19 [843249/888800 94.88%] train loss: 1.6318361304001883e-05 \n",
      "epoch: 19 [844360/888800 95.00%] train loss: 1.2117521691834554e-05 \n",
      "epoch: 19 [845471/888800 95.12%] train loss: 1.5262219676515087e-05 \n",
      "epoch: 19 [846582/888800 95.25%] train loss: 1.4255938367568888e-05 \n",
      "epoch: 19 [847693/888800 95.38%] train loss: 1.6617044821032323e-05 \n",
      "epoch: 19 [848804/888800 95.50%] train loss: 1.3984043107484467e-05 \n",
      "epoch: 19 [849915/888800 95.62%] train loss: 1.4785231542191468e-05 \n",
      "epoch: 19 [851026/888800 95.75%] train loss: 1.3778341781289782e-05 \n",
      "epoch: 19 [852137/888800 95.88%] train loss: 1.3687052160094026e-05 \n",
      "epoch: 19 [853248/888800 96.00%] train loss: 1.484412860008888e-05 \n",
      "epoch: 19 [854359/888800 96.12%] train loss: 1.3326872249308508e-05 \n",
      "epoch: 19 [855470/888800 96.25%] train loss: 1.3090444554109126e-05 \n",
      "epoch: 19 [856581/888800 96.38%] train loss: 1.565264756209217e-05 \n",
      "epoch: 19 [857692/888800 96.50%] train loss: 1.6160098311956972e-05 \n",
      "epoch: 19 [858803/888800 96.62%] train loss: 1.379634159093257e-05 \n",
      "epoch: 19 [859914/888800 96.75%] train loss: 1.539489494462032e-05 \n",
      "epoch: 19 [861025/888800 96.88%] train loss: 1.5212880498438608e-05 \n",
      "epoch: 19 [862136/888800 97.00%] train loss: 1.4313473002403043e-05 \n",
      "epoch: 19 [863247/888800 97.12%] train loss: 1.4557609574694652e-05 \n",
      "epoch: 19 [864358/888800 97.25%] train loss: 1.374201565340627e-05 \n",
      "epoch: 19 [865469/888800 97.38%] train loss: 1.4838698007224593e-05 \n",
      "epoch: 19 [866580/888800 97.50%] train loss: 1.5614672520314343e-05 \n",
      "epoch: 19 [867691/888800 97.62%] train loss: 1.3496742212737445e-05 \n",
      "epoch: 19 [868802/888800 97.75%] train loss: 1.3974571629660204e-05 \n",
      "epoch: 19 [869913/888800 97.88%] train loss: 1.4032263607077766e-05 \n",
      "epoch: 19 [871024/888800 98.00%] train loss: 1.5841074855416082e-05 \n",
      "epoch: 19 [872135/888800 98.12%] train loss: 1.4768435903533828e-05 \n",
      "epoch: 19 [873246/888800 98.25%] train loss: 1.3674258298124187e-05 \n",
      "epoch: 19 [874357/888800 98.38%] train loss: 1.3801033674099017e-05 \n",
      "epoch: 19 [875468/888800 98.50%] train loss: 1.336368586635217e-05 \n",
      "epoch: 19 [876579/888800 98.62%] train loss: 1.3823274457536172e-05 \n",
      "epoch: 19 [877690/888800 98.75%] train loss: 1.4057970474823378e-05 \n",
      "epoch: 19 [878801/888800 98.88%] train loss: 1.2927703210152686e-05 \n",
      "epoch: 19 [879912/888800 99.00%] train loss: 1.387303836963838e-05 \n",
      "epoch: 19 [881023/888800 99.12%] train loss: 1.3975045476399828e-05 \n",
      "epoch: 19 [882134/888800 99.25%] train loss: 1.3232071069069207e-05 \n",
      "epoch: 19 [883245/888800 99.38%] train loss: 1.3788421711069532e-05 \n",
      "epoch: 19 [884356/888800 99.50%] train loss: 1.4974227269703988e-05 \n",
      "epoch: 19 [885467/888800 99.62%] train loss: 1.3163717994757462e-05 \n",
      "epoch: 19 [886578/888800 99.75%] train loss: 1.415438327967422e-05 \n",
      "epoch: 19 [887689/888800 99.88%] train loss: 1.4793718037253711e-05 \n",
      "epoch: 20 [0/888800 0.00%] train loss: 1.43558236231911e-05 \n",
      "epoch: 20 [1111/888800 0.12%] train loss: 1.5168480786087457e-05 \n",
      "epoch: 20 [2222/888800 0.25%] train loss: 1.3523081179300789e-05 \n",
      "epoch: 20 [3333/888800 0.38%] train loss: 1.3777666026726365e-05 \n",
      "epoch: 20 [4444/888800 0.50%] train loss: 1.3938295523985289e-05 \n",
      "epoch: 20 [5555/888800 0.62%] train loss: 1.5116595022846013e-05 \n",
      "epoch: 20 [6666/888800 0.75%] train loss: 1.4410526091523934e-05 \n",
      "epoch: 20 [7777/888800 0.88%] train loss: 1.411544690199662e-05 \n",
      "epoch: 20 [8888/888800 1.00%] train loss: 1.4052946426090784e-05 \n",
      "epoch: 20 [9999/888800 1.12%] train loss: 1.4256941540224943e-05 \n",
      "epoch: 20 [11110/888800 1.25%] train loss: 1.3751870937994681e-05 \n",
      "epoch: 20 [12221/888800 1.38%] train loss: 1.3512398254533764e-05 \n",
      "epoch: 20 [13332/888800 1.50%] train loss: 1.4698867744300514e-05 \n",
      "epoch: 20 [14443/888800 1.62%] train loss: 1.360382157145068e-05 \n",
      "epoch: 20 [15554/888800 1.75%] train loss: 1.4246727914724033e-05 \n",
      "epoch: 20 [16665/888800 1.88%] train loss: 1.4429048860620242e-05 \n",
      "epoch: 20 [17776/888800 2.00%] train loss: 1.515255371487001e-05 \n",
      "epoch: 20 [18887/888800 2.12%] train loss: 1.3579397091234569e-05 \n",
      "epoch: 20 [19998/888800 2.25%] train loss: 1.5006311514298432e-05 \n",
      "epoch: 20 [21109/888800 2.38%] train loss: 1.4464701962424442e-05 \n",
      "epoch: 20 [22220/888800 2.50%] train loss: 1.437975515727885e-05 \n",
      "epoch: 20 [23331/888800 2.62%] train loss: 1.4766531421628315e-05 \n",
      "epoch: 20 [24442/888800 2.75%] train loss: 1.4882892173773143e-05 \n",
      "epoch: 20 [25553/888800 2.88%] train loss: 1.4237126379157417e-05 \n",
      "epoch: 20 [26664/888800 3.00%] train loss: 1.3888949069951195e-05 \n",
      "epoch: 20 [27775/888800 3.12%] train loss: 1.3512530131265521e-05 \n",
      "epoch: 20 [28886/888800 3.25%] train loss: 1.3325979125511367e-05 \n",
      "epoch: 20 [29997/888800 3.38%] train loss: 1.420305034116609e-05 \n",
      "epoch: 20 [31108/888800 3.50%] train loss: 1.5437261026818305e-05 \n",
      "epoch: 20 [32219/888800 3.62%] train loss: 1.3154201951692812e-05 \n",
      "epoch: 20 [33330/888800 3.75%] train loss: 1.4947611816751305e-05 \n",
      "epoch: 20 [34441/888800 3.88%] train loss: 1.4581161849491764e-05 \n",
      "epoch: 20 [35552/888800 4.00%] train loss: 1.4236711649573408e-05 \n",
      "epoch: 20 [36663/888800 4.12%] train loss: 1.5436464309459552e-05 \n",
      "epoch: 20 [37774/888800 4.25%] train loss: 1.3380236850935034e-05 \n",
      "epoch: 20 [38885/888800 4.38%] train loss: 1.471466566727031e-05 \n",
      "epoch: 20 [39996/888800 4.50%] train loss: 1.4044996532902587e-05 \n",
      "epoch: 20 [41107/888800 4.62%] train loss: 1.2899569810542744e-05 \n",
      "epoch: 20 [42218/888800 4.75%] train loss: 1.429371604899643e-05 \n",
      "epoch: 20 [43329/888800 4.88%] train loss: 1.3615775969810784e-05 \n",
      "epoch: 20 [44440/888800 5.00%] train loss: 1.5810182958375663e-05 \n",
      "epoch: 20 [45551/888800 5.12%] train loss: 1.4522399396810215e-05 \n",
      "epoch: 20 [46662/888800 5.25%] train loss: 1.581705510034226e-05 \n",
      "epoch: 20 [47773/888800 5.38%] train loss: 1.3906544154451694e-05 \n",
      "epoch: 20 [48884/888800 5.50%] train loss: 1.4523438949254341e-05 \n",
      "epoch: 20 [49995/888800 5.62%] train loss: 1.3159619811631273e-05 \n",
      "epoch: 20 [51106/888800 5.75%] train loss: 1.5164976503001526e-05 \n",
      "epoch: 20 [52217/888800 5.88%] train loss: 1.3852765732735861e-05 \n",
      "epoch: 20 [53328/888800 6.00%] train loss: 1.543311373097822e-05 \n",
      "epoch: 20 [54439/888800 6.12%] train loss: 1.5259171050274745e-05 \n",
      "epoch: 20 [55550/888800 6.25%] train loss: 1.4659100088465493e-05 \n",
      "epoch: 20 [56661/888800 6.38%] train loss: 1.39132671392872e-05 \n",
      "epoch: 20 [57772/888800 6.50%] train loss: 1.3661103366757743e-05 \n",
      "epoch: 20 [58883/888800 6.62%] train loss: 1.5030675058369525e-05 \n",
      "epoch: 20 [59994/888800 6.75%] train loss: 1.384877941745799e-05 \n",
      "epoch: 20 [61105/888800 6.88%] train loss: 1.4573186490451917e-05 \n",
      "epoch: 20 [62216/888800 7.00%] train loss: 1.3857385965820868e-05 \n",
      "epoch: 20 [63327/888800 7.12%] train loss: 1.4208884749677964e-05 \n",
      "epoch: 20 [64438/888800 7.25%] train loss: 1.4248185834730975e-05 \n",
      "epoch: 20 [65549/888800 7.38%] train loss: 1.35727441374911e-05 \n",
      "epoch: 20 [66660/888800 7.50%] train loss: 1.466312551201554e-05 \n",
      "epoch: 20 [67771/888800 7.62%] train loss: 1.4293332242232282e-05 \n",
      "epoch: 20 [68882/888800 7.75%] train loss: 1.5572428310406394e-05 \n",
      "epoch: 20 [69993/888800 7.88%] train loss: 1.2769277418556157e-05 \n",
      "epoch: 20 [71104/888800 8.00%] train loss: 1.3395298992691096e-05 \n",
      "epoch: 20 [72215/888800 8.12%] train loss: 1.3868109817849472e-05 \n",
      "epoch: 20 [73326/888800 8.25%] train loss: 1.4706463844049722e-05 \n",
      "epoch: 20 [74437/888800 8.38%] train loss: 1.4221887795429211e-05 \n",
      "epoch: 20 [75548/888800 8.50%] train loss: 1.3375929484027438e-05 \n",
      "epoch: 20 [76659/888800 8.62%] train loss: 1.3936903087596875e-05 \n",
      "epoch: 20 [77770/888800 8.75%] train loss: 1.416479153704131e-05 \n",
      "epoch: 20 [78881/888800 8.88%] train loss: 1.4687600923934951e-05 \n",
      "epoch: 20 [79992/888800 9.00%] train loss: 1.4381295841303654e-05 \n",
      "epoch: 20 [81103/888800 9.12%] train loss: 1.5052440176077653e-05 \n",
      "epoch: 20 [82214/888800 9.25%] train loss: 1.3796308849123307e-05 \n",
      "epoch: 20 [83325/888800 9.38%] train loss: 1.4660901797469705e-05 \n",
      "epoch: 20 [84436/888800 9.50%] train loss: 1.3620701793115586e-05 \n",
      "epoch: 20 [85547/888800 9.62%] train loss: 1.5063779756019358e-05 \n",
      "epoch: 20 [86658/888800 9.75%] train loss: 1.3375338312471285e-05 \n",
      "epoch: 20 [87769/888800 9.88%] train loss: 1.4845631085336208e-05 \n",
      "epoch: 20 [88880/888800 10.00%] train loss: 1.5998057278920896e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [89991/888800 10.12%] train loss: 1.4663334695796948e-05 \n",
      "epoch: 20 [91102/888800 10.25%] train loss: 1.4708491107739974e-05 \n",
      "epoch: 20 [92213/888800 10.38%] train loss: 1.4508790627587587e-05 \n",
      "epoch: 20 [93324/888800 10.50%] train loss: 1.5217804502754007e-05 \n",
      "epoch: 20 [94435/888800 10.62%] train loss: 1.4278703019954264e-05 \n",
      "epoch: 20 [95546/888800 10.75%] train loss: 1.4305641343526077e-05 \n",
      "epoch: 20 [96657/888800 10.88%] train loss: 1.4232427020033356e-05 \n",
      "epoch: 20 [97768/888800 11.00%] train loss: 1.5477111446671188e-05 \n",
      "epoch: 20 [98879/888800 11.12%] train loss: 1.3151665370969567e-05 \n",
      "epoch: 20 [99990/888800 11.25%] train loss: 1.5245859685819596e-05 \n",
      "epoch: 20 [101101/888800 11.38%] train loss: 1.3819009836879559e-05 \n",
      "epoch: 20 [102212/888800 11.50%] train loss: 1.3975297406432219e-05 \n",
      "epoch: 20 [103323/888800 11.62%] train loss: 1.404304384777788e-05 \n",
      "epoch: 20 [104434/888800 11.75%] train loss: 1.484045060351491e-05 \n",
      "epoch: 20 [105545/888800 11.88%] train loss: 1.4452138202614151e-05 \n",
      "epoch: 20 [106656/888800 12.00%] train loss: 1.4673864825454075e-05 \n",
      "epoch: 20 [107767/888800 12.12%] train loss: 1.492639239586424e-05 \n",
      "epoch: 20 [108878/888800 12.25%] train loss: 1.4055096471565776e-05 \n",
      "epoch: 20 [109989/888800 12.38%] train loss: 1.471098767069634e-05 \n",
      "epoch: 20 [111100/888800 12.50%] train loss: 1.4576937246602029e-05 \n",
      "epoch: 20 [112211/888800 12.62%] train loss: 1.455969595554052e-05 \n",
      "epoch: 20 [113322/888800 12.75%] train loss: 1.4448342881223653e-05 \n",
      "epoch: 20 [114433/888800 12.88%] train loss: 1.469740891479887e-05 \n",
      "epoch: 20 [115544/888800 13.00%] train loss: 1.3262611901154742e-05 \n",
      "epoch: 20 [116655/888800 13.12%] train loss: 1.355647782474989e-05 \n",
      "epoch: 20 [117766/888800 13.25%] train loss: 1.4224016922526062e-05 \n",
      "epoch: 20 [118877/888800 13.38%] train loss: 1.3988017599331215e-05 \n",
      "epoch: 20 [119988/888800 13.50%] train loss: 1.4795153219893109e-05 \n",
      "epoch: 20 [121099/888800 13.62%] train loss: 1.5311548850149848e-05 \n",
      "epoch: 20 [122210/888800 13.75%] train loss: 1.4484608072962146e-05 \n",
      "epoch: 20 [123321/888800 13.88%] train loss: 1.3038811630394775e-05 \n",
      "epoch: 20 [124432/888800 14.00%] train loss: 1.4033892512088642e-05 \n",
      "epoch: 20 [125543/888800 14.12%] train loss: 1.3035170013608877e-05 \n",
      "epoch: 20 [126654/888800 14.25%] train loss: 1.3971488442621194e-05 \n",
      "epoch: 20 [127765/888800 14.38%] train loss: 1.4760368685529102e-05 \n",
      "epoch: 20 [128876/888800 14.50%] train loss: 1.5287007045117207e-05 \n",
      "epoch: 20 [129987/888800 14.62%] train loss: 1.4916738109604921e-05 \n",
      "epoch: 20 [131098/888800 14.75%] train loss: 1.4526959603244904e-05 \n",
      "epoch: 20 [132209/888800 14.88%] train loss: 1.382737718813587e-05 \n",
      "epoch: 20 [133320/888800 15.00%] train loss: 1.4147958609100897e-05 \n",
      "epoch: 20 [134431/888800 15.12%] train loss: 1.6655725630698726e-05 \n",
      "epoch: 20 [135542/888800 15.25%] train loss: 1.5045405234559439e-05 \n",
      "epoch: 20 [136653/888800 15.38%] train loss: 1.5011575669632293e-05 \n",
      "epoch: 20 [137764/888800 15.50%] train loss: 1.537443313281983e-05 \n",
      "epoch: 20 [138875/888800 15.62%] train loss: 1.4894193554937374e-05 \n",
      "epoch: 20 [139986/888800 15.75%] train loss: 1.3967902305012103e-05 \n",
      "epoch: 20 [141097/888800 15.88%] train loss: 1.410181175742764e-05 \n",
      "epoch: 20 [142208/888800 16.00%] train loss: 1.499042809882667e-05 \n",
      "epoch: 20 [143319/888800 16.12%] train loss: 1.3475179912347812e-05 \n",
      "epoch: 20 [144430/888800 16.25%] train loss: 1.4809246749791782e-05 \n",
      "epoch: 20 [145541/888800 16.38%] train loss: 1.4842400560155511e-05 \n",
      "epoch: 20 [146652/888800 16.50%] train loss: 1.265137780137593e-05 \n",
      "epoch: 20 [147763/888800 16.62%] train loss: 1.3133936590747908e-05 \n",
      "epoch: 20 [148874/888800 16.75%] train loss: 1.3646550542034674e-05 \n",
      "epoch: 20 [149985/888800 16.88%] train loss: 1.3935014067101292e-05 \n",
      "epoch: 20 [151096/888800 17.00%] train loss: 1.3156203749531414e-05 \n",
      "epoch: 20 [152207/888800 17.12%] train loss: 1.4514525901176967e-05 \n",
      "epoch: 20 [153318/888800 17.25%] train loss: 1.5813902791705914e-05 \n",
      "epoch: 20 [154429/888800 17.38%] train loss: 1.34838428493822e-05 \n",
      "epoch: 20 [155540/888800 17.50%] train loss: 1.3322413906280417e-05 \n",
      "epoch: 20 [156651/888800 17.62%] train loss: 1.4138539881969336e-05 \n",
      "epoch: 20 [157762/888800 17.75%] train loss: 1.4707318769069389e-05 \n",
      "epoch: 20 [158873/888800 17.88%] train loss: 1.4432396710617468e-05 \n",
      "epoch: 20 [159984/888800 18.00%] train loss: 1.3619755918625742e-05 \n",
      "epoch: 20 [161095/888800 18.12%] train loss: 1.4057354746910278e-05 \n",
      "epoch: 20 [162206/888800 18.25%] train loss: 1.4362305591930635e-05 \n",
      "epoch: 20 [163317/888800 18.38%] train loss: 1.4456276403507218e-05 \n",
      "epoch: 20 [164428/888800 18.50%] train loss: 1.4243468285712879e-05 \n",
      "epoch: 20 [165539/888800 18.62%] train loss: 1.5104510566743556e-05 \n",
      "epoch: 20 [166650/888800 18.75%] train loss: 1.4140676285023801e-05 \n",
      "epoch: 20 [167761/888800 18.88%] train loss: 1.442062966816593e-05 \n",
      "epoch: 20 [168872/888800 19.00%] train loss: 1.3526043403544463e-05 \n",
      "epoch: 20 [169983/888800 19.12%] train loss: 1.379378136334708e-05 \n",
      "epoch: 20 [171094/888800 19.25%] train loss: 1.2939990483573638e-05 \n",
      "epoch: 20 [172205/888800 19.38%] train loss: 1.3895419215259608e-05 \n",
      "epoch: 20 [173316/888800 19.50%] train loss: 1.4982313587097451e-05 \n",
      "epoch: 20 [174427/888800 19.62%] train loss: 1.4271946383814793e-05 \n",
      "epoch: 20 [175538/888800 19.75%] train loss: 1.4179209756548516e-05 \n",
      "epoch: 20 [176649/888800 19.88%] train loss: 1.3894433323002886e-05 \n",
      "epoch: 20 [177760/888800 20.00%] train loss: 1.3729841157328337e-05 \n",
      "epoch: 20 [178871/888800 20.12%] train loss: 1.343028179690009e-05 \n",
      "epoch: 20 [179982/888800 20.25%] train loss: 1.4116508282313589e-05 \n",
      "epoch: 20 [181093/888800 20.38%] train loss: 1.5287107089534402e-05 \n",
      "epoch: 20 [182204/888800 20.50%] train loss: 1.326414985669544e-05 \n",
      "epoch: 20 [183315/888800 20.62%] train loss: 1.3220646906120237e-05 \n",
      "epoch: 20 [184426/888800 20.75%] train loss: 1.4134681805444416e-05 \n",
      "epoch: 20 [185537/888800 20.88%] train loss: 1.5066861124068964e-05 \n",
      "epoch: 20 [186648/888800 21.00%] train loss: 1.5223547961795703e-05 \n",
      "epoch: 20 [187759/888800 21.12%] train loss: 1.4417031707125716e-05 \n",
      "epoch: 20 [188870/888800 21.25%] train loss: 1.5199305380519945e-05 \n",
      "epoch: 20 [189981/888800 21.38%] train loss: 1.281873574043857e-05 \n",
      "epoch: 20 [191092/888800 21.50%] train loss: 1.391146633977769e-05 \n",
      "epoch: 20 [192203/888800 21.62%] train loss: 1.4019505215401296e-05 \n",
      "epoch: 20 [193314/888800 21.75%] train loss: 1.3935318747826386e-05 \n",
      "epoch: 20 [194425/888800 21.88%] train loss: 1.3382428733166307e-05 \n",
      "epoch: 20 [195536/888800 22.00%] train loss: 1.322364914813079e-05 \n",
      "epoch: 20 [196647/888800 22.12%] train loss: 1.3609555026050657e-05 \n",
      "epoch: 20 [197758/888800 22.25%] train loss: 1.3198232409195043e-05 \n",
      "epoch: 20 [198869/888800 22.38%] train loss: 1.5605362932546996e-05 \n",
      "epoch: 20 [199980/888800 22.50%] train loss: 1.4822579942119773e-05 \n",
      "epoch: 20 [201091/888800 22.62%] train loss: 1.4073784768697806e-05 \n",
      "epoch: 20 [202202/888800 22.75%] train loss: 1.3550768926506862e-05 \n",
      "epoch: 20 [203313/888800 22.88%] train loss: 1.3510208191291895e-05 \n",
      "epoch: 20 [204424/888800 23.00%] train loss: 1.3761934496869799e-05 \n",
      "epoch: 20 [205535/888800 23.12%] train loss: 1.3808741641696543e-05 \n",
      "epoch: 20 [206646/888800 23.25%] train loss: 1.4930687029846013e-05 \n",
      "epoch: 20 [207757/888800 23.38%] train loss: 1.4876926798024215e-05 \n",
      "epoch: 20 [208868/888800 23.50%] train loss: 1.473894553782884e-05 \n",
      "epoch: 20 [209979/888800 23.62%] train loss: 1.3528416275221389e-05 \n",
      "epoch: 20 [211090/888800 23.75%] train loss: 1.4642198948422447e-05 \n",
      "epoch: 20 [212201/888800 23.88%] train loss: 1.4357636246131733e-05 \n",
      "epoch: 20 [213312/888800 24.00%] train loss: 1.405636612616945e-05 \n",
      "epoch: 20 [214423/888800 24.12%] train loss: 1.557711402710993e-05 \n",
      "epoch: 20 [215534/888800 24.25%] train loss: 1.4670709788333625e-05 \n",
      "epoch: 20 [216645/888800 24.38%] train loss: 1.477824571338715e-05 \n",
      "epoch: 20 [217756/888800 24.50%] train loss: 1.605907891644165e-05 \n",
      "epoch: 20 [218867/888800 24.62%] train loss: 1.4188719433150254e-05 \n",
      "epoch: 20 [219978/888800 24.75%] train loss: 1.4003446267452091e-05 \n",
      "epoch: 20 [221089/888800 24.88%] train loss: 1.4002564057591371e-05 \n",
      "epoch: 20 [222200/888800 25.00%] train loss: 1.387232532579219e-05 \n",
      "epoch: 20 [223311/888800 25.12%] train loss: 1.3245709851616994e-05 \n",
      "epoch: 20 [224422/888800 25.25%] train loss: 1.449779392714845e-05 \n",
      "epoch: 20 [225533/888800 25.38%] train loss: 1.4003459909872618e-05 \n",
      "epoch: 20 [226644/888800 25.50%] train loss: 1.3509530617739074e-05 \n",
      "epoch: 20 [227755/888800 25.62%] train loss: 1.5222921319946181e-05 \n",
      "epoch: 20 [228866/888800 25.75%] train loss: 1.4230909073376097e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [229977/888800 25.88%] train loss: 1.4809719687036704e-05 \n",
      "epoch: 20 [231088/888800 26.00%] train loss: 1.4471980648522731e-05 \n",
      "epoch: 20 [232199/888800 26.12%] train loss: 1.4558379916707054e-05 \n",
      "epoch: 20 [233310/888800 26.25%] train loss: 1.4236577953852247e-05 \n",
      "epoch: 20 [234421/888800 26.38%] train loss: 1.3714035048906226e-05 \n",
      "epoch: 20 [235532/888800 26.50%] train loss: 1.608464117452968e-05 \n",
      "epoch: 20 [236643/888800 26.62%] train loss: 1.4061101865081582e-05 \n",
      "epoch: 20 [237754/888800 26.75%] train loss: 1.3615058378491085e-05 \n",
      "epoch: 20 [238865/888800 26.88%] train loss: 1.4814586393185891e-05 \n",
      "epoch: 20 [239976/888800 27.00%] train loss: 1.4597129847970791e-05 \n",
      "epoch: 20 [241087/888800 27.12%] train loss: 1.2887378034065478e-05 \n",
      "epoch: 20 [242198/888800 27.25%] train loss: 1.452956803404959e-05 \n",
      "epoch: 20 [243309/888800 27.38%] train loss: 1.3678562936547678e-05 \n",
      "epoch: 20 [244420/888800 27.50%] train loss: 1.478831018175697e-05 \n",
      "epoch: 20 [245531/888800 27.62%] train loss: 1.328662892774446e-05 \n",
      "epoch: 20 [246642/888800 27.75%] train loss: 1.3343239515961614e-05 \n",
      "epoch: 20 [247753/888800 27.88%] train loss: 1.4056575309950858e-05 \n",
      "epoch: 20 [248864/888800 28.00%] train loss: 1.5648340195184574e-05 \n",
      "epoch: 20 [249975/888800 28.12%] train loss: 1.4160596947476733e-05 \n",
      "epoch: 20 [251086/888800 28.25%] train loss: 1.5337880540755577e-05 \n",
      "epoch: 20 [252197/888800 28.38%] train loss: 1.5225887182168663e-05 \n",
      "epoch: 20 [253308/888800 28.50%] train loss: 1.4553929759131279e-05 \n",
      "epoch: 20 [254419/888800 28.62%] train loss: 1.4784885934204794e-05 \n",
      "epoch: 20 [255530/888800 28.75%] train loss: 1.4772164831811097e-05 \n",
      "epoch: 20 [256641/888800 28.88%] train loss: 1.37641918627196e-05 \n",
      "epoch: 20 [257752/888800 29.00%] train loss: 1.4716278201376554e-05 \n",
      "epoch: 20 [258863/888800 29.12%] train loss: 1.448228067602031e-05 \n",
      "epoch: 20 [259974/888800 29.25%] train loss: 1.4005081538925879e-05 \n",
      "epoch: 20 [261085/888800 29.38%] train loss: 1.5093621186679229e-05 \n",
      "epoch: 20 [262196/888800 29.50%] train loss: 1.3959336683910806e-05 \n",
      "epoch: 20 [263307/888800 29.62%] train loss: 1.4222868230717722e-05 \n",
      "epoch: 20 [264418/888800 29.75%] train loss: 1.4409280993277207e-05 \n",
      "epoch: 20 [265529/888800 29.88%] train loss: 1.4266875950852409e-05 \n",
      "epoch: 20 [266640/888800 30.00%] train loss: 1.3165280506655108e-05 \n",
      "epoch: 20 [267751/888800 30.12%] train loss: 1.373134546156507e-05 \n",
      "epoch: 20 [268862/888800 30.25%] train loss: 1.5167209312494379e-05 \n",
      "epoch: 20 [269973/888800 30.38%] train loss: 1.4596768778574187e-05 \n",
      "epoch: 20 [271084/888800 30.50%] train loss: 1.4244032172427978e-05 \n",
      "epoch: 20 [272195/888800 30.62%] train loss: 1.4286855730460957e-05 \n",
      "epoch: 20 [273306/888800 30.75%] train loss: 1.3994315850140993e-05 \n",
      "epoch: 20 [274417/888800 30.88%] train loss: 1.4684515008411836e-05 \n",
      "epoch: 20 [275528/888800 31.00%] train loss: 1.5101461940503214e-05 \n",
      "epoch: 20 [276639/888800 31.12%] train loss: 1.4480066056421492e-05 \n",
      "epoch: 20 [277750/888800 31.25%] train loss: 1.3852065421815496e-05 \n",
      "epoch: 20 [278861/888800 31.38%] train loss: 1.591359978192486e-05 \n",
      "epoch: 20 [279972/888800 31.50%] train loss: 1.4341379028337542e-05 \n",
      "epoch: 20 [281083/888800 31.62%] train loss: 1.4828567145741545e-05 \n",
      "epoch: 20 [282194/888800 31.75%] train loss: 1.3350871995498892e-05 \n",
      "epoch: 20 [283305/888800 31.88%] train loss: 1.557938776386436e-05 \n",
      "epoch: 20 [284416/888800 32.00%] train loss: 1.4392996490641963e-05 \n",
      "epoch: 20 [285527/888800 32.12%] train loss: 1.464108208892867e-05 \n",
      "epoch: 20 [286638/888800 32.25%] train loss: 1.4127534996077884e-05 \n",
      "epoch: 20 [287749/888800 32.38%] train loss: 1.2417103789630346e-05 \n",
      "epoch: 20 [288860/888800 32.50%] train loss: 1.417338899045717e-05 \n",
      "epoch: 20 [289971/888800 32.62%] train loss: 1.3894436051486991e-05 \n",
      "epoch: 20 [291082/888800 32.75%] train loss: 1.31330089061521e-05 \n",
      "epoch: 20 [292193/888800 32.88%] train loss: 1.3565548215410672e-05 \n",
      "epoch: 20 [293304/888800 33.00%] train loss: 1.4551967979059555e-05 \n",
      "epoch: 20 [294415/888800 33.12%] train loss: 1.4995941455708817e-05 \n",
      "epoch: 20 [295526/888800 33.25%] train loss: 1.405996226822026e-05 \n",
      "epoch: 20 [296637/888800 33.38%] train loss: 1.4032339095138013e-05 \n",
      "epoch: 20 [297748/888800 33.50%] train loss: 1.4947082490834873e-05 \n",
      "epoch: 20 [298859/888800 33.62%] train loss: 1.4316817214421462e-05 \n",
      "epoch: 20 [299970/888800 33.75%] train loss: 1.3207129995862488e-05 \n",
      "epoch: 20 [301081/888800 33.88%] train loss: 1.473104566684924e-05 \n",
      "epoch: 20 [302192/888800 34.00%] train loss: 1.501844326412538e-05 \n",
      "epoch: 20 [303303/888800 34.12%] train loss: 1.4769972040085122e-05 \n",
      "epoch: 20 [304414/888800 34.25%] train loss: 1.4899892448738683e-05 \n",
      "epoch: 20 [305525/888800 34.38%] train loss: 1.3838548511557747e-05 \n",
      "epoch: 20 [306636/888800 34.50%] train loss: 1.3440280781651381e-05 \n",
      "epoch: 20 [307747/888800 34.62%] train loss: 1.4909271158103365e-05 \n",
      "epoch: 20 [308858/888800 34.75%] train loss: 1.4601821021642536e-05 \n",
      "epoch: 20 [309969/888800 34.88%] train loss: 1.581884134793654e-05 \n",
      "epoch: 20 [311080/888800 35.00%] train loss: 1.4707389709656127e-05 \n",
      "epoch: 20 [312191/888800 35.12%] train loss: 1.4857752830721438e-05 \n",
      "epoch: 20 [313302/888800 35.25%] train loss: 1.3397230759437662e-05 \n",
      "epoch: 20 [314413/888800 35.38%] train loss: 1.3531614058592822e-05 \n",
      "epoch: 20 [315524/888800 35.50%] train loss: 1.4549784282280598e-05 \n",
      "epoch: 20 [316635/888800 35.62%] train loss: 1.4931758414604701e-05 \n",
      "epoch: 20 [317746/888800 35.75%] train loss: 1.386896565236384e-05 \n",
      "epoch: 20 [318857/888800 35.88%] train loss: 1.4520767763315234e-05 \n",
      "epoch: 20 [319968/888800 36.00%] train loss: 1.3788931028102525e-05 \n",
      "epoch: 20 [321079/888800 36.12%] train loss: 1.4196937627275474e-05 \n",
      "epoch: 20 [322190/888800 36.25%] train loss: 1.4416672456718516e-05 \n",
      "epoch: 20 [323301/888800 36.38%] train loss: 1.3737902008870151e-05 \n",
      "epoch: 20 [324412/888800 36.50%] train loss: 1.4024746633367613e-05 \n",
      "epoch: 20 [325523/888800 36.62%] train loss: 1.4416759768209886e-05 \n",
      "epoch: 20 [326634/888800 36.75%] train loss: 1.3322055565367918e-05 \n",
      "epoch: 20 [327745/888800 36.88%] train loss: 1.4398183338926174e-05 \n",
      "epoch: 20 [328856/888800 37.00%] train loss: 1.3346106243261602e-05 \n",
      "epoch: 20 [329967/888800 37.12%] train loss: 1.2838818292948417e-05 \n",
      "epoch: 20 [331078/888800 37.25%] train loss: 1.3858616512152366e-05 \n",
      "epoch: 20 [332189/888800 37.38%] train loss: 1.4786136489419732e-05 \n",
      "epoch: 20 [333300/888800 37.50%] train loss: 1.447903377993498e-05 \n",
      "epoch: 20 [334411/888800 37.62%] train loss: 1.5320800230256282e-05 \n",
      "epoch: 20 [335522/888800 37.75%] train loss: 1.3725819371757098e-05 \n",
      "epoch: 20 [336633/888800 37.88%] train loss: 1.517878808954265e-05 \n",
      "epoch: 20 [337744/888800 38.00%] train loss: 1.3619885066873394e-05 \n",
      "epoch: 20 [338855/888800 38.12%] train loss: 1.2929160220664926e-05 \n",
      "epoch: 20 [339966/888800 38.25%] train loss: 1.4318671674118377e-05 \n",
      "epoch: 20 [341077/888800 38.38%] train loss: 1.2741579666908365e-05 \n",
      "epoch: 20 [342188/888800 38.50%] train loss: 1.5900039215921424e-05 \n",
      "epoch: 20 [343299/888800 38.62%] train loss: 1.4478753655566834e-05 \n",
      "epoch: 20 [344410/888800 38.75%] train loss: 1.6465950466226786e-05 \n",
      "epoch: 20 [345521/888800 38.88%] train loss: 1.4637873391620815e-05 \n",
      "epoch: 20 [346632/888800 39.00%] train loss: 1.5072199857968371e-05 \n",
      "epoch: 20 [347743/888800 39.12%] train loss: 1.576478643983137e-05 \n",
      "epoch: 20 [348854/888800 39.25%] train loss: 1.4486538020719308e-05 \n",
      "epoch: 20 [349965/888800 39.38%] train loss: 1.4815617760177702e-05 \n",
      "epoch: 20 [351076/888800 39.50%] train loss: 1.4189146895660087e-05 \n",
      "epoch: 20 [352187/888800 39.62%] train loss: 1.5577352314721793e-05 \n",
      "epoch: 20 [353298/888800 39.75%] train loss: 1.3146169294486754e-05 \n",
      "epoch: 20 [354409/888800 39.88%] train loss: 1.4516859664581716e-05 \n",
      "epoch: 20 [355520/888800 40.00%] train loss: 1.3865428627468646e-05 \n",
      "epoch: 20 [356631/888800 40.12%] train loss: 1.4997033758845646e-05 \n",
      "epoch: 20 [357742/888800 40.25%] train loss: 1.614324537513312e-05 \n",
      "epoch: 20 [358853/888800 40.38%] train loss: 1.539364893687889e-05 \n",
      "epoch: 20 [359964/888800 40.50%] train loss: 1.5060008081491105e-05 \n",
      "epoch: 20 [361075/888800 40.62%] train loss: 1.46619249790092e-05 \n",
      "epoch: 20 [362186/888800 40.75%] train loss: 1.4621082300436683e-05 \n",
      "epoch: 20 [363297/888800 40.88%] train loss: 1.5574105418636464e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [364408/888800 41.00%] train loss: 1.3931579815107398e-05 \n",
      "epoch: 20 [365519/888800 41.12%] train loss: 1.7529477190691978e-05 \n",
      "epoch: 20 [366630/888800 41.25%] train loss: 1.3546862646762747e-05 \n",
      "epoch: 20 [367741/888800 41.38%] train loss: 1.525027892057551e-05 \n",
      "epoch: 20 [368852/888800 41.50%] train loss: 1.3938956726633478e-05 \n",
      "epoch: 20 [369963/888800 41.62%] train loss: 1.449131468689302e-05 \n",
      "epoch: 20 [371074/888800 41.75%] train loss: 1.4720060789841227e-05 \n",
      "epoch: 20 [372185/888800 41.88%] train loss: 1.4883165931678377e-05 \n",
      "epoch: 20 [373296/888800 42.00%] train loss: 1.4943739188311156e-05 \n",
      "epoch: 20 [374407/888800 42.12%] train loss: 1.4660189663118217e-05 \n",
      "epoch: 20 [375518/888800 42.25%] train loss: 1.4398751773114782e-05 \n",
      "epoch: 20 [376629/888800 42.38%] train loss: 1.4504969840345439e-05 \n",
      "epoch: 20 [377740/888800 42.50%] train loss: 1.535613955638837e-05 \n",
      "epoch: 20 [378851/888800 42.62%] train loss: 1.4470694623014424e-05 \n",
      "epoch: 20 [379962/888800 42.75%] train loss: 1.5424820958287455e-05 \n",
      "epoch: 20 [381073/888800 42.88%] train loss: 1.5178504327195697e-05 \n",
      "epoch: 20 [382184/888800 43.00%] train loss: 1.5145153156481683e-05 \n",
      "epoch: 20 [383295/888800 43.12%] train loss: 1.4597776498703752e-05 \n",
      "epoch: 20 [384406/888800 43.25%] train loss: 1.4592046682082582e-05 \n",
      "epoch: 20 [385517/888800 43.38%] train loss: 1.4949452634027693e-05 \n",
      "epoch: 20 [386628/888800 43.50%] train loss: 1.5965060811140575e-05 \n",
      "epoch: 20 [387739/888800 43.62%] train loss: 1.5746967619634233e-05 \n",
      "epoch: 20 [388850/888800 43.75%] train loss: 1.2829620573029388e-05 \n",
      "epoch: 20 [389961/888800 43.88%] train loss: 1.5052934031700715e-05 \n",
      "epoch: 20 [391072/888800 44.00%] train loss: 1.4079339052841533e-05 \n",
      "epoch: 20 [392183/888800 44.12%] train loss: 1.4906117030477617e-05 \n",
      "epoch: 20 [393294/888800 44.25%] train loss: 1.5356572475866415e-05 \n",
      "epoch: 20 [394405/888800 44.38%] train loss: 1.534744842501823e-05 \n",
      "epoch: 20 [395516/888800 44.50%] train loss: 1.4323225514090154e-05 \n",
      "epoch: 20 [396627/888800 44.62%] train loss: 1.3662881428899709e-05 \n",
      "epoch: 20 [397738/888800 44.75%] train loss: 1.4123625078354962e-05 \n",
      "epoch: 20 [398849/888800 44.88%] train loss: 1.4067850315768737e-05 \n",
      "epoch: 20 [399960/888800 45.00%] train loss: 1.505369073129259e-05 \n",
      "epoch: 20 [401071/888800 45.12%] train loss: 1.351979881292209e-05 \n",
      "epoch: 20 [402182/888800 45.25%] train loss: 1.503793100710027e-05 \n",
      "epoch: 20 [403293/888800 45.38%] train loss: 1.3717690308112651e-05 \n",
      "epoch: 20 [404404/888800 45.50%] train loss: 1.3825258065480739e-05 \n",
      "epoch: 20 [405515/888800 45.62%] train loss: 1.542905556561891e-05 \n",
      "epoch: 20 [406626/888800 45.75%] train loss: 1.5151894331211224e-05 \n",
      "epoch: 20 [407737/888800 45.88%] train loss: 1.634186082810629e-05 \n",
      "epoch: 20 [408848/888800 46.00%] train loss: 1.3985343684908003e-05 \n",
      "epoch: 20 [409959/888800 46.12%] train loss: 1.661297028476838e-05 \n",
      "epoch: 20 [411070/888800 46.25%] train loss: 1.4804086276853923e-05 \n",
      "epoch: 20 [412181/888800 46.38%] train loss: 1.7134128938778304e-05 \n",
      "epoch: 20 [413292/888800 46.50%] train loss: 1.3591818060376681e-05 \n",
      "epoch: 20 [414403/888800 46.62%] train loss: 1.8056305634672754e-05 \n",
      "epoch: 20 [415514/888800 46.75%] train loss: 1.3644455975736491e-05 \n",
      "epoch: 20 [416625/888800 46.88%] train loss: 1.6975236576399766e-05 \n",
      "epoch: 20 [417736/888800 47.00%] train loss: 1.616250847291667e-05 \n",
      "epoch: 20 [418847/888800 47.12%] train loss: 1.645436896069441e-05 \n",
      "epoch: 20 [419958/888800 47.25%] train loss: 1.806789259717334e-05 \n",
      "epoch: 20 [421069/888800 47.38%] train loss: 1.3898992619942874e-05 \n",
      "epoch: 20 [422180/888800 47.50%] train loss: 1.64734465215588e-05 \n",
      "epoch: 20 [423291/888800 47.62%] train loss: 1.3468175893649459e-05 \n",
      "epoch: 20 [424402/888800 47.75%] train loss: 1.7142048818641342e-05 \n",
      "epoch: 20 [425513/888800 47.88%] train loss: 1.4371365978149697e-05 \n",
      "epoch: 20 [426624/888800 48.00%] train loss: 1.503698240412632e-05 \n",
      "epoch: 20 [427735/888800 48.12%] train loss: 1.320673072768841e-05 \n",
      "epoch: 20 [428846/888800 48.25%] train loss: 1.3886287888453808e-05 \n",
      "epoch: 20 [429957/888800 48.38%] train loss: 1.4444832231674809e-05 \n",
      "epoch: 20 [431068/888800 48.50%] train loss: 1.533766044303775e-05 \n",
      "epoch: 20 [432179/888800 48.62%] train loss: 1.4085926522966474e-05 \n",
      "epoch: 20 [433290/888800 48.75%] train loss: 1.4472543625743128e-05 \n",
      "epoch: 20 [434401/888800 48.88%] train loss: 1.5307083231164142e-05 \n",
      "epoch: 20 [435512/888800 49.00%] train loss: 1.3513328667613678e-05 \n",
      "epoch: 20 [436623/888800 49.12%] train loss: 1.4735202967131045e-05 \n",
      "epoch: 20 [437734/888800 49.25%] train loss: 1.5097334653546568e-05 \n",
      "epoch: 20 [438845/888800 49.38%] train loss: 1.4162233128445223e-05 \n",
      "epoch: 20 [439956/888800 49.50%] train loss: 1.249025808647275e-05 \n",
      "epoch: 20 [441067/888800 49.62%] train loss: 1.3749198842560872e-05 \n",
      "epoch: 20 [442178/888800 49.75%] train loss: 1.5242017070704605e-05 \n",
      "epoch: 20 [443289/888800 49.88%] train loss: 1.4365881725098006e-05 \n",
      "epoch: 20 [444400/888800 50.00%] train loss: 1.3219992979429662e-05 \n",
      "epoch: 20 [445511/888800 50.12%] train loss: 1.4720149920322001e-05 \n",
      "epoch: 20 [446622/888800 50.25%] train loss: 1.5557192455162294e-05 \n",
      "epoch: 20 [447733/888800 50.38%] train loss: 1.4462419130722992e-05 \n",
      "epoch: 20 [448844/888800 50.50%] train loss: 1.3629380191559903e-05 \n",
      "epoch: 20 [449955/888800 50.62%] train loss: 1.3452650819090195e-05 \n",
      "epoch: 20 [451066/888800 50.75%] train loss: 1.4431570889428258e-05 \n",
      "epoch: 20 [452177/888800 50.88%] train loss: 1.5574341887258925e-05 \n",
      "epoch: 20 [453288/888800 51.00%] train loss: 1.391266232531052e-05 \n",
      "epoch: 20 [454399/888800 51.12%] train loss: 1.5121662727324292e-05 \n",
      "epoch: 20 [455510/888800 51.25%] train loss: 1.4194546565704513e-05 \n",
      "epoch: 20 [456621/888800 51.38%] train loss: 1.4130822819424793e-05 \n",
      "epoch: 20 [457732/888800 51.50%] train loss: 1.5129661733226385e-05 \n",
      "epoch: 20 [458843/888800 51.62%] train loss: 1.4911157450114843e-05 \n",
      "epoch: 20 [459954/888800 51.75%] train loss: 1.4376698345586192e-05 \n",
      "epoch: 20 [461065/888800 51.88%] train loss: 1.3416623005468864e-05 \n",
      "epoch: 20 [462176/888800 52.00%] train loss: 1.353795323666418e-05 \n",
      "epoch: 20 [463287/888800 52.12%] train loss: 1.4482622646028176e-05 \n",
      "epoch: 20 [464398/888800 52.25%] train loss: 1.3994233995617833e-05 \n",
      "epoch: 20 [465509/888800 52.38%] train loss: 1.4498034033749718e-05 \n",
      "epoch: 20 [466620/888800 52.50%] train loss: 1.3705007404496428e-05 \n",
      "epoch: 20 [467731/888800 52.62%] train loss: 1.3462436982081272e-05 \n",
      "epoch: 20 [468842/888800 52.75%] train loss: 1.3799305634165648e-05 \n",
      "epoch: 20 [469953/888800 52.88%] train loss: 1.347827219433384e-05 \n",
      "epoch: 20 [471064/888800 53.00%] train loss: 1.4420705156226177e-05 \n",
      "epoch: 20 [472175/888800 53.12%] train loss: 1.4126175301498733e-05 \n",
      "epoch: 20 [473286/888800 53.25%] train loss: 1.409126434737118e-05 \n",
      "epoch: 20 [474397/888800 53.38%] train loss: 1.4878605725243688e-05 \n",
      "epoch: 20 [475508/888800 53.50%] train loss: 1.436568891222123e-05 \n",
      "epoch: 20 [476619/888800 53.62%] train loss: 1.4498704331344925e-05 \n",
      "epoch: 20 [477730/888800 53.75%] train loss: 1.466029880248243e-05 \n",
      "epoch: 20 [478841/888800 53.88%] train loss: 1.3948999367130455e-05 \n",
      "epoch: 20 [479952/888800 54.00%] train loss: 1.327131667494541e-05 \n",
      "epoch: 20 [481063/888800 54.12%] train loss: 1.4505069884762634e-05 \n",
      "epoch: 20 [482174/888800 54.25%] train loss: 1.4547033970302437e-05 \n",
      "epoch: 20 [483285/888800 54.38%] train loss: 1.4300375369202811e-05 \n",
      "epoch: 20 [484396/888800 54.50%] train loss: 1.407745457981946e-05 \n",
      "epoch: 20 [485507/888800 54.62%] train loss: 1.3765763469564263e-05 \n",
      "epoch: 20 [486618/888800 54.75%] train loss: 1.5099513802852016e-05 \n",
      "epoch: 20 [487729/888800 54.88%] train loss: 1.4176929653331172e-05 \n",
      "epoch: 20 [488840/888800 55.00%] train loss: 1.5433761291205883e-05 \n",
      "epoch: 20 [489951/888800 55.12%] train loss: 1.3399107956502121e-05 \n",
      "epoch: 20 [491062/888800 55.25%] train loss: 1.4591462786484044e-05 \n",
      "epoch: 20 [492173/888800 55.38%] train loss: 1.395802064507734e-05 \n",
      "epoch: 20 [493284/888800 55.50%] train loss: 1.5078076103236526e-05 \n",
      "epoch: 20 [494395/888800 55.62%] train loss: 1.3948179002909455e-05 \n",
      "epoch: 20 [495506/888800 55.75%] train loss: 1.4675492820970248e-05 \n",
      "epoch: 20 [496617/888800 55.88%] train loss: 1.516205975349294e-05 \n",
      "epoch: 20 [497728/888800 56.00%] train loss: 1.4392356206371915e-05 \n",
      "epoch: 20 [498839/888800 56.12%] train loss: 1.4434652257477865e-05 \n",
      "epoch: 20 [499950/888800 56.25%] train loss: 1.4068458767724223e-05 \n",
      "epoch: 20 [501061/888800 56.38%] train loss: 1.4519577234750614e-05 \n",
      "epoch: 20 [502172/888800 56.50%] train loss: 1.3188962839194573e-05 \n",
      "epoch: 20 [503283/888800 56.62%] train loss: 1.4488717170024756e-05 \n",
      "epoch: 20 [504394/888800 56.75%] train loss: 1.5204700503090862e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [505505/888800 56.88%] train loss: 1.4720796571054962e-05 \n",
      "epoch: 20 [506616/888800 57.00%] train loss: 1.4641621419286821e-05 \n",
      "epoch: 20 [507727/888800 57.12%] train loss: 1.4222298887034412e-05 \n",
      "epoch: 20 [508838/888800 57.25%] train loss: 1.5092868125066161e-05 \n",
      "epoch: 20 [509949/888800 57.38%] train loss: 1.3620785466628149e-05 \n",
      "epoch: 20 [511060/888800 57.50%] train loss: 1.4698985069117043e-05 \n",
      "epoch: 20 [512171/888800 57.62%] train loss: 1.5233075828291476e-05 \n",
      "epoch: 20 [513282/888800 57.75%] train loss: 1.468236223445274e-05 \n",
      "epoch: 20 [514393/888800 57.88%] train loss: 1.3817864783050027e-05 \n",
      "epoch: 20 [515504/888800 58.00%] train loss: 1.4640589142800309e-05 \n",
      "epoch: 20 [516615/888800 58.12%] train loss: 1.376408454234479e-05 \n",
      "epoch: 20 [517726/888800 58.25%] train loss: 1.643303403398022e-05 \n",
      "epoch: 20 [518837/888800 58.38%] train loss: 1.407996842317516e-05 \n",
      "epoch: 20 [519948/888800 58.50%] train loss: 1.2949145457241684e-05 \n",
      "epoch: 20 [521059/888800 58.62%] train loss: 1.3646719708049204e-05 \n",
      "epoch: 20 [522170/888800 58.75%] train loss: 1.374287785438355e-05 \n",
      "epoch: 20 [523281/888800 58.88%] train loss: 1.294974845222896e-05 \n",
      "epoch: 20 [524392/888800 59.00%] train loss: 1.4793148693570402e-05 \n",
      "epoch: 20 [525503/888800 59.12%] train loss: 1.348572095594136e-05 \n",
      "epoch: 20 [526614/888800 59.25%] train loss: 1.5509165677940473e-05 \n",
      "epoch: 20 [527725/888800 59.38%] train loss: 1.4947549971111584e-05 \n",
      "epoch: 20 [528836/888800 59.50%] train loss: 1.3621131074614823e-05 \n",
      "epoch: 20 [529947/888800 59.62%] train loss: 1.3964552636025473e-05 \n",
      "epoch: 20 [531058/888800 59.75%] train loss: 1.541851452202536e-05 \n",
      "epoch: 20 [532169/888800 59.88%] train loss: 1.4737446690560319e-05 \n",
      "epoch: 20 [533280/888800 60.00%] train loss: 1.4590768842026591e-05 \n",
      "epoch: 20 [534391/888800 60.12%] train loss: 1.4681315406050999e-05 \n",
      "epoch: 20 [535502/888800 60.25%] train loss: 1.3244777619547676e-05 \n",
      "epoch: 20 [536613/888800 60.38%] train loss: 1.405154853273416e-05 \n",
      "epoch: 20 [537724/888800 60.50%] train loss: 1.3957618648419157e-05 \n",
      "epoch: 20 [538835/888800 60.62%] train loss: 1.4231232853489928e-05 \n",
      "epoch: 20 [539946/888800 60.75%] train loss: 1.2856372450187337e-05 \n",
      "epoch: 20 [541057/888800 60.88%] train loss: 1.404909653501818e-05 \n",
      "epoch: 20 [542168/888800 61.00%] train loss: 1.4083296264288947e-05 \n",
      "epoch: 20 [543279/888800 61.12%] train loss: 1.2857987712777685e-05 \n",
      "epoch: 20 [544390/888800 61.25%] train loss: 1.3670096450368874e-05 \n",
      "epoch: 20 [545501/888800 61.38%] train loss: 1.3322655831871089e-05 \n",
      "epoch: 20 [546612/888800 61.50%] train loss: 1.4748366083949804e-05 \n",
      "epoch: 20 [547723/888800 61.62%] train loss: 1.573763438500464e-05 \n",
      "epoch: 20 [548834/888800 61.75%] train loss: 1.4195520634530112e-05 \n",
      "epoch: 20 [549945/888800 61.88%] train loss: 1.5163805983320344e-05 \n",
      "epoch: 20 [551056/888800 62.00%] train loss: 1.4745169210073072e-05 \n",
      "epoch: 20 [552167/888800 62.12%] train loss: 1.4484355233435053e-05 \n",
      "epoch: 20 [553278/888800 62.25%] train loss: 1.380922731186729e-05 \n",
      "epoch: 20 [554389/888800 62.38%] train loss: 1.4049311175767798e-05 \n",
      "epoch: 20 [555500/888800 62.50%] train loss: 1.4089256183069665e-05 \n",
      "epoch: 20 [556611/888800 62.62%] train loss: 1.4192524758982472e-05 \n",
      "epoch: 20 [557722/888800 62.75%] train loss: 1.3949054846307263e-05 \n",
      "epoch: 20 [558833/888800 62.88%] train loss: 1.469312519475352e-05 \n",
      "epoch: 20 [559944/888800 63.00%] train loss: 1.53564615175128e-05 \n",
      "epoch: 20 [561055/888800 63.12%] train loss: 1.3799911357637029e-05 \n",
      "epoch: 20 [562166/888800 63.25%] train loss: 1.369407709717052e-05 \n",
      "epoch: 20 [563277/888800 63.38%] train loss: 1.392939066136023e-05 \n",
      "epoch: 20 [564388/888800 63.50%] train loss: 1.501730912423227e-05 \n",
      "epoch: 20 [565499/888800 63.62%] train loss: 1.483832147641806e-05 \n",
      "epoch: 20 [566610/888800 63.75%] train loss: 1.4095343431108631e-05 \n",
      "epoch: 20 [567721/888800 63.88%] train loss: 1.5297169738914818e-05 \n",
      "epoch: 20 [568832/888800 64.00%] train loss: 1.3802392459183466e-05 \n",
      "epoch: 20 [569943/888800 64.12%] train loss: 1.29400732475915e-05 \n",
      "epoch: 20 [571054/888800 64.25%] train loss: 1.4802027180849109e-05 \n",
      "epoch: 20 [572165/888800 64.38%] train loss: 1.3374927220866084e-05 \n",
      "epoch: 20 [573276/888800 64.50%] train loss: 1.4735981494595762e-05 \n",
      "epoch: 20 [574387/888800 64.62%] train loss: 1.3382206816459075e-05 \n",
      "epoch: 20 [575498/888800 64.75%] train loss: 1.4384952010004781e-05 \n",
      "epoch: 20 [576609/888800 64.88%] train loss: 1.4572108739230316e-05 \n",
      "epoch: 20 [577720/888800 65.00%] train loss: 1.492859792051604e-05 \n",
      "epoch: 20 [578831/888800 65.12%] train loss: 1.4447071407630574e-05 \n",
      "epoch: 20 [579942/888800 65.25%] train loss: 1.3114907233102713e-05 \n",
      "epoch: 20 [581053/888800 65.38%] train loss: 1.4256484973884653e-05 \n",
      "epoch: 20 [582164/888800 65.50%] train loss: 1.4728217138326727e-05 \n",
      "epoch: 20 [583275/888800 65.62%] train loss: 1.4144850865704939e-05 \n",
      "epoch: 20 [584386/888800 65.75%] train loss: 1.3682382814295124e-05 \n",
      "epoch: 20 [585497/888800 65.88%] train loss: 1.4150143215374555e-05 \n",
      "epoch: 20 [586608/888800 66.00%] train loss: 1.5167236597335432e-05 \n",
      "epoch: 20 [587719/888800 66.12%] train loss: 1.4453736184805166e-05 \n",
      "epoch: 20 [588830/888800 66.25%] train loss: 1.3991889318276662e-05 \n",
      "epoch: 20 [589941/888800 66.38%] train loss: 1.3224851500126533e-05 \n",
      "epoch: 20 [591052/888800 66.50%] train loss: 1.4239751180866733e-05 \n",
      "epoch: 20 [592163/888800 66.62%] train loss: 1.3731982107856311e-05 \n",
      "epoch: 20 [593274/888800 66.75%] train loss: 1.4934374121367e-05 \n",
      "epoch: 20 [594385/888800 66.88%] train loss: 1.470928418711992e-05 \n",
      "epoch: 20 [595496/888800 67.00%] train loss: 1.544464066682849e-05 \n",
      "epoch: 20 [596607/888800 67.12%] train loss: 1.3716014109377284e-05 \n",
      "epoch: 20 [597718/888800 67.25%] train loss: 1.4878486581437755e-05 \n",
      "epoch: 20 [598829/888800 67.38%] train loss: 1.5912375602056272e-05 \n",
      "epoch: 20 [599940/888800 67.50%] train loss: 1.4866979654470924e-05 \n",
      "epoch: 20 [601051/888800 67.62%] train loss: 1.5487632481381297e-05 \n",
      "epoch: 20 [602162/888800 67.75%] train loss: 1.5144199096539523e-05 \n",
      "epoch: 20 [603273/888800 67.88%] train loss: 1.65267465490615e-05 \n",
      "epoch: 20 [604384/888800 68.00%] train loss: 1.3803647561871912e-05 \n",
      "epoch: 20 [605495/888800 68.12%] train loss: 1.4960840417188592e-05 \n",
      "epoch: 20 [606606/888800 68.25%] train loss: 1.3701363059226424e-05 \n",
      "epoch: 20 [607717/888800 68.38%] train loss: 1.5464849639101885e-05 \n",
      "epoch: 20 [608828/888800 68.50%] train loss: 1.3951919754617848e-05 \n",
      "epoch: 20 [609939/888800 68.62%] train loss: 1.387860447721323e-05 \n",
      "epoch: 20 [611050/888800 68.75%] train loss: 1.402520683768671e-05 \n",
      "epoch: 20 [612161/888800 68.88%] train loss: 1.428901668987237e-05 \n",
      "epoch: 20 [613272/888800 69.00%] train loss: 1.4653126527264249e-05 \n",
      "epoch: 20 [614383/888800 69.12%] train loss: 1.553693800815381e-05 \n",
      "epoch: 20 [615494/888800 69.25%] train loss: 1.6241208868450485e-05 \n",
      "epoch: 20 [616605/888800 69.38%] train loss: 1.528153006802313e-05 \n",
      "epoch: 20 [617716/888800 69.50%] train loss: 1.5754179912619293e-05 \n",
      "epoch: 20 [618827/888800 69.62%] train loss: 1.3821205357089639e-05 \n",
      "epoch: 20 [619938/888800 69.75%] train loss: 1.5125326171983033e-05 \n",
      "epoch: 20 [621049/888800 69.88%] train loss: 1.3656892406288534e-05 \n",
      "epoch: 20 [622160/888800 70.00%] train loss: 1.3935821698396467e-05 \n",
      "epoch: 20 [623271/888800 70.12%] train loss: 1.5098075891728513e-05 \n",
      "epoch: 20 [624382/888800 70.25%] train loss: 1.5067749700392596e-05 \n",
      "epoch: 20 [625493/888800 70.38%] train loss: 1.3963413948658854e-05 \n",
      "epoch: 20 [626604/888800 70.50%] train loss: 1.5348779925261624e-05 \n",
      "epoch: 20 [627715/888800 70.62%] train loss: 1.4261652722780127e-05 \n",
      "epoch: 20 [628826/888800 70.75%] train loss: 1.4361442481458653e-05 \n",
      "epoch: 20 [629937/888800 70.88%] train loss: 1.4204156286723446e-05 \n",
      "epoch: 20 [631048/888800 71.00%] train loss: 1.3218754247645847e-05 \n",
      "epoch: 20 [632159/888800 71.12%] train loss: 1.2919455912197009e-05 \n",
      "epoch: 20 [633270/888800 71.25%] train loss: 1.3197064617997967e-05 \n",
      "epoch: 20 [634381/888800 71.38%] train loss: 1.3957296687294729e-05 \n",
      "epoch: 20 [635492/888800 71.50%] train loss: 1.4985768757469486e-05 \n",
      "epoch: 20 [636603/888800 71.62%] train loss: 1.3353831491258461e-05 \n",
      "epoch: 20 [637714/888800 71.75%] train loss: 1.3656681403517723e-05 \n",
      "epoch: 20 [638825/888800 71.88%] train loss: 1.4156007637211587e-05 \n",
      "epoch: 20 [639936/888800 72.00%] train loss: 1.5481387890758924e-05 \n",
      "epoch: 20 [641047/888800 72.12%] train loss: 1.4763265426154248e-05 \n",
      "epoch: 20 [642158/888800 72.25%] train loss: 1.385425275657326e-05 \n",
      "epoch: 20 [643269/888800 72.38%] train loss: 1.4564321645593736e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [644380/888800 72.50%] train loss: 1.4500003999273758e-05 \n",
      "epoch: 20 [645491/888800 72.62%] train loss: 1.488445013819728e-05 \n",
      "epoch: 20 [646602/888800 72.75%] train loss: 1.2583107491082046e-05 \n",
      "epoch: 20 [647713/888800 72.88%] train loss: 1.4704619388794526e-05 \n",
      "epoch: 20 [648824/888800 73.00%] train loss: 1.4874437511025462e-05 \n",
      "epoch: 20 [649935/888800 73.12%] train loss: 1.3681875316251535e-05 \n",
      "epoch: 20 [651046/888800 73.25%] train loss: 1.4756733435206115e-05 \n",
      "epoch: 20 [652157/888800 73.38%] train loss: 1.4561324860551395e-05 \n",
      "epoch: 20 [653268/888800 73.50%] train loss: 1.4855113477096893e-05 \n",
      "epoch: 20 [654379/888800 73.62%] train loss: 1.4214281691238284e-05 \n",
      "epoch: 20 [655490/888800 73.75%] train loss: 1.537066236778628e-05 \n",
      "epoch: 20 [656601/888800 73.88%] train loss: 1.3060495803074446e-05 \n",
      "epoch: 20 [657712/888800 74.00%] train loss: 1.4012137398822233e-05 \n",
      "epoch: 20 [658823/888800 74.12%] train loss: 1.52969550981652e-05 \n",
      "epoch: 20 [659934/888800 74.25%] train loss: 1.4769002518733032e-05 \n",
      "epoch: 20 [661045/888800 74.38%] train loss: 1.3308560482983012e-05 \n",
      "epoch: 20 [662156/888800 74.50%] train loss: 1.6457253877888434e-05 \n",
      "epoch: 20 [663267/888800 74.62%] train loss: 1.4756918062630575e-05 \n",
      "epoch: 20 [664378/888800 74.75%] train loss: 1.529076871520374e-05 \n",
      "epoch: 20 [665489/888800 74.88%] train loss: 1.3602817489299923e-05 \n",
      "epoch: 20 [666600/888800 75.00%] train loss: 1.3434305401460733e-05 \n",
      "epoch: 20 [667711/888800 75.12%] train loss: 1.4226585335563868e-05 \n",
      "epoch: 20 [668822/888800 75.25%] train loss: 1.2531904758361634e-05 \n",
      "epoch: 20 [669933/888800 75.38%] train loss: 1.3900887097406667e-05 \n",
      "epoch: 20 [671044/888800 75.50%] train loss: 1.3423921700450592e-05 \n",
      "epoch: 20 [672155/888800 75.62%] train loss: 1.3477520951710176e-05 \n",
      "epoch: 20 [673266/888800 75.75%] train loss: 1.3258479157229885e-05 \n",
      "epoch: 20 [674377/888800 75.88%] train loss: 1.3889792171539739e-05 \n",
      "epoch: 20 [675488/888800 76.00%] train loss: 1.4233683941711206e-05 \n",
      "epoch: 20 [676599/888800 76.12%] train loss: 1.4781201571167912e-05 \n",
      "epoch: 20 [677710/888800 76.25%] train loss: 1.458188307879027e-05 \n",
      "epoch: 20 [678821/888800 76.38%] train loss: 1.4692363947688136e-05 \n",
      "epoch: 20 [679932/888800 76.50%] train loss: 1.590054489497561e-05 \n",
      "epoch: 20 [681043/888800 76.62%] train loss: 1.4373528756550513e-05 \n",
      "epoch: 20 [682154/888800 76.75%] train loss: 1.589038765814621e-05 \n",
      "epoch: 20 [683265/888800 76.88%] train loss: 1.4637426829722244e-05 \n",
      "epoch: 20 [684376/888800 77.00%] train loss: 1.4464353625953663e-05 \n",
      "epoch: 20 [685487/888800 77.12%] train loss: 1.3997805581311695e-05 \n",
      "epoch: 20 [686598/888800 77.25%] train loss: 1.5479006833629683e-05 \n",
      "epoch: 20 [687709/888800 77.38%] train loss: 1.313853954343358e-05 \n",
      "epoch: 20 [688820/888800 77.50%] train loss: 1.5254194295266643e-05 \n",
      "epoch: 20 [689931/888800 77.62%] train loss: 1.3422762094705831e-05 \n",
      "epoch: 20 [691042/888800 77.75%] train loss: 1.403665646648733e-05 \n",
      "epoch: 20 [692153/888800 77.88%] train loss: 1.2934267033415381e-05 \n",
      "epoch: 20 [693264/888800 78.00%] train loss: 1.3899274563300423e-05 \n",
      "epoch: 20 [694375/888800 78.12%] train loss: 1.2526015780167654e-05 \n",
      "epoch: 20 [695486/888800 78.25%] train loss: 1.3848058188159484e-05 \n",
      "epoch: 20 [696597/888800 78.38%] train loss: 1.336241348326439e-05 \n",
      "epoch: 20 [697708/888800 78.50%] train loss: 1.3663895515492186e-05 \n",
      "epoch: 20 [698819/888800 78.62%] train loss: 1.5390811313409358e-05 \n",
      "epoch: 20 [699930/888800 78.75%] train loss: 1.4725600522069726e-05 \n",
      "epoch: 20 [701041/888800 78.88%] train loss: 1.43426395879942e-05 \n",
      "epoch: 20 [702152/888800 79.00%] train loss: 1.4775346244277898e-05 \n",
      "epoch: 20 [703263/888800 79.12%] train loss: 1.4656955499958713e-05 \n",
      "epoch: 20 [704374/888800 79.25%] train loss: 1.467693527956726e-05 \n",
      "epoch: 20 [705485/888800 79.38%] train loss: 1.420133685314795e-05 \n",
      "epoch: 20 [706596/888800 79.50%] train loss: 1.4537531569658313e-05 \n",
      "epoch: 20 [707707/888800 79.62%] train loss: 1.3683838005817961e-05 \n",
      "epoch: 20 [708818/888800 79.75%] train loss: 1.389431236020755e-05 \n",
      "epoch: 20 [709929/888800 79.88%] train loss: 1.2917038475279696e-05 \n",
      "epoch: 20 [711040/888800 80.00%] train loss: 1.3821311767969746e-05 \n",
      "epoch: 20 [712151/888800 80.12%] train loss: 1.3039139957982115e-05 \n",
      "epoch: 20 [713262/888800 80.25%] train loss: 1.468767186452169e-05 \n",
      "epoch: 20 [714373/888800 80.38%] train loss: 1.462957061448833e-05 \n",
      "epoch: 20 [715484/888800 80.50%] train loss: 1.4240551536204293e-05 \n",
      "epoch: 20 [716595/888800 80.62%] train loss: 1.4064693459658884e-05 \n",
      "epoch: 20 [717706/888800 80.75%] train loss: 1.4240658856579103e-05 \n",
      "epoch: 20 [718817/888800 80.88%] train loss: 1.373162285744911e-05 \n",
      "epoch: 20 [719928/888800 81.00%] train loss: 1.2659819731197786e-05 \n",
      "epoch: 20 [721039/888800 81.12%] train loss: 1.3732749721384607e-05 \n",
      "epoch: 20 [722150/888800 81.25%] train loss: 1.3737733752350323e-05 \n",
      "epoch: 20 [723261/888800 81.38%] train loss: 1.4116848433332052e-05 \n",
      "epoch: 20 [724372/888800 81.50%] train loss: 1.345336113445228e-05 \n",
      "epoch: 20 [725483/888800 81.62%] train loss: 1.3682193639397155e-05 \n",
      "epoch: 20 [726594/888800 81.75%] train loss: 1.4886689314153045e-05 \n",
      "epoch: 20 [727705/888800 81.88%] train loss: 1.3800714441458695e-05 \n",
      "epoch: 20 [728816/888800 82.00%] train loss: 1.3558364116761368e-05 \n",
      "epoch: 20 [729927/888800 82.12%] train loss: 1.3689209481526632e-05 \n",
      "epoch: 20 [731038/888800 82.25%] train loss: 1.461474494135473e-05 \n",
      "epoch: 20 [732149/888800 82.38%] train loss: 1.4586554243578576e-05 \n",
      "epoch: 20 [733260/888800 82.50%] train loss: 1.3051516361883841e-05 \n",
      "epoch: 20 [734371/888800 82.62%] train loss: 1.402615089318715e-05 \n",
      "epoch: 20 [735482/888800 82.75%] train loss: 1.4944345821277238e-05 \n",
      "epoch: 20 [736593/888800 82.88%] train loss: 1.4434674994845409e-05 \n",
      "epoch: 20 [737704/888800 83.00%] train loss: 1.4747944987902883e-05 \n",
      "epoch: 20 [738815/888800 83.12%] train loss: 1.4220523553376552e-05 \n",
      "epoch: 20 [739926/888800 83.25%] train loss: 1.3319474419404287e-05 \n",
      "epoch: 20 [741037/888800 83.38%] train loss: 1.2731682545563672e-05 \n",
      "epoch: 20 [742148/888800 83.50%] train loss: 1.292085744353244e-05 \n",
      "epoch: 20 [743259/888800 83.62%] train loss: 1.4798643860558514e-05 \n",
      "epoch: 20 [744370/888800 83.75%] train loss: 1.4867549907648936e-05 \n",
      "epoch: 20 [745481/888800 83.88%] train loss: 1.3179359484638553e-05 \n",
      "epoch: 20 [746592/888800 84.00%] train loss: 1.4398395251191687e-05 \n",
      "epoch: 20 [747703/888800 84.12%] train loss: 1.3995798326504882e-05 \n",
      "epoch: 20 [748814/888800 84.25%] train loss: 1.4618498425988946e-05 \n",
      "epoch: 20 [749925/888800 84.38%] train loss: 1.4806702893110923e-05 \n",
      "epoch: 20 [751036/888800 84.50%] train loss: 1.43467441375833e-05 \n",
      "epoch: 20 [752147/888800 84.62%] train loss: 1.5054696632432751e-05 \n",
      "epoch: 20 [753258/888800 84.75%] train loss: 1.310672359977616e-05 \n",
      "epoch: 20 [754369/888800 84.88%] train loss: 1.606349542271346e-05 \n",
      "epoch: 20 [755480/888800 85.00%] train loss: 1.3676701200893149e-05 \n",
      "epoch: 20 [756591/888800 85.12%] train loss: 1.5256053302437067e-05 \n",
      "epoch: 20 [757702/888800 85.25%] train loss: 1.4534460206050426e-05 \n",
      "epoch: 20 [758813/888800 85.38%] train loss: 1.4574191482097376e-05 \n",
      "epoch: 20 [759924/888800 85.50%] train loss: 1.4130630006548017e-05 \n",
      "epoch: 20 [761035/888800 85.62%] train loss: 1.3622085134556983e-05 \n",
      "epoch: 20 [762146/888800 85.75%] train loss: 1.649511614232324e-05 \n",
      "epoch: 20 [763257/888800 85.88%] train loss: 1.4455225027631968e-05 \n",
      "epoch: 20 [764368/888800 86.00%] train loss: 1.4357653526531067e-05 \n",
      "epoch: 20 [765479/888800 86.12%] train loss: 1.3630361536343116e-05 \n",
      "epoch: 20 [766590/888800 86.25%] train loss: 1.3104213394399267e-05 \n",
      "epoch: 20 [767701/888800 86.38%] train loss: 1.4037424989510328e-05 \n",
      "epoch: 20 [768812/888800 86.50%] train loss: 1.3958140698377974e-05 \n",
      "epoch: 20 [769923/888800 86.62%] train loss: 1.357886958430754e-05 \n",
      "epoch: 20 [771034/888800 86.75%] train loss: 1.4891102182446048e-05 \n",
      "epoch: 20 [772145/888800 86.88%] train loss: 1.4638178072345909e-05 \n",
      "epoch: 20 [773256/888800 87.00%] train loss: 1.4482158803730272e-05 \n",
      "epoch: 20 [774367/888800 87.12%] train loss: 1.4165197171678301e-05 \n",
      "epoch: 20 [775478/888800 87.25%] train loss: 1.3255556041258387e-05 \n",
      "epoch: 20 [776589/888800 87.38%] train loss: 1.4062806258152705e-05 \n",
      "epoch: 20 [777700/888800 87.50%] train loss: 1.371263169858139e-05 \n",
      "epoch: 20 [778811/888800 87.62%] train loss: 1.4833640307188034e-05 \n",
      "epoch: 20 [779922/888800 87.75%] train loss: 1.4280144569056574e-05 \n",
      "epoch: 20 [781033/888800 87.88%] train loss: 1.5693714885856025e-05 \n",
      "epoch: 20 [782144/888800 88.00%] train loss: 1.4211667803465389e-05 \n",
      "epoch: 20 [783255/888800 88.12%] train loss: 1.3940965800429694e-05 \n",
      "epoch: 20 [784366/888800 88.25%] train loss: 1.5745106793474406e-05 \n",
      "epoch: 20 [785477/888800 88.38%] train loss: 1.5246706425386947e-05 \n",
      "epoch: 20 [786588/888800 88.50%] train loss: 1.390063698636368e-05 \n",
      "epoch: 20 [787699/888800 88.62%] train loss: 1.5004267879703548e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 [788810/888800 88.75%] train loss: 1.3539161045628134e-05 \n",
      "epoch: 20 [789921/888800 88.88%] train loss: 1.3347812455322128e-05 \n",
      "epoch: 20 [791032/888800 89.00%] train loss: 1.4941861081751995e-05 \n",
      "epoch: 20 [792143/888800 89.12%] train loss: 1.4308944628282916e-05 \n",
      "epoch: 20 [793254/888800 89.25%] train loss: 1.4732658200955484e-05 \n",
      "epoch: 20 [794365/888800 89.38%] train loss: 1.4412155906029511e-05 \n",
      "epoch: 20 [795476/888800 89.50%] train loss: 1.4080948858463671e-05 \n",
      "epoch: 20 [796587/888800 89.62%] train loss: 1.527496351627633e-05 \n",
      "epoch: 20 [797698/888800 89.75%] train loss: 1.2918500033265445e-05 \n",
      "epoch: 20 [798809/888800 89.88%] train loss: 1.4378711966855917e-05 \n",
      "epoch: 20 [799920/888800 90.00%] train loss: 1.2735568816424347e-05 \n",
      "epoch: 20 [801031/888800 90.12%] train loss: 1.4824074241914786e-05 \n",
      "epoch: 20 [802142/888800 90.25%] train loss: 1.43918359754025e-05 \n",
      "epoch: 20 [803253/888800 90.38%] train loss: 1.5457144399988465e-05 \n",
      "epoch: 20 [804364/888800 90.50%] train loss: 1.3278337974043097e-05 \n",
      "epoch: 20 [805475/888800 90.62%] train loss: 1.4468028894043528e-05 \n",
      "epoch: 20 [806586/888800 90.75%] train loss: 1.4268321137933526e-05 \n",
      "epoch: 20 [807697/888800 90.88%] train loss: 1.3942355508334003e-05 \n",
      "epoch: 20 [808808/888800 91.00%] train loss: 1.3117967682774179e-05 \n",
      "epoch: 20 [809919/888800 91.12%] train loss: 1.2824285477108788e-05 \n",
      "epoch: 20 [811030/888800 91.25%] train loss: 1.4311288396129385e-05 \n",
      "epoch: 20 [812141/888800 91.38%] train loss: 1.2834657354687806e-05 \n",
      "epoch: 20 [813252/888800 91.50%] train loss: 1.4521751836582553e-05 \n",
      "epoch: 20 [814363/888800 91.62%] train loss: 1.3964892787043937e-05 \n",
      "epoch: 20 [815474/888800 91.75%] train loss: 1.2857632100349292e-05 \n",
      "epoch: 20 [816585/888800 91.88%] train loss: 1.3515706086764112e-05 \n",
      "epoch: 20 [817696/888800 92.00%] train loss: 1.3771157682640478e-05 \n",
      "epoch: 20 [818807/888800 92.12%] train loss: 1.4950646800571121e-05 \n",
      "epoch: 20 [819918/888800 92.25%] train loss: 1.30875068862224e-05 \n",
      "epoch: 20 [821029/888800 92.38%] train loss: 1.4216993804438971e-05 \n",
      "epoch: 20 [822140/888800 92.50%] train loss: 1.4948458556318656e-05 \n",
      "epoch: 20 [823251/888800 92.62%] train loss: 1.39821104312432e-05 \n",
      "epoch: 20 [824362/888800 92.75%] train loss: 1.4536271010001656e-05 \n",
      "epoch: 20 [825473/888800 92.88%] train loss: 1.3703388503927272e-05 \n",
      "epoch: 20 [826584/888800 93.00%] train loss: 1.2668926501646638e-05 \n",
      "epoch: 20 [827695/888800 93.12%] train loss: 1.3241736269264948e-05 \n",
      "epoch: 20 [828806/888800 93.25%] train loss: 1.3931700777902734e-05 \n",
      "epoch: 20 [829917/888800 93.38%] train loss: 1.4000817827763967e-05 \n",
      "epoch: 20 [831028/888800 93.50%] train loss: 1.3368588952289429e-05 \n",
      "epoch: 20 [832139/888800 93.62%] train loss: 1.4545733392878901e-05 \n",
      "epoch: 20 [833250/888800 93.75%] train loss: 1.3764372852165252e-05 \n",
      "epoch: 20 [834361/888800 93.88%] train loss: 1.3378599760471843e-05 \n",
      "epoch: 20 [835472/888800 94.00%] train loss: 1.4504389582725707e-05 \n",
      "epoch: 20 [836583/888800 94.12%] train loss: 1.45086432894459e-05 \n",
      "epoch: 20 [837694/888800 94.25%] train loss: 1.3654232134285849e-05 \n",
      "epoch: 20 [838805/888800 94.38%] train loss: 1.4328913493955042e-05 \n",
      "epoch: 20 [839916/888800 94.50%] train loss: 1.336554214503849e-05 \n",
      "epoch: 20 [841027/888800 94.62%] train loss: 1.251017238246277e-05 \n",
      "epoch: 20 [842138/888800 94.75%] train loss: 1.4362804904521909e-05 \n",
      "epoch: 20 [843249/888800 94.88%] train loss: 1.33218409246183e-05 \n",
      "epoch: 20 [844360/888800 95.00%] train loss: 1.4288370039139409e-05 \n",
      "epoch: 20 [845471/888800 95.12%] train loss: 1.4078967069508508e-05 \n",
      "epoch: 20 [846582/888800 95.25%] train loss: 1.5005885870778002e-05 \n",
      "epoch: 20 [847693/888800 95.38%] train loss: 1.4884838492434938e-05 \n",
      "epoch: 20 [848804/888800 95.50%] train loss: 1.490709291829262e-05 \n",
      "epoch: 20 [849915/888800 95.62%] train loss: 1.5495535990339704e-05 \n",
      "epoch: 20 [851026/888800 95.75%] train loss: 1.3511840734281577e-05 \n",
      "epoch: 20 [852137/888800 95.88%] train loss: 1.588762825122103e-05 \n",
      "epoch: 20 [853248/888800 96.00%] train loss: 1.4124207154964097e-05 \n",
      "epoch: 20 [854359/888800 96.12%] train loss: 1.4982111679273658e-05 \n",
      "epoch: 20 [855470/888800 96.25%] train loss: 1.4706549336551689e-05 \n",
      "epoch: 20 [856581/888800 96.38%] train loss: 1.3635953109769616e-05 \n",
      "epoch: 20 [857692/888800 96.50%] train loss: 1.3757268789049704e-05 \n",
      "epoch: 20 [858803/888800 96.62%] train loss: 1.4866624951537233e-05 \n",
      "epoch: 20 [859914/888800 96.75%] train loss: 1.358467670797836e-05 \n",
      "epoch: 20 [861025/888800 96.88%] train loss: 1.2593698556884192e-05 \n",
      "epoch: 20 [862136/888800 97.00%] train loss: 1.38128752951161e-05 \n",
      "epoch: 20 [863247/888800 97.12%] train loss: 1.3966401638754178e-05 \n",
      "epoch: 20 [864358/888800 97.25%] train loss: 1.5723026081104763e-05 \n",
      "epoch: 20 [865469/888800 97.38%] train loss: 1.4866917808831204e-05 \n",
      "epoch: 20 [866580/888800 97.50%] train loss: 1.543660619063303e-05 \n",
      "epoch: 20 [867691/888800 97.62%] train loss: 1.5602863641106524e-05 \n",
      "epoch: 20 [868802/888800 97.75%] train loss: 1.3152131032256875e-05 \n",
      "epoch: 20 [869913/888800 97.88%] train loss: 1.4464488231169526e-05 \n",
      "epoch: 20 [871024/888800 98.00%] train loss: 1.3594067240774166e-05 \n",
      "epoch: 20 [872135/888800 98.12%] train loss: 1.3680250049219467e-05 \n",
      "epoch: 20 [873246/888800 98.25%] train loss: 1.4196979464031756e-05 \n",
      "epoch: 20 [874357/888800 98.38%] train loss: 1.348083151242463e-05 \n",
      "epoch: 20 [875468/888800 98.50%] train loss: 1.3081405995762907e-05 \n",
      "epoch: 20 [876579/888800 98.62%] train loss: 1.543035796203185e-05 \n",
      "epoch: 20 [877690/888800 98.75%] train loss: 1.3940375538368244e-05 \n",
      "epoch: 20 [878801/888800 98.88%] train loss: 1.4910610843799077e-05 \n",
      "epoch: 20 [879912/888800 99.00%] train loss: 1.6062755094026215e-05 \n",
      "epoch: 20 [881023/888800 99.12%] train loss: 1.3418009984889068e-05 \n",
      "epoch: 20 [882134/888800 99.25%] train loss: 1.4907991499057971e-05 \n",
      "epoch: 20 [883245/888800 99.38%] train loss: 1.4649538570665754e-05 \n",
      "epoch: 20 [884356/888800 99.50%] train loss: 1.4369354175869375e-05 \n",
      "epoch: 20 [885467/888800 99.62%] train loss: 1.3751029655395541e-05 \n",
      "epoch: 20 [886578/888800 99.75%] train loss: 1.4090381228015758e-05 \n",
      "epoch: 20 [887689/888800 99.88%] train loss: 1.3026805390836671e-05 \n",
      "epoch: 21 [0/888800 0.00%] train loss: 1.4073605598241556e-05 \n",
      "epoch: 21 [1111/888800 0.12%] train loss: 1.5352361515397206e-05 \n",
      "epoch: 21 [2222/888800 0.25%] train loss: 1.4453402400249615e-05 \n",
      "epoch: 21 [3333/888800 0.38%] train loss: 1.3895920346840285e-05 \n",
      "epoch: 21 [4444/888800 0.50%] train loss: 1.4241892131394707e-05 \n",
      "epoch: 21 [5555/888800 0.62%] train loss: 1.2929078366141766e-05 \n",
      "epoch: 21 [6666/888800 0.75%] train loss: 1.4409513823920861e-05 \n",
      "epoch: 21 [7777/888800 0.88%] train loss: 1.354008236376103e-05 \n",
      "epoch: 21 [8888/888800 1.00%] train loss: 1.494808111601742e-05 \n",
      "epoch: 21 [9999/888800 1.12%] train loss: 1.4348360309668351e-05 \n",
      "epoch: 21 [11110/888800 1.25%] train loss: 1.3682461940334179e-05 \n",
      "epoch: 21 [12221/888800 1.38%] train loss: 1.4015924534760416e-05 \n",
      "epoch: 21 [13332/888800 1.50%] train loss: 1.394623177475296e-05 \n",
      "epoch: 21 [14443/888800 1.62%] train loss: 1.537934258522e-05 \n",
      "epoch: 21 [15554/888800 1.75%] train loss: 1.4359331544255838e-05 \n",
      "epoch: 21 [16665/888800 1.88%] train loss: 1.431986856914591e-05 \n",
      "epoch: 21 [17776/888800 2.00%] train loss: 1.4227247447706759e-05 \n",
      "epoch: 21 [18887/888800 2.12%] train loss: 1.427380720997462e-05 \n",
      "epoch: 21 [19998/888800 2.25%] train loss: 1.4359978194988798e-05 \n",
      "epoch: 21 [21109/888800 2.38%] train loss: 1.3004565516894218e-05 \n",
      "epoch: 21 [22220/888800 2.50%] train loss: 1.4723352251166943e-05 \n",
      "epoch: 21 [23331/888800 2.62%] train loss: 1.4125308553047944e-05 \n",
      "epoch: 21 [24442/888800 2.75%] train loss: 1.4043981536815409e-05 \n",
      "epoch: 21 [25553/888800 2.88%] train loss: 1.2975014215044212e-05 \n",
      "epoch: 21 [26664/888800 3.00%] train loss: 1.4062283298699185e-05 \n",
      "epoch: 21 [27775/888800 3.12%] train loss: 1.4209736036718823e-05 \n",
      "epoch: 21 [28886/888800 3.25%] train loss: 1.3918746844865382e-05 \n",
      "epoch: 21 [29997/888800 3.38%] train loss: 1.391475962009281e-05 \n",
      "epoch: 21 [31108/888800 3.50%] train loss: 1.3502606634574477e-05 \n",
      "epoch: 21 [32219/888800 3.62%] train loss: 1.4901969734637532e-05 \n",
      "epoch: 21 [33330/888800 3.75%] train loss: 1.4522865058097523e-05 \n",
      "epoch: 21 [34441/888800 3.88%] train loss: 1.4454833944910206e-05 \n",
      "epoch: 21 [35552/888800 4.00%] train loss: 1.4689343515783548e-05 \n",
      "epoch: 21 [36663/888800 4.12%] train loss: 1.367757886328036e-05 \n",
      "epoch: 21 [37774/888800 4.25%] train loss: 1.4207454114512075e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [38885/888800 4.38%] train loss: 1.461325791751733e-05 \n",
      "epoch: 21 [39996/888800 4.50%] train loss: 1.3257389582577161e-05 \n",
      "epoch: 21 [41107/888800 4.62%] train loss: 1.367564527754439e-05 \n",
      "epoch: 21 [42218/888800 4.75%] train loss: 1.490221984568052e-05 \n",
      "epoch: 21 [43329/888800 4.88%] train loss: 1.413998870702926e-05 \n",
      "epoch: 21 [44440/888800 5.00%] train loss: 1.5400413758470677e-05 \n",
      "epoch: 21 [45551/888800 5.12%] train loss: 1.3453499377646949e-05 \n",
      "epoch: 21 [46662/888800 5.25%] train loss: 1.4387466762855183e-05 \n",
      "epoch: 21 [47773/888800 5.38%] train loss: 1.4170997928886209e-05 \n",
      "epoch: 21 [48884/888800 5.50%] train loss: 1.5109047126316e-05 \n",
      "epoch: 21 [49995/888800 5.62%] train loss: 1.447189333703136e-05 \n",
      "epoch: 21 [51106/888800 5.75%] train loss: 1.4604343959945254e-05 \n",
      "epoch: 21 [52217/888800 5.88%] train loss: 1.4615388863603584e-05 \n",
      "epoch: 21 [53328/888800 6.00%] train loss: 1.4549357729265466e-05 \n",
      "epoch: 21 [54439/888800 6.12%] train loss: 1.3668088286067359e-05 \n",
      "epoch: 21 [55550/888800 6.25%] train loss: 1.5075032933964394e-05 \n",
      "epoch: 21 [56661/888800 6.38%] train loss: 1.3764750292466488e-05 \n",
      "epoch: 21 [57772/888800 6.50%] train loss: 1.4196749361872207e-05 \n",
      "epoch: 21 [58883/888800 6.62%] train loss: 1.3491069694282487e-05 \n",
      "epoch: 21 [59994/888800 6.75%] train loss: 1.4481218386208639e-05 \n",
      "epoch: 21 [61105/888800 6.88%] train loss: 1.4796826690144371e-05 \n",
      "epoch: 21 [62216/888800 7.00%] train loss: 1.381279798806645e-05 \n",
      "epoch: 21 [63327/888800 7.12%] train loss: 1.581879041623324e-05 \n",
      "epoch: 21 [64438/888800 7.25%] train loss: 1.3538862731365953e-05 \n",
      "epoch: 21 [65549/888800 7.38%] train loss: 1.421112483512843e-05 \n",
      "epoch: 21 [66660/888800 7.50%] train loss: 1.4968760297051631e-05 \n",
      "epoch: 21 [67771/888800 7.62%] train loss: 1.5116118447622284e-05 \n",
      "epoch: 21 [68882/888800 7.75%] train loss: 1.3784447219222784e-05 \n",
      "epoch: 21 [69993/888800 7.88%] train loss: 1.3697705071535893e-05 \n",
      "epoch: 21 [71104/888800 8.00%] train loss: 1.4579140042769723e-05 \n",
      "epoch: 21 [72215/888800 8.12%] train loss: 1.603084456291981e-05 \n",
      "epoch: 21 [73326/888800 8.25%] train loss: 1.598013477632776e-05 \n",
      "epoch: 21 [74437/888800 8.38%] train loss: 1.4205167644831818e-05 \n",
      "epoch: 21 [75548/888800 8.50%] train loss: 1.5967727449606173e-05 \n",
      "epoch: 21 [76659/888800 8.62%] train loss: 1.4631435078626964e-05 \n",
      "epoch: 21 [77770/888800 8.75%] train loss: 1.5201186215563212e-05 \n",
      "epoch: 21 [78881/888800 8.88%] train loss: 1.3113452951074578e-05 \n",
      "epoch: 21 [79992/888800 9.00%] train loss: 1.2849170161643997e-05 \n",
      "epoch: 21 [81103/888800 9.12%] train loss: 1.4321474736789241e-05 \n",
      "epoch: 21 [82214/888800 9.25%] train loss: 1.427561255695764e-05 \n",
      "epoch: 21 [83325/888800 9.38%] train loss: 1.4301178453024477e-05 \n",
      "epoch: 21 [84436/888800 9.50%] train loss: 1.5208513104880694e-05 \n",
      "epoch: 21 [85547/888800 9.62%] train loss: 1.4888915757182986e-05 \n",
      "epoch: 21 [86658/888800 9.75%] train loss: 1.3360097000258975e-05 \n",
      "epoch: 21 [87769/888800 9.88%] train loss: 1.3884248801332433e-05 \n",
      "epoch: 21 [88880/888800 10.00%] train loss: 1.5952964531606995e-05 \n",
      "epoch: 21 [89991/888800 10.12%] train loss: 1.2921591405756772e-05 \n",
      "epoch: 21 [91102/888800 10.25%] train loss: 1.551370405650232e-05 \n",
      "epoch: 21 [92213/888800 10.38%] train loss: 1.5129819075809792e-05 \n",
      "epoch: 21 [93324/888800 10.50%] train loss: 1.4437900972552598e-05 \n",
      "epoch: 21 [94435/888800 10.62%] train loss: 1.4906271644576918e-05 \n",
      "epoch: 21 [95546/888800 10.75%] train loss: 1.467219499318162e-05 \n",
      "epoch: 21 [96657/888800 10.88%] train loss: 1.5010446077212691e-05 \n",
      "epoch: 21 [97768/888800 11.00%] train loss: 1.3757186025031842e-05 \n",
      "epoch: 21 [98879/888800 11.12%] train loss: 1.6062482245615683e-05 \n",
      "epoch: 21 [99990/888800 11.25%] train loss: 1.401653753418941e-05 \n",
      "epoch: 21 [101101/888800 11.38%] train loss: 1.4161235412757378e-05 \n",
      "epoch: 21 [102212/888800 11.50%] train loss: 1.2436918950697873e-05 \n",
      "epoch: 21 [103323/888800 11.62%] train loss: 1.5264489775290713e-05 \n",
      "epoch: 21 [104434/888800 11.75%] train loss: 1.4154440577840433e-05 \n",
      "epoch: 21 [105545/888800 11.88%] train loss: 1.5182195056695491e-05 \n",
      "epoch: 21 [106656/888800 12.00%] train loss: 1.4817753253737465e-05 \n",
      "epoch: 21 [107767/888800 12.12%] train loss: 1.3728835256188177e-05 \n",
      "epoch: 21 [108878/888800 12.25%] train loss: 1.431602595403092e-05 \n",
      "epoch: 21 [109989/888800 12.38%] train loss: 1.4273781744122971e-05 \n",
      "epoch: 21 [111100/888800 12.50%] train loss: 1.4143254702503327e-05 \n",
      "epoch: 21 [112211/888800 12.62%] train loss: 1.4027380530023947e-05 \n",
      "epoch: 21 [113322/888800 12.75%] train loss: 1.4552647371601779e-05 \n",
      "epoch: 21 [114433/888800 12.88%] train loss: 1.2549202438094653e-05 \n",
      "epoch: 21 [115544/888800 13.00%] train loss: 1.4667730283690616e-05 \n",
      "epoch: 21 [116655/888800 13.12%] train loss: 1.5153345884755254e-05 \n",
      "epoch: 21 [117766/888800 13.25%] train loss: 1.5396699382108636e-05 \n",
      "epoch: 21 [118877/888800 13.38%] train loss: 1.3788691830995958e-05 \n",
      "epoch: 21 [119988/888800 13.50%] train loss: 1.372696988255484e-05 \n",
      "epoch: 21 [121099/888800 13.62%] train loss: 1.380327194056008e-05 \n",
      "epoch: 21 [122210/888800 13.75%] train loss: 1.4926323274266906e-05 \n",
      "epoch: 21 [123321/888800 13.88%] train loss: 1.3945218597655185e-05 \n",
      "epoch: 21 [124432/888800 14.00%] train loss: 1.4306539924291428e-05 \n",
      "epoch: 21 [125543/888800 14.12%] train loss: 1.513825191068463e-05 \n",
      "epoch: 21 [126654/888800 14.25%] train loss: 1.4469990674115252e-05 \n",
      "epoch: 21 [127765/888800 14.38%] train loss: 1.4886860299156979e-05 \n",
      "epoch: 21 [128876/888800 14.50%] train loss: 1.3812819815939292e-05 \n",
      "epoch: 21 [129987/888800 14.62%] train loss: 1.5495381376240402e-05 \n",
      "epoch: 21 [131098/888800 14.75%] train loss: 1.429037183697801e-05 \n",
      "epoch: 21 [132209/888800 14.88%] train loss: 1.4551507774740458e-05 \n",
      "epoch: 21 [133320/888800 15.00%] train loss: 1.3637900337926112e-05 \n",
      "epoch: 21 [134431/888800 15.12%] train loss: 1.5015338249213528e-05 \n",
      "epoch: 21 [135542/888800 15.25%] train loss: 1.4592195839213673e-05 \n",
      "epoch: 21 [136653/888800 15.38%] train loss: 1.4003685464558657e-05 \n",
      "epoch: 21 [137764/888800 15.50%] train loss: 1.4030346392246429e-05 \n",
      "epoch: 21 [138875/888800 15.62%] train loss: 1.3707004654861521e-05 \n",
      "epoch: 21 [139986/888800 15.75%] train loss: 1.4309284779301379e-05 \n",
      "epoch: 21 [141097/888800 15.88%] train loss: 1.3809250958729535e-05 \n",
      "epoch: 21 [142208/888800 16.00%] train loss: 1.408795560564613e-05 \n",
      "epoch: 21 [143319/888800 16.12%] train loss: 1.3244430192571599e-05 \n",
      "epoch: 21 [144430/888800 16.25%] train loss: 1.4678567822556943e-05 \n",
      "epoch: 21 [145541/888800 16.38%] train loss: 1.3343430509848986e-05 \n",
      "epoch: 21 [146652/888800 16.50%] train loss: 1.417225576005876e-05 \n",
      "epoch: 21 [147763/888800 16.62%] train loss: 1.495293963671429e-05 \n",
      "epoch: 21 [148874/888800 16.75%] train loss: 1.3284216947795358e-05 \n",
      "epoch: 21 [149985/888800 16.88%] train loss: 1.358918052574154e-05 \n",
      "epoch: 21 [151096/888800 17.00%] train loss: 1.3091218534100335e-05 \n",
      "epoch: 21 [152207/888800 17.12%] train loss: 1.4528945939673577e-05 \n",
      "epoch: 21 [153318/888800 17.25%] train loss: 1.4528384781442583e-05 \n",
      "epoch: 21 [154429/888800 17.38%] train loss: 1.4221378478396218e-05 \n",
      "epoch: 21 [155540/888800 17.50%] train loss: 1.2945432899869047e-05 \n",
      "epoch: 21 [156651/888800 17.62%] train loss: 1.5048095519887283e-05 \n",
      "epoch: 21 [157762/888800 17.75%] train loss: 1.4941429071768653e-05 \n",
      "epoch: 21 [158873/888800 17.88%] train loss: 1.3925760868005455e-05 \n",
      "epoch: 21 [159984/888800 18.00%] train loss: 1.3320374819159042e-05 \n",
      "epoch: 21 [161095/888800 18.12%] train loss: 1.355372296529822e-05 \n",
      "epoch: 21 [162206/888800 18.25%] train loss: 1.4061016372579616e-05 \n",
      "epoch: 21 [163317/888800 18.38%] train loss: 1.3123518328939099e-05 \n",
      "epoch: 21 [164428/888800 18.50%] train loss: 1.4993938748375513e-05 \n",
      "epoch: 21 [165539/888800 18.62%] train loss: 1.4593524610972963e-05 \n",
      "epoch: 21 [166650/888800 18.75%] train loss: 1.2947375580552034e-05 \n",
      "epoch: 21 [167761/888800 18.88%] train loss: 1.3377651157497894e-05 \n",
      "epoch: 21 [168872/888800 19.00%] train loss: 1.344251631962834e-05 \n",
      "epoch: 21 [169983/888800 19.12%] train loss: 1.4550063497154042e-05 \n",
      "epoch: 21 [171094/888800 19.25%] train loss: 1.5156481822486967e-05 \n",
      "epoch: 21 [172205/888800 19.38%] train loss: 1.3624070561490953e-05 \n",
      "epoch: 21 [173316/888800 19.50%] train loss: 1.343118947261246e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [174427/888800 19.62%] train loss: 1.4201919839251786e-05 \n",
      "epoch: 21 [175538/888800 19.75%] train loss: 1.3572999705502298e-05 \n",
      "epoch: 21 [176649/888800 19.88%] train loss: 1.35985992528731e-05 \n",
      "epoch: 21 [177760/888800 20.00%] train loss: 1.3014632713748142e-05 \n",
      "epoch: 21 [178871/888800 20.12%] train loss: 1.3670673070009798e-05 \n",
      "epoch: 21 [179982/888800 20.25%] train loss: 1.4022352843312547e-05 \n",
      "epoch: 21 [181093/888800 20.38%] train loss: 1.4998314327385742e-05 \n",
      "epoch: 21 [182204/888800 20.50%] train loss: 1.4458418263529893e-05 \n",
      "epoch: 21 [183315/888800 20.62%] train loss: 1.423016692569945e-05 \n",
      "epoch: 21 [184426/888800 20.75%] train loss: 1.2563099517137744e-05 \n",
      "epoch: 21 [185537/888800 20.88%] train loss: 1.4388987437996548e-05 \n",
      "epoch: 21 [186648/888800 21.00%] train loss: 1.5167690435191616e-05 \n",
      "epoch: 21 [187759/888800 21.12%] train loss: 1.3851048606738914e-05 \n",
      "epoch: 21 [188870/888800 21.25%] train loss: 1.3732652405451518e-05 \n",
      "epoch: 21 [189981/888800 21.38%] train loss: 1.4061070942261722e-05 \n",
      "epoch: 21 [191092/888800 21.50%] train loss: 1.3422528354567476e-05 \n",
      "epoch: 21 [192203/888800 21.62%] train loss: 1.5217653526633512e-05 \n",
      "epoch: 21 [193314/888800 21.75%] train loss: 1.4653319340141024e-05 \n",
      "epoch: 21 [194425/888800 21.88%] train loss: 1.4965391528676264e-05 \n",
      "epoch: 21 [195536/888800 22.00%] train loss: 1.3434033462544903e-05 \n",
      "epoch: 21 [196647/888800 22.12%] train loss: 1.3745823707722593e-05 \n",
      "epoch: 21 [197758/888800 22.25%] train loss: 1.4448396541411057e-05 \n",
      "epoch: 21 [198869/888800 22.38%] train loss: 1.5618144971085712e-05 \n",
      "epoch: 21 [199980/888800 22.50%] train loss: 1.3610519090434536e-05 \n",
      "epoch: 21 [201091/888800 22.62%] train loss: 1.5485837138839997e-05 \n",
      "epoch: 21 [202202/888800 22.75%] train loss: 1.458950100641232e-05 \n",
      "epoch: 21 [203313/888800 22.88%] train loss: 1.3312784176378045e-05 \n",
      "epoch: 21 [204424/888800 23.00%] train loss: 1.3942658370069694e-05 \n",
      "epoch: 21 [205535/888800 23.12%] train loss: 1.4911203834344633e-05 \n",
      "epoch: 21 [206646/888800 23.25%] train loss: 1.4171099792292807e-05 \n",
      "epoch: 21 [207757/888800 23.38%] train loss: 1.6346064512617886e-05 \n",
      "epoch: 21 [208868/888800 23.50%] train loss: 1.2422572581272107e-05 \n",
      "epoch: 21 [209979/888800 23.62%] train loss: 1.5130912288441323e-05 \n",
      "epoch: 21 [211090/888800 23.75%] train loss: 1.3001700608583633e-05 \n",
      "epoch: 21 [212201/888800 23.88%] train loss: 1.6343976312782615e-05 \n",
      "epoch: 21 [213312/888800 24.00%] train loss: 1.3796249731967691e-05 \n",
      "epoch: 21 [214423/888800 24.12%] train loss: 1.4201977137417998e-05 \n",
      "epoch: 21 [215534/888800 24.25%] train loss: 1.2962624168721959e-05 \n",
      "epoch: 21 [216645/888800 24.38%] train loss: 1.378244451188948e-05 \n",
      "epoch: 21 [217756/888800 24.50%] train loss: 1.425274331268156e-05 \n",
      "epoch: 21 [218867/888800 24.62%] train loss: 1.4370996723300777e-05 \n",
      "epoch: 21 [219978/888800 24.75%] train loss: 1.349999729427509e-05 \n",
      "epoch: 21 [221089/888800 24.88%] train loss: 1.4319725778477732e-05 \n",
      "epoch: 21 [222200/888800 25.00%] train loss: 1.4906868273101281e-05 \n",
      "epoch: 21 [223311/888800 25.12%] train loss: 1.5458053894690238e-05 \n",
      "epoch: 21 [224422/888800 25.25%] train loss: 1.3314687748788856e-05 \n",
      "epoch: 21 [225533/888800 25.38%] train loss: 1.4998342521721497e-05 \n",
      "epoch: 21 [226644/888800 25.50%] train loss: 1.3192621736379806e-05 \n",
      "epoch: 21 [227755/888800 25.62%] train loss: 1.4433614524023142e-05 \n",
      "epoch: 21 [228866/888800 25.75%] train loss: 1.5175867702055257e-05 \n",
      "epoch: 21 [229977/888800 25.88%] train loss: 1.4165233551466372e-05 \n",
      "epoch: 21 [231088/888800 26.00%] train loss: 1.3776298146694899e-05 \n",
      "epoch: 21 [232199/888800 26.12%] train loss: 1.3617845979752019e-05 \n",
      "epoch: 21 [233310/888800 26.25%] train loss: 1.3869921531295404e-05 \n",
      "epoch: 21 [234421/888800 26.38%] train loss: 1.4207395906851161e-05 \n",
      "epoch: 21 [235532/888800 26.50%] train loss: 1.2950990821991581e-05 \n",
      "epoch: 21 [236643/888800 26.62%] train loss: 1.3590677554020658e-05 \n",
      "epoch: 21 [237754/888800 26.75%] train loss: 1.4777482647332363e-05 \n",
      "epoch: 21 [238865/888800 26.88%] train loss: 1.3643939382745884e-05 \n",
      "epoch: 21 [239976/888800 27.00%] train loss: 1.5017561054264661e-05 \n",
      "epoch: 21 [241087/888800 27.12%] train loss: 1.3082254554319661e-05 \n",
      "epoch: 21 [242198/888800 27.25%] train loss: 1.4304330761660822e-05 \n",
      "epoch: 21 [243309/888800 27.38%] train loss: 1.4216209820006043e-05 \n",
      "epoch: 21 [244420/888800 27.50%] train loss: 1.5078197066031862e-05 \n",
      "epoch: 21 [245531/888800 27.62%] train loss: 1.3866259905626066e-05 \n",
      "epoch: 21 [246642/888800 27.75%] train loss: 1.4128490875009447e-05 \n",
      "epoch: 21 [247753/888800 27.88%] train loss: 1.4154154087009374e-05 \n",
      "epoch: 21 [248864/888800 28.00%] train loss: 1.3928681255492847e-05 \n",
      "epoch: 21 [249975/888800 28.12%] train loss: 1.4893821571604349e-05 \n",
      "epoch: 21 [251086/888800 28.25%] train loss: 1.4620221918448806e-05 \n",
      "epoch: 21 [252197/888800 28.38%] train loss: 1.4833864952379372e-05 \n",
      "epoch: 21 [253308/888800 28.50%] train loss: 1.466902995161945e-05 \n",
      "epoch: 21 [254419/888800 28.62%] train loss: 1.5581923435092904e-05 \n",
      "epoch: 21 [255530/888800 28.75%] train loss: 1.4928102245903574e-05 \n",
      "epoch: 21 [256641/888800 28.88%] train loss: 1.3110764484736137e-05 \n",
      "epoch: 21 [257752/888800 29.00%] train loss: 1.3661663615494035e-05 \n",
      "epoch: 21 [258863/888800 29.12%] train loss: 1.40214569910313e-05 \n",
      "epoch: 21 [259974/888800 29.25%] train loss: 1.309018443862442e-05 \n",
      "epoch: 21 [261085/888800 29.38%] train loss: 1.4268745871959254e-05 \n",
      "epoch: 21 [262196/888800 29.50%] train loss: 1.3661362572747748e-05 \n",
      "epoch: 21 [263307/888800 29.62%] train loss: 1.546112252981402e-05 \n",
      "epoch: 21 [264418/888800 29.75%] train loss: 1.3885322005080525e-05 \n",
      "epoch: 21 [265529/888800 29.88%] train loss: 1.4436600395129062e-05 \n",
      "epoch: 21 [266640/888800 30.00%] train loss: 1.4942743291612715e-05 \n",
      "epoch: 21 [267751/888800 30.12%] train loss: 1.5230078133754432e-05 \n",
      "epoch: 21 [268862/888800 30.25%] train loss: 1.4794224625802599e-05 \n",
      "epoch: 21 [269973/888800 30.38%] train loss: 1.4531790839100722e-05 \n",
      "epoch: 21 [271084/888800 30.50%] train loss: 1.4347669093695004e-05 \n",
      "epoch: 21 [272195/888800 30.62%] train loss: 1.5897259800112806e-05 \n",
      "epoch: 21 [273306/888800 30.75%] train loss: 1.4668195035483222e-05 \n",
      "epoch: 21 [274417/888800 30.88%] train loss: 1.3919461707700975e-05 \n",
      "epoch: 21 [275528/888800 31.00%] train loss: 1.529213841422461e-05 \n",
      "epoch: 21 [276639/888800 31.12%] train loss: 1.4249567357182968e-05 \n",
      "epoch: 21 [277750/888800 31.25%] train loss: 1.4435151570069138e-05 \n",
      "epoch: 21 [278861/888800 31.38%] train loss: 1.4058891792956274e-05 \n",
      "epoch: 21 [279972/888800 31.50%] train loss: 1.3967147424409632e-05 \n",
      "epoch: 21 [281083/888800 31.62%] train loss: 1.422642162651755e-05 \n",
      "epoch: 21 [282194/888800 31.75%] train loss: 1.4204310900822747e-05 \n",
      "epoch: 21 [283305/888800 31.88%] train loss: 1.392808280797908e-05 \n",
      "epoch: 21 [284416/888800 32.00%] train loss: 1.5002548934717197e-05 \n",
      "epoch: 21 [285527/888800 32.12%] train loss: 1.33624180307379e-05 \n",
      "epoch: 21 [286638/888800 32.25%] train loss: 1.5024961612652987e-05 \n",
      "epoch: 21 [287749/888800 32.38%] train loss: 1.3854901226295624e-05 \n",
      "epoch: 21 [288860/888800 32.50%] train loss: 1.3851371477358043e-05 \n",
      "epoch: 21 [289971/888800 32.62%] train loss: 1.5698604329372756e-05 \n",
      "epoch: 21 [291082/888800 32.75%] train loss: 1.4691111573483795e-05 \n",
      "epoch: 21 [292193/888800 32.88%] train loss: 1.4549498700944241e-05 \n",
      "epoch: 21 [293304/888800 33.00%] train loss: 1.5717616406618617e-05 \n",
      "epoch: 21 [294415/888800 33.12%] train loss: 1.3672880413651e-05 \n",
      "epoch: 21 [295526/888800 33.25%] train loss: 1.4960360203986056e-05 \n",
      "epoch: 21 [296637/888800 33.38%] train loss: 1.3362562640395481e-05 \n",
      "epoch: 21 [297748/888800 33.50%] train loss: 1.4452178220381029e-05 \n",
      "epoch: 21 [298859/888800 33.62%] train loss: 1.409094147675205e-05 \n",
      "epoch: 21 [299970/888800 33.75%] train loss: 1.3597416000266094e-05 \n",
      "epoch: 21 [301081/888800 33.88%] train loss: 1.3948031664767768e-05 \n",
      "epoch: 21 [302192/888800 34.00%] train loss: 1.4456668395723682e-05 \n",
      "epoch: 21 [303303/888800 34.12%] train loss: 1.5257035556714982e-05 \n",
      "epoch: 21 [304414/888800 34.25%] train loss: 1.4590836144634522e-05 \n",
      "epoch: 21 [305525/888800 34.38%] train loss: 1.566516402817797e-05 \n",
      "epoch: 21 [306636/888800 34.50%] train loss: 1.4383967936737463e-05 \n",
      "epoch: 21 [307747/888800 34.62%] train loss: 1.5761721442686394e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [308858/888800 34.75%] train loss: 1.509944377175998e-05 \n",
      "epoch: 21 [309969/888800 34.88%] train loss: 1.485443954152288e-05 \n",
      "epoch: 21 [311080/888800 35.00%] train loss: 1.4416347767109983e-05 \n",
      "epoch: 21 [312191/888800 35.12%] train loss: 1.4300621842266992e-05 \n",
      "epoch: 21 [313302/888800 35.25%] train loss: 1.407863510394236e-05 \n",
      "epoch: 21 [314413/888800 35.38%] train loss: 1.338276888418477e-05 \n",
      "epoch: 21 [315524/888800 35.50%] train loss: 1.4657362953585107e-05 \n",
      "epoch: 21 [316635/888800 35.62%] train loss: 1.4605300748371519e-05 \n",
      "epoch: 21 [317746/888800 35.75%] train loss: 1.388523196510505e-05 \n",
      "epoch: 21 [318857/888800 35.88%] train loss: 1.381051060889149e-05 \n",
      "epoch: 21 [319968/888800 36.00%] train loss: 1.6061421774793416e-05 \n",
      "epoch: 21 [321079/888800 36.12%] train loss: 1.544153201393783e-05 \n",
      "epoch: 21 [322190/888800 36.25%] train loss: 1.5662631994928233e-05 \n",
      "epoch: 21 [323301/888800 36.38%] train loss: 1.467874608351849e-05 \n",
      "epoch: 21 [324412/888800 36.50%] train loss: 1.4556979294866323e-05 \n",
      "epoch: 21 [325523/888800 36.62%] train loss: 1.3704421689908486e-05 \n",
      "epoch: 21 [326634/888800 36.75%] train loss: 1.4399584870261606e-05 \n",
      "epoch: 21 [327745/888800 36.88%] train loss: 1.3479258996085264e-05 \n",
      "epoch: 21 [328856/888800 37.00%] train loss: 1.5060634723340627e-05 \n",
      "epoch: 21 [329967/888800 37.12%] train loss: 1.4184519386617467e-05 \n",
      "epoch: 21 [331078/888800 37.25%] train loss: 1.4745996850251686e-05 \n",
      "epoch: 21 [332189/888800 37.38%] train loss: 1.3923881851951592e-05 \n",
      "epoch: 21 [333300/888800 37.50%] train loss: 1.2967107068106998e-05 \n",
      "epoch: 21 [334411/888800 37.62%] train loss: 1.4491074580291752e-05 \n",
      "epoch: 21 [335522/888800 37.75%] train loss: 1.4544006262440234e-05 \n",
      "epoch: 21 [336633/888800 37.88%] train loss: 1.4044422641745768e-05 \n",
      "epoch: 21 [337744/888800 38.00%] train loss: 1.5468198398593813e-05 \n",
      "epoch: 21 [338855/888800 38.12%] train loss: 1.3268028851598501e-05 \n",
      "epoch: 21 [339966/888800 38.25%] train loss: 1.5052792150527239e-05 \n",
      "epoch: 21 [341077/888800 38.38%] train loss: 1.5475852706003934e-05 \n",
      "epoch: 21 [342188/888800 38.50%] train loss: 1.3332684829947539e-05 \n",
      "epoch: 21 [343299/888800 38.62%] train loss: 1.3167796169000212e-05 \n",
      "epoch: 21 [344410/888800 38.75%] train loss: 1.4015811757417396e-05 \n",
      "epoch: 21 [345521/888800 38.88%] train loss: 1.3781678717350587e-05 \n",
      "epoch: 21 [346632/888800 39.00%] train loss: 1.4200770237948745e-05 \n",
      "epoch: 21 [347743/888800 39.12%] train loss: 1.3741758266405668e-05 \n",
      "epoch: 21 [348854/888800 39.25%] train loss: 1.3595805285149254e-05 \n",
      "epoch: 21 [349965/888800 39.38%] train loss: 1.4852967069600709e-05 \n",
      "epoch: 21 [351076/888800 39.50%] train loss: 1.4405679394258186e-05 \n",
      "epoch: 21 [352187/888800 39.62%] train loss: 1.4310336155176628e-05 \n",
      "epoch: 21 [353298/888800 39.75%] train loss: 1.4472163456957787e-05 \n",
      "epoch: 21 [354409/888800 39.88%] train loss: 1.381504534947453e-05 \n",
      "epoch: 21 [355520/888800 40.00%] train loss: 1.4030844795343e-05 \n",
      "epoch: 21 [356631/888800 40.12%] train loss: 1.535011688247323e-05 \n",
      "epoch: 21 [357742/888800 40.25%] train loss: 1.5649720808141865e-05 \n",
      "epoch: 21 [358853/888800 40.38%] train loss: 1.4041952454135753e-05 \n",
      "epoch: 21 [359964/888800 40.50%] train loss: 1.437469200027408e-05 \n",
      "epoch: 21 [361075/888800 40.62%] train loss: 1.3807284631184302e-05 \n",
      "epoch: 21 [362186/888800 40.75%] train loss: 1.4783384358452167e-05 \n",
      "epoch: 21 [363297/888800 40.88%] train loss: 1.4672305951535236e-05 \n",
      "epoch: 21 [364408/888800 41.00%] train loss: 1.3539366591430735e-05 \n",
      "epoch: 21 [365519/888800 41.12%] train loss: 1.296642585657537e-05 \n",
      "epoch: 21 [366630/888800 41.25%] train loss: 1.419127238477813e-05 \n",
      "epoch: 21 [367741/888800 41.38%] train loss: 1.454386074328795e-05 \n",
      "epoch: 21 [368852/888800 41.50%] train loss: 1.4201068552210927e-05 \n",
      "epoch: 21 [369963/888800 41.62%] train loss: 1.5490468285861425e-05 \n",
      "epoch: 21 [371074/888800 41.75%] train loss: 1.415800488757668e-05 \n",
      "epoch: 21 [372185/888800 41.88%] train loss: 1.3081914403301198e-05 \n",
      "epoch: 21 [373296/888800 42.00%] train loss: 1.3052520444034599e-05 \n",
      "epoch: 21 [374407/888800 42.12%] train loss: 1.4669765732833184e-05 \n",
      "epoch: 21 [375518/888800 42.25%] train loss: 1.3429169484879822e-05 \n",
      "epoch: 21 [376629/888800 42.38%] train loss: 1.4268205632106401e-05 \n",
      "epoch: 21 [377740/888800 42.50%] train loss: 1.3757546184933744e-05 \n",
      "epoch: 21 [378851/888800 42.62%] train loss: 1.5069498658704106e-05 \n",
      "epoch: 21 [379962/888800 42.75%] train loss: 1.4918286069587339e-05 \n",
      "epoch: 21 [381073/888800 42.88%] train loss: 1.4330535123008303e-05 \n",
      "epoch: 21 [382184/888800 43.00%] train loss: 1.4778146578464657e-05 \n",
      "epoch: 21 [383295/888800 43.12%] train loss: 1.4208711945684627e-05 \n",
      "epoch: 21 [384406/888800 43.25%] train loss: 1.4802613804931752e-05 \n",
      "epoch: 21 [385517/888800 43.38%] train loss: 1.3647631931235082e-05 \n",
      "epoch: 21 [386628/888800 43.50%] train loss: 1.4890056263539009e-05 \n",
      "epoch: 21 [387739/888800 43.62%] train loss: 1.4747914974577725e-05 \n",
      "epoch: 21 [388850/888800 43.75%] train loss: 1.4717802514496725e-05 \n",
      "epoch: 21 [389961/888800 43.88%] train loss: 1.3723018128075637e-05 \n",
      "epoch: 21 [391072/888800 44.00%] train loss: 1.4744538020750042e-05 \n",
      "epoch: 21 [392183/888800 44.12%] train loss: 1.321015770372469e-05 \n",
      "epoch: 21 [393294/888800 44.25%] train loss: 1.344939573755255e-05 \n",
      "epoch: 21 [394405/888800 44.38%] train loss: 1.4116042621026281e-05 \n",
      "epoch: 21 [395516/888800 44.50%] train loss: 1.2992562005820218e-05 \n",
      "epoch: 21 [396627/888800 44.62%] train loss: 1.431516921002185e-05 \n",
      "epoch: 21 [397738/888800 44.75%] train loss: 1.468096706958022e-05 \n",
      "epoch: 21 [398849/888800 44.88%] train loss: 1.6169056834769435e-05 \n",
      "epoch: 21 [399960/888800 45.00%] train loss: 1.5026534128992353e-05 \n",
      "epoch: 21 [401071/888800 45.12%] train loss: 1.4876330169499852e-05 \n",
      "epoch: 21 [402182/888800 45.25%] train loss: 1.5275976693374105e-05 \n",
      "epoch: 21 [403293/888800 45.38%] train loss: 1.397101459588157e-05 \n",
      "epoch: 21 [404404/888800 45.50%] train loss: 1.548003092466388e-05 \n",
      "epoch: 21 [405515/888800 45.62%] train loss: 1.4116654710960574e-05 \n",
      "epoch: 21 [406626/888800 45.75%] train loss: 1.3478741493599955e-05 \n",
      "epoch: 21 [407737/888800 45.88%] train loss: 1.4725444088981021e-05 \n",
      "epoch: 21 [408848/888800 46.00%] train loss: 1.4277237823989708e-05 \n",
      "epoch: 21 [409959/888800 46.12%] train loss: 1.5134301065700129e-05 \n",
      "epoch: 21 [411070/888800 46.25%] train loss: 1.5058290955494158e-05 \n",
      "epoch: 21 [412181/888800 46.38%] train loss: 1.5014517884992529e-05 \n",
      "epoch: 21 [413292/888800 46.50%] train loss: 1.4133987860986963e-05 \n",
      "epoch: 21 [414403/888800 46.62%] train loss: 1.3276510799187236e-05 \n",
      "epoch: 21 [415514/888800 46.75%] train loss: 1.3495386156137101e-05 \n",
      "epoch: 21 [416625/888800 46.88%] train loss: 1.519782017567195e-05 \n",
      "epoch: 21 [417736/888800 47.00%] train loss: 1.4384955647983588e-05 \n",
      "epoch: 21 [418847/888800 47.12%] train loss: 1.4523988284054212e-05 \n",
      "epoch: 21 [419958/888800 47.25%] train loss: 1.4275302419264335e-05 \n",
      "epoch: 21 [421069/888800 47.38%] train loss: 1.4787647160119377e-05 \n",
      "epoch: 21 [422180/888800 47.50%] train loss: 1.4427929272642359e-05 \n",
      "epoch: 21 [423291/888800 47.62%] train loss: 1.4734321666765027e-05 \n",
      "epoch: 21 [424402/888800 47.75%] train loss: 1.4806235412834212e-05 \n",
      "epoch: 21 [425513/888800 47.88%] train loss: 1.4201658814272378e-05 \n",
      "epoch: 21 [426624/888800 48.00%] train loss: 1.442490793124307e-05 \n",
      "epoch: 21 [427735/888800 48.12%] train loss: 1.4449261470872443e-05 \n",
      "epoch: 21 [428846/888800 48.25%] train loss: 1.5873732991167344e-05 \n",
      "epoch: 21 [429957/888800 48.38%] train loss: 1.428070663678227e-05 \n",
      "epoch: 21 [431068/888800 48.50%] train loss: 1.777989018592052e-05 \n",
      "epoch: 21 [432179/888800 48.62%] train loss: 1.4588948033633642e-05 \n",
      "epoch: 21 [433290/888800 48.75%] train loss: 1.5555029676761478e-05 \n",
      "epoch: 21 [434401/888800 48.88%] train loss: 1.3267384929349646e-05 \n",
      "epoch: 21 [435512/888800 49.00%] train loss: 1.5465002434211783e-05 \n",
      "epoch: 21 [436623/888800 49.12%] train loss: 1.4627788914367557e-05 \n",
      "epoch: 21 [437734/888800 49.25%] train loss: 1.550848173792474e-05 \n",
      "epoch: 21 [438845/888800 49.38%] train loss: 1.4563960576197132e-05 \n",
      "epoch: 21 [439956/888800 49.50%] train loss: 1.5088542568264529e-05 \n",
      "epoch: 21 [441067/888800 49.62%] train loss: 1.7103047866839916e-05 \n",
      "epoch: 21 [442178/888800 49.75%] train loss: 1.3497134204953909e-05 \n",
      "epoch: 21 [443289/888800 49.88%] train loss: 1.6819270967971534e-05 \n",
      "epoch: 21 [444400/888800 50.00%] train loss: 1.3798715372104198e-05 \n",
      "epoch: 21 [445511/888800 50.12%] train loss: 1.724089088384062e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [446622/888800 50.25%] train loss: 1.531189809611533e-05 \n",
      "epoch: 21 [447733/888800 50.38%] train loss: 1.4649860531790182e-05 \n",
      "epoch: 21 [448844/888800 50.50%] train loss: 1.5321777027565986e-05 \n",
      "epoch: 21 [449955/888800 50.62%] train loss: 1.5286221241694875e-05 \n",
      "epoch: 21 [451066/888800 50.75%] train loss: 1.4974004443502054e-05 \n",
      "epoch: 21 [452177/888800 50.88%] train loss: 1.3533914170693606e-05 \n",
      "epoch: 21 [453288/888800 51.00%] train loss: 1.4509801985695958e-05 \n",
      "epoch: 21 [454399/888800 51.12%] train loss: 1.2956030332134105e-05 \n",
      "epoch: 21 [455510/888800 51.25%] train loss: 1.4027550605533179e-05 \n",
      "epoch: 21 [456621/888800 51.38%] train loss: 1.388906912325183e-05 \n",
      "epoch: 21 [457732/888800 51.50%] train loss: 1.5195792911981698e-05 \n",
      "epoch: 21 [458843/888800 51.62%] train loss: 1.3928199223300908e-05 \n",
      "epoch: 21 [459954/888800 51.75%] train loss: 1.3890587069909088e-05 \n",
      "epoch: 21 [461065/888800 51.88%] train loss: 1.445244015485514e-05 \n",
      "epoch: 21 [462176/888800 52.00%] train loss: 1.3591759852715768e-05 \n",
      "epoch: 21 [463287/888800 52.12%] train loss: 1.3854123608325608e-05 \n",
      "epoch: 21 [464398/888800 52.25%] train loss: 1.3407006917987019e-05 \n",
      "epoch: 21 [465509/888800 52.38%] train loss: 1.5896073819021694e-05 \n",
      "epoch: 21 [466620/888800 52.50%] train loss: 1.31291108118603e-05 \n",
      "epoch: 21 [467731/888800 52.62%] train loss: 1.4889794329064898e-05 \n",
      "epoch: 21 [468842/888800 52.75%] train loss: 1.5334411727963015e-05 \n",
      "epoch: 21 [469953/888800 52.88%] train loss: 1.5092187823029235e-05 \n",
      "epoch: 21 [471064/888800 53.00%] train loss: 1.5392959539894946e-05 \n",
      "epoch: 21 [472175/888800 53.12%] train loss: 1.4379882486537099e-05 \n",
      "epoch: 21 [473286/888800 53.25%] train loss: 1.3495212442649063e-05 \n",
      "epoch: 21 [474397/888800 53.38%] train loss: 1.4676343198516406e-05 \n",
      "epoch: 21 [475508/888800 53.50%] train loss: 1.38741261253017e-05 \n",
      "epoch: 21 [476619/888800 53.62%] train loss: 1.3175314052205067e-05 \n",
      "epoch: 21 [477730/888800 53.75%] train loss: 1.36999142341665e-05 \n",
      "epoch: 21 [478841/888800 53.88%] train loss: 1.3412377484200988e-05 \n",
      "epoch: 21 [479952/888800 54.00%] train loss: 1.6301968571497127e-05 \n",
      "epoch: 21 [481063/888800 54.12%] train loss: 1.3664755897480063e-05 \n",
      "epoch: 21 [482174/888800 54.25%] train loss: 1.3218586900620721e-05 \n",
      "epoch: 21 [483285/888800 54.38%] train loss: 1.4560030649590772e-05 \n",
      "epoch: 21 [484396/888800 54.50%] train loss: 1.554876689624507e-05 \n",
      "epoch: 21 [485507/888800 54.62%] train loss: 1.3787418538413476e-05 \n",
      "epoch: 21 [486618/888800 54.75%] train loss: 1.4654967344540637e-05 \n",
      "epoch: 21 [487729/888800 54.88%] train loss: 1.3969071005703881e-05 \n",
      "epoch: 21 [488840/888800 55.00%] train loss: 1.576086287968792e-05 \n",
      "epoch: 21 [489951/888800 55.12%] train loss: 1.3982832570036408e-05 \n",
      "epoch: 21 [491062/888800 55.25%] train loss: 1.4079572792979889e-05 \n",
      "epoch: 21 [492173/888800 55.38%] train loss: 1.3739360838371795e-05 \n",
      "epoch: 21 [493284/888800 55.50%] train loss: 1.342926589131821e-05 \n",
      "epoch: 21 [494395/888800 55.62%] train loss: 1.4659810403827578e-05 \n",
      "epoch: 21 [495506/888800 55.75%] train loss: 1.498576511949068e-05 \n",
      "epoch: 21 [496617/888800 55.88%] train loss: 1.4288688362285029e-05 \n",
      "epoch: 21 [497728/888800 56.00%] train loss: 1.4781353456783108e-05 \n",
      "epoch: 21 [498839/888800 56.12%] train loss: 1.4987163922342006e-05 \n",
      "epoch: 21 [499950/888800 56.25%] train loss: 1.5083298421814106e-05 \n",
      "epoch: 21 [501061/888800 56.38%] train loss: 1.459312807128299e-05 \n",
      "epoch: 21 [502172/888800 56.50%] train loss: 1.4458111763815396e-05 \n",
      "epoch: 21 [503283/888800 56.62%] train loss: 1.3572553143603727e-05 \n",
      "epoch: 21 [504394/888800 56.75%] train loss: 1.2909941688121762e-05 \n",
      "epoch: 21 [505505/888800 56.88%] train loss: 1.4365007700689603e-05 \n",
      "epoch: 21 [506616/888800 57.00%] train loss: 1.4591546459996607e-05 \n",
      "epoch: 21 [507727/888800 57.12%] train loss: 1.40610600283253e-05 \n",
      "epoch: 21 [508838/888800 57.25%] train loss: 1.3608621884486638e-05 \n",
      "epoch: 21 [509949/888800 57.38%] train loss: 1.3390284948400222e-05 \n",
      "epoch: 21 [511060/888800 57.50%] train loss: 1.490541035309434e-05 \n",
      "epoch: 21 [512171/888800 57.62%] train loss: 1.3610670976049732e-05 \n",
      "epoch: 21 [513282/888800 57.75%] train loss: 1.4592857951356564e-05 \n",
      "epoch: 21 [514393/888800 57.88%] train loss: 1.5008671653049532e-05 \n",
      "epoch: 21 [515504/888800 58.00%] train loss: 1.4179223398969043e-05 \n",
      "epoch: 21 [516615/888800 58.12%] train loss: 1.4346142052090727e-05 \n",
      "epoch: 21 [517726/888800 58.25%] train loss: 1.417790826963028e-05 \n",
      "epoch: 21 [518837/888800 58.38%] train loss: 1.4067930351302493e-05 \n",
      "epoch: 21 [519948/888800 58.50%] train loss: 1.23663457998191e-05 \n",
      "epoch: 21 [521059/888800 58.62%] train loss: 1.3991353625897318e-05 \n",
      "epoch: 21 [522170/888800 58.75%] train loss: 1.358412737317849e-05 \n",
      "epoch: 21 [523281/888800 58.88%] train loss: 1.5062622878758702e-05 \n",
      "epoch: 21 [524392/888800 59.00%] train loss: 1.4262098375183996e-05 \n",
      "epoch: 21 [525503/888800 59.12%] train loss: 1.4333433682622854e-05 \n",
      "epoch: 21 [526614/888800 59.25%] train loss: 1.4247189938032534e-05 \n",
      "epoch: 21 [527725/888800 59.38%] train loss: 1.3457825843943283e-05 \n",
      "epoch: 21 [528836/888800 59.50%] train loss: 1.490269187343074e-05 \n",
      "epoch: 21 [529947/888800 59.62%] train loss: 1.526546293462161e-05 \n",
      "epoch: 21 [531058/888800 59.75%] train loss: 1.472987059969455e-05 \n",
      "epoch: 21 [532169/888800 59.88%] train loss: 1.2658947525778785e-05 \n",
      "epoch: 21 [533280/888800 60.00%] train loss: 1.4712717529619113e-05 \n",
      "epoch: 21 [534391/888800 60.12%] train loss: 1.426936978532467e-05 \n",
      "epoch: 21 [535502/888800 60.25%] train loss: 1.4281677067629062e-05 \n",
      "epoch: 21 [536613/888800 60.38%] train loss: 1.3958139788883273e-05 \n",
      "epoch: 21 [537724/888800 60.50%] train loss: 1.3680141819349956e-05 \n",
      "epoch: 21 [538835/888800 60.62%] train loss: 1.3337443306227215e-05 \n",
      "epoch: 21 [539946/888800 60.75%] train loss: 1.435119156667497e-05 \n",
      "epoch: 21 [541057/888800 60.88%] train loss: 1.3864768334315158e-05 \n",
      "epoch: 21 [542168/888800 61.00%] train loss: 1.4311888662632555e-05 \n",
      "epoch: 21 [543279/888800 61.12%] train loss: 1.4970792108215392e-05 \n",
      "epoch: 21 [544390/888800 61.25%] train loss: 1.4173641829984263e-05 \n",
      "epoch: 21 [545501/888800 61.38%] train loss: 1.4508927961287554e-05 \n",
      "epoch: 21 [546612/888800 61.50%] train loss: 1.4008674952492584e-05 \n",
      "epoch: 21 [547723/888800 61.62%] train loss: 1.3962245247967076e-05 \n",
      "epoch: 21 [548834/888800 61.75%] train loss: 1.336433706455864e-05 \n",
      "epoch: 21 [549945/888800 61.88%] train loss: 1.516382963018259e-05 \n",
      "epoch: 21 [551056/888800 62.00%] train loss: 1.4312562598206569e-05 \n",
      "epoch: 21 [552167/888800 62.12%] train loss: 1.4145291061140597e-05 \n",
      "epoch: 21 [553278/888800 62.25%] train loss: 1.4820234355283901e-05 \n",
      "epoch: 21 [554389/888800 62.38%] train loss: 1.4588514204660896e-05 \n",
      "epoch: 21 [555500/888800 62.50%] train loss: 1.4071287296246737e-05 \n",
      "epoch: 21 [556611/888800 62.62%] train loss: 1.3469464647641871e-05 \n",
      "epoch: 21 [557722/888800 62.75%] train loss: 1.4441361599892844e-05 \n",
      "epoch: 21 [558833/888800 62.88%] train loss: 1.3556180419982411e-05 \n",
      "epoch: 21 [559944/888800 63.00%] train loss: 1.375242391077336e-05 \n",
      "epoch: 21 [561055/888800 63.12%] train loss: 1.4749863112228923e-05 \n",
      "epoch: 21 [562166/888800 63.25%] train loss: 1.4820814612903632e-05 \n",
      "epoch: 21 [563277/888800 63.38%] train loss: 1.384310053254012e-05 \n",
      "epoch: 21 [564388/888800 63.50%] train loss: 1.6115192920551635e-05 \n",
      "epoch: 21 [565499/888800 63.62%] train loss: 1.4282080883276649e-05 \n",
      "epoch: 21 [566610/888800 63.75%] train loss: 1.3411015061137732e-05 \n",
      "epoch: 21 [567721/888800 63.88%] train loss: 1.401555255142739e-05 \n",
      "epoch: 21 [568832/888800 64.00%] train loss: 1.3666482118424028e-05 \n",
      "epoch: 21 [569943/888800 64.12%] train loss: 1.3876450793759432e-05 \n",
      "epoch: 21 [571054/888800 64.25%] train loss: 1.3944305464974605e-05 \n",
      "epoch: 21 [572165/888800 64.38%] train loss: 1.4328911674965639e-05 \n",
      "epoch: 21 [573276/888800 64.50%] train loss: 1.5614235962857492e-05 \n",
      "epoch: 21 [574387/888800 64.62%] train loss: 1.4515267139358912e-05 \n",
      "epoch: 21 [575498/888800 64.75%] train loss: 1.4915290194039699e-05 \n",
      "epoch: 21 [576609/888800 64.88%] train loss: 1.3563168977270834e-05 \n",
      "epoch: 21 [577720/888800 65.00%] train loss: 1.546924249851145e-05 \n",
      "epoch: 21 [578831/888800 65.12%] train loss: 1.3172719263820909e-05 \n",
      "epoch: 21 [579942/888800 65.25%] train loss: 1.466662888560677e-05 \n",
      "epoch: 21 [581053/888800 65.38%] train loss: 1.3815755664836615e-05 \n",
      "epoch: 21 [582164/888800 65.50%] train loss: 1.4662598914583214e-05 \n",
      "epoch: 21 [583275/888800 65.62%] train loss: 1.3966387996333651e-05 \n",
      "epoch: 21 [584386/888800 65.75%] train loss: 1.3028880857746117e-05 \n",
      "epoch: 21 [585497/888800 65.88%] train loss: 1.4149608432489913e-05 \n",
      "epoch: 21 [586608/888800 66.00%] train loss: 1.3381051758187823e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [587719/888800 66.12%] train loss: 1.5002029613242485e-05 \n",
      "epoch: 21 [588830/888800 66.25%] train loss: 1.483891173847951e-05 \n",
      "epoch: 21 [589941/888800 66.38%] train loss: 1.5444997188751586e-05 \n",
      "epoch: 21 [591052/888800 66.50%] train loss: 1.5020028513390571e-05 \n",
      "epoch: 21 [592163/888800 66.62%] train loss: 1.4189266948960721e-05 \n",
      "epoch: 21 [593274/888800 66.75%] train loss: 1.3700347153644543e-05 \n",
      "epoch: 21 [594385/888800 66.88%] train loss: 1.3283037333167158e-05 \n",
      "epoch: 21 [595496/888800 67.00%] train loss: 1.495247215643758e-05 \n",
      "epoch: 21 [596607/888800 67.12%] train loss: 1.4197013115335722e-05 \n",
      "epoch: 21 [597718/888800 67.25%] train loss: 1.3467838471115101e-05 \n",
      "epoch: 21 [598829/888800 67.38%] train loss: 1.3668401152244769e-05 \n",
      "epoch: 21 [599940/888800 67.50%] train loss: 1.45637895911932e-05 \n",
      "epoch: 21 [601051/888800 67.62%] train loss: 1.4434471268032212e-05 \n",
      "epoch: 21 [602162/888800 67.75%] train loss: 1.5700137737439945e-05 \n",
      "epoch: 21 [603273/888800 67.88%] train loss: 1.5096728020580485e-05 \n",
      "epoch: 21 [604384/888800 68.00%] train loss: 1.3252897588245105e-05 \n",
      "epoch: 21 [605495/888800 68.12%] train loss: 1.400294786435552e-05 \n",
      "epoch: 21 [606606/888800 68.25%] train loss: 1.4113681572780479e-05 \n",
      "epoch: 21 [607717/888800 68.38%] train loss: 1.3532590855902527e-05 \n",
      "epoch: 21 [608828/888800 68.50%] train loss: 1.4555353118339553e-05 \n",
      "epoch: 21 [609939/888800 68.62%] train loss: 1.424207857780857e-05 \n",
      "epoch: 21 [611050/888800 68.75%] train loss: 1.5285671906895004e-05 \n",
      "epoch: 21 [612161/888800 68.88%] train loss: 1.422764307790203e-05 \n",
      "epoch: 21 [613272/888800 69.00%] train loss: 1.4158235899230931e-05 \n",
      "epoch: 21 [614383/888800 69.12%] train loss: 1.3761076843366027e-05 \n",
      "epoch: 21 [615494/888800 69.25%] train loss: 1.465788773202803e-05 \n",
      "epoch: 21 [616605/888800 69.38%] train loss: 1.3784821931039914e-05 \n",
      "epoch: 21 [617716/888800 69.50%] train loss: 1.4653351172455586e-05 \n",
      "epoch: 21 [618827/888800 69.62%] train loss: 1.4979724255681504e-05 \n",
      "epoch: 21 [619938/888800 69.75%] train loss: 1.4276791262091137e-05 \n",
      "epoch: 21 [621049/888800 69.88%] train loss: 1.3456216038321145e-05 \n",
      "epoch: 21 [622160/888800 70.00%] train loss: 1.3240138287073933e-05 \n",
      "epoch: 21 [623271/888800 70.12%] train loss: 1.3679247786058113e-05 \n",
      "epoch: 21 [624382/888800 70.25%] train loss: 1.3787277566734701e-05 \n",
      "epoch: 21 [625493/888800 70.38%] train loss: 1.4561873285856564e-05 \n",
      "epoch: 21 [626604/888800 70.50%] train loss: 1.3962879165774211e-05 \n",
      "epoch: 21 [627715/888800 70.62%] train loss: 1.4867915524519049e-05 \n",
      "epoch: 21 [628826/888800 70.75%] train loss: 1.559594238642603e-05 \n",
      "epoch: 21 [629937/888800 70.88%] train loss: 1.576768590894062e-05 \n",
      "epoch: 21 [631048/888800 71.00%] train loss: 1.3577440768131055e-05 \n",
      "epoch: 21 [632159/888800 71.12%] train loss: 1.5026141227281187e-05 \n",
      "epoch: 21 [633270/888800 71.25%] train loss: 1.4212413589120843e-05 \n",
      "epoch: 21 [634381/888800 71.38%] train loss: 1.3306608707353007e-05 \n",
      "epoch: 21 [635492/888800 71.50%] train loss: 1.4449945410888176e-05 \n",
      "epoch: 21 [636603/888800 71.62%] train loss: 1.4365241440827958e-05 \n",
      "epoch: 21 [637714/888800 71.75%] train loss: 1.3288713489600923e-05 \n",
      "epoch: 21 [638825/888800 71.88%] train loss: 1.372196311422158e-05 \n",
      "epoch: 21 [639936/888800 72.00%] train loss: 1.5161952433118131e-05 \n",
      "epoch: 21 [641047/888800 72.12%] train loss: 1.339444952463964e-05 \n",
      "epoch: 21 [642158/888800 72.25%] train loss: 1.3305176253197715e-05 \n",
      "epoch: 21 [643269/888800 72.38%] train loss: 1.3226042938185856e-05 \n",
      "epoch: 21 [644380/888800 72.50%] train loss: 1.350674301647814e-05 \n",
      "epoch: 21 [645491/888800 72.62%] train loss: 1.4211542293196544e-05 \n",
      "epoch: 21 [646602/888800 72.75%] train loss: 1.3911740097682923e-05 \n",
      "epoch: 21 [647713/888800 72.88%] train loss: 1.3432394553092308e-05 \n",
      "epoch: 21 [648824/888800 73.00%] train loss: 1.6139872968778946e-05 \n",
      "epoch: 21 [649935/888800 73.12%] train loss: 1.4142406143946573e-05 \n",
      "epoch: 21 [651046/888800 73.25%] train loss: 1.4315461157821119e-05 \n",
      "epoch: 21 [652157/888800 73.38%] train loss: 1.4311447557702195e-05 \n",
      "epoch: 21 [653268/888800 73.50%] train loss: 1.495470860390924e-05 \n",
      "epoch: 21 [654379/888800 73.62%] train loss: 1.4546239981427789e-05 \n",
      "epoch: 21 [655490/888800 73.75%] train loss: 1.3205806681071408e-05 \n",
      "epoch: 21 [656601/888800 73.88%] train loss: 1.5498328139074147e-05 \n",
      "epoch: 21 [657712/888800 74.00%] train loss: 1.3134965229255613e-05 \n",
      "epoch: 21 [658823/888800 74.12%] train loss: 1.462384079786716e-05 \n",
      "epoch: 21 [659934/888800 74.25%] train loss: 1.5046578482724726e-05 \n",
      "epoch: 21 [661045/888800 74.38%] train loss: 1.3551143638323992e-05 \n",
      "epoch: 21 [662156/888800 74.50%] train loss: 1.51634239955456e-05 \n",
      "epoch: 21 [663267/888800 74.62%] train loss: 1.4151172763376962e-05 \n",
      "epoch: 21 [664378/888800 74.75%] train loss: 1.425375376129523e-05 \n",
      "epoch: 21 [665489/888800 74.88%] train loss: 1.4346495845529716e-05 \n",
      "epoch: 21 [666600/888800 75.00%] train loss: 1.4802460100327153e-05 \n",
      "epoch: 21 [667711/888800 75.12%] train loss: 1.4465989806922153e-05 \n",
      "epoch: 21 [668822/888800 75.25%] train loss: 1.4094037396716885e-05 \n",
      "epoch: 21 [669933/888800 75.38%] train loss: 1.3360921002458781e-05 \n",
      "epoch: 21 [671044/888800 75.50%] train loss: 1.3328364730114117e-05 \n",
      "epoch: 21 [672155/888800 75.62%] train loss: 1.3586444765678607e-05 \n",
      "epoch: 21 [673266/888800 75.75%] train loss: 1.3898331417294685e-05 \n",
      "epoch: 21 [674377/888800 75.88%] train loss: 1.515288204245735e-05 \n",
      "epoch: 21 [675488/888800 76.00%] train loss: 1.5137392438191455e-05 \n",
      "epoch: 21 [676599/888800 76.12%] train loss: 1.4599609130527824e-05 \n",
      "epoch: 21 [677710/888800 76.25%] train loss: 1.4221534001990221e-05 \n",
      "epoch: 21 [678821/888800 76.38%] train loss: 1.5381443517981097e-05 \n",
      "epoch: 21 [679932/888800 76.50%] train loss: 1.4583531083189882e-05 \n",
      "epoch: 21 [681043/888800 76.62%] train loss: 1.425794016540749e-05 \n",
      "epoch: 21 [682154/888800 76.75%] train loss: 1.4661125533166341e-05 \n",
      "epoch: 21 [683265/888800 76.88%] train loss: 1.4200178156897891e-05 \n",
      "epoch: 21 [684376/888800 77.00%] train loss: 1.4263110642787069e-05 \n",
      "epoch: 21 [685487/888800 77.12%] train loss: 1.437065475329291e-05 \n",
      "epoch: 21 [686598/888800 77.25%] train loss: 1.3874466276320163e-05 \n",
      "epoch: 21 [687709/888800 77.38%] train loss: 1.3630493413074873e-05 \n",
      "epoch: 21 [688820/888800 77.50%] train loss: 1.3994311302667484e-05 \n",
      "epoch: 21 [689931/888800 77.62%] train loss: 1.5602989151375368e-05 \n",
      "epoch: 21 [691042/888800 77.75%] train loss: 1.4719876162416767e-05 \n",
      "epoch: 21 [692153/888800 77.88%] train loss: 1.568884363223333e-05 \n",
      "epoch: 21 [693264/888800 78.00%] train loss: 1.4137200196273625e-05 \n",
      "epoch: 21 [694375/888800 78.12%] train loss: 1.3933803529653233e-05 \n",
      "epoch: 21 [695486/888800 78.25%] train loss: 1.5110802451090422e-05 \n",
      "epoch: 21 [696597/888800 78.38%] train loss: 1.3576322999142576e-05 \n",
      "epoch: 21 [697708/888800 78.50%] train loss: 1.5554780475213192e-05 \n",
      "epoch: 21 [698819/888800 78.62%] train loss: 1.3756884072790854e-05 \n",
      "epoch: 21 [699930/888800 78.75%] train loss: 1.4997529433458112e-05 \n",
      "epoch: 21 [701041/888800 78.88%] train loss: 1.401821464241948e-05 \n",
      "epoch: 21 [702152/888800 79.00%] train loss: 1.5076784620760009e-05 \n",
      "epoch: 21 [703263/888800 79.12%] train loss: 1.3984426914248616e-05 \n",
      "epoch: 21 [704374/888800 79.25%] train loss: 1.3684772056876682e-05 \n",
      "epoch: 21 [705485/888800 79.38%] train loss: 1.4569262020813767e-05 \n",
      "epoch: 21 [706596/888800 79.50%] train loss: 1.3779570508631878e-05 \n",
      "epoch: 21 [707707/888800 79.62%] train loss: 1.4190298315952532e-05 \n",
      "epoch: 21 [708818/888800 79.75%] train loss: 1.4958590327296406e-05 \n",
      "epoch: 21 [709929/888800 79.88%] train loss: 1.406870796927251e-05 \n",
      "epoch: 21 [711040/888800 80.00%] train loss: 1.482051629864145e-05 \n",
      "epoch: 21 [712151/888800 80.12%] train loss: 1.354511459794594e-05 \n",
      "epoch: 21 [713262/888800 80.25%] train loss: 1.3560708794102538e-05 \n",
      "epoch: 21 [714373/888800 80.38%] train loss: 1.414323560311459e-05 \n",
      "epoch: 21 [715484/888800 80.50%] train loss: 1.3228592251834925e-05 \n",
      "epoch: 21 [716595/888800 80.62%] train loss: 1.4262909644457977e-05 \n",
      "epoch: 21 [717706/888800 80.75%] train loss: 1.4429541806748603e-05 \n",
      "epoch: 21 [718817/888800 80.88%] train loss: 1.3153277905075811e-05 \n",
      "epoch: 21 [719928/888800 81.00%] train loss: 1.5199530025711283e-05 \n",
      "epoch: 21 [721039/888800 81.12%] train loss: 1.5149436876527034e-05 \n",
      "epoch: 21 [722150/888800 81.25%] train loss: 1.5701465599704534e-05 \n",
      "epoch: 21 [723261/888800 81.38%] train loss: 1.4372666555573232e-05 \n",
      "epoch: 21 [724372/888800 81.50%] train loss: 1.368885477859294e-05 \n",
      "epoch: 21 [725483/888800 81.62%] train loss: 1.4671933968202211e-05 \n",
      "epoch: 21 [726594/888800 81.75%] train loss: 1.6160782251972705e-05 \n",
      "epoch: 21 [727705/888800 81.88%] train loss: 1.491224338678876e-05 \n",
      "epoch: 21 [728816/888800 82.00%] train loss: 1.5313717085518874e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [729927/888800 82.12%] train loss: 1.4109792573435698e-05 \n",
      "epoch: 21 [731038/888800 82.25%] train loss: 1.4214685506885871e-05 \n",
      "epoch: 21 [732149/888800 82.38%] train loss: 1.4523056051984895e-05 \n",
      "epoch: 21 [733260/888800 82.50%] train loss: 1.443640940124169e-05 \n",
      "epoch: 21 [734371/888800 82.62%] train loss: 1.5717208952992223e-05 \n",
      "epoch: 21 [735482/888800 82.75%] train loss: 1.420950866304338e-05 \n",
      "epoch: 21 [736593/888800 82.88%] train loss: 1.449239243811462e-05 \n",
      "epoch: 21 [737704/888800 83.00%] train loss: 1.4354755876411218e-05 \n",
      "epoch: 21 [738815/888800 83.12%] train loss: 1.437533774151234e-05 \n",
      "epoch: 21 [739926/888800 83.25%] train loss: 1.496179356763605e-05 \n",
      "epoch: 21 [741037/888800 83.38%] train loss: 1.3991535524837673e-05 \n",
      "epoch: 21 [742148/888800 83.50%] train loss: 1.4562109754479025e-05 \n",
      "epoch: 21 [743259/888800 83.62%] train loss: 1.440124378859764e-05 \n",
      "epoch: 21 [744370/888800 83.75%] train loss: 1.510568745288765e-05 \n",
      "epoch: 21 [745481/888800 83.88%] train loss: 1.485284974478418e-05 \n",
      "epoch: 21 [746592/888800 84.00%] train loss: 1.2681185580731835e-05 \n",
      "epoch: 21 [747703/888800 84.12%] train loss: 1.4601895600208081e-05 \n",
      "epoch: 21 [748814/888800 84.25%] train loss: 1.3707340258406475e-05 \n",
      "epoch: 21 [749925/888800 84.38%] train loss: 1.4807801562710665e-05 \n",
      "epoch: 21 [751036/888800 84.50%] train loss: 1.4234377886168659e-05 \n",
      "epoch: 21 [752147/888800 84.62%] train loss: 1.4161380931909662e-05 \n",
      "epoch: 21 [753258/888800 84.75%] train loss: 1.3732721527048852e-05 \n",
      "epoch: 21 [754369/888800 84.88%] train loss: 1.4940939763619099e-05 \n",
      "epoch: 21 [755480/888800 85.00%] train loss: 1.5077835996635258e-05 \n",
      "epoch: 21 [756591/888800 85.12%] train loss: 1.4338773326016963e-05 \n",
      "epoch: 21 [757702/888800 85.25%] train loss: 1.3951190339867026e-05 \n",
      "epoch: 21 [758813/888800 85.38%] train loss: 1.4738838217454031e-05 \n",
      "epoch: 21 [759924/888800 85.50%] train loss: 1.4667614777863491e-05 \n",
      "epoch: 21 [761035/888800 85.62%] train loss: 1.4964778529247269e-05 \n",
      "epoch: 21 [762146/888800 85.75%] train loss: 1.4965544323786162e-05 \n",
      "epoch: 21 [763257/888800 85.88%] train loss: 1.456257450627163e-05 \n",
      "epoch: 21 [764368/888800 86.00%] train loss: 1.5259940482792445e-05 \n",
      "epoch: 21 [765479/888800 86.12%] train loss: 1.5220815839711577e-05 \n",
      "epoch: 21 [766590/888800 86.25%] train loss: 1.3462009519571438e-05 \n",
      "epoch: 21 [767701/888800 86.38%] train loss: 1.5527439245488495e-05 \n",
      "epoch: 21 [768812/888800 86.50%] train loss: 1.536758827569429e-05 \n",
      "epoch: 21 [769923/888800 86.62%] train loss: 1.4290780200099107e-05 \n",
      "epoch: 21 [771034/888800 86.75%] train loss: 1.4447128705796786e-05 \n",
      "epoch: 21 [772145/888800 86.88%] train loss: 1.4486303371086251e-05 \n",
      "epoch: 21 [773256/888800 87.00%] train loss: 1.5239983440551441e-05 \n",
      "epoch: 21 [774367/888800 87.12%] train loss: 1.4534520232700743e-05 \n",
      "epoch: 21 [775478/888800 87.25%] train loss: 1.4580414244846907e-05 \n",
      "epoch: 21 [776589/888800 87.38%] train loss: 1.459915529267164e-05 \n",
      "epoch: 21 [777700/888800 87.50%] train loss: 1.4887616998748854e-05 \n",
      "epoch: 21 [778811/888800 87.62%] train loss: 1.4134881894278806e-05 \n",
      "epoch: 21 [779922/888800 87.75%] train loss: 1.3371507520787418e-05 \n",
      "epoch: 21 [781033/888800 87.88%] train loss: 1.410112963640131e-05 \n",
      "epoch: 21 [782144/888800 88.00%] train loss: 1.5113095287233591e-05 \n",
      "epoch: 21 [783255/888800 88.12%] train loss: 1.4431066119868774e-05 \n",
      "epoch: 21 [784366/888800 88.25%] train loss: 1.3935873539594468e-05 \n",
      "epoch: 21 [785477/888800 88.38%] train loss: 1.3547467460739426e-05 \n",
      "epoch: 21 [786588/888800 88.50%] train loss: 1.4202108104655053e-05 \n",
      "epoch: 21 [787699/888800 88.62%] train loss: 1.4684036614198703e-05 \n",
      "epoch: 21 [788810/888800 88.75%] train loss: 1.3036737982474733e-05 \n",
      "epoch: 21 [789921/888800 88.88%] train loss: 1.315148711000802e-05 \n",
      "epoch: 21 [791032/888800 89.00%] train loss: 1.4059534805710427e-05 \n",
      "epoch: 21 [792143/888800 89.12%] train loss: 1.3825408132106531e-05 \n",
      "epoch: 21 [793254/888800 89.25%] train loss: 1.2893569873995148e-05 \n",
      "epoch: 21 [794365/888800 89.38%] train loss: 1.378466549795121e-05 \n",
      "epoch: 21 [795476/888800 89.50%] train loss: 1.3533005585486535e-05 \n",
      "epoch: 21 [796587/888800 89.62%] train loss: 1.3717472938878927e-05 \n",
      "epoch: 21 [797698/888800 89.75%] train loss: 1.4086308510741219e-05 \n",
      "epoch: 21 [798809/888800 89.88%] train loss: 1.3870323527953587e-05 \n",
      "epoch: 21 [799920/888800 90.00%] train loss: 1.3329713510756847e-05 \n",
      "epoch: 21 [801031/888800 90.12%] train loss: 1.4623133210989181e-05 \n",
      "epoch: 21 [802142/888800 90.25%] train loss: 1.4197160453477409e-05 \n",
      "epoch: 21 [803253/888800 90.38%] train loss: 1.2788749700121116e-05 \n",
      "epoch: 21 [804364/888800 90.50%] train loss: 1.4145252862363122e-05 \n",
      "epoch: 21 [805475/888800 90.62%] train loss: 1.345573673461331e-05 \n",
      "epoch: 21 [806586/888800 90.75%] train loss: 1.3688842955161817e-05 \n",
      "epoch: 21 [807697/888800 90.88%] train loss: 1.3609452253149357e-05 \n",
      "epoch: 21 [808808/888800 91.00%] train loss: 1.3669442523678299e-05 \n",
      "epoch: 21 [809919/888800 91.12%] train loss: 1.2749426787195262e-05 \n",
      "epoch: 21 [811030/888800 91.25%] train loss: 1.4517787349177524e-05 \n",
      "epoch: 21 [812141/888800 91.38%] train loss: 1.40943529913784e-05 \n",
      "epoch: 21 [813252/888800 91.50%] train loss: 1.3486100215232e-05 \n",
      "epoch: 21 [814363/888800 91.62%] train loss: 1.3162166396796238e-05 \n",
      "epoch: 21 [815474/888800 91.75%] train loss: 1.4209608707460575e-05 \n",
      "epoch: 21 [816585/888800 91.88%] train loss: 1.3879343896405771e-05 \n",
      "epoch: 21 [817696/888800 92.00%] train loss: 1.3956350812804885e-05 \n",
      "epoch: 21 [818807/888800 92.12%] train loss: 1.3488506738212891e-05 \n",
      "epoch: 21 [819918/888800 92.25%] train loss: 1.4339779227157123e-05 \n",
      "epoch: 21 [821029/888800 92.38%] train loss: 1.4193685274221934e-05 \n",
      "epoch: 21 [822140/888800 92.50%] train loss: 1.4729433132742997e-05 \n",
      "epoch: 21 [823251/888800 92.62%] train loss: 1.4742578969162423e-05 \n",
      "epoch: 21 [824362/888800 92.75%] train loss: 1.3521724213205744e-05 \n",
      "epoch: 21 [825473/888800 92.88%] train loss: 1.4647322132077534e-05 \n",
      "epoch: 21 [826584/888800 93.00%] train loss: 1.4190080037224106e-05 \n",
      "epoch: 21 [827695/888800 93.12%] train loss: 1.3122587006364483e-05 \n",
      "epoch: 21 [828806/888800 93.25%] train loss: 1.4288809325080365e-05 \n",
      "epoch: 21 [829917/888800 93.38%] train loss: 1.506494027125882e-05 \n",
      "epoch: 21 [831028/888800 93.50%] train loss: 1.435749072697945e-05 \n",
      "epoch: 21 [832139/888800 93.62%] train loss: 1.4261494470702019e-05 \n",
      "epoch: 21 [833250/888800 93.75%] train loss: 1.5428586266352795e-05 \n",
      "epoch: 21 [834361/888800 93.88%] train loss: 1.405363673256943e-05 \n",
      "epoch: 21 [835472/888800 94.00%] train loss: 1.40476195156225e-05 \n",
      "epoch: 21 [836583/888800 94.12%] train loss: 1.3380401469476055e-05 \n",
      "epoch: 21 [837694/888800 94.25%] train loss: 1.439562674931949e-05 \n",
      "epoch: 21 [838805/888800 94.38%] train loss: 1.3825860150973313e-05 \n",
      "epoch: 21 [839916/888800 94.50%] train loss: 1.3258708349894732e-05 \n",
      "epoch: 21 [841027/888800 94.62%] train loss: 1.4655091035820078e-05 \n",
      "epoch: 21 [842138/888800 94.75%] train loss: 1.3745459000347182e-05 \n",
      "epoch: 21 [843249/888800 94.88%] train loss: 1.2973629054613411e-05 \n",
      "epoch: 21 [844360/888800 95.00%] train loss: 1.3341562407731544e-05 \n",
      "epoch: 21 [845471/888800 95.12%] train loss: 1.5148743841564283e-05 \n",
      "epoch: 21 [846582/888800 95.25%] train loss: 1.3776154446532018e-05 \n",
      "epoch: 21 [847693/888800 95.38%] train loss: 1.341114239039598e-05 \n",
      "epoch: 21 [848804/888800 95.50%] train loss: 1.4621503396483604e-05 \n",
      "epoch: 21 [849915/888800 95.62%] train loss: 1.4952787751099095e-05 \n",
      "epoch: 21 [851026/888800 95.75%] train loss: 1.4374668353411835e-05 \n",
      "epoch: 21 [852137/888800 95.88%] train loss: 1.4521849152515642e-05 \n",
      "epoch: 21 [853248/888800 96.00%] train loss: 1.4413319149753079e-05 \n",
      "epoch: 21 [854359/888800 96.12%] train loss: 1.546673411212396e-05 \n",
      "epoch: 21 [855470/888800 96.25%] train loss: 1.479272759752348e-05 \n",
      "epoch: 21 [856581/888800 96.38%] train loss: 1.4138380720396526e-05 \n",
      "epoch: 21 [857692/888800 96.50%] train loss: 1.3393208973866422e-05 \n",
      "epoch: 21 [858803/888800 96.62%] train loss: 1.475542285334086e-05 \n",
      "epoch: 21 [859914/888800 96.75%] train loss: 1.3521843357011676e-05 \n",
      "epoch: 21 [861025/888800 96.88%] train loss: 1.5965999409672804e-05 \n",
      "epoch: 21 [862136/888800 97.00%] train loss: 1.4087747331359424e-05 \n",
      "epoch: 21 [863247/888800 97.12%] train loss: 1.3584395674115513e-05 \n",
      "epoch: 21 [864358/888800 97.25%] train loss: 1.4260605894378386e-05 \n",
      "epoch: 21 [865469/888800 97.38%] train loss: 1.5049371540953871e-05 \n",
      "epoch: 21 [866580/888800 97.50%] train loss: 1.5189333680609707e-05 \n",
      "epoch: 21 [867691/888800 97.62%] train loss: 1.4141062820272055e-05 \n",
      "epoch: 21 [868802/888800 97.75%] train loss: 1.4066944459045772e-05 \n",
      "epoch: 21 [869913/888800 97.88%] train loss: 1.4705360626976471e-05 \n",
      "epoch: 21 [871024/888800 98.00%] train loss: 1.5646366591681726e-05 \n",
      "epoch: 21 [872135/888800 98.12%] train loss: 1.5238352716551162e-05 \n",
      "epoch: 21 [873246/888800 98.25%] train loss: 1.3772306374448817e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 [874357/888800 98.38%] train loss: 1.4428323083848227e-05 \n",
      "epoch: 21 [875468/888800 98.50%] train loss: 1.4331823877000716e-05 \n",
      "epoch: 21 [876579/888800 98.62%] train loss: 1.3839349776390009e-05 \n",
      "epoch: 21 [877690/888800 98.75%] train loss: 1.3896381460654084e-05 \n",
      "epoch: 21 [878801/888800 98.88%] train loss: 1.2619330846064258e-05 \n",
      "epoch: 21 [879912/888800 99.00%] train loss: 1.475068802392343e-05 \n",
      "epoch: 21 [881023/888800 99.12%] train loss: 1.4089520846027881e-05 \n",
      "epoch: 21 [882134/888800 99.25%] train loss: 1.3618803677672986e-05 \n",
      "epoch: 21 [883245/888800 99.38%] train loss: 1.5287474525393918e-05 \n",
      "epoch: 21 [884356/888800 99.50%] train loss: 1.5009291928436141e-05 \n",
      "epoch: 21 [885467/888800 99.62%] train loss: 1.4892032595525961e-05 \n",
      "epoch: 21 [886578/888800 99.75%] train loss: 1.5528055882896297e-05 \n",
      "epoch: 21 [887689/888800 99.88%] train loss: 1.38073864945909e-05 \n",
      "epoch: 22 [0/888800 0.00%] train loss: 1.2306152711971663e-05 \n",
      "epoch: 22 [1111/888800 0.12%] train loss: 1.3488645890902262e-05 \n",
      "epoch: 22 [2222/888800 0.25%] train loss: 1.4344585906655993e-05 \n",
      "epoch: 22 [3333/888800 0.38%] train loss: 1.4349408047564793e-05 \n",
      "epoch: 22 [4444/888800 0.50%] train loss: 1.5319756130338646e-05 \n",
      "epoch: 22 [5555/888800 0.62%] train loss: 1.546697603771463e-05 \n",
      "epoch: 22 [6666/888800 0.75%] train loss: 1.4515901057166047e-05 \n",
      "epoch: 22 [7777/888800 0.88%] train loss: 1.3828221199219115e-05 \n",
      "epoch: 22 [8888/888800 1.00%] train loss: 1.4126244423096068e-05 \n",
      "epoch: 22 [9999/888800 1.12%] train loss: 1.4278723028837703e-05 \n",
      "epoch: 22 [11110/888800 1.25%] train loss: 1.4473259398073424e-05 \n",
      "epoch: 22 [12221/888800 1.38%] train loss: 1.4053935046831612e-05 \n",
      "epoch: 22 [13332/888800 1.50%] train loss: 1.411313860444352e-05 \n",
      "epoch: 22 [14443/888800 1.62%] train loss: 1.4839290088275447e-05 \n",
      "epoch: 22 [15554/888800 1.75%] train loss: 1.3806723472953308e-05 \n",
      "epoch: 22 [16665/888800 1.88%] train loss: 1.3674214642378502e-05 \n",
      "epoch: 22 [17776/888800 2.00%] train loss: 1.4159292732074391e-05 \n",
      "epoch: 22 [18887/888800 2.12%] train loss: 1.379646437271731e-05 \n",
      "epoch: 22 [19998/888800 2.25%] train loss: 1.360590886179125e-05 \n",
      "epoch: 22 [21109/888800 2.38%] train loss: 1.4520846889354289e-05 \n",
      "epoch: 22 [22220/888800 2.50%] train loss: 1.4381751498149242e-05 \n",
      "epoch: 22 [23331/888800 2.62%] train loss: 1.369357414660044e-05 \n",
      "epoch: 22 [24442/888800 2.75%] train loss: 1.3777567801298574e-05 \n",
      "epoch: 22 [25553/888800 2.88%] train loss: 1.3523405868909322e-05 \n",
      "epoch: 22 [26664/888800 3.00%] train loss: 1.4968625691835769e-05 \n",
      "epoch: 22 [27775/888800 3.12%] train loss: 1.3835464415024035e-05 \n",
      "epoch: 22 [28886/888800 3.25%] train loss: 1.4412618838832714e-05 \n",
      "epoch: 22 [29997/888800 3.38%] train loss: 1.4433159776672255e-05 \n",
      "epoch: 22 [31108/888800 3.50%] train loss: 1.4587842997570988e-05 \n",
      "epoch: 22 [32219/888800 3.62%] train loss: 1.3466013115248643e-05 \n",
      "epoch: 22 [33330/888800 3.75%] train loss: 1.3616035175800789e-05 \n",
      "epoch: 22 [34441/888800 3.88%] train loss: 1.3521362234314438e-05 \n",
      "epoch: 22 [35552/888800 4.00%] train loss: 1.3973583918414079e-05 \n",
      "epoch: 22 [36663/888800 4.12%] train loss: 1.2954948942933697e-05 \n",
      "epoch: 22 [37774/888800 4.25%] train loss: 1.4257908333092928e-05 \n",
      "epoch: 22 [38885/888800 4.38%] train loss: 1.4280852155934554e-05 \n",
      "epoch: 22 [39996/888800 4.50%] train loss: 1.4372723853739444e-05 \n",
      "epoch: 22 [41107/888800 4.62%] train loss: 1.5431396604981273e-05 \n",
      "epoch: 22 [42218/888800 4.75%] train loss: 1.4614891370001715e-05 \n",
      "epoch: 22 [43329/888800 4.88%] train loss: 1.4527184248436242e-05 \n",
      "epoch: 22 [44440/888800 5.00%] train loss: 1.4094263860897627e-05 \n",
      "epoch: 22 [45551/888800 5.12%] train loss: 1.3431357729132287e-05 \n",
      "epoch: 22 [46662/888800 5.25%] train loss: 1.400108612870099e-05 \n",
      "epoch: 22 [47773/888800 5.38%] train loss: 1.3954497262602672e-05 \n",
      "epoch: 22 [48884/888800 5.50%] train loss: 1.4858894246572163e-05 \n",
      "epoch: 22 [49995/888800 5.62%] train loss: 1.4109616131463554e-05 \n",
      "epoch: 22 [51106/888800 5.75%] train loss: 1.3670990483660717e-05 \n",
      "epoch: 22 [52217/888800 5.88%] train loss: 1.4050355275685433e-05 \n",
      "epoch: 22 [53328/888800 6.00%] train loss: 1.40993288368918e-05 \n",
      "epoch: 22 [54439/888800 6.12%] train loss: 1.3822289474774152e-05 \n",
      "epoch: 22 [55550/888800 6.25%] train loss: 1.5272104064933956e-05 \n",
      "epoch: 22 [56661/888800 6.38%] train loss: 1.3855563338438515e-05 \n",
      "epoch: 22 [57772/888800 6.50%] train loss: 1.549880653328728e-05 \n",
      "epoch: 22 [58883/888800 6.62%] train loss: 1.4179853678797372e-05 \n",
      "epoch: 22 [59994/888800 6.75%] train loss: 1.37540864670882e-05 \n",
      "epoch: 22 [61105/888800 6.88%] train loss: 1.3915735507907812e-05 \n",
      "epoch: 22 [62216/888800 7.00%] train loss: 1.36016769829439e-05 \n",
      "epoch: 22 [63327/888800 7.12%] train loss: 1.274070473300526e-05 \n",
      "epoch: 22 [64438/888800 7.25%] train loss: 1.4744744476047345e-05 \n",
      "epoch: 22 [65549/888800 7.38%] train loss: 1.4466510037891567e-05 \n",
      "epoch: 22 [66660/888800 7.50%] train loss: 1.4710081813973375e-05 \n",
      "epoch: 22 [67771/888800 7.62%] train loss: 1.5627996617695317e-05 \n",
      "epoch: 22 [68882/888800 7.75%] train loss: 1.4688530427520163e-05 \n",
      "epoch: 22 [69993/888800 7.88%] train loss: 1.3586123714048881e-05 \n",
      "epoch: 22 [71104/888800 8.00%] train loss: 1.3498769476427697e-05 \n",
      "epoch: 22 [72215/888800 8.12%] train loss: 1.3681494237971492e-05 \n",
      "epoch: 22 [73326/888800 8.25%] train loss: 1.5418741895700805e-05 \n",
      "epoch: 22 [74437/888800 8.38%] train loss: 1.529037945147138e-05 \n",
      "epoch: 22 [75548/888800 8.50%] train loss: 1.3618654520541895e-05 \n",
      "epoch: 22 [76659/888800 8.62%] train loss: 1.4380174434336368e-05 \n",
      "epoch: 22 [77770/888800 8.75%] train loss: 1.401555255142739e-05 \n",
      "epoch: 22 [78881/888800 8.88%] train loss: 1.5477322449442e-05 \n",
      "epoch: 22 [79992/888800 9.00%] train loss: 1.3537161976273637e-05 \n",
      "epoch: 22 [81103/888800 9.12%] train loss: 1.3997961104905698e-05 \n",
      "epoch: 22 [82214/888800 9.25%] train loss: 1.434726709703682e-05 \n",
      "epoch: 22 [83325/888800 9.38%] train loss: 1.552869434817694e-05 \n",
      "epoch: 22 [84436/888800 9.50%] train loss: 1.5171640370681416e-05 \n",
      "epoch: 22 [85547/888800 9.62%] train loss: 1.4458049918175675e-05 \n",
      "epoch: 22 [86658/888800 9.75%] train loss: 1.4326928976515774e-05 \n",
      "epoch: 22 [87769/888800 9.88%] train loss: 1.4542270946549252e-05 \n",
      "epoch: 22 [88880/888800 10.00%] train loss: 1.4539292351400945e-05 \n",
      "epoch: 22 [89991/888800 10.12%] train loss: 1.3654246686201077e-05 \n",
      "epoch: 22 [91102/888800 10.25%] train loss: 1.597290793142747e-05 \n",
      "epoch: 22 [92213/888800 10.38%] train loss: 1.4982065295043867e-05 \n",
      "epoch: 22 [93324/888800 10.50%] train loss: 1.3856682926416397e-05 \n",
      "epoch: 22 [94435/888800 10.62%] train loss: 1.4084228496358264e-05 \n",
      "epoch: 22 [95546/888800 10.75%] train loss: 1.5602257917635143e-05 \n",
      "epoch: 22 [96657/888800 10.88%] train loss: 1.4856736015644856e-05 \n",
      "epoch: 22 [97768/888800 11.00%] train loss: 1.4298427231551614e-05 \n",
      "epoch: 22 [98879/888800 11.12%] train loss: 1.450354466214776e-05 \n",
      "epoch: 22 [99990/888800 11.25%] train loss: 1.3895960364607163e-05 \n",
      "epoch: 22 [101101/888800 11.38%] train loss: 1.5203875591396354e-05 \n",
      "epoch: 22 [102212/888800 11.50%] train loss: 1.3836362995789386e-05 \n",
      "epoch: 22 [103323/888800 11.62%] train loss: 1.546648309158627e-05 \n",
      "epoch: 22 [104434/888800 11.75%] train loss: 1.4288435522757936e-05 \n",
      "epoch: 22 [105545/888800 11.88%] train loss: 1.3435790606308728e-05 \n",
      "epoch: 22 [106656/888800 12.00%] train loss: 1.3942150872026104e-05 \n",
      "epoch: 22 [107767/888800 12.12%] train loss: 1.4983053915784694e-05 \n",
      "epoch: 22 [108878/888800 12.25%] train loss: 1.3761195077677257e-05 \n",
      "epoch: 22 [109989/888800 12.38%] train loss: 1.2691323718172498e-05 \n",
      "epoch: 22 [111100/888800 12.50%] train loss: 1.4360377463162877e-05 \n",
      "epoch: 22 [112211/888800 12.62%] train loss: 1.4308996469480917e-05 \n",
      "epoch: 22 [113322/888800 12.75%] train loss: 1.508374134573387e-05 \n",
      "epoch: 22 [114433/888800 12.88%] train loss: 1.4691797332488932e-05 \n",
      "epoch: 22 [115544/888800 13.00%] train loss: 1.5287430869648233e-05 \n",
      "epoch: 22 [116655/888800 13.12%] train loss: 1.3829513591190334e-05 \n",
      "epoch: 22 [117766/888800 13.25%] train loss: 1.4777303476876114e-05 \n",
      "epoch: 22 [118877/888800 13.38%] train loss: 1.2490628250816371e-05 \n",
      "epoch: 22 [119988/888800 13.50%] train loss: 1.376274576614378e-05 \n",
      "epoch: 22 [121099/888800 13.62%] train loss: 1.426352628186578e-05 \n",
      "epoch: 22 [122210/888800 13.75%] train loss: 1.4149655726214405e-05 \n",
      "epoch: 22 [123321/888800 13.88%] train loss: 1.2843425793107599e-05 \n",
      "epoch: 22 [124432/888800 14.00%] train loss: 1.4697482583869714e-05 \n",
      "epoch: 22 [125543/888800 14.12%] train loss: 1.2196772331662942e-05 \n",
      "epoch: 22 [126654/888800 14.25%] train loss: 1.3555611076299101e-05 \n",
      "epoch: 22 [127765/888800 14.38%] train loss: 1.390250963595463e-05 \n",
      "epoch: 22 [128876/888800 14.50%] train loss: 1.373568557028193e-05 \n",
      "epoch: 22 [129987/888800 14.62%] train loss: 1.3380285054154228e-05 \n",
      "epoch: 22 [131098/888800 14.75%] train loss: 1.3358719115785789e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [132209/888800 14.88%] train loss: 1.3904108527640346e-05 \n",
      "epoch: 22 [133320/888800 15.00%] train loss: 1.5072984751896001e-05 \n",
      "epoch: 22 [134431/888800 15.12%] train loss: 1.3149023288860917e-05 \n",
      "epoch: 22 [135542/888800 15.25%] train loss: 1.5459370843018405e-05 \n",
      "epoch: 22 [136653/888800 15.38%] train loss: 1.4175048818287905e-05 \n",
      "epoch: 22 [137764/888800 15.50%] train loss: 1.4325431948236655e-05 \n",
      "epoch: 22 [138875/888800 15.62%] train loss: 1.5773306586197577e-05 \n",
      "epoch: 22 [139986/888800 15.75%] train loss: 1.30824801090057e-05 \n",
      "epoch: 22 [141097/888800 15.88%] train loss: 1.4056212421564851e-05 \n",
      "epoch: 22 [142208/888800 16.00%] train loss: 1.4541266864398494e-05 \n",
      "epoch: 22 [143319/888800 16.12%] train loss: 1.5157323105086107e-05 \n",
      "epoch: 22 [144430/888800 16.25%] train loss: 1.3112948181515094e-05 \n",
      "epoch: 22 [145541/888800 16.38%] train loss: 1.4239424672268797e-05 \n",
      "epoch: 22 [146652/888800 16.50%] train loss: 1.4399268366105389e-05 \n",
      "epoch: 22 [147763/888800 16.62%] train loss: 1.3995347217132803e-05 \n",
      "epoch: 22 [148874/888800 16.75%] train loss: 1.546161547594238e-05 \n",
      "epoch: 22 [149985/888800 16.88%] train loss: 1.393735692545306e-05 \n",
      "epoch: 22 [151096/888800 17.00%] train loss: 1.5549589079455473e-05 \n",
      "epoch: 22 [152207/888800 17.12%] train loss: 1.3507417861546855e-05 \n",
      "epoch: 22 [153318/888800 17.25%] train loss: 1.3920478522777557e-05 \n",
      "epoch: 22 [154429/888800 17.38%] train loss: 1.2906921256217174e-05 \n",
      "epoch: 22 [155540/888800 17.50%] train loss: 1.4587278201361187e-05 \n",
      "epoch: 22 [156651/888800 17.62%] train loss: 1.4638179891335312e-05 \n",
      "epoch: 22 [157762/888800 17.75%] train loss: 1.4975065823819023e-05 \n",
      "epoch: 22 [158873/888800 17.88%] train loss: 1.4464735613728408e-05 \n",
      "epoch: 22 [159984/888800 18.00%] train loss: 1.3826832400809508e-05 \n",
      "epoch: 22 [161095/888800 18.12%] train loss: 1.4359711713041179e-05 \n",
      "epoch: 22 [162206/888800 18.25%] train loss: 1.578456794959493e-05 \n",
      "epoch: 22 [163317/888800 18.38%] train loss: 1.3331743502931204e-05 \n",
      "epoch: 22 [164428/888800 18.50%] train loss: 1.5359804820036516e-05 \n",
      "epoch: 22 [165539/888800 18.62%] train loss: 1.3946068975201342e-05 \n",
      "epoch: 22 [166650/888800 18.75%] train loss: 1.6403200788772665e-05 \n",
      "epoch: 22 [167761/888800 18.88%] train loss: 1.386671829095576e-05 \n",
      "epoch: 22 [168872/888800 19.00%] train loss: 1.4904126146575436e-05 \n",
      "epoch: 22 [169983/888800 19.12%] train loss: 1.3869167560187634e-05 \n",
      "epoch: 22 [171094/888800 19.25%] train loss: 1.5111297216208186e-05 \n",
      "epoch: 22 [172205/888800 19.38%] train loss: 1.4533885405398905e-05 \n",
      "epoch: 22 [173316/888800 19.50%] train loss: 1.5086924577190075e-05 \n",
      "epoch: 22 [174427/888800 19.62%] train loss: 1.5366900697699748e-05 \n",
      "epoch: 22 [175538/888800 19.75%] train loss: 1.5946265193633735e-05 \n",
      "epoch: 22 [176649/888800 19.88%] train loss: 1.4989175724622328e-05 \n",
      "epoch: 22 [177760/888800 20.00%] train loss: 1.507866818428738e-05 \n",
      "epoch: 22 [178871/888800 20.12%] train loss: 1.360505211778218e-05 \n",
      "epoch: 22 [179982/888800 20.25%] train loss: 1.5195657397271134e-05 \n",
      "epoch: 22 [181093/888800 20.38%] train loss: 1.472959866077872e-05 \n",
      "epoch: 22 [182204/888800 20.50%] train loss: 1.4055723113415297e-05 \n",
      "epoch: 22 [183315/888800 20.62%] train loss: 1.5565912690362893e-05 \n",
      "epoch: 22 [184426/888800 20.75%] train loss: 1.425423670298187e-05 \n",
      "epoch: 22 [185537/888800 20.88%] train loss: 1.4061021829547826e-05 \n",
      "epoch: 22 [186648/888800 21.00%] train loss: 1.3495309758582152e-05 \n",
      "epoch: 22 [187759/888800 21.12%] train loss: 1.3507490621122997e-05 \n",
      "epoch: 22 [188870/888800 21.25%] train loss: 1.3913067959947512e-05 \n",
      "epoch: 22 [189981/888800 21.38%] train loss: 1.394739138049772e-05 \n",
      "epoch: 22 [191092/888800 21.50%] train loss: 1.368755692965351e-05 \n",
      "epoch: 22 [192203/888800 21.62%] train loss: 1.396160587319173e-05 \n",
      "epoch: 22 [193314/888800 21.75%] train loss: 1.3994933397043496e-05 \n",
      "epoch: 22 [194425/888800 21.88%] train loss: 1.3793169273412786e-05 \n",
      "epoch: 22 [195536/888800 22.00%] train loss: 1.4208363609213848e-05 \n",
      "epoch: 22 [196647/888800 22.12%] train loss: 1.5132796761463396e-05 \n",
      "epoch: 22 [197758/888800 22.25%] train loss: 1.4351551726576872e-05 \n",
      "epoch: 22 [198869/888800 22.38%] train loss: 1.3891327398596331e-05 \n",
      "epoch: 22 [199980/888800 22.50%] train loss: 1.4117289538262412e-05 \n",
      "epoch: 22 [201091/888800 22.62%] train loss: 1.4830944564891979e-05 \n",
      "epoch: 22 [202202/888800 22.75%] train loss: 1.2891897313238587e-05 \n",
      "epoch: 22 [203313/888800 22.88%] train loss: 1.3928463886259124e-05 \n",
      "epoch: 22 [204424/888800 23.00%] train loss: 1.2531521861092187e-05 \n",
      "epoch: 22 [205535/888800 23.12%] train loss: 1.2834019798901863e-05 \n",
      "epoch: 22 [206646/888800 23.25%] train loss: 1.4014119187777396e-05 \n",
      "epoch: 22 [207757/888800 23.38%] train loss: 1.357794099021703e-05 \n",
      "epoch: 22 [208868/888800 23.50%] train loss: 1.324905315414071e-05 \n",
      "epoch: 22 [209979/888800 23.62%] train loss: 1.3030993613938335e-05 \n",
      "epoch: 22 [211090/888800 23.75%] train loss: 1.455888559576124e-05 \n",
      "epoch: 22 [212201/888800 23.88%] train loss: 1.3833949196850881e-05 \n",
      "epoch: 22 [213312/888800 24.00%] train loss: 1.4399179235624615e-05 \n",
      "epoch: 22 [214423/888800 24.12%] train loss: 1.4443568034039345e-05 \n",
      "epoch: 22 [215534/888800 24.25%] train loss: 1.4437030586123e-05 \n",
      "epoch: 22 [216645/888800 24.38%] train loss: 1.372584119962994e-05 \n",
      "epoch: 22 [217756/888800 24.50%] train loss: 1.3489485354511999e-05 \n",
      "epoch: 22 [218867/888800 24.62%] train loss: 1.4852236745355185e-05 \n",
      "epoch: 22 [219978/888800 24.75%] train loss: 1.4248893421608955e-05 \n",
      "epoch: 22 [221089/888800 24.88%] train loss: 1.514083214715356e-05 \n",
      "epoch: 22 [222200/888800 25.00%] train loss: 1.3309710084286053e-05 \n",
      "epoch: 22 [223311/888800 25.12%] train loss: 1.3777224012301303e-05 \n",
      "epoch: 22 [224422/888800 25.25%] train loss: 1.4910398931533564e-05 \n",
      "epoch: 22 [225533/888800 25.38%] train loss: 1.3887681234336924e-05 \n",
      "epoch: 22 [226644/888800 25.50%] train loss: 1.3907727407058701e-05 \n",
      "epoch: 22 [227755/888800 25.62%] train loss: 1.4202185411704704e-05 \n",
      "epoch: 22 [228866/888800 25.75%] train loss: 1.4979670595494099e-05 \n",
      "epoch: 22 [229977/888800 25.88%] train loss: 1.4421641935769003e-05 \n",
      "epoch: 22 [231088/888800 26.00%] train loss: 1.4323303730634507e-05 \n",
      "epoch: 22 [232199/888800 26.12%] train loss: 1.4158516023599077e-05 \n",
      "epoch: 22 [233310/888800 26.25%] train loss: 1.4949549949960783e-05 \n",
      "epoch: 22 [234421/888800 26.38%] train loss: 1.5026577784738038e-05 \n",
      "epoch: 22 [235532/888800 26.50%] train loss: 1.3977823982713744e-05 \n",
      "epoch: 22 [236643/888800 26.62%] train loss: 1.583643097546883e-05 \n",
      "epoch: 22 [237754/888800 26.75%] train loss: 1.4692642253066879e-05 \n",
      "epoch: 22 [238865/888800 26.88%] train loss: 1.2853217413066886e-05 \n",
      "epoch: 22 [239976/888800 27.00%] train loss: 1.4979986190155614e-05 \n",
      "epoch: 22 [241087/888800 27.12%] train loss: 1.4569548511644825e-05 \n",
      "epoch: 22 [242198/888800 27.25%] train loss: 1.3774129911325872e-05 \n",
      "epoch: 22 [243309/888800 27.38%] train loss: 1.3999527254782151e-05 \n",
      "epoch: 22 [244420/888800 27.50%] train loss: 1.3166893040761352e-05 \n",
      "epoch: 22 [245531/888800 27.62%] train loss: 1.4387658666237257e-05 \n",
      "epoch: 22 [246642/888800 27.75%] train loss: 1.312914628215367e-05 \n",
      "epoch: 22 [247753/888800 27.88%] train loss: 1.415044334862614e-05 \n",
      "epoch: 22 [248864/888800 28.00%] train loss: 1.3313189811015036e-05 \n",
      "epoch: 22 [249975/888800 28.12%] train loss: 1.3971271982882172e-05 \n",
      "epoch: 22 [251086/888800 28.25%] train loss: 1.3909329936723225e-05 \n",
      "epoch: 22 [252197/888800 28.38%] train loss: 1.310987863689661e-05 \n",
      "epoch: 22 [253308/888800 28.50%] train loss: 1.4790603017900139e-05 \n",
      "epoch: 22 [254419/888800 28.62%] train loss: 1.4287521480582654e-05 \n",
      "epoch: 22 [255530/888800 28.75%] train loss: 1.4604682291974314e-05 \n",
      "epoch: 22 [256641/888800 28.88%] train loss: 1.2499505828600377e-05 \n",
      "epoch: 22 [257752/888800 29.00%] train loss: 1.3476023923431057e-05 \n",
      "epoch: 22 [258863/888800 29.12%] train loss: 1.3986033991386648e-05 \n",
      "epoch: 22 [259974/888800 29.25%] train loss: 1.4770434063393623e-05 \n",
      "epoch: 22 [261085/888800 29.38%] train loss: 1.3144702279532794e-05 \n",
      "epoch: 22 [262196/888800 29.50%] train loss: 1.368538141832687e-05 \n",
      "epoch: 22 [263307/888800 29.62%] train loss: 1.4626524716732092e-05 \n",
      "epoch: 22 [264418/888800 29.75%] train loss: 1.4059204659133684e-05 \n",
      "epoch: 22 [265529/888800 29.88%] train loss: 1.4778810509596951e-05 \n",
      "epoch: 22 [266640/888800 30.00%] train loss: 1.3822515029460192e-05 \n",
      "epoch: 22 [267751/888800 30.12%] train loss: 1.4266692232922651e-05 \n",
      "epoch: 22 [268862/888800 30.25%] train loss: 1.4185396139509976e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [269973/888800 30.38%] train loss: 1.2902605703857262e-05 \n",
      "epoch: 22 [271084/888800 30.50%] train loss: 1.4331978491100017e-05 \n",
      "epoch: 22 [272195/888800 30.62%] train loss: 1.4223654943634756e-05 \n",
      "epoch: 22 [273306/888800 30.75%] train loss: 1.4772938811802305e-05 \n",
      "epoch: 22 [274417/888800 30.88%] train loss: 1.4512333109450992e-05 \n",
      "epoch: 22 [275528/888800 31.00%] train loss: 1.3433998901746236e-05 \n",
      "epoch: 22 [276639/888800 31.12%] train loss: 1.3936056348029524e-05 \n",
      "epoch: 22 [277750/888800 31.25%] train loss: 1.3316405784280505e-05 \n",
      "epoch: 22 [278861/888800 31.38%] train loss: 1.4315472981252242e-05 \n",
      "epoch: 22 [279972/888800 31.50%] train loss: 1.3782120731775649e-05 \n",
      "epoch: 22 [281083/888800 31.62%] train loss: 1.40018091769889e-05 \n",
      "epoch: 22 [282194/888800 31.75%] train loss: 1.3099110219627619e-05 \n",
      "epoch: 22 [283305/888800 31.88%] train loss: 1.4003799151396379e-05 \n",
      "epoch: 22 [284416/888800 32.00%] train loss: 1.4405641195480712e-05 \n",
      "epoch: 22 [285527/888800 32.12%] train loss: 1.4093744539422914e-05 \n",
      "epoch: 22 [286638/888800 32.25%] train loss: 1.4949108845030423e-05 \n",
      "epoch: 22 [287749/888800 32.38%] train loss: 1.3798442523693666e-05 \n",
      "epoch: 22 [288860/888800 32.50%] train loss: 1.346469343843637e-05 \n",
      "epoch: 22 [289971/888800 32.62%] train loss: 1.3931214198237285e-05 \n",
      "epoch: 22 [291082/888800 32.75%] train loss: 1.436910042684758e-05 \n",
      "epoch: 22 [292193/888800 32.88%] train loss: 1.4204477338353172e-05 \n",
      "epoch: 22 [293304/888800 33.00%] train loss: 1.3639974895340856e-05 \n",
      "epoch: 22 [294415/888800 33.12%] train loss: 1.371445796394255e-05 \n",
      "epoch: 22 [295526/888800 33.25%] train loss: 1.336274181085173e-05 \n",
      "epoch: 22 [296637/888800 33.38%] train loss: 1.3000533726881258e-05 \n",
      "epoch: 22 [297748/888800 33.50%] train loss: 1.5602357962052338e-05 \n",
      "epoch: 22 [298859/888800 33.62%] train loss: 1.4751975868421141e-05 \n",
      "epoch: 22 [299970/888800 33.75%] train loss: 1.3951645996712614e-05 \n",
      "epoch: 22 [301081/888800 33.88%] train loss: 1.325795801676577e-05 \n",
      "epoch: 22 [302192/888800 34.00%] train loss: 1.4731243027199525e-05 \n",
      "epoch: 22 [303303/888800 34.12%] train loss: 1.39478943310678e-05 \n",
      "epoch: 22 [304414/888800 34.25%] train loss: 1.38579152917373e-05 \n",
      "epoch: 22 [305525/888800 34.38%] train loss: 1.4403800378204323e-05 \n",
      "epoch: 22 [306636/888800 34.50%] train loss: 1.5058099961606786e-05 \n",
      "epoch: 22 [307747/888800 34.62%] train loss: 1.453873028367525e-05 \n",
      "epoch: 22 [308858/888800 34.75%] train loss: 1.4175387150316965e-05 \n",
      "epoch: 22 [309969/888800 34.88%] train loss: 1.4341734640765935e-05 \n",
      "epoch: 22 [311080/888800 35.00%] train loss: 1.4090588592807762e-05 \n",
      "epoch: 22 [312191/888800 35.12%] train loss: 1.4451293282036204e-05 \n",
      "epoch: 22 [313302/888800 35.25%] train loss: 1.5043869098008145e-05 \n",
      "epoch: 22 [314413/888800 35.38%] train loss: 1.3752200175076723e-05 \n",
      "epoch: 22 [315524/888800 35.50%] train loss: 1.55159505084157e-05 \n",
      "epoch: 22 [316635/888800 35.62%] train loss: 1.332187639491167e-05 \n",
      "epoch: 22 [317746/888800 35.75%] train loss: 1.3639715689350851e-05 \n",
      "epoch: 22 [318857/888800 35.88%] train loss: 1.4455817108682822e-05 \n",
      "epoch: 22 [319968/888800 36.00%] train loss: 1.4738402569491882e-05 \n",
      "epoch: 22 [321079/888800 36.12%] train loss: 1.5391085980809294e-05 \n",
      "epoch: 22 [322190/888800 36.25%] train loss: 1.3432649211608805e-05 \n",
      "epoch: 22 [323301/888800 36.38%] train loss: 1.366318974760361e-05 \n",
      "epoch: 22 [324412/888800 36.50%] train loss: 1.4652928257419262e-05 \n",
      "epoch: 22 [325523/888800 36.62%] train loss: 1.598436756466981e-05 \n",
      "epoch: 22 [326634/888800 36.75%] train loss: 1.4411245501833037e-05 \n",
      "epoch: 22 [327745/888800 36.88%] train loss: 1.4141304745862726e-05 \n",
      "epoch: 22 [328856/888800 37.00%] train loss: 1.3557645615946967e-05 \n",
      "epoch: 22 [329967/888800 37.12%] train loss: 1.3970643522043247e-05 \n",
      "epoch: 22 [331078/888800 37.25%] train loss: 1.608213278814219e-05 \n",
      "epoch: 22 [332189/888800 37.38%] train loss: 1.4177237972035073e-05 \n",
      "epoch: 22 [333300/888800 37.50%] train loss: 1.3996274901728611e-05 \n",
      "epoch: 22 [334411/888800 37.62%] train loss: 1.33348194140126e-05 \n",
      "epoch: 22 [335522/888800 37.75%] train loss: 1.3877336641598959e-05 \n",
      "epoch: 22 [336633/888800 37.88%] train loss: 1.4346915122587234e-05 \n",
      "epoch: 22 [337744/888800 38.00%] train loss: 1.3929225133324508e-05 \n",
      "epoch: 22 [338855/888800 38.12%] train loss: 1.4704392015119083e-05 \n",
      "epoch: 22 [339966/888800 38.25%] train loss: 1.4004372133058496e-05 \n",
      "epoch: 22 [341077/888800 38.38%] train loss: 1.4760482372366823e-05 \n",
      "epoch: 22 [342188/888800 38.50%] train loss: 1.5828027244424447e-05 \n",
      "epoch: 22 [343299/888800 38.62%] train loss: 1.3265537745610345e-05 \n",
      "epoch: 22 [344410/888800 38.75%] train loss: 1.5707724742242135e-05 \n",
      "epoch: 22 [345521/888800 38.88%] train loss: 1.4007624486112036e-05 \n",
      "epoch: 22 [346632/888800 39.00%] train loss: 1.4593100786441937e-05 \n",
      "epoch: 22 [347743/888800 39.12%] train loss: 1.3579699043475557e-05 \n",
      "epoch: 22 [348854/888800 39.25%] train loss: 1.44299510793644e-05 \n",
      "epoch: 22 [349965/888800 39.38%] train loss: 1.4614372958021704e-05 \n",
      "epoch: 22 [351076/888800 39.50%] train loss: 1.4341647329274565e-05 \n",
      "epoch: 22 [352187/888800 39.62%] train loss: 1.53032142407028e-05 \n",
      "epoch: 22 [353298/888800 39.75%] train loss: 1.5856672689551488e-05 \n",
      "epoch: 22 [354409/888800 39.88%] train loss: 1.391708883602405e-05 \n",
      "epoch: 22 [355520/888800 40.00%] train loss: 1.4610834114137106e-05 \n",
      "epoch: 22 [356631/888800 40.12%] train loss: 1.4871231542201713e-05 \n",
      "epoch: 22 [357742/888800 40.25%] train loss: 1.5841291315155104e-05 \n",
      "epoch: 22 [358853/888800 40.38%] train loss: 1.4621647096646484e-05 \n",
      "epoch: 22 [359964/888800 40.50%] train loss: 1.4216509953257628e-05 \n",
      "epoch: 22 [361075/888800 40.62%] train loss: 1.5027791050670203e-05 \n",
      "epoch: 22 [362186/888800 40.75%] train loss: 1.4342072972794995e-05 \n",
      "epoch: 22 [363297/888800 40.88%] train loss: 1.3951534128864296e-05 \n",
      "epoch: 22 [364408/888800 41.00%] train loss: 1.4146823559713084e-05 \n",
      "epoch: 22 [365519/888800 41.12%] train loss: 1.4685718269902281e-05 \n",
      "epoch: 22 [366630/888800 41.25%] train loss: 1.411428729625186e-05 \n",
      "epoch: 22 [367741/888800 41.38%] train loss: 1.4460541024163831e-05 \n",
      "epoch: 22 [368852/888800 41.50%] train loss: 1.453298500564415e-05 \n",
      "epoch: 22 [369963/888800 41.62%] train loss: 1.5078972865012474e-05 \n",
      "epoch: 22 [371074/888800 41.75%] train loss: 1.4043715054867789e-05 \n",
      "epoch: 22 [372185/888800 41.88%] train loss: 1.4543242286890745e-05 \n",
      "epoch: 22 [373296/888800 42.00%] train loss: 1.4558676411979832e-05 \n",
      "epoch: 22 [374407/888800 42.12%] train loss: 1.3341280464373995e-05 \n",
      "epoch: 22 [375518/888800 42.25%] train loss: 1.4056534382689279e-05 \n",
      "epoch: 22 [376629/888800 42.38%] train loss: 1.451061325496994e-05 \n",
      "epoch: 22 [377740/888800 42.50%] train loss: 1.4387599549081642e-05 \n",
      "epoch: 22 [378851/888800 42.62%] train loss: 1.4987969734647777e-05 \n",
      "epoch: 22 [379962/888800 42.75%] train loss: 1.566442006151192e-05 \n",
      "epoch: 22 [381073/888800 42.88%] train loss: 1.4438306607189588e-05 \n",
      "epoch: 22 [382184/888800 43.00%] train loss: 1.4285235920397099e-05 \n",
      "epoch: 22 [383295/888800 43.12%] train loss: 1.459337454434717e-05 \n",
      "epoch: 22 [384406/888800 43.25%] train loss: 1.4300714610726573e-05 \n",
      "epoch: 22 [385517/888800 43.38%] train loss: 1.517457621957874e-05 \n",
      "epoch: 22 [386628/888800 43.50%] train loss: 1.4680715139547829e-05 \n",
      "epoch: 22 [387739/888800 43.62%] train loss: 1.4980087144067511e-05 \n",
      "epoch: 22 [388850/888800 43.75%] train loss: 1.482519928686088e-05 \n",
      "epoch: 22 [389961/888800 43.88%] train loss: 1.4593130799767096e-05 \n",
      "epoch: 22 [391072/888800 44.00%] train loss: 1.4974326404626481e-05 \n",
      "epoch: 22 [392183/888800 44.12%] train loss: 1.3764068171440158e-05 \n",
      "epoch: 22 [393294/888800 44.25%] train loss: 1.4261164324125275e-05 \n",
      "epoch: 22 [394405/888800 44.38%] train loss: 1.3823385415889788e-05 \n",
      "epoch: 22 [395516/888800 44.50%] train loss: 1.29178097267868e-05 \n",
      "epoch: 22 [396627/888800 44.62%] train loss: 1.4141340216156095e-05 \n",
      "epoch: 22 [397738/888800 44.75%] train loss: 1.526555570308119e-05 \n",
      "epoch: 22 [398849/888800 44.88%] train loss: 1.2374651305435691e-05 \n",
      "epoch: 22 [399960/888800 45.00%] train loss: 1.3956241673440672e-05 \n",
      "epoch: 22 [401071/888800 45.12%] train loss: 1.4329123587231152e-05 \n",
      "epoch: 22 [402182/888800 45.25%] train loss: 1.3774642866337672e-05 \n",
      "epoch: 22 [403293/888800 45.38%] train loss: 1.3657662748300936e-05 \n",
      "epoch: 22 [404404/888800 45.50%] train loss: 1.4054754501557909e-05 \n",
      "epoch: 22 [405515/888800 45.62%] train loss: 1.4157786608848255e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [406626/888800 45.75%] train loss: 1.5460098438779823e-05 \n",
      "epoch: 22 [407737/888800 45.88%] train loss: 1.4542053577315528e-05 \n",
      "epoch: 22 [408848/888800 46.00%] train loss: 1.5121050637389999e-05 \n",
      "epoch: 22 [409959/888800 46.12%] train loss: 1.567796425661072e-05 \n",
      "epoch: 22 [411070/888800 46.25%] train loss: 1.2918245374748949e-05 \n",
      "epoch: 22 [412181/888800 46.38%] train loss: 1.4316584383777808e-05 \n",
      "epoch: 22 [413292/888800 46.50%] train loss: 1.543719736218918e-05 \n",
      "epoch: 22 [414403/888800 46.62%] train loss: 1.4361806279339362e-05 \n",
      "epoch: 22 [415514/888800 46.75%] train loss: 1.3744070201937575e-05 \n",
      "epoch: 22 [416625/888800 46.88%] train loss: 1.4591221770388074e-05 \n",
      "epoch: 22 [417736/888800 47.00%] train loss: 1.3896384189138189e-05 \n",
      "epoch: 22 [418847/888800 47.12%] train loss: 1.303816225117771e-05 \n",
      "epoch: 22 [419958/888800 47.25%] train loss: 1.2478590178943705e-05 \n",
      "epoch: 22 [421069/888800 47.38%] train loss: 1.4411656593438238e-05 \n",
      "epoch: 22 [422180/888800 47.50%] train loss: 1.3805909475195222e-05 \n",
      "epoch: 22 [423291/888800 47.62%] train loss: 1.4361387002281845e-05 \n",
      "epoch: 22 [424402/888800 47.75%] train loss: 1.5786396033945493e-05 \n",
      "epoch: 22 [425513/888800 47.88%] train loss: 1.3703580407309346e-05 \n",
      "epoch: 22 [426624/888800 48.00%] train loss: 1.6054860680014826e-05 \n",
      "epoch: 22 [427735/888800 48.12%] train loss: 1.4253660083340947e-05 \n",
      "epoch: 22 [428846/888800 48.25%] train loss: 1.4351126083056442e-05 \n",
      "epoch: 22 [429957/888800 48.38%] train loss: 1.4788058251724578e-05 \n",
      "epoch: 22 [431068/888800 48.50%] train loss: 1.3932026377005968e-05 \n",
      "epoch: 22 [432179/888800 48.62%] train loss: 1.4574134183931164e-05 \n",
      "epoch: 22 [433290/888800 48.75%] train loss: 1.3776280866295565e-05 \n",
      "epoch: 22 [434401/888800 48.88%] train loss: 1.4263539924286306e-05 \n",
      "epoch: 22 [435512/888800 49.00%] train loss: 1.4196456504578236e-05 \n",
      "epoch: 22 [436623/888800 49.12%] train loss: 1.3602377293864265e-05 \n",
      "epoch: 22 [437734/888800 49.25%] train loss: 1.4458511031989474e-05 \n",
      "epoch: 22 [438845/888800 49.38%] train loss: 1.4691737305838615e-05 \n",
      "epoch: 22 [439956/888800 49.50%] train loss: 1.494198204454733e-05 \n",
      "epoch: 22 [441067/888800 49.62%] train loss: 1.4685201676911674e-05 \n",
      "epoch: 22 [442178/888800 49.75%] train loss: 1.4625617950514425e-05 \n",
      "epoch: 22 [443289/888800 49.88%] train loss: 1.51999493027688e-05 \n",
      "epoch: 22 [444400/888800 50.00%] train loss: 1.4963941794121638e-05 \n",
      "epoch: 22 [445511/888800 50.12%] train loss: 1.5212791367957834e-05 \n",
      "epoch: 22 [446622/888800 50.25%] train loss: 1.2758549019054044e-05 \n",
      "epoch: 22 [447733/888800 50.38%] train loss: 1.3688225408259314e-05 \n",
      "epoch: 22 [448844/888800 50.50%] train loss: 1.4278488379204646e-05 \n",
      "epoch: 22 [449955/888800 50.62%] train loss: 1.4694599485665094e-05 \n",
      "epoch: 22 [451066/888800 50.75%] train loss: 1.4224915503291413e-05 \n",
      "epoch: 22 [452177/888800 50.88%] train loss: 1.4392479897651356e-05 \n",
      "epoch: 22 [453288/888800 51.00%] train loss: 1.5211779100354761e-05 \n",
      "epoch: 22 [454399/888800 51.12%] train loss: 1.4025564269104507e-05 \n",
      "epoch: 22 [455510/888800 51.25%] train loss: 1.5169777725532185e-05 \n",
      "epoch: 22 [456621/888800 51.38%] train loss: 1.4809068488830235e-05 \n",
      "epoch: 22 [457732/888800 51.50%] train loss: 1.4533234207192436e-05 \n",
      "epoch: 22 [458843/888800 51.62%] train loss: 1.3791458513878752e-05 \n",
      "epoch: 22 [459954/888800 51.75%] train loss: 1.2955109923495911e-05 \n",
      "epoch: 22 [461065/888800 51.88%] train loss: 1.4385619579115883e-05 \n",
      "epoch: 22 [462176/888800 52.00%] train loss: 1.3882347047911026e-05 \n",
      "epoch: 22 [463287/888800 52.12%] train loss: 1.5064956642163452e-05 \n",
      "epoch: 22 [464398/888800 52.25%] train loss: 1.2878733286925126e-05 \n",
      "epoch: 22 [465509/888800 52.38%] train loss: 1.318942304351367e-05 \n",
      "epoch: 22 [466620/888800 52.50%] train loss: 1.4440292034123559e-05 \n",
      "epoch: 22 [467731/888800 52.62%] train loss: 1.3575727280112915e-05 \n",
      "epoch: 22 [468842/888800 52.75%] train loss: 1.409426567988703e-05 \n",
      "epoch: 22 [469953/888800 52.88%] train loss: 1.3306008440849837e-05 \n",
      "epoch: 22 [471064/888800 53.00%] train loss: 1.6129715731949545e-05 \n",
      "epoch: 22 [472175/888800 53.12%] train loss: 1.3980183211970143e-05 \n",
      "epoch: 22 [473286/888800 53.25%] train loss: 1.5963327314238995e-05 \n",
      "epoch: 22 [474397/888800 53.38%] train loss: 1.4320076843432616e-05 \n",
      "epoch: 22 [475508/888800 53.50%] train loss: 1.4228537111193873e-05 \n",
      "epoch: 22 [476619/888800 53.62%] train loss: 1.3824818779539783e-05 \n",
      "epoch: 22 [477730/888800 53.75%] train loss: 1.4613556231779512e-05 \n",
      "epoch: 22 [478841/888800 53.88%] train loss: 1.6154883269337006e-05 \n",
      "epoch: 22 [479952/888800 54.00%] train loss: 1.3798425243294332e-05 \n",
      "epoch: 22 [481063/888800 54.12%] train loss: 1.3996544112160336e-05 \n",
      "epoch: 22 [482174/888800 54.25%] train loss: 1.3494552149495576e-05 \n",
      "epoch: 22 [483285/888800 54.38%] train loss: 1.4549906154570635e-05 \n",
      "epoch: 22 [484396/888800 54.50%] train loss: 1.550969682284631e-05 \n",
      "epoch: 22 [485507/888800 54.62%] train loss: 1.4052512597118039e-05 \n",
      "epoch: 22 [486618/888800 54.75%] train loss: 1.4255256246542558e-05 \n",
      "epoch: 22 [487729/888800 54.88%] train loss: 1.4861649106023833e-05 \n",
      "epoch: 22 [488840/888800 55.00%] train loss: 1.4149844901112374e-05 \n",
      "epoch: 22 [489951/888800 55.12%] train loss: 1.3934773960500024e-05 \n",
      "epoch: 22 [491062/888800 55.25%] train loss: 1.4073563761485275e-05 \n",
      "epoch: 22 [492173/888800 55.38%] train loss: 1.603628152224701e-05 \n",
      "epoch: 22 [493284/888800 55.50%] train loss: 1.4012971405463759e-05 \n",
      "epoch: 22 [494395/888800 55.62%] train loss: 1.4071174518903717e-05 \n",
      "epoch: 22 [495506/888800 55.75%] train loss: 1.3108246093906928e-05 \n",
      "epoch: 22 [496617/888800 55.88%] train loss: 1.3336985830392223e-05 \n",
      "epoch: 22 [497728/888800 56.00%] train loss: 1.3611235772259533e-05 \n",
      "epoch: 22 [498839/888800 56.12%] train loss: 1.4018351066624746e-05 \n",
      "epoch: 22 [499950/888800 56.25%] train loss: 1.3795942322758492e-05 \n",
      "epoch: 22 [501061/888800 56.38%] train loss: 1.476504075981211e-05 \n",
      "epoch: 22 [502172/888800 56.50%] train loss: 1.5408963008667342e-05 \n",
      "epoch: 22 [503283/888800 56.62%] train loss: 1.3968325220048428e-05 \n",
      "epoch: 22 [504394/888800 56.75%] train loss: 1.2967456314072479e-05 \n",
      "epoch: 22 [505505/888800 56.88%] train loss: 1.3390623280429281e-05 \n",
      "epoch: 22 [506616/888800 57.00%] train loss: 1.5119669114938006e-05 \n",
      "epoch: 22 [507727/888800 57.12%] train loss: 1.4492951777356211e-05 \n",
      "epoch: 22 [508838/888800 57.25%] train loss: 1.4750419722986408e-05 \n",
      "epoch: 22 [509949/888800 57.38%] train loss: 1.2790599612344522e-05 \n",
      "epoch: 22 [511060/888800 57.50%] train loss: 1.5551710021100007e-05 \n",
      "epoch: 22 [512171/888800 57.62%] train loss: 1.4007444406161085e-05 \n",
      "epoch: 22 [513282/888800 57.75%] train loss: 1.5187710232567042e-05 \n",
      "epoch: 22 [514393/888800 57.88%] train loss: 1.4257900147640612e-05 \n",
      "epoch: 22 [515504/888800 58.00%] train loss: 1.4777462638448924e-05 \n",
      "epoch: 22 [516615/888800 58.12%] train loss: 1.3918541299062781e-05 \n",
      "epoch: 22 [517726/888800 58.25%] train loss: 1.363879164273385e-05 \n",
      "epoch: 22 [518837/888800 58.38%] train loss: 1.4335336345538963e-05 \n",
      "epoch: 22 [519948/888800 58.50%] train loss: 1.5000620805949438e-05 \n",
      "epoch: 22 [521059/888800 58.62%] train loss: 1.3418747585092206e-05 \n",
      "epoch: 22 [522170/888800 58.75%] train loss: 1.3464152289088815e-05 \n",
      "epoch: 22 [523281/888800 58.88%] train loss: 1.4303738680609968e-05 \n",
      "epoch: 22 [524392/888800 59.00%] train loss: 1.5595980585203506e-05 \n",
      "epoch: 22 [525503/888800 59.12%] train loss: 1.5415160305565223e-05 \n",
      "epoch: 22 [526614/888800 59.25%] train loss: 1.580109164933674e-05 \n",
      "epoch: 22 [527725/888800 59.38%] train loss: 1.6132013115566224e-05 \n",
      "epoch: 22 [528836/888800 59.50%] train loss: 1.4514857866743114e-05 \n",
      "epoch: 22 [529947/888800 59.62%] train loss: 1.510849324404262e-05 \n",
      "epoch: 22 [531058/888800 59.75%] train loss: 1.3863144886272494e-05 \n",
      "epoch: 22 [532169/888800 59.88%] train loss: 1.598715243744664e-05 \n",
      "epoch: 22 [533280/888800 60.00%] train loss: 1.437645096302731e-05 \n",
      "epoch: 22 [534391/888800 60.12%] train loss: 1.2885288015240803e-05 \n",
      "epoch: 22 [535502/888800 60.25%] train loss: 1.617548696231097e-05 \n",
      "epoch: 22 [536613/888800 60.38%] train loss: 1.4444824955717195e-05 \n",
      "epoch: 22 [537724/888800 60.50%] train loss: 1.4886130884406157e-05 \n",
      "epoch: 22 [538835/888800 60.62%] train loss: 1.4092089259065688e-05 \n",
      "epoch: 22 [539946/888800 60.75%] train loss: 1.5423936929437332e-05 \n",
      "epoch: 22 [541057/888800 60.88%] train loss: 1.4909567653376143e-05 \n",
      "epoch: 22 [542168/888800 61.00%] train loss: 1.4278283742896747e-05 \n",
      "epoch: 22 [543279/888800 61.12%] train loss: 1.4422626009036321e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [544390/888800 61.25%] train loss: 1.4341073438117746e-05 \n",
      "epoch: 22 [545501/888800 61.38%] train loss: 1.5201008864096366e-05 \n",
      "epoch: 22 [546612/888800 61.50%] train loss: 1.4357399777509272e-05 \n",
      "epoch: 22 [547723/888800 61.62%] train loss: 1.6576666894252412e-05 \n",
      "epoch: 22 [548834/888800 61.75%] train loss: 1.6959851564024575e-05 \n",
      "epoch: 22 [549945/888800 61.88%] train loss: 1.3146503079042304e-05 \n",
      "epoch: 22 [551056/888800 62.00%] train loss: 1.980433262360748e-05 \n",
      "epoch: 22 [552167/888800 62.12%] train loss: 1.5057597011036705e-05 \n",
      "epoch: 22 [553278/888800 62.25%] train loss: 1.5946701751090586e-05 \n",
      "epoch: 22 [554389/888800 62.38%] train loss: 1.5612016795785166e-05 \n",
      "epoch: 22 [555500/888800 62.50%] train loss: 1.50357918755617e-05 \n",
      "epoch: 22 [556611/888800 62.62%] train loss: 1.5519655789830722e-05 \n",
      "epoch: 22 [557722/888800 62.75%] train loss: 1.4160616956360172e-05 \n",
      "epoch: 22 [558833/888800 62.88%] train loss: 1.5644123777747154e-05 \n",
      "epoch: 22 [559944/888800 63.00%] train loss: 1.4889958947605919e-05 \n",
      "epoch: 22 [561055/888800 63.12%] train loss: 1.5161576811806299e-05 \n",
      "epoch: 22 [562166/888800 63.25%] train loss: 1.4909213859937154e-05 \n",
      "epoch: 22 [563277/888800 63.38%] train loss: 1.288435305468738e-05 \n",
      "epoch: 22 [564388/888800 63.50%] train loss: 1.4574945453205146e-05 \n",
      "epoch: 22 [565499/888800 63.62%] train loss: 1.3617187505587935e-05 \n",
      "epoch: 22 [566610/888800 63.75%] train loss: 1.5265726688085124e-05 \n",
      "epoch: 22 [567721/888800 63.88%] train loss: 1.4671903954877052e-05 \n",
      "epoch: 22 [568832/888800 64.00%] train loss: 1.4706289221066982e-05 \n",
      "epoch: 22 [569943/888800 64.12%] train loss: 1.4533621651935391e-05 \n",
      "epoch: 22 [571054/888800 64.25%] train loss: 1.3011262126383372e-05 \n",
      "epoch: 22 [572165/888800 64.38%] train loss: 1.5115390851860866e-05 \n",
      "epoch: 22 [573276/888800 64.50%] train loss: 1.4491163710772526e-05 \n",
      "epoch: 22 [574387/888800 64.62%] train loss: 1.372138831357006e-05 \n",
      "epoch: 22 [575498/888800 64.75%] train loss: 1.3753890925727319e-05 \n",
      "epoch: 22 [576609/888800 64.88%] train loss: 1.3870308066543657e-05 \n",
      "epoch: 22 [577720/888800 65.00%] train loss: 1.4380482753040269e-05 \n",
      "epoch: 22 [578831/888800 65.12%] train loss: 1.4879473383189179e-05 \n",
      "epoch: 22 [579942/888800 65.25%] train loss: 1.330195755144814e-05 \n",
      "epoch: 22 [581053/888800 65.38%] train loss: 1.2618301298061851e-05 \n",
      "epoch: 22 [582164/888800 65.50%] train loss: 1.3319063327799086e-05 \n",
      "epoch: 22 [583275/888800 65.62%] train loss: 1.4347422620630823e-05 \n",
      "epoch: 22 [584386/888800 65.75%] train loss: 1.4751248272659723e-05 \n",
      "epoch: 22 [585497/888800 65.88%] train loss: 1.4702249245601706e-05 \n",
      "epoch: 22 [586608/888800 66.00%] train loss: 1.4045373063709121e-05 \n",
      "epoch: 22 [587719/888800 66.12%] train loss: 1.552202047605533e-05 \n",
      "epoch: 22 [588830/888800 66.25%] train loss: 1.3980559742776677e-05 \n",
      "epoch: 22 [589941/888800 66.38%] train loss: 1.4840820767858531e-05 \n",
      "epoch: 22 [591052/888800 66.50%] train loss: 1.2768987289746292e-05 \n",
      "epoch: 22 [592163/888800 66.62%] train loss: 1.2853507541876752e-05 \n",
      "epoch: 22 [593274/888800 66.75%] train loss: 1.4209018445399124e-05 \n",
      "epoch: 22 [594385/888800 66.88%] train loss: 1.4177784578350838e-05 \n",
      "epoch: 22 [595496/888800 67.00%] train loss: 1.3927275176683906e-05 \n",
      "epoch: 22 [596607/888800 67.12%] train loss: 1.5070715562615078e-05 \n",
      "epoch: 22 [597718/888800 67.25%] train loss: 1.3868890164303593e-05 \n",
      "epoch: 22 [598829/888800 67.38%] train loss: 1.2330870958976448e-05 \n",
      "epoch: 22 [599940/888800 67.50%] train loss: 1.4888957593939267e-05 \n",
      "epoch: 22 [601051/888800 67.62%] train loss: 1.4503596503345761e-05 \n",
      "epoch: 22 [602162/888800 67.75%] train loss: 1.4500946235784795e-05 \n",
      "epoch: 22 [603273/888800 67.88%] train loss: 1.4843514691165183e-05 \n",
      "epoch: 22 [604384/888800 68.00%] train loss: 1.4010513041284867e-05 \n",
      "epoch: 22 [605495/888800 68.12%] train loss: 1.4271075997385196e-05 \n",
      "epoch: 22 [606606/888800 68.25%] train loss: 1.4102866771281697e-05 \n",
      "epoch: 22 [607717/888800 68.38%] train loss: 1.304409761360148e-05 \n",
      "epoch: 22 [608828/888800 68.50%] train loss: 1.3787398529530037e-05 \n",
      "epoch: 22 [609939/888800 68.62%] train loss: 1.4487820408248808e-05 \n",
      "epoch: 22 [611050/888800 68.75%] train loss: 1.333777981926687e-05 \n",
      "epoch: 22 [612161/888800 68.88%] train loss: 1.4286612895375583e-05 \n",
      "epoch: 22 [613272/888800 69.00%] train loss: 1.3369849511946086e-05 \n",
      "epoch: 22 [614383/888800 69.12%] train loss: 1.5235297723847907e-05 \n",
      "epoch: 22 [615494/888800 69.25%] train loss: 1.393879392708186e-05 \n",
      "epoch: 22 [616605/888800 69.38%] train loss: 1.3196696272643749e-05 \n",
      "epoch: 22 [617716/888800 69.50%] train loss: 1.483946107327938e-05 \n",
      "epoch: 22 [618827/888800 69.62%] train loss: 1.3670964108314365e-05 \n",
      "epoch: 22 [619938/888800 69.75%] train loss: 1.5357778465840966e-05 \n",
      "epoch: 22 [621049/888800 69.88%] train loss: 1.326981873717159e-05 \n",
      "epoch: 22 [622160/888800 70.00%] train loss: 1.4834606190561317e-05 \n",
      "epoch: 22 [623271/888800 70.12%] train loss: 1.5502319001825526e-05 \n",
      "epoch: 22 [624382/888800 70.25%] train loss: 1.3642023077409249e-05 \n",
      "epoch: 22 [625493/888800 70.38%] train loss: 1.406715909979539e-05 \n",
      "epoch: 22 [626604/888800 70.50%] train loss: 1.4394455320143607e-05 \n",
      "epoch: 22 [627715/888800 70.62%] train loss: 1.3131663763488177e-05 \n",
      "epoch: 22 [628826/888800 70.75%] train loss: 1.4101444321568124e-05 \n",
      "epoch: 22 [629937/888800 70.88%] train loss: 1.455080655432539e-05 \n",
      "epoch: 22 [631048/888800 71.00%] train loss: 1.443955443392042e-05 \n",
      "epoch: 22 [632159/888800 71.12%] train loss: 1.3430869330477435e-05 \n",
      "epoch: 22 [633270/888800 71.25%] train loss: 1.3515943464881275e-05 \n",
      "epoch: 22 [634381/888800 71.38%] train loss: 1.3133236279827543e-05 \n",
      "epoch: 22 [635492/888800 71.50%] train loss: 1.4295637811301276e-05 \n",
      "epoch: 22 [636603/888800 71.62%] train loss: 1.4756904420210049e-05 \n",
      "epoch: 22 [637714/888800 71.75%] train loss: 1.4505053513858002e-05 \n",
      "epoch: 22 [638825/888800 71.88%] train loss: 1.4618795830756426e-05 \n",
      "epoch: 22 [639936/888800 72.00%] train loss: 1.3535590369428974e-05 \n",
      "epoch: 22 [641047/888800 72.12%] train loss: 1.4330966223496944e-05 \n",
      "epoch: 22 [642158/888800 72.25%] train loss: 1.3401101568888407e-05 \n",
      "epoch: 22 [643269/888800 72.38%] train loss: 1.3886018678022083e-05 \n",
      "epoch: 22 [644380/888800 72.50%] train loss: 1.6662805137457326e-05 \n",
      "epoch: 22 [645491/888800 72.62%] train loss: 1.47599057527259e-05 \n",
      "epoch: 22 [646602/888800 72.75%] train loss: 1.512264680059161e-05 \n",
      "epoch: 22 [647713/888800 72.88%] train loss: 1.4722710147907492e-05 \n",
      "epoch: 22 [648824/888800 73.00%] train loss: 1.388429336657282e-05 \n",
      "epoch: 22 [649935/888800 73.12%] train loss: 1.3187640433898196e-05 \n",
      "epoch: 22 [651046/888800 73.25%] train loss: 1.3584393855126109e-05 \n",
      "epoch: 22 [652157/888800 73.38%] train loss: 1.444660756533267e-05 \n",
      "epoch: 22 [653268/888800 73.50%] train loss: 1.5095882190507837e-05 \n",
      "epoch: 22 [654379/888800 73.62%] train loss: 1.3071969988232013e-05 \n",
      "epoch: 22 [655490/888800 73.75%] train loss: 1.3546416994358879e-05 \n",
      "epoch: 22 [656601/888800 73.88%] train loss: 1.5278475984814577e-05 \n",
      "epoch: 22 [657712/888800 74.00%] train loss: 1.342721952823922e-05 \n",
      "epoch: 22 [658823/888800 74.12%] train loss: 1.4968736650189385e-05 \n",
      "epoch: 22 [659934/888800 74.25%] train loss: 1.4457084034802392e-05 \n",
      "epoch: 22 [661045/888800 74.38%] train loss: 1.5191345482890029e-05 \n",
      "epoch: 22 [662156/888800 74.50%] train loss: 1.5452014849870466e-05 \n",
      "epoch: 22 [663267/888800 74.62%] train loss: 1.4483564882539213e-05 \n",
      "epoch: 22 [664378/888800 74.75%] train loss: 1.5513665857724845e-05 \n",
      "epoch: 22 [665489/888800 74.88%] train loss: 1.4578529771824833e-05 \n",
      "epoch: 22 [666600/888800 75.00%] train loss: 1.567118670209311e-05 \n",
      "epoch: 22 [667711/888800 75.12%] train loss: 1.2783120837411843e-05 \n",
      "epoch: 22 [668822/888800 75.25%] train loss: 1.559466909384355e-05 \n",
      "epoch: 22 [669933/888800 75.38%] train loss: 1.4652046957053244e-05 \n",
      "epoch: 22 [671044/888800 75.50%] train loss: 1.3737495464738458e-05 \n",
      "epoch: 22 [672155/888800 75.62%] train loss: 1.586885809956584e-05 \n",
      "epoch: 22 [673266/888800 75.75%] train loss: 1.3832316653861199e-05 \n",
      "epoch: 22 [674377/888800 75.88%] train loss: 1.392904141539475e-05 \n",
      "epoch: 22 [675488/888800 76.00%] train loss: 1.4430923329200596e-05 \n",
      "epoch: 22 [676599/888800 76.12%] train loss: 1.5456165783689357e-05 \n",
      "epoch: 22 [677710/888800 76.25%] train loss: 1.4591442777600605e-05 \n",
      "epoch: 22 [678821/888800 76.38%] train loss: 1.4696423022542149e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [679932/888800 76.50%] train loss: 1.4706976799061522e-05 \n",
      "epoch: 22 [681043/888800 76.62%] train loss: 1.3406255675363354e-05 \n",
      "epoch: 22 [682154/888800 76.75%] train loss: 1.564079684612807e-05 \n",
      "epoch: 22 [683265/888800 76.88%] train loss: 1.4835685760772321e-05 \n",
      "epoch: 22 [684376/888800 77.00%] train loss: 1.558590156491846e-05 \n",
      "epoch: 22 [685487/888800 77.12%] train loss: 1.5756895663798787e-05 \n",
      "epoch: 22 [686598/888800 77.25%] train loss: 1.5545347196166404e-05 \n",
      "epoch: 22 [687709/888800 77.38%] train loss: 1.5649788110749796e-05 \n",
      "epoch: 22 [688820/888800 77.50%] train loss: 1.5536612409050576e-05 \n",
      "epoch: 22 [689931/888800 77.62%] train loss: 1.505550153524382e-05 \n",
      "epoch: 22 [691042/888800 77.75%] train loss: 1.3921983736508992e-05 \n",
      "epoch: 22 [692153/888800 77.88%] train loss: 1.5406747479573824e-05 \n",
      "epoch: 22 [693264/888800 78.00%] train loss: 1.3302304068929516e-05 \n",
      "epoch: 22 [694375/888800 78.12%] train loss: 1.5136701222218107e-05 \n",
      "epoch: 22 [695486/888800 78.25%] train loss: 1.427247298124712e-05 \n",
      "epoch: 22 [696597/888800 78.38%] train loss: 1.4798643860558514e-05 \n",
      "epoch: 22 [697708/888800 78.50%] train loss: 1.6216832591453567e-05 \n",
      "epoch: 22 [698819/888800 78.62%] train loss: 1.4666692550235894e-05 \n",
      "epoch: 22 [699930/888800 78.75%] train loss: 1.5175498447206337e-05 \n",
      "epoch: 22 [701041/888800 78.88%] train loss: 1.3397309885476716e-05 \n",
      "epoch: 22 [702152/888800 79.00%] train loss: 1.72345698956633e-05 \n",
      "epoch: 22 [703263/888800 79.12%] train loss: 1.4063023627386428e-05 \n",
      "epoch: 22 [704374/888800 79.25%] train loss: 1.2877922927145846e-05 \n",
      "epoch: 22 [705485/888800 79.38%] train loss: 1.4072798876441084e-05 \n",
      "epoch: 22 [706596/888800 79.50%] train loss: 1.4075183571549132e-05 \n",
      "epoch: 22 [707707/888800 79.62%] train loss: 1.5231425095407758e-05 \n",
      "epoch: 22 [708818/888800 79.75%] train loss: 1.3411471627478022e-05 \n",
      "epoch: 22 [709929/888800 79.88%] train loss: 1.4708841263200156e-05 \n",
      "epoch: 22 [711040/888800 80.00%] train loss: 1.3359454896999523e-05 \n",
      "epoch: 22 [712151/888800 80.12%] train loss: 1.5189953955996316e-05 \n",
      "epoch: 22 [713262/888800 80.25%] train loss: 1.3483516340784263e-05 \n",
      "epoch: 22 [714373/888800 80.38%] train loss: 1.3943827070761472e-05 \n",
      "epoch: 22 [715484/888800 80.50%] train loss: 1.2615923878911417e-05 \n",
      "epoch: 22 [716595/888800 80.62%] train loss: 1.3518340892915148e-05 \n",
      "epoch: 22 [717706/888800 80.75%] train loss: 1.5127936421777122e-05 \n",
      "epoch: 22 [718817/888800 80.88%] train loss: 1.5981375327100977e-05 \n",
      "epoch: 22 [719928/888800 81.00%] train loss: 1.503998828411568e-05 \n",
      "epoch: 22 [721039/888800 81.12%] train loss: 1.58316452143481e-05 \n",
      "epoch: 22 [722150/888800 81.25%] train loss: 1.3901896636525635e-05 \n",
      "epoch: 22 [723261/888800 81.38%] train loss: 1.507391789346002e-05 \n",
      "epoch: 22 [724372/888800 81.50%] train loss: 1.4970460142649245e-05 \n",
      "epoch: 22 [725483/888800 81.62%] train loss: 1.4112198186921887e-05 \n",
      "epoch: 22 [726594/888800 81.75%] train loss: 1.5013839401945006e-05 \n",
      "epoch: 22 [727705/888800 81.88%] train loss: 1.487151712353807e-05 \n",
      "epoch: 22 [728816/888800 82.00%] train loss: 1.6439827959402464e-05 \n",
      "epoch: 22 [729927/888800 82.12%] train loss: 1.573088957229629e-05 \n",
      "epoch: 22 [731038/888800 82.25%] train loss: 1.4816204384260345e-05 \n",
      "epoch: 22 [732149/888800 82.38%] train loss: 1.5040205653349403e-05 \n",
      "epoch: 22 [733260/888800 82.50%] train loss: 1.4832449778623413e-05 \n",
      "epoch: 22 [734371/888800 82.62%] train loss: 1.3862392734154128e-05 \n",
      "epoch: 22 [735482/888800 82.75%] train loss: 1.4207717867975589e-05 \n",
      "epoch: 22 [736593/888800 82.88%] train loss: 1.4083652786212042e-05 \n",
      "epoch: 22 [737704/888800 83.00%] train loss: 1.4769640074518975e-05 \n",
      "epoch: 22 [738815/888800 83.12%] train loss: 1.5389579857583158e-05 \n",
      "epoch: 22 [739926/888800 83.25%] train loss: 1.4756703421880957e-05 \n",
      "epoch: 22 [741037/888800 83.38%] train loss: 1.4360321983986069e-05 \n",
      "epoch: 22 [742148/888800 83.50%] train loss: 1.3667628991242964e-05 \n",
      "epoch: 22 [743259/888800 83.62%] train loss: 1.4314745385490824e-05 \n",
      "epoch: 22 [744370/888800 83.75%] train loss: 1.4657281099061947e-05 \n",
      "epoch: 22 [745481/888800 83.88%] train loss: 1.4333821127365809e-05 \n",
      "epoch: 22 [746592/888800 84.00%] train loss: 1.3603483239421621e-05 \n",
      "epoch: 22 [747703/888800 84.12%] train loss: 1.6179343219846487e-05 \n",
      "epoch: 22 [748814/888800 84.25%] train loss: 1.3745346223004162e-05 \n",
      "epoch: 22 [749925/888800 84.38%] train loss: 1.4448939509748016e-05 \n",
      "epoch: 22 [751036/888800 84.50%] train loss: 1.3130542356520891e-05 \n",
      "epoch: 22 [752147/888800 84.62%] train loss: 1.4552472748619039e-05 \n",
      "epoch: 22 [753258/888800 84.75%] train loss: 1.4996488062024582e-05 \n",
      "epoch: 22 [754369/888800 84.88%] train loss: 1.4964872207201552e-05 \n",
      "epoch: 22 [755480/888800 85.00%] train loss: 1.4872588508296758e-05 \n",
      "epoch: 22 [756591/888800 85.12%] train loss: 1.4991975149314385e-05 \n",
      "epoch: 22 [757702/888800 85.25%] train loss: 1.3961118384031579e-05 \n",
      "epoch: 22 [758813/888800 85.38%] train loss: 1.3823092558595818e-05 \n",
      "epoch: 22 [759924/888800 85.50%] train loss: 1.4305524018709548e-05 \n",
      "epoch: 22 [761035/888800 85.62%] train loss: 1.4562586329702754e-05 \n",
      "epoch: 22 [762146/888800 85.75%] train loss: 1.4983339497121051e-05 \n",
      "epoch: 22 [763257/888800 85.88%] train loss: 1.4294962056737859e-05 \n",
      "epoch: 22 [764368/888800 86.00%] train loss: 1.5508880096604116e-05 \n",
      "epoch: 22 [765479/888800 86.12%] train loss: 1.4849882973066997e-05 \n",
      "epoch: 22 [766590/888800 86.25%] train loss: 1.449404862796655e-05 \n",
      "epoch: 22 [767701/888800 86.38%] train loss: 1.3903244507673662e-05 \n",
      "epoch: 22 [768812/888800 86.50%] train loss: 1.6312580555677414e-05 \n",
      "epoch: 22 [769923/888800 86.62%] train loss: 1.4671177268610336e-05 \n",
      "epoch: 22 [771034/888800 86.75%] train loss: 1.2912661986774765e-05 \n",
      "epoch: 22 [772145/888800 86.88%] train loss: 1.5592260751873255e-05 \n",
      "epoch: 22 [773256/888800 87.00%] train loss: 1.4015598026162479e-05 \n",
      "epoch: 22 [774367/888800 87.12%] train loss: 1.4384620044438634e-05 \n",
      "epoch: 22 [775478/888800 87.25%] train loss: 1.4217160241969395e-05 \n",
      "epoch: 22 [776589/888800 87.38%] train loss: 1.6680924090906046e-05 \n",
      "epoch: 22 [777700/888800 87.50%] train loss: 1.5999559764168225e-05 \n",
      "epoch: 22 [778811/888800 87.62%] train loss: 1.377007629344007e-05 \n",
      "epoch: 22 [779922/888800 87.75%] train loss: 1.4544174518960062e-05 \n",
      "epoch: 22 [781033/888800 87.88%] train loss: 1.438095023331698e-05 \n",
      "epoch: 22 [782144/888800 88.00%] train loss: 1.4488629858533386e-05 \n",
      "epoch: 22 [783255/888800 88.12%] train loss: 1.5152023479458876e-05 \n",
      "epoch: 22 [784366/888800 88.25%] train loss: 1.4117949831415899e-05 \n",
      "epoch: 22 [785477/888800 88.38%] train loss: 1.464801243855618e-05 \n",
      "epoch: 22 [786588/888800 88.50%] train loss: 1.3413230590231251e-05 \n",
      "epoch: 22 [787699/888800 88.62%] train loss: 1.4970730262575671e-05 \n",
      "epoch: 22 [788810/888800 88.75%] train loss: 1.3219828360888641e-05 \n",
      "epoch: 22 [789921/888800 88.88%] train loss: 1.5723991964478046e-05 \n",
      "epoch: 22 [791032/888800 89.00%] train loss: 1.4513235328195151e-05 \n",
      "epoch: 22 [792143/888800 89.12%] train loss: 1.4983929759182502e-05 \n",
      "epoch: 22 [793254/888800 89.25%] train loss: 1.384140250593191e-05 \n",
      "epoch: 22 [794365/888800 89.38%] train loss: 1.4532971363223623e-05 \n",
      "epoch: 22 [795476/888800 89.50%] train loss: 1.6118941857712343e-05 \n",
      "epoch: 22 [796587/888800 89.62%] train loss: 1.5091079148987774e-05 \n",
      "epoch: 22 [797698/888800 89.75%] train loss: 1.591813088452909e-05 \n",
      "epoch: 22 [798809/888800 89.88%] train loss: 1.524626713944599e-05 \n",
      "epoch: 22 [799920/888800 90.00%] train loss: 1.581914875714574e-05 \n",
      "epoch: 22 [801031/888800 90.12%] train loss: 1.4398769053514116e-05 \n",
      "epoch: 22 [802142/888800 90.25%] train loss: 1.4495523828372825e-05 \n",
      "epoch: 22 [803253/888800 90.38%] train loss: 1.3909951121604536e-05 \n",
      "epoch: 22 [804364/888800 90.50%] train loss: 1.4407550224859733e-05 \n",
      "epoch: 22 [805475/888800 90.62%] train loss: 1.4203023056325037e-05 \n",
      "epoch: 22 [806586/888800 90.75%] train loss: 1.582697223057039e-05 \n",
      "epoch: 22 [807697/888800 90.88%] train loss: 1.3685777958016843e-05 \n",
      "epoch: 22 [808808/888800 91.00%] train loss: 1.691797297098674e-05 \n",
      "epoch: 22 [809919/888800 91.12%] train loss: 1.467329821025487e-05 \n",
      "epoch: 22 [811030/888800 91.25%] train loss: 1.637286004552152e-05 \n",
      "epoch: 22 [812141/888800 91.38%] train loss: 1.566921127960086e-05 \n",
      "epoch: 22 [813252/888800 91.50%] train loss: 1.4731313967786264e-05 \n",
      "epoch: 22 [814363/888800 91.62%] train loss: 1.6273363144136965e-05 \n",
      "epoch: 22 [815474/888800 91.75%] train loss: 1.4675325473945122e-05 \n",
      "epoch: 22 [816585/888800 91.88%] train loss: 1.5503175745834596e-05 \n",
      "epoch: 22 [817696/888800 92.00%] train loss: 1.5821773558855057e-05 \n",
      "epoch: 22 [818807/888800 92.12%] train loss: 1.512567814643262e-05 \n",
      "epoch: 22 [819918/888800 92.25%] train loss: 1.3783299436909147e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 [821029/888800 92.38%] train loss: 1.4802573787164874e-05 \n",
      "epoch: 22 [822140/888800 92.50%] train loss: 1.5451008948730305e-05 \n",
      "epoch: 22 [823251/888800 92.62%] train loss: 1.4375147657119669e-05 \n",
      "epoch: 22 [824362/888800 92.75%] train loss: 1.4213832400855608e-05 \n",
      "epoch: 22 [825473/888800 92.88%] train loss: 1.530770350655075e-05 \n",
      "epoch: 22 [826584/888800 93.00%] train loss: 1.466159119445365e-05 \n",
      "epoch: 22 [827695/888800 93.12%] train loss: 1.387017073284369e-05 \n",
      "epoch: 22 [828806/888800 93.25%] train loss: 1.507205524831079e-05 \n",
      "epoch: 22 [829917/888800 93.38%] train loss: 1.4715131328557618e-05 \n",
      "epoch: 22 [831028/888800 93.50%] train loss: 1.3963307537778746e-05 \n",
      "epoch: 22 [832139/888800 93.62%] train loss: 1.4265788195189089e-05 \n",
      "epoch: 22 [833250/888800 93.75%] train loss: 1.4172627743391786e-05 \n",
      "epoch: 22 [834361/888800 93.88%] train loss: 1.3708537153434008e-05 \n",
      "epoch: 22 [835472/888800 94.00%] train loss: 1.3996546840644442e-05 \n",
      "epoch: 22 [836583/888800 94.12%] train loss: 1.335788329015486e-05 \n",
      "epoch: 22 [837694/888800 94.25%] train loss: 1.4780999663344119e-05 \n",
      "epoch: 22 [838805/888800 94.38%] train loss: 1.4379013919096906e-05 \n",
      "epoch: 22 [839916/888800 94.50%] train loss: 1.4972701137594413e-05 \n",
      "epoch: 22 [841027/888800 94.62%] train loss: 1.4259700947150122e-05 \n",
      "epoch: 22 [842138/888800 94.75%] train loss: 1.4184513929649256e-05 \n",
      "epoch: 22 [843249/888800 94.88%] train loss: 1.507125034549972e-05 \n",
      "epoch: 22 [844360/888800 95.00%] train loss: 1.5033662748464849e-05 \n",
      "epoch: 22 [845471/888800 95.12%] train loss: 1.3824452253174968e-05 \n",
      "epoch: 22 [846582/888800 95.25%] train loss: 1.5142147276492324e-05 \n",
      "epoch: 22 [847693/888800 95.38%] train loss: 1.533418253529817e-05 \n",
      "epoch: 22 [848804/888800 95.50%] train loss: 1.4766568710911088e-05 \n",
      "epoch: 22 [849915/888800 95.62%] train loss: 1.3770111763733439e-05 \n",
      "epoch: 22 [851026/888800 95.75%] train loss: 1.4216673662303947e-05 \n",
      "epoch: 22 [852137/888800 95.88%] train loss: 1.536356285214424e-05 \n",
      "epoch: 22 [853248/888800 96.00%] train loss: 1.3508154552255291e-05 \n",
      "epoch: 22 [854359/888800 96.12%] train loss: 1.6523588783456944e-05 \n",
      "epoch: 22 [855470/888800 96.25%] train loss: 1.4338153050630353e-05 \n",
      "epoch: 22 [856581/888800 96.38%] train loss: 1.533928298158571e-05 \n",
      "epoch: 22 [857692/888800 96.50%] train loss: 1.499135669291718e-05 \n",
      "epoch: 22 [858803/888800 96.62%] train loss: 1.4199078577803448e-05 \n",
      "epoch: 22 [859914/888800 96.75%] train loss: 1.4038369045010768e-05 \n",
      "epoch: 22 [861025/888800 96.88%] train loss: 1.4327637472888455e-05 \n",
      "epoch: 22 [862136/888800 97.00%] train loss: 1.3708830920222681e-05 \n",
      "epoch: 22 [863247/888800 97.12%] train loss: 1.431630789738847e-05 \n",
      "epoch: 22 [864358/888800 97.25%] train loss: 1.4018467481946573e-05 \n",
      "epoch: 22 [865469/888800 97.38%] train loss: 1.4119897059572395e-05 \n",
      "epoch: 22 [866580/888800 97.50%] train loss: 1.4281606127042323e-05 \n",
      "epoch: 22 [867691/888800 97.62%] train loss: 1.3715040950046387e-05 \n",
      "epoch: 22 [868802/888800 97.75%] train loss: 1.4329662917589303e-05 \n",
      "epoch: 22 [869913/888800 97.88%] train loss: 1.5213904589472804e-05 \n",
      "epoch: 22 [871024/888800 98.00%] train loss: 1.3689582374354359e-05 \n",
      "epoch: 22 [872135/888800 98.12%] train loss: 1.5255051039275713e-05 \n",
      "epoch: 22 [873246/888800 98.25%] train loss: 1.3375994967645966e-05 \n",
      "epoch: 22 [874357/888800 98.38%] train loss: 1.483934738644166e-05 \n",
      "epoch: 22 [875468/888800 98.50%] train loss: 1.3702879186894279e-05 \n",
      "epoch: 22 [876579/888800 98.62%] train loss: 1.4770122106710915e-05 \n",
      "epoch: 22 [877690/888800 98.75%] train loss: 1.4851992091280408e-05 \n",
      "epoch: 22 [878801/888800 98.88%] train loss: 1.4322712559078354e-05 \n",
      "epoch: 22 [879912/888800 99.00%] train loss: 1.3760938600171357e-05 \n",
      "epoch: 22 [881023/888800 99.12%] train loss: 1.2818204595532734e-05 \n",
      "epoch: 22 [882134/888800 99.25%] train loss: 1.43316619869438e-05 \n",
      "epoch: 22 [883245/888800 99.38%] train loss: 1.3183956980356015e-05 \n",
      "epoch: 22 [884356/888800 99.50%] train loss: 1.359207908535609e-05 \n",
      "epoch: 22 [885467/888800 99.62%] train loss: 1.3324716746865306e-05 \n",
      "epoch: 22 [886578/888800 99.75%] train loss: 1.3248941286292393e-05 \n",
      "epoch: 22 [887689/888800 99.88%] train loss: 1.3289027265273035e-05 \n",
      "epoch: 23 [0/888800 0.00%] train loss: 1.3894548828830011e-05 \n",
      "epoch: 23 [1111/888800 0.12%] train loss: 1.4526882296195254e-05 \n",
      "epoch: 23 [2222/888800 0.25%] train loss: 1.3487378964782692e-05 \n",
      "epoch: 23 [3333/888800 0.38%] train loss: 1.4226942766981665e-05 \n",
      "epoch: 23 [4444/888800 0.50%] train loss: 1.419770524080377e-05 \n",
      "epoch: 23 [5555/888800 0.62%] train loss: 1.394874561810866e-05 \n",
      "epoch: 23 [6666/888800 0.75%] train loss: 1.4191971786203794e-05 \n",
      "epoch: 23 [7777/888800 0.88%] train loss: 1.2807003258785699e-05 \n",
      "epoch: 23 [8888/888800 1.00%] train loss: 1.3082871191727463e-05 \n",
      "epoch: 23 [9999/888800 1.12%] train loss: 1.3853627933713142e-05 \n",
      "epoch: 23 [11110/888800 1.25%] train loss: 1.4303733223641757e-05 \n",
      "epoch: 23 [12221/888800 1.38%] train loss: 1.4113036741036922e-05 \n",
      "epoch: 23 [13332/888800 1.50%] train loss: 1.4582557014364284e-05 \n",
      "epoch: 23 [14443/888800 1.62%] train loss: 1.4313685824163258e-05 \n",
      "epoch: 23 [15554/888800 1.75%] train loss: 1.5313280528062023e-05 \n",
      "epoch: 23 [16665/888800 1.88%] train loss: 1.5281502783182077e-05 \n",
      "epoch: 23 [17776/888800 2.00%] train loss: 1.4101692613621708e-05 \n",
      "epoch: 23 [18887/888800 2.12%] train loss: 1.3744738680543378e-05 \n",
      "epoch: 23 [19998/888800 2.25%] train loss: 1.3774886610917747e-05 \n",
      "epoch: 23 [21109/888800 2.38%] train loss: 1.3531426702684257e-05 \n",
      "epoch: 23 [22220/888800 2.50%] train loss: 1.374613020743709e-05 \n",
      "epoch: 23 [23331/888800 2.62%] train loss: 1.2970774150744546e-05 \n",
      "epoch: 23 [24442/888800 2.75%] train loss: 1.3041336387686897e-05 \n",
      "epoch: 23 [25553/888800 2.88%] train loss: 1.317534133704612e-05 \n",
      "epoch: 23 [26664/888800 3.00%] train loss: 1.3622249753098004e-05 \n",
      "epoch: 23 [27775/888800 3.12%] train loss: 1.3399723684415221e-05 \n",
      "epoch: 23 [28886/888800 3.25%] train loss: 1.3594492884294596e-05 \n",
      "epoch: 23 [29997/888800 3.38%] train loss: 1.4760898011445533e-05 \n",
      "epoch: 23 [31108/888800 3.50%] train loss: 1.3518421837943606e-05 \n",
      "epoch: 23 [32219/888800 3.62%] train loss: 1.5070749213919044e-05 \n",
      "epoch: 23 [33330/888800 3.75%] train loss: 1.4067258234717883e-05 \n",
      "epoch: 23 [34441/888800 3.88%] train loss: 1.5265333786373958e-05 \n",
      "epoch: 23 [35552/888800 4.00%] train loss: 1.5849382180022076e-05 \n",
      "epoch: 23 [36663/888800 4.12%] train loss: 1.45099256769754e-05 \n",
      "epoch: 23 [37774/888800 4.25%] train loss: 1.503152452642098e-05 \n",
      "epoch: 23 [38885/888800 4.38%] train loss: 1.552690810058266e-05 \n",
      "epoch: 23 [39996/888800 4.50%] train loss: 1.622657146072015e-05 \n",
      "epoch: 23 [41107/888800 4.62%] train loss: 1.3047443644609302e-05 \n",
      "epoch: 23 [42218/888800 4.75%] train loss: 1.463413082092302e-05 \n",
      "epoch: 23 [43329/888800 4.88%] train loss: 1.4421689229493495e-05 \n",
      "epoch: 23 [44440/888800 5.00%] train loss: 1.4180463949742261e-05 \n",
      "epoch: 23 [45551/888800 5.12%] train loss: 1.5182610695774201e-05 \n",
      "epoch: 23 [46662/888800 5.25%] train loss: 1.3645612852997147e-05 \n",
      "epoch: 23 [47773/888800 5.38%] train loss: 1.3425292308966164e-05 \n",
      "epoch: 23 [48884/888800 5.50%] train loss: 1.4264463970903307e-05 \n",
      "epoch: 23 [49995/888800 5.62%] train loss: 1.4916166946932208e-05 \n",
      "epoch: 23 [51106/888800 5.75%] train loss: 1.3307527297001798e-05 \n",
      "epoch: 23 [52217/888800 5.88%] train loss: 1.655540836509317e-05 \n",
      "epoch: 23 [53328/888800 6.00%] train loss: 1.4089809155848343e-05 \n",
      "epoch: 23 [54439/888800 6.12%] train loss: 1.5743833500891924e-05 \n",
      "epoch: 23 [55550/888800 6.25%] train loss: 1.4354175618791487e-05 \n",
      "epoch: 23 [56661/888800 6.38%] train loss: 1.654789775784593e-05 \n",
      "epoch: 23 [57772/888800 6.50%] train loss: 1.5893478121142834e-05 \n",
      "epoch: 23 [58883/888800 6.62%] train loss: 1.5761039321660064e-05 \n",
      "epoch: 23 [59994/888800 6.75%] train loss: 1.684110247879289e-05 \n",
      "epoch: 23 [61105/888800 6.88%] train loss: 1.4905202078807633e-05 \n",
      "epoch: 23 [62216/888800 7.00%] train loss: 1.7472604668000713e-05 \n",
      "epoch: 23 [63327/888800 7.12%] train loss: 1.3991359082865529e-05 \n",
      "epoch: 23 [64438/888800 7.25%] train loss: 1.6691486962372437e-05 \n",
      "epoch: 23 [65549/888800 7.38%] train loss: 1.4092884157435037e-05 \n",
      "epoch: 23 [66660/888800 7.50%] train loss: 1.7023610780597664e-05 \n",
      "epoch: 23 [67771/888800 7.62%] train loss: 1.5456471373909153e-05 \n",
      "epoch: 23 [68882/888800 7.75%] train loss: 1.4438946891459636e-05 \n",
      "epoch: 23 [69993/888800 7.88%] train loss: 1.5643407095922157e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [71104/888800 8.00%] train loss: 1.4464389096247032e-05 \n",
      "epoch: 23 [72215/888800 8.12%] train loss: 1.5248268937284593e-05 \n",
      "epoch: 23 [73326/888800 8.25%] train loss: 1.4043606824998278e-05 \n",
      "epoch: 23 [74437/888800 8.38%] train loss: 1.5199833796941675e-05 \n",
      "epoch: 23 [75548/888800 8.50%] train loss: 1.4296892913989723e-05 \n",
      "epoch: 23 [76659/888800 8.62%] train loss: 1.3396008398558479e-05 \n",
      "epoch: 23 [77770/888800 8.75%] train loss: 1.2857381989306305e-05 \n",
      "epoch: 23 [78881/888800 8.88%] train loss: 1.4223352991393767e-05 \n",
      "epoch: 23 [79992/888800 9.00%] train loss: 1.4211845154932234e-05 \n",
      "epoch: 23 [81103/888800 9.12%] train loss: 1.3804766240355093e-05 \n",
      "epoch: 23 [82214/888800 9.25%] train loss: 1.5106797036423814e-05 \n",
      "epoch: 23 [83325/888800 9.38%] train loss: 1.3596642929769587e-05 \n",
      "epoch: 23 [84436/888800 9.50%] train loss: 1.3318694982444867e-05 \n",
      "epoch: 23 [85547/888800 9.62%] train loss: 1.3022748134972062e-05 \n",
      "epoch: 23 [86658/888800 9.75%] train loss: 1.4843919416307472e-05 \n",
      "epoch: 23 [87769/888800 9.88%] train loss: 1.2911963494843803e-05 \n",
      "epoch: 23 [88880/888800 10.00%] train loss: 1.4721143998031039e-05 \n",
      "epoch: 23 [89991/888800 10.12%] train loss: 1.4929207281966228e-05 \n",
      "epoch: 23 [91102/888800 10.25%] train loss: 1.4061370166018605e-05 \n",
      "epoch: 23 [92213/888800 10.38%] train loss: 1.4292383639258333e-05 \n",
      "epoch: 23 [93324/888800 10.50%] train loss: 1.3320796824700665e-05 \n",
      "epoch: 23 [94435/888800 10.62%] train loss: 1.442859138478525e-05 \n",
      "epoch: 23 [95546/888800 10.75%] train loss: 1.45648673424148e-05 \n",
      "epoch: 23 [96657/888800 10.88%] train loss: 1.4872000065224711e-05 \n",
      "epoch: 23 [97768/888800 11.00%] train loss: 1.4386450857273303e-05 \n",
      "epoch: 23 [98879/888800 11.12%] train loss: 1.408967909810599e-05 \n",
      "epoch: 23 [99990/888800 11.25%] train loss: 1.3901279089623131e-05 \n",
      "epoch: 23 [101101/888800 11.38%] train loss: 1.5050396541482769e-05 \n",
      "epoch: 23 [102212/888800 11.50%] train loss: 1.4303794159786776e-05 \n",
      "epoch: 23 [103323/888800 11.62%] train loss: 1.429363874194678e-05 \n",
      "epoch: 23 [104434/888800 11.75%] train loss: 1.5082996469573118e-05 \n",
      "epoch: 23 [105545/888800 11.88%] train loss: 1.3520215361495502e-05 \n",
      "epoch: 23 [106656/888800 12.00%] train loss: 1.408500611432828e-05 \n",
      "epoch: 23 [107767/888800 12.12%] train loss: 1.4927470147085842e-05 \n",
      "epoch: 23 [108878/888800 12.25%] train loss: 1.3745440810453147e-05 \n",
      "epoch: 23 [109989/888800 12.38%] train loss: 1.5182913557509892e-05 \n",
      "epoch: 23 [111100/888800 12.50%] train loss: 1.293798050028272e-05 \n",
      "epoch: 23 [112211/888800 12.62%] train loss: 1.4510456821881235e-05 \n",
      "epoch: 23 [113322/888800 12.75%] train loss: 1.3720725291932467e-05 \n",
      "epoch: 23 [114433/888800 12.88%] train loss: 1.595865614945069e-05 \n",
      "epoch: 23 [115544/888800 13.00%] train loss: 1.4177875527821016e-05 \n",
      "epoch: 23 [116655/888800 13.12%] train loss: 1.3984261386212893e-05 \n",
      "epoch: 23 [117766/888800 13.25%] train loss: 1.3340276382223237e-05 \n",
      "epoch: 23 [118877/888800 13.38%] train loss: 1.4651961464551277e-05 \n",
      "epoch: 23 [119988/888800 13.50%] train loss: 1.3822686923958827e-05 \n",
      "epoch: 23 [121099/888800 13.62%] train loss: 1.3472499631461687e-05 \n",
      "epoch: 23 [122210/888800 13.75%] train loss: 1.4267344340623822e-05 \n",
      "epoch: 23 [123321/888800 13.88%] train loss: 1.4428597751248162e-05 \n",
      "epoch: 23 [124432/888800 14.00%] train loss: 1.3928814951214008e-05 \n",
      "epoch: 23 [125543/888800 14.12%] train loss: 1.431269174645422e-05 \n",
      "epoch: 23 [126654/888800 14.25%] train loss: 1.3359735021367669e-05 \n",
      "epoch: 23 [127765/888800 14.38%] train loss: 1.3876853699912317e-05 \n",
      "epoch: 23 [128876/888800 14.50%] train loss: 1.4140015082375612e-05 \n",
      "epoch: 23 [129987/888800 14.62%] train loss: 1.452048309147358e-05 \n",
      "epoch: 23 [131098/888800 14.75%] train loss: 1.3945676982984878e-05 \n",
      "epoch: 23 [132209/888800 14.88%] train loss: 1.3665970982401632e-05 \n",
      "epoch: 23 [133320/888800 15.00%] train loss: 1.4233159163268283e-05 \n",
      "epoch: 23 [134431/888800 15.12%] train loss: 1.5316139979404397e-05 \n",
      "epoch: 23 [135542/888800 15.25%] train loss: 1.4537055903929286e-05 \n",
      "epoch: 23 [136653/888800 15.38%] train loss: 1.4482807273452636e-05 \n",
      "epoch: 23 [137764/888800 15.50%] train loss: 1.3355922419577837e-05 \n",
      "epoch: 23 [138875/888800 15.62%] train loss: 1.3710253369936254e-05 \n",
      "epoch: 23 [139986/888800 15.75%] train loss: 1.4346203897730447e-05 \n",
      "epoch: 23 [141097/888800 15.88%] train loss: 1.3382465112954378e-05 \n",
      "epoch: 23 [142208/888800 16.00%] train loss: 1.4031063074071426e-05 \n",
      "epoch: 23 [143319/888800 16.12%] train loss: 1.3182513612264302e-05 \n",
      "epoch: 23 [144430/888800 16.25%] train loss: 1.542216159577947e-05 \n",
      "epoch: 23 [145541/888800 16.38%] train loss: 1.4036322681931779e-05 \n",
      "epoch: 23 [146652/888800 16.50%] train loss: 1.4822800949332304e-05 \n",
      "epoch: 23 [147763/888800 16.62%] train loss: 1.3756345651927404e-05 \n",
      "epoch: 23 [148874/888800 16.75%] train loss: 1.4309366633824538e-05 \n",
      "epoch: 23 [149985/888800 16.88%] train loss: 1.4984341760282405e-05 \n",
      "epoch: 23 [151096/888800 17.00%] train loss: 1.463044281990733e-05 \n",
      "epoch: 23 [152207/888800 17.12%] train loss: 1.4879403352097142e-05 \n",
      "epoch: 23 [153318/888800 17.25%] train loss: 1.3319350728124846e-05 \n",
      "epoch: 23 [154429/888800 17.38%] train loss: 1.3728025805903599e-05 \n",
      "epoch: 23 [155540/888800 17.50%] train loss: 1.3951157598057762e-05 \n",
      "epoch: 23 [156651/888800 17.62%] train loss: 1.3307522749528289e-05 \n",
      "epoch: 23 [157762/888800 17.75%] train loss: 1.353263360215351e-05 \n",
      "epoch: 23 [158873/888800 17.88%] train loss: 1.3105786820233334e-05 \n",
      "epoch: 23 [159984/888800 18.00%] train loss: 1.3623239283333533e-05 \n",
      "epoch: 23 [161095/888800 18.12%] train loss: 1.5013785741757601e-05 \n",
      "epoch: 23 [162206/888800 18.25%] train loss: 1.4614674910262693e-05 \n",
      "epoch: 23 [163317/888800 18.38%] train loss: 1.3492483958543744e-05 \n",
      "epoch: 23 [164428/888800 18.50%] train loss: 1.3556110388890374e-05 \n",
      "epoch: 23 [165539/888800 18.62%] train loss: 1.4004989679961e-05 \n",
      "epoch: 23 [166650/888800 18.75%] train loss: 1.5135385183384642e-05 \n",
      "epoch: 23 [167761/888800 18.88%] train loss: 1.4135462151898537e-05 \n",
      "epoch: 23 [168872/888800 19.00%] train loss: 1.3723007214139216e-05 \n",
      "epoch: 23 [169983/888800 19.12%] train loss: 1.4935105355107225e-05 \n",
      "epoch: 23 [171094/888800 19.25%] train loss: 1.3209655662649311e-05 \n",
      "epoch: 23 [172205/888800 19.38%] train loss: 1.5396459275507368e-05 \n",
      "epoch: 23 [173316/888800 19.50%] train loss: 1.4495324649033137e-05 \n",
      "epoch: 23 [174427/888800 19.62%] train loss: 1.4547899809258524e-05 \n",
      "epoch: 23 [175538/888800 19.75%] train loss: 1.3869316717318725e-05 \n",
      "epoch: 23 [176649/888800 19.88%] train loss: 1.4649498552898876e-05 \n",
      "epoch: 23 [177760/888800 20.00%] train loss: 1.4468981134996284e-05 \n",
      "epoch: 23 [178871/888800 20.12%] train loss: 1.3294064956426155e-05 \n",
      "epoch: 23 [179982/888800 20.25%] train loss: 1.5783596609253436e-05 \n",
      "epoch: 23 [181093/888800 20.38%] train loss: 1.4220959201338701e-05 \n",
      "epoch: 23 [182204/888800 20.50%] train loss: 1.4775371710129548e-05 \n",
      "epoch: 23 [183315/888800 20.62%] train loss: 1.4998287042544689e-05 \n",
      "epoch: 23 [184426/888800 20.75%] train loss: 1.4679647392767947e-05 \n",
      "epoch: 23 [185537/888800 20.88%] train loss: 1.3351653251447715e-05 \n",
      "epoch: 23 [186648/888800 21.00%] train loss: 1.5399495168821886e-05 \n",
      "epoch: 23 [187759/888800 21.12%] train loss: 1.6253099602181464e-05 \n",
      "epoch: 23 [188870/888800 21.25%] train loss: 1.4588363228540402e-05 \n",
      "epoch: 23 [189981/888800 21.38%] train loss: 1.5179768524831161e-05 \n",
      "epoch: 23 [191092/888800 21.50%] train loss: 1.4204265426087659e-05 \n",
      "epoch: 23 [192203/888800 21.62%] train loss: 1.7206144548254088e-05 \n",
      "epoch: 23 [193314/888800 21.75%] train loss: 1.3273156582727097e-05 \n",
      "epoch: 23 [194425/888800 21.88%] train loss: 1.5474348401767202e-05 \n",
      "epoch: 23 [195536/888800 22.00%] train loss: 1.351199080090737e-05 \n",
      "epoch: 23 [196647/888800 22.12%] train loss: 1.542214522487484e-05 \n",
      "epoch: 23 [197758/888800 22.25%] train loss: 1.4247066246753093e-05 \n",
      "epoch: 23 [198869/888800 22.38%] train loss: 1.4273071428760886e-05 \n",
      "epoch: 23 [199980/888800 22.50%] train loss: 1.5734378393972293e-05 \n",
      "epoch: 23 [201091/888800 22.62%] train loss: 1.4078559615882114e-05 \n",
      "epoch: 23 [202202/888800 22.75%] train loss: 1.6094769307528622e-05 \n",
      "epoch: 23 [203313/888800 22.88%] train loss: 1.5684045138186775e-05 \n",
      "epoch: 23 [204424/888800 23.00%] train loss: 1.4630280020355713e-05 \n",
      "epoch: 23 [205535/888800 23.12%] train loss: 1.4784374798182398e-05 \n",
      "epoch: 23 [206646/888800 23.25%] train loss: 1.560689452162478e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [207757/888800 23.38%] train loss: 1.5345738574978895e-05 \n",
      "epoch: 23 [208868/888800 23.50%] train loss: 1.3686230886378326e-05 \n",
      "epoch: 23 [209979/888800 23.62%] train loss: 1.519826128060231e-05 \n",
      "epoch: 23 [211090/888800 23.75%] train loss: 1.3556988051277585e-05 \n",
      "epoch: 23 [212201/888800 23.88%] train loss: 1.4715195902681444e-05 \n",
      "epoch: 23 [213312/888800 24.00%] train loss: 1.3732731531490572e-05 \n",
      "epoch: 23 [214423/888800 24.12%] train loss: 1.595159847056493e-05 \n",
      "epoch: 23 [215534/888800 24.25%] train loss: 1.4025471500644926e-05 \n",
      "epoch: 23 [216645/888800 24.38%] train loss: 1.4605656360799912e-05 \n",
      "epoch: 23 [217756/888800 24.50%] train loss: 1.4585068129235879e-05 \n",
      "epoch: 23 [218867/888800 24.62%] train loss: 1.2987059562874492e-05 \n",
      "epoch: 23 [219978/888800 24.75%] train loss: 1.4298520000011194e-05 \n",
      "epoch: 23 [221089/888800 24.88%] train loss: 1.3251018572191242e-05 \n",
      "epoch: 23 [222200/888800 25.00%] train loss: 1.3440675502351951e-05 \n",
      "epoch: 23 [223311/888800 25.12%] train loss: 1.3411213330982719e-05 \n",
      "epoch: 23 [224422/888800 25.25%] train loss: 1.4994116099842358e-05 \n",
      "epoch: 23 [225533/888800 25.38%] train loss: 1.313085977017181e-05 \n",
      "epoch: 23 [226644/888800 25.50%] train loss: 1.4461564205703326e-05 \n",
      "epoch: 23 [227755/888800 25.62%] train loss: 1.3286801731737796e-05 \n",
      "epoch: 23 [228866/888800 25.75%] train loss: 1.4183052371663507e-05 \n",
      "epoch: 23 [229977/888800 25.88%] train loss: 1.443475230189506e-05 \n",
      "epoch: 23 [231088/888800 26.00%] train loss: 1.4209548680810258e-05 \n",
      "epoch: 23 [232199/888800 26.12%] train loss: 1.4322088645712938e-05 \n",
      "epoch: 23 [233310/888800 26.25%] train loss: 1.4273256056185346e-05 \n",
      "epoch: 23 [234421/888800 26.38%] train loss: 1.3648404092236888e-05 \n",
      "epoch: 23 [235532/888800 26.50%] train loss: 1.4564095181412995e-05 \n",
      "epoch: 23 [236643/888800 26.62%] train loss: 1.4624430150433909e-05 \n",
      "epoch: 23 [237754/888800 26.75%] train loss: 1.4814665519224945e-05 \n",
      "epoch: 23 [238865/888800 26.88%] train loss: 1.3596366443380248e-05 \n",
      "epoch: 23 [239976/888800 27.00%] train loss: 1.5715408153482713e-05 \n",
      "epoch: 23 [241087/888800 27.12%] train loss: 1.3473335457092617e-05 \n",
      "epoch: 23 [242198/888800 27.25%] train loss: 1.501569840911543e-05 \n",
      "epoch: 23 [243309/888800 27.38%] train loss: 1.4985399502620567e-05 \n",
      "epoch: 23 [244420/888800 27.50%] train loss: 1.4476179785560817e-05 \n",
      "epoch: 23 [245531/888800 27.62%] train loss: 1.4727463167218957e-05 \n",
      "epoch: 23 [246642/888800 27.75%] train loss: 1.3455024600261822e-05 \n",
      "epoch: 23 [247753/888800 27.88%] train loss: 1.4208006177796051e-05 \n",
      "epoch: 23 [248864/888800 28.00%] train loss: 1.5421352145494893e-05 \n",
      "epoch: 23 [249975/888800 28.12%] train loss: 1.4296584595285822e-05 \n",
      "epoch: 23 [251086/888800 28.25%] train loss: 1.308864557358902e-05 \n",
      "epoch: 23 [252197/888800 28.38%] train loss: 1.4643398571934085e-05 \n",
      "epoch: 23 [253308/888800 28.50%] train loss: 1.4252491382649168e-05 \n",
      "epoch: 23 [254419/888800 28.62%] train loss: 1.4901295799063519e-05 \n",
      "epoch: 23 [255530/888800 28.75%] train loss: 1.4245617421693169e-05 \n",
      "epoch: 23 [256641/888800 28.88%] train loss: 1.500564394518733e-05 \n",
      "epoch: 23 [257752/888800 29.00%] train loss: 1.4364361049956642e-05 \n",
      "epoch: 23 [258863/888800 29.12%] train loss: 1.3896275959268678e-05 \n",
      "epoch: 23 [259974/888800 29.25%] train loss: 1.3725024473387748e-05 \n",
      "epoch: 23 [261085/888800 29.38%] train loss: 1.3789004697173368e-05 \n",
      "epoch: 23 [262196/888800 29.50%] train loss: 1.4468762856267858e-05 \n",
      "epoch: 23 [263307/888800 29.62%] train loss: 1.507974047854077e-05 \n",
      "epoch: 23 [264418/888800 29.75%] train loss: 1.4575636669178493e-05 \n",
      "epoch: 23 [265529/888800 29.88%] train loss: 1.4048657249077223e-05 \n",
      "epoch: 23 [266640/888800 30.00%] train loss: 1.3502969522960484e-05 \n",
      "epoch: 23 [267751/888800 30.12%] train loss: 1.459490795241436e-05 \n",
      "epoch: 23 [268862/888800 30.25%] train loss: 1.3763348761131056e-05 \n",
      "epoch: 23 [269973/888800 30.38%] train loss: 1.2701601008302532e-05 \n",
      "epoch: 23 [271084/888800 30.50%] train loss: 1.3444782780425157e-05 \n",
      "epoch: 23 [272195/888800 30.62%] train loss: 1.3944410056865308e-05 \n",
      "epoch: 23 [273306/888800 30.75%] train loss: 1.4462368199019693e-05 \n",
      "epoch: 23 [274417/888800 30.88%] train loss: 1.5098980838956777e-05 \n",
      "epoch: 23 [275528/888800 31.00%] train loss: 1.3581238818005659e-05 \n",
      "epoch: 23 [276639/888800 31.12%] train loss: 1.3982185919303447e-05 \n",
      "epoch: 23 [277750/888800 31.25%] train loss: 1.3338588360056747e-05 \n",
      "epoch: 23 [278861/888800 31.38%] train loss: 1.470573988626711e-05 \n",
      "epoch: 23 [279972/888800 31.50%] train loss: 1.426748167432379e-05 \n",
      "epoch: 23 [281083/888800 31.62%] train loss: 1.478497051721206e-05 \n",
      "epoch: 23 [282194/888800 31.75%] train loss: 1.4126093446975574e-05 \n",
      "epoch: 23 [283305/888800 31.88%] train loss: 1.3675076843355782e-05 \n",
      "epoch: 23 [284416/888800 32.00%] train loss: 1.512833023298299e-05 \n",
      "epoch: 23 [285527/888800 32.12%] train loss: 1.3243966350273695e-05 \n",
      "epoch: 23 [286638/888800 32.25%] train loss: 1.3491955542122014e-05 \n",
      "epoch: 23 [287749/888800 32.38%] train loss: 1.4049976016394794e-05 \n",
      "epoch: 23 [288860/888800 32.50%] train loss: 1.3345763363759033e-05 \n",
      "epoch: 23 [289971/888800 32.62%] train loss: 1.460548082832247e-05 \n",
      "epoch: 23 [291082/888800 32.75%] train loss: 1.4380660104507115e-05 \n",
      "epoch: 23 [292193/888800 32.88%] train loss: 1.3864346328773536e-05 \n",
      "epoch: 23 [293304/888800 33.00%] train loss: 1.5119149793463293e-05 \n",
      "epoch: 23 [294415/888800 33.12%] train loss: 1.4737946003151592e-05 \n",
      "epoch: 23 [295526/888800 33.25%] train loss: 1.2983371561858803e-05 \n",
      "epoch: 23 [296637/888800 33.38%] train loss: 1.4729905160493217e-05 \n",
      "epoch: 23 [297748/888800 33.50%] train loss: 1.3858775673725177e-05 \n",
      "epoch: 23 [298859/888800 33.62%] train loss: 1.3693203072762117e-05 \n",
      "epoch: 23 [299970/888800 33.75%] train loss: 1.4139810446067713e-05 \n",
      "epoch: 23 [301081/888800 33.88%] train loss: 1.3944494639872573e-05 \n",
      "epoch: 23 [302192/888800 34.00%] train loss: 1.3960982869321015e-05 \n",
      "epoch: 23 [303303/888800 34.12%] train loss: 1.5043649909785017e-05 \n",
      "epoch: 23 [304414/888800 34.25%] train loss: 1.3739617315877695e-05 \n",
      "epoch: 23 [305525/888800 34.38%] train loss: 1.5027095287223347e-05 \n",
      "epoch: 23 [306636/888800 34.50%] train loss: 1.5293317119358107e-05 \n",
      "epoch: 23 [307747/888800 34.62%] train loss: 1.530746703792829e-05 \n",
      "epoch: 23 [308858/888800 34.75%] train loss: 1.3949695130577311e-05 \n",
      "epoch: 23 [309969/888800 34.88%] train loss: 1.5790177712915465e-05 \n",
      "epoch: 23 [311080/888800 35.00%] train loss: 1.4171782822813839e-05 \n",
      "epoch: 23 [312191/888800 35.12%] train loss: 1.598439303052146e-05 \n",
      "epoch: 23 [313302/888800 35.25%] train loss: 1.4090401236899197e-05 \n",
      "epoch: 23 [314413/888800 35.38%] train loss: 1.5029538189992309e-05 \n",
      "epoch: 23 [315524/888800 35.50%] train loss: 1.4068468772165943e-05 \n",
      "epoch: 23 [316635/888800 35.62%] train loss: 1.4417381862585898e-05 \n",
      "epoch: 23 [317746/888800 35.75%] train loss: 1.436313868907746e-05 \n",
      "epoch: 23 [318857/888800 35.88%] train loss: 1.545864506624639e-05 \n",
      "epoch: 23 [319968/888800 36.00%] train loss: 1.434605655958876e-05 \n",
      "epoch: 23 [321079/888800 36.12%] train loss: 1.4290076251199935e-05 \n",
      "epoch: 23 [322190/888800 36.25%] train loss: 1.3144024705979973e-05 \n",
      "epoch: 23 [323301/888800 36.38%] train loss: 1.3550816220231354e-05 \n",
      "epoch: 23 [324412/888800 36.50%] train loss: 1.2622121175809298e-05 \n",
      "epoch: 23 [325523/888800 36.62%] train loss: 1.394755054207053e-05 \n",
      "epoch: 23 [326634/888800 36.75%] train loss: 1.4102433851803653e-05 \n",
      "epoch: 23 [327745/888800 36.88%] train loss: 1.3887365639675409e-05 \n",
      "epoch: 23 [328856/888800 37.00%] train loss: 1.4007048775965814e-05 \n",
      "epoch: 23 [329967/888800 37.12%] train loss: 1.321091713180067e-05 \n",
      "epoch: 23 [331078/888800 37.25%] train loss: 1.5066085325088352e-05 \n",
      "epoch: 23 [332189/888800 37.38%] train loss: 1.4970102711231448e-05 \n",
      "epoch: 23 [333300/888800 37.50%] train loss: 1.3414525710686576e-05 \n",
      "epoch: 23 [334411/888800 37.62%] train loss: 1.3901542843086645e-05 \n",
      "epoch: 23 [335522/888800 37.75%] train loss: 1.3654748727276456e-05 \n",
      "epoch: 23 [336633/888800 37.88%] train loss: 1.2098186743969563e-05 \n",
      "epoch: 23 [337744/888800 38.00%] train loss: 1.3616492651635781e-05 \n",
      "epoch: 23 [338855/888800 38.12%] train loss: 1.3903860235586762e-05 \n",
      "epoch: 23 [339966/888800 38.25%] train loss: 1.4958350220695138e-05 \n",
      "epoch: 23 [341077/888800 38.38%] train loss: 1.371063081023749e-05 \n",
      "epoch: 23 [342188/888800 38.50%] train loss: 1.3820575986756012e-05 \n",
      "epoch: 23 [343299/888800 38.62%] train loss: 1.3427324120129924e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [344410/888800 38.75%] train loss: 1.2680640793405473e-05 \n",
      "epoch: 23 [345521/888800 38.88%] train loss: 1.4399252904695459e-05 \n",
      "epoch: 23 [346632/888800 39.00%] train loss: 1.4186433872964699e-05 \n",
      "epoch: 23 [347743/888800 39.12%] train loss: 1.373723443975905e-05 \n",
      "epoch: 23 [348854/888800 39.25%] train loss: 1.4227141946321353e-05 \n",
      "epoch: 23 [349965/888800 39.38%] train loss: 1.3800105989503209e-05 \n",
      "epoch: 23 [351076/888800 39.50%] train loss: 1.4414154065889306e-05 \n",
      "epoch: 23 [352187/888800 39.62%] train loss: 1.317418173130136e-05 \n",
      "epoch: 23 [353298/888800 39.75%] train loss: 1.4065023606235627e-05 \n",
      "epoch: 23 [354409/888800 39.88%] train loss: 1.2834427252528258e-05 \n",
      "epoch: 23 [355520/888800 40.00%] train loss: 1.4679100786452182e-05 \n",
      "epoch: 23 [356631/888800 40.12%] train loss: 1.485843131376896e-05 \n",
      "epoch: 23 [357742/888800 40.25%] train loss: 1.4530654880218208e-05 \n",
      "epoch: 23 [358853/888800 40.38%] train loss: 1.4570407074643299e-05 \n",
      "epoch: 23 [359964/888800 40.50%] train loss: 1.5104266822163481e-05 \n",
      "epoch: 23 [361075/888800 40.62%] train loss: 1.3900076737627387e-05 \n",
      "epoch: 23 [362186/888800 40.75%] train loss: 1.3511448742065113e-05 \n",
      "epoch: 23 [363297/888800 40.88%] train loss: 1.3674177353095729e-05 \n",
      "epoch: 23 [364408/888800 41.00%] train loss: 1.5367242667707615e-05 \n",
      "epoch: 23 [365519/888800 41.12%] train loss: 1.4197591553966049e-05 \n",
      "epoch: 23 [366630/888800 41.25%] train loss: 1.4745674889127258e-05 \n",
      "epoch: 23 [367741/888800 41.38%] train loss: 1.46879847306991e-05 \n",
      "epoch: 23 [368852/888800 41.50%] train loss: 1.3794427104585338e-05 \n",
      "epoch: 23 [369963/888800 41.62%] train loss: 1.3903918443247676e-05 \n",
      "epoch: 23 [371074/888800 41.75%] train loss: 1.332371357420925e-05 \n",
      "epoch: 23 [372185/888800 41.88%] train loss: 1.3324295650818385e-05 \n",
      "epoch: 23 [373296/888800 42.00%] train loss: 1.205488842970226e-05 \n",
      "epoch: 23 [374407/888800 42.12%] train loss: 1.3216224033385515e-05 \n",
      "epoch: 23 [375518/888800 42.25%] train loss: 1.3854743883712217e-05 \n",
      "epoch: 23 [376629/888800 42.38%] train loss: 1.588679697306361e-05 \n",
      "epoch: 23 [377740/888800 42.50%] train loss: 1.5633315342711285e-05 \n",
      "epoch: 23 [378851/888800 42.62%] train loss: 1.4939013453840744e-05 \n",
      "epoch: 23 [379962/888800 42.75%] train loss: 1.6394798876717687e-05 \n",
      "epoch: 23 [381073/888800 42.88%] train loss: 1.4051177458895836e-05 \n",
      "epoch: 23 [382184/888800 43.00%] train loss: 1.6224863429670222e-05 \n",
      "epoch: 23 [383295/888800 43.12%] train loss: 1.4378117157320958e-05 \n",
      "epoch: 23 [384406/888800 43.25%] train loss: 1.4413527424039785e-05 \n",
      "epoch: 23 [385517/888800 43.38%] train loss: 1.4720070794282947e-05 \n",
      "epoch: 23 [386628/888800 43.50%] train loss: 1.5145006727834698e-05 \n",
      "epoch: 23 [387739/888800 43.62%] train loss: 1.5056366464705206e-05 \n",
      "epoch: 23 [388850/888800 43.75%] train loss: 1.5623147191945463e-05 \n",
      "epoch: 23 [389961/888800 43.88%] train loss: 1.5943920516292565e-05 \n",
      "epoch: 23 [391072/888800 44.00%] train loss: 1.4760150406800676e-05 \n",
      "epoch: 23 [392183/888800 44.12%] train loss: 1.6440730178146623e-05 \n",
      "epoch: 23 [393294/888800 44.25%] train loss: 1.4892193576088175e-05 \n",
      "epoch: 23 [394405/888800 44.38%] train loss: 1.6251709894277155e-05 \n",
      "epoch: 23 [395516/888800 44.50%] train loss: 1.6050489648478106e-05 \n",
      "epoch: 23 [396627/888800 44.62%] train loss: 1.4830618965788744e-05 \n",
      "epoch: 23 [397738/888800 44.75%] train loss: 1.5314450138248503e-05 \n",
      "epoch: 23 [398849/888800 44.88%] train loss: 1.681670437392313e-05 \n",
      "epoch: 23 [399960/888800 45.00%] train loss: 1.468234677304281e-05 \n",
      "epoch: 23 [401071/888800 45.12%] train loss: 1.5123280718398746e-05 \n",
      "epoch: 23 [402182/888800 45.25%] train loss: 1.6251668057520874e-05 \n",
      "epoch: 23 [403293/888800 45.38%] train loss: 1.54234076035209e-05 \n",
      "epoch: 23 [404404/888800 45.50%] train loss: 1.5530948076047935e-05 \n",
      "epoch: 23 [405515/888800 45.62%] train loss: 1.4952346646168735e-05 \n",
      "epoch: 23 [406626/888800 45.75%] train loss: 1.6872210835572332e-05 \n",
      "epoch: 23 [407737/888800 45.88%] train loss: 1.350370621366892e-05 \n",
      "epoch: 23 [408848/888800 46.00%] train loss: 1.603861528565176e-05 \n",
      "epoch: 23 [409959/888800 46.12%] train loss: 1.4369300515681971e-05 \n",
      "epoch: 23 [411070/888800 46.25%] train loss: 1.4745651242265012e-05 \n",
      "epoch: 23 [412181/888800 46.38%] train loss: 1.53103446791647e-05 \n",
      "epoch: 23 [413292/888800 46.50%] train loss: 1.412352139595896e-05 \n",
      "epoch: 23 [414403/888800 46.62%] train loss: 1.4593203559343237e-05 \n",
      "epoch: 23 [415514/888800 46.75%] train loss: 1.4398567145690322e-05 \n",
      "epoch: 23 [416625/888800 46.88%] train loss: 1.395019262417918e-05 \n",
      "epoch: 23 [417736/888800 47.00%] train loss: 1.3870793736714404e-05 \n",
      "epoch: 23 [418847/888800 47.12%] train loss: 1.429073017789051e-05 \n",
      "epoch: 23 [419958/888800 47.25%] train loss: 1.403220358042745e-05 \n",
      "epoch: 23 [421069/888800 47.38%] train loss: 1.4477175682259258e-05 \n",
      "epoch: 23 [422180/888800 47.50%] train loss: 1.5190587873803452e-05 \n",
      "epoch: 23 [423291/888800 47.62%] train loss: 1.3595968084700871e-05 \n",
      "epoch: 23 [424402/888800 47.75%] train loss: 1.3285419299791101e-05 \n",
      "epoch: 23 [425513/888800 47.88%] train loss: 1.434064415661851e-05 \n",
      "epoch: 23 [426624/888800 48.00%] train loss: 1.4753001778444741e-05 \n",
      "epoch: 23 [427735/888800 48.12%] train loss: 1.3216006664151791e-05 \n",
      "epoch: 23 [428846/888800 48.25%] train loss: 1.4912201550032478e-05 \n",
      "epoch: 23 [429957/888800 48.38%] train loss: 1.4766030290047638e-05 \n",
      "epoch: 23 [431068/888800 48.50%] train loss: 1.4038404515304137e-05 \n",
      "epoch: 23 [432179/888800 48.62%] train loss: 1.4965279660827946e-05 \n",
      "epoch: 23 [433290/888800 48.75%] train loss: 1.4126878340903204e-05 \n",
      "epoch: 23 [434401/888800 48.88%] train loss: 1.471636369387852e-05 \n",
      "epoch: 23 [435512/888800 49.00%] train loss: 1.3783263966615777e-05 \n",
      "epoch: 23 [436623/888800 49.12%] train loss: 1.462522050132975e-05 \n",
      "epoch: 23 [437734/888800 49.25%] train loss: 1.3972717169963289e-05 \n",
      "epoch: 23 [438845/888800 49.38%] train loss: 1.3319488971319515e-05 \n",
      "epoch: 23 [439956/888800 49.50%] train loss: 1.4966290109441616e-05 \n",
      "epoch: 23 [441067/888800 49.62%] train loss: 1.3710676284972578e-05 \n",
      "epoch: 23 [442178/888800 49.75%] train loss: 1.347395755146863e-05 \n",
      "epoch: 23 [443289/888800 49.88%] train loss: 1.5011602954473346e-05 \n",
      "epoch: 23 [444400/888800 50.00%] train loss: 1.3255976227810606e-05 \n",
      "epoch: 23 [445511/888800 50.12%] train loss: 1.5044848623801954e-05 \n",
      "epoch: 23 [446622/888800 50.25%] train loss: 1.3772242709819693e-05 \n",
      "epoch: 23 [447733/888800 50.38%] train loss: 1.3748753190157004e-05 \n",
      "epoch: 23 [448844/888800 50.50%] train loss: 1.4980079868109897e-05 \n",
      "epoch: 23 [449955/888800 50.62%] train loss: 1.5930809240671806e-05 \n",
      "epoch: 23 [451066/888800 50.75%] train loss: 1.4660647138953209e-05 \n",
      "epoch: 23 [452177/888800 50.88%] train loss: 1.4260656826081686e-05 \n",
      "epoch: 23 [453288/888800 51.00%] train loss: 1.4422093045141082e-05 \n",
      "epoch: 23 [454399/888800 51.12%] train loss: 1.3883371138945222e-05 \n",
      "epoch: 23 [455510/888800 51.25%] train loss: 1.4294224456534721e-05 \n",
      "epoch: 23 [456621/888800 51.38%] train loss: 1.449876344850054e-05 \n",
      "epoch: 23 [457732/888800 51.50%] train loss: 1.567580875416752e-05 \n",
      "epoch: 23 [458843/888800 51.62%] train loss: 1.3117790331307333e-05 \n",
      "epoch: 23 [459954/888800 51.75%] train loss: 1.3803183719574008e-05 \n",
      "epoch: 23 [461065/888800 51.88%] train loss: 1.4783778169658035e-05 \n",
      "epoch: 23 [462176/888800 52.00%] train loss: 1.4331081729324069e-05 \n",
      "epoch: 23 [463287/888800 52.12%] train loss: 1.4614108295063488e-05 \n",
      "epoch: 23 [464398/888800 52.25%] train loss: 1.4410326912184246e-05 \n",
      "epoch: 23 [465509/888800 52.38%] train loss: 1.3251118616608437e-05 \n",
      "epoch: 23 [466620/888800 52.50%] train loss: 1.4046377145859879e-05 \n",
      "epoch: 23 [467731/888800 52.62%] train loss: 1.355570839223219e-05 \n",
      "epoch: 23 [468842/888800 52.75%] train loss: 1.5159770555328578e-05 \n",
      "epoch: 23 [469953/888800 52.88%] train loss: 1.401722511218395e-05 \n",
      "epoch: 23 [471064/888800 53.00%] train loss: 1.4983413166191895e-05 \n",
      "epoch: 23 [472175/888800 53.12%] train loss: 1.4196800293575507e-05 \n",
      "epoch: 23 [473286/888800 53.25%] train loss: 1.459627765143523e-05 \n",
      "epoch: 23 [474397/888800 53.38%] train loss: 1.3935521565144882e-05 \n",
      "epoch: 23 [475508/888800 53.50%] train loss: 1.3776418199995533e-05 \n",
      "epoch: 23 [476619/888800 53.62%] train loss: 1.4279973584052641e-05 \n",
      "epoch: 23 [477730/888800 53.75%] train loss: 1.4934501450625248e-05 \n",
      "epoch: 23 [478841/888800 53.88%] train loss: 1.3670155567524489e-05 \n",
      "epoch: 23 [479952/888800 54.00%] train loss: 1.580096250108909e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [481063/888800 54.12%] train loss: 1.3151265193300787e-05 \n",
      "epoch: 23 [482174/888800 54.25%] train loss: 1.5347954104072414e-05 \n",
      "epoch: 23 [483285/888800 54.38%] train loss: 1.4047776858205907e-05 \n",
      "epoch: 23 [484396/888800 54.50%] train loss: 1.5429472114192322e-05 \n",
      "epoch: 23 [485507/888800 54.62%] train loss: 1.3578177458839491e-05 \n",
      "epoch: 23 [486618/888800 54.75%] train loss: 1.500576672697207e-05 \n",
      "epoch: 23 [487729/888800 54.88%] train loss: 1.367079767078394e-05 \n",
      "epoch: 23 [488840/888800 55.00%] train loss: 1.4327287317428272e-05 \n",
      "epoch: 23 [489951/888800 55.12%] train loss: 1.520623300166335e-05 \n",
      "epoch: 23 [491062/888800 55.25%] train loss: 1.3791984201816376e-05 \n",
      "epoch: 23 [492173/888800 55.38%] train loss: 1.4740170627192128e-05 \n",
      "epoch: 23 [493284/888800 55.50%] train loss: 1.3758063687419053e-05 \n",
      "epoch: 23 [494395/888800 55.62%] train loss: 1.4862270290905144e-05 \n",
      "epoch: 23 [495506/888800 55.75%] train loss: 1.3812106772093102e-05 \n",
      "epoch: 23 [496617/888800 55.88%] train loss: 1.5091460227267817e-05 \n",
      "epoch: 23 [497728/888800 56.00%] train loss: 1.4155545613903087e-05 \n",
      "epoch: 23 [498839/888800 56.12%] train loss: 1.4409275536308996e-05 \n",
      "epoch: 23 [499950/888800 56.25%] train loss: 1.7008478607749566e-05 \n",
      "epoch: 23 [501061/888800 56.38%] train loss: 1.4891054888721555e-05 \n",
      "epoch: 23 [502172/888800 56.50%] train loss: 1.5864556189626455e-05 \n",
      "epoch: 23 [503283/888800 56.62%] train loss: 1.4254755114961881e-05 \n",
      "epoch: 23 [504394/888800 56.75%] train loss: 1.5617120880051516e-05 \n",
      "epoch: 23 [505505/888800 56.88%] train loss: 1.4375083992490545e-05 \n",
      "epoch: 23 [506616/888800 57.00%] train loss: 1.3646089428220876e-05 \n",
      "epoch: 23 [507727/888800 57.12%] train loss: 1.5466048353118822e-05 \n",
      "epoch: 23 [508838/888800 57.25%] train loss: 1.5221871763060335e-05 \n",
      "epoch: 23 [509949/888800 57.38%] train loss: 1.550810702610761e-05 \n",
      "epoch: 23 [511060/888800 57.50%] train loss: 1.429913299944019e-05 \n",
      "epoch: 23 [512171/888800 57.62%] train loss: 1.4590037608286366e-05 \n",
      "epoch: 23 [513282/888800 57.75%] train loss: 1.4560795534634963e-05 \n",
      "epoch: 23 [514393/888800 57.88%] train loss: 1.3729654710914474e-05 \n",
      "epoch: 23 [515504/888800 58.00%] train loss: 1.596893162059132e-05 \n",
      "epoch: 23 [516615/888800 58.12%] train loss: 1.4877492503728718e-05 \n",
      "epoch: 23 [517726/888800 58.25%] train loss: 1.4526365703204647e-05 \n",
      "epoch: 23 [518837/888800 58.38%] train loss: 1.4229332009563223e-05 \n",
      "epoch: 23 [519948/888800 58.50%] train loss: 1.5518386135227047e-05 \n",
      "epoch: 23 [521059/888800 58.62%] train loss: 1.4982638276705984e-05 \n",
      "epoch: 23 [522170/888800 58.75%] train loss: 1.3273403055791277e-05 \n",
      "epoch: 23 [523281/888800 58.88%] train loss: 1.383666221954627e-05 \n",
      "epoch: 23 [524392/888800 59.00%] train loss: 1.3937346011516638e-05 \n",
      "epoch: 23 [525503/888800 59.12%] train loss: 1.3941183169663418e-05 \n",
      "epoch: 23 [526614/888800 59.25%] train loss: 1.3380396012507845e-05 \n",
      "epoch: 23 [527725/888800 59.38%] train loss: 1.4867127902107313e-05 \n",
      "epoch: 23 [528836/888800 59.50%] train loss: 1.5150273611652665e-05 \n",
      "epoch: 23 [529947/888800 59.62%] train loss: 1.4491047295450699e-05 \n",
      "epoch: 23 [531058/888800 59.75%] train loss: 1.4462816579907667e-05 \n",
      "epoch: 23 [532169/888800 59.88%] train loss: 1.3777525964542292e-05 \n",
      "epoch: 23 [533280/888800 60.00%] train loss: 1.590754254721105e-05 \n",
      "epoch: 23 [534391/888800 60.12%] train loss: 1.455598703614669e-05 \n",
      "epoch: 23 [535502/888800 60.25%] train loss: 1.454071025364101e-05 \n",
      "epoch: 23 [536613/888800 60.38%] train loss: 1.4768099390494172e-05 \n",
      "epoch: 23 [537724/888800 60.50%] train loss: 1.4542246390192304e-05 \n",
      "epoch: 23 [538835/888800 60.62%] train loss: 1.5930752852000296e-05 \n",
      "epoch: 23 [539946/888800 60.75%] train loss: 1.51809172166395e-05 \n",
      "epoch: 23 [541057/888800 60.88%] train loss: 1.506040007370757e-05 \n",
      "epoch: 23 [542168/888800 61.00%] train loss: 1.47646769619314e-05 \n",
      "epoch: 23 [543279/888800 61.12%] train loss: 1.3192360711400397e-05 \n",
      "epoch: 23 [544390/888800 61.25%] train loss: 1.4407964954443742e-05 \n",
      "epoch: 23 [545501/888800 61.38%] train loss: 1.268329651793465e-05 \n",
      "epoch: 23 [546612/888800 61.50%] train loss: 1.4954364814911969e-05 \n",
      "epoch: 23 [547723/888800 61.62%] train loss: 1.4720684703206643e-05 \n",
      "epoch: 23 [548834/888800 61.75%] train loss: 1.4301607734523714e-05 \n",
      "epoch: 23 [549945/888800 61.88%] train loss: 1.4089516298554372e-05 \n",
      "epoch: 23 [551056/888800 62.00%] train loss: 1.531740781501867e-05 \n",
      "epoch: 23 [552167/888800 62.12%] train loss: 1.4458803889283445e-05 \n",
      "epoch: 23 [553278/888800 62.25%] train loss: 1.3310918802744709e-05 \n",
      "epoch: 23 [554389/888800 62.38%] train loss: 1.3095999747747555e-05 \n",
      "epoch: 23 [555500/888800 62.50%] train loss: 1.3898505130782723e-05 \n",
      "epoch: 23 [556611/888800 62.62%] train loss: 1.4366902178153396e-05 \n",
      "epoch: 23 [557722/888800 62.75%] train loss: 1.4349949196912348e-05 \n",
      "epoch: 23 [558833/888800 62.88%] train loss: 1.5816976883797906e-05 \n",
      "epoch: 23 [559944/888800 63.00%] train loss: 1.4138653568807058e-05 \n",
      "epoch: 23 [561055/888800 63.12%] train loss: 1.509333469584817e-05 \n",
      "epoch: 23 [562166/888800 63.25%] train loss: 1.528786015114747e-05 \n",
      "epoch: 23 [563277/888800 63.38%] train loss: 1.4477298464043997e-05 \n",
      "epoch: 23 [564388/888800 63.50%] train loss: 1.6561647498747334e-05 \n",
      "epoch: 23 [565499/888800 63.62%] train loss: 1.3992369531479198e-05 \n",
      "epoch: 23 [566610/888800 63.75%] train loss: 1.6233540009125136e-05 \n",
      "epoch: 23 [567721/888800 63.88%] train loss: 1.4088021998759359e-05 \n",
      "epoch: 23 [568832/888800 64.00%] train loss: 1.5013510164862964e-05 \n",
      "epoch: 23 [569943/888800 64.12%] train loss: 1.4834642570349388e-05 \n",
      "epoch: 23 [571054/888800 64.25%] train loss: 1.4156697034195531e-05 \n",
      "epoch: 23 [572165/888800 64.38%] train loss: 1.4341502719616983e-05 \n",
      "epoch: 23 [573276/888800 64.50%] train loss: 1.5537472791038454e-05 \n",
      "epoch: 23 [574387/888800 64.62%] train loss: 1.417225576005876e-05 \n",
      "epoch: 23 [575498/888800 64.75%] train loss: 1.4339041626953986e-05 \n",
      "epoch: 23 [576609/888800 64.88%] train loss: 1.339049958914984e-05 \n",
      "epoch: 23 [577720/888800 65.00%] train loss: 1.3942243640485685e-05 \n",
      "epoch: 23 [578831/888800 65.12%] train loss: 1.492082083132118e-05 \n",
      "epoch: 23 [579942/888800 65.25%] train loss: 1.4670813470729627e-05 \n",
      "epoch: 23 [581053/888800 65.38%] train loss: 1.4892861145199277e-05 \n",
      "epoch: 23 [582164/888800 65.50%] train loss: 1.444032841391163e-05 \n",
      "epoch: 23 [583275/888800 65.62%] train loss: 1.4750372429261915e-05 \n",
      "epoch: 23 [584386/888800 65.75%] train loss: 1.2882148439530283e-05 \n",
      "epoch: 23 [585497/888800 65.88%] train loss: 1.3846448382537346e-05 \n",
      "epoch: 23 [586608/888800 66.00%] train loss: 1.3467339158523828e-05 \n",
      "epoch: 23 [587719/888800 66.12%] train loss: 1.375474312226288e-05 \n",
      "epoch: 23 [588830/888800 66.25%] train loss: 1.4508836102322675e-05 \n",
      "epoch: 23 [589941/888800 66.38%] train loss: 1.3322577615326736e-05 \n",
      "epoch: 23 [591052/888800 66.50%] train loss: 1.3102010598231573e-05 \n",
      "epoch: 23 [592163/888800 66.62%] train loss: 1.4777572687307838e-05 \n",
      "epoch: 23 [593274/888800 66.75%] train loss: 1.3780841982224956e-05 \n",
      "epoch: 23 [594385/888800 66.88%] train loss: 1.3918865079176612e-05 \n",
      "epoch: 23 [595496/888800 67.00%] train loss: 1.3965739526611287e-05 \n",
      "epoch: 23 [596607/888800 67.12%] train loss: 1.5616520613548346e-05 \n",
      "epoch: 23 [597718/888800 67.25%] train loss: 1.2979074199392926e-05 \n",
      "epoch: 23 [598829/888800 67.38%] train loss: 1.3527244846045505e-05 \n",
      "epoch: 23 [599940/888800 67.50%] train loss: 1.3516785656975117e-05 \n",
      "epoch: 23 [601051/888800 67.62%] train loss: 1.3370842680160422e-05 \n",
      "epoch: 23 [602162/888800 67.75%] train loss: 1.3040151316090487e-05 \n",
      "epoch: 23 [603273/888800 67.88%] train loss: 1.491042257839581e-05 \n",
      "epoch: 23 [604384/888800 68.00%] train loss: 1.4156247743812855e-05 \n",
      "epoch: 23 [605495/888800 68.12%] train loss: 1.41122045533848e-05 \n",
      "epoch: 23 [606606/888800 68.25%] train loss: 1.3806828064844012e-05 \n",
      "epoch: 23 [607717/888800 68.38%] train loss: 1.4945838302082848e-05 \n",
      "epoch: 23 [608828/888800 68.50%] train loss: 1.6071748177637346e-05 \n",
      "epoch: 23 [609939/888800 68.62%] train loss: 1.3138447684468701e-05 \n",
      "epoch: 23 [611050/888800 68.75%] train loss: 1.525932202639524e-05 \n",
      "epoch: 23 [612161/888800 68.88%] train loss: 1.3529841453419067e-05 \n",
      "epoch: 23 [613272/888800 69.00%] train loss: 1.489218539063586e-05 \n",
      "epoch: 23 [614383/888800 69.12%] train loss: 1.4320963600766845e-05 \n",
      "epoch: 23 [615494/888800 69.25%] train loss: 1.4781046957068611e-05 \n",
      "epoch: 23 [616605/888800 69.38%] train loss: 1.5674548194510862e-05 \n",
      "epoch: 23 [617716/888800 69.50%] train loss: 1.4490641660813708e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [618827/888800 69.62%] train loss: 1.4591952094633598e-05 \n",
      "epoch: 23 [619938/888800 69.75%] train loss: 1.4893139450578019e-05 \n",
      "epoch: 23 [621049/888800 69.88%] train loss: 1.519952820672188e-05 \n",
      "epoch: 23 [622160/888800 70.00%] train loss: 1.4741726772626862e-05 \n",
      "epoch: 23 [623271/888800 70.12%] train loss: 1.5384212019853294e-05 \n",
      "epoch: 23 [624382/888800 70.25%] train loss: 1.4185045984049793e-05 \n",
      "epoch: 23 [625493/888800 70.38%] train loss: 1.33564681163989e-05 \n",
      "epoch: 23 [626604/888800 70.50%] train loss: 1.4208763786882628e-05 \n",
      "epoch: 23 [627715/888800 70.62%] train loss: 1.3954972018836997e-05 \n",
      "epoch: 23 [628826/888800 70.75%] train loss: 1.5123197044886183e-05 \n",
      "epoch: 23 [629937/888800 70.88%] train loss: 1.4231883142201696e-05 \n",
      "epoch: 23 [631048/888800 71.00%] train loss: 1.4454414667852689e-05 \n",
      "epoch: 23 [632159/888800 71.12%] train loss: 1.416496616002405e-05 \n",
      "epoch: 23 [633270/888800 71.25%] train loss: 1.4422228559851646e-05 \n",
      "epoch: 23 [634381/888800 71.38%] train loss: 1.5711633750470355e-05 \n",
      "epoch: 23 [635492/888800 71.50%] train loss: 1.4048522643861361e-05 \n",
      "epoch: 23 [636603/888800 71.62%] train loss: 1.3214767932367977e-05 \n",
      "epoch: 23 [637714/888800 71.75%] train loss: 1.3933818081568461e-05 \n",
      "epoch: 23 [638825/888800 71.88%] train loss: 1.343094845651649e-05 \n",
      "epoch: 23 [639936/888800 72.00%] train loss: 1.3814574231219012e-05 \n",
      "epoch: 23 [641047/888800 72.12%] train loss: 1.4078160347708035e-05 \n",
      "epoch: 23 [642158/888800 72.25%] train loss: 1.3653960195370018e-05 \n",
      "epoch: 23 [643269/888800 72.38%] train loss: 1.4460270904237404e-05 \n",
      "epoch: 23 [644380/888800 72.50%] train loss: 1.3157279681763612e-05 \n",
      "epoch: 23 [645491/888800 72.62%] train loss: 1.3562000276579056e-05 \n",
      "epoch: 23 [646602/888800 72.75%] train loss: 1.3905606465414166e-05 \n",
      "epoch: 23 [647713/888800 72.88%] train loss: 1.4956205632188357e-05 \n",
      "epoch: 23 [648824/888800 73.00%] train loss: 1.3514011698134709e-05 \n",
      "epoch: 23 [649935/888800 73.12%] train loss: 1.3604220839624759e-05 \n",
      "epoch: 23 [651046/888800 73.25%] train loss: 1.3889984984416515e-05 \n",
      "epoch: 23 [652157/888800 73.38%] train loss: 1.3965385733172297e-05 \n",
      "epoch: 23 [653268/888800 73.50%] train loss: 1.4348071999847889e-05 \n",
      "epoch: 23 [654379/888800 73.62%] train loss: 1.4203267710399814e-05 \n",
      "epoch: 23 [655490/888800 73.75%] train loss: 1.4615259715355933e-05 \n",
      "epoch: 23 [656601/888800 73.88%] train loss: 1.404134582116967e-05 \n",
      "epoch: 23 [657712/888800 74.00%] train loss: 1.4033234037924558e-05 \n",
      "epoch: 23 [658823/888800 74.12%] train loss: 1.3900818885304034e-05 \n",
      "epoch: 23 [659934/888800 74.25%] train loss: 1.461660758650396e-05 \n",
      "epoch: 23 [661045/888800 74.38%] train loss: 1.3327434317034204e-05 \n",
      "epoch: 23 [662156/888800 74.50%] train loss: 1.6601825336692855e-05 \n",
      "epoch: 23 [663267/888800 74.62%] train loss: 1.434537443856243e-05 \n",
      "epoch: 23 [664378/888800 74.75%] train loss: 1.481477556808386e-05 \n",
      "epoch: 23 [665489/888800 74.88%] train loss: 1.4223007383407094e-05 \n",
      "epoch: 23 [666600/888800 75.00%] train loss: 1.4286998521129135e-05 \n",
      "epoch: 23 [667711/888800 75.12%] train loss: 1.3941588804300409e-05 \n",
      "epoch: 23 [668822/888800 75.25%] train loss: 1.566206628922373e-05 \n",
      "epoch: 23 [669933/888800 75.38%] train loss: 1.4910929166944697e-05 \n",
      "epoch: 23 [671044/888800 75.50%] train loss: 1.3860742910765111e-05 \n",
      "epoch: 23 [672155/888800 75.62%] train loss: 1.3757779015577398e-05 \n",
      "epoch: 23 [673266/888800 75.75%] train loss: 1.4916608051862568e-05 \n",
      "epoch: 23 [674377/888800 75.88%] train loss: 1.407325362379197e-05 \n",
      "epoch: 23 [675488/888800 76.00%] train loss: 1.48677881952608e-05 \n",
      "epoch: 23 [676599/888800 76.12%] train loss: 1.4231411114451475e-05 \n",
      "epoch: 23 [677710/888800 76.25%] train loss: 1.4131367606751155e-05 \n",
      "epoch: 23 [678821/888800 76.38%] train loss: 1.4871930943627376e-05 \n",
      "epoch: 23 [679932/888800 76.50%] train loss: 1.406699539074907e-05 \n",
      "epoch: 23 [681043/888800 76.62%] train loss: 1.468805203330703e-05 \n",
      "epoch: 23 [682154/888800 76.75%] train loss: 1.3821028005622793e-05 \n",
      "epoch: 23 [683265/888800 76.88%] train loss: 1.3816407772537787e-05 \n",
      "epoch: 23 [684376/888800 77.00%] train loss: 1.580456410010811e-05 \n",
      "epoch: 23 [685487/888800 77.12%] train loss: 1.3825153473590035e-05 \n",
      "epoch: 23 [686598/888800 77.25%] train loss: 1.3515950740838889e-05 \n",
      "epoch: 23 [687709/888800 77.38%] train loss: 1.4809829735895619e-05 \n",
      "epoch: 23 [688820/888800 77.50%] train loss: 1.5415478628710844e-05 \n",
      "epoch: 23 [689931/888800 77.62%] train loss: 1.389575390930986e-05 \n",
      "epoch: 23 [691042/888800 77.75%] train loss: 1.3750534890277777e-05 \n",
      "epoch: 23 [692153/888800 77.88%] train loss: 1.574087582412176e-05 \n",
      "epoch: 23 [693264/888800 78.00%] train loss: 1.4855378140055109e-05 \n",
      "epoch: 23 [694375/888800 78.12%] train loss: 1.4214759175956715e-05 \n",
      "epoch: 23 [695486/888800 78.25%] train loss: 1.5469911886611953e-05 \n",
      "epoch: 23 [696597/888800 78.38%] train loss: 1.624761898710858e-05 \n",
      "epoch: 23 [697708/888800 78.50%] train loss: 1.4183396160660777e-05 \n",
      "epoch: 23 [698819/888800 78.62%] train loss: 1.6550202417420223e-05 \n",
      "epoch: 23 [699930/888800 78.75%] train loss: 1.4533546163875144e-05 \n",
      "epoch: 23 [701041/888800 78.88%] train loss: 1.4511243534798268e-05 \n",
      "epoch: 23 [702152/888800 79.00%] train loss: 1.4131723219179548e-05 \n",
      "epoch: 23 [703263/888800 79.12%] train loss: 1.3692721040570177e-05 \n",
      "epoch: 23 [704374/888800 79.25%] train loss: 1.3873666830477305e-05 \n",
      "epoch: 23 [705485/888800 79.38%] train loss: 1.551450986880809e-05 \n",
      "epoch: 23 [706596/888800 79.50%] train loss: 1.4995001038187183e-05 \n",
      "epoch: 23 [707707/888800 79.62%] train loss: 1.3228301213530358e-05 \n",
      "epoch: 23 [708818/888800 79.75%] train loss: 1.6062360373325646e-05 \n",
      "epoch: 23 [709929/888800 79.88%] train loss: 1.2013450032100081e-05 \n",
      "epoch: 23 [711040/888800 80.00%] train loss: 1.4198087228578515e-05 \n",
      "epoch: 23 [712151/888800 80.12%] train loss: 1.3464362382364925e-05 \n",
      "epoch: 23 [713262/888800 80.25%] train loss: 1.4306215234682895e-05 \n",
      "epoch: 23 [714373/888800 80.38%] train loss: 1.4530731277773157e-05 \n",
      "epoch: 23 [715484/888800 80.50%] train loss: 1.4713677956024185e-05 \n",
      "epoch: 23 [716595/888800 80.62%] train loss: 1.436719139746856e-05 \n",
      "epoch: 23 [717706/888800 80.75%] train loss: 1.505883574282052e-05 \n",
      "epoch: 23 [718817/888800 80.88%] train loss: 1.4219979675544892e-05 \n",
      "epoch: 23 [719928/888800 81.00%] train loss: 1.4367670701176394e-05 \n",
      "epoch: 23 [721039/888800 81.12%] train loss: 1.4101451597525738e-05 \n",
      "epoch: 23 [722150/888800 81.25%] train loss: 1.5300036466214806e-05 \n",
      "epoch: 23 [723261/888800 81.38%] train loss: 1.493404579377966e-05 \n",
      "epoch: 23 [724372/888800 81.50%] train loss: 1.4101910892350134e-05 \n",
      "epoch: 23 [725483/888800 81.62%] train loss: 1.4406908121600281e-05 \n",
      "epoch: 23 [726594/888800 81.75%] train loss: 1.3890384252590593e-05 \n",
      "epoch: 23 [727705/888800 81.88%] train loss: 1.430232896382222e-05 \n",
      "epoch: 23 [728816/888800 82.00%] train loss: 1.3289698472362943e-05 \n",
      "epoch: 23 [729927/888800 82.12%] train loss: 1.3506788491213229e-05 \n",
      "epoch: 23 [731038/888800 82.25%] train loss: 1.4565863239113241e-05 \n",
      "epoch: 23 [732149/888800 82.38%] train loss: 1.4207978892954998e-05 \n",
      "epoch: 23 [733260/888800 82.50%] train loss: 1.3906244930694811e-05 \n",
      "epoch: 23 [734371/888800 82.62%] train loss: 1.4053969607630279e-05 \n",
      "epoch: 23 [735482/888800 82.75%] train loss: 1.4847585589450318e-05 \n",
      "epoch: 23 [736593/888800 82.88%] train loss: 1.3580986887973268e-05 \n",
      "epoch: 23 [737704/888800 83.00%] train loss: 1.3956177099316847e-05 \n",
      "epoch: 23 [738815/888800 83.12%] train loss: 1.4276840374805033e-05 \n",
      "epoch: 23 [739926/888800 83.25%] train loss: 1.5329127563745715e-05 \n",
      "epoch: 23 [741037/888800 83.38%] train loss: 1.4777212527405936e-05 \n",
      "epoch: 23 [742148/888800 83.50%] train loss: 1.468965183448745e-05 \n",
      "epoch: 23 [743259/888800 83.62%] train loss: 1.3937072253611404e-05 \n",
      "epoch: 23 [744370/888800 83.75%] train loss: 1.4824909158051014e-05 \n",
      "epoch: 23 [745481/888800 83.88%] train loss: 1.4708306480315514e-05 \n",
      "epoch: 23 [746592/888800 84.00%] train loss: 1.499476820754353e-05 \n",
      "epoch: 23 [747703/888800 84.12%] train loss: 1.4240788004826754e-05 \n",
      "epoch: 23 [748814/888800 84.25%] train loss: 1.4844026736682281e-05 \n",
      "epoch: 23 [749925/888800 84.38%] train loss: 1.3732887055084575e-05 \n",
      "epoch: 23 [751036/888800 84.50%] train loss: 1.5076229828991927e-05 \n",
      "epoch: 23 [752147/888800 84.62%] train loss: 1.5696921764174476e-05 \n",
      "epoch: 23 [753258/888800 84.75%] train loss: 1.4569631275662687e-05 \n",
      "epoch: 23 [754369/888800 84.88%] train loss: 1.4847106285742484e-05 \n",
      "epoch: 23 [755480/888800 85.00%] train loss: 1.4288874808698893e-05 \n",
      "epoch: 23 [756591/888800 85.12%] train loss: 1.5386192899313755e-05 \n",
      "epoch: 23 [757702/888800 85.25%] train loss: 1.4391678632819094e-05 \n",
      "epoch: 23 [758813/888800 85.38%] train loss: 1.4952714991522953e-05 \n",
      "epoch: 23 [759924/888800 85.50%] train loss: 1.3938795746071264e-05 \n",
      "epoch: 23 [761035/888800 85.62%] train loss: 1.372829319734592e-05 \n",
      "epoch: 23 [762146/888800 85.75%] train loss: 1.4268284758145455e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 [763257/888800 85.88%] train loss: 1.355664153379621e-05 \n",
      "epoch: 23 [764368/888800 86.00%] train loss: 1.4505486433336046e-05 \n",
      "epoch: 23 [765479/888800 86.12%] train loss: 1.4447231478698086e-05 \n",
      "epoch: 23 [766590/888800 86.25%] train loss: 1.517483815405285e-05 \n",
      "epoch: 23 [767701/888800 86.38%] train loss: 1.3844327440892812e-05 \n",
      "epoch: 23 [768812/888800 86.50%] train loss: 1.4244749763747677e-05 \n",
      "epoch: 23 [769923/888800 86.62%] train loss: 1.4733737771166489e-05 \n",
      "epoch: 23 [771034/888800 86.75%] train loss: 1.1343168807798065e-05 \n",
      "epoch: 23 [772145/888800 86.88%] train loss: 1.4202088095771614e-05 \n",
      "epoch: 23 [773256/888800 87.00%] train loss: 1.3567561836680397e-05 \n",
      "epoch: 23 [774367/888800 87.12%] train loss: 1.3968628081784118e-05 \n",
      "epoch: 23 [775478/888800 87.25%] train loss: 1.3740935173700564e-05 \n",
      "epoch: 23 [776589/888800 87.38%] train loss: 1.4135367564449552e-05 \n",
      "epoch: 23 [777700/888800 87.50%] train loss: 1.3749971003562678e-05 \n",
      "epoch: 23 [778811/888800 87.62%] train loss: 1.4056265172257554e-05 \n",
      "epoch: 23 [779922/888800 87.75%] train loss: 1.3583644431491848e-05 \n",
      "epoch: 23 [781033/888800 87.88%] train loss: 1.451414755138103e-05 \n",
      "epoch: 23 [782144/888800 88.00%] train loss: 1.4160106729832478e-05 \n",
      "epoch: 23 [783255/888800 88.12%] train loss: 1.4689264389744494e-05 \n",
      "epoch: 23 [784366/888800 88.25%] train loss: 1.425811933586374e-05 \n",
      "epoch: 23 [785477/888800 88.38%] train loss: 1.5191932106972672e-05 \n",
      "epoch: 23 [786588/888800 88.50%] train loss: 1.5340589015977457e-05 \n",
      "epoch: 23 [787699/888800 88.62%] train loss: 1.392827198287705e-05 \n",
      "epoch: 23 [788810/888800 88.75%] train loss: 1.3934885828348342e-05 \n",
      "epoch: 23 [789921/888800 88.88%] train loss: 1.3901772035751492e-05 \n",
      "epoch: 23 [791032/888800 89.00%] train loss: 1.4395043763215654e-05 \n",
      "epoch: 23 [792143/888800 89.12%] train loss: 1.3813199984724633e-05 \n",
      "epoch: 23 [793254/888800 89.25%] train loss: 1.374699695588788e-05 \n",
      "epoch: 23 [794365/888800 89.38%] train loss: 1.409621017955942e-05 \n",
      "epoch: 23 [795476/888800 89.50%] train loss: 1.4064336028241087e-05 \n",
      "epoch: 23 [796587/888800 89.62%] train loss: 1.4229819498723373e-05 \n",
      "epoch: 23 [797698/888800 89.75%] train loss: 1.4353280676004943e-05 \n",
      "epoch: 23 [798809/888800 89.88%] train loss: 1.3177677828934975e-05 \n",
      "epoch: 23 [799920/888800 90.00%] train loss: 1.4137845937511884e-05 \n",
      "epoch: 23 [801031/888800 90.12%] train loss: 1.3958540876046754e-05 \n",
      "epoch: 23 [802142/888800 90.25%] train loss: 1.3745850083068945e-05 \n",
      "epoch: 23 [803253/888800 90.38%] train loss: 1.3717152796743903e-05 \n",
      "epoch: 23 [804364/888800 90.50%] train loss: 1.4556597307091579e-05 \n",
      "epoch: 23 [805475/888800 90.62%] train loss: 1.398393669660436e-05 \n",
      "epoch: 23 [806586/888800 90.75%] train loss: 1.476912984799128e-05 \n",
      "epoch: 23 [807697/888800 90.88%] train loss: 1.4746412489330396e-05 \n",
      "epoch: 23 [808808/888800 91.00%] train loss: 1.4970339179853909e-05 \n",
      "epoch: 23 [809919/888800 91.12%] train loss: 1.350194634142099e-05 \n",
      "epoch: 23 [811030/888800 91.25%] train loss: 1.4407726666831877e-05 \n",
      "epoch: 23 [812141/888800 91.38%] train loss: 1.454487119190162e-05 \n",
      "epoch: 23 [813252/888800 91.50%] train loss: 1.4472840121015906e-05 \n",
      "epoch: 23 [814363/888800 91.62%] train loss: 1.494538264523726e-05 \n",
      "epoch: 23 [815474/888800 91.75%] train loss: 1.5863164662732743e-05 \n",
      "epoch: 23 [816585/888800 91.88%] train loss: 1.3871695955458563e-05 \n",
      "epoch: 23 [817696/888800 92.00%] train loss: 1.4893578736518975e-05 \n",
      "epoch: 23 [818807/888800 92.12%] train loss: 1.338241963821929e-05 \n",
      "epoch: 23 [819918/888800 92.25%] train loss: 1.410362256137887e-05 \n",
      "epoch: 23 [821029/888800 92.38%] train loss: 1.4293010281107854e-05 \n",
      "epoch: 23 [822140/888800 92.50%] train loss: 1.4474830095423386e-05 \n",
      "epoch: 23 [823251/888800 92.62%] train loss: 1.4497972188109998e-05 \n",
      "epoch: 23 [824362/888800 92.75%] train loss: 1.4872793144604657e-05 \n",
      "epoch: 23 [825473/888800 92.88%] train loss: 1.4711566109326668e-05 \n",
      "epoch: 23 [826584/888800 93.00%] train loss: 1.4750594345969148e-05 \n",
      "epoch: 23 [827695/888800 93.12%] train loss: 1.4112940334598534e-05 \n",
      "epoch: 23 [828806/888800 93.25%] train loss: 1.3304579624673352e-05 \n",
      "epoch: 23 [829917/888800 93.38%] train loss: 1.5070402696437668e-05 \n",
      "epoch: 23 [831028/888800 93.50%] train loss: 1.3365676750254352e-05 \n",
      "epoch: 23 [832139/888800 93.62%] train loss: 1.4723821550433058e-05 \n",
      "epoch: 23 [833250/888800 93.75%] train loss: 1.423154662916204e-05 \n",
      "epoch: 23 [834361/888800 93.88%] train loss: 1.3924566701462027e-05 \n",
      "epoch: 23 [835472/888800 94.00%] train loss: 1.4345885574584827e-05 \n",
      "epoch: 23 [836583/888800 94.12%] train loss: 1.2981528925593011e-05 \n",
      "epoch: 23 [837694/888800 94.25%] train loss: 1.3514265447156504e-05 \n",
      "epoch: 23 [838805/888800 94.38%] train loss: 1.286190399696352e-05 \n",
      "epoch: 23 [839916/888800 94.50%] train loss: 1.4470038877334446e-05 \n",
      "epoch: 23 [841027/888800 94.62%] train loss: 1.5474026440642774e-05 \n",
      "epoch: 23 [842138/888800 94.75%] train loss: 1.4867120626149699e-05 \n",
      "epoch: 23 [843249/888800 94.88%] train loss: 1.352155322820181e-05 \n",
      "epoch: 23 [844360/888800 95.00%] train loss: 1.2996468285564333e-05 \n",
      "epoch: 23 [845471/888800 95.12%] train loss: 1.3873645002604462e-05 \n",
      "epoch: 23 [846582/888800 95.25%] train loss: 1.3601227692561224e-05 \n",
      "epoch: 23 [847693/888800 95.38%] train loss: 1.4042841939954087e-05 \n",
      "epoch: 23 [848804/888800 95.50%] train loss: 1.652993159950711e-05 \n",
      "epoch: 23 [849915/888800 95.62%] train loss: 1.4809645108471159e-05 \n",
      "epoch: 23 [851026/888800 95.75%] train loss: 1.5500516383326612e-05 \n",
      "epoch: 23 [852137/888800 95.88%] train loss: 1.4530062799167354e-05 \n",
      "epoch: 23 [853248/888800 96.00%] train loss: 1.3050897905486636e-05 \n",
      "epoch: 23 [854359/888800 96.12%] train loss: 1.557609357405454e-05 \n",
      "epoch: 23 [855470/888800 96.25%] train loss: 1.3382472388911992e-05 \n",
      "epoch: 23 [856581/888800 96.38%] train loss: 1.5559931853204034e-05 \n",
      "epoch: 23 [857692/888800 96.50%] train loss: 1.4718997590534855e-05 \n",
      "epoch: 23 [858803/888800 96.62%] train loss: 1.4001135241414886e-05 \n",
      "epoch: 23 [859914/888800 96.75%] train loss: 1.3895156371290796e-05 \n",
      "epoch: 23 [861025/888800 96.88%] train loss: 1.3262532775115687e-05 \n",
      "epoch: 23 [862136/888800 97.00%] train loss: 1.4341542737383861e-05 \n",
      "epoch: 23 [863247/888800 97.12%] train loss: 1.5028148482088e-05 \n",
      "epoch: 23 [864358/888800 97.25%] train loss: 1.3468004908645526e-05 \n",
      "epoch: 23 [865469/888800 97.38%] train loss: 1.380174853693461e-05 \n",
      "epoch: 23 [866580/888800 97.50%] train loss: 1.4993374861660413e-05 \n",
      "epoch: 23 [867691/888800 97.62%] train loss: 1.566755963722244e-05 \n",
      "epoch: 23 [868802/888800 97.75%] train loss: 1.362917828373611e-05 \n",
      "epoch: 23 [869913/888800 97.88%] train loss: 1.3662042874784674e-05 \n",
      "epoch: 23 [871024/888800 98.00%] train loss: 1.4498149539576843e-05 \n",
      "epoch: 23 [872135/888800 98.12%] train loss: 1.446806072635809e-05 \n",
      "epoch: 23 [873246/888800 98.25%] train loss: 1.3050880625087302e-05 \n",
      "epoch: 23 [874357/888800 98.38%] train loss: 1.4632975762651768e-05 \n",
      "epoch: 23 [875468/888800 98.50%] train loss: 1.45969806908397e-05 \n",
      "epoch: 23 [876579/888800 98.62%] train loss: 1.3481773748935666e-05 \n",
      "epoch: 23 [877690/888800 98.75%] train loss: 1.5422805518028326e-05 \n",
      "epoch: 23 [878801/888800 98.88%] train loss: 1.388450891681714e-05 \n",
      "epoch: 23 [879912/888800 99.00%] train loss: 1.439248717360897e-05 \n",
      "epoch: 23 [881023/888800 99.12%] train loss: 1.4000816008774564e-05 \n",
      "epoch: 23 [882134/888800 99.25%] train loss: 1.36936560011236e-05 \n",
      "epoch: 23 [883245/888800 99.38%] train loss: 1.4408293282031082e-05 \n",
      "epoch: 23 [884356/888800 99.50%] train loss: 1.3835675417794846e-05 \n",
      "epoch: 23 [885467/888800 99.62%] train loss: 1.4109576113696676e-05 \n",
      "epoch: 23 [886578/888800 99.75%] train loss: 1.4079042557568755e-05 \n",
      "epoch: 23 [887689/888800 99.88%] train loss: 1.3944699276180472e-05 \n",
      "epoch: 24 [0/888800 0.00%] train loss: 1.4559640476363711e-05 \n",
      "epoch: 24 [1111/888800 0.12%] train loss: 1.428315863449825e-05 \n",
      "epoch: 24 [2222/888800 0.25%] train loss: 1.328711641690461e-05 \n",
      "epoch: 24 [3333/888800 0.38%] train loss: 1.4431813724513631e-05 \n",
      "epoch: 24 [4444/888800 0.50%] train loss: 1.3634280549013056e-05 \n",
      "epoch: 24 [5555/888800 0.62%] train loss: 1.3645340004586615e-05 \n",
      "epoch: 24 [6666/888800 0.75%] train loss: 1.3879116522730328e-05 \n",
      "epoch: 24 [7777/888800 0.88%] train loss: 1.4129047485766932e-05 \n",
      "epoch: 24 [8888/888800 1.00%] train loss: 1.5609897673130035e-05 \n",
      "epoch: 24 [9999/888800 1.12%] train loss: 1.4345299859996885e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [11110/888800 1.25%] train loss: 1.3207252777647227e-05 \n",
      "epoch: 24 [12221/888800 1.38%] train loss: 1.3742020200879779e-05 \n",
      "epoch: 24 [13332/888800 1.50%] train loss: 1.436023012502119e-05 \n",
      "epoch: 24 [14443/888800 1.62%] train loss: 1.4184334759193007e-05 \n",
      "epoch: 24 [15554/888800 1.75%] train loss: 1.3608582776214462e-05 \n",
      "epoch: 24 [16665/888800 1.88%] train loss: 1.405687908118125e-05 \n",
      "epoch: 24 [17776/888800 2.00%] train loss: 1.538036303827539e-05 \n",
      "epoch: 24 [18887/888800 2.12%] train loss: 1.4409213690669276e-05 \n",
      "epoch: 24 [19998/888800 2.25%] train loss: 1.5759178495500237e-05 \n",
      "epoch: 24 [21109/888800 2.38%] train loss: 1.4826833648839965e-05 \n",
      "epoch: 24 [22220/888800 2.50%] train loss: 1.3730009413848165e-05 \n",
      "epoch: 24 [23331/888800 2.62%] train loss: 1.4633881619374733e-05 \n",
      "epoch: 24 [24442/888800 2.75%] train loss: 1.3733260857407004e-05 \n",
      "epoch: 24 [25553/888800 2.88%] train loss: 1.5041116057545878e-05 \n",
      "epoch: 24 [26664/888800 3.00%] train loss: 1.5631998394383118e-05 \n",
      "epoch: 24 [27775/888800 3.12%] train loss: 1.4009302503836807e-05 \n",
      "epoch: 24 [28886/888800 3.25%] train loss: 1.4069915778236464e-05 \n",
      "epoch: 24 [29997/888800 3.38%] train loss: 1.3104011486575473e-05 \n",
      "epoch: 24 [31108/888800 3.50%] train loss: 1.400134260620689e-05 \n",
      "epoch: 24 [32219/888800 3.62%] train loss: 1.3543598470278084e-05 \n",
      "epoch: 24 [33330/888800 3.75%] train loss: 1.3434464563033544e-05 \n",
      "epoch: 24 [34441/888800 3.88%] train loss: 1.413992140442133e-05 \n",
      "epoch: 24 [35552/888800 4.00%] train loss: 1.4671125427412335e-05 \n",
      "epoch: 24 [36663/888800 4.12%] train loss: 1.5769714082125574e-05 \n",
      "epoch: 24 [37774/888800 4.25%] train loss: 1.3355635928746779e-05 \n",
      "epoch: 24 [38885/888800 4.38%] train loss: 1.4412897144211456e-05 \n",
      "epoch: 24 [39996/888800 4.50%] train loss: 1.4615700820286293e-05 \n",
      "epoch: 24 [41107/888800 4.62%] train loss: 1.4987379472586326e-05 \n",
      "epoch: 24 [42218/888800 4.75%] train loss: 1.4300601833383553e-05 \n",
      "epoch: 24 [43329/888800 4.88%] train loss: 1.3434807442536112e-05 \n",
      "epoch: 24 [44440/888800 5.00%] train loss: 1.5251624063239433e-05 \n",
      "epoch: 24 [45551/888800 5.12%] train loss: 1.4177281627780758e-05 \n",
      "epoch: 24 [46662/888800 5.25%] train loss: 1.439434436178999e-05 \n",
      "epoch: 24 [47773/888800 5.38%] train loss: 1.4318399735202547e-05 \n",
      "epoch: 24 [48884/888800 5.50%] train loss: 1.2477016753109638e-05 \n",
      "epoch: 24 [49995/888800 5.62%] train loss: 1.3074542039248627e-05 \n",
      "epoch: 24 [51106/888800 5.75%] train loss: 1.5674215319450013e-05 \n",
      "epoch: 24 [52217/888800 5.88%] train loss: 1.5027578228909988e-05 \n",
      "epoch: 24 [53328/888800 6.00%] train loss: 1.608335333003197e-05 \n",
      "epoch: 24 [54439/888800 6.12%] train loss: 1.309929029957857e-05 \n",
      "epoch: 24 [55550/888800 6.25%] train loss: 1.5183203686319757e-05 \n",
      "epoch: 24 [56661/888800 6.38%] train loss: 1.3936020877736155e-05 \n",
      "epoch: 24 [57772/888800 6.50%] train loss: 1.3401550859271083e-05 \n",
      "epoch: 24 [58883/888800 6.62%] train loss: 1.4912412552803289e-05 \n",
      "epoch: 24 [59994/888800 6.75%] train loss: 1.3993645552545786e-05 \n",
      "epoch: 24 [61105/888800 6.88%] train loss: 1.4977999853726942e-05 \n",
      "epoch: 24 [62216/888800 7.00%] train loss: 1.3369354746828321e-05 \n",
      "epoch: 24 [63327/888800 7.12%] train loss: 1.5174187865341082e-05 \n",
      "epoch: 24 [64438/888800 7.25%] train loss: 1.4007291611051187e-05 \n",
      "epoch: 24 [65549/888800 7.38%] train loss: 1.4153351003187709e-05 \n",
      "epoch: 24 [66660/888800 7.50%] train loss: 1.3331273294170387e-05 \n",
      "epoch: 24 [67771/888800 7.62%] train loss: 1.5228224583552219e-05 \n",
      "epoch: 24 [68882/888800 7.75%] train loss: 1.348873684037244e-05 \n",
      "epoch: 24 [69993/888800 7.88%] train loss: 1.4581044524675235e-05 \n",
      "epoch: 24 [71104/888800 8.00%] train loss: 1.4142684449325316e-05 \n",
      "epoch: 24 [72215/888800 8.12%] train loss: 1.4529073268931825e-05 \n",
      "epoch: 24 [73326/888800 8.25%] train loss: 1.2301397873670794e-05 \n",
      "epoch: 24 [74437/888800 8.38%] train loss: 1.4140903658699244e-05 \n",
      "epoch: 24 [75548/888800 8.50%] train loss: 1.5231020370265469e-05 \n",
      "epoch: 24 [76659/888800 8.62%] train loss: 1.3074784874334e-05 \n",
      "epoch: 24 [77770/888800 8.75%] train loss: 1.5459965652553365e-05 \n",
      "epoch: 24 [78881/888800 8.88%] train loss: 1.4083862879488152e-05 \n",
      "epoch: 24 [79992/888800 9.00%] train loss: 1.4860558621876407e-05 \n",
      "epoch: 24 [81103/888800 9.12%] train loss: 1.3420072718872689e-05 \n",
      "epoch: 24 [82214/888800 9.25%] train loss: 1.6834526832099073e-05 \n",
      "epoch: 24 [83325/888800 9.38%] train loss: 1.385550967825111e-05 \n",
      "epoch: 24 [84436/888800 9.50%] train loss: 1.6899297406780533e-05 \n",
      "epoch: 24 [85547/888800 9.62%] train loss: 1.3765850781055633e-05 \n",
      "epoch: 24 [86658/888800 9.75%] train loss: 1.7520827896078117e-05 \n",
      "epoch: 24 [87769/888800 9.88%] train loss: 1.4983951587055344e-05 \n",
      "epoch: 24 [88880/888800 10.00%] train loss: 1.6960831999313086e-05 \n",
      "epoch: 24 [89991/888800 10.12%] train loss: 1.5257723134709522e-05 \n",
      "epoch: 24 [91102/888800 10.25%] train loss: 1.623714342713356e-05 \n",
      "epoch: 24 [92213/888800 10.38%] train loss: 1.7079055396607146e-05 \n",
      "epoch: 24 [93324/888800 10.50%] train loss: 1.483340747654438e-05 \n",
      "epoch: 24 [94435/888800 10.62%] train loss: 1.8069720681523904e-05 \n",
      "epoch: 24 [95546/888800 10.75%] train loss: 1.4275825378717855e-05 \n",
      "epoch: 24 [96657/888800 10.88%] train loss: 1.8026459656539373e-05 \n",
      "epoch: 24 [97768/888800 11.00%] train loss: 1.4809646927460562e-05 \n",
      "epoch: 24 [98879/888800 11.12%] train loss: 1.8423446817905642e-05 \n",
      "epoch: 24 [99990/888800 11.25%] train loss: 1.5624618754372932e-05 \n",
      "epoch: 24 [101101/888800 11.38%] train loss: 1.7873906472232193e-05 \n",
      "epoch: 24 [102212/888800 11.50%] train loss: 1.4584203199774493e-05 \n",
      "epoch: 24 [103323/888800 11.62%] train loss: 1.476443594583543e-05 \n",
      "epoch: 24 [104434/888800 11.75%] train loss: 1.4499217286356725e-05 \n",
      "epoch: 24 [105545/888800 11.88%] train loss: 1.5060596524563152e-05 \n",
      "epoch: 24 [106656/888800 12.00%] train loss: 1.6574411347392015e-05 \n",
      "epoch: 24 [107767/888800 12.12%] train loss: 1.4266316611610819e-05 \n",
      "epoch: 24 [108878/888800 12.25%] train loss: 1.6624644558760338e-05 \n",
      "epoch: 24 [109989/888800 12.38%] train loss: 1.5031194379844237e-05 \n",
      "epoch: 24 [111100/888800 12.50%] train loss: 1.2904715731565375e-05 \n",
      "epoch: 24 [112211/888800 12.62%] train loss: 1.4263558114180341e-05 \n",
      "epoch: 24 [113322/888800 12.75%] train loss: 1.4532827663060743e-05 \n",
      "epoch: 24 [114433/888800 12.88%] train loss: 1.4251449101720937e-05 \n",
      "epoch: 24 [115544/888800 13.00%] train loss: 1.3530546311812941e-05 \n",
      "epoch: 24 [116655/888800 13.12%] train loss: 1.3953399502497632e-05 \n",
      "epoch: 24 [117766/888800 13.25%] train loss: 1.4914225175743923e-05 \n",
      "epoch: 24 [118877/888800 13.38%] train loss: 1.4789950910198968e-05 \n",
      "epoch: 24 [119988/888800 13.50%] train loss: 1.5312136383727193e-05 \n",
      "epoch: 24 [121099/888800 13.62%] train loss: 1.3867993402527645e-05 \n",
      "epoch: 24 [122210/888800 13.75%] train loss: 1.3773206774203572e-05 \n",
      "epoch: 24 [123321/888800 13.88%] train loss: 1.571645771036856e-05 \n",
      "epoch: 24 [124432/888800 14.00%] train loss: 1.4788611224503256e-05 \n",
      "epoch: 24 [125543/888800 14.12%] train loss: 1.4677850231237244e-05 \n",
      "epoch: 24 [126654/888800 14.25%] train loss: 1.4529798136209138e-05 \n",
      "epoch: 24 [127765/888800 14.38%] train loss: 1.3952287190477364e-05 \n",
      "epoch: 24 [128876/888800 14.50%] train loss: 1.370974860037677e-05 \n",
      "epoch: 24 [129987/888800 14.62%] train loss: 1.4031412320036907e-05 \n",
      "epoch: 24 [131098/888800 14.75%] train loss: 1.2640403838304337e-05 \n",
      "epoch: 24 [132209/888800 14.88%] train loss: 1.4559551345882937e-05 \n",
      "epoch: 24 [133320/888800 15.00%] train loss: 1.351761875412194e-05 \n",
      "epoch: 24 [134431/888800 15.12%] train loss: 1.281632012251066e-05 \n",
      "epoch: 24 [135542/888800 15.25%] train loss: 1.3713145563087892e-05 \n",
      "epoch: 24 [136653/888800 15.38%] train loss: 1.3532957382267341e-05 \n",
      "epoch: 24 [137764/888800 15.50%] train loss: 1.4365752576850355e-05 \n",
      "epoch: 24 [138875/888800 15.62%] train loss: 1.4108723917161115e-05 \n",
      "epoch: 24 [139986/888800 15.75%] train loss: 1.355052700091619e-05 \n",
      "epoch: 24 [141097/888800 15.88%] train loss: 1.556892311782576e-05 \n",
      "epoch: 24 [142208/888800 16.00%] train loss: 1.3753047824138775e-05 \n",
      "epoch: 24 [143319/888800 16.12%] train loss: 1.4260426723922137e-05 \n",
      "epoch: 24 [144430/888800 16.25%] train loss: 1.419847467332147e-05 \n",
      "epoch: 24 [145541/888800 16.38%] train loss: 1.3630807188746985e-05 \n",
      "epoch: 24 [146652/888800 16.50%] train loss: 1.4548098988598213e-05 \n",
      "epoch: 24 [147763/888800 16.62%] train loss: 1.426766630174825e-05 \n",
      "epoch: 24 [148874/888800 16.75%] train loss: 1.4621275113313459e-05 \n",
      "epoch: 24 [149985/888800 16.88%] train loss: 1.4219094737200066e-05 \n",
      "epoch: 24 [151096/888800 17.00%] train loss: 1.47911987369298e-05 \n",
      "epoch: 24 [152207/888800 17.12%] train loss: 1.2783491911250167e-05 \n",
      "epoch: 24 [153318/888800 17.25%] train loss: 1.2918272659590002e-05 \n",
      "epoch: 24 [154429/888800 17.38%] train loss: 1.3551301890402101e-05 \n",
      "epoch: 24 [155540/888800 17.50%] train loss: 1.3296041288413107e-05 \n",
      "epoch: 24 [156651/888800 17.62%] train loss: 1.3663207937497646e-05 \n",
      "epoch: 24 [157762/888800 17.75%] train loss: 1.4452390132646542e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [158873/888800 17.88%] train loss: 1.4407583876163699e-05 \n",
      "epoch: 24 [159984/888800 18.00%] train loss: 1.4056374311621767e-05 \n",
      "epoch: 24 [161095/888800 18.12%] train loss: 1.4948215721233282e-05 \n",
      "epoch: 24 [162206/888800 18.25%] train loss: 1.4503848433378153e-05 \n",
      "epoch: 24 [163317/888800 18.38%] train loss: 1.4880435628583655e-05 \n",
      "epoch: 24 [164428/888800 18.50%] train loss: 1.3055831914243754e-05 \n",
      "epoch: 24 [165539/888800 18.62%] train loss: 1.3710135135625023e-05 \n",
      "epoch: 24 [166650/888800 18.75%] train loss: 1.3928726730227936e-05 \n",
      "epoch: 24 [167761/888800 18.88%] train loss: 1.3687174941878766e-05 \n",
      "epoch: 24 [168872/888800 19.00%] train loss: 1.3150200175005011e-05 \n",
      "epoch: 24 [169983/888800 19.12%] train loss: 1.2720066479232628e-05 \n",
      "epoch: 24 [171094/888800 19.25%] train loss: 1.444047757104272e-05 \n",
      "epoch: 24 [172205/888800 19.38%] train loss: 1.3706497156817932e-05 \n",
      "epoch: 24 [173316/888800 19.50%] train loss: 1.4787256986892316e-05 \n",
      "epoch: 24 [174427/888800 19.62%] train loss: 1.3770566511084326e-05 \n",
      "epoch: 24 [175538/888800 19.75%] train loss: 1.396500192640815e-05 \n",
      "epoch: 24 [176649/888800 19.88%] train loss: 1.336709647148382e-05 \n",
      "epoch: 24 [177760/888800 20.00%] train loss: 1.2646369214053266e-05 \n",
      "epoch: 24 [178871/888800 20.12%] train loss: 1.381378842779668e-05 \n",
      "epoch: 24 [179982/888800 20.25%] train loss: 1.5182868992269505e-05 \n",
      "epoch: 24 [181093/888800 20.38%] train loss: 1.4654337064712308e-05 \n",
      "epoch: 24 [182204/888800 20.50%] train loss: 1.5063777027535252e-05 \n",
      "epoch: 24 [183315/888800 20.62%] train loss: 1.4620658475905657e-05 \n",
      "epoch: 24 [184426/888800 20.75%] train loss: 1.3973249224363826e-05 \n",
      "epoch: 24 [185537/888800 20.88%] train loss: 1.3617414879263379e-05 \n",
      "epoch: 24 [186648/888800 21.00%] train loss: 1.4249921150621958e-05 \n",
      "epoch: 24 [187759/888800 21.12%] train loss: 1.348226851405343e-05 \n",
      "epoch: 24 [188870/888800 21.25%] train loss: 1.4399914107343648e-05 \n",
      "epoch: 24 [189981/888800 21.38%] train loss: 1.4241875760490075e-05 \n",
      "epoch: 24 [191092/888800 21.50%] train loss: 1.4091552657191642e-05 \n",
      "epoch: 24 [192203/888800 21.62%] train loss: 1.404677277605515e-05 \n",
      "epoch: 24 [193314/888800 21.75%] train loss: 1.4355887287820224e-05 \n",
      "epoch: 24 [194425/888800 21.88%] train loss: 1.4322146853373852e-05 \n",
      "epoch: 24 [195536/888800 22.00%] train loss: 1.4165874745231122e-05 \n",
      "epoch: 24 [196647/888800 22.12%] train loss: 1.3419892638921738e-05 \n",
      "epoch: 24 [197758/888800 22.25%] train loss: 1.4297812413133215e-05 \n",
      "epoch: 24 [198869/888800 22.38%] train loss: 1.4837769413134083e-05 \n",
      "epoch: 24 [199980/888800 22.50%] train loss: 1.4730582734046038e-05 \n",
      "epoch: 24 [201091/888800 22.62%] train loss: 1.325682933384087e-05 \n",
      "epoch: 24 [202202/888800 22.75%] train loss: 1.4269797247834504e-05 \n",
      "epoch: 24 [203313/888800 22.88%] train loss: 1.4238697076507378e-05 \n",
      "epoch: 24 [204424/888800 23.00%] train loss: 1.570374115544837e-05 \n",
      "epoch: 24 [205535/888800 23.12%] train loss: 1.4001882846059743e-05 \n",
      "epoch: 24 [206646/888800 23.25%] train loss: 1.4209697837941349e-05 \n",
      "epoch: 24 [207757/888800 23.38%] train loss: 1.3713135558646172e-05 \n",
      "epoch: 24 [208868/888800 23.50%] train loss: 1.4716017176397145e-05 \n",
      "epoch: 24 [209979/888800 23.62%] train loss: 1.358943700324744e-05 \n",
      "epoch: 24 [211090/888800 23.75%] train loss: 1.3621023754240014e-05 \n",
      "epoch: 24 [212201/888800 23.88%] train loss: 1.5286304915207438e-05 \n",
      "epoch: 24 [213312/888800 24.00%] train loss: 1.3653167115990072e-05 \n",
      "epoch: 24 [214423/888800 24.12%] train loss: 1.4653585822088644e-05 \n",
      "epoch: 24 [215534/888800 24.25%] train loss: 1.399106713506626e-05 \n",
      "epoch: 24 [216645/888800 24.38%] train loss: 1.3983893950353377e-05 \n",
      "epoch: 24 [217756/888800 24.50%] train loss: 1.4240929886000231e-05 \n",
      "epoch: 24 [218867/888800 24.62%] train loss: 1.3905362720834091e-05 \n",
      "epoch: 24 [219978/888800 24.75%] train loss: 1.3736981600231957e-05 \n",
      "epoch: 24 [221089/888800 24.88%] train loss: 1.451789285056293e-05 \n",
      "epoch: 24 [222200/888800 25.00%] train loss: 1.3758796740148682e-05 \n",
      "epoch: 24 [223311/888800 25.12%] train loss: 1.423806679667905e-05 \n",
      "epoch: 24 [224422/888800 25.25%] train loss: 1.4417453712667339e-05 \n",
      "epoch: 24 [225533/888800 25.38%] train loss: 1.3680094525625464e-05 \n",
      "epoch: 24 [226644/888800 25.50%] train loss: 1.5138847629714292e-05 \n",
      "epoch: 24 [227755/888800 25.62%] train loss: 1.4295119399321266e-05 \n",
      "epoch: 24 [228866/888800 25.75%] train loss: 1.541690835438203e-05 \n",
      "epoch: 24 [229977/888800 25.88%] train loss: 1.3838089216733351e-05 \n",
      "epoch: 24 [231088/888800 26.00%] train loss: 1.409955984854605e-05 \n",
      "epoch: 24 [232199/888800 26.12%] train loss: 1.3558826140069868e-05 \n",
      "epoch: 24 [233310/888800 26.25%] train loss: 1.4903580449754372e-05 \n",
      "epoch: 24 [234421/888800 26.38%] train loss: 1.508836339780828e-05 \n",
      "epoch: 24 [235532/888800 26.50%] train loss: 1.3570442206400912e-05 \n",
      "epoch: 24 [236643/888800 26.62%] train loss: 1.4010253835294861e-05 \n",
      "epoch: 24 [237754/888800 26.75%] train loss: 1.5152798368944786e-05 \n",
      "epoch: 24 [238865/888800 26.88%] train loss: 1.4922130503691733e-05 \n",
      "epoch: 24 [239976/888800 27.00%] train loss: 1.6323645468219183e-05 \n",
      "epoch: 24 [241087/888800 27.12%] train loss: 1.3889312867831904e-05 \n",
      "epoch: 24 [242198/888800 27.25%] train loss: 1.534680268377997e-05 \n",
      "epoch: 24 [243309/888800 27.38%] train loss: 1.3936845789430663e-05 \n",
      "epoch: 24 [244420/888800 27.50%] train loss: 1.4036381799087394e-05 \n",
      "epoch: 24 [245531/888800 27.62%] train loss: 1.4216693671187386e-05 \n",
      "epoch: 24 [246642/888800 27.75%] train loss: 1.4418959835893475e-05 \n",
      "epoch: 24 [247753/888800 27.88%] train loss: 1.4273149645305239e-05 \n",
      "epoch: 24 [248864/888800 28.00%] train loss: 1.3935913557361346e-05 \n",
      "epoch: 24 [249975/888800 28.12%] train loss: 1.3588689398602583e-05 \n",
      "epoch: 24 [251086/888800 28.25%] train loss: 1.4136965546640567e-05 \n",
      "epoch: 24 [252197/888800 28.38%] train loss: 1.3299610145622864e-05 \n",
      "epoch: 24 [253308/888800 28.50%] train loss: 1.3348374523047823e-05 \n",
      "epoch: 24 [254419/888800 28.62%] train loss: 1.3710988241655286e-05 \n",
      "epoch: 24 [255530/888800 28.75%] train loss: 1.489430451329099e-05 \n",
      "epoch: 24 [256641/888800 28.88%] train loss: 1.3745855540037155e-05 \n",
      "epoch: 24 [257752/888800 29.00%] train loss: 1.45062322189915e-05 \n",
      "epoch: 24 [258863/888800 29.12%] train loss: 1.3985110854264349e-05 \n",
      "epoch: 24 [259974/888800 29.25%] train loss: 1.3285855857247952e-05 \n",
      "epoch: 24 [261085/888800 29.38%] train loss: 1.3927722648077179e-05 \n",
      "epoch: 24 [262196/888800 29.50%] train loss: 1.315073313890025e-05 \n",
      "epoch: 24 [263307/888800 29.62%] train loss: 1.492601768404711e-05 \n",
      "epoch: 24 [264418/888800 29.75%] train loss: 1.4836433365417179e-05 \n",
      "epoch: 24 [265529/888800 29.88%] train loss: 1.325175617239438e-05 \n",
      "epoch: 24 [266640/888800 30.00%] train loss: 1.3904696970712394e-05 \n",
      "epoch: 24 [267751/888800 30.12%] train loss: 1.3106076039548498e-05 \n",
      "epoch: 24 [268862/888800 30.25%] train loss: 1.3936850336904172e-05 \n",
      "epoch: 24 [269973/888800 30.38%] train loss: 1.4981699678173754e-05 \n",
      "epoch: 24 [271084/888800 30.50%] train loss: 1.3934020898886956e-05 \n",
      "epoch: 24 [272195/888800 30.62%] train loss: 1.4275067769631278e-05 \n",
      "epoch: 24 [273306/888800 30.75%] train loss: 1.3542826309276279e-05 \n",
      "epoch: 24 [274417/888800 30.88%] train loss: 1.4527935491059907e-05 \n",
      "epoch: 24 [275528/888800 31.00%] train loss: 1.4240778909879737e-05 \n",
      "epoch: 24 [276639/888800 31.12%] train loss: 1.516900010756217e-05 \n",
      "epoch: 24 [277750/888800 31.25%] train loss: 1.486864493926987e-05 \n",
      "epoch: 24 [278861/888800 31.38%] train loss: 1.3430334547592793e-05 \n",
      "epoch: 24 [279972/888800 31.50%] train loss: 1.4097122402745299e-05 \n",
      "epoch: 24 [281083/888800 31.62%] train loss: 1.5096261449798476e-05 \n",
      "epoch: 24 [282194/888800 31.75%] train loss: 1.432563476555515e-05 \n",
      "epoch: 24 [283305/888800 31.88%] train loss: 1.517761393188266e-05 \n",
      "epoch: 24 [284416/888800 32.00%] train loss: 1.3999101611261722e-05 \n",
      "epoch: 24 [285527/888800 32.12%] train loss: 1.4396840924746357e-05 \n",
      "epoch: 24 [286638/888800 32.25%] train loss: 1.4130586350802332e-05 \n",
      "epoch: 24 [287749/888800 32.38%] train loss: 1.3719561138714198e-05 \n",
      "epoch: 24 [288860/888800 32.50%] train loss: 1.482394782215124e-05 \n",
      "epoch: 24 [289971/888800 32.62%] train loss: 1.4094072867010254e-05 \n",
      "epoch: 24 [291082/888800 32.75%] train loss: 1.4403015484276693e-05 \n",
      "epoch: 24 [292193/888800 32.88%] train loss: 1.4364518392540049e-05 \n",
      "epoch: 24 [293304/888800 33.00%] train loss: 1.4275353350967634e-05 \n",
      "epoch: 24 [294415/888800 33.12%] train loss: 1.3888717148802243e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [295526/888800 33.25%] train loss: 1.3960998330730945e-05 \n",
      "epoch: 24 [296637/888800 33.38%] train loss: 1.3749383469985332e-05 \n",
      "epoch: 24 [297748/888800 33.50%] train loss: 1.4631331396230962e-05 \n",
      "epoch: 24 [298859/888800 33.62%] train loss: 1.3697572285309434e-05 \n",
      "epoch: 24 [299970/888800 33.75%] train loss: 1.3647272680827882e-05 \n",
      "epoch: 24 [301081/888800 33.88%] train loss: 1.3767034943157341e-05 \n",
      "epoch: 24 [302192/888800 34.00%] train loss: 1.4184566680341959e-05 \n",
      "epoch: 24 [303303/888800 34.12%] train loss: 1.3982492419017944e-05 \n",
      "epoch: 24 [304414/888800 34.25%] train loss: 1.3914655028202105e-05 \n",
      "epoch: 24 [305525/888800 34.38%] train loss: 1.4027995348442346e-05 \n",
      "epoch: 24 [306636/888800 34.50%] train loss: 1.3951484106655698e-05 \n",
      "epoch: 24 [307747/888800 34.62%] train loss: 1.5412340871989727e-05 \n",
      "epoch: 24 [308858/888800 34.75%] train loss: 1.341424558631843e-05 \n",
      "epoch: 24 [309969/888800 34.88%] train loss: 1.449241244699806e-05 \n",
      "epoch: 24 [311080/888800 35.00%] train loss: 1.3018548997933976e-05 \n",
      "epoch: 24 [312191/888800 35.12%] train loss: 1.3246471098682377e-05 \n",
      "epoch: 24 [313302/888800 35.25%] train loss: 1.480176069890149e-05 \n",
      "epoch: 24 [314413/888800 35.38%] train loss: 1.4799123164266348e-05 \n",
      "epoch: 24 [315524/888800 35.50%] train loss: 1.4383818779606372e-05 \n",
      "epoch: 24 [316635/888800 35.62%] train loss: 1.3676910384674557e-05 \n",
      "epoch: 24 [317746/888800 35.75%] train loss: 1.5209421690087765e-05 \n",
      "epoch: 24 [318857/888800 35.88%] train loss: 1.480612172599649e-05 \n",
      "epoch: 24 [319968/888800 36.00%] train loss: 1.692111800366547e-05 \n",
      "epoch: 24 [321079/888800 36.12%] train loss: 1.4565828678314574e-05 \n",
      "epoch: 24 [322190/888800 36.25%] train loss: 1.687174881226383e-05 \n",
      "epoch: 24 [323301/888800 36.38%] train loss: 1.5014074051578064e-05 \n",
      "epoch: 24 [324412/888800 36.50%] train loss: 1.5605546650476754e-05 \n",
      "epoch: 24 [325523/888800 36.62%] train loss: 1.4393943274626508e-05 \n",
      "epoch: 24 [326634/888800 36.75%] train loss: 1.509884350525681e-05 \n",
      "epoch: 24 [327745/888800 36.88%] train loss: 1.521007561677834e-05 \n",
      "epoch: 24 [328856/888800 37.00%] train loss: 1.461964438931318e-05 \n",
      "epoch: 24 [329967/888800 37.12%] train loss: 1.5148269994824659e-05 \n",
      "epoch: 24 [331078/888800 37.25%] train loss: 1.4642104360973462e-05 \n",
      "epoch: 24 [332189/888800 37.38%] train loss: 1.4166628716338892e-05 \n",
      "epoch: 24 [333300/888800 37.50%] train loss: 1.393882939737523e-05 \n",
      "epoch: 24 [334411/888800 37.62%] train loss: 1.4516708688461222e-05 \n",
      "epoch: 24 [335522/888800 37.75%] train loss: 1.3470589692587964e-05 \n",
      "epoch: 24 [336633/888800 37.88%] train loss: 1.4059967725188471e-05 \n",
      "epoch: 24 [337744/888800 38.00%] train loss: 1.4706487490911968e-05 \n",
      "epoch: 24 [338855/888800 38.12%] train loss: 1.3172626495361328e-05 \n",
      "epoch: 24 [339966/888800 38.25%] train loss: 1.4592210391128901e-05 \n",
      "epoch: 24 [341077/888800 38.38%] train loss: 1.4258490409702063e-05 \n",
      "epoch: 24 [342188/888800 38.50%] train loss: 1.439580137230223e-05 \n",
      "epoch: 24 [343299/888800 38.62%] train loss: 1.4576226021745242e-05 \n",
      "epoch: 24 [344410/888800 38.75%] train loss: 1.3497487998392899e-05 \n",
      "epoch: 24 [345521/888800 38.88%] train loss: 1.369717483612476e-05 \n",
      "epoch: 24 [346632/888800 39.00%] train loss: 1.4104934962233528e-05 \n",
      "epoch: 24 [347743/888800 39.12%] train loss: 1.3738223969994579e-05 \n",
      "epoch: 24 [348854/888800 39.25%] train loss: 1.3809408301312942e-05 \n",
      "epoch: 24 [349965/888800 39.38%] train loss: 1.4609254321840126e-05 \n",
      "epoch: 24 [351076/888800 39.50%] train loss: 1.4499869394057896e-05 \n",
      "epoch: 24 [352187/888800 39.62%] train loss: 1.5042262930364814e-05 \n",
      "epoch: 24 [353298/888800 39.75%] train loss: 1.4510081200569402e-05 \n",
      "epoch: 24 [354409/888800 39.88%] train loss: 1.3352631867746823e-05 \n",
      "epoch: 24 [355520/888800 40.00%] train loss: 1.3905379091738723e-05 \n",
      "epoch: 24 [356631/888800 40.12%] train loss: 1.3032954484515358e-05 \n",
      "epoch: 24 [357742/888800 40.25%] train loss: 1.3002103514736518e-05 \n",
      "epoch: 24 [358853/888800 40.38%] train loss: 1.4202529200701974e-05 \n",
      "epoch: 24 [359964/888800 40.50%] train loss: 1.4632231795985717e-05 \n",
      "epoch: 24 [361075/888800 40.62%] train loss: 1.4267602637119126e-05 \n",
      "epoch: 24 [362186/888800 40.75%] train loss: 1.4917272892489564e-05 \n",
      "epoch: 24 [363297/888800 40.88%] train loss: 1.4723328604304697e-05 \n",
      "epoch: 24 [364408/888800 41.00%] train loss: 1.3882387975172605e-05 \n",
      "epoch: 24 [365519/888800 41.12%] train loss: 1.3563457287091296e-05 \n",
      "epoch: 24 [366630/888800 41.25%] train loss: 1.391466776112793e-05 \n",
      "epoch: 24 [367741/888800 41.38%] train loss: 1.4732631825609133e-05 \n",
      "epoch: 24 [368852/888800 41.50%] train loss: 1.4548862054653e-05 \n",
      "epoch: 24 [369963/888800 41.62%] train loss: 1.4355528946907725e-05 \n",
      "epoch: 24 [371074/888800 41.75%] train loss: 1.5482515664189123e-05 \n",
      "epoch: 24 [372185/888800 41.88%] train loss: 1.4277115042204969e-05 \n",
      "epoch: 24 [373296/888800 42.00%] train loss: 1.3113244676787872e-05 \n",
      "epoch: 24 [374407/888800 42.12%] train loss: 1.7195570762851276e-05 \n",
      "epoch: 24 [375518/888800 42.25%] train loss: 1.4207565072865691e-05 \n",
      "epoch: 24 [376629/888800 42.38%] train loss: 1.5522444300586358e-05 \n",
      "epoch: 24 [377740/888800 42.50%] train loss: 1.44090208777925e-05 \n",
      "epoch: 24 [378851/888800 42.62%] train loss: 1.6936941392486915e-05 \n",
      "epoch: 24 [379962/888800 42.75%] train loss: 1.5328459994634613e-05 \n",
      "epoch: 24 [381073/888800 42.88%] train loss: 1.5924946637824178e-05 \n",
      "epoch: 24 [382184/888800 43.00%] train loss: 1.5046361113491002e-05 \n",
      "epoch: 24 [383295/888800 43.12%] train loss: 1.4215450391930062e-05 \n",
      "epoch: 24 [384406/888800 43.25%] train loss: 1.5408568287966773e-05 \n",
      "epoch: 24 [385517/888800 43.38%] train loss: 1.4755721167603042e-05 \n",
      "epoch: 24 [386628/888800 43.50%] train loss: 1.3792581739835441e-05 \n",
      "epoch: 24 [387739/888800 43.62%] train loss: 1.5550371244898997e-05 \n",
      "epoch: 24 [388850/888800 43.75%] train loss: 1.4390961041499395e-05 \n",
      "epoch: 24 [389961/888800 43.88%] train loss: 1.3918389413447585e-05 \n",
      "epoch: 24 [391072/888800 44.00%] train loss: 1.550920569570735e-05 \n",
      "epoch: 24 [392183/888800 44.12%] train loss: 1.5666179024265148e-05 \n",
      "epoch: 24 [393294/888800 44.25%] train loss: 1.427880306437146e-05 \n",
      "epoch: 24 [394405/888800 44.38%] train loss: 1.4223413927538786e-05 \n",
      "epoch: 24 [395516/888800 44.50%] train loss: 1.387721931678243e-05 \n",
      "epoch: 24 [396627/888800 44.62%] train loss: 1.505596264905762e-05 \n",
      "epoch: 24 [397738/888800 44.75%] train loss: 1.4750367881788407e-05 \n",
      "epoch: 24 [398849/888800 44.88%] train loss: 1.4316879060061183e-05 \n",
      "epoch: 24 [399960/888800 45.00%] train loss: 1.6199077435885556e-05 \n",
      "epoch: 24 [401071/888800 45.12%] train loss: 1.5306724890251644e-05 \n",
      "epoch: 24 [402182/888800 45.25%] train loss: 1.3756360203842632e-05 \n",
      "epoch: 24 [403293/888800 45.38%] train loss: 1.3187833246774971e-05 \n",
      "epoch: 24 [404404/888800 45.50%] train loss: 1.3928845874033868e-05 \n",
      "epoch: 24 [405515/888800 45.62%] train loss: 1.4382019799086265e-05 \n",
      "epoch: 24 [406626/888800 45.75%] train loss: 1.383864218951203e-05 \n",
      "epoch: 24 [407737/888800 45.88%] train loss: 1.5316303688450716e-05 \n",
      "epoch: 24 [408848/888800 46.00%] train loss: 1.425945902155945e-05 \n",
      "epoch: 24 [409959/888800 46.12%] train loss: 1.4260106581787113e-05 \n",
      "epoch: 24 [411070/888800 46.25%] train loss: 1.355935000901809e-05 \n",
      "epoch: 24 [412181/888800 46.38%] train loss: 1.500237613072386e-05 \n",
      "epoch: 24 [413292/888800 46.50%] train loss: 1.466383309889352e-05 \n",
      "epoch: 24 [414403/888800 46.62%] train loss: 1.2215981769259088e-05 \n",
      "epoch: 24 [415514/888800 46.75%] train loss: 1.4901644135534298e-05 \n",
      "epoch: 24 [416625/888800 46.88%] train loss: 1.339525533694541e-05 \n",
      "epoch: 24 [417736/888800 47.00%] train loss: 1.4786603060201742e-05 \n",
      "epoch: 24 [418847/888800 47.12%] train loss: 1.3247497918200679e-05 \n",
      "epoch: 24 [419958/888800 47.25%] train loss: 1.4442713109019678e-05 \n",
      "epoch: 24 [421069/888800 47.38%] train loss: 1.4116480087977834e-05 \n",
      "epoch: 24 [422180/888800 47.50%] train loss: 1.4440576705965213e-05 \n",
      "epoch: 24 [423291/888800 47.62%] train loss: 1.6261865312117152e-05 \n",
      "epoch: 24 [424402/888800 47.75%] train loss: 1.3685592421097681e-05 \n",
      "epoch: 24 [425513/888800 47.88%] train loss: 1.4573138287232723e-05 \n",
      "epoch: 24 [426624/888800 48.00%] train loss: 1.37622946567717e-05 \n",
      "epoch: 24 [427735/888800 48.12%] train loss: 1.455691108276369e-05 \n",
      "epoch: 24 [428846/888800 48.25%] train loss: 1.4045574062038213e-05 \n",
      "epoch: 24 [429957/888800 48.38%] train loss: 1.4448611182160676e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [431068/888800 48.50%] train loss: 1.3096454495098442e-05 \n",
      "epoch: 24 [432179/888800 48.62%] train loss: 1.4833580280537717e-05 \n",
      "epoch: 24 [433290/888800 48.75%] train loss: 1.345844520983519e-05 \n",
      "epoch: 24 [434401/888800 48.88%] train loss: 1.4740856386197265e-05 \n",
      "epoch: 24 [435512/888800 49.00%] train loss: 1.3395327187026851e-05 \n",
      "epoch: 24 [436623/888800 49.12%] train loss: 1.3674127330887131e-05 \n",
      "epoch: 24 [437734/888800 49.25%] train loss: 1.4232230569177773e-05 \n",
      "epoch: 24 [438845/888800 49.38%] train loss: 1.450544277759036e-05 \n",
      "epoch: 24 [439956/888800 49.50%] train loss: 1.454181892768247e-05 \n",
      "epoch: 24 [441067/888800 49.62%] train loss: 1.2668386261793785e-05 \n",
      "epoch: 24 [442178/888800 49.75%] train loss: 1.3834597666573245e-05 \n",
      "epoch: 24 [443289/888800 49.88%] train loss: 1.424783386028139e-05 \n",
      "epoch: 24 [444400/888800 50.00%] train loss: 1.4390793694474269e-05 \n",
      "epoch: 24 [445511/888800 50.12%] train loss: 1.5113623703655321e-05 \n",
      "epoch: 24 [446622/888800 50.25%] train loss: 1.404820886818925e-05 \n",
      "epoch: 24 [447733/888800 50.38%] train loss: 1.395511208102107e-05 \n",
      "epoch: 24 [448844/888800 50.50%] train loss: 1.4208058018994052e-05 \n",
      "epoch: 24 [449955/888800 50.62%] train loss: 1.4938431377231609e-05 \n",
      "epoch: 24 [451066/888800 50.75%] train loss: 1.4100332919042557e-05 \n",
      "epoch: 24 [452177/888800 50.88%] train loss: 1.4232326066121459e-05 \n",
      "epoch: 24 [453288/888800 51.00%] train loss: 1.4058819033380132e-05 \n",
      "epoch: 24 [454399/888800 51.12%] train loss: 1.4461711543845013e-05 \n",
      "epoch: 24 [455510/888800 51.25%] train loss: 1.4064211427466944e-05 \n",
      "epoch: 24 [456621/888800 51.38%] train loss: 1.4244224985304754e-05 \n",
      "epoch: 24 [457732/888800 51.50%] train loss: 1.4376541003002785e-05 \n",
      "epoch: 24 [458843/888800 51.62%] train loss: 1.4571054634870961e-05 \n",
      "epoch: 24 [459954/888800 51.75%] train loss: 1.4753137293155305e-05 \n",
      "epoch: 24 [461065/888800 51.88%] train loss: 1.5466086551896296e-05 \n",
      "epoch: 24 [462176/888800 52.00%] train loss: 1.3819466403219849e-05 \n",
      "epoch: 24 [463287/888800 52.12%] train loss: 1.4317176464828663e-05 \n",
      "epoch: 24 [464398/888800 52.25%] train loss: 1.5155864275584463e-05 \n",
      "epoch: 24 [465509/888800 52.38%] train loss: 1.4305041077022906e-05 \n",
      "epoch: 24 [466620/888800 52.50%] train loss: 1.5259523934219033e-05 \n",
      "epoch: 24 [467731/888800 52.62%] train loss: 1.3958233466837555e-05 \n",
      "epoch: 24 [468842/888800 52.75%] train loss: 1.3233709978521802e-05 \n",
      "epoch: 24 [469953/888800 52.88%] train loss: 1.438339677406475e-05 \n",
      "epoch: 24 [471064/888800 53.00%] train loss: 1.3566825145971961e-05 \n",
      "epoch: 24 [472175/888800 53.12%] train loss: 1.3840165593137499e-05 \n",
      "epoch: 24 [473286/888800 53.25%] train loss: 1.579205309099052e-05 \n",
      "epoch: 24 [474397/888800 53.38%] train loss: 1.4189779903972521e-05 \n",
      "epoch: 24 [475508/888800 53.50%] train loss: 1.5611165508744307e-05 \n",
      "epoch: 24 [476619/888800 53.62%] train loss: 1.3770468285656534e-05 \n",
      "epoch: 24 [477730/888800 53.75%] train loss: 1.4179277059156448e-05 \n",
      "epoch: 24 [478841/888800 53.88%] train loss: 1.478472495364258e-05 \n",
      "epoch: 24 [479952/888800 54.00%] train loss: 1.4071474652155302e-05 \n",
      "epoch: 24 [481063/888800 54.12%] train loss: 1.3597338693216443e-05 \n",
      "epoch: 24 [482174/888800 54.25%] train loss: 1.4412556993192993e-05 \n",
      "epoch: 24 [483285/888800 54.38%] train loss: 1.4537436072714627e-05 \n",
      "epoch: 24 [484396/888800 54.50%] train loss: 1.3493501683115028e-05 \n",
      "epoch: 24 [485507/888800 54.62%] train loss: 1.548752697999589e-05 \n",
      "epoch: 24 [486618/888800 54.75%] train loss: 1.4084491340327077e-05 \n",
      "epoch: 24 [487729/888800 54.88%] train loss: 1.3653845599037595e-05 \n",
      "epoch: 24 [488840/888800 55.00%] train loss: 1.3967232007416897e-05 \n",
      "epoch: 24 [489951/888800 55.12%] train loss: 1.4219798686099239e-05 \n",
      "epoch: 24 [491062/888800 55.25%] train loss: 1.4272318367147818e-05 \n",
      "epoch: 24 [492173/888800 55.38%] train loss: 1.359400266665034e-05 \n",
      "epoch: 24 [493284/888800 55.50%] train loss: 1.363196406600764e-05 \n",
      "epoch: 24 [494395/888800 55.62%] train loss: 1.3740472240897361e-05 \n",
      "epoch: 24 [495506/888800 55.75%] train loss: 1.4449868103838526e-05 \n",
      "epoch: 24 [496617/888800 55.88%] train loss: 1.4526057384500746e-05 \n",
      "epoch: 24 [497728/888800 56.00%] train loss: 1.3319714526005555e-05 \n",
      "epoch: 24 [498839/888800 56.12%] train loss: 1.4372533769346774e-05 \n",
      "epoch: 24 [499950/888800 56.25%] train loss: 1.2904105460620485e-05 \n",
      "epoch: 24 [501061/888800 56.38%] train loss: 1.33972507683211e-05 \n",
      "epoch: 24 [502172/888800 56.50%] train loss: 1.4069679309614003e-05 \n",
      "epoch: 24 [503283/888800 56.62%] train loss: 1.3875443983124569e-05 \n",
      "epoch: 24 [504394/888800 56.75%] train loss: 1.4898866538715083e-05 \n",
      "epoch: 24 [505505/888800 56.88%] train loss: 1.49935221998021e-05 \n",
      "epoch: 24 [506616/888800 57.00%] train loss: 1.3385224519879557e-05 \n",
      "epoch: 24 [507727/888800 57.12%] train loss: 1.7136428141384386e-05 \n",
      "epoch: 24 [508838/888800 57.25%] train loss: 1.39187050081091e-05 \n",
      "epoch: 24 [509949/888800 57.38%] train loss: 1.4197398741089273e-05 \n",
      "epoch: 24 [511060/888800 57.50%] train loss: 1.4412253221962601e-05 \n",
      "epoch: 24 [512171/888800 57.62%] train loss: 1.4306151570053771e-05 \n",
      "epoch: 24 [513282/888800 57.75%] train loss: 1.4003261640027631e-05 \n",
      "epoch: 24 [514393/888800 57.88%] train loss: 1.4480570825980976e-05 \n",
      "epoch: 24 [515504/888800 58.00%] train loss: 1.3362097888602875e-05 \n",
      "epoch: 24 [516615/888800 58.12%] train loss: 1.3753490748058539e-05 \n",
      "epoch: 24 [517726/888800 58.25%] train loss: 1.42237804539036e-05 \n",
      "epoch: 24 [518837/888800 58.38%] train loss: 1.4969165931688622e-05 \n",
      "epoch: 24 [519948/888800 58.50%] train loss: 1.4706423826282844e-05 \n",
      "epoch: 24 [521059/888800 58.62%] train loss: 1.4546626516676042e-05 \n",
      "epoch: 24 [522170/888800 58.75%] train loss: 1.4015476153872442e-05 \n",
      "epoch: 24 [523281/888800 58.88%] train loss: 1.515139956609346e-05 \n",
      "epoch: 24 [524392/888800 59.00%] train loss: 1.4534281035594177e-05 \n",
      "epoch: 24 [525503/888800 59.12%] train loss: 1.4180673133523669e-05 \n",
      "epoch: 24 [526614/888800 59.25%] train loss: 1.3417968148132786e-05 \n",
      "epoch: 24 [527725/888800 59.38%] train loss: 1.4985327652539127e-05 \n",
      "epoch: 24 [528836/888800 59.50%] train loss: 1.4626720258092973e-05 \n",
      "epoch: 24 [529947/888800 59.62%] train loss: 1.5017712030385155e-05 \n",
      "epoch: 24 [531058/888800 59.75%] train loss: 1.4410171388590243e-05 \n",
      "epoch: 24 [532169/888800 59.88%] train loss: 1.4061201000004075e-05 \n",
      "epoch: 24 [533280/888800 60.00%] train loss: 1.4141267456579953e-05 \n",
      "epoch: 24 [534391/888800 60.12%] train loss: 1.3138447684468701e-05 \n",
      "epoch: 24 [535502/888800 60.25%] train loss: 1.4325758456834592e-05 \n",
      "epoch: 24 [536613/888800 60.38%] train loss: 1.4534396541421302e-05 \n",
      "epoch: 24 [537724/888800 60.50%] train loss: 1.4109683434071485e-05 \n",
      "epoch: 24 [538835/888800 60.62%] train loss: 1.3345234037842602e-05 \n",
      "epoch: 24 [539946/888800 60.75%] train loss: 1.3446649973047897e-05 \n",
      "epoch: 24 [541057/888800 60.88%] train loss: 1.3891676644561812e-05 \n",
      "epoch: 24 [542168/888800 61.00%] train loss: 1.3379261872614734e-05 \n",
      "epoch: 24 [543279/888800 61.12%] train loss: 1.5008031368779484e-05 \n",
      "epoch: 24 [544390/888800 61.25%] train loss: 1.285741564061027e-05 \n",
      "epoch: 24 [545501/888800 61.38%] train loss: 1.4254022062232252e-05 \n",
      "epoch: 24 [546612/888800 61.50%] train loss: 1.4769352674193215e-05 \n",
      "epoch: 24 [547723/888800 61.62%] train loss: 1.367198728985386e-05 \n",
      "epoch: 24 [548834/888800 61.75%] train loss: 1.3681533346243668e-05 \n",
      "epoch: 24 [549945/888800 61.88%] train loss: 1.3600703823613003e-05 \n",
      "epoch: 24 [551056/888800 62.00%] train loss: 1.4874997759761754e-05 \n",
      "epoch: 24 [552167/888800 62.12%] train loss: 1.3605382264358923e-05 \n",
      "epoch: 24 [553278/888800 62.25%] train loss: 1.3893202776671387e-05 \n",
      "epoch: 24 [554389/888800 62.38%] train loss: 1.4315286534838378e-05 \n",
      "epoch: 24 [555500/888800 62.50%] train loss: 1.581627657287754e-05 \n",
      "epoch: 24 [556611/888800 62.62%] train loss: 1.4786322935833596e-05 \n",
      "epoch: 24 [557722/888800 62.75%] train loss: 1.3953549569123425e-05 \n",
      "epoch: 24 [558833/888800 62.88%] train loss: 1.5061994417919777e-05 \n",
      "epoch: 24 [559944/888800 63.00%] train loss: 1.5461262591998093e-05 \n",
      "epoch: 24 [561055/888800 63.12%] train loss: 1.4170510439726058e-05 \n",
      "epoch: 24 [562166/888800 63.25%] train loss: 1.5460464055649936e-05 \n",
      "epoch: 24 [563277/888800 63.38%] train loss: 1.5153837921388913e-05 \n",
      "epoch: 24 [564388/888800 63.50%] train loss: 1.4806505532760639e-05 \n",
      "epoch: 24 [565499/888800 63.62%] train loss: 1.4968993127695285e-05 \n",
      "epoch: 24 [566610/888800 63.75%] train loss: 1.4136287973087747e-05 \n",
      "epoch: 24 [567721/888800 63.88%] train loss: 1.5611078197252937e-05 \n",
      "epoch: 24 [568832/888800 64.00%] train loss: 1.3074542948743328e-05 \n",
      "epoch: 24 [569943/888800 64.12%] train loss: 1.608451930223964e-05 \n",
      "epoch: 24 [571054/888800 64.25%] train loss: 1.4533780813508201e-05 \n",
      "epoch: 24 [572165/888800 64.38%] train loss: 1.4745020962436683e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [573276/888800 64.50%] train loss: 1.3275432138470933e-05 \n",
      "epoch: 24 [574387/888800 64.62%] train loss: 1.4840007679595146e-05 \n",
      "epoch: 24 [575498/888800 64.75%] train loss: 1.4463347724813502e-05 \n",
      "epoch: 24 [576609/888800 64.88%] train loss: 1.328231974184746e-05 \n",
      "epoch: 24 [577720/888800 65.00%] train loss: 1.4474261661234777e-05 \n",
      "epoch: 24 [578831/888800 65.12%] train loss: 1.5026426808617543e-05 \n",
      "epoch: 24 [579942/888800 65.25%] train loss: 1.3197995940572582e-05 \n",
      "epoch: 24 [581053/888800 65.38%] train loss: 1.3369960470299702e-05 \n",
      "epoch: 24 [582164/888800 65.50%] train loss: 1.4940842447686009e-05 \n",
      "epoch: 24 [583275/888800 65.62%] train loss: 1.3890879017708357e-05 \n",
      "epoch: 24 [584386/888800 65.75%] train loss: 1.5401730706798844e-05 \n",
      "epoch: 24 [585497/888800 65.88%] train loss: 1.4033986190042924e-05 \n",
      "epoch: 24 [586608/888800 66.00%] train loss: 1.4497451957140584e-05 \n",
      "epoch: 24 [587719/888800 66.12%] train loss: 1.3652624147653114e-05 \n",
      "epoch: 24 [588830/888800 66.25%] train loss: 1.4519264368573204e-05 \n",
      "epoch: 24 [589941/888800 66.38%] train loss: 1.4458814803219866e-05 \n",
      "epoch: 24 [591052/888800 66.50%] train loss: 1.4567474863724783e-05 \n",
      "epoch: 24 [592163/888800 66.62%] train loss: 1.5299194274120964e-05 \n",
      "epoch: 24 [593274/888800 66.75%] train loss: 1.4449247828451917e-05 \n",
      "epoch: 24 [594385/888800 66.88%] train loss: 1.3274257071316242e-05 \n",
      "epoch: 24 [595496/888800 67.00%] train loss: 1.3542736269300804e-05 \n",
      "epoch: 24 [596607/888800 67.12%] train loss: 1.4527886378346011e-05 \n",
      "epoch: 24 [597718/888800 67.25%] train loss: 1.512603739683982e-05 \n",
      "epoch: 24 [598829/888800 67.38%] train loss: 1.4169138921715785e-05 \n",
      "epoch: 24 [599940/888800 67.50%] train loss: 1.3324685824045446e-05 \n",
      "epoch: 24 [601051/888800 67.62%] train loss: 1.4907535842212383e-05 \n",
      "epoch: 24 [602162/888800 67.75%] train loss: 1.4421176274481695e-05 \n",
      "epoch: 24 [603273/888800 67.88%] train loss: 1.4327849385153968e-05 \n",
      "epoch: 24 [604384/888800 68.00%] train loss: 1.4406004993361421e-05 \n",
      "epoch: 24 [605495/888800 68.12%] train loss: 1.2789913853339385e-05 \n",
      "epoch: 24 [606606/888800 68.25%] train loss: 1.4107745300862007e-05 \n",
      "epoch: 24 [607717/888800 68.38%] train loss: 1.4045270290807821e-05 \n",
      "epoch: 24 [608828/888800 68.50%] train loss: 1.4147231013339479e-05 \n",
      "epoch: 24 [609939/888800 68.62%] train loss: 1.417773455614224e-05 \n",
      "epoch: 24 [611050/888800 68.75%] train loss: 1.4184242900228128e-05 \n",
      "epoch: 24 [612161/888800 68.88%] train loss: 1.3910899724578485e-05 \n",
      "epoch: 24 [613272/888800 69.00%] train loss: 1.4558328985003754e-05 \n",
      "epoch: 24 [614383/888800 69.12%] train loss: 1.4981069398345426e-05 \n",
      "epoch: 24 [615494/888800 69.25%] train loss: 1.4457722500083037e-05 \n",
      "epoch: 24 [616605/888800 69.38%] train loss: 1.4711627954966389e-05 \n",
      "epoch: 24 [617716/888800 69.50%] train loss: 1.4614498468290549e-05 \n",
      "epoch: 24 [618827/888800 69.62%] train loss: 1.3251900782051962e-05 \n",
      "epoch: 24 [619938/888800 69.75%] train loss: 1.4018821275385562e-05 \n",
      "epoch: 24 [621049/888800 69.88%] train loss: 1.4431891031563282e-05 \n",
      "epoch: 24 [622160/888800 70.00%] train loss: 1.2789790162059944e-05 \n",
      "epoch: 24 [623271/888800 70.12%] train loss: 1.445137877453817e-05 \n",
      "epoch: 24 [624382/888800 70.25%] train loss: 1.3764383766101673e-05 \n",
      "epoch: 24 [625493/888800 70.38%] train loss: 1.4624823052145075e-05 \n",
      "epoch: 24 [626604/888800 70.50%] train loss: 1.4889998965372797e-05 \n",
      "epoch: 24 [627715/888800 70.62%] train loss: 1.4302110685093794e-05 \n",
      "epoch: 24 [628826/888800 70.75%] train loss: 1.4853944776405115e-05 \n",
      "epoch: 24 [629937/888800 70.88%] train loss: 1.4122129869065247e-05 \n",
      "epoch: 24 [631048/888800 71.00%] train loss: 1.44109189932351e-05 \n",
      "epoch: 24 [632159/888800 71.12%] train loss: 1.4988174370955676e-05 \n",
      "epoch: 24 [633270/888800 71.25%] train loss: 1.2846021490986459e-05 \n",
      "epoch: 24 [634381/888800 71.38%] train loss: 1.3219620086601935e-05 \n",
      "epoch: 24 [635492/888800 71.50%] train loss: 1.4788245607633144e-05 \n",
      "epoch: 24 [636603/888800 71.62%] train loss: 1.4685267160530202e-05 \n",
      "epoch: 24 [637714/888800 71.75%] train loss: 1.4239736628951505e-05 \n",
      "epoch: 24 [638825/888800 71.88%] train loss: 1.4970181837270502e-05 \n",
      "epoch: 24 [639936/888800 72.00%] train loss: 1.4147341971693095e-05 \n",
      "epoch: 24 [641047/888800 72.12%] train loss: 1.5358675227616914e-05 \n",
      "epoch: 24 [642158/888800 72.25%] train loss: 1.4086687770031858e-05 \n",
      "epoch: 24 [643269/888800 72.38%] train loss: 1.343506846751552e-05 \n",
      "epoch: 24 [644380/888800 72.50%] train loss: 1.4236913557397202e-05 \n",
      "epoch: 24 [645491/888800 72.62%] train loss: 1.4768077562621329e-05 \n",
      "epoch: 24 [646602/888800 72.75%] train loss: 1.5173035535553936e-05 \n",
      "epoch: 24 [647713/888800 72.88%] train loss: 1.358264034934109e-05 \n",
      "epoch: 24 [648824/888800 73.00%] train loss: 1.4981800632085651e-05 \n",
      "epoch: 24 [649935/888800 73.12%] train loss: 1.5178410649241414e-05 \n",
      "epoch: 24 [651046/888800 73.25%] train loss: 1.4331686543300748e-05 \n",
      "epoch: 24 [652157/888800 73.38%] train loss: 1.3836819562129676e-05 \n",
      "epoch: 24 [653268/888800 73.50%] train loss: 1.4168449524731841e-05 \n",
      "epoch: 24 [654379/888800 73.62%] train loss: 1.5980862372089177e-05 \n",
      "epoch: 24 [655490/888800 73.75%] train loss: 1.4518207535729744e-05 \n",
      "epoch: 24 [656601/888800 73.88%] train loss: 1.4669888514617924e-05 \n",
      "epoch: 24 [657712/888800 74.00%] train loss: 1.3622182450490072e-05 \n",
      "epoch: 24 [658823/888800 74.12%] train loss: 1.3491955542122014e-05 \n",
      "epoch: 24 [659934/888800 74.25%] train loss: 1.5751231330796145e-05 \n",
      "epoch: 24 [661045/888800 74.38%] train loss: 1.3805910384689923e-05 \n",
      "epoch: 24 [662156/888800 74.50%] train loss: 1.418637839378789e-05 \n",
      "epoch: 24 [663267/888800 74.62%] train loss: 1.3897851204092149e-05 \n",
      "epoch: 24 [664378/888800 74.75%] train loss: 1.4241986718843691e-05 \n",
      "epoch: 24 [665489/888800 74.88%] train loss: 1.4584825294150505e-05 \n",
      "epoch: 24 [666600/888800 75.00%] train loss: 1.453828917874489e-05 \n",
      "epoch: 24 [667711/888800 75.12%] train loss: 1.4266597645473666e-05 \n",
      "epoch: 24 [668822/888800 75.25%] train loss: 1.2661720575124491e-05 \n",
      "epoch: 24 [669933/888800 75.38%] train loss: 1.4547614227922168e-05 \n",
      "epoch: 24 [671044/888800 75.50%] train loss: 1.504231204307871e-05 \n",
      "epoch: 24 [672155/888800 75.62%] train loss: 1.3575080629379954e-05 \n",
      "epoch: 24 [673266/888800 75.75%] train loss: 1.3089584172121249e-05 \n",
      "epoch: 24 [674377/888800 75.88%] train loss: 1.372064980387222e-05 \n",
      "epoch: 24 [675488/888800 76.00%] train loss: 1.4194908544595819e-05 \n",
      "epoch: 24 [676599/888800 76.12%] train loss: 1.4421952073462307e-05 \n",
      "epoch: 24 [677710/888800 76.25%] train loss: 1.29901927721221e-05 \n",
      "epoch: 24 [678821/888800 76.38%] train loss: 1.4249683772504795e-05 \n",
      "epoch: 24 [679932/888800 76.50%] train loss: 1.318583144893637e-05 \n",
      "epoch: 24 [681043/888800 76.62%] train loss: 1.3613569535664283e-05 \n",
      "epoch: 24 [682154/888800 76.75%] train loss: 1.4430450391955674e-05 \n",
      "epoch: 24 [683265/888800 76.88%] train loss: 1.3833438060828485e-05 \n",
      "epoch: 24 [684376/888800 77.00%] train loss: 1.4887526049278677e-05 \n",
      "epoch: 24 [685487/888800 77.12%] train loss: 1.3603376828541514e-05 \n",
      "epoch: 24 [686598/888800 77.25%] train loss: 1.4325498341349885e-05 \n",
      "epoch: 24 [687709/888800 77.38%] train loss: 1.297050403081812e-05 \n",
      "epoch: 24 [688820/888800 77.50%] train loss: 1.3259308616397902e-05 \n",
      "epoch: 24 [689931/888800 77.62%] train loss: 1.5115508176677395e-05 \n",
      "epoch: 24 [691042/888800 77.75%] train loss: 1.3852514712198172e-05 \n",
      "epoch: 24 [692153/888800 77.88%] train loss: 1.4256887880037539e-05 \n",
      "epoch: 24 [693264/888800 78.00%] train loss: 1.4989321243774612e-05 \n",
      "epoch: 24 [694375/888800 78.12%] train loss: 1.5578138118144125e-05 \n",
      "epoch: 24 [695486/888800 78.25%] train loss: 1.3302585102792364e-05 \n",
      "epoch: 24 [696597/888800 78.38%] train loss: 1.4147089132166002e-05 \n",
      "epoch: 24 [697708/888800 78.50%] train loss: 1.3404041055764537e-05 \n",
      "epoch: 24 [698819/888800 78.62%] train loss: 1.3964348909212276e-05 \n",
      "epoch: 24 [699930/888800 78.75%] train loss: 1.3879294783691876e-05 \n",
      "epoch: 24 [701041/888800 78.88%] train loss: 1.4706118236063048e-05 \n",
      "epoch: 24 [702152/888800 79.00%] train loss: 1.4631864360126201e-05 \n",
      "epoch: 24 [703263/888800 79.12%] train loss: 1.3516830222215503e-05 \n",
      "epoch: 24 [704374/888800 79.25%] train loss: 1.4202507372829132e-05 \n",
      "epoch: 24 [705485/888800 79.38%] train loss: 1.523924947832711e-05 \n",
      "epoch: 24 [706596/888800 79.50%] train loss: 1.528616667201277e-05 \n",
      "epoch: 24 [707707/888800 79.62%] train loss: 1.2928935575473588e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [708818/888800 79.75%] train loss: 1.4271711734181736e-05 \n",
      "epoch: 24 [709929/888800 79.88%] train loss: 1.4652546269644517e-05 \n",
      "epoch: 24 [711040/888800 80.00%] train loss: 1.5042648556118365e-05 \n",
      "epoch: 24 [712151/888800 80.12%] train loss: 1.4959745385567658e-05 \n",
      "epoch: 24 [713262/888800 80.25%] train loss: 1.4431229828915093e-05 \n",
      "epoch: 24 [714373/888800 80.38%] train loss: 1.5090899978531525e-05 \n",
      "epoch: 24 [715484/888800 80.50%] train loss: 1.552399407955818e-05 \n",
      "epoch: 24 [716595/888800 80.62%] train loss: 1.54310509969946e-05 \n",
      "epoch: 24 [717706/888800 80.75%] train loss: 1.518914541520644e-05 \n",
      "epoch: 24 [718817/888800 80.88%] train loss: 1.544211045256816e-05 \n",
      "epoch: 24 [719928/888800 81.00%] train loss: 1.475902354286518e-05 \n",
      "epoch: 24 [721039/888800 81.12%] train loss: 1.3999489965499379e-05 \n",
      "epoch: 24 [722150/888800 81.25%] train loss: 1.3549658433475997e-05 \n",
      "epoch: 24 [723261/888800 81.38%] train loss: 1.3608168956125155e-05 \n",
      "epoch: 24 [724372/888800 81.50%] train loss: 1.3857437807018869e-05 \n",
      "epoch: 24 [725483/888800 81.62%] train loss: 1.4448476576944813e-05 \n",
      "epoch: 24 [726594/888800 81.75%] train loss: 1.538105971121695e-05 \n",
      "epoch: 24 [727705/888800 81.88%] train loss: 1.2148253517807461e-05 \n",
      "epoch: 24 [728816/888800 82.00%] train loss: 1.4453982657869346e-05 \n",
      "epoch: 24 [729927/888800 82.12%] train loss: 1.4836031368758995e-05 \n",
      "epoch: 24 [731038/888800 82.25%] train loss: 1.4818051567999646e-05 \n",
      "epoch: 24 [732149/888800 82.38%] train loss: 1.5156106201175135e-05 \n",
      "epoch: 24 [733260/888800 82.50%] train loss: 1.525794777990086e-05 \n",
      "epoch: 24 [734371/888800 82.62%] train loss: 1.4792944057262503e-05 \n",
      "epoch: 24 [735482/888800 82.75%] train loss: 1.538910328235943e-05 \n",
      "epoch: 24 [736593/888800 82.88%] train loss: 1.6640093235764652e-05 \n",
      "epoch: 24 [737704/888800 83.00%] train loss: 1.3943639714852907e-05 \n",
      "epoch: 24 [738815/888800 83.12%] train loss: 1.7365509847877547e-05 \n",
      "epoch: 24 [739926/888800 83.25%] train loss: 1.4696857761009596e-05 \n",
      "epoch: 24 [741037/888800 83.38%] train loss: 1.5002015970821958e-05 \n",
      "epoch: 24 [742148/888800 83.50%] train loss: 1.4191465197654907e-05 \n",
      "epoch: 24 [743259/888800 83.62%] train loss: 1.4806959370616823e-05 \n",
      "epoch: 24 [744370/888800 83.75%] train loss: 1.5537949366262183e-05 \n",
      "epoch: 24 [745481/888800 83.88%] train loss: 1.438986600987846e-05 \n",
      "epoch: 24 [746592/888800 84.00%] train loss: 1.5528830772382207e-05 \n",
      "epoch: 24 [747703/888800 84.12%] train loss: 1.3998364011058584e-05 \n",
      "epoch: 24 [748814/888800 84.25%] train loss: 1.6337251508957706e-05 \n",
      "epoch: 24 [749925/888800 84.38%] train loss: 1.3424935787043069e-05 \n",
      "epoch: 24 [751036/888800 84.50%] train loss: 1.575644637341611e-05 \n",
      "epoch: 24 [752147/888800 84.62%] train loss: 1.549414446344599e-05 \n",
      "epoch: 24 [753258/888800 84.75%] train loss: 1.347419402009109e-05 \n",
      "epoch: 24 [754369/888800 84.88%] train loss: 1.6401081666117534e-05 \n",
      "epoch: 24 [755480/888800 85.00%] train loss: 1.4500449651677627e-05 \n",
      "epoch: 24 [756591/888800 85.12%] train loss: 1.5475221516680904e-05 \n",
      "epoch: 24 [757702/888800 85.25%] train loss: 1.2253280146978796e-05 \n",
      "epoch: 24 [758813/888800 85.38%] train loss: 1.5938348951749504e-05 \n",
      "epoch: 24 [759924/888800 85.50%] train loss: 1.4848074897599872e-05 \n",
      "epoch: 24 [761035/888800 85.62%] train loss: 1.4532806744682603e-05 \n",
      "epoch: 24 [762146/888800 85.75%] train loss: 1.6438698366982862e-05 \n",
      "epoch: 24 [763257/888800 85.88%] train loss: 1.5523000911343843e-05 \n",
      "epoch: 24 [764368/888800 86.00%] train loss: 1.4148158697935287e-05 \n",
      "epoch: 24 [765479/888800 86.12%] train loss: 1.3661730008607265e-05 \n",
      "epoch: 24 [766590/888800 86.25%] train loss: 1.749222428770736e-05 \n",
      "epoch: 24 [767701/888800 86.38%] train loss: 1.576970134919975e-05 \n",
      "epoch: 24 [768812/888800 86.50%] train loss: 1.3879704056307673e-05 \n",
      "epoch: 24 [769923/888800 86.62%] train loss: 1.4107288734521717e-05 \n",
      "epoch: 24 [771034/888800 86.75%] train loss: 1.3790599950880278e-05 \n",
      "epoch: 24 [772145/888800 86.88%] train loss: 1.503003113612067e-05 \n",
      "epoch: 24 [773256/888800 87.00%] train loss: 1.3777229469269514e-05 \n",
      "epoch: 24 [774367/888800 87.12%] train loss: 1.415294173057191e-05 \n",
      "epoch: 24 [775478/888800 87.25%] train loss: 1.2865488315583207e-05 \n",
      "epoch: 24 [776589/888800 87.38%] train loss: 1.36339440359734e-05 \n",
      "epoch: 24 [777700/888800 87.50%] train loss: 1.4850525076326448e-05 \n",
      "epoch: 24 [778811/888800 87.62%] train loss: 1.4749041838513222e-05 \n",
      "epoch: 24 [779922/888800 87.75%] train loss: 1.4639279470429756e-05 \n",
      "epoch: 24 [781033/888800 87.88%] train loss: 1.4799174095969647e-05 \n",
      "epoch: 24 [782144/888800 88.00%] train loss: 1.5240679203998297e-05 \n",
      "epoch: 24 [783255/888800 88.12%] train loss: 1.3366640814638231e-05 \n",
      "epoch: 24 [784366/888800 88.25%] train loss: 1.669631092227064e-05 \n",
      "epoch: 24 [785477/888800 88.38%] train loss: 1.5868181435507722e-05 \n",
      "epoch: 24 [786588/888800 88.50%] train loss: 1.4148387890600134e-05 \n",
      "epoch: 24 [787699/888800 88.62%] train loss: 1.4888414625602309e-05 \n",
      "epoch: 24 [788810/888800 88.75%] train loss: 1.3951070286566392e-05 \n",
      "epoch: 24 [789921/888800 88.88%] train loss: 1.5117147995624691e-05 \n",
      "epoch: 24 [791032/888800 89.00%] train loss: 1.5016757970442995e-05 \n",
      "epoch: 24 [792143/888800 89.12%] train loss: 1.4940818800823763e-05 \n",
      "epoch: 24 [793254/888800 89.25%] train loss: 1.426370090484852e-05 \n",
      "epoch: 24 [794365/888800 89.38%] train loss: 1.48991830428713e-05 \n",
      "epoch: 24 [795476/888800 89.50%] train loss: 1.3971859516459517e-05 \n",
      "epoch: 24 [796587/888800 89.62%] train loss: 1.5129542589420453e-05 \n",
      "epoch: 24 [797698/888800 89.75%] train loss: 1.634312138776295e-05 \n",
      "epoch: 24 [798809/888800 89.88%] train loss: 1.4531747183355037e-05 \n",
      "epoch: 24 [799920/888800 90.00%] train loss: 1.4347119758895133e-05 \n",
      "epoch: 24 [801031/888800 90.12%] train loss: 1.4172914234222844e-05 \n",
      "epoch: 24 [802142/888800 90.25%] train loss: 1.4363814443640877e-05 \n",
      "epoch: 24 [803253/888800 90.38%] train loss: 1.541916572023183e-05 \n",
      "epoch: 24 [804364/888800 90.50%] train loss: 1.497939410910476e-05 \n",
      "epoch: 24 [805475/888800 90.62%] train loss: 1.3358289834286552e-05 \n",
      "epoch: 24 [806586/888800 90.75%] train loss: 1.4169455425872002e-05 \n",
      "epoch: 24 [807697/888800 90.88%] train loss: 1.4786726751481183e-05 \n",
      "epoch: 24 [808808/888800 91.00%] train loss: 1.3823068911733571e-05 \n",
      "epoch: 24 [809919/888800 91.12%] train loss: 1.5438517948496155e-05 \n",
      "epoch: 24 [811030/888800 91.25%] train loss: 1.4247169929149095e-05 \n",
      "epoch: 24 [812141/888800 91.38%] train loss: 1.3268968359625433e-05 \n",
      "epoch: 24 [813252/888800 91.50%] train loss: 1.5086707207956351e-05 \n",
      "epoch: 24 [814363/888800 91.62%] train loss: 1.3362939171202015e-05 \n",
      "epoch: 24 [815474/888800 91.75%] train loss: 1.3961604963697027e-05 \n",
      "epoch: 24 [816585/888800 91.88%] train loss: 1.4769222616450861e-05 \n",
      "epoch: 24 [817696/888800 92.00%] train loss: 1.588964369148016e-05 \n",
      "epoch: 24 [818807/888800 92.12%] train loss: 1.5136334695853293e-05 \n",
      "epoch: 24 [819918/888800 92.25%] train loss: 1.4623515198763926e-05 \n",
      "epoch: 24 [821029/888800 92.38%] train loss: 1.4148715308692772e-05 \n",
      "epoch: 24 [822140/888800 92.50%] train loss: 1.5283676475519314e-05 \n",
      "epoch: 24 [823251/888800 92.62%] train loss: 1.3762420167040545e-05 \n",
      "epoch: 24 [824362/888800 92.75%] train loss: 1.5001328392827418e-05 \n",
      "epoch: 24 [825473/888800 92.88%] train loss: 1.4588153135264292e-05 \n",
      "epoch: 24 [826584/888800 93.00%] train loss: 1.4258184819482267e-05 \n",
      "epoch: 24 [827695/888800 93.12%] train loss: 1.4676476894237567e-05 \n",
      "epoch: 24 [828806/888800 93.25%] train loss: 1.4216691852197982e-05 \n",
      "epoch: 24 [829917/888800 93.38%] train loss: 1.396965490130242e-05 \n",
      "epoch: 24 [831028/888800 93.50%] train loss: 1.3651856534124818e-05 \n",
      "epoch: 24 [832139/888800 93.62%] train loss: 1.4031716091267299e-05 \n",
      "epoch: 24 [833250/888800 93.75%] train loss: 1.415325459674932e-05 \n",
      "epoch: 24 [834361/888800 93.88%] train loss: 1.3879506695957389e-05 \n",
      "epoch: 24 [835472/888800 94.00%] train loss: 1.4102289242146071e-05 \n",
      "epoch: 24 [836583/888800 94.12%] train loss: 1.3057087926426902e-05 \n",
      "epoch: 24 [837694/888800 94.25%] train loss: 1.4218534488463774e-05 \n",
      "epoch: 24 [838805/888800 94.38%] train loss: 1.36310709422105e-05 \n",
      "epoch: 24 [839916/888800 94.50%] train loss: 1.46009306263295e-05 \n",
      "epoch: 24 [841027/888800 94.62%] train loss: 1.4340101188281551e-05 \n",
      "epoch: 24 [842138/888800 94.75%] train loss: 1.5715058907517232e-05 \n",
      "epoch: 24 [843249/888800 94.88%] train loss: 1.3694068911718205e-05 \n",
      "epoch: 24 [844360/888800 95.00%] train loss: 1.4810135326115415e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 [845471/888800 95.12%] train loss: 1.4872139217914082e-05 \n",
      "epoch: 24 [846582/888800 95.25%] train loss: 1.3537777704186738e-05 \n",
      "epoch: 24 [847693/888800 95.38%] train loss: 1.4379884305526502e-05 \n",
      "epoch: 24 [848804/888800 95.50%] train loss: 1.534433613414876e-05 \n",
      "epoch: 24 [849915/888800 95.62%] train loss: 1.4810580978519283e-05 \n",
      "epoch: 24 [851026/888800 95.75%] train loss: 1.4613130588259082e-05 \n",
      "epoch: 24 [852137/888800 95.88%] train loss: 1.4390072465175763e-05 \n",
      "epoch: 24 [853248/888800 96.00%] train loss: 1.3836250218446366e-05 \n",
      "epoch: 24 [854359/888800 96.12%] train loss: 1.337612047791481e-05 \n",
      "epoch: 24 [855470/888800 96.25%] train loss: 1.3797573956253473e-05 \n",
      "epoch: 24 [856581/888800 96.38%] train loss: 1.4386174370883964e-05 \n",
      "epoch: 24 [857692/888800 96.50%] train loss: 1.455891106161289e-05 \n",
      "epoch: 24 [858803/888800 96.62%] train loss: 1.3920430319558363e-05 \n",
      "epoch: 24 [859914/888800 96.75%] train loss: 1.4212636415322777e-05 \n",
      "epoch: 24 [861025/888800 96.88%] train loss: 1.4766977074032184e-05 \n",
      "epoch: 24 [862136/888800 97.00%] train loss: 1.4080404071137309e-05 \n",
      "epoch: 24 [863247/888800 97.12%] train loss: 1.3440740076475777e-05 \n",
      "epoch: 24 [864358/888800 97.25%] train loss: 1.4173258023220114e-05 \n",
      "epoch: 24 [865469/888800 97.38%] train loss: 1.3432634659693576e-05 \n",
      "epoch: 24 [866580/888800 97.50%] train loss: 1.284957215830218e-05 \n",
      "epoch: 24 [867691/888800 97.62%] train loss: 1.364851777907461e-05 \n",
      "epoch: 24 [868802/888800 97.75%] train loss: 1.4523954632750247e-05 \n",
      "epoch: 24 [869913/888800 97.88%] train loss: 1.3639999451697804e-05 \n",
      "epoch: 24 [871024/888800 98.00%] train loss: 1.3014358955842908e-05 \n",
      "epoch: 24 [872135/888800 98.12%] train loss: 1.43669039971428e-05 \n",
      "epoch: 24 [873246/888800 98.25%] train loss: 1.4264155652199406e-05 \n",
      "epoch: 24 [874357/888800 98.38%] train loss: 1.373169925500406e-05 \n",
      "epoch: 24 [875468/888800 98.50%] train loss: 1.3366747225518338e-05 \n",
      "epoch: 24 [876579/888800 98.62%] train loss: 1.4374395505001303e-05 \n",
      "epoch: 24 [877690/888800 98.75%] train loss: 1.3594448319054209e-05 \n",
      "epoch: 24 [878801/888800 98.88%] train loss: 1.3687697901332285e-05 \n",
      "epoch: 24 [879912/888800 99.00%] train loss: 1.4233771253202576e-05 \n",
      "epoch: 24 [881023/888800 99.12%] train loss: 1.3260389096103609e-05 \n",
      "epoch: 24 [882134/888800 99.25%] train loss: 1.4846511476207525e-05 \n",
      "epoch: 24 [883245/888800 99.38%] train loss: 1.4408105926122516e-05 \n",
      "epoch: 24 [884356/888800 99.50%] train loss: 1.481741765019251e-05 \n",
      "epoch: 24 [885467/888800 99.62%] train loss: 1.5463552699657157e-05 \n",
      "epoch: 24 [886578/888800 99.75%] train loss: 1.4299773283710238e-05 \n",
      "epoch: 24 [887689/888800 99.88%] train loss: 1.5589890608680435e-05 \n",
      "epoch: 25 [0/888800 0.00%] train loss: 1.5453322703251615e-05 \n",
      "epoch: 25 [1111/888800 0.12%] train loss: 1.6543861420359462e-05 \n",
      "epoch: 25 [2222/888800 0.25%] train loss: 1.3535377547668759e-05 \n",
      "epoch: 25 [3333/888800 0.38%] train loss: 1.5902392988209613e-05 \n",
      "epoch: 25 [4444/888800 0.50%] train loss: 1.576196518726647e-05 \n",
      "epoch: 25 [5555/888800 0.62%] train loss: 1.4979445950302761e-05 \n",
      "epoch: 25 [6666/888800 0.75%] train loss: 1.4749296497029718e-05 \n",
      "epoch: 25 [7777/888800 0.88%] train loss: 1.450939271308016e-05 \n",
      "epoch: 25 [8888/888800 1.00%] train loss: 1.4962489331082907e-05 \n",
      "epoch: 25 [9999/888800 1.12%] train loss: 1.539623917778954e-05 \n",
      "epoch: 25 [11110/888800 1.25%] train loss: 1.5854071534704417e-05 \n",
      "epoch: 25 [12221/888800 1.38%] train loss: 1.4843929420749191e-05 \n",
      "epoch: 25 [13332/888800 1.50%] train loss: 1.3544651665142737e-05 \n",
      "epoch: 25 [14443/888800 1.62%] train loss: 1.438790604879614e-05 \n",
      "epoch: 25 [15554/888800 1.75%] train loss: 1.4672986253572162e-05 \n",
      "epoch: 25 [16665/888800 1.88%] train loss: 1.3897312783228699e-05 \n",
      "epoch: 25 [17776/888800 2.00%] train loss: 1.5804920622031204e-05 \n",
      "epoch: 25 [18887/888800 2.12%] train loss: 1.4667556570202578e-05 \n",
      "epoch: 25 [19998/888800 2.25%] train loss: 1.3755084182776045e-05 \n",
      "epoch: 25 [21109/888800 2.38%] train loss: 1.4276393812906463e-05 \n",
      "epoch: 25 [22220/888800 2.50%] train loss: 1.4002556781633757e-05 \n",
      "epoch: 25 [23331/888800 2.62%] train loss: 1.3700905583391432e-05 \n",
      "epoch: 25 [24442/888800 2.75%] train loss: 1.3306894288689364e-05 \n",
      "epoch: 25 [25553/888800 2.88%] train loss: 1.5006375178927556e-05 \n",
      "epoch: 25 [26664/888800 3.00%] train loss: 1.358393274131231e-05 \n",
      "epoch: 25 [27775/888800 3.12%] train loss: 1.5194406842056196e-05 \n",
      "epoch: 25 [28886/888800 3.25%] train loss: 1.3552566088037565e-05 \n",
      "epoch: 25 [29997/888800 3.38%] train loss: 1.4672406905447133e-05 \n",
      "epoch: 25 [31108/888800 3.50%] train loss: 1.3237935490906239e-05 \n",
      "epoch: 25 [32219/888800 3.62%] train loss: 1.624467950023245e-05 \n",
      "epoch: 25 [33330/888800 3.75%] train loss: 1.4456030839937739e-05 \n",
      "epoch: 25 [34441/888800 3.88%] train loss: 1.3656370356329717e-05 \n",
      "epoch: 25 [35552/888800 4.00%] train loss: 1.6175552445929497e-05 \n",
      "epoch: 25 [36663/888800 4.12%] train loss: 1.398881522618467e-05 \n",
      "epoch: 25 [37774/888800 4.25%] train loss: 1.4616136468248442e-05 \n",
      "epoch: 25 [38885/888800 4.38%] train loss: 1.3624974599224515e-05 \n",
      "epoch: 25 [39996/888800 4.50%] train loss: 1.4230733540898655e-05 \n",
      "epoch: 25 [41107/888800 4.62%] train loss: 1.3745312571700197e-05 \n",
      "epoch: 25 [42218/888800 4.75%] train loss: 1.5039487152535003e-05 \n",
      "epoch: 25 [43329/888800 4.88%] train loss: 1.519759916845942e-05 \n",
      "epoch: 25 [44440/888800 5.00%] train loss: 1.396175503032282e-05 \n",
      "epoch: 25 [45551/888800 5.12%] train loss: 1.4699114217364695e-05 \n",
      "epoch: 25 [46662/888800 5.25%] train loss: 1.3874051546736155e-05 \n",
      "epoch: 25 [47773/888800 5.38%] train loss: 1.5040221114759333e-05 \n",
      "epoch: 25 [48884/888800 5.50%] train loss: 1.4186923181114253e-05 \n",
      "epoch: 25 [49995/888800 5.62%] train loss: 1.4284240023698658e-05 \n",
      "epoch: 25 [51106/888800 5.75%] train loss: 1.3758627574134152e-05 \n",
      "epoch: 25 [52217/888800 5.88%] train loss: 1.51575759446132e-05 \n",
      "epoch: 25 [53328/888800 6.00%] train loss: 1.4907034710631706e-05 \n",
      "epoch: 25 [54439/888800 6.12%] train loss: 1.4783146070840303e-05 \n",
      "epoch: 25 [55550/888800 6.25%] train loss: 1.440409141650889e-05 \n",
      "epoch: 25 [56661/888800 6.38%] train loss: 1.4504768842016347e-05 \n",
      "epoch: 25 [57772/888800 6.50%] train loss: 1.4465999811363872e-05 \n",
      "epoch: 25 [58883/888800 6.62%] train loss: 1.404683462169487e-05 \n",
      "epoch: 25 [59994/888800 6.75%] train loss: 1.4034155356057454e-05 \n",
      "epoch: 25 [61105/888800 6.88%] train loss: 1.525228435639292e-05 \n",
      "epoch: 25 [62216/888800 7.00%] train loss: 1.5397345123346895e-05 \n",
      "epoch: 25 [63327/888800 7.12%] train loss: 1.354275536868954e-05 \n",
      "epoch: 25 [64438/888800 7.25%] train loss: 1.4631880731030833e-05 \n",
      "epoch: 25 [65549/888800 7.38%] train loss: 1.4759450095880311e-05 \n",
      "epoch: 25 [66660/888800 7.50%] train loss: 1.2995883480471093e-05 \n",
      "epoch: 25 [67771/888800 7.62%] train loss: 1.4681590982945636e-05 \n",
      "epoch: 25 [68882/888800 7.75%] train loss: 1.4771064343221951e-05 \n",
      "epoch: 25 [69993/888800 7.88%] train loss: 1.4539788026013412e-05 \n",
      "epoch: 25 [71104/888800 8.00%] train loss: 1.496302957093576e-05 \n",
      "epoch: 25 [72215/888800 8.12%] train loss: 1.4260354873840697e-05 \n",
      "epoch: 25 [73326/888800 8.25%] train loss: 1.4853700122330338e-05 \n",
      "epoch: 25 [74437/888800 8.38%] train loss: 1.4603929230361246e-05 \n",
      "epoch: 25 [75548/888800 8.50%] train loss: 1.4491882211586926e-05 \n",
      "epoch: 25 [76659/888800 8.62%] train loss: 1.4718524653289933e-05 \n",
      "epoch: 25 [77770/888800 8.75%] train loss: 1.524063918623142e-05 \n",
      "epoch: 25 [78881/888800 8.88%] train loss: 1.3583653526438866e-05 \n",
      "epoch: 25 [79992/888800 9.00%] train loss: 1.6417354345321655e-05 \n",
      "epoch: 25 [81103/888800 9.12%] train loss: 1.583101948199328e-05 \n",
      "epoch: 25 [82214/888800 9.25%] train loss: 1.5300163795473054e-05 \n",
      "epoch: 25 [83325/888800 9.38%] train loss: 1.4238539733923972e-05 \n",
      "epoch: 25 [84436/888800 9.50%] train loss: 1.4563743206963409e-05 \n",
      "epoch: 25 [85547/888800 9.62%] train loss: 1.4215426745067816e-05 \n",
      "epoch: 25 [86658/888800 9.75%] train loss: 1.5258216080837883e-05 \n",
      "epoch: 25 [87769/888800 9.88%] train loss: 1.577916191308759e-05 \n",
      "epoch: 25 [88880/888800 10.00%] train loss: 1.4743160136276856e-05 \n",
      "epoch: 25 [89991/888800 10.12%] train loss: 1.544034603284672e-05 \n",
      "epoch: 25 [91102/888800 10.25%] train loss: 1.325232005910948e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [92213/888800 10.38%] train loss: 1.3926726751378737e-05 \n",
      "epoch: 25 [93324/888800 10.50%] train loss: 1.373394115944393e-05 \n",
      "epoch: 25 [94435/888800 10.62%] train loss: 1.5526635252172127e-05 \n",
      "epoch: 25 [95546/888800 10.75%] train loss: 1.2807430721295532e-05 \n",
      "epoch: 25 [96657/888800 10.88%] train loss: 1.6093526937766e-05 \n",
      "epoch: 25 [97768/888800 11.00%] train loss: 1.3005063919990789e-05 \n",
      "epoch: 25 [98879/888800 11.12%] train loss: 1.4213444956112653e-05 \n",
      "epoch: 25 [99990/888800 11.25%] train loss: 1.5343051927629858e-05 \n",
      "epoch: 25 [101101/888800 11.38%] train loss: 1.4312407984107267e-05 \n",
      "epoch: 25 [102212/888800 11.50%] train loss: 1.543528924230486e-05 \n",
      "epoch: 25 [103323/888800 11.62%] train loss: 1.5169023754424416e-05 \n",
      "epoch: 25 [104434/888800 11.75%] train loss: 1.4857944734103512e-05 \n",
      "epoch: 25 [105545/888800 11.88%] train loss: 1.553516813146416e-05 \n",
      "epoch: 25 [106656/888800 12.00%] train loss: 1.5311168681364506e-05 \n",
      "epoch: 25 [107767/888800 12.12%] train loss: 1.4488299711956643e-05 \n",
      "epoch: 25 [108878/888800 12.25%] train loss: 1.446593159926124e-05 \n",
      "epoch: 25 [109989/888800 12.38%] train loss: 1.3968279745313339e-05 \n",
      "epoch: 25 [111100/888800 12.50%] train loss: 1.539925142424181e-05 \n",
      "epoch: 25 [112211/888800 12.62%] train loss: 1.4364944036060479e-05 \n",
      "epoch: 25 [113322/888800 12.75%] train loss: 1.4479308447334915e-05 \n",
      "epoch: 25 [114433/888800 12.88%] train loss: 1.540487755846698e-05 \n",
      "epoch: 25 [115544/888800 13.00%] train loss: 1.4971828022680711e-05 \n",
      "epoch: 25 [116655/888800 13.12%] train loss: 1.2731946299027186e-05 \n",
      "epoch: 25 [117766/888800 13.25%] train loss: 1.4259831914387178e-05 \n",
      "epoch: 25 [118877/888800 13.38%] train loss: 1.3512096302292775e-05 \n",
      "epoch: 25 [119988/888800 13.50%] train loss: 1.4823175661149435e-05 \n",
      "epoch: 25 [121099/888800 13.62%] train loss: 1.328479265794158e-05 \n",
      "epoch: 25 [122210/888800 13.75%] train loss: 1.3262812899483833e-05 \n",
      "epoch: 25 [123321/888800 13.88%] train loss: 1.4858352187729906e-05 \n",
      "epoch: 25 [124432/888800 14.00%] train loss: 1.575265014253091e-05 \n",
      "epoch: 25 [125543/888800 14.12%] train loss: 1.4596827895729803e-05 \n",
      "epoch: 25 [126654/888800 14.25%] train loss: 1.4090480362938251e-05 \n",
      "epoch: 25 [127765/888800 14.38%] train loss: 1.563598016218748e-05 \n",
      "epoch: 25 [128876/888800 14.50%] train loss: 1.3619463970826473e-05 \n",
      "epoch: 25 [129987/888800 14.62%] train loss: 1.4930350516806357e-05 \n",
      "epoch: 25 [131098/888800 14.75%] train loss: 1.487652934883954e-05 \n",
      "epoch: 25 [132209/888800 14.88%] train loss: 1.4519046089844778e-05 \n",
      "epoch: 25 [133320/888800 15.00%] train loss: 1.5654000890208408e-05 \n",
      "epoch: 25 [134431/888800 15.12%] train loss: 1.5075371265993454e-05 \n",
      "epoch: 25 [135542/888800 15.25%] train loss: 1.5378969692392275e-05 \n",
      "epoch: 25 [136653/888800 15.38%] train loss: 1.4472863767878152e-05 \n",
      "epoch: 25 [137764/888800 15.50%] train loss: 1.5322726540034637e-05 \n",
      "epoch: 25 [138875/888800 15.62%] train loss: 1.3577137906395365e-05 \n",
      "epoch: 25 [139986/888800 15.75%] train loss: 1.4184244719217531e-05 \n",
      "epoch: 25 [141097/888800 15.88%] train loss: 1.3653175301442388e-05 \n",
      "epoch: 25 [142208/888800 16.00%] train loss: 1.5923496903269552e-05 \n",
      "epoch: 25 [143319/888800 16.12%] train loss: 1.4368386473506689e-05 \n",
      "epoch: 25 [144430/888800 16.25%] train loss: 1.5653711670893244e-05 \n",
      "epoch: 25 [145541/888800 16.38%] train loss: 1.4341705536935478e-05 \n",
      "epoch: 25 [146652/888800 16.50%] train loss: 1.4563011973223183e-05 \n",
      "epoch: 25 [147763/888800 16.62%] train loss: 1.4046579053683672e-05 \n",
      "epoch: 25 [148874/888800 16.75%] train loss: 1.5334349882323295e-05 \n",
      "epoch: 25 [149985/888800 16.88%] train loss: 1.477474143030122e-05 \n",
      "epoch: 25 [151096/888800 17.00%] train loss: 1.4655015547759831e-05 \n",
      "epoch: 25 [152207/888800 17.12%] train loss: 1.5341171092586592e-05 \n",
      "epoch: 25 [153318/888800 17.25%] train loss: 1.3896690688852686e-05 \n",
      "epoch: 25 [154429/888800 17.38%] train loss: 1.4950595868867822e-05 \n",
      "epoch: 25 [155540/888800 17.50%] train loss: 1.4347619071486406e-05 \n",
      "epoch: 25 [156651/888800 17.62%] train loss: 1.4325451957120094e-05 \n",
      "epoch: 25 [157762/888800 17.75%] train loss: 1.5459643691428937e-05 \n",
      "epoch: 25 [158873/888800 17.88%] train loss: 1.4452161849476397e-05 \n",
      "epoch: 25 [159984/888800 18.00%] train loss: 1.654279367357958e-05 \n",
      "epoch: 25 [161095/888800 18.12%] train loss: 1.694427919574082e-05 \n",
      "epoch: 25 [162206/888800 18.25%] train loss: 1.37582419483806e-05 \n",
      "epoch: 25 [163317/888800 18.38%] train loss: 1.6088988559204154e-05 \n",
      "epoch: 25 [164428/888800 18.50%] train loss: 1.2919404070999008e-05 \n",
      "epoch: 25 [165539/888800 18.62%] train loss: 1.4431994713959284e-05 \n",
      "epoch: 25 [166650/888800 18.75%] train loss: 1.3939402379037347e-05 \n",
      "epoch: 25 [167761/888800 18.88%] train loss: 1.5552417607977986e-05 \n",
      "epoch: 25 [168872/888800 19.00%] train loss: 1.4089001524553169e-05 \n",
      "epoch: 25 [169983/888800 19.12%] train loss: 1.3426659279502928e-05 \n",
      "epoch: 25 [171094/888800 19.25%] train loss: 1.3270124327391386e-05 \n",
      "epoch: 25 [172205/888800 19.38%] train loss: 1.5755593267385848e-05 \n",
      "epoch: 25 [173316/888800 19.50%] train loss: 1.3836424841429107e-05 \n",
      "epoch: 25 [174427/888800 19.62%] train loss: 1.3537078302761074e-05 \n",
      "epoch: 25 [175538/888800 19.75%] train loss: 1.4614260180678684e-05 \n",
      "epoch: 25 [176649/888800 19.88%] train loss: 1.489516125730006e-05 \n",
      "epoch: 25 [177760/888800 20.00%] train loss: 1.3704487173527014e-05 \n",
      "epoch: 25 [178871/888800 20.12%] train loss: 1.3275399396661669e-05 \n",
      "epoch: 25 [179982/888800 20.25%] train loss: 1.529865403426811e-05 \n",
      "epoch: 25 [181093/888800 20.38%] train loss: 1.4346603165904526e-05 \n",
      "epoch: 25 [182204/888800 20.50%] train loss: 1.3351243069337215e-05 \n",
      "epoch: 25 [183315/888800 20.62%] train loss: 1.4060749890631996e-05 \n",
      "epoch: 25 [184426/888800 20.75%] train loss: 1.3451849554257933e-05 \n",
      "epoch: 25 [185537/888800 20.88%] train loss: 1.4537456081598066e-05 \n",
      "epoch: 25 [186648/888800 21.00%] train loss: 1.4038260815141257e-05 \n",
      "epoch: 25 [187759/888800 21.12%] train loss: 1.3864972970623057e-05 \n",
      "epoch: 25 [188870/888800 21.25%] train loss: 1.384207916999003e-05 \n",
      "epoch: 25 [189981/888800 21.38%] train loss: 1.3882518032914959e-05 \n",
      "epoch: 25 [191092/888800 21.50%] train loss: 1.4191264199325815e-05 \n",
      "epoch: 25 [192203/888800 21.62%] train loss: 1.385662289976608e-05 \n",
      "epoch: 25 [193314/888800 21.75%] train loss: 1.4678713341709226e-05 \n",
      "epoch: 25 [194425/888800 21.88%] train loss: 1.4842140444670804e-05 \n",
      "epoch: 25 [195536/888800 22.00%] train loss: 1.4925696632417385e-05 \n",
      "epoch: 25 [196647/888800 22.12%] train loss: 1.5791392797837034e-05 \n",
      "epoch: 25 [197758/888800 22.25%] train loss: 1.316653288085945e-05 \n",
      "epoch: 25 [198869/888800 22.38%] train loss: 1.5905261534499004e-05 \n",
      "epoch: 25 [199980/888800 22.50%] train loss: 1.3570804185292218e-05 \n",
      "epoch: 25 [201091/888800 22.62%] train loss: 1.5425437595695257e-05 \n",
      "epoch: 25 [202202/888800 22.75%] train loss: 1.3095613212499302e-05 \n",
      "epoch: 25 [203313/888800 22.88%] train loss: 1.554769551148638e-05 \n",
      "epoch: 25 [204424/888800 23.00%] train loss: 1.3745625437877607e-05 \n",
      "epoch: 25 [205535/888800 23.12%] train loss: 1.6376241546822712e-05 \n",
      "epoch: 25 [206646/888800 23.25%] train loss: 1.4132226169749629e-05 \n",
      "epoch: 25 [207757/888800 23.38%] train loss: 1.4162747902446426e-05 \n",
      "epoch: 25 [208868/888800 23.50%] train loss: 1.2373169738566503e-05 \n",
      "epoch: 25 [209979/888800 23.62%] train loss: 1.32517661768361e-05 \n",
      "epoch: 25 [211090/888800 23.75%] train loss: 1.4270742212829646e-05 \n",
      "epoch: 25 [212201/888800 23.88%] train loss: 1.4705867215525359e-05 \n",
      "epoch: 25 [213312/888800 24.00%] train loss: 1.510070069343783e-05 \n",
      "epoch: 25 [214423/888800 24.12%] train loss: 1.4668562471342739e-05 \n",
      "epoch: 25 [215534/888800 24.25%] train loss: 1.444589452148648e-05 \n",
      "epoch: 25 [216645/888800 24.38%] train loss: 1.3739421774516813e-05 \n",
      "epoch: 25 [217756/888800 24.50%] train loss: 1.547730789752677e-05 \n",
      "epoch: 25 [218867/888800 24.62%] train loss: 1.4862947864457965e-05 \n",
      "epoch: 25 [219978/888800 24.75%] train loss: 1.512095332145691e-05 \n",
      "epoch: 25 [221089/888800 24.88%] train loss: 1.413410427630879e-05 \n",
      "epoch: 25 [222200/888800 25.00%] train loss: 1.3456956367008388e-05 \n",
      "epoch: 25 [223311/888800 25.12%] train loss: 1.5026270375528838e-05 \n",
      "epoch: 25 [224422/888800 25.25%] train loss: 1.4268955055740662e-05 \n",
      "epoch: 25 [225533/888800 25.38%] train loss: 1.4998552614997607e-05 \n",
      "epoch: 25 [226644/888800 25.50%] train loss: 1.6557702110731043e-05 \n",
      "epoch: 25 [227755/888800 25.62%] train loss: 1.4911467587808147e-05 \n",
      "epoch: 25 [228866/888800 25.75%] train loss: 1.511030950496206e-05 \n",
      "epoch: 25 [229977/888800 25.88%] train loss: 1.470874576625647e-05 \n",
      "epoch: 25 [231088/888800 26.00%] train loss: 1.6077430700534023e-05 \n",
      "epoch: 25 [232199/888800 26.12%] train loss: 1.4797772564634215e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [233310/888800 26.25%] train loss: 1.6909405530896038e-05 \n",
      "epoch: 25 [234421/888800 26.38%] train loss: 1.423555841029156e-05 \n",
      "epoch: 25 [235532/888800 26.50%] train loss: 1.4445418855757453e-05 \n",
      "epoch: 25 [236643/888800 26.62%] train loss: 1.4499497410724871e-05 \n",
      "epoch: 25 [237754/888800 26.75%] train loss: 1.542090467410162e-05 \n",
      "epoch: 25 [238865/888800 26.88%] train loss: 1.407909167028265e-05 \n",
      "epoch: 25 [239976/888800 27.00%] train loss: 1.3177176697354298e-05 \n",
      "epoch: 25 [241087/888800 27.12%] train loss: 1.3187323020247277e-05 \n",
      "epoch: 25 [242198/888800 27.25%] train loss: 1.5141390576900449e-05 \n",
      "epoch: 25 [243309/888800 27.38%] train loss: 1.4554605513694696e-05 \n",
      "epoch: 25 [244420/888800 27.50%] train loss: 1.5128612176340539e-05 \n",
      "epoch: 25 [245531/888800 27.62%] train loss: 1.393979891872732e-05 \n",
      "epoch: 25 [246642/888800 27.75%] train loss: 1.4661682143923827e-05 \n",
      "epoch: 25 [247753/888800 27.88%] train loss: 1.4128024304227438e-05 \n",
      "epoch: 25 [248864/888800 28.00%] train loss: 1.3921824574936181e-05 \n",
      "epoch: 25 [249975/888800 28.12%] train loss: 1.4439418009715155e-05 \n",
      "epoch: 25 [251086/888800 28.25%] train loss: 1.356531629426172e-05 \n",
      "epoch: 25 [252197/888800 28.38%] train loss: 1.3103985111229122e-05 \n",
      "epoch: 25 [253308/888800 28.50%] train loss: 1.4793439731874969e-05 \n",
      "epoch: 25 [254419/888800 28.62%] train loss: 1.3575438970292453e-05 \n",
      "epoch: 25 [255530/888800 28.75%] train loss: 1.4017267858434934e-05 \n",
      "epoch: 25 [256641/888800 28.88%] train loss: 1.4965078662498854e-05 \n",
      "epoch: 25 [257752/888800 29.00%] train loss: 1.2925672308483627e-05 \n",
      "epoch: 25 [258863/888800 29.12%] train loss: 1.4084845133766066e-05 \n",
      "epoch: 25 [259974/888800 29.25%] train loss: 1.4880250091664493e-05 \n",
      "epoch: 25 [261085/888800 29.38%] train loss: 1.2496760064095724e-05 \n",
      "epoch: 25 [262196/888800 29.50%] train loss: 1.4374703823705204e-05 \n",
      "epoch: 25 [263307/888800 29.62%] train loss: 1.2969795534445439e-05 \n",
      "epoch: 25 [264418/888800 29.75%] train loss: 1.5925303159747273e-05 \n",
      "epoch: 25 [265529/888800 29.88%] train loss: 1.427500774298096e-05 \n",
      "epoch: 25 [266640/888800 30.00%] train loss: 1.4952281162550207e-05 \n",
      "epoch: 25 [267751/888800 30.12%] train loss: 1.3990300431032665e-05 \n",
      "epoch: 25 [268862/888800 30.25%] train loss: 1.3599361409433186e-05 \n",
      "epoch: 25 [269973/888800 30.38%] train loss: 1.4322625247586984e-05 \n",
      "epoch: 25 [271084/888800 30.50%] train loss: 1.4892410035827197e-05 \n",
      "epoch: 25 [272195/888800 30.62%] train loss: 1.3499801752914209e-05 \n",
      "epoch: 25 [273306/888800 30.75%] train loss: 1.3432690138870385e-05 \n",
      "epoch: 25 [274417/888800 30.88%] train loss: 1.3848595699528232e-05 \n",
      "epoch: 25 [275528/888800 31.00%] train loss: 1.3310328540683258e-05 \n",
      "epoch: 25 [276639/888800 31.12%] train loss: 1.4068347809370607e-05 \n",
      "epoch: 25 [277750/888800 31.25%] train loss: 1.4389708667295054e-05 \n",
      "epoch: 25 [278861/888800 31.38%] train loss: 1.3625522115034983e-05 \n",
      "epoch: 25 [279972/888800 31.50%] train loss: 1.4084745998843573e-05 \n",
      "epoch: 25 [281083/888800 31.62%] train loss: 1.4516740520775784e-05 \n",
      "epoch: 25 [282194/888800 31.75%] train loss: 1.3895549273001961e-05 \n",
      "epoch: 25 [283305/888800 31.88%] train loss: 1.6368885553674772e-05 \n",
      "epoch: 25 [284416/888800 32.00%] train loss: 1.5707890270277858e-05 \n",
      "epoch: 25 [285527/888800 32.12%] train loss: 1.4013032341608778e-05 \n",
      "epoch: 25 [286638/888800 32.25%] train loss: 1.415863516740501e-05 \n",
      "epoch: 25 [287749/888800 32.38%] train loss: 1.4147070032777265e-05 \n",
      "epoch: 25 [288860/888800 32.50%] train loss: 1.4136462596070487e-05 \n",
      "epoch: 25 [289971/888800 32.62%] train loss: 1.3284688066050876e-05 \n",
      "epoch: 25 [291082/888800 32.75%] train loss: 1.6558262359467335e-05 \n",
      "epoch: 25 [292193/888800 32.88%] train loss: 1.4427020687435288e-05 \n",
      "epoch: 25 [293304/888800 33.00%] train loss: 1.5218112821457908e-05 \n",
      "epoch: 25 [294415/888800 33.12%] train loss: 1.4031502360012382e-05 \n",
      "epoch: 25 [295526/888800 33.25%] train loss: 1.5136269212234765e-05 \n",
      "epoch: 25 [296637/888800 33.38%] train loss: 1.3602872968476731e-05 \n",
      "epoch: 25 [297748/888800 33.50%] train loss: 1.5038725905469619e-05 \n",
      "epoch: 25 [298859/888800 33.62%] train loss: 1.4313131032395177e-05 \n",
      "epoch: 25 [299970/888800 33.75%] train loss: 1.5751616956549697e-05 \n",
      "epoch: 25 [301081/888800 33.88%] train loss: 1.3432163541438058e-05 \n",
      "epoch: 25 [302192/888800 34.00%] train loss: 1.5466932381968945e-05 \n",
      "epoch: 25 [303303/888800 34.12%] train loss: 1.3765421499556396e-05 \n",
      "epoch: 25 [304414/888800 34.25%] train loss: 1.558360963826999e-05 \n",
      "epoch: 25 [305525/888800 34.38%] train loss: 1.4438930520555004e-05 \n",
      "epoch: 25 [306636/888800 34.50%] train loss: 1.5295512639568187e-05 \n",
      "epoch: 25 [307747/888800 34.62%] train loss: 1.5153967979131266e-05 \n",
      "epoch: 25 [308858/888800 34.75%] train loss: 1.3640652468893677e-05 \n",
      "epoch: 25 [309969/888800 34.88%] train loss: 1.3424026292341296e-05 \n",
      "epoch: 25 [311080/888800 35.00%] train loss: 1.4199673387338407e-05 \n",
      "epoch: 25 [312191/888800 35.12%] train loss: 1.4156933502817992e-05 \n",
      "epoch: 25 [313302/888800 35.25%] train loss: 1.3850094546796754e-05 \n",
      "epoch: 25 [314413/888800 35.38%] train loss: 1.3032435163040645e-05 \n",
      "epoch: 25 [315524/888800 35.50%] train loss: 1.3610337191494182e-05 \n",
      "epoch: 25 [316635/888800 35.62%] train loss: 1.5207047908916138e-05 \n",
      "epoch: 25 [317746/888800 35.75%] train loss: 1.4223764082998969e-05 \n",
      "epoch: 25 [318857/888800 35.88%] train loss: 1.4980137166276108e-05 \n",
      "epoch: 25 [319968/888800 36.00%] train loss: 1.4402482520381454e-05 \n",
      "epoch: 25 [321079/888800 36.12%] train loss: 1.4108149116509594e-05 \n",
      "epoch: 25 [322190/888800 36.25%] train loss: 1.5281902960850857e-05 \n",
      "epoch: 25 [323301/888800 36.38%] train loss: 1.3386088539846241e-05 \n",
      "epoch: 25 [324412/888800 36.50%] train loss: 1.4715252291352954e-05 \n",
      "epoch: 25 [325523/888800 36.62%] train loss: 1.3511967154045124e-05 \n",
      "epoch: 25 [326634/888800 36.75%] train loss: 1.4269853636506014e-05 \n",
      "epoch: 25 [327745/888800 36.88%] train loss: 1.5033991076052189e-05 \n",
      "epoch: 25 [328856/888800 37.00%] train loss: 1.378015622321982e-05 \n",
      "epoch: 25 [329967/888800 37.12%] train loss: 1.4816057046118658e-05 \n",
      "epoch: 25 [331078/888800 37.25%] train loss: 1.4664006812381558e-05 \n",
      "epoch: 25 [332189/888800 37.38%] train loss: 1.4780946003156714e-05 \n",
      "epoch: 25 [333300/888800 37.50%] train loss: 1.51160747918766e-05 \n",
      "epoch: 25 [334411/888800 37.62%] train loss: 1.418014562659664e-05 \n",
      "epoch: 25 [335522/888800 37.75%] train loss: 1.5363835700554773e-05 \n",
      "epoch: 25 [336633/888800 37.88%] train loss: 1.459825307392748e-05 \n",
      "epoch: 25 [337744/888800 38.00%] train loss: 1.4749984075024258e-05 \n",
      "epoch: 25 [338855/888800 38.12%] train loss: 1.402014913765015e-05 \n",
      "epoch: 25 [339966/888800 38.25%] train loss: 1.395756862621056e-05 \n",
      "epoch: 25 [341077/888800 38.38%] train loss: 1.355049607809633e-05 \n",
      "epoch: 25 [342188/888800 38.50%] train loss: 1.5442683434230275e-05 \n",
      "epoch: 25 [343299/888800 38.62%] train loss: 1.3694539120479021e-05 \n",
      "epoch: 25 [344410/888800 38.75%] train loss: 1.4550259948009625e-05 \n",
      "epoch: 25 [345521/888800 38.88%] train loss: 1.4829730389465112e-05 \n",
      "epoch: 25 [346632/888800 39.00%] train loss: 1.4352269317896571e-05 \n",
      "epoch: 25 [347743/888800 39.12%] train loss: 1.4805668797635008e-05 \n",
      "epoch: 25 [348854/888800 39.25%] train loss: 1.2901079571747687e-05 \n",
      "epoch: 25 [349965/888800 39.38%] train loss: 1.3936142750026193e-05 \n",
      "epoch: 25 [351076/888800 39.50%] train loss: 1.3889112778997514e-05 \n",
      "epoch: 25 [352187/888800 39.62%] train loss: 1.3551468327932525e-05 \n",
      "epoch: 25 [353298/888800 39.75%] train loss: 1.4079851098358631e-05 \n",
      "epoch: 25 [354409/888800 39.88%] train loss: 1.3184612726035994e-05 \n",
      "epoch: 25 [355520/888800 40.00%] train loss: 1.556333518237807e-05 \n",
      "epoch: 25 [356631/888800 40.12%] train loss: 1.4556278983945958e-05 \n",
      "epoch: 25 [357742/888800 40.25%] train loss: 1.5123280718398746e-05 \n",
      "epoch: 25 [358853/888800 40.38%] train loss: 1.45894910019706e-05 \n",
      "epoch: 25 [359964/888800 40.50%] train loss: 1.4496667063212954e-05 \n",
      "epoch: 25 [361075/888800 40.62%] train loss: 1.4119213119556662e-05 \n",
      "epoch: 25 [362186/888800 40.75%] train loss: 1.4820237993262708e-05 \n",
      "epoch: 25 [363297/888800 40.88%] train loss: 1.394475930283079e-05 \n",
      "epoch: 25 [364408/888800 41.00%] train loss: 1.3913928341935389e-05 \n",
      "epoch: 25 [365519/888800 41.12%] train loss: 1.478971626056591e-05 \n",
      "epoch: 25 [366630/888800 41.25%] train loss: 1.4133423064777162e-05 \n",
      "epoch: 25 [367741/888800 41.38%] train loss: 1.384616280120099e-05 \n",
      "epoch: 25 [368852/888800 41.50%] train loss: 1.5278050341294147e-05 \n",
      "epoch: 25 [369963/888800 41.62%] train loss: 1.3981974007037934e-05 \n",
      "epoch: 25 [371074/888800 41.75%] train loss: 1.4769619156140834e-05 \n",
      "epoch: 25 [372185/888800 41.88%] train loss: 1.3254279110697098e-05 \n",
      "epoch: 25 [373296/888800 42.00%] train loss: 1.357762266707141e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [374407/888800 42.12%] train loss: 1.469538710807683e-05 \n",
      "epoch: 25 [375518/888800 42.25%] train loss: 1.5467885532416403e-05 \n",
      "epoch: 25 [376629/888800 42.38%] train loss: 1.4283064956543967e-05 \n",
      "epoch: 25 [377740/888800 42.50%] train loss: 1.4151231880532578e-05 \n",
      "epoch: 25 [378851/888800 42.62%] train loss: 1.5195309060800355e-05 \n",
      "epoch: 25 [379962/888800 42.75%] train loss: 1.3813067198498175e-05 \n",
      "epoch: 25 [381073/888800 42.88%] train loss: 1.3188241609896068e-05 \n",
      "epoch: 25 [382184/888800 43.00%] train loss: 1.3663758181792218e-05 \n",
      "epoch: 25 [383295/888800 43.12%] train loss: 1.3437123016046826e-05 \n",
      "epoch: 25 [384406/888800 43.25%] train loss: 1.3231517186795827e-05 \n",
      "epoch: 25 [385517/888800 43.38%] train loss: 1.4742768144060392e-05 \n",
      "epoch: 25 [386628/888800 43.50%] train loss: 1.2693401004071347e-05 \n",
      "epoch: 25 [387739/888800 43.62%] train loss: 1.4286109944805503e-05 \n",
      "epoch: 25 [388850/888800 43.75%] train loss: 1.3927467989560682e-05 \n",
      "epoch: 25 [389961/888800 43.88%] train loss: 1.461612009734381e-05 \n",
      "epoch: 25 [391072/888800 44.00%] train loss: 1.359534689981956e-05 \n",
      "epoch: 25 [392183/888800 44.12%] train loss: 1.488411635364173e-05 \n",
      "epoch: 25 [393294/888800 44.25%] train loss: 1.4001940144225955e-05 \n",
      "epoch: 25 [394405/888800 44.38%] train loss: 1.3315896467247512e-05 \n",
      "epoch: 25 [395516/888800 44.50%] train loss: 1.4597523659176659e-05 \n",
      "epoch: 25 [396627/888800 44.62%] train loss: 1.314043220190797e-05 \n",
      "epoch: 25 [397738/888800 44.75%] train loss: 1.4062095033295918e-05 \n",
      "epoch: 25 [398849/888800 44.88%] train loss: 1.4560775525751524e-05 \n",
      "epoch: 25 [399960/888800 45.00%] train loss: 1.3037075405009091e-05 \n",
      "epoch: 25 [401071/888800 45.12%] train loss: 1.4620849469793029e-05 \n",
      "epoch: 25 [402182/888800 45.25%] train loss: 1.5121724572964013e-05 \n",
      "epoch: 25 [403293/888800 45.38%] train loss: 1.4597084373235703e-05 \n",
      "epoch: 25 [404404/888800 45.50%] train loss: 1.4483003724308219e-05 \n",
      "epoch: 25 [405515/888800 45.62%] train loss: 1.3905325431551319e-05 \n",
      "epoch: 25 [406626/888800 45.75%] train loss: 1.4101229680818506e-05 \n",
      "epoch: 25 [407737/888800 45.88%] train loss: 1.3231837328930851e-05 \n",
      "epoch: 25 [408848/888800 46.00%] train loss: 1.5024127606011461e-05 \n",
      "epoch: 25 [409959/888800 46.12%] train loss: 1.4800726603425574e-05 \n",
      "epoch: 25 [411070/888800 46.25%] train loss: 1.3712367945117876e-05 \n",
      "epoch: 25 [412181/888800 46.38%] train loss: 1.4050211575522553e-05 \n",
      "epoch: 25 [413292/888800 46.50%] train loss: 1.5337458535213955e-05 \n",
      "epoch: 25 [414403/888800 46.62%] train loss: 1.339120717602782e-05 \n",
      "epoch: 25 [415514/888800 46.75%] train loss: 1.3718232366954908e-05 \n",
      "epoch: 25 [416625/888800 46.88%] train loss: 1.4388712770596612e-05 \n",
      "epoch: 25 [417736/888800 47.00%] train loss: 1.3607777873403393e-05 \n",
      "epoch: 25 [418847/888800 47.12%] train loss: 1.402743873768486e-05 \n",
      "epoch: 25 [419958/888800 47.25%] train loss: 1.4295485016191378e-05 \n",
      "epoch: 25 [421069/888800 47.38%] train loss: 1.5307259673136286e-05 \n",
      "epoch: 25 [422180/888800 47.50%] train loss: 1.4302822819445282e-05 \n",
      "epoch: 25 [423291/888800 47.62%] train loss: 1.4465104868577328e-05 \n",
      "epoch: 25 [424402/888800 47.75%] train loss: 1.527194217487704e-05 \n",
      "epoch: 25 [425513/888800 47.88%] train loss: 1.2309031262702774e-05 \n",
      "epoch: 25 [426624/888800 48.00%] train loss: 1.3898789802624378e-05 \n",
      "epoch: 25 [427735/888800 48.12%] train loss: 1.511116624897113e-05 \n",
      "epoch: 25 [428846/888800 48.25%] train loss: 1.5098759831744246e-05 \n",
      "epoch: 25 [429957/888800 48.38%] train loss: 1.5764080671942793e-05 \n",
      "epoch: 25 [431068/888800 48.50%] train loss: 1.4040638234291691e-05 \n",
      "epoch: 25 [432179/888800 48.62%] train loss: 1.3818660590914078e-05 \n",
      "epoch: 25 [433290/888800 48.75%] train loss: 1.5339899618993513e-05 \n",
      "epoch: 25 [434401/888800 48.88%] train loss: 1.4137899597699288e-05 \n",
      "epoch: 25 [435512/888800 49.00%] train loss: 1.4217981515685096e-05 \n",
      "epoch: 25 [436623/888800 49.12%] train loss: 1.3784022485197056e-05 \n",
      "epoch: 25 [437734/888800 49.25%] train loss: 1.377679654979147e-05 \n",
      "epoch: 25 [438845/888800 49.38%] train loss: 1.3643056263390463e-05 \n",
      "epoch: 25 [439956/888800 49.50%] train loss: 1.3208755262894556e-05 \n",
      "epoch: 25 [441067/888800 49.62%] train loss: 1.4761273632757366e-05 \n",
      "epoch: 25 [442178/888800 49.75%] train loss: 1.3710309758607764e-05 \n",
      "epoch: 25 [443289/888800 49.88%] train loss: 1.4146497051115148e-05 \n",
      "epoch: 25 [444400/888800 50.00%] train loss: 1.4422466847463511e-05 \n",
      "epoch: 25 [445511/888800 50.12%] train loss: 1.438180697732605e-05 \n",
      "epoch: 25 [446622/888800 50.25%] train loss: 1.4647979696746916e-05 \n",
      "epoch: 25 [447733/888800 50.38%] train loss: 1.57417689479189e-05 \n",
      "epoch: 25 [448844/888800 50.50%] train loss: 1.4114575606072322e-05 \n",
      "epoch: 25 [449955/888800 50.62%] train loss: 1.393894217471825e-05 \n",
      "epoch: 25 [451066/888800 50.75%] train loss: 1.2799696378351655e-05 \n",
      "epoch: 25 [452177/888800 50.88%] train loss: 1.4243839359551203e-05 \n",
      "epoch: 25 [453288/888800 51.00%] train loss: 1.4234024092729669e-05 \n",
      "epoch: 25 [454399/888800 51.12%] train loss: 1.4467827895714436e-05 \n",
      "epoch: 25 [455510/888800 51.25%] train loss: 1.3820628737448715e-05 \n",
      "epoch: 25 [456621/888800 51.38%] train loss: 1.3503168702300172e-05 \n",
      "epoch: 25 [457732/888800 51.50%] train loss: 1.3247535207483452e-05 \n",
      "epoch: 25 [458843/888800 51.62%] train loss: 1.3990132174512837e-05 \n",
      "epoch: 25 [459954/888800 51.75%] train loss: 1.3643933016282972e-05 \n",
      "epoch: 25 [461065/888800 51.88%] train loss: 1.2796269402315374e-05 \n",
      "epoch: 25 [462176/888800 52.00%] train loss: 1.3937173207523301e-05 \n",
      "epoch: 25 [463287/888800 52.12%] train loss: 1.4436068340728525e-05 \n",
      "epoch: 25 [464398/888800 52.25%] train loss: 1.3187343938625418e-05 \n",
      "epoch: 25 [465509/888800 52.38%] train loss: 1.4299055692390539e-05 \n",
      "epoch: 25 [466620/888800 52.50%] train loss: 1.439795050828252e-05 \n",
      "epoch: 25 [467731/888800 52.62%] train loss: 1.4338600522023626e-05 \n",
      "epoch: 25 [468842/888800 52.75%] train loss: 1.672851067269221e-05 \n",
      "epoch: 25 [469953/888800 52.88%] train loss: 1.2713779142359272e-05 \n",
      "epoch: 25 [471064/888800 53.00%] train loss: 1.4965115042286925e-05 \n",
      "epoch: 25 [472175/888800 53.12%] train loss: 1.4465094864135608e-05 \n",
      "epoch: 25 [473286/888800 53.25%] train loss: 1.4506428669847082e-05 \n",
      "epoch: 25 [474397/888800 53.38%] train loss: 1.4286619261838496e-05 \n",
      "epoch: 25 [475508/888800 53.50%] train loss: 1.5395786249428056e-05 \n",
      "epoch: 25 [476619/888800 53.62%] train loss: 1.373322811559774e-05 \n",
      "epoch: 25 [477730/888800 53.75%] train loss: 1.5324147170758806e-05 \n",
      "epoch: 25 [478841/888800 53.88%] train loss: 1.4499547432933468e-05 \n",
      "epoch: 25 [479952/888800 54.00%] train loss: 1.4192967682902236e-05 \n",
      "epoch: 25 [481063/888800 54.12%] train loss: 1.4995913261373062e-05 \n",
      "epoch: 25 [482174/888800 54.25%] train loss: 1.3975340152683202e-05 \n",
      "epoch: 25 [483285/888800 54.38%] train loss: 1.3318087439984083e-05 \n",
      "epoch: 25 [484396/888800 54.50%] train loss: 1.4772684153285809e-05 \n",
      "epoch: 25 [485507/888800 54.62%] train loss: 1.375531246594619e-05 \n",
      "epoch: 25 [486618/888800 54.75%] train loss: 1.3626530744659249e-05 \n",
      "epoch: 25 [487729/888800 54.88%] train loss: 1.5735022316221148e-05 \n",
      "epoch: 25 [488840/888800 55.00%] train loss: 1.4959914551582187e-05 \n",
      "epoch: 25 [489951/888800 55.12%] train loss: 1.3916953321313486e-05 \n",
      "epoch: 25 [491062/888800 55.25%] train loss: 1.5990288375178352e-05 \n",
      "epoch: 25 [492173/888800 55.38%] train loss: 1.3282685358717572e-05 \n",
      "epoch: 25 [493284/888800 55.50%] train loss: 1.4191155059961602e-05 \n",
      "epoch: 25 [494395/888800 55.62%] train loss: 1.3493166989064775e-05 \n",
      "epoch: 25 [495506/888800 55.75%] train loss: 1.507789329480147e-05 \n",
      "epoch: 25 [496617/888800 55.88%] train loss: 1.4095687220105901e-05 \n",
      "epoch: 25 [497728/888800 56.00%] train loss: 1.4592586012440734e-05 \n",
      "epoch: 25 [498839/888800 56.12%] train loss: 1.4375228602148127e-05 \n",
      "epoch: 25 [499950/888800 56.25%] train loss: 1.4848578757664654e-05 \n",
      "epoch: 25 [501061/888800 56.38%] train loss: 1.4287305020843633e-05 \n",
      "epoch: 25 [502172/888800 56.50%] train loss: 1.4218796422937885e-05 \n",
      "epoch: 25 [503283/888800 56.62%] train loss: 1.456298468838213e-05 \n",
      "epoch: 25 [504394/888800 56.75%] train loss: 1.4371861652762163e-05 \n",
      "epoch: 25 [505505/888800 56.88%] train loss: 1.3463950381265022e-05 \n",
      "epoch: 25 [506616/888800 57.00%] train loss: 1.5068641914695036e-05 \n",
      "epoch: 25 [507727/888800 57.12%] train loss: 1.486790097260382e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [508838/888800 57.25%] train loss: 1.3306360415299423e-05 \n",
      "epoch: 25 [509949/888800 57.38%] train loss: 1.4428701433644164e-05 \n",
      "epoch: 25 [511060/888800 57.50%] train loss: 1.4018442016094923e-05 \n",
      "epoch: 25 [512171/888800 57.62%] train loss: 1.4557909707946237e-05 \n",
      "epoch: 25 [513282/888800 57.75%] train loss: 1.3573469004768413e-05 \n",
      "epoch: 25 [514393/888800 57.88%] train loss: 1.4352249309013132e-05 \n",
      "epoch: 25 [515504/888800 58.00%] train loss: 1.4191083209880162e-05 \n",
      "epoch: 25 [516615/888800 58.12%] train loss: 1.3947086699772626e-05 \n",
      "epoch: 25 [517726/888800 58.25%] train loss: 1.4337185348267667e-05 \n",
      "epoch: 25 [518837/888800 58.38%] train loss: 1.4759417354071047e-05 \n",
      "epoch: 25 [519948/888800 58.50%] train loss: 1.511391565145459e-05 \n",
      "epoch: 25 [521059/888800 58.62%] train loss: 1.402608359057922e-05 \n",
      "epoch: 25 [522170/888800 58.75%] train loss: 1.3782697351416573e-05 \n",
      "epoch: 25 [523281/888800 58.88%] train loss: 1.4536009075527545e-05 \n",
      "epoch: 25 [524392/888800 59.00%] train loss: 1.5647177860955708e-05 \n",
      "epoch: 25 [525503/888800 59.12%] train loss: 1.2992585652682465e-05 \n",
      "epoch: 25 [526614/888800 59.25%] train loss: 1.4466494576481637e-05 \n",
      "epoch: 25 [527725/888800 59.38%] train loss: 1.447609975002706e-05 \n",
      "epoch: 25 [528836/888800 59.50%] train loss: 1.3930149179941509e-05 \n",
      "epoch: 25 [529947/888800 59.62%] train loss: 1.5195695596048608e-05 \n",
      "epoch: 25 [531058/888800 59.75%] train loss: 1.3340147233975586e-05 \n",
      "epoch: 25 [532169/888800 59.88%] train loss: 1.4679830201203004e-05 \n",
      "epoch: 25 [533280/888800 60.00%] train loss: 1.4545723388437182e-05 \n",
      "epoch: 25 [534391/888800 60.12%] train loss: 1.449394130759174e-05 \n",
      "epoch: 25 [535502/888800 60.25%] train loss: 1.3851702533429489e-05 \n",
      "epoch: 25 [536613/888800 60.38%] train loss: 1.4579802154912613e-05 \n",
      "epoch: 25 [537724/888800 60.50%] train loss: 1.4653484868176747e-05 \n",
      "epoch: 25 [538835/888800 60.62%] train loss: 1.55944380821893e-05 \n",
      "epoch: 25 [539946/888800 60.75%] train loss: 1.4036529137229081e-05 \n",
      "epoch: 25 [541057/888800 60.88%] train loss: 1.589548628544435e-05 \n",
      "epoch: 25 [542168/888800 61.00%] train loss: 1.4968345567467622e-05 \n",
      "epoch: 25 [543279/888800 61.12%] train loss: 1.3547759408538695e-05 \n",
      "epoch: 25 [544390/888800 61.25%] train loss: 1.3034224139119033e-05 \n",
      "epoch: 25 [545501/888800 61.38%] train loss: 1.4420015759242233e-05 \n",
      "epoch: 25 [546612/888800 61.50%] train loss: 1.579295530973468e-05 \n",
      "epoch: 25 [547723/888800 61.62%] train loss: 1.4987436770752538e-05 \n",
      "epoch: 25 [548834/888800 61.75%] train loss: 1.3919304365117569e-05 \n",
      "epoch: 25 [549945/888800 61.88%] train loss: 1.5251228433044162e-05 \n",
      "epoch: 25 [551056/888800 62.00%] train loss: 1.443673772882903e-05 \n",
      "epoch: 25 [552167/888800 62.12%] train loss: 1.3649284483108204e-05 \n",
      "epoch: 25 [553278/888800 62.25%] train loss: 1.4437123354582582e-05 \n",
      "epoch: 25 [554389/888800 62.38%] train loss: 1.4649759577878285e-05 \n",
      "epoch: 25 [555500/888800 62.50%] train loss: 1.5201102542050648e-05 \n",
      "epoch: 25 [556611/888800 62.62%] train loss: 1.4646076124336105e-05 \n",
      "epoch: 25 [557722/888800 62.75%] train loss: 1.3005441360292025e-05 \n",
      "epoch: 25 [558833/888800 62.88%] train loss: 1.3615518582810182e-05 \n",
      "epoch: 25 [559944/888800 63.00%] train loss: 1.3325736290425994e-05 \n",
      "epoch: 25 [561055/888800 63.12%] train loss: 1.3268553630041424e-05 \n",
      "epoch: 25 [562166/888800 63.25%] train loss: 1.3999729162605945e-05 \n",
      "epoch: 25 [563277/888800 63.38%] train loss: 1.4343690963869449e-05 \n",
      "epoch: 25 [564388/888800 63.50%] train loss: 1.3846964975527953e-05 \n",
      "epoch: 25 [565499/888800 63.62%] train loss: 1.507924753241241e-05 \n",
      "epoch: 25 [566610/888800 63.75%] train loss: 1.4479675883194432e-05 \n",
      "epoch: 25 [567721/888800 63.88%] train loss: 1.3304331332619768e-05 \n",
      "epoch: 25 [568832/888800 64.00%] train loss: 1.2641878129215911e-05 \n",
      "epoch: 25 [569943/888800 64.12%] train loss: 1.5341058315243572e-05 \n",
      "epoch: 25 [571054/888800 64.25%] train loss: 1.529460132587701e-05 \n",
      "epoch: 25 [572165/888800 64.38%] train loss: 1.3576425772043876e-05 \n",
      "epoch: 25 [573276/888800 64.50%] train loss: 1.5860066923778504e-05 \n",
      "epoch: 25 [574387/888800 64.62%] train loss: 1.461130796087673e-05 \n",
      "epoch: 25 [575498/888800 64.75%] train loss: 1.3811901226290502e-05 \n",
      "epoch: 25 [576609/888800 64.88%] train loss: 1.478809008403914e-05 \n",
      "epoch: 25 [577720/888800 65.00%] train loss: 1.4090588592807762e-05 \n",
      "epoch: 25 [578831/888800 65.12%] train loss: 1.5487212294829078e-05 \n",
      "epoch: 25 [579942/888800 65.25%] train loss: 1.4387851479114033e-05 \n",
      "epoch: 25 [581053/888800 65.38%] train loss: 1.538487231300678e-05 \n",
      "epoch: 25 [582164/888800 65.50%] train loss: 1.4117346836428624e-05 \n",
      "epoch: 25 [583275/888800 65.62%] train loss: 1.3491920071828645e-05 \n",
      "epoch: 25 [584386/888800 65.75%] train loss: 1.4418815226235893e-05 \n",
      "epoch: 25 [585497/888800 65.88%] train loss: 1.5113180779735558e-05 \n",
      "epoch: 25 [586608/888800 66.00%] train loss: 1.4730309885635506e-05 \n",
      "epoch: 25 [587719/888800 66.12%] train loss: 1.4563417607860174e-05 \n",
      "epoch: 25 [588830/888800 66.25%] train loss: 1.752587195369415e-05 \n",
      "epoch: 25 [589941/888800 66.38%] train loss: 1.3807397408527322e-05 \n",
      "epoch: 25 [591052/888800 66.50%] train loss: 1.699576932878699e-05 \n",
      "epoch: 25 [592163/888800 66.62%] train loss: 1.457755388400983e-05 \n",
      "epoch: 25 [593274/888800 66.75%] train loss: 1.5728011931059882e-05 \n",
      "epoch: 25 [594385/888800 66.88%] train loss: 1.5954909031279385e-05 \n",
      "epoch: 25 [595496/888800 67.00%] train loss: 1.5219782653730363e-05 \n",
      "epoch: 25 [596607/888800 67.12%] train loss: 1.5432906366186216e-05 \n",
      "epoch: 25 [597718/888800 67.25%] train loss: 1.43873730849009e-05 \n",
      "epoch: 25 [598829/888800 67.38%] train loss: 1.3907905668020248e-05 \n",
      "epoch: 25 [599940/888800 67.50%] train loss: 1.3074067283014301e-05 \n",
      "epoch: 25 [601051/888800 67.62%] train loss: 1.3875694094167557e-05 \n",
      "epoch: 25 [602162/888800 67.75%] train loss: 1.2897430679004174e-05 \n",
      "epoch: 25 [603273/888800 67.88%] train loss: 1.5622335922671482e-05 \n",
      "epoch: 25 [604384/888800 68.00%] train loss: 1.3578040125139523e-05 \n",
      "epoch: 25 [605495/888800 68.12%] train loss: 1.5281251762644388e-05 \n",
      "epoch: 25 [606606/888800 68.25%] train loss: 1.3350681911106221e-05 \n",
      "epoch: 25 [607717/888800 68.38%] train loss: 1.5614576113875955e-05 \n",
      "epoch: 25 [608828/888800 68.50%] train loss: 1.4299772374215536e-05 \n",
      "epoch: 25 [609939/888800 68.62%] train loss: 1.3481197129294742e-05 \n",
      "epoch: 25 [611050/888800 68.75%] train loss: 1.350331604044186e-05 \n",
      "epoch: 25 [612161/888800 68.88%] train loss: 1.429396252206061e-05 \n",
      "epoch: 25 [613272/888800 69.00%] train loss: 1.4468480912910309e-05 \n",
      "epoch: 25 [614383/888800 69.12%] train loss: 1.421694196324097e-05 \n",
      "epoch: 25 [615494/888800 69.25%] train loss: 1.4953366189729422e-05 \n",
      "epoch: 25 [616605/888800 69.38%] train loss: 1.4657291103503667e-05 \n",
      "epoch: 25 [617716/888800 69.50%] train loss: 1.4797617950534914e-05 \n",
      "epoch: 25 [618827/888800 69.62%] train loss: 1.4671031749458052e-05 \n",
      "epoch: 25 [619938/888800 69.75%] train loss: 1.550608067191206e-05 \n",
      "epoch: 25 [621049/888800 69.88%] train loss: 1.5414829249493778e-05 \n",
      "epoch: 25 [622160/888800 70.00%] train loss: 1.4217856005416252e-05 \n",
      "epoch: 25 [623271/888800 70.12%] train loss: 1.5261968655977398e-05 \n",
      "epoch: 25 [624382/888800 70.25%] train loss: 1.3107763152220286e-05 \n",
      "epoch: 25 [625493/888800 70.38%] train loss: 1.4169673704600427e-05 \n",
      "epoch: 25 [626604/888800 70.50%] train loss: 1.4732130694028456e-05 \n",
      "epoch: 25 [627715/888800 70.62%] train loss: 1.5341634934884496e-05 \n",
      "epoch: 25 [628826/888800 70.75%] train loss: 1.4428861504711676e-05 \n",
      "epoch: 25 [629937/888800 70.88%] train loss: 1.5511974197579548e-05 \n",
      "epoch: 25 [631048/888800 71.00%] train loss: 1.3652963389176875e-05 \n",
      "epoch: 25 [632159/888800 71.12%] train loss: 1.384867118758848e-05 \n",
      "epoch: 25 [633270/888800 71.25%] train loss: 1.4524950529448688e-05 \n",
      "epoch: 25 [634381/888800 71.38%] train loss: 1.4084063877817243e-05 \n",
      "epoch: 25 [635492/888800 71.50%] train loss: 1.3962783668830525e-05 \n",
      "epoch: 25 [636603/888800 71.62%] train loss: 1.2848996448155958e-05 \n",
      "epoch: 25 [637714/888800 71.75%] train loss: 1.485302436776692e-05 \n",
      "epoch: 25 [638825/888800 71.88%] train loss: 1.4051694961381145e-05 \n",
      "epoch: 25 [639936/888800 72.00%] train loss: 1.3715836757910438e-05 \n",
      "epoch: 25 [641047/888800 72.12%] train loss: 1.4963827197789215e-05 \n",
      "epoch: 25 [642158/888800 72.25%] train loss: 1.451201933377888e-05 \n",
      "epoch: 25 [643269/888800 72.38%] train loss: 1.479918591940077e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [644380/888800 72.50%] train loss: 1.465031618863577e-05 \n",
      "epoch: 25 [645491/888800 72.62%] train loss: 1.4656955499958713e-05 \n",
      "epoch: 25 [646602/888800 72.75%] train loss: 1.3170246347726788e-05 \n",
      "epoch: 25 [647713/888800 72.88%] train loss: 1.488689213147154e-05 \n",
      "epoch: 25 [648824/888800 73.00%] train loss: 1.4145239219942596e-05 \n",
      "epoch: 25 [649935/888800 73.12%] train loss: 1.4048313460079953e-05 \n",
      "epoch: 25 [651046/888800 73.25%] train loss: 1.3752486665907782e-05 \n",
      "epoch: 25 [652157/888800 73.38%] train loss: 1.4491275578620844e-05 \n",
      "epoch: 25 [653268/888800 73.50%] train loss: 1.3777989806840196e-05 \n",
      "epoch: 25 [654379/888800 73.62%] train loss: 1.446659371140413e-05 \n",
      "epoch: 25 [655490/888800 73.75%] train loss: 1.2821176824218128e-05 \n",
      "epoch: 25 [656601/888800 73.88%] train loss: 1.3790388038614765e-05 \n",
      "epoch: 25 [657712/888800 74.00%] train loss: 1.4237347386369947e-05 \n",
      "epoch: 25 [658823/888800 74.12%] train loss: 1.3657011550094467e-05 \n",
      "epoch: 25 [659934/888800 74.25%] train loss: 1.402782800141722e-05 \n",
      "epoch: 25 [661045/888800 74.38%] train loss: 1.3935234164819121e-05 \n",
      "epoch: 25 [662156/888800 74.50%] train loss: 1.319421426160261e-05 \n",
      "epoch: 25 [663267/888800 74.62%] train loss: 1.421181696059648e-05 \n",
      "epoch: 25 [664378/888800 74.75%] train loss: 1.4648198884970043e-05 \n",
      "epoch: 25 [665489/888800 74.88%] train loss: 1.359476664219983e-05 \n",
      "epoch: 25 [666600/888800 75.00%] train loss: 1.5144056305871345e-05 \n",
      "epoch: 25 [667711/888800 75.12%] train loss: 1.4072083104110789e-05 \n",
      "epoch: 25 [668822/888800 75.25%] train loss: 1.45076692206203e-05 \n",
      "epoch: 25 [669933/888800 75.38%] train loss: 1.3869725989934523e-05 \n",
      "epoch: 25 [671044/888800 75.50%] train loss: 1.4654836377303582e-05 \n",
      "epoch: 25 [672155/888800 75.62%] train loss: 1.4119251318334136e-05 \n",
      "epoch: 25 [673266/888800 75.75%] train loss: 1.3302659681357909e-05 \n",
      "epoch: 25 [674377/888800 75.88%] train loss: 1.3961501281301025e-05 \n",
      "epoch: 25 [675488/888800 76.00%] train loss: 1.2830958439735696e-05 \n",
      "epoch: 25 [676599/888800 76.12%] train loss: 1.560046621307265e-05 \n",
      "epoch: 25 [677710/888800 76.25%] train loss: 1.4035091226105578e-05 \n",
      "epoch: 25 [678821/888800 76.38%] train loss: 1.365926527796546e-05 \n",
      "epoch: 25 [679932/888800 76.50%] train loss: 1.5562251064693555e-05 \n",
      "epoch: 25 [681043/888800 76.62%] train loss: 1.4789008673687931e-05 \n",
      "epoch: 25 [682154/888800 76.75%] train loss: 1.613911081221886e-05 \n",
      "epoch: 25 [683265/888800 76.88%] train loss: 1.465806235501077e-05 \n",
      "epoch: 25 [684376/888800 77.00%] train loss: 1.5371279005194083e-05 \n",
      "epoch: 25 [685487/888800 77.12%] train loss: 1.429165877198102e-05 \n",
      "epoch: 25 [686598/888800 77.25%] train loss: 1.489327860326739e-05 \n",
      "epoch: 25 [687709/888800 77.38%] train loss: 1.5329662346630357e-05 \n",
      "epoch: 25 [688820/888800 77.50%] train loss: 1.505574255133979e-05 \n",
      "epoch: 25 [689931/888800 77.62%] train loss: 1.571502252772916e-05 \n",
      "epoch: 25 [691042/888800 77.75%] train loss: 1.5330968381022103e-05 \n",
      "epoch: 25 [692153/888800 77.88%] train loss: 1.4260887837735936e-05 \n",
      "epoch: 25 [693264/888800 78.00%] train loss: 1.3712512554775458e-05 \n",
      "epoch: 25 [694375/888800 78.12%] train loss: 1.4094315702095628e-05 \n",
      "epoch: 25 [695486/888800 78.25%] train loss: 1.357290875603212e-05 \n",
      "epoch: 25 [696597/888800 78.38%] train loss: 1.4632611964771058e-05 \n",
      "epoch: 25 [697708/888800 78.50%] train loss: 1.5304221960832365e-05 \n",
      "epoch: 25 [698819/888800 78.62%] train loss: 1.4639716937381309e-05 \n",
      "epoch: 25 [699930/888800 78.75%] train loss: 1.574949419591576e-05 \n",
      "epoch: 25 [701041/888800 78.88%] train loss: 1.3941699762654025e-05 \n",
      "epoch: 25 [702152/888800 79.00%] train loss: 1.680159584793728e-05 \n",
      "epoch: 25 [703263/888800 79.12%] train loss: 1.4213159374776296e-05 \n",
      "epoch: 25 [704374/888800 79.25%] train loss: 1.5674948372179642e-05 \n",
      "epoch: 25 [705485/888800 79.38%] train loss: 1.3725992175750434e-05 \n",
      "epoch: 25 [706596/888800 79.50%] train loss: 1.64078355737729e-05 \n",
      "epoch: 25 [707707/888800 79.62%] train loss: 1.4896932952979114e-05 \n",
      "epoch: 25 [708818/888800 79.75%] train loss: 1.4443681720877066e-05 \n",
      "epoch: 25 [709929/888800 79.88%] train loss: 1.3498727639671415e-05 \n",
      "epoch: 25 [711040/888800 80.00%] train loss: 1.401010467816377e-05 \n",
      "epoch: 25 [712151/888800 80.12%] train loss: 1.5362535123131238e-05 \n",
      "epoch: 25 [713262/888800 80.25%] train loss: 1.3892351489630528e-05 \n",
      "epoch: 25 [714373/888800 80.38%] train loss: 1.3367693100008182e-05 \n",
      "epoch: 25 [715484/888800 80.50%] train loss: 1.3998450413055252e-05 \n",
      "epoch: 25 [716595/888800 80.62%] train loss: 1.3827480870531872e-05 \n",
      "epoch: 25 [717706/888800 80.75%] train loss: 1.370494737784611e-05 \n",
      "epoch: 25 [718817/888800 80.88%] train loss: 1.4099873624218162e-05 \n",
      "epoch: 25 [719928/888800 81.00%] train loss: 1.363612409477355e-05 \n",
      "epoch: 25 [721039/888800 81.12%] train loss: 1.4408075003302656e-05 \n",
      "epoch: 25 [722150/888800 81.25%] train loss: 1.626010998734273e-05 \n",
      "epoch: 25 [723261/888800 81.38%] train loss: 1.4695162462885492e-05 \n",
      "epoch: 25 [724372/888800 81.50%] train loss: 1.4343897419166751e-05 \n",
      "epoch: 25 [725483/888800 81.62%] train loss: 1.540951598144602e-05 \n",
      "epoch: 25 [726594/888800 81.75%] train loss: 1.5894993339315988e-05 \n",
      "epoch: 25 [727705/888800 81.88%] train loss: 1.312431413680315e-05 \n",
      "epoch: 25 [728816/888800 82.00%] train loss: 1.72242089320207e-05 \n",
      "epoch: 25 [729927/888800 82.12%] train loss: 1.3005873370275367e-05 \n",
      "epoch: 25 [731038/888800 82.25%] train loss: 1.54062217916362e-05 \n",
      "epoch: 25 [732149/888800 82.38%] train loss: 1.42483522722614e-05 \n",
      "epoch: 25 [733260/888800 82.50%] train loss: 1.581649667059537e-05 \n",
      "epoch: 25 [734371/888800 82.62%] train loss: 1.4591442777600605e-05 \n",
      "epoch: 25 [735482/888800 82.75%] train loss: 1.7155416571768e-05 \n",
      "epoch: 25 [736593/888800 82.88%] train loss: 1.3442867384583224e-05 \n",
      "epoch: 25 [737704/888800 83.00%] train loss: 1.538594369776547e-05 \n",
      "epoch: 25 [738815/888800 83.12%] train loss: 1.3078433767077513e-05 \n",
      "epoch: 25 [739926/888800 83.25%] train loss: 1.592540866113268e-05 \n",
      "epoch: 25 [741037/888800 83.38%] train loss: 1.3758299246546812e-05 \n",
      "epoch: 25 [742148/888800 83.50%] train loss: 1.5362635167548433e-05 \n",
      "epoch: 25 [743259/888800 83.62%] train loss: 1.4966221897338983e-05 \n",
      "epoch: 25 [744370/888800 83.75%] train loss: 1.6116131519083865e-05 \n",
      "epoch: 25 [745481/888800 83.88%] train loss: 1.540673110866919e-05 \n",
      "epoch: 25 [746592/888800 84.00%] train loss: 1.4537779861711897e-05 \n",
      "epoch: 25 [747703/888800 84.12%] train loss: 1.5074961083882954e-05 \n",
      "epoch: 25 [748814/888800 84.25%] train loss: 1.5191276361292694e-05 \n",
      "epoch: 25 [749925/888800 84.38%] train loss: 1.4299735084932763e-05 \n",
      "epoch: 25 [751036/888800 84.50%] train loss: 1.4722171727044042e-05 \n",
      "epoch: 25 [752147/888800 84.62%] train loss: 1.4795206880080514e-05 \n",
      "epoch: 25 [753258/888800 84.75%] train loss: 1.4512438610836398e-05 \n",
      "epoch: 25 [754369/888800 84.88%] train loss: 1.5514353435719386e-05 \n",
      "epoch: 25 [755480/888800 85.00%] train loss: 1.4928442396922037e-05 \n",
      "epoch: 25 [756591/888800 85.12%] train loss: 1.6600282833678648e-05 \n",
      "epoch: 25 [757702/888800 85.25%] train loss: 1.3379228221310768e-05 \n",
      "epoch: 25 [758813/888800 85.38%] train loss: 1.663576222199481e-05 \n",
      "epoch: 25 [759924/888800 85.50%] train loss: 1.4195485164236743e-05 \n",
      "epoch: 25 [761035/888800 85.62%] train loss: 1.520380192232551e-05 \n",
      "epoch: 25 [762146/888800 85.75%] train loss: 1.3487152500601951e-05 \n",
      "epoch: 25 [763257/888800 85.88%] train loss: 1.5189608348009642e-05 \n",
      "epoch: 25 [764368/888800 86.00%] train loss: 1.5620578778907657e-05 \n",
      "epoch: 25 [765479/888800 86.12%] train loss: 1.5874285963946022e-05 \n",
      "epoch: 25 [766590/888800 86.25%] train loss: 1.3241259694041219e-05 \n",
      "epoch: 25 [767701/888800 86.38%] train loss: 1.3687986211152747e-05 \n",
      "epoch: 25 [768812/888800 86.50%] train loss: 1.3318984201760031e-05 \n",
      "epoch: 25 [769923/888800 86.62%] train loss: 1.488436282670591e-05 \n",
      "epoch: 25 [771034/888800 86.75%] train loss: 1.5163048374233767e-05 \n",
      "epoch: 25 [772145/888800 86.88%] train loss: 1.5640247511328198e-05 \n",
      "epoch: 25 [773256/888800 87.00%] train loss: 1.4293288586486597e-05 \n",
      "epoch: 25 [774367/888800 87.12%] train loss: 1.5562160115223378e-05 \n",
      "epoch: 25 [775478/888800 87.25%] train loss: 1.485526081523858e-05 \n",
      "epoch: 25 [776589/888800 87.38%] train loss: 1.3867514098819811e-05 \n",
      "epoch: 25 [777700/888800 87.50%] train loss: 1.5853234799578786e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 [778811/888800 87.62%] train loss: 1.4827755876467563e-05 \n",
      "epoch: 25 [779922/888800 87.75%] train loss: 1.4035198546480387e-05 \n",
      "epoch: 25 [781033/888800 87.88%] train loss: 1.430085194442654e-05 \n",
      "epoch: 25 [782144/888800 88.00%] train loss: 1.4296534573077224e-05 \n",
      "epoch: 25 [783255/888800 88.12%] train loss: 1.4022322829987388e-05 \n",
      "epoch: 25 [784366/888800 88.25%] train loss: 1.539820004836656e-05 \n",
      "epoch: 25 [785477/888800 88.38%] train loss: 1.3353316717257258e-05 \n",
      "epoch: 25 [786588/888800 88.50%] train loss: 1.4353020560520235e-05 \n",
      "epoch: 25 [787699/888800 88.62%] train loss: 1.503843395767035e-05 \n",
      "epoch: 25 [788810/888800 88.75%] train loss: 1.4072044905333314e-05 \n",
      "epoch: 25 [789921/888800 88.88%] train loss: 1.4480417121376377e-05 \n",
      "epoch: 25 [791032/888800 89.00%] train loss: 1.3584164662461262e-05 \n",
      "epoch: 25 [792143/888800 89.12%] train loss: 1.558706753712613e-05 \n",
      "epoch: 25 [793254/888800 89.25%] train loss: 1.4022359209775459e-05 \n",
      "epoch: 25 [794365/888800 89.38%] train loss: 1.4046232536202297e-05 \n",
      "epoch: 25 [795476/888800 89.50%] train loss: 1.4760277736058924e-05 \n",
      "epoch: 25 [796587/888800 89.62%] train loss: 1.4535686204908416e-05 \n",
      "epoch: 25 [797698/888800 89.75%] train loss: 1.3105960533721372e-05 \n",
      "epoch: 25 [798809/888800 89.88%] train loss: 1.309159051743336e-05 \n",
      "epoch: 25 [799920/888800 90.00%] train loss: 1.3948922060080804e-05 \n",
      "epoch: 25 [801031/888800 90.12%] train loss: 1.398950280417921e-05 \n",
      "epoch: 25 [802142/888800 90.25%] train loss: 1.372790302411886e-05 \n",
      "epoch: 25 [803253/888800 90.38%] train loss: 1.486488963564625e-05 \n",
      "epoch: 25 [804364/888800 90.50%] train loss: 1.4044810995983426e-05 \n",
      "epoch: 25 [805475/888800 90.62%] train loss: 1.5438521586474963e-05 \n",
      "epoch: 25 [806586/888800 90.75%] train loss: 1.5018855265225284e-05 \n",
      "epoch: 25 [807697/888800 90.88%] train loss: 1.502980012446642e-05 \n",
      "epoch: 25 [808808/888800 91.00%] train loss: 1.3984862562210765e-05 \n",
      "epoch: 25 [809919/888800 91.12%] train loss: 1.3876606317353435e-05 \n",
      "epoch: 25 [811030/888800 91.25%] train loss: 1.4424864275497384e-05 \n",
      "epoch: 25 [812141/888800 91.38%] train loss: 1.3950160791864619e-05 \n",
      "epoch: 25 [813252/888800 91.50%] train loss: 1.4310094229585957e-05 \n",
      "epoch: 25 [814363/888800 91.62%] train loss: 1.3498331099981442e-05 \n",
      "epoch: 25 [815474/888800 91.75%] train loss: 1.482971856603399e-05 \n",
      "epoch: 25 [816585/888800 91.88%] train loss: 1.409109518135665e-05 \n",
      "epoch: 25 [817696/888800 92.00%] train loss: 1.4397464838111773e-05 \n",
      "epoch: 25 [818807/888800 92.12%] train loss: 1.3800653505313676e-05 \n",
      "epoch: 25 [819918/888800 92.25%] train loss: 1.4030954844201915e-05 \n",
      "epoch: 25 [821029/888800 92.38%] train loss: 1.426925700798165e-05 \n",
      "epoch: 25 [822140/888800 92.50%] train loss: 1.2898150089313276e-05 \n",
      "epoch: 25 [823251/888800 92.62%] train loss: 1.3505633432941977e-05 \n",
      "epoch: 25 [824362/888800 92.75%] train loss: 1.4041670510778204e-05 \n",
      "epoch: 25 [825473/888800 92.88%] train loss: 1.327242443949217e-05 \n",
      "epoch: 25 [826584/888800 93.00%] train loss: 1.2862331459473353e-05 \n",
      "epoch: 25 [827695/888800 93.12%] train loss: 1.4072128578845877e-05 \n",
      "epoch: 25 [828806/888800 93.25%] train loss: 1.455580240872223e-05 \n",
      "epoch: 25 [829917/888800 93.38%] train loss: 1.585391328262631e-05 \n",
      "epoch: 25 [831028/888800 93.50%] train loss: 1.4726237168360967e-05 \n",
      "epoch: 25 [832139/888800 93.62%] train loss: 1.3704164302907884e-05 \n",
      "epoch: 25 [833250/888800 93.75%] train loss: 1.5035823707876261e-05 \n",
      "epoch: 25 [834361/888800 93.88%] train loss: 1.3964086974738166e-05 \n",
      "epoch: 25 [835472/888800 94.00%] train loss: 1.5091130990185775e-05 \n",
      "epoch: 25 [836583/888800 94.12%] train loss: 1.3454441614157986e-05 \n",
      "epoch: 25 [837694/888800 94.25%] train loss: 1.4406263289856724e-05 \n",
      "epoch: 25 [838805/888800 94.38%] train loss: 1.4624247341998853e-05 \n",
      "epoch: 25 [839916/888800 94.50%] train loss: 1.423351659468608e-05 \n",
      "epoch: 25 [841027/888800 94.62%] train loss: 1.314636210736353e-05 \n",
      "epoch: 25 [842138/888800 94.75%] train loss: 1.3284352462505922e-05 \n",
      "epoch: 25 [843249/888800 94.88%] train loss: 1.5345554857049137e-05 \n",
      "epoch: 25 [844360/888800 95.00%] train loss: 1.5358882592408918e-05 \n",
      "epoch: 25 [845471/888800 95.12%] train loss: 1.3910283087170683e-05 \n",
      "epoch: 25 [846582/888800 95.25%] train loss: 1.3981178199173883e-05 \n",
      "epoch: 25 [847693/888800 95.38%] train loss: 1.3661077900906093e-05 \n",
      "epoch: 25 [848804/888800 95.50%] train loss: 1.470015831728233e-05 \n",
      "epoch: 25 [849915/888800 95.62%] train loss: 1.422610421286663e-05 \n",
      "epoch: 25 [851026/888800 95.75%] train loss: 1.4033774277777411e-05 \n",
      "epoch: 25 [852137/888800 95.88%] train loss: 1.3473078979586717e-05 \n",
      "epoch: 25 [853248/888800 96.00%] train loss: 1.4851696505502332e-05 \n",
      "epoch: 25 [854359/888800 96.12%] train loss: 1.4311876839201432e-05 \n",
      "epoch: 25 [855470/888800 96.25%] train loss: 1.5521289242315106e-05 \n",
      "epoch: 25 [856581/888800 96.38%] train loss: 1.4589359125238843e-05 \n",
      "epoch: 25 [857692/888800 96.50%] train loss: 1.4860433111607563e-05 \n",
      "epoch: 25 [858803/888800 96.62%] train loss: 1.4243944860936608e-05 \n",
      "epoch: 25 [859914/888800 96.75%] train loss: 1.5969009837135673e-05 \n",
      "epoch: 25 [861025/888800 96.88%] train loss: 1.4175192518450785e-05 \n",
      "epoch: 25 [862136/888800 97.00%] train loss: 1.4049033779883757e-05 \n",
      "epoch: 25 [863247/888800 97.12%] train loss: 1.3976366062706802e-05 \n",
      "epoch: 25 [864358/888800 97.25%] train loss: 1.45786152643268e-05 \n",
      "epoch: 25 [865469/888800 97.38%] train loss: 1.5352843547589146e-05 \n",
      "epoch: 25 [866580/888800 97.50%] train loss: 1.4581547475245316e-05 \n",
      "epoch: 25 [867691/888800 97.62%] train loss: 1.4979288607719354e-05 \n",
      "epoch: 25 [868802/888800 97.75%] train loss: 1.481729395891307e-05 \n",
      "epoch: 25 [869913/888800 97.88%] train loss: 1.3482643225870561e-05 \n",
      "epoch: 25 [871024/888800 98.00%] train loss: 1.5085774975887034e-05 \n",
      "epoch: 25 [872135/888800 98.12%] train loss: 1.4293455024017021e-05 \n",
      "epoch: 25 [873246/888800 98.25%] train loss: 1.514641371613834e-05 \n",
      "epoch: 25 [874357/888800 98.38%] train loss: 1.5703486496931873e-05 \n",
      "epoch: 25 [875468/888800 98.50%] train loss: 1.2951806638739072e-05 \n",
      "epoch: 25 [876579/888800 98.62%] train loss: 1.4777606338611804e-05 \n",
      "epoch: 25 [877690/888800 98.75%] train loss: 1.3887187378713861e-05 \n",
      "epoch: 25 [878801/888800 98.88%] train loss: 1.5113962945179082e-05 \n",
      "epoch: 25 [879912/888800 99.00%] train loss: 1.4515614566334989e-05 \n",
      "epoch: 25 [881023/888800 99.12%] train loss: 1.5246986549755093e-05 \n",
      "epoch: 25 [882134/888800 99.25%] train loss: 1.468602022214327e-05 \n",
      "epoch: 25 [883245/888800 99.38%] train loss: 1.5080002413014881e-05 \n",
      "epoch: 25 [884356/888800 99.50%] train loss: 1.4362372894538566e-05 \n",
      "epoch: 25 [885467/888800 99.62%] train loss: 1.5223855371004902e-05 \n",
      "epoch: 25 [886578/888800 99.75%] train loss: 1.436991078662686e-05 \n",
      "epoch: 25 [887689/888800 99.88%] train loss: 1.4842840755591169e-05 \n",
      "epoch: 26 [0/888800 0.00%] train loss: 1.4299411304818932e-05 \n",
      "epoch: 26 [1111/888800 0.12%] train loss: 1.4872643077978864e-05 \n",
      "epoch: 26 [2222/888800 0.25%] train loss: 1.3858677448297385e-05 \n",
      "epoch: 26 [3333/888800 0.38%] train loss: 1.4228382497094572e-05 \n",
      "epoch: 26 [4444/888800 0.50%] train loss: 1.4200122677721083e-05 \n",
      "epoch: 26 [5555/888800 0.62%] train loss: 1.361694376100786e-05 \n",
      "epoch: 26 [6666/888800 0.75%] train loss: 1.4804209968133364e-05 \n",
      "epoch: 26 [7777/888800 0.88%] train loss: 1.340341168543091e-05 \n",
      "epoch: 26 [8888/888800 1.00%] train loss: 1.461688952986151e-05 \n",
      "epoch: 26 [9999/888800 1.12%] train loss: 1.4661414752481505e-05 \n",
      "epoch: 26 [11110/888800 1.25%] train loss: 1.5342789993155748e-05 \n",
      "epoch: 26 [12221/888800 1.38%] train loss: 1.4722609193995595e-05 \n",
      "epoch: 26 [13332/888800 1.50%] train loss: 1.4217009265848901e-05 \n",
      "epoch: 26 [14443/888800 1.62%] train loss: 1.4479073797701858e-05 \n",
      "epoch: 26 [15554/888800 1.75%] train loss: 1.4962236491555814e-05 \n",
      "epoch: 26 [16665/888800 1.88%] train loss: 1.4843833923805505e-05 \n",
      "epoch: 26 [17776/888800 2.00%] train loss: 1.551252898934763e-05 \n",
      "epoch: 26 [18887/888800 2.12%] train loss: 1.351232913293643e-05 \n",
      "epoch: 26 [19998/888800 2.25%] train loss: 1.4792018191656098e-05 \n",
      "epoch: 26 [21109/888800 2.38%] train loss: 1.4488048691418953e-05 \n",
      "epoch: 26 [22220/888800 2.50%] train loss: 1.4160122191242408e-05 \n",
      "epoch: 26 [23331/888800 2.62%] train loss: 1.4214497241482604e-05 \n",
      "epoch: 26 [24442/888800 2.75%] train loss: 1.4695891877636313e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [25553/888800 2.88%] train loss: 1.3830921488988679e-05 \n",
      "epoch: 26 [26664/888800 3.00%] train loss: 1.361062368232524e-05 \n",
      "epoch: 26 [27775/888800 3.12%] train loss: 1.5457764675375074e-05 \n",
      "epoch: 26 [28886/888800 3.25%] train loss: 1.4516903320327401e-05 \n",
      "epoch: 26 [29997/888800 3.38%] train loss: 1.3721092727791984e-05 \n",
      "epoch: 26 [31108/888800 3.50%] train loss: 1.4117018508841284e-05 \n",
      "epoch: 26 [32219/888800 3.62%] train loss: 1.3317997400008608e-05 \n",
      "epoch: 26 [33330/888800 3.75%] train loss: 1.3861000297765713e-05 \n",
      "epoch: 26 [34441/888800 3.88%] train loss: 1.3095213944325224e-05 \n",
      "epoch: 26 [35552/888800 4.00%] train loss: 1.5693613022449426e-05 \n",
      "epoch: 26 [36663/888800 4.12%] train loss: 1.5513449397985823e-05 \n",
      "epoch: 26 [37774/888800 4.25%] train loss: 1.4829291103524156e-05 \n",
      "epoch: 26 [38885/888800 4.38%] train loss: 1.5310466551454738e-05 \n",
      "epoch: 26 [39996/888800 4.50%] train loss: 1.4481360267382115e-05 \n",
      "epoch: 26 [41107/888800 4.62%] train loss: 1.49384777614614e-05 \n",
      "epoch: 26 [42218/888800 4.75%] train loss: 1.424131914973259e-05 \n",
      "epoch: 26 [43329/888800 4.88%] train loss: 1.4504689715977293e-05 \n",
      "epoch: 26 [44440/888800 5.00%] train loss: 1.5656109098927118e-05 \n",
      "epoch: 26 [45551/888800 5.12%] train loss: 1.4574885426554829e-05 \n",
      "epoch: 26 [46662/888800 5.25%] train loss: 1.397285086568445e-05 \n",
      "epoch: 26 [47773/888800 5.38%] train loss: 1.4813441339356359e-05 \n",
      "epoch: 26 [48884/888800 5.50%] train loss: 1.4824181562289596e-05 \n",
      "epoch: 26 [49995/888800 5.62%] train loss: 1.4717552403453737e-05 \n",
      "epoch: 26 [51106/888800 5.75%] train loss: 1.4609668141929433e-05 \n",
      "epoch: 26 [52217/888800 5.88%] train loss: 1.3907960237702355e-05 \n",
      "epoch: 26 [53328/888800 6.00%] train loss: 1.3057704563834704e-05 \n",
      "epoch: 26 [54439/888800 6.12%] train loss: 1.4754574294784106e-05 \n",
      "epoch: 26 [55550/888800 6.25%] train loss: 1.4117393220658414e-05 \n",
      "epoch: 26 [56661/888800 6.38%] train loss: 1.4792511137784459e-05 \n",
      "epoch: 26 [57772/888800 6.50%] train loss: 1.3173746992833912e-05 \n",
      "epoch: 26 [58883/888800 6.62%] train loss: 1.4523619938699994e-05 \n",
      "epoch: 26 [59994/888800 6.75%] train loss: 1.394528317177901e-05 \n",
      "epoch: 26 [61105/888800 6.88%] train loss: 1.4918855413270649e-05 \n",
      "epoch: 26 [62216/888800 7.00%] train loss: 1.4592899788112845e-05 \n",
      "epoch: 26 [63327/888800 7.12%] train loss: 1.4028022633283399e-05 \n",
      "epoch: 26 [64438/888800 7.25%] train loss: 1.3101422155159526e-05 \n",
      "epoch: 26 [65549/888800 7.38%] train loss: 1.3072080946585629e-05 \n",
      "epoch: 26 [66660/888800 7.50%] train loss: 1.4062396076042205e-05 \n",
      "epoch: 26 [67771/888800 7.62%] train loss: 1.4414647012017667e-05 \n",
      "epoch: 26 [68882/888800 7.75%] train loss: 1.4124564586381894e-05 \n",
      "epoch: 26 [69993/888800 7.88%] train loss: 1.3011101145821158e-05 \n",
      "epoch: 26 [71104/888800 8.00%] train loss: 1.556950155645609e-05 \n",
      "epoch: 26 [72215/888800 8.12%] train loss: 1.445845737180207e-05 \n",
      "epoch: 26 [73326/888800 8.25%] train loss: 1.378545039187884e-05 \n",
      "epoch: 26 [74437/888800 8.38%] train loss: 1.4547216778737493e-05 \n",
      "epoch: 26 [75548/888800 8.50%] train loss: 1.4039843335922342e-05 \n",
      "epoch: 26 [76659/888800 8.62%] train loss: 1.4167447261570487e-05 \n",
      "epoch: 26 [77770/888800 8.75%] train loss: 1.4361266039486509e-05 \n",
      "epoch: 26 [78881/888800 8.88%] train loss: 1.3589472473540809e-05 \n",
      "epoch: 26 [79992/888800 9.00%] train loss: 1.4311430277302861e-05 \n",
      "epoch: 26 [81103/888800 9.12%] train loss: 1.5842593711568043e-05 \n",
      "epoch: 26 [82214/888800 9.25%] train loss: 1.4427162568608765e-05 \n",
      "epoch: 26 [83325/888800 9.38%] train loss: 1.3742090231971815e-05 \n",
      "epoch: 26 [84436/888800 9.50%] train loss: 1.5830979464226402e-05 \n",
      "epoch: 26 [85547/888800 9.62%] train loss: 1.4704090062878095e-05 \n",
      "epoch: 26 [86658/888800 9.75%] train loss: 1.4383832422026899e-05 \n",
      "epoch: 26 [87769/888800 9.88%] train loss: 1.30598564282991e-05 \n",
      "epoch: 26 [88880/888800 10.00%] train loss: 1.4605022442992777e-05 \n",
      "epoch: 26 [89991/888800 10.12%] train loss: 1.352054277958814e-05 \n",
      "epoch: 26 [91102/888800 10.25%] train loss: 1.4449124137172475e-05 \n",
      "epoch: 26 [92213/888800 10.38%] train loss: 1.4055684914637823e-05 \n",
      "epoch: 26 [93324/888800 10.50%] train loss: 1.5221449757518712e-05 \n",
      "epoch: 26 [94435/888800 10.62%] train loss: 1.3490052879205905e-05 \n",
      "epoch: 26 [95546/888800 10.75%] train loss: 1.320013871008996e-05 \n",
      "epoch: 26 [96657/888800 10.88%] train loss: 1.2917031199322082e-05 \n",
      "epoch: 26 [97768/888800 11.00%] train loss: 1.3257643331598956e-05 \n",
      "epoch: 26 [98879/888800 11.12%] train loss: 1.3560257684730459e-05 \n",
      "epoch: 26 [99990/888800 11.25%] train loss: 1.3090889297018293e-05 \n",
      "epoch: 26 [101101/888800 11.38%] train loss: 1.518992030469235e-05 \n",
      "epoch: 26 [102212/888800 11.50%] train loss: 1.388278542435728e-05 \n",
      "epoch: 26 [103323/888800 11.62%] train loss: 1.3427230442175642e-05 \n",
      "epoch: 26 [104434/888800 11.75%] train loss: 1.4082431334827561e-05 \n",
      "epoch: 26 [105545/888800 11.88%] train loss: 1.4560306226485409e-05 \n",
      "epoch: 26 [106656/888800 12.00%] train loss: 1.4569905943062622e-05 \n",
      "epoch: 26 [107767/888800 12.12%] train loss: 1.4768759683647659e-05 \n",
      "epoch: 26 [108878/888800 12.25%] train loss: 1.3172582839615643e-05 \n",
      "epoch: 26 [109989/888800 12.38%] train loss: 1.4002538591739722e-05 \n",
      "epoch: 26 [111100/888800 12.50%] train loss: 1.4120513696980197e-05 \n",
      "epoch: 26 [112211/888800 12.62%] train loss: 1.3878708159609232e-05 \n",
      "epoch: 26 [113322/888800 12.75%] train loss: 1.3743679119215813e-05 \n",
      "epoch: 26 [114433/888800 12.88%] train loss: 1.515380063210614e-05 \n",
      "epoch: 26 [115544/888800 13.00%] train loss: 1.3484862392942887e-05 \n",
      "epoch: 26 [116655/888800 13.12%] train loss: 1.3918634067522362e-05 \n",
      "epoch: 26 [117766/888800 13.25%] train loss: 1.4058517081139144e-05 \n",
      "epoch: 26 [118877/888800 13.38%] train loss: 1.3722221410716884e-05 \n",
      "epoch: 26 [119988/888800 13.50%] train loss: 1.5037652701721527e-05 \n",
      "epoch: 26 [121099/888800 13.62%] train loss: 1.38556588353822e-05 \n",
      "epoch: 26 [122210/888800 13.75%] train loss: 1.6013855201890692e-05 \n",
      "epoch: 26 [123321/888800 13.88%] train loss: 1.3878793652111199e-05 \n",
      "epoch: 26 [124432/888800 14.00%] train loss: 1.4597367226087954e-05 \n",
      "epoch: 26 [125543/888800 14.12%] train loss: 1.4428961549128871e-05 \n",
      "epoch: 26 [126654/888800 14.25%] train loss: 1.4496338735625613e-05 \n",
      "epoch: 26 [127765/888800 14.38%] train loss: 1.3550458788813557e-05 \n",
      "epoch: 26 [128876/888800 14.50%] train loss: 1.3855285033059772e-05 \n",
      "epoch: 26 [129987/888800 14.62%] train loss: 1.4276488400355447e-05 \n",
      "epoch: 26 [131098/888800 14.75%] train loss: 1.3271944226289634e-05 \n",
      "epoch: 26 [132209/888800 14.88%] train loss: 1.5118734154384583e-05 \n",
      "epoch: 26 [133320/888800 15.00%] train loss: 1.3807880350213964e-05 \n",
      "epoch: 26 [134431/888800 15.12%] train loss: 1.3972313354315702e-05 \n",
      "epoch: 26 [135542/888800 15.25%] train loss: 1.4556102541973814e-05 \n",
      "epoch: 26 [136653/888800 15.38%] train loss: 1.3943429621576797e-05 \n",
      "epoch: 26 [137764/888800 15.50%] train loss: 1.4640358131146058e-05 \n",
      "epoch: 26 [138875/888800 15.62%] train loss: 1.3971674889035057e-05 \n",
      "epoch: 26 [139986/888800 15.75%] train loss: 1.3950096217740793e-05 \n",
      "epoch: 26 [141097/888800 15.88%] train loss: 1.4378860214492306e-05 \n",
      "epoch: 26 [142208/888800 16.00%] train loss: 1.4258738701755647e-05 \n",
      "epoch: 26 [143319/888800 16.12%] train loss: 1.368235461995937e-05 \n",
      "epoch: 26 [144430/888800 16.25%] train loss: 1.3883211977372412e-05 \n",
      "epoch: 26 [145541/888800 16.38%] train loss: 1.354902906314237e-05 \n",
      "epoch: 26 [146652/888800 16.50%] train loss: 1.4904007912264206e-05 \n",
      "epoch: 26 [147763/888800 16.62%] train loss: 1.3947123989055399e-05 \n",
      "epoch: 26 [148874/888800 16.75%] train loss: 1.3850619325239677e-05 \n",
      "epoch: 26 [149985/888800 16.88%] train loss: 1.4640279005107004e-05 \n",
      "epoch: 26 [151096/888800 17.00%] train loss: 1.3883767678635195e-05 \n",
      "epoch: 26 [152207/888800 17.12%] train loss: 1.3196029613027349e-05 \n",
      "epoch: 26 [153318/888800 17.25%] train loss: 1.4155317330732942e-05 \n",
      "epoch: 26 [154429/888800 17.38%] train loss: 1.3410040992312133e-05 \n",
      "epoch: 26 [155540/888800 17.50%] train loss: 1.4394116078619845e-05 \n",
      "epoch: 26 [156651/888800 17.62%] train loss: 1.2648983101826161e-05 \n",
      "epoch: 26 [157762/888800 17.75%] train loss: 1.561523458804004e-05 \n",
      "epoch: 26 [158873/888800 17.88%] train loss: 1.4496585208689794e-05 \n",
      "epoch: 26 [159984/888800 18.00%] train loss: 1.5121821888897102e-05 \n",
      "epoch: 26 [161095/888800 18.12%] train loss: 1.4700161955261137e-05 \n",
      "epoch: 26 [162206/888800 18.25%] train loss: 1.4523073332384229e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [163317/888800 18.38%] train loss: 1.3948528248874936e-05 \n",
      "epoch: 26 [164428/888800 18.50%] train loss: 1.4814900168858003e-05 \n",
      "epoch: 26 [165539/888800 18.62%] train loss: 1.3476878848450724e-05 \n",
      "epoch: 26 [166650/888800 18.75%] train loss: 1.351968603557907e-05 \n",
      "epoch: 26 [167761/888800 18.88%] train loss: 1.4190693946147803e-05 \n",
      "epoch: 26 [168872/888800 19.00%] train loss: 1.3405019672063645e-05 \n",
      "epoch: 26 [169983/888800 19.12%] train loss: 1.3477926586347166e-05 \n",
      "epoch: 26 [171094/888800 19.25%] train loss: 1.505817363067763e-05 \n",
      "epoch: 26 [172205/888800 19.38%] train loss: 1.4389879652298987e-05 \n",
      "epoch: 26 [173316/888800 19.50%] train loss: 1.4044884665054269e-05 \n",
      "epoch: 26 [174427/888800 19.62%] train loss: 1.4924379684089217e-05 \n",
      "epoch: 26 [175538/888800 19.75%] train loss: 1.3432619198283646e-05 \n",
      "epoch: 26 [176649/888800 19.88%] train loss: 1.4745935004611965e-05 \n",
      "epoch: 26 [177760/888800 20.00%] train loss: 1.4616701264458243e-05 \n",
      "epoch: 26 [178871/888800 20.12%] train loss: 1.4086727787798736e-05 \n",
      "epoch: 26 [179982/888800 20.25%] train loss: 1.4035825188329909e-05 \n",
      "epoch: 26 [181093/888800 20.38%] train loss: 1.3955064787296578e-05 \n",
      "epoch: 26 [182204/888800 20.50%] train loss: 1.5054134564707056e-05 \n",
      "epoch: 26 [183315/888800 20.62%] train loss: 1.527316271676682e-05 \n",
      "epoch: 26 [184426/888800 20.75%] train loss: 1.3855357792635914e-05 \n",
      "epoch: 26 [185537/888800 20.88%] train loss: 1.5701143638580106e-05 \n",
      "epoch: 26 [186648/888800 21.00%] train loss: 1.4612285667681135e-05 \n",
      "epoch: 26 [187759/888800 21.12%] train loss: 1.4420220395550132e-05 \n",
      "epoch: 26 [188870/888800 21.25%] train loss: 1.354095911665354e-05 \n",
      "epoch: 26 [189981/888800 21.38%] train loss: 1.521284048067173e-05 \n",
      "epoch: 26 [191092/888800 21.50%] train loss: 1.4196250049280934e-05 \n",
      "epoch: 26 [192203/888800 21.62%] train loss: 1.423590219928883e-05 \n",
      "epoch: 26 [193314/888800 21.75%] train loss: 1.3640707038575783e-05 \n",
      "epoch: 26 [194425/888800 21.88%] train loss: 1.4289153114077635e-05 \n",
      "epoch: 26 [195536/888800 22.00%] train loss: 1.3981742995383684e-05 \n",
      "epoch: 26 [196647/888800 22.12%] train loss: 1.4517594536300749e-05 \n",
      "epoch: 26 [197758/888800 22.25%] train loss: 1.4351865502248984e-05 \n",
      "epoch: 26 [198869/888800 22.38%] train loss: 1.3388301340455655e-05 \n",
      "epoch: 26 [199980/888800 22.50%] train loss: 1.4183124221744947e-05 \n",
      "epoch: 26 [201091/888800 22.62%] train loss: 1.4219812328519765e-05 \n",
      "epoch: 26 [202202/888800 22.75%] train loss: 1.4770873349334579e-05 \n",
      "epoch: 26 [203313/888800 22.88%] train loss: 1.2633619007829111e-05 \n",
      "epoch: 26 [204424/888800 23.00%] train loss: 1.2901716218038928e-05 \n",
      "epoch: 26 [205535/888800 23.12%] train loss: 1.3562343156081624e-05 \n",
      "epoch: 26 [206646/888800 23.25%] train loss: 1.3402377589954995e-05 \n",
      "epoch: 26 [207757/888800 23.38%] train loss: 1.4807537809247151e-05 \n",
      "epoch: 26 [208868/888800 23.50%] train loss: 1.4428756912820973e-05 \n",
      "epoch: 26 [209979/888800 23.62%] train loss: 1.47847858897876e-05 \n",
      "epoch: 26 [211090/888800 23.75%] train loss: 1.3912705981056206e-05 \n",
      "epoch: 26 [212201/888800 23.88%] train loss: 1.3552165910368785e-05 \n",
      "epoch: 26 [213312/888800 24.00%] train loss: 1.3796230632578954e-05 \n",
      "epoch: 26 [214423/888800 24.12%] train loss: 1.6792837413959205e-05 \n",
      "epoch: 26 [215534/888800 24.25%] train loss: 1.4871117855363991e-05 \n",
      "epoch: 26 [216645/888800 24.38%] train loss: 1.443587098037824e-05 \n",
      "epoch: 26 [217756/888800 24.50%] train loss: 1.3283933185448404e-05 \n",
      "epoch: 26 [218867/888800 24.62%] train loss: 1.3233531717560254e-05 \n",
      "epoch: 26 [219978/888800 24.75%] train loss: 1.539275581308175e-05 \n",
      "epoch: 26 [221089/888800 24.88%] train loss: 1.4905589523550589e-05 \n",
      "epoch: 26 [222200/888800 25.00%] train loss: 1.4742516214028e-05 \n",
      "epoch: 26 [223311/888800 25.12%] train loss: 1.4604184798372444e-05 \n",
      "epoch: 26 [224422/888800 25.25%] train loss: 1.4333574654301628e-05 \n",
      "epoch: 26 [225533/888800 25.38%] train loss: 1.4641113921243232e-05 \n",
      "epoch: 26 [226644/888800 25.50%] train loss: 1.4405553883989342e-05 \n",
      "epoch: 26 [227755/888800 25.62%] train loss: 1.3868588212062605e-05 \n",
      "epoch: 26 [228866/888800 25.75%] train loss: 1.607542253623251e-05 \n",
      "epoch: 26 [229977/888800 25.88%] train loss: 1.5516467101406306e-05 \n",
      "epoch: 26 [231088/888800 26.00%] train loss: 1.4591635590477381e-05 \n",
      "epoch: 26 [232199/888800 26.12%] train loss: 1.384539336868329e-05 \n",
      "epoch: 26 [233310/888800 26.25%] train loss: 1.4577755791833624e-05 \n",
      "epoch: 26 [234421/888800 26.38%] train loss: 1.5224819435388781e-05 \n",
      "epoch: 26 [235532/888800 26.50%] train loss: 1.4722721061843913e-05 \n",
      "epoch: 26 [236643/888800 26.62%] train loss: 1.4246600585465785e-05 \n",
      "epoch: 26 [237754/888800 26.75%] train loss: 1.4316176930151414e-05 \n",
      "epoch: 26 [238865/888800 26.88%] train loss: 1.480749142501736e-05 \n",
      "epoch: 26 [239976/888800 27.00%] train loss: 1.3323339771886822e-05 \n",
      "epoch: 26 [241087/888800 27.12%] train loss: 1.4260232092055958e-05 \n",
      "epoch: 26 [242198/888800 27.25%] train loss: 1.4207616914063692e-05 \n",
      "epoch: 26 [243309/888800 27.38%] train loss: 1.3953062079963274e-05 \n",
      "epoch: 26 [244420/888800 27.50%] train loss: 1.4838282368145883e-05 \n",
      "epoch: 26 [245531/888800 27.62%] train loss: 1.4503946658805944e-05 \n",
      "epoch: 26 [246642/888800 27.75%] train loss: 1.2745883395837154e-05 \n",
      "epoch: 26 [247753/888800 27.88%] train loss: 1.5228769370878581e-05 \n",
      "epoch: 26 [248864/888800 28.00%] train loss: 1.3886693523090798e-05 \n",
      "epoch: 26 [249975/888800 28.12%] train loss: 1.3354381735553034e-05 \n",
      "epoch: 26 [251086/888800 28.25%] train loss: 1.3245025002106559e-05 \n",
      "epoch: 26 [252197/888800 28.38%] train loss: 1.4172894225339405e-05 \n",
      "epoch: 26 [253308/888800 28.50%] train loss: 1.4443045074585825e-05 \n",
      "epoch: 26 [254419/888800 28.62%] train loss: 1.5189762962108944e-05 \n",
      "epoch: 26 [255530/888800 28.75%] train loss: 1.4275185094447806e-05 \n",
      "epoch: 26 [256641/888800 28.88%] train loss: 1.449867613700917e-05 \n",
      "epoch: 26 [257752/888800 29.00%] train loss: 1.4936767911422066e-05 \n",
      "epoch: 26 [258863/888800 29.12%] train loss: 1.6281184798572212e-05 \n",
      "epoch: 26 [259974/888800 29.25%] train loss: 1.4353127880895045e-05 \n",
      "epoch: 26 [261085/888800 29.38%] train loss: 1.4333578292280436e-05 \n",
      "epoch: 26 [262196/888800 29.50%] train loss: 1.4775719137105625e-05 \n",
      "epoch: 26 [263307/888800 29.62%] train loss: 1.48041262946208e-05 \n",
      "epoch: 26 [264418/888800 29.75%] train loss: 1.539159165986348e-05 \n",
      "epoch: 26 [265529/888800 29.88%] train loss: 1.4016303794051055e-05 \n",
      "epoch: 26 [266640/888800 30.00%] train loss: 1.466732646804303e-05 \n",
      "epoch: 26 [267751/888800 30.12%] train loss: 1.3451442100631539e-05 \n",
      "epoch: 26 [268862/888800 30.25%] train loss: 1.4656649000244215e-05 \n",
      "epoch: 26 [269973/888800 30.38%] train loss: 1.5639972843928263e-05 \n",
      "epoch: 26 [271084/888800 30.50%] train loss: 1.5040938706079032e-05 \n",
      "epoch: 26 [272195/888800 30.62%] train loss: 1.51981021190295e-05 \n",
      "epoch: 26 [273306/888800 30.75%] train loss: 1.5221157809719443e-05 \n",
      "epoch: 26 [274417/888800 30.88%] train loss: 1.4017617104400415e-05 \n",
      "epoch: 26 [275528/888800 31.00%] train loss: 1.4289720638771541e-05 \n",
      "epoch: 26 [276639/888800 31.12%] train loss: 1.3678592040378135e-05 \n",
      "epoch: 26 [277750/888800 31.25%] train loss: 1.3430648323264904e-05 \n",
      "epoch: 26 [278861/888800 31.38%] train loss: 1.3274951015773695e-05 \n",
      "epoch: 26 [279972/888800 31.50%] train loss: 1.4173965610098094e-05 \n",
      "epoch: 26 [281083/888800 31.62%] train loss: 1.470715506002307e-05 \n",
      "epoch: 26 [282194/888800 31.75%] train loss: 1.3340896657609846e-05 \n",
      "epoch: 26 [283305/888800 31.88%] train loss: 1.5142370102694258e-05 \n",
      "epoch: 26 [284416/888800 32.00%] train loss: 1.4896783795848023e-05 \n",
      "epoch: 26 [285527/888800 32.12%] train loss: 1.3650699656864163e-05 \n",
      "epoch: 26 [286638/888800 32.25%] train loss: 1.4590423234039918e-05 \n",
      "epoch: 26 [287749/888800 32.38%] train loss: 1.3812057659379207e-05 \n",
      "epoch: 26 [288860/888800 32.50%] train loss: 1.5467876437469386e-05 \n",
      "epoch: 26 [289971/888800 32.62%] train loss: 1.5097743926162366e-05 \n",
      "epoch: 26 [291082/888800 32.75%] train loss: 1.323984452028526e-05 \n",
      "epoch: 26 [292193/888800 32.88%] train loss: 1.4447799003391992e-05 \n",
      "epoch: 26 [293304/888800 33.00%] train loss: 1.4823305718891788e-05 \n",
      "epoch: 26 [294415/888800 33.12%] train loss: 1.4010526683705393e-05 \n",
      "epoch: 26 [295526/888800 33.25%] train loss: 1.2811153283109888e-05 \n",
      "epoch: 26 [296637/888800 33.38%] train loss: 1.3284894521348178e-05 \n",
      "epoch: 26 [297748/888800 33.50%] train loss: 1.4646652743977029e-05 \n",
      "epoch: 26 [298859/888800 33.62%] train loss: 1.3921524441684596e-05 \n",
      "epoch: 26 [299970/888800 33.75%] train loss: 1.4097486200626008e-05 \n",
      "epoch: 26 [301081/888800 33.88%] train loss: 1.416017948940862e-05 \n",
      "epoch: 26 [302192/888800 34.00%] train loss: 1.534033981442917e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [303303/888800 34.12%] train loss: 1.3756422958977055e-05 \n",
      "epoch: 26 [304414/888800 34.25%] train loss: 1.350366983388085e-05 \n",
      "epoch: 26 [305525/888800 34.38%] train loss: 1.5313342373701744e-05 \n",
      "epoch: 26 [306636/888800 34.50%] train loss: 1.3712393410969526e-05 \n",
      "epoch: 26 [307747/888800 34.62%] train loss: 1.4077211744734086e-05 \n",
      "epoch: 26 [308858/888800 34.75%] train loss: 1.3329179637366906e-05 \n",
      "epoch: 26 [309969/888800 34.88%] train loss: 1.4515002476400696e-05 \n",
      "epoch: 26 [311080/888800 35.00%] train loss: 1.4241939425119199e-05 \n",
      "epoch: 26 [312191/888800 35.12%] train loss: 1.434942168998532e-05 \n",
      "epoch: 26 [313302/888800 35.25%] train loss: 1.3500812201527879e-05 \n",
      "epoch: 26 [314413/888800 35.38%] train loss: 1.4026348253537435e-05 \n",
      "epoch: 26 [315524/888800 35.50%] train loss: 1.5193801118584815e-05 \n",
      "epoch: 26 [316635/888800 35.62%] train loss: 1.461422743886942e-05 \n",
      "epoch: 26 [317746/888800 35.75%] train loss: 1.4678938896395266e-05 \n",
      "epoch: 26 [318857/888800 35.88%] train loss: 1.3709392078453675e-05 \n",
      "epoch: 26 [319968/888800 36.00%] train loss: 1.492705905548064e-05 \n",
      "epoch: 26 [321079/888800 36.12%] train loss: 1.456857626180863e-05 \n",
      "epoch: 26 [322190/888800 36.25%] train loss: 1.3838532140653115e-05 \n",
      "epoch: 26 [323301/888800 36.38%] train loss: 1.4407464732357766e-05 \n",
      "epoch: 26 [324412/888800 36.50%] train loss: 1.4774468581890687e-05 \n",
      "epoch: 26 [325523/888800 36.62%] train loss: 1.5185833035502583e-05 \n",
      "epoch: 26 [326634/888800 36.75%] train loss: 1.3778627362626139e-05 \n",
      "epoch: 26 [327745/888800 36.88%] train loss: 1.3718717127630953e-05 \n",
      "epoch: 26 [328856/888800 37.00%] train loss: 1.4274717614171095e-05 \n",
      "epoch: 26 [329967/888800 37.12%] train loss: 1.3883840438211337e-05 \n",
      "epoch: 26 [331078/888800 37.25%] train loss: 1.4742169696546625e-05 \n",
      "epoch: 26 [332189/888800 37.38%] train loss: 1.4093607205722947e-05 \n",
      "epoch: 26 [333300/888800 37.50%] train loss: 1.4670812561234925e-05 \n",
      "epoch: 26 [334411/888800 37.62%] train loss: 1.4454398296948057e-05 \n",
      "epoch: 26 [335522/888800 37.75%] train loss: 1.3942065379524138e-05 \n",
      "epoch: 26 [336633/888800 37.88%] train loss: 1.3808697076456156e-05 \n",
      "epoch: 26 [337744/888800 38.00%] train loss: 1.453504228265956e-05 \n",
      "epoch: 26 [338855/888800 38.12%] train loss: 1.3664490325027145e-05 \n",
      "epoch: 26 [339966/888800 38.25%] train loss: 1.3682593817065936e-05 \n",
      "epoch: 26 [341077/888800 38.38%] train loss: 1.3730588761973195e-05 \n",
      "epoch: 26 [342188/888800 38.50%] train loss: 1.4538083632942289e-05 \n",
      "epoch: 26 [343299/888800 38.62%] train loss: 1.4685067981190514e-05 \n",
      "epoch: 26 [344410/888800 38.75%] train loss: 1.416332906956086e-05 \n",
      "epoch: 26 [345521/888800 38.88%] train loss: 1.4495933100988623e-05 \n",
      "epoch: 26 [346632/888800 39.00%] train loss: 1.4332055798149668e-05 \n",
      "epoch: 26 [347743/888800 39.12%] train loss: 1.3666952327184845e-05 \n",
      "epoch: 26 [348854/888800 39.25%] train loss: 1.39524599944707e-05 \n",
      "epoch: 26 [349965/888800 39.38%] train loss: 1.51124331750907e-05 \n",
      "epoch: 26 [351076/888800 39.50%] train loss: 1.3513876183424145e-05 \n",
      "epoch: 26 [352187/888800 39.62%] train loss: 1.4298315363703296e-05 \n",
      "epoch: 26 [353298/888800 39.75%] train loss: 1.4354071936395485e-05 \n",
      "epoch: 26 [354409/888800 39.88%] train loss: 1.2557009540614672e-05 \n",
      "epoch: 26 [355520/888800 40.00%] train loss: 1.3802369721815921e-05 \n",
      "epoch: 26 [356631/888800 40.12%] train loss: 1.3982021300762426e-05 \n",
      "epoch: 26 [357742/888800 40.25%] train loss: 1.42959579534363e-05 \n",
      "epoch: 26 [358853/888800 40.38%] train loss: 1.3617527656606399e-05 \n",
      "epoch: 26 [359964/888800 40.50%] train loss: 1.5066449122969061e-05 \n",
      "epoch: 26 [361075/888800 40.62%] train loss: 1.3807273717247881e-05 \n",
      "epoch: 26 [362186/888800 40.75%] train loss: 1.3955330359749496e-05 \n",
      "epoch: 26 [363297/888800 40.88%] train loss: 1.4240454220271204e-05 \n",
      "epoch: 26 [364408/888800 41.00%] train loss: 1.3411040526989382e-05 \n",
      "epoch: 26 [365519/888800 41.12%] train loss: 1.3828664123138878e-05 \n",
      "epoch: 26 [366630/888800 41.25%] train loss: 1.546416933706496e-05 \n",
      "epoch: 26 [367741/888800 41.38%] train loss: 1.4343297152663581e-05 \n",
      "epoch: 26 [368852/888800 41.50%] train loss: 1.4466318134509493e-05 \n",
      "epoch: 26 [369963/888800 41.62%] train loss: 1.3688920262211468e-05 \n",
      "epoch: 26 [371074/888800 41.75%] train loss: 1.3790767297905404e-05 \n",
      "epoch: 26 [372185/888800 41.88%] train loss: 1.4734592696186155e-05 \n",
      "epoch: 26 [373296/888800 42.00%] train loss: 1.3527133887691889e-05 \n",
      "epoch: 26 [374407/888800 42.12%] train loss: 1.458546375943115e-05 \n",
      "epoch: 26 [375518/888800 42.25%] train loss: 1.415541919413954e-05 \n",
      "epoch: 26 [376629/888800 42.38%] train loss: 1.5087457541085314e-05 \n",
      "epoch: 26 [377740/888800 42.50%] train loss: 1.4829064639343414e-05 \n",
      "epoch: 26 [378851/888800 42.62%] train loss: 1.4007881873112638e-05 \n",
      "epoch: 26 [379962/888800 42.75%] train loss: 1.382502250635298e-05 \n",
      "epoch: 26 [381073/888800 42.88%] train loss: 1.4112530152488034e-05 \n",
      "epoch: 26 [382184/888800 43.00%] train loss: 1.5038232959341258e-05 \n",
      "epoch: 26 [383295/888800 43.12%] train loss: 1.3527352166420314e-05 \n",
      "epoch: 26 [384406/888800 43.25%] train loss: 1.3577288882515859e-05 \n",
      "epoch: 26 [385517/888800 43.38%] train loss: 1.3343275895749684e-05 \n",
      "epoch: 26 [386628/888800 43.50%] train loss: 1.3645751096191816e-05 \n",
      "epoch: 26 [387739/888800 43.62%] train loss: 1.4269988241721876e-05 \n",
      "epoch: 26 [388850/888800 43.75%] train loss: 1.252392030437477e-05 \n",
      "epoch: 26 [389961/888800 43.88%] train loss: 1.3469230907503515e-05 \n",
      "epoch: 26 [391072/888800 44.00%] train loss: 1.4627114978793543e-05 \n",
      "epoch: 26 [392183/888800 44.12%] train loss: 1.4810024367761798e-05 \n",
      "epoch: 26 [393294/888800 44.25%] train loss: 1.4809868844167795e-05 \n",
      "epoch: 26 [394405/888800 44.38%] train loss: 1.433240595360985e-05 \n",
      "epoch: 26 [395516/888800 44.50%] train loss: 1.5752344552311115e-05 \n",
      "epoch: 26 [396627/888800 44.62%] train loss: 1.3129170838510618e-05 \n",
      "epoch: 26 [397738/888800 44.75%] train loss: 1.3853152267984115e-05 \n",
      "epoch: 26 [398849/888800 44.88%] train loss: 1.6353938917745836e-05 \n",
      "epoch: 26 [399960/888800 45.00%] train loss: 1.3185167517804075e-05 \n",
      "epoch: 26 [401071/888800 45.12%] train loss: 1.3412565749604255e-05 \n",
      "epoch: 26 [402182/888800 45.25%] train loss: 1.3559564649767708e-05 \n",
      "epoch: 26 [403293/888800 45.38%] train loss: 1.486442306486424e-05 \n",
      "epoch: 26 [404404/888800 45.50%] train loss: 1.4695754543936346e-05 \n",
      "epoch: 26 [405515/888800 45.62%] train loss: 1.4064179595152382e-05 \n",
      "epoch: 26 [406626/888800 45.75%] train loss: 1.367805089103058e-05 \n",
      "epoch: 26 [407737/888800 45.88%] train loss: 1.4522284800477792e-05 \n",
      "epoch: 26 [408848/888800 46.00%] train loss: 1.3240320186014287e-05 \n",
      "epoch: 26 [409959/888800 46.12%] train loss: 1.2505433915066533e-05 \n",
      "epoch: 26 [411070/888800 46.25%] train loss: 1.4136804566078354e-05 \n",
      "epoch: 26 [412181/888800 46.38%] train loss: 1.6030682672862895e-05 \n",
      "epoch: 26 [413292/888800 46.50%] train loss: 1.3754007341049146e-05 \n",
      "epoch: 26 [414403/888800 46.62%] train loss: 1.508673722128151e-05 \n",
      "epoch: 26 [415514/888800 46.75%] train loss: 1.4173439012665767e-05 \n",
      "epoch: 26 [416625/888800 46.88%] train loss: 1.4127813301456627e-05 \n",
      "epoch: 26 [417736/888800 47.00%] train loss: 1.3396863323578145e-05 \n",
      "epoch: 26 [418847/888800 47.12%] train loss: 1.3487822798197158e-05 \n",
      "epoch: 26 [419958/888800 47.25%] train loss: 1.372379392705625e-05 \n",
      "epoch: 26 [421069/888800 47.38%] train loss: 1.3921574463893194e-05 \n",
      "epoch: 26 [422180/888800 47.50%] train loss: 1.358164445264265e-05 \n",
      "epoch: 26 [423291/888800 47.62%] train loss: 1.3917517208028585e-05 \n",
      "epoch: 26 [424402/888800 47.75%] train loss: 1.5736713976366445e-05 \n",
      "epoch: 26 [425513/888800 47.88%] train loss: 1.3363365724217147e-05 \n",
      "epoch: 26 [426624/888800 48.00%] train loss: 1.4806805666012224e-05 \n",
      "epoch: 26 [427735/888800 48.12%] train loss: 1.4063815797271673e-05 \n",
      "epoch: 26 [428846/888800 48.25%] train loss: 1.4645113878941629e-05 \n",
      "epoch: 26 [429957/888800 48.38%] train loss: 1.4789489796385169e-05 \n",
      "epoch: 26 [431068/888800 48.50%] train loss: 1.3744110219704453e-05 \n",
      "epoch: 26 [432179/888800 48.62%] train loss: 1.5523064575972967e-05 \n",
      "epoch: 26 [433290/888800 48.75%] train loss: 1.4566797290171962e-05 \n",
      "epoch: 26 [434401/888800 48.88%] train loss: 1.5061835256346967e-05 \n",
      "epoch: 26 [435512/888800 49.00%] train loss: 1.3046981621300802e-05 \n",
      "epoch: 26 [436623/888800 49.12%] train loss: 1.4375015780387912e-05 \n",
      "epoch: 26 [437734/888800 49.25%] train loss: 1.419990530848736e-05 \n",
      "epoch: 26 [438845/888800 49.38%] train loss: 1.4443614418269135e-05 \n",
      "epoch: 26 [439956/888800 49.50%] train loss: 1.4508691492665093e-05 \n",
      "epoch: 26 [441067/888800 49.62%] train loss: 1.4453107723966241e-05 \n",
      "epoch: 26 [442178/888800 49.75%] train loss: 1.3658599527843762e-05 \n",
      "epoch: 26 [443289/888800 49.88%] train loss: 1.332020474364981e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [444400/888800 50.00%] train loss: 1.448819057259243e-05 \n",
      "epoch: 26 [445511/888800 50.12%] train loss: 1.4303534044302069e-05 \n",
      "epoch: 26 [446622/888800 50.25%] train loss: 1.3306901564646978e-05 \n",
      "epoch: 26 [447733/888800 50.38%] train loss: 1.4445405213336926e-05 \n",
      "epoch: 26 [448844/888800 50.50%] train loss: 1.4794529306527693e-05 \n",
      "epoch: 26 [449955/888800 50.62%] train loss: 1.4753316463611554e-05 \n",
      "epoch: 26 [451066/888800 50.75%] train loss: 1.4616569387726486e-05 \n",
      "epoch: 26 [452177/888800 50.88%] train loss: 1.4256161193770822e-05 \n",
      "epoch: 26 [453288/888800 51.00%] train loss: 1.4702048247272614e-05 \n",
      "epoch: 26 [454399/888800 51.12%] train loss: 1.3947308616479859e-05 \n",
      "epoch: 26 [455510/888800 51.25%] train loss: 1.5695632100687362e-05 \n",
      "epoch: 26 [456621/888800 51.38%] train loss: 1.4330447811516933e-05 \n",
      "epoch: 26 [457732/888800 51.50%] train loss: 1.4264257515606005e-05 \n",
      "epoch: 26 [458843/888800 51.62%] train loss: 1.4253188965085428e-05 \n",
      "epoch: 26 [459954/888800 51.75%] train loss: 1.4495738469122443e-05 \n",
      "epoch: 26 [461065/888800 51.88%] train loss: 1.3885744010622147e-05 \n",
      "epoch: 26 [462176/888800 52.00%] train loss: 1.3795020095130894e-05 \n",
      "epoch: 26 [463287/888800 52.12%] train loss: 1.5052607523102779e-05 \n",
      "epoch: 26 [464398/888800 52.25%] train loss: 1.3553428289014846e-05 \n",
      "epoch: 26 [465509/888800 52.38%] train loss: 1.4253762856242247e-05 \n",
      "epoch: 26 [466620/888800 52.50%] train loss: 1.3610514542961027e-05 \n",
      "epoch: 26 [467731/888800 52.62%] train loss: 1.36618509714026e-05 \n",
      "epoch: 26 [468842/888800 52.75%] train loss: 1.3945399587100837e-05 \n",
      "epoch: 26 [469953/888800 52.88%] train loss: 1.531248381070327e-05 \n",
      "epoch: 26 [471064/888800 53.00%] train loss: 1.3620382560475264e-05 \n",
      "epoch: 26 [472175/888800 53.12%] train loss: 1.508769128122367e-05 \n",
      "epoch: 26 [473286/888800 53.25%] train loss: 1.3376569768297486e-05 \n",
      "epoch: 26 [474397/888800 53.38%] train loss: 1.3445816875901073e-05 \n",
      "epoch: 26 [475508/888800 53.50%] train loss: 1.4593253581551835e-05 \n",
      "epoch: 26 [476619/888800 53.62%] train loss: 1.5359633835032582e-05 \n",
      "epoch: 26 [477730/888800 53.75%] train loss: 1.3071574358036742e-05 \n",
      "epoch: 26 [478841/888800 53.88%] train loss: 1.5189462828857359e-05 \n",
      "epoch: 26 [479952/888800 54.00%] train loss: 1.43645956995897e-05 \n",
      "epoch: 26 [481063/888800 54.12%] train loss: 1.3876230696041603e-05 \n",
      "epoch: 26 [482174/888800 54.25%] train loss: 1.388682267133845e-05 \n",
      "epoch: 26 [483285/888800 54.38%] train loss: 1.474574219173519e-05 \n",
      "epoch: 26 [484396/888800 54.50%] train loss: 1.4729781469213776e-05 \n",
      "epoch: 26 [485507/888800 54.62%] train loss: 1.4194140931067523e-05 \n",
      "epoch: 26 [486618/888800 54.75%] train loss: 1.3986805242893752e-05 \n",
      "epoch: 26 [487729/888800 54.88%] train loss: 1.4895288586558308e-05 \n",
      "epoch: 26 [488840/888800 55.00%] train loss: 1.48592207551701e-05 \n",
      "epoch: 26 [489951/888800 55.12%] train loss: 1.3464828953146935e-05 \n",
      "epoch: 26 [491062/888800 55.25%] train loss: 1.4244829799281433e-05 \n",
      "epoch: 26 [492173/888800 55.38%] train loss: 1.4327380085887853e-05 \n",
      "epoch: 26 [493284/888800 55.50%] train loss: 1.500110374763608e-05 \n",
      "epoch: 26 [494395/888800 55.62%] train loss: 1.456749851058703e-05 \n",
      "epoch: 26 [495506/888800 55.75%] train loss: 1.4934908904251643e-05 \n",
      "epoch: 26 [496617/888800 55.88%] train loss: 1.4791726243856829e-05 \n",
      "epoch: 26 [497728/888800 56.00%] train loss: 1.445459474780364e-05 \n",
      "epoch: 26 [498839/888800 56.12%] train loss: 1.6082129150163382e-05 \n",
      "epoch: 26 [499950/888800 56.25%] train loss: 1.48815361171728e-05 \n",
      "epoch: 26 [501061/888800 56.38%] train loss: 1.3848273738403805e-05 \n",
      "epoch: 26 [502172/888800 56.50%] train loss: 1.4311453924165107e-05 \n",
      "epoch: 26 [503283/888800 56.62%] train loss: 1.39618987304857e-05 \n",
      "epoch: 26 [504394/888800 56.75%] train loss: 1.3589173249783926e-05 \n",
      "epoch: 26 [505505/888800 56.88%] train loss: 1.456679092370905e-05 \n",
      "epoch: 26 [506616/888800 57.00%] train loss: 1.5345543943112716e-05 \n",
      "epoch: 26 [507727/888800 57.12%] train loss: 1.315821282332763e-05 \n",
      "epoch: 26 [508838/888800 57.25%] train loss: 1.3817723811371252e-05 \n",
      "epoch: 26 [509949/888800 57.38%] train loss: 1.2708644135273062e-05 \n",
      "epoch: 26 [511060/888800 57.50%] train loss: 1.4060610737942625e-05 \n",
      "epoch: 26 [512171/888800 57.62%] train loss: 1.4131522220850457e-05 \n",
      "epoch: 26 [513282/888800 57.75%] train loss: 1.3566689631261397e-05 \n",
      "epoch: 26 [514393/888800 57.88%] train loss: 1.4679535524919629e-05 \n",
      "epoch: 26 [515504/888800 58.00%] train loss: 1.348544901702553e-05 \n",
      "epoch: 26 [516615/888800 58.12%] train loss: 1.4731369446963072e-05 \n",
      "epoch: 26 [517726/888800 58.25%] train loss: 1.3225258953752927e-05 \n",
      "epoch: 26 [518837/888800 58.38%] train loss: 1.4763121725991368e-05 \n",
      "epoch: 26 [519948/888800 58.50%] train loss: 1.5059858924360014e-05 \n",
      "epoch: 26 [521059/888800 58.62%] train loss: 1.4233964066079352e-05 \n",
      "epoch: 26 [522170/888800 58.75%] train loss: 1.4495497453026474e-05 \n",
      "epoch: 26 [523281/888800 58.88%] train loss: 1.2893515304313041e-05 \n",
      "epoch: 26 [524392/888800 59.00%] train loss: 1.5092296052898746e-05 \n",
      "epoch: 26 [525503/888800 59.12%] train loss: 1.4282283700595144e-05 \n",
      "epoch: 26 [526614/888800 59.25%] train loss: 1.568880361446645e-05 \n",
      "epoch: 26 [527725/888800 59.38%] train loss: 1.3919614502810873e-05 \n",
      "epoch: 26 [528836/888800 59.50%] train loss: 1.3308948837220669e-05 \n",
      "epoch: 26 [529947/888800 59.62%] train loss: 1.36803182613221e-05 \n",
      "epoch: 26 [531058/888800 59.75%] train loss: 1.535332739877049e-05 \n",
      "epoch: 26 [532169/888800 59.88%] train loss: 1.2591851373144891e-05 \n",
      "epoch: 26 [533280/888800 60.00%] train loss: 1.470566803618567e-05 \n",
      "epoch: 26 [534391/888800 60.12%] train loss: 1.4773770999454428e-05 \n",
      "epoch: 26 [535502/888800 60.25%] train loss: 1.2870585123891942e-05 \n",
      "epoch: 26 [536613/888800 60.38%] train loss: 1.3597114048025105e-05 \n",
      "epoch: 26 [537724/888800 60.50%] train loss: 1.442778648197418e-05 \n",
      "epoch: 26 [538835/888800 60.62%] train loss: 1.3449651305563748e-05 \n",
      "epoch: 26 [539946/888800 60.75%] train loss: 1.3738059351453558e-05 \n",
      "epoch: 26 [541057/888800 60.88%] train loss: 1.5656527466489933e-05 \n",
      "epoch: 26 [542168/888800 61.00%] train loss: 1.4284099961514585e-05 \n",
      "epoch: 26 [543279/888800 61.12%] train loss: 1.4182490303937811e-05 \n",
      "epoch: 26 [544390/888800 61.25%] train loss: 1.363782212138176e-05 \n",
      "epoch: 26 [545501/888800 61.38%] train loss: 1.4722871128469706e-05 \n",
      "epoch: 26 [546612/888800 61.50%] train loss: 1.526970117993187e-05 \n",
      "epoch: 26 [547723/888800 61.62%] train loss: 1.4656438906968106e-05 \n",
      "epoch: 26 [548834/888800 61.75%] train loss: 1.6261388736893423e-05 \n",
      "epoch: 26 [549945/888800 61.88%] train loss: 1.3432384548650589e-05 \n",
      "epoch: 26 [551056/888800 62.00%] train loss: 1.4952457604522351e-05 \n",
      "epoch: 26 [552167/888800 62.12%] train loss: 1.4496346011583228e-05 \n",
      "epoch: 26 [553278/888800 62.25%] train loss: 1.4953835488995537e-05 \n",
      "epoch: 26 [554389/888800 62.38%] train loss: 1.4944108443160076e-05 \n",
      "epoch: 26 [555500/888800 62.50%] train loss: 1.4367221410793718e-05 \n",
      "epoch: 26 [556611/888800 62.62%] train loss: 1.6294185115839355e-05 \n",
      "epoch: 26 [557722/888800 62.75%] train loss: 1.5641508070984855e-05 \n",
      "epoch: 26 [558833/888800 62.88%] train loss: 1.498154870205326e-05 \n",
      "epoch: 26 [559944/888800 63.00%] train loss: 1.3560312254412565e-05 \n",
      "epoch: 26 [561055/888800 63.12%] train loss: 1.2757529475493357e-05 \n",
      "epoch: 26 [562166/888800 63.25%] train loss: 1.3659388969244901e-05 \n",
      "epoch: 26 [563277/888800 63.38%] train loss: 1.350245474895928e-05 \n",
      "epoch: 26 [564388/888800 63.50%] train loss: 1.3635721188620664e-05 \n",
      "epoch: 26 [565499/888800 63.62%] train loss: 1.4585916687792633e-05 \n",
      "epoch: 26 [566610/888800 63.75%] train loss: 1.4261558135331143e-05 \n",
      "epoch: 26 [567721/888800 63.88%] train loss: 1.3016506272833794e-05 \n",
      "epoch: 26 [568832/888800 64.00%] train loss: 1.4971066775615327e-05 \n",
      "epoch: 26 [569943/888800 64.12%] train loss: 1.5262963643181138e-05 \n",
      "epoch: 26 [571054/888800 64.25%] train loss: 1.4022900359123014e-05 \n",
      "epoch: 26 [572165/888800 64.38%] train loss: 1.414994039805606e-05 \n",
      "epoch: 26 [573276/888800 64.50%] train loss: 1.488409088779008e-05 \n",
      "epoch: 26 [574387/888800 64.62%] train loss: 1.407789568474982e-05 \n",
      "epoch: 26 [575498/888800 64.75%] train loss: 1.4583051779482048e-05 \n",
      "epoch: 26 [576609/888800 64.88%] train loss: 1.3776000741927419e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [577720/888800 65.00%] train loss: 1.4575130080629606e-05 \n",
      "epoch: 26 [578831/888800 65.12%] train loss: 1.3449925972963683e-05 \n",
      "epoch: 26 [579942/888800 65.25%] train loss: 1.4058517081139144e-05 \n",
      "epoch: 26 [581053/888800 65.38%] train loss: 1.582564800628461e-05 \n",
      "epoch: 26 [582164/888800 65.50%] train loss: 1.2738618352159392e-05 \n",
      "epoch: 26 [583275/888800 65.62%] train loss: 1.3937617040937766e-05 \n",
      "epoch: 26 [584386/888800 65.75%] train loss: 1.3336659321794286e-05 \n",
      "epoch: 26 [585497/888800 65.88%] train loss: 1.4104306501394603e-05 \n",
      "epoch: 26 [586608/888800 66.00%] train loss: 1.3966659935249481e-05 \n",
      "epoch: 26 [587719/888800 66.12%] train loss: 1.4467542314378079e-05 \n",
      "epoch: 26 [588830/888800 66.25%] train loss: 1.4404277862922754e-05 \n",
      "epoch: 26 [589941/888800 66.38%] train loss: 1.5506577256019227e-05 \n",
      "epoch: 26 [591052/888800 66.50%] train loss: 1.5630714187864214e-05 \n",
      "epoch: 26 [592163/888800 66.62%] train loss: 1.4665610251540784e-05 \n",
      "epoch: 26 [593274/888800 66.75%] train loss: 1.4686868780700024e-05 \n",
      "epoch: 26 [594385/888800 66.88%] train loss: 1.4062499758438207e-05 \n",
      "epoch: 26 [595496/888800 67.00%] train loss: 1.535490810056217e-05 \n",
      "epoch: 26 [596607/888800 67.12%] train loss: 1.5559258827124722e-05 \n",
      "epoch: 26 [597718/888800 67.25%] train loss: 1.5646597603335977e-05 \n",
      "epoch: 26 [598829/888800 67.38%] train loss: 1.4449876289290842e-05 \n",
      "epoch: 26 [599940/888800 67.50%] train loss: 1.3591626156994607e-05 \n",
      "epoch: 26 [601051/888800 67.62%] train loss: 1.3991089872433804e-05 \n",
      "epoch: 26 [602162/888800 67.75%] train loss: 1.5234353668347467e-05 \n",
      "epoch: 26 [603273/888800 67.88%] train loss: 1.4071620171307586e-05 \n",
      "epoch: 26 [604384/888800 68.00%] train loss: 1.4748206922376994e-05 \n",
      "epoch: 26 [605495/888800 68.12%] train loss: 1.3508027222997043e-05 \n",
      "epoch: 26 [606606/888800 68.25%] train loss: 1.4584958080376964e-05 \n",
      "epoch: 26 [607717/888800 68.38%] train loss: 1.3865388609701768e-05 \n",
      "epoch: 26 [608828/888800 68.50%] train loss: 1.4528062820318155e-05 \n",
      "epoch: 26 [609939/888800 68.62%] train loss: 1.5371429981314577e-05 \n",
      "epoch: 26 [611050/888800 68.75%] train loss: 1.603050623089075e-05 \n",
      "epoch: 26 [612161/888800 68.88%] train loss: 1.587810220371466e-05 \n",
      "epoch: 26 [613272/888800 69.00%] train loss: 1.4532156455970835e-05 \n",
      "epoch: 26 [614383/888800 69.12%] train loss: 1.4880298294883687e-05 \n",
      "epoch: 26 [615494/888800 69.25%] train loss: 1.3598050827567931e-05 \n",
      "epoch: 26 [616605/888800 69.38%] train loss: 1.4517744602926541e-05 \n",
      "epoch: 26 [617716/888800 69.50%] train loss: 1.4283038581197616e-05 \n",
      "epoch: 26 [618827/888800 69.62%] train loss: 1.487871941208141e-05 \n",
      "epoch: 26 [619938/888800 69.75%] train loss: 1.2776245966961142e-05 \n",
      "epoch: 26 [621049/888800 69.88%] train loss: 1.392800004396122e-05 \n",
      "epoch: 26 [622160/888800 70.00%] train loss: 1.4704712157254107e-05 \n",
      "epoch: 26 [623271/888800 70.12%] train loss: 1.5712044842075557e-05 \n",
      "epoch: 26 [624382/888800 70.25%] train loss: 1.4309614925878122e-05 \n",
      "epoch: 26 [625493/888800 70.38%] train loss: 1.4470577298197895e-05 \n",
      "epoch: 26 [626604/888800 70.50%] train loss: 1.326334950135788e-05 \n",
      "epoch: 26 [627715/888800 70.62%] train loss: 1.389466069667833e-05 \n",
      "epoch: 26 [628826/888800 70.75%] train loss: 1.3192148799134884e-05 \n",
      "epoch: 26 [629937/888800 70.88%] train loss: 1.2966627764399163e-05 \n",
      "epoch: 26 [631048/888800 71.00%] train loss: 1.4889162230247166e-05 \n",
      "epoch: 26 [632159/888800 71.12%] train loss: 1.4240326891012955e-05 \n",
      "epoch: 26 [633270/888800 71.25%] train loss: 1.5248418094415683e-05 \n",
      "epoch: 26 [634381/888800 71.38%] train loss: 1.5466659533558413e-05 \n",
      "epoch: 26 [635492/888800 71.50%] train loss: 1.3852450138074346e-05 \n",
      "epoch: 26 [636603/888800 71.62%] train loss: 1.3847396985511295e-05 \n",
      "epoch: 26 [637714/888800 71.75%] train loss: 1.5596271623508073e-05 \n",
      "epoch: 26 [638825/888800 71.88%] train loss: 1.624661854293663e-05 \n",
      "epoch: 26 [639936/888800 72.00%] train loss: 1.3999519069329835e-05 \n",
      "epoch: 26 [641047/888800 72.12%] train loss: 1.5503826944041066e-05 \n",
      "epoch: 26 [642158/888800 72.25%] train loss: 1.3784044313069899e-05 \n",
      "epoch: 26 [643269/888800 72.38%] train loss: 1.5691848602727987e-05 \n",
      "epoch: 26 [644380/888800 72.50%] train loss: 1.4932459635019768e-05 \n",
      "epoch: 26 [645491/888800 72.62%] train loss: 1.3835019672114868e-05 \n",
      "epoch: 26 [646602/888800 72.75%] train loss: 1.4432133866648655e-05 \n",
      "epoch: 26 [647713/888800 72.88%] train loss: 1.414419966749847e-05 \n",
      "epoch: 26 [648824/888800 73.00%] train loss: 1.40238680614857e-05 \n",
      "epoch: 26 [649935/888800 73.12%] train loss: 1.3218324056651909e-05 \n",
      "epoch: 26 [651046/888800 73.25%] train loss: 1.4986993846832775e-05 \n",
      "epoch: 26 [652157/888800 73.38%] train loss: 1.4724600987392478e-05 \n",
      "epoch: 26 [653268/888800 73.50%] train loss: 1.3432504601951223e-05 \n",
      "epoch: 26 [654379/888800 73.62%] train loss: 1.4664127775176894e-05 \n",
      "epoch: 26 [655490/888800 73.75%] train loss: 1.4185165127855726e-05 \n",
      "epoch: 26 [656601/888800 73.88%] train loss: 1.2992863958061207e-05 \n",
      "epoch: 26 [657712/888800 74.00%] train loss: 1.5248403542500455e-05 \n",
      "epoch: 26 [658823/888800 74.12%] train loss: 1.429776330041932e-05 \n",
      "epoch: 26 [659934/888800 74.25%] train loss: 1.476620582252508e-05 \n",
      "epoch: 26 [661045/888800 74.38%] train loss: 1.5662333680666052e-05 \n",
      "epoch: 26 [662156/888800 74.50%] train loss: 1.4202426427800674e-05 \n",
      "epoch: 26 [663267/888800 74.62%] train loss: 1.365393018204486e-05 \n",
      "epoch: 26 [664378/888800 74.75%] train loss: 1.4597682820749469e-05 \n",
      "epoch: 26 [665489/888800 74.88%] train loss: 1.4304508113127667e-05 \n",
      "epoch: 26 [666600/888800 75.00%] train loss: 1.3729018974117935e-05 \n",
      "epoch: 26 [667711/888800 75.12%] train loss: 1.3755853615293745e-05 \n",
      "epoch: 26 [668822/888800 75.25%] train loss: 1.3862146261089947e-05 \n",
      "epoch: 26 [669933/888800 75.38%] train loss: 1.4749809452041518e-05 \n",
      "epoch: 26 [671044/888800 75.50%] train loss: 1.377090211462928e-05 \n",
      "epoch: 26 [672155/888800 75.62%] train loss: 1.4091035154706333e-05 \n",
      "epoch: 26 [673266/888800 75.75%] train loss: 1.486822384322295e-05 \n",
      "epoch: 26 [674377/888800 75.88%] train loss: 1.5091854038473684e-05 \n",
      "epoch: 26 [675488/888800 76.00%] train loss: 1.4054758139536716e-05 \n",
      "epoch: 26 [676599/888800 76.12%] train loss: 1.591853470017668e-05 \n",
      "epoch: 26 [677710/888800 76.25%] train loss: 1.337402227363782e-05 \n",
      "epoch: 26 [678821/888800 76.38%] train loss: 1.490945851401193e-05 \n",
      "epoch: 26 [679932/888800 76.50%] train loss: 1.4096369341132231e-05 \n",
      "epoch: 26 [681043/888800 76.62%] train loss: 1.3028717148699798e-05 \n",
      "epoch: 26 [682154/888800 76.75%] train loss: 1.4187107808538713e-05 \n",
      "epoch: 26 [683265/888800 76.88%] train loss: 1.4829006431682501e-05 \n",
      "epoch: 26 [684376/888800 77.00%] train loss: 1.3229076103016268e-05 \n",
      "epoch: 26 [685487/888800 77.12%] train loss: 1.3318122910277452e-05 \n",
      "epoch: 26 [686598/888800 77.25%] train loss: 1.3971406588098034e-05 \n",
      "epoch: 26 [687709/888800 77.38%] train loss: 1.4175705473462585e-05 \n",
      "epoch: 26 [688820/888800 77.50%] train loss: 1.4556394489773083e-05 \n",
      "epoch: 26 [689931/888800 77.62%] train loss: 1.3027001841692254e-05 \n",
      "epoch: 26 [691042/888800 77.75%] train loss: 1.3670717635250185e-05 \n",
      "epoch: 26 [692153/888800 77.88%] train loss: 1.362975308438763e-05 \n",
      "epoch: 26 [693264/888800 78.00%] train loss: 1.4876367458782624e-05 \n",
      "epoch: 26 [694375/888800 78.12%] train loss: 1.4562185242539272e-05 \n",
      "epoch: 26 [695486/888800 78.25%] train loss: 1.2516799870354589e-05 \n",
      "epoch: 26 [696597/888800 78.38%] train loss: 1.4279636161518283e-05 \n",
      "epoch: 26 [697708/888800 78.50%] train loss: 1.4871829080220778e-05 \n",
      "epoch: 26 [698819/888800 78.62%] train loss: 1.4447717148868833e-05 \n",
      "epoch: 26 [699930/888800 78.75%] train loss: 1.4390847354661673e-05 \n",
      "epoch: 26 [701041/888800 78.88%] train loss: 1.5256683582265396e-05 \n",
      "epoch: 26 [702152/888800 79.00%] train loss: 1.4281013136496767e-05 \n",
      "epoch: 26 [703263/888800 79.12%] train loss: 1.3655082511832006e-05 \n",
      "epoch: 26 [704374/888800 79.25%] train loss: 1.4936555089661852e-05 \n",
      "epoch: 26 [705485/888800 79.38%] train loss: 1.4379612366610672e-05 \n",
      "epoch: 26 [706596/888800 79.50%] train loss: 1.4104670299275313e-05 \n",
      "epoch: 26 [707707/888800 79.62%] train loss: 1.474539385526441e-05 \n",
      "epoch: 26 [708818/888800 79.75%] train loss: 1.4476821888820268e-05 \n",
      "epoch: 26 [709929/888800 79.88%] train loss: 1.372732913296204e-05 \n",
      "epoch: 26 [711040/888800 80.00%] train loss: 1.4044144336367026e-05 \n",
      "epoch: 26 [712151/888800 80.12%] train loss: 1.2995547876926139e-05 \n",
      "epoch: 26 [713262/888800 80.25%] train loss: 1.3154784028301947e-05 \n",
      "epoch: 26 [714373/888800 80.38%] train loss: 1.4872975043545011e-05 \n",
      "epoch: 26 [715484/888800 80.50%] train loss: 1.4082455891184509e-05 \n",
      "epoch: 26 [716595/888800 80.62%] train loss: 1.5000619896454737e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [717706/888800 80.75%] train loss: 1.3976553418615367e-05 \n",
      "epoch: 26 [718817/888800 80.88%] train loss: 1.4335520972963423e-05 \n",
      "epoch: 26 [719928/888800 81.00%] train loss: 1.4064158676774241e-05 \n",
      "epoch: 26 [721039/888800 81.12%] train loss: 1.401083318341989e-05 \n",
      "epoch: 26 [722150/888800 81.25%] train loss: 1.3318352102942299e-05 \n",
      "epoch: 26 [723261/888800 81.38%] train loss: 1.3606691936729476e-05 \n",
      "epoch: 26 [724372/888800 81.50%] train loss: 1.4676353202958126e-05 \n",
      "epoch: 26 [725483/888800 81.62%] train loss: 1.521765716461232e-05 \n",
      "epoch: 26 [726594/888800 81.75%] train loss: 1.3657347153639421e-05 \n",
      "epoch: 26 [727705/888800 81.88%] train loss: 1.4364909475261811e-05 \n",
      "epoch: 26 [728816/888800 82.00%] train loss: 1.4589514648832846e-05 \n",
      "epoch: 26 [729927/888800 82.12%] train loss: 1.4188995919539593e-05 \n",
      "epoch: 26 [731038/888800 82.25%] train loss: 1.559496195113752e-05 \n",
      "epoch: 26 [732149/888800 82.38%] train loss: 1.5617915778420866e-05 \n",
      "epoch: 26 [733260/888800 82.50%] train loss: 1.5000993698777165e-05 \n",
      "epoch: 26 [734371/888800 82.62%] train loss: 1.289895226364024e-05 \n",
      "epoch: 26 [735482/888800 82.75%] train loss: 1.351861919829389e-05 \n",
      "epoch: 26 [736593/888800 82.88%] train loss: 1.3612821021524724e-05 \n",
      "epoch: 26 [737704/888800 83.00%] train loss: 1.529637665953487e-05 \n",
      "epoch: 26 [738815/888800 83.12%] train loss: 1.3186748219595756e-05 \n",
      "epoch: 26 [739926/888800 83.25%] train loss: 1.4484277926385403e-05 \n",
      "epoch: 26 [741037/888800 83.38%] train loss: 1.3525424947147258e-05 \n",
      "epoch: 26 [742148/888800 83.50%] train loss: 1.3355876944842748e-05 \n",
      "epoch: 26 [743259/888800 83.62%] train loss: 1.4626864867750555e-05 \n",
      "epoch: 26 [744370/888800 83.75%] train loss: 1.3563773791247513e-05 \n",
      "epoch: 26 [745481/888800 83.88%] train loss: 1.3963890523882583e-05 \n",
      "epoch: 26 [746592/888800 84.00%] train loss: 1.3447726814774796e-05 \n",
      "epoch: 26 [747703/888800 84.12%] train loss: 1.450519630452618e-05 \n",
      "epoch: 26 [748814/888800 84.25%] train loss: 1.381824586133007e-05 \n",
      "epoch: 26 [749925/888800 84.38%] train loss: 1.3852469237463083e-05 \n",
      "epoch: 26 [751036/888800 84.50%] train loss: 1.4920773537596688e-05 \n",
      "epoch: 26 [752147/888800 84.62%] train loss: 1.5493109458475374e-05 \n",
      "epoch: 26 [753258/888800 84.75%] train loss: 1.3674269212060608e-05 \n",
      "epoch: 26 [754369/888800 84.88%] train loss: 1.399301709170686e-05 \n",
      "epoch: 26 [755480/888800 85.00%] train loss: 1.4991748685133643e-05 \n",
      "epoch: 26 [756591/888800 85.12%] train loss: 1.4858003851259127e-05 \n",
      "epoch: 26 [757702/888800 85.25%] train loss: 1.6818485164549202e-05 \n",
      "epoch: 26 [758813/888800 85.38%] train loss: 1.3802814464725088e-05 \n",
      "epoch: 26 [759924/888800 85.50%] train loss: 1.5058857570693363e-05 \n",
      "epoch: 26 [761035/888800 85.62%] train loss: 1.3778395441477187e-05 \n",
      "epoch: 26 [762146/888800 85.75%] train loss: 1.502590657764813e-05 \n",
      "epoch: 26 [763257/888800 85.88%] train loss: 1.4666135029983707e-05 \n",
      "epoch: 26 [764368/888800 86.00%] train loss: 1.5192954379017465e-05 \n",
      "epoch: 26 [765479/888800 86.12%] train loss: 1.4855673725833185e-05 \n",
      "epoch: 26 [766590/888800 86.25%] train loss: 1.5026868823042605e-05 \n",
      "epoch: 26 [767701/888800 86.38%] train loss: 1.3293656593305059e-05 \n",
      "epoch: 26 [768812/888800 86.50%] train loss: 1.3151279745216016e-05 \n",
      "epoch: 26 [769923/888800 86.62%] train loss: 1.4974551049817819e-05 \n",
      "epoch: 26 [771034/888800 86.75%] train loss: 1.500247344665695e-05 \n",
      "epoch: 26 [772145/888800 86.88%] train loss: 1.4710256436956115e-05 \n",
      "epoch: 26 [773256/888800 87.00%] train loss: 1.471646646677982e-05 \n",
      "epoch: 26 [774367/888800 87.12%] train loss: 1.315678673563525e-05 \n",
      "epoch: 26 [775478/888800 87.25%] train loss: 1.4624477444158401e-05 \n",
      "epoch: 26 [776589/888800 87.38%] train loss: 1.3796267921861727e-05 \n",
      "epoch: 26 [777700/888800 87.50%] train loss: 1.523970058769919e-05 \n",
      "epoch: 26 [778811/888800 87.62%] train loss: 1.4017138710187282e-05 \n",
      "epoch: 26 [779922/888800 87.75%] train loss: 1.4276957699621562e-05 \n",
      "epoch: 26 [781033/888800 87.88%] train loss: 1.3014846445003059e-05 \n",
      "epoch: 26 [782144/888800 88.00%] train loss: 1.4815163012826815e-05 \n",
      "epoch: 26 [783255/888800 88.12%] train loss: 1.3831324395141564e-05 \n",
      "epoch: 26 [784366/888800 88.25%] train loss: 1.4893143998051528e-05 \n",
      "epoch: 26 [785477/888800 88.38%] train loss: 1.3003314052184578e-05 \n",
      "epoch: 26 [786588/888800 88.50%] train loss: 1.4154061318549793e-05 \n",
      "epoch: 26 [787699/888800 88.62%] train loss: 1.4256902431952767e-05 \n",
      "epoch: 26 [788810/888800 88.75%] train loss: 1.4342941540235188e-05 \n",
      "epoch: 26 [789921/888800 88.88%] train loss: 1.2772969967045356e-05 \n",
      "epoch: 26 [791032/888800 89.00%] train loss: 1.4443071449932177e-05 \n",
      "epoch: 26 [792143/888800 89.12%] train loss: 1.3906589629186783e-05 \n",
      "epoch: 26 [793254/888800 89.25%] train loss: 1.548622276459355e-05 \n",
      "epoch: 26 [794365/888800 89.38%] train loss: 1.41331347549567e-05 \n",
      "epoch: 26 [795476/888800 89.50%] train loss: 1.4119990737526678e-05 \n",
      "epoch: 26 [796587/888800 89.62%] train loss: 1.3971956832392607e-05 \n",
      "epoch: 26 [797698/888800 89.75%] train loss: 1.5097820323717315e-05 \n",
      "epoch: 26 [798809/888800 89.88%] train loss: 1.5170194274105597e-05 \n",
      "epoch: 26 [799920/888800 90.00%] train loss: 1.4621251466451213e-05 \n",
      "epoch: 26 [801031/888800 90.12%] train loss: 1.365002117381664e-05 \n",
      "epoch: 26 [802142/888800 90.25%] train loss: 1.5504125258303247e-05 \n",
      "epoch: 26 [803253/888800 90.38%] train loss: 1.4523170648317318e-05 \n",
      "epoch: 26 [804364/888800 90.50%] train loss: 1.4192439266480505e-05 \n",
      "epoch: 26 [805475/888800 90.62%] train loss: 1.4496046787826344e-05 \n",
      "epoch: 26 [806586/888800 90.75%] train loss: 1.4143529369903263e-05 \n",
      "epoch: 26 [807697/888800 90.88%] train loss: 1.3561580999521539e-05 \n",
      "epoch: 26 [808808/888800 91.00%] train loss: 1.462656473449897e-05 \n",
      "epoch: 26 [809919/888800 91.12%] train loss: 1.3830705029249657e-05 \n",
      "epoch: 26 [811030/888800 91.25%] train loss: 1.3541771295422222e-05 \n",
      "epoch: 26 [812141/888800 91.38%] train loss: 1.3081348697596695e-05 \n",
      "epoch: 26 [813252/888800 91.50%] train loss: 1.3328169188753236e-05 \n",
      "epoch: 26 [814363/888800 91.62%] train loss: 1.3983403732709121e-05 \n",
      "epoch: 26 [815474/888800 91.75%] train loss: 1.4289797945821192e-05 \n",
      "epoch: 26 [816585/888800 91.88%] train loss: 1.388873624819098e-05 \n",
      "epoch: 26 [817696/888800 92.00%] train loss: 1.4083386304264423e-05 \n",
      "epoch: 26 [818807/888800 92.12%] train loss: 1.5665234968764707e-05 \n",
      "epoch: 26 [819918/888800 92.25%] train loss: 1.3564751498051919e-05 \n",
      "epoch: 26 [821029/888800 92.38%] train loss: 1.454981065762695e-05 \n",
      "epoch: 26 [822140/888800 92.50%] train loss: 1.5358747987193055e-05 \n",
      "epoch: 26 [823251/888800 92.62%] train loss: 1.392680496792309e-05 \n",
      "epoch: 26 [824362/888800 92.75%] train loss: 1.4397228369489312e-05 \n",
      "epoch: 26 [825473/888800 92.88%] train loss: 1.2608556062332354e-05 \n",
      "epoch: 26 [826584/888800 93.00%] train loss: 1.5584057109663263e-05 \n",
      "epoch: 26 [827695/888800 93.12%] train loss: 1.365394018648658e-05 \n",
      "epoch: 26 [828806/888800 93.25%] train loss: 1.380836602038471e-05 \n",
      "epoch: 26 [829917/888800 93.38%] train loss: 1.39168068926665e-05 \n",
      "epoch: 26 [831028/888800 93.50%] train loss: 1.4853125321678817e-05 \n",
      "epoch: 26 [832139/888800 93.62%] train loss: 1.5554131095996127e-05 \n",
      "epoch: 26 [833250/888800 93.75%] train loss: 1.4015735359862447e-05 \n",
      "epoch: 26 [834361/888800 93.88%] train loss: 1.3808210496790707e-05 \n",
      "epoch: 26 [835472/888800 94.00%] train loss: 1.4360129171109293e-05 \n",
      "epoch: 26 [836583/888800 94.12%] train loss: 1.4043379451322835e-05 \n",
      "epoch: 26 [837694/888800 94.25%] train loss: 1.3566455891123042e-05 \n",
      "epoch: 26 [838805/888800 94.38%] train loss: 1.3773984392173588e-05 \n",
      "epoch: 26 [839916/888800 94.50%] train loss: 1.32969607875566e-05 \n",
      "epoch: 26 [841027/888800 94.62%] train loss: 1.4326517884910572e-05 \n",
      "epoch: 26 [842138/888800 94.75%] train loss: 1.503959902038332e-05 \n",
      "epoch: 26 [843249/888800 94.88%] train loss: 1.4471660506387707e-05 \n",
      "epoch: 26 [844360/888800 95.00%] train loss: 1.4119620573183056e-05 \n",
      "epoch: 26 [845471/888800 95.12%] train loss: 1.4006571291247383e-05 \n",
      "epoch: 26 [846582/888800 95.25%] train loss: 1.347567649645498e-05 \n",
      "epoch: 26 [847693/888800 95.38%] train loss: 1.449486990168225e-05 \n",
      "epoch: 26 [848804/888800 95.50%] train loss: 1.3860118997399695e-05 \n",
      "epoch: 26 [849915/888800 95.62%] train loss: 1.4579197340935934e-05 \n",
      "epoch: 26 [851026/888800 95.75%] train loss: 1.3777518688584678e-05 \n",
      "epoch: 26 [852137/888800 95.88%] train loss: 1.4543769793817773e-05 \n",
      "epoch: 26 [853248/888800 96.00%] train loss: 1.3039486475463491e-05 \n",
      "epoch: 26 [854359/888800 96.12%] train loss: 1.4169755559123587e-05 \n",
      "epoch: 26 [855470/888800 96.25%] train loss: 1.359853740723338e-05 \n",
      "epoch: 26 [856581/888800 96.38%] train loss: 1.347674879070837e-05 \n",
      "epoch: 26 [857692/888800 96.50%] train loss: 1.387716838507913e-05 \n",
      "epoch: 26 [858803/888800 96.62%] train loss: 1.3973374734632671e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 [859914/888800 96.75%] train loss: 1.6035222870414145e-05 \n",
      "epoch: 26 [861025/888800 96.88%] train loss: 1.4385544091055635e-05 \n",
      "epoch: 26 [862136/888800 97.00%] train loss: 1.5569490642519668e-05 \n",
      "epoch: 26 [863247/888800 97.12%] train loss: 1.492711999162566e-05 \n",
      "epoch: 26 [864358/888800 97.25%] train loss: 1.4713166820001788e-05 \n",
      "epoch: 26 [865469/888800 97.38%] train loss: 1.3307290828379337e-05 \n",
      "epoch: 26 [866580/888800 97.50%] train loss: 1.4211500456440262e-05 \n",
      "epoch: 26 [867691/888800 97.62%] train loss: 1.3699494957108982e-05 \n",
      "epoch: 26 [868802/888800 97.75%] train loss: 1.4767845641472377e-05 \n",
      "epoch: 26 [869913/888800 97.88%] train loss: 1.3994492292113137e-05 \n",
      "epoch: 26 [871024/888800 98.00%] train loss: 1.5967729268595576e-05 \n",
      "epoch: 26 [872135/888800 98.12%] train loss: 1.4815865142736584e-05 \n",
      "epoch: 26 [873246/888800 98.25%] train loss: 1.4585636563424487e-05 \n",
      "epoch: 26 [874357/888800 98.38%] train loss: 1.516695829195669e-05 \n",
      "epoch: 26 [875468/888800 98.50%] train loss: 1.289110878133215e-05 \n",
      "epoch: 26 [876579/888800 98.62%] train loss: 1.427108782081632e-05 \n",
      "epoch: 26 [877690/888800 98.75%] train loss: 1.5019193597254343e-05 \n",
      "epoch: 26 [878801/888800 98.88%] train loss: 1.4348301192512736e-05 \n",
      "epoch: 26 [879912/888800 99.00%] train loss: 1.5021916624391451e-05 \n",
      "epoch: 26 [881023/888800 99.12%] train loss: 1.4244209523894824e-05 \n",
      "epoch: 26 [882134/888800 99.25%] train loss: 1.532680107629858e-05 \n",
      "epoch: 26 [883245/888800 99.38%] train loss: 1.4590874343411997e-05 \n",
      "epoch: 26 [884356/888800 99.50%] train loss: 1.4241275493986905e-05 \n",
      "epoch: 26 [885467/888800 99.62%] train loss: 1.5714475011918694e-05 \n",
      "epoch: 26 [886578/888800 99.75%] train loss: 1.3674458386958577e-05 \n",
      "epoch: 26 [887689/888800 99.88%] train loss: 1.614567736396566e-05 \n",
      "epoch: 27 [0/888800 0.00%] train loss: 1.4436184756050352e-05 \n",
      "epoch: 27 [1111/888800 0.12%] train loss: 1.6317511835950427e-05 \n",
      "epoch: 27 [2222/888800 0.25%] train loss: 1.7695585484034382e-05 \n",
      "epoch: 27 [3333/888800 0.38%] train loss: 1.3906581443734467e-05 \n",
      "epoch: 27 [4444/888800 0.50%] train loss: 1.464339584344998e-05 \n",
      "epoch: 27 [5555/888800 0.62%] train loss: 1.4075867511564866e-05 \n",
      "epoch: 27 [6666/888800 0.75%] train loss: 1.5386778613901697e-05 \n",
      "epoch: 27 [7777/888800 0.88%] train loss: 1.442059874534607e-05 \n",
      "epoch: 27 [8888/888800 1.00%] train loss: 1.3271028365124948e-05 \n",
      "epoch: 27 [9999/888800 1.12%] train loss: 1.5115108908503316e-05 \n",
      "epoch: 27 [11110/888800 1.25%] train loss: 1.437281389371492e-05 \n",
      "epoch: 27 [12221/888800 1.38%] train loss: 1.4624683899455704e-05 \n",
      "epoch: 27 [13332/888800 1.50%] train loss: 1.3360329830902629e-05 \n",
      "epoch: 27 [14443/888800 1.62%] train loss: 1.541254277981352e-05 \n",
      "epoch: 27 [15554/888800 1.75%] train loss: 1.4338917935674544e-05 \n",
      "epoch: 27 [16665/888800 1.88%] train loss: 1.4197768905432895e-05 \n",
      "epoch: 27 [17776/888800 2.00%] train loss: 1.5091862223926e-05 \n",
      "epoch: 27 [18887/888800 2.12%] train loss: 1.5053477909532376e-05 \n",
      "epoch: 27 [19998/888800 2.25%] train loss: 1.404420254402794e-05 \n",
      "epoch: 27 [21109/888800 2.38%] train loss: 1.4163249034027103e-05 \n",
      "epoch: 27 [22220/888800 2.50%] train loss: 1.5742121831863187e-05 \n",
      "epoch: 27 [23331/888800 2.62%] train loss: 1.3434954780677799e-05 \n",
      "epoch: 27 [24442/888800 2.75%] train loss: 1.5179371075646486e-05 \n",
      "epoch: 27 [25553/888800 2.88%] train loss: 1.3727310943068005e-05 \n",
      "epoch: 27 [26664/888800 3.00%] train loss: 1.3076152754365467e-05 \n",
      "epoch: 27 [27775/888800 3.12%] train loss: 1.2920793778903317e-05 \n",
      "epoch: 27 [28886/888800 3.25%] train loss: 1.3136442248651292e-05 \n",
      "epoch: 27 [29997/888800 3.38%] train loss: 1.326075926044723e-05 \n",
      "epoch: 27 [31108/888800 3.50%] train loss: 1.5289293514797464e-05 \n",
      "epoch: 27 [32219/888800 3.62%] train loss: 1.5432653526659124e-05 \n",
      "epoch: 27 [33330/888800 3.75%] train loss: 1.4963728972361423e-05 \n",
      "epoch: 27 [34441/888800 3.88%] train loss: 1.4930712495697662e-05 \n",
      "epoch: 27 [35552/888800 4.00%] train loss: 1.4329270925372839e-05 \n",
      "epoch: 27 [36663/888800 4.12%] train loss: 1.3551873962569516e-05 \n",
      "epoch: 27 [37774/888800 4.25%] train loss: 1.4305599506769795e-05 \n",
      "epoch: 27 [38885/888800 4.38%] train loss: 1.4593850210076198e-05 \n",
      "epoch: 27 [39996/888800 4.50%] train loss: 1.377012267766986e-05 \n",
      "epoch: 27 [41107/888800 4.62%] train loss: 1.4685853784612846e-05 \n",
      "epoch: 27 [42218/888800 4.75%] train loss: 1.368695120618213e-05 \n",
      "epoch: 27 [43329/888800 4.88%] train loss: 1.4549133084074128e-05 \n",
      "epoch: 27 [44440/888800 5.00%] train loss: 1.3304150343174115e-05 \n",
      "epoch: 27 [45551/888800 5.12%] train loss: 1.4076705156185199e-05 \n",
      "epoch: 27 [46662/888800 5.25%] train loss: 1.5085538507264573e-05 \n",
      "epoch: 27 [47773/888800 5.38%] train loss: 1.428925861546304e-05 \n",
      "epoch: 27 [48884/888800 5.50%] train loss: 1.41907439683564e-05 \n",
      "epoch: 27 [49995/888800 5.62%] train loss: 1.282681023440091e-05 \n",
      "epoch: 27 [51106/888800 5.75%] train loss: 1.4484894563793205e-05 \n",
      "epoch: 27 [52217/888800 5.88%] train loss: 1.3783987924398389e-05 \n",
      "epoch: 27 [53328/888800 6.00%] train loss: 1.3714430679101497e-05 \n",
      "epoch: 27 [54439/888800 6.12%] train loss: 1.4202979400579352e-05 \n",
      "epoch: 27 [55550/888800 6.25%] train loss: 1.3519288586394396e-05 \n",
      "epoch: 27 [56661/888800 6.38%] train loss: 1.370856898574857e-05 \n",
      "epoch: 27 [57772/888800 6.50%] train loss: 1.454721495974809e-05 \n",
      "epoch: 27 [58883/888800 6.62%] train loss: 1.436542697774712e-05 \n",
      "epoch: 27 [59994/888800 6.75%] train loss: 1.4521584489557426e-05 \n",
      "epoch: 27 [61105/888800 6.88%] train loss: 1.2560100003611296e-05 \n",
      "epoch: 27 [62216/888800 7.00%] train loss: 1.4535040463670157e-05 \n",
      "epoch: 27 [63327/888800 7.12%] train loss: 1.3279829545354005e-05 \n",
      "epoch: 27 [64438/888800 7.25%] train loss: 1.4323342838906683e-05 \n",
      "epoch: 27 [65549/888800 7.38%] train loss: 1.3674938600161113e-05 \n",
      "epoch: 27 [66660/888800 7.50%] train loss: 1.487718054704601e-05 \n",
      "epoch: 27 [67771/888800 7.62%] train loss: 1.3422456504486036e-05 \n",
      "epoch: 27 [68882/888800 7.75%] train loss: 1.3940122698841151e-05 \n",
      "epoch: 27 [69993/888800 7.88%] train loss: 1.4387547707883641e-05 \n",
      "epoch: 27 [71104/888800 8.00%] train loss: 1.5143637028813828e-05 \n",
      "epoch: 27 [72215/888800 8.12%] train loss: 1.5829231415409595e-05 \n",
      "epoch: 27 [73326/888800 8.25%] train loss: 1.2880369467893615e-05 \n",
      "epoch: 27 [74437/888800 8.38%] train loss: 1.582331424287986e-05 \n",
      "epoch: 27 [75548/888800 8.50%] train loss: 1.4834397916274611e-05 \n",
      "epoch: 27 [76659/888800 8.62%] train loss: 1.4948557691241149e-05 \n",
      "epoch: 27 [77770/888800 8.75%] train loss: 1.5009567505330779e-05 \n",
      "epoch: 27 [78881/888800 8.88%] train loss: 1.4782458492845763e-05 \n",
      "epoch: 27 [79992/888800 9.00%] train loss: 1.525163770565996e-05 \n",
      "epoch: 27 [81103/888800 9.12%] train loss: 1.5146554687817115e-05 \n",
      "epoch: 27 [82214/888800 9.25%] train loss: 1.55183115566615e-05 \n",
      "epoch: 27 [83325/888800 9.38%] train loss: 1.4040969290363137e-05 \n",
      "epoch: 27 [84436/888800 9.50%] train loss: 1.336648165306542e-05 \n",
      "epoch: 27 [85547/888800 9.62%] train loss: 1.3501267858373467e-05 \n",
      "epoch: 27 [86658/888800 9.75%] train loss: 1.5106228602235205e-05 \n",
      "epoch: 27 [87769/888800 9.88%] train loss: 1.4338304026750848e-05 \n",
      "epoch: 27 [88880/888800 10.00%] train loss: 1.5712355889263563e-05 \n",
      "epoch: 27 [89991/888800 10.12%] train loss: 1.551445893710479e-05 \n",
      "epoch: 27 [91102/888800 10.25%] train loss: 1.4348286640597507e-05 \n",
      "epoch: 27 [92213/888800 10.38%] train loss: 1.4068280506762676e-05 \n",
      "epoch: 27 [93324/888800 10.50%] train loss: 1.5791902114870027e-05 \n",
      "epoch: 27 [94435/888800 10.62%] train loss: 1.4553945220541209e-05 \n",
      "epoch: 27 [95546/888800 10.75%] train loss: 1.5209733646770474e-05 \n",
      "epoch: 27 [96657/888800 10.88%] train loss: 1.4148205082165077e-05 \n",
      "epoch: 27 [97768/888800 11.00%] train loss: 1.4674470548925456e-05 \n",
      "epoch: 27 [98879/888800 11.12%] train loss: 1.6500351193826646e-05 \n",
      "epoch: 27 [99990/888800 11.25%] train loss: 1.3717492038267665e-05 \n",
      "epoch: 27 [101101/888800 11.38%] train loss: 1.6722446162020788e-05 \n",
      "epoch: 27 [102212/888800 11.50%] train loss: 1.3803305591864046e-05 \n",
      "epoch: 27 [103323/888800 11.62%] train loss: 1.5357849406427704e-05 \n",
      "epoch: 27 [104434/888800 11.75%] train loss: 1.4943184396543074e-05 \n",
      "epoch: 27 [105545/888800 11.88%] train loss: 1.4736224329681136e-05 \n",
      "epoch: 27 [106656/888800 12.00%] train loss: 1.679009073995985e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [107767/888800 12.12%] train loss: 1.5529296433669515e-05 \n",
      "epoch: 27 [108878/888800 12.25%] train loss: 1.460574731027009e-05 \n",
      "epoch: 27 [109989/888800 12.38%] train loss: 1.3565868357545696e-05 \n",
      "epoch: 27 [111100/888800 12.50%] train loss: 1.575343412696384e-05 \n",
      "epoch: 27 [112211/888800 12.62%] train loss: 1.3284298802318517e-05 \n",
      "epoch: 27 [113322/888800 12.75%] train loss: 1.575773421791382e-05 \n",
      "epoch: 27 [114433/888800 12.88%] train loss: 1.5111347238416784e-05 \n",
      "epoch: 27 [115544/888800 13.00%] train loss: 1.4004454897076357e-05 \n",
      "epoch: 27 [116655/888800 13.12%] train loss: 1.4013970940141007e-05 \n",
      "epoch: 27 [117766/888800 13.25%] train loss: 1.351823902950855e-05 \n",
      "epoch: 27 [118877/888800 13.38%] train loss: 1.3183799637772609e-05 \n",
      "epoch: 27 [119988/888800 13.50%] train loss: 1.3497643521986902e-05 \n",
      "epoch: 27 [121099/888800 13.62%] train loss: 1.3966959159006365e-05 \n",
      "epoch: 27 [122210/888800 13.75%] train loss: 1.5249531315930653e-05 \n",
      "epoch: 27 [123321/888800 13.88%] train loss: 1.4041378562978934e-05 \n",
      "epoch: 27 [124432/888800 14.00%] train loss: 1.452139622415416e-05 \n",
      "epoch: 27 [125543/888800 14.12%] train loss: 1.4985880625317805e-05 \n",
      "epoch: 27 [126654/888800 14.25%] train loss: 1.3962810044176877e-05 \n",
      "epoch: 27 [127765/888800 14.38%] train loss: 1.3839530765835661e-05 \n",
      "epoch: 27 [128876/888800 14.50%] train loss: 1.3906925232731737e-05 \n",
      "epoch: 27 [129987/888800 14.62%] train loss: 1.3883029168937355e-05 \n",
      "epoch: 27 [131098/888800 14.75%] train loss: 1.5207277101580985e-05 \n",
      "epoch: 27 [132209/888800 14.88%] train loss: 1.314204837399302e-05 \n",
      "epoch: 27 [133320/888800 15.00%] train loss: 1.3495064195012674e-05 \n",
      "epoch: 27 [134431/888800 15.12%] train loss: 1.3824472262058407e-05 \n",
      "epoch: 27 [135542/888800 15.25%] train loss: 1.4094088328420185e-05 \n",
      "epoch: 27 [136653/888800 15.38%] train loss: 1.3515622413251549e-05 \n",
      "epoch: 27 [137764/888800 15.50%] train loss: 1.4838230526947882e-05 \n",
      "epoch: 27 [138875/888800 15.62%] train loss: 1.4813598681939766e-05 \n",
      "epoch: 27 [139986/888800 15.75%] train loss: 1.4626120901084505e-05 \n",
      "epoch: 27 [141097/888800 15.88%] train loss: 1.5843934306758456e-05 \n",
      "epoch: 27 [142208/888800 16.00%] train loss: 1.4247871149564162e-05 \n",
      "epoch: 27 [143319/888800 16.12%] train loss: 1.3995924746268429e-05 \n",
      "epoch: 27 [144430/888800 16.25%] train loss: 1.351356604573084e-05 \n",
      "epoch: 27 [145541/888800 16.38%] train loss: 1.3955128451925702e-05 \n",
      "epoch: 27 [146652/888800 16.50%] train loss: 1.4349132470670156e-05 \n",
      "epoch: 27 [147763/888800 16.62%] train loss: 1.4553542314388324e-05 \n",
      "epoch: 27 [148874/888800 16.75%] train loss: 1.2839948794862721e-05 \n",
      "epoch: 27 [149985/888800 16.88%] train loss: 1.473069642088376e-05 \n",
      "epoch: 27 [151096/888800 17.00%] train loss: 1.5656087271054275e-05 \n",
      "epoch: 27 [152207/888800 17.12%] train loss: 1.4476081560133025e-05 \n",
      "epoch: 27 [153318/888800 17.25%] train loss: 1.4523908248520456e-05 \n",
      "epoch: 27 [154429/888800 17.38%] train loss: 1.4340225789055694e-05 \n",
      "epoch: 27 [155540/888800 17.50%] train loss: 1.4197229575074743e-05 \n",
      "epoch: 27 [156651/888800 17.62%] train loss: 1.3896701602789108e-05 \n",
      "epoch: 27 [157762/888800 17.75%] train loss: 1.428788891644217e-05 \n",
      "epoch: 27 [158873/888800 17.88%] train loss: 1.2768635315296706e-05 \n",
      "epoch: 27 [159984/888800 18.00%] train loss: 1.4249364539864473e-05 \n",
      "epoch: 27 [161095/888800 18.12%] train loss: 1.344590236840304e-05 \n",
      "epoch: 27 [162206/888800 18.25%] train loss: 1.4506995285046287e-05 \n",
      "epoch: 27 [163317/888800 18.38%] train loss: 1.487617555540055e-05 \n",
      "epoch: 27 [164428/888800 18.50%] train loss: 1.4233087313186843e-05 \n",
      "epoch: 27 [165539/888800 18.62%] train loss: 1.3812099496135488e-05 \n",
      "epoch: 27 [166650/888800 18.75%] train loss: 1.221524416905595e-05 \n",
      "epoch: 27 [167761/888800 18.88%] train loss: 1.3735359971178696e-05 \n",
      "epoch: 27 [168872/888800 19.00%] train loss: 1.4944707800168544e-05 \n",
      "epoch: 27 [169983/888800 19.12%] train loss: 1.4399558494915254e-05 \n",
      "epoch: 27 [171094/888800 19.25%] train loss: 1.4111909877101425e-05 \n",
      "epoch: 27 [172205/888800 19.38%] train loss: 1.4303475836641155e-05 \n",
      "epoch: 27 [173316/888800 19.50%] train loss: 1.4321257367555518e-05 \n",
      "epoch: 27 [174427/888800 19.62%] train loss: 1.3482584108714946e-05 \n",
      "epoch: 27 [175538/888800 19.75%] train loss: 1.4027025827090256e-05 \n",
      "epoch: 27 [176649/888800 19.88%] train loss: 1.4841652046015952e-05 \n",
      "epoch: 27 [177760/888800 20.00%] train loss: 1.396545849274844e-05 \n",
      "epoch: 27 [178871/888800 20.12%] train loss: 1.3970246072858572e-05 \n",
      "epoch: 27 [179982/888800 20.25%] train loss: 1.2443357263691723e-05 \n",
      "epoch: 27 [181093/888800 20.38%] train loss: 1.3993195352668408e-05 \n",
      "epoch: 27 [182204/888800 20.50%] train loss: 1.3730540558754e-05 \n",
      "epoch: 27 [183315/888800 20.62%] train loss: 1.318402610195335e-05 \n",
      "epoch: 27 [184426/888800 20.75%] train loss: 1.4519245269184466e-05 \n",
      "epoch: 27 [185537/888800 20.88%] train loss: 1.315553981839912e-05 \n",
      "epoch: 27 [186648/888800 21.00%] train loss: 1.427598181180656e-05 \n",
      "epoch: 27 [187759/888800 21.12%] train loss: 1.4473253031610511e-05 \n",
      "epoch: 27 [188870/888800 21.25%] train loss: 1.3984637917019427e-05 \n",
      "epoch: 27 [189981/888800 21.38%] train loss: 1.3160802154743578e-05 \n",
      "epoch: 27 [191092/888800 21.50%] train loss: 1.3748271157965064e-05 \n",
      "epoch: 27 [192203/888800 21.62%] train loss: 1.3782230780634563e-05 \n",
      "epoch: 27 [193314/888800 21.75%] train loss: 1.398840959154768e-05 \n",
      "epoch: 27 [194425/888800 21.88%] train loss: 1.4287151316239033e-05 \n",
      "epoch: 27 [195536/888800 22.00%] train loss: 1.482412244513398e-05 \n",
      "epoch: 27 [196647/888800 22.12%] train loss: 1.3989997569296975e-05 \n",
      "epoch: 27 [197758/888800 22.25%] train loss: 1.4276419278758112e-05 \n",
      "epoch: 27 [198869/888800 22.38%] train loss: 1.391473415424116e-05 \n",
      "epoch: 27 [199980/888800 22.50%] train loss: 1.4033551451575477e-05 \n",
      "epoch: 27 [201091/888800 22.62%] train loss: 1.4267489859776106e-05 \n",
      "epoch: 27 [202202/888800 22.75%] train loss: 1.3679305993719026e-05 \n",
      "epoch: 27 [203313/888800 22.88%] train loss: 1.4525574442814104e-05 \n",
      "epoch: 27 [204424/888800 23.00%] train loss: 1.4518469470203854e-05 \n",
      "epoch: 27 [205535/888800 23.12%] train loss: 1.2608178622031119e-05 \n",
      "epoch: 27 [206646/888800 23.25%] train loss: 1.3813448276778217e-05 \n",
      "epoch: 27 [207757/888800 23.38%] train loss: 1.4854531400487758e-05 \n",
      "epoch: 27 [208868/888800 23.50%] train loss: 1.3653967471327633e-05 \n",
      "epoch: 27 [209979/888800 23.62%] train loss: 1.4264140190789476e-05 \n",
      "epoch: 27 [211090/888800 23.75%] train loss: 1.2808165593014564e-05 \n",
      "epoch: 27 [212201/888800 23.88%] train loss: 1.4675494639959652e-05 \n",
      "epoch: 27 [213312/888800 24.00%] train loss: 1.4714776625623927e-05 \n",
      "epoch: 27 [214423/888800 24.12%] train loss: 1.3858480997441802e-05 \n",
      "epoch: 27 [215534/888800 24.25%] train loss: 1.3189860510465223e-05 \n",
      "epoch: 27 [216645/888800 24.38%] train loss: 1.5911160517134704e-05 \n",
      "epoch: 27 [217756/888800 24.50%] train loss: 1.463303306081798e-05 \n",
      "epoch: 27 [218867/888800 24.62%] train loss: 1.281719232792966e-05 \n",
      "epoch: 27 [219978/888800 24.75%] train loss: 1.654330117162317e-05 \n",
      "epoch: 27 [221089/888800 24.88%] train loss: 1.4771741916774772e-05 \n",
      "epoch: 27 [222200/888800 25.00%] train loss: 1.4102440218266565e-05 \n",
      "epoch: 27 [223311/888800 25.12%] train loss: 1.6789615983725525e-05 \n",
      "epoch: 27 [224422/888800 25.25%] train loss: 1.371380676573608e-05 \n",
      "epoch: 27 [225533/888800 25.38%] train loss: 1.5850346244405955e-05 \n",
      "epoch: 27 [226644/888800 25.50%] train loss: 1.4904789168213028e-05 \n",
      "epoch: 27 [227755/888800 25.62%] train loss: 1.5156989320530556e-05 \n",
      "epoch: 27 [228866/888800 25.75%] train loss: 1.550247907289304e-05 \n",
      "epoch: 27 [229977/888800 25.88%] train loss: 1.3544441571866628e-05 \n",
      "epoch: 27 [231088/888800 26.00%] train loss: 1.4725511391588952e-05 \n",
      "epoch: 27 [232199/888800 26.12%] train loss: 1.363996125292033e-05 \n",
      "epoch: 27 [233310/888800 26.25%] train loss: 1.4278469279815909e-05 \n",
      "epoch: 27 [234421/888800 26.38%] train loss: 1.5074949260451831e-05 \n",
      "epoch: 27 [235532/888800 26.50%] train loss: 1.4183376151777338e-05 \n",
      "epoch: 27 [236643/888800 26.62%] train loss: 1.4062856280361302e-05 \n",
      "epoch: 27 [237754/888800 26.75%] train loss: 1.4626194570155349e-05 \n",
      "epoch: 27 [238865/888800 26.88%] train loss: 1.3773485989077017e-05 \n",
      "epoch: 27 [239976/888800 27.00%] train loss: 1.5120648640731815e-05 \n",
      "epoch: 27 [241087/888800 27.12%] train loss: 1.5515446648350917e-05 \n",
      "epoch: 27 [242198/888800 27.25%] train loss: 1.2620253073691856e-05 \n",
      "epoch: 27 [243309/888800 27.38%] train loss: 1.5080847333592828e-05 \n",
      "epoch: 27 [244420/888800 27.50%] train loss: 1.3453267456497997e-05 \n",
      "epoch: 27 [245531/888800 27.62%] train loss: 1.4348014701681677e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [246642/888800 27.75%] train loss: 1.4149325579637662e-05 \n",
      "epoch: 27 [247753/888800 27.88%] train loss: 1.2437529221642762e-05 \n",
      "epoch: 27 [248864/888800 28.00%] train loss: 1.4585387361876201e-05 \n",
      "epoch: 27 [249975/888800 28.12%] train loss: 1.382466325594578e-05 \n",
      "epoch: 27 [251086/888800 28.25%] train loss: 1.5955600247252733e-05 \n",
      "epoch: 27 [252197/888800 28.38%] train loss: 1.4305722288554534e-05 \n",
      "epoch: 27 [253308/888800 28.50%] train loss: 1.4317645764094777e-05 \n",
      "epoch: 27 [254419/888800 28.62%] train loss: 1.5292762327590026e-05 \n",
      "epoch: 27 [255530/888800 28.75%] train loss: 1.5145515135372989e-05 \n",
      "epoch: 27 [256641/888800 28.88%] train loss: 1.5751826140331104e-05 \n",
      "epoch: 27 [257752/888800 29.00%] train loss: 1.4267429833125789e-05 \n",
      "epoch: 27 [258863/888800 29.12%] train loss: 1.3552601558330934e-05 \n",
      "epoch: 27 [259974/888800 29.25%] train loss: 1.5244058886310086e-05 \n",
      "epoch: 27 [261085/888800 29.38%] train loss: 1.3796827261103317e-05 \n",
      "epoch: 27 [262196/888800 29.50%] train loss: 1.3765629773843102e-05 \n",
      "epoch: 27 [263307/888800 29.62%] train loss: 1.348323803540552e-05 \n",
      "epoch: 27 [264418/888800 29.75%] train loss: 1.4187759916239884e-05 \n",
      "epoch: 27 [265529/888800 29.88%] train loss: 1.4095669030211866e-05 \n",
      "epoch: 27 [266640/888800 30.00%] train loss: 1.5227213225443847e-05 \n",
      "epoch: 27 [267751/888800 30.12%] train loss: 1.509512458142126e-05 \n",
      "epoch: 27 [268862/888800 30.25%] train loss: 1.3459028195939027e-05 \n",
      "epoch: 27 [269973/888800 30.38%] train loss: 1.3710664461541455e-05 \n",
      "epoch: 27 [271084/888800 30.50%] train loss: 1.285940106754424e-05 \n",
      "epoch: 27 [272195/888800 30.62%] train loss: 1.4287937119661365e-05 \n",
      "epoch: 27 [273306/888800 30.75%] train loss: 1.4707085938425735e-05 \n",
      "epoch: 27 [274417/888800 30.88%] train loss: 1.3265843335830141e-05 \n",
      "epoch: 27 [275528/888800 31.00%] train loss: 1.4671105418528896e-05 \n",
      "epoch: 27 [276639/888800 31.12%] train loss: 1.4168471352604683e-05 \n",
      "epoch: 27 [277750/888800 31.25%] train loss: 1.4422208550968207e-05 \n",
      "epoch: 27 [278861/888800 31.38%] train loss: 1.3893213690607809e-05 \n",
      "epoch: 27 [279972/888800 31.50%] train loss: 1.3414608474704437e-05 \n",
      "epoch: 27 [281083/888800 31.62%] train loss: 1.4424594155570958e-05 \n",
      "epoch: 27 [282194/888800 31.75%] train loss: 1.4380992070073262e-05 \n",
      "epoch: 27 [283305/888800 31.88%] train loss: 1.4685757378174458e-05 \n",
      "epoch: 27 [284416/888800 32.00%] train loss: 1.3336223673832137e-05 \n",
      "epoch: 27 [285527/888800 32.12%] train loss: 1.3781886082142591e-05 \n",
      "epoch: 27 [286638/888800 32.25%] train loss: 1.3582410247181542e-05 \n",
      "epoch: 27 [287749/888800 32.38%] train loss: 1.4392418052011635e-05 \n",
      "epoch: 27 [288860/888800 32.50%] train loss: 1.4388891941052862e-05 \n",
      "epoch: 27 [289971/888800 32.62%] train loss: 1.3065476196061354e-05 \n",
      "epoch: 27 [291082/888800 32.75%] train loss: 1.4724257198395208e-05 \n",
      "epoch: 27 [292193/888800 32.88%] train loss: 1.4258876035455614e-05 \n",
      "epoch: 27 [293304/888800 33.00%] train loss: 1.3139333532308228e-05 \n",
      "epoch: 27 [294415/888800 33.12%] train loss: 1.3757192391494755e-05 \n",
      "epoch: 27 [295526/888800 33.25%] train loss: 1.5156836525420658e-05 \n",
      "epoch: 27 [296637/888800 33.38%] train loss: 1.4553948858520016e-05 \n",
      "epoch: 27 [297748/888800 33.50%] train loss: 1.5188330507953651e-05 \n",
      "epoch: 27 [298859/888800 33.62%] train loss: 1.2926744602737017e-05 \n",
      "epoch: 27 [299970/888800 33.75%] train loss: 1.5736635759822093e-05 \n",
      "epoch: 27 [301081/888800 33.88%] train loss: 1.5211140635074116e-05 \n",
      "epoch: 27 [302192/888800 34.00%] train loss: 1.4349602679430973e-05 \n",
      "epoch: 27 [303303/888800 34.12%] train loss: 1.3632602531288285e-05 \n",
      "epoch: 27 [304414/888800 34.25%] train loss: 1.4643803297076374e-05 \n",
      "epoch: 27 [305525/888800 34.38%] train loss: 1.4383045709109865e-05 \n",
      "epoch: 27 [306636/888800 34.50%] train loss: 1.4356833162310068e-05 \n",
      "epoch: 27 [307747/888800 34.62%] train loss: 1.3854518329026178e-05 \n",
      "epoch: 27 [308858/888800 34.75%] train loss: 1.5670415450586006e-05 \n",
      "epoch: 27 [309969/888800 34.88%] train loss: 1.4066924450162333e-05 \n",
      "epoch: 27 [311080/888800 35.00%] train loss: 1.4718219972564839e-05 \n",
      "epoch: 27 [312191/888800 35.12%] train loss: 1.4249225387175102e-05 \n",
      "epoch: 27 [313302/888800 35.25%] train loss: 1.3029371075390372e-05 \n",
      "epoch: 27 [314413/888800 35.38%] train loss: 1.4105415175436065e-05 \n",
      "epoch: 27 [315524/888800 35.50%] train loss: 1.2974847777513787e-05 \n",
      "epoch: 27 [316635/888800 35.62%] train loss: 1.3848137314198539e-05 \n",
      "epoch: 27 [317746/888800 35.75%] train loss: 1.4159721104078926e-05 \n",
      "epoch: 27 [318857/888800 35.88%] train loss: 1.3311767361301463e-05 \n",
      "epoch: 27 [319968/888800 36.00%] train loss: 1.268551750399638e-05 \n",
      "epoch: 27 [321079/888800 36.12%] train loss: 1.471647101425333e-05 \n",
      "epoch: 27 [322190/888800 36.25%] train loss: 1.4345670933835208e-05 \n",
      "epoch: 27 [323301/888800 36.38%] train loss: 1.4631230442319065e-05 \n",
      "epoch: 27 [324412/888800 36.50%] train loss: 1.3983657481730916e-05 \n",
      "epoch: 27 [325523/888800 36.62%] train loss: 1.4153520169202238e-05 \n",
      "epoch: 27 [326634/888800 36.75%] train loss: 1.46955262607662e-05 \n",
      "epoch: 27 [327745/888800 36.88%] train loss: 1.3161974493414164e-05 \n",
      "epoch: 27 [328856/888800 37.00%] train loss: 1.3967796803626698e-05 \n",
      "epoch: 27 [329967/888800 37.12%] train loss: 1.5180223272182047e-05 \n",
      "epoch: 27 [331078/888800 37.25%] train loss: 1.4582916264771484e-05 \n",
      "epoch: 27 [332189/888800 37.38%] train loss: 1.4207506865204778e-05 \n",
      "epoch: 27 [333300/888800 37.50%] train loss: 1.4281720723374747e-05 \n",
      "epoch: 27 [334411/888800 37.62%] train loss: 1.3593473340733908e-05 \n",
      "epoch: 27 [335522/888800 37.75%] train loss: 1.4067534721107222e-05 \n",
      "epoch: 27 [336633/888800 37.88%] train loss: 1.3263756045489572e-05 \n",
      "epoch: 27 [337744/888800 38.00%] train loss: 1.3365825907385442e-05 \n",
      "epoch: 27 [338855/888800 38.12%] train loss: 1.4468406334344763e-05 \n",
      "epoch: 27 [339966/888800 38.25%] train loss: 1.3229211617726833e-05 \n",
      "epoch: 27 [341077/888800 38.38%] train loss: 1.4816916518611833e-05 \n",
      "epoch: 27 [342188/888800 38.50%] train loss: 1.4067222764424514e-05 \n",
      "epoch: 27 [343299/888800 38.62%] train loss: 1.4321663002192508e-05 \n",
      "epoch: 27 [344410/888800 38.75%] train loss: 1.4827752238488756e-05 \n",
      "epoch: 27 [345521/888800 38.88%] train loss: 1.4747864952369127e-05 \n",
      "epoch: 27 [346632/888800 39.00%] train loss: 1.3996082088851836e-05 \n",
      "epoch: 27 [347743/888800 39.12%] train loss: 1.3356063391256612e-05 \n",
      "epoch: 27 [348854/888800 39.25%] train loss: 1.4283257769420743e-05 \n",
      "epoch: 27 [349965/888800 39.38%] train loss: 1.4378163541550748e-05 \n",
      "epoch: 27 [351076/888800 39.50%] train loss: 1.2767461157636717e-05 \n",
      "epoch: 27 [352187/888800 39.62%] train loss: 1.4618334716942627e-05 \n",
      "epoch: 27 [353298/888800 39.75%] train loss: 1.3549415598390624e-05 \n",
      "epoch: 27 [354409/888800 39.88%] train loss: 1.4788314729230478e-05 \n",
      "epoch: 27 [355520/888800 40.00%] train loss: 1.4939487300580367e-05 \n",
      "epoch: 27 [356631/888800 40.12%] train loss: 1.7680351447779685e-05 \n",
      "epoch: 27 [357742/888800 40.25%] train loss: 1.5161616829573177e-05 \n",
      "epoch: 27 [358853/888800 40.38%] train loss: 1.4422182175621856e-05 \n",
      "epoch: 27 [359964/888800 40.50%] train loss: 1.4711215044371784e-05 \n",
      "epoch: 27 [361075/888800 40.62%] train loss: 1.2650708413275424e-05 \n",
      "epoch: 27 [362186/888800 40.75%] train loss: 1.440766664018156e-05 \n",
      "epoch: 27 [363297/888800 40.88%] train loss: 1.415148926753318e-05 \n",
      "epoch: 27 [364408/888800 41.00%] train loss: 1.3559859326051082e-05 \n",
      "epoch: 27 [365519/888800 41.12%] train loss: 1.497123776061926e-05 \n",
      "epoch: 27 [366630/888800 41.25%] train loss: 1.3357761417864822e-05 \n",
      "epoch: 27 [367741/888800 41.38%] train loss: 1.4800129065406509e-05 \n",
      "epoch: 27 [368852/888800 41.50%] train loss: 1.6071697245934047e-05 \n",
      "epoch: 27 [369963/888800 41.62%] train loss: 1.4364191883942112e-05 \n",
      "epoch: 27 [371074/888800 41.75%] train loss: 1.4884845768392552e-05 \n",
      "epoch: 27 [372185/888800 41.88%] train loss: 1.383892958983779e-05 \n",
      "epoch: 27 [373296/888800 42.00%] train loss: 1.3952399967820384e-05 \n",
      "epoch: 27 [374407/888800 42.12%] train loss: 1.3895431948185433e-05 \n",
      "epoch: 27 [375518/888800 42.25%] train loss: 1.449857882107608e-05 \n",
      "epoch: 27 [376629/888800 42.38%] train loss: 1.3551095435104799e-05 \n",
      "epoch: 27 [377740/888800 42.50%] train loss: 1.3714929082198068e-05 \n",
      "epoch: 27 [378851/888800 42.62%] train loss: 1.4553442269971129e-05 \n",
      "epoch: 27 [379962/888800 42.75%] train loss: 1.5212907783279661e-05 \n",
      "epoch: 27 [381073/888800 42.88%] train loss: 1.4240420568967238e-05 \n",
      "epoch: 27 [382184/888800 43.00%] train loss: 1.4382693734660279e-05 \n",
      "epoch: 27 [383295/888800 43.12%] train loss: 1.330948816757882e-05 \n",
      "epoch: 27 [384406/888800 43.25%] train loss: 1.4695116988150403e-05 \n",
      "epoch: 27 [385517/888800 43.38%] train loss: 1.5512983736698516e-05 \n",
      "epoch: 27 [386628/888800 43.50%] train loss: 1.563334444654174e-05 \n",
      "epoch: 27 [387739/888800 43.62%] train loss: 1.3903489161748439e-05 \n",
      "epoch: 27 [388850/888800 43.75%] train loss: 1.4625240510213189e-05 \n",
      "epoch: 27 [389961/888800 43.88%] train loss: 1.4896220818627626e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [391072/888800 44.00%] train loss: 1.540398625365924e-05 \n",
      "epoch: 27 [392183/888800 44.12%] train loss: 1.556799907120876e-05 \n",
      "epoch: 27 [393294/888800 44.25%] train loss: 1.5428709957632236e-05 \n",
      "epoch: 27 [394405/888800 44.38%] train loss: 1.4124811968940776e-05 \n",
      "epoch: 27 [395516/888800 44.50%] train loss: 1.630972110433504e-05 \n",
      "epoch: 27 [396627/888800 44.62%] train loss: 1.4141483916318975e-05 \n",
      "epoch: 27 [397738/888800 44.75%] train loss: 1.5219913620967418e-05 \n",
      "epoch: 27 [398849/888800 44.88%] train loss: 1.4451318747887854e-05 \n",
      "epoch: 27 [399960/888800 45.00%] train loss: 1.5572644770145416e-05 \n",
      "epoch: 27 [401071/888800 45.12%] train loss: 1.459738086850848e-05 \n",
      "epoch: 27 [402182/888800 45.25%] train loss: 1.4241426470107399e-05 \n",
      "epoch: 27 [403293/888800 45.38%] train loss: 1.5554318451904692e-05 \n",
      "epoch: 27 [404404/888800 45.50%] train loss: 1.4401221960724797e-05 \n",
      "epoch: 27 [405515/888800 45.62%] train loss: 1.5771649486850947e-05 \n",
      "epoch: 27 [406626/888800 45.75%] train loss: 1.5083612197486218e-05 \n",
      "epoch: 27 [407737/888800 45.88%] train loss: 1.3542171473091003e-05 \n",
      "epoch: 27 [408848/888800 46.00%] train loss: 1.4920455214451067e-05 \n",
      "epoch: 27 [409959/888800 46.12%] train loss: 1.489996793679893e-05 \n",
      "epoch: 27 [411070/888800 46.25%] train loss: 1.2669466741499491e-05 \n",
      "epoch: 27 [412181/888800 46.38%] train loss: 1.5890533177298494e-05 \n",
      "epoch: 27 [413292/888800 46.50%] train loss: 1.436596085113706e-05 \n",
      "epoch: 27 [414403/888800 46.62%] train loss: 1.5331681424868293e-05 \n",
      "epoch: 27 [415514/888800 46.75%] train loss: 1.379058539896505e-05 \n",
      "epoch: 27 [416625/888800 46.88%] train loss: 1.560588862048462e-05 \n",
      "epoch: 27 [417736/888800 47.00%] train loss: 1.5024661479401402e-05 \n",
      "epoch: 27 [418847/888800 47.12%] train loss: 1.3308843335835263e-05 \n",
      "epoch: 27 [419958/888800 47.25%] train loss: 1.3174916603020392e-05 \n",
      "epoch: 27 [421069/888800 47.38%] train loss: 1.4465691492659971e-05 \n",
      "epoch: 27 [422180/888800 47.50%] train loss: 1.4675343663839158e-05 \n",
      "epoch: 27 [423291/888800 47.62%] train loss: 1.4678587831440382e-05 \n",
      "epoch: 27 [424402/888800 47.75%] train loss: 1.4068104974285234e-05 \n",
      "epoch: 27 [425513/888800 47.88%] train loss: 1.4022870345797855e-05 \n",
      "epoch: 27 [426624/888800 48.00%] train loss: 1.399346274411073e-05 \n",
      "epoch: 27 [427735/888800 48.12%] train loss: 1.245733983523678e-05 \n",
      "epoch: 27 [428846/888800 48.25%] train loss: 1.5051790796860587e-05 \n",
      "epoch: 27 [429957/888800 48.38%] train loss: 1.457336747989757e-05 \n",
      "epoch: 27 [431068/888800 48.50%] train loss: 1.3335617040866055e-05 \n",
      "epoch: 27 [432179/888800 48.62%] train loss: 1.5945526683935896e-05 \n",
      "epoch: 27 [433290/888800 48.75%] train loss: 1.494724529038649e-05 \n",
      "epoch: 27 [434401/888800 48.88%] train loss: 1.3893361028749496e-05 \n",
      "epoch: 27 [435512/888800 49.00%] train loss: 1.530840563646052e-05 \n",
      "epoch: 27 [436623/888800 49.12%] train loss: 1.3373584806686267e-05 \n",
      "epoch: 27 [437734/888800 49.25%] train loss: 1.4655021004728042e-05 \n",
      "epoch: 27 [438845/888800 49.38%] train loss: 1.4449009540840052e-05 \n",
      "epoch: 27 [439956/888800 49.50%] train loss: 1.5338238881668076e-05 \n",
      "epoch: 27 [441067/888800 49.62%] train loss: 1.3762891285296064e-05 \n",
      "epoch: 27 [442178/888800 49.75%] train loss: 1.5213930055324454e-05 \n",
      "epoch: 27 [443289/888800 49.88%] train loss: 1.4791666217206512e-05 \n",
      "epoch: 27 [444400/888800 50.00%] train loss: 1.4119611478236038e-05 \n",
      "epoch: 27 [445511/888800 50.12%] train loss: 1.4568367078027222e-05 \n",
      "epoch: 27 [446622/888800 50.25%] train loss: 1.3500718523573596e-05 \n",
      "epoch: 27 [447733/888800 50.38%] train loss: 1.4456423741648905e-05 \n",
      "epoch: 27 [448844/888800 50.50%] train loss: 1.5007834917923901e-05 \n",
      "epoch: 27 [449955/888800 50.62%] train loss: 1.3272006071929354e-05 \n",
      "epoch: 27 [451066/888800 50.75%] train loss: 1.4600613212678581e-05 \n",
      "epoch: 27 [452177/888800 50.88%] train loss: 1.3316160220711026e-05 \n",
      "epoch: 27 [453288/888800 51.00%] train loss: 1.4082414054428227e-05 \n",
      "epoch: 27 [454399/888800 51.12%] train loss: 1.4560378076566849e-05 \n",
      "epoch: 27 [455510/888800 51.25%] train loss: 1.4362361071107443e-05 \n",
      "epoch: 27 [456621/888800 51.38%] train loss: 1.5093902220542077e-05 \n",
      "epoch: 27 [457732/888800 51.50%] train loss: 1.4260140233091079e-05 \n",
      "epoch: 27 [458843/888800 51.62%] train loss: 1.392238300468307e-05 \n",
      "epoch: 27 [459954/888800 51.75%] train loss: 1.4201658814272378e-05 \n",
      "epoch: 27 [461065/888800 51.88%] train loss: 1.4103833564149681e-05 \n",
      "epoch: 27 [462176/888800 52.00%] train loss: 1.3474346815200988e-05 \n",
      "epoch: 27 [463287/888800 52.12%] train loss: 1.4638649190601427e-05 \n",
      "epoch: 27 [464398/888800 52.25%] train loss: 1.3250487427285407e-05 \n",
      "epoch: 27 [465509/888800 52.38%] train loss: 1.3385658348852303e-05 \n",
      "epoch: 27 [466620/888800 52.50%] train loss: 1.569615960761439e-05 \n",
      "epoch: 27 [467731/888800 52.62%] train loss: 1.4098445717536379e-05 \n",
      "epoch: 27 [468842/888800 52.75%] train loss: 1.4189708053891081e-05 \n",
      "epoch: 27 [469953/888800 52.88%] train loss: 1.3675115951627959e-05 \n",
      "epoch: 27 [471064/888800 53.00%] train loss: 1.3079575182928238e-05 \n",
      "epoch: 27 [472175/888800 53.12%] train loss: 1.408884327247506e-05 \n",
      "epoch: 27 [473286/888800 53.25%] train loss: 1.3657228009833489e-05 \n",
      "epoch: 27 [474397/888800 53.38%] train loss: 1.3671353372046724e-05 \n",
      "epoch: 27 [475508/888800 53.50%] train loss: 1.3998462236486375e-05 \n",
      "epoch: 27 [476619/888800 53.62%] train loss: 1.3074245543975849e-05 \n",
      "epoch: 27 [477730/888800 53.75%] train loss: 1.3086656508676242e-05 \n",
      "epoch: 27 [478841/888800 53.88%] train loss: 1.3585268789029215e-05 \n",
      "epoch: 27 [479952/888800 54.00%] train loss: 1.4227873180061579e-05 \n",
      "epoch: 27 [481063/888800 54.12%] train loss: 1.4719217688252684e-05 \n",
      "epoch: 27 [482174/888800 54.25%] train loss: 1.316969792242162e-05 \n",
      "epoch: 27 [483285/888800 54.38%] train loss: 1.4654606275144033e-05 \n",
      "epoch: 27 [484396/888800 54.50%] train loss: 1.3667275197803974e-05 \n",
      "epoch: 27 [485507/888800 54.62%] train loss: 1.3709111044590827e-05 \n",
      "epoch: 27 [486618/888800 54.75%] train loss: 1.3757485248788726e-05 \n",
      "epoch: 27 [487729/888800 54.88%] train loss: 1.357913151878165e-05 \n",
      "epoch: 27 [488840/888800 55.00%] train loss: 1.362593593512429e-05 \n",
      "epoch: 27 [489951/888800 55.12%] train loss: 1.443910787202185e-05 \n",
      "epoch: 27 [491062/888800 55.25%] train loss: 1.4436442143050954e-05 \n",
      "epoch: 27 [492173/888800 55.38%] train loss: 1.4576000467059202e-05 \n",
      "epoch: 27 [493284/888800 55.50%] train loss: 1.4356898645928595e-05 \n",
      "epoch: 27 [494395/888800 55.62%] train loss: 1.434200930816587e-05 \n",
      "epoch: 27 [495506/888800 55.75%] train loss: 1.3822990695189219e-05 \n",
      "epoch: 27 [496617/888800 55.88%] train loss: 1.4103483408689499e-05 \n",
      "epoch: 27 [497728/888800 56.00%] train loss: 1.3346552805160172e-05 \n",
      "epoch: 27 [498839/888800 56.12%] train loss: 1.598416747583542e-05 \n",
      "epoch: 27 [499950/888800 56.25%] train loss: 1.3861928891856223e-05 \n",
      "epoch: 27 [501061/888800 56.38%] train loss: 1.3788172509521246e-05 \n",
      "epoch: 27 [502172/888800 56.50%] train loss: 1.4841860320302658e-05 \n",
      "epoch: 27 [503283/888800 56.62%] train loss: 1.434809837519424e-05 \n",
      "epoch: 27 [504394/888800 56.75%] train loss: 1.4404125067812856e-05 \n",
      "epoch: 27 [505505/888800 56.88%] train loss: 1.4471680515271146e-05 \n",
      "epoch: 27 [506616/888800 57.00%] train loss: 1.3926248357165605e-05 \n",
      "epoch: 27 [507727/888800 57.12%] train loss: 1.3908605069445912e-05 \n",
      "epoch: 27 [508838/888800 57.25%] train loss: 1.4870867744321004e-05 \n",
      "epoch: 27 [509949/888800 57.38%] train loss: 1.2822869393858127e-05 \n",
      "epoch: 27 [511060/888800 57.50%] train loss: 1.3686110833077691e-05 \n",
      "epoch: 27 [512171/888800 57.62%] train loss: 1.3527754163078498e-05 \n",
      "epoch: 27 [513282/888800 57.75%] train loss: 1.570701351738535e-05 \n",
      "epoch: 27 [514393/888800 57.88%] train loss: 1.36110647872556e-05 \n",
      "epoch: 27 [515504/888800 58.00%] train loss: 1.461601732444251e-05 \n",
      "epoch: 27 [516615/888800 58.12%] train loss: 1.4102864952292293e-05 \n",
      "epoch: 27 [517726/888800 58.25%] train loss: 1.4115175872575492e-05 \n",
      "epoch: 27 [518837/888800 58.38%] train loss: 1.471818450227147e-05 \n",
      "epoch: 27 [519948/888800 58.50%] train loss: 1.436369348084554e-05 \n",
      "epoch: 27 [521059/888800 58.62%] train loss: 1.4817183000559453e-05 \n",
      "epoch: 27 [522170/888800 58.75%] train loss: 1.4239208212529775e-05 \n",
      "epoch: 27 [523281/888800 58.88%] train loss: 1.475188309996156e-05 \n",
      "epoch: 27 [524392/888800 59.00%] train loss: 1.4509259926853701e-05 \n",
      "epoch: 27 [525503/888800 59.12%] train loss: 1.3241519809525926e-05 \n",
      "epoch: 27 [526614/888800 59.25%] train loss: 1.4504455066344235e-05 \n",
      "epoch: 27 [527725/888800 59.38%] train loss: 1.5066308151290286e-05 \n",
      "epoch: 27 [528836/888800 59.50%] train loss: 1.4284507415140979e-05 \n",
      "epoch: 27 [529947/888800 59.62%] train loss: 1.567028994031716e-05 \n",
      "epoch: 27 [531058/888800 59.75%] train loss: 1.5026878827484325e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [532169/888800 59.88%] train loss: 1.3563410902861506e-05 \n",
      "epoch: 27 [533280/888800 60.00%] train loss: 1.539338154543657e-05 \n",
      "epoch: 27 [534391/888800 60.12%] train loss: 1.5153535969147924e-05 \n",
      "epoch: 27 [535502/888800 60.25%] train loss: 1.2996681107324548e-05 \n",
      "epoch: 27 [536613/888800 60.38%] train loss: 1.491540842835093e-05 \n",
      "epoch: 27 [537724/888800 60.50%] train loss: 1.3915799172536936e-05 \n",
      "epoch: 27 [538835/888800 60.62%] train loss: 1.3638034033647273e-05 \n",
      "epoch: 27 [539946/888800 60.75%] train loss: 1.4449633454205468e-05 \n",
      "epoch: 27 [541057/888800 60.88%] train loss: 1.564579906698782e-05 \n",
      "epoch: 27 [542168/888800 61.00%] train loss: 1.4138301594357472e-05 \n",
      "epoch: 27 [543279/888800 61.12%] train loss: 1.662085014686454e-05 \n",
      "epoch: 27 [544390/888800 61.25%] train loss: 1.5638303011655807e-05 \n",
      "epoch: 27 [545501/888800 61.38%] train loss: 1.2502905519795604e-05 \n",
      "epoch: 27 [546612/888800 61.50%] train loss: 1.5666491890442558e-05 \n",
      "epoch: 27 [547723/888800 61.62%] train loss: 1.4009103324497119e-05 \n",
      "epoch: 27 [548834/888800 61.75%] train loss: 1.5720048395451158e-05 \n",
      "epoch: 27 [549945/888800 61.88%] train loss: 1.4272177395469043e-05 \n",
      "epoch: 27 [551056/888800 62.00%] train loss: 1.4173224371916149e-05 \n",
      "epoch: 27 [552167/888800 62.12%] train loss: 1.4751029993931297e-05 \n",
      "epoch: 27 [553278/888800 62.25%] train loss: 1.585835161677096e-05 \n",
      "epoch: 27 [554389/888800 62.38%] train loss: 1.3952627341495827e-05 \n",
      "epoch: 27 [555500/888800 62.50%] train loss: 1.5342557162512094e-05 \n",
      "epoch: 27 [556611/888800 62.62%] train loss: 1.4433102478506044e-05 \n",
      "epoch: 27 [557722/888800 62.75%] train loss: 1.371866983390646e-05 \n",
      "epoch: 27 [558833/888800 62.88%] train loss: 1.4315818589238916e-05 \n",
      "epoch: 27 [559944/888800 63.00%] train loss: 1.4098038263909984e-05 \n",
      "epoch: 27 [561055/888800 63.12%] train loss: 1.4134071534499526e-05 \n",
      "epoch: 27 [562166/888800 63.25%] train loss: 1.3581391613115557e-05 \n",
      "epoch: 27 [563277/888800 63.38%] train loss: 1.4693826415168587e-05 \n",
      "epoch: 27 [564388/888800 63.50%] train loss: 1.3952380868431646e-05 \n",
      "epoch: 27 [565499/888800 63.62%] train loss: 1.3927368854638189e-05 \n",
      "epoch: 27 [566610/888800 63.75%] train loss: 1.4335157175082713e-05 \n",
      "epoch: 27 [567721/888800 63.88%] train loss: 1.4595408174500335e-05 \n",
      "epoch: 27 [568832/888800 64.00%] train loss: 1.4450112757913303e-05 \n",
      "epoch: 27 [569943/888800 64.12%] train loss: 1.444650479243137e-05 \n",
      "epoch: 27 [571054/888800 64.25%] train loss: 1.4871882740408182e-05 \n",
      "epoch: 27 [572165/888800 64.38%] train loss: 1.2521406461019069e-05 \n",
      "epoch: 27 [573276/888800 64.50%] train loss: 1.4614272004109807e-05 \n",
      "epoch: 27 [574387/888800 64.62%] train loss: 1.4170427675708197e-05 \n",
      "epoch: 27 [575498/888800 64.75%] train loss: 1.4100884982326534e-05 \n",
      "epoch: 27 [576609/888800 64.88%] train loss: 1.4446536624745931e-05 \n",
      "epoch: 27 [577720/888800 65.00%] train loss: 1.3910693269281182e-05 \n",
      "epoch: 27 [578831/888800 65.12%] train loss: 1.4376888429978862e-05 \n",
      "epoch: 27 [579942/888800 65.25%] train loss: 1.5020990758785047e-05 \n",
      "epoch: 27 [581053/888800 65.38%] train loss: 1.4174484931572806e-05 \n",
      "epoch: 27 [582164/888800 65.50%] train loss: 1.4089259821048472e-05 \n",
      "epoch: 27 [583275/888800 65.62%] train loss: 1.4145372006169055e-05 \n",
      "epoch: 27 [584386/888800 65.75%] train loss: 1.2800494914699811e-05 \n",
      "epoch: 27 [585497/888800 65.88%] train loss: 1.4557308531948365e-05 \n",
      "epoch: 27 [586608/888800 66.00%] train loss: 1.4967005881771911e-05 \n",
      "epoch: 27 [587719/888800 66.12%] train loss: 1.4649486729467753e-05 \n",
      "epoch: 27 [588830/888800 66.25%] train loss: 1.596849506313447e-05 \n",
      "epoch: 27 [589941/888800 66.38%] train loss: 1.3493729056790471e-05 \n",
      "epoch: 27 [591052/888800 66.50%] train loss: 1.3478322216542438e-05 \n",
      "epoch: 27 [592163/888800 66.62%] train loss: 1.5092991816345602e-05 \n",
      "epoch: 27 [593274/888800 66.75%] train loss: 1.4622670278185979e-05 \n",
      "epoch: 27 [594385/888800 66.88%] train loss: 1.385819268762134e-05 \n",
      "epoch: 27 [595496/888800 67.00%] train loss: 1.4674899830424692e-05 \n",
      "epoch: 27 [596607/888800 67.12%] train loss: 1.4155490134726278e-05 \n",
      "epoch: 27 [597718/888800 67.25%] train loss: 1.5130699466681108e-05 \n",
      "epoch: 27 [598829/888800 67.38%] train loss: 1.5457566405530088e-05 \n",
      "epoch: 27 [599940/888800 67.50%] train loss: 1.391035857523093e-05 \n",
      "epoch: 27 [601051/888800 67.62%] train loss: 1.602812517376151e-05 \n",
      "epoch: 27 [602162/888800 67.75%] train loss: 1.5613375580869615e-05 \n",
      "epoch: 27 [603273/888800 67.88%] train loss: 1.4862944226479158e-05 \n",
      "epoch: 27 [604384/888800 68.00%] train loss: 1.3608103472506627e-05 \n",
      "epoch: 27 [605495/888800 68.12%] train loss: 1.3959956049802713e-05 \n",
      "epoch: 27 [606606/888800 68.25%] train loss: 1.5963634723448195e-05 \n",
      "epoch: 27 [607717/888800 68.38%] train loss: 1.7208052668138407e-05 \n",
      "epoch: 27 [608828/888800 68.50%] train loss: 1.3844360182702076e-05 \n",
      "epoch: 27 [609939/888800 68.62%] train loss: 1.5417675967910327e-05 \n",
      "epoch: 27 [611050/888800 68.75%] train loss: 1.452010383218294e-05 \n",
      "epoch: 27 [612161/888800 68.88%] train loss: 1.4663340152765159e-05 \n",
      "epoch: 27 [613272/888800 69.00%] train loss: 1.3606413631350733e-05 \n",
      "epoch: 27 [614383/888800 69.12%] train loss: 1.3643171769217588e-05 \n",
      "epoch: 27 [615494/888800 69.25%] train loss: 1.5303037798730657e-05 \n",
      "epoch: 27 [616605/888800 69.38%] train loss: 1.5214265658869408e-05 \n",
      "epoch: 27 [617716/888800 69.50%] train loss: 1.428850373486057e-05 \n",
      "epoch: 27 [618827/888800 69.62%] train loss: 1.4655468476121314e-05 \n",
      "epoch: 27 [619938/888800 69.75%] train loss: 1.3283662156027276e-05 \n",
      "epoch: 27 [621049/888800 69.88%] train loss: 1.4135840501694474e-05 \n",
      "epoch: 27 [622160/888800 70.00%] train loss: 1.3881263839721214e-05 \n",
      "epoch: 27 [623271/888800 70.12%] train loss: 1.554537084302865e-05 \n",
      "epoch: 27 [624382/888800 70.25%] train loss: 1.488178713771049e-05 \n",
      "epoch: 27 [625493/888800 70.38%] train loss: 1.381280344503466e-05 \n",
      "epoch: 27 [626604/888800 70.50%] train loss: 1.340843846264761e-05 \n",
      "epoch: 27 [627715/888800 70.62%] train loss: 1.3814636076858733e-05 \n",
      "epoch: 27 [628826/888800 70.75%] train loss: 1.4246412320062518e-05 \n",
      "epoch: 27 [629937/888800 70.88%] train loss: 1.2970592251804192e-05 \n",
      "epoch: 27 [631048/888800 71.00%] train loss: 1.3534335266740527e-05 \n",
      "epoch: 27 [632159/888800 71.12%] train loss: 1.4494758033833932e-05 \n",
      "epoch: 27 [633270/888800 71.25%] train loss: 1.4655463019153103e-05 \n",
      "epoch: 27 [634381/888800 71.38%] train loss: 1.4135391211311799e-05 \n",
      "epoch: 27 [635492/888800 71.50%] train loss: 1.3161971764930058e-05 \n",
      "epoch: 27 [636603/888800 71.62%] train loss: 1.2341295587248169e-05 \n",
      "epoch: 27 [637714/888800 71.75%] train loss: 1.3996401321492158e-05 \n",
      "epoch: 27 [638825/888800 71.88%] train loss: 1.5152258129091933e-05 \n",
      "epoch: 27 [639936/888800 72.00%] train loss: 1.3493989172275178e-05 \n",
      "epoch: 27 [641047/888800 72.12%] train loss: 1.3746415788773447e-05 \n",
      "epoch: 27 [642158/888800 72.25%] train loss: 1.3744150237471331e-05 \n",
      "epoch: 27 [643269/888800 72.38%] train loss: 1.5163012903940398e-05 \n",
      "epoch: 27 [644380/888800 72.50%] train loss: 1.5111100765352603e-05 \n",
      "epoch: 27 [645491/888800 72.62%] train loss: 1.6064628653111868e-05 \n",
      "epoch: 27 [646602/888800 72.75%] train loss: 1.5290839655790478e-05 \n",
      "epoch: 27 [647713/888800 72.88%] train loss: 1.5473144230782054e-05 \n",
      "epoch: 27 [648824/888800 73.00%] train loss: 1.3317553566594142e-05 \n",
      "epoch: 27 [649935/888800 73.12%] train loss: 1.3998732356412802e-05 \n",
      "epoch: 27 [651046/888800 73.25%] train loss: 1.5397756214952096e-05 \n",
      "epoch: 27 [652157/888800 73.38%] train loss: 1.3916248462919611e-05 \n",
      "epoch: 27 [653268/888800 73.50%] train loss: 1.5088777217897587e-05 \n",
      "epoch: 27 [654379/888800 73.62%] train loss: 1.443929249944631e-05 \n",
      "epoch: 27 [655490/888800 73.75%] train loss: 1.539138247608207e-05 \n",
      "epoch: 27 [656601/888800 73.88%] train loss: 1.35034397317213e-05 \n",
      "epoch: 27 [657712/888800 74.00%] train loss: 1.461712599848397e-05 \n",
      "epoch: 27 [658823/888800 74.12%] train loss: 1.4967587958381046e-05 \n",
      "epoch: 27 [659934/888800 74.25%] train loss: 1.3867757843399886e-05 \n",
      "epoch: 27 [661045/888800 74.38%] train loss: 1.4439248843700625e-05 \n",
      "epoch: 27 [662156/888800 74.50%] train loss: 1.4859591829008423e-05 \n",
      "epoch: 27 [663267/888800 74.62%] train loss: 1.4618571185565088e-05 \n",
      "epoch: 27 [664378/888800 74.75%] train loss: 1.3928223779657856e-05 \n",
      "epoch: 27 [665489/888800 74.88%] train loss: 1.3984979887027293e-05 \n",
      "epoch: 27 [666600/888800 75.00%] train loss: 1.4775849194847979e-05 \n",
      "epoch: 27 [667711/888800 75.12%] train loss: 1.4527056919177994e-05 \n",
      "epoch: 27 [668822/888800 75.25%] train loss: 1.3953606867289636e-05 \n",
      "epoch: 27 [669933/888800 75.38%] train loss: 1.3510731150745414e-05 \n",
      "epoch: 27 [671044/888800 75.50%] train loss: 1.4374822967511136e-05 \n",
      "epoch: 27 [672155/888800 75.62%] train loss: 1.4316695342131425e-05 \n",
      "epoch: 27 [673266/888800 75.75%] train loss: 1.3618343473353889e-05 \n",
      "epoch: 27 [674377/888800 75.88%] train loss: 1.3746316653850954e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [675488/888800 76.00%] train loss: 1.4106184607953764e-05 \n",
      "epoch: 27 [676599/888800 76.12%] train loss: 1.4888862096995581e-05 \n",
      "epoch: 27 [677710/888800 76.25%] train loss: 1.4277337868406903e-05 \n",
      "epoch: 27 [678821/888800 76.38%] train loss: 1.4894994819769636e-05 \n",
      "epoch: 27 [679932/888800 76.50%] train loss: 1.4668825315311551e-05 \n",
      "epoch: 27 [681043/888800 76.62%] train loss: 1.3680311894859187e-05 \n",
      "epoch: 27 [682154/888800 76.75%] train loss: 1.5510904631810263e-05 \n",
      "epoch: 27 [683265/888800 76.88%] train loss: 1.5326690117944963e-05 \n",
      "epoch: 27 [684376/888800 77.00%] train loss: 1.477174555475358e-05 \n",
      "epoch: 27 [685487/888800 77.12%] train loss: 1.3854663848178461e-05 \n",
      "epoch: 27 [686598/888800 77.25%] train loss: 1.6180167222046293e-05 \n",
      "epoch: 27 [687709/888800 77.38%] train loss: 1.3382490578806028e-05 \n",
      "epoch: 27 [688820/888800 77.50%] train loss: 1.6636631698929705e-05 \n",
      "epoch: 27 [689931/888800 77.62%] train loss: 1.39888816192979e-05 \n",
      "epoch: 27 [691042/888800 77.75%] train loss: 1.5345880456152372e-05 \n",
      "epoch: 27 [692153/888800 77.88%] train loss: 1.5448209524038248e-05 \n",
      "epoch: 27 [693264/888800 78.00%] train loss: 1.3712362488149665e-05 \n",
      "epoch: 27 [694375/888800 78.12%] train loss: 1.5512337995460257e-05 \n",
      "epoch: 27 [695486/888800 78.25%] train loss: 1.3928721273259725e-05 \n",
      "epoch: 27 [696597/888800 78.38%] train loss: 1.5888195775914937e-05 \n",
      "epoch: 27 [697708/888800 78.50%] train loss: 1.46886004586122e-05 \n",
      "epoch: 27 [698819/888800 78.62%] train loss: 1.555795461172238e-05 \n",
      "epoch: 27 [699930/888800 78.75%] train loss: 1.4506059414998163e-05 \n",
      "epoch: 27 [701041/888800 78.88%] train loss: 1.6156483980012126e-05 \n",
      "epoch: 27 [702152/888800 79.00%] train loss: 1.5395715308841318e-05 \n",
      "epoch: 27 [703263/888800 79.12%] train loss: 1.460837938793702e-05 \n",
      "epoch: 27 [704374/888800 79.25%] train loss: 1.4365434253704734e-05 \n",
      "epoch: 27 [705485/888800 79.38%] train loss: 1.4395355719898362e-05 \n",
      "epoch: 27 [706596/888800 79.50%] train loss: 1.3216937986726407e-05 \n",
      "epoch: 27 [707707/888800 79.62%] train loss: 1.3263809705676977e-05 \n",
      "epoch: 27 [708818/888800 79.75%] train loss: 1.4705203284393065e-05 \n",
      "epoch: 27 [709929/888800 79.88%] train loss: 1.5493591490667313e-05 \n",
      "epoch: 27 [711040/888800 80.00%] train loss: 1.5529918528045528e-05 \n",
      "epoch: 27 [712151/888800 80.12%] train loss: 1.4256800568546169e-05 \n",
      "epoch: 27 [713262/888800 80.25%] train loss: 1.5081246601766907e-05 \n",
      "epoch: 27 [714373/888800 80.38%] train loss: 1.4523126992571633e-05 \n",
      "epoch: 27 [715484/888800 80.50%] train loss: 1.442926895833807e-05 \n",
      "epoch: 27 [716595/888800 80.62%] train loss: 1.2922883797727991e-05 \n",
      "epoch: 27 [717706/888800 80.75%] train loss: 1.5121141586860176e-05 \n",
      "epoch: 27 [718817/888800 80.88%] train loss: 1.4496625226456672e-05 \n",
      "epoch: 27 [719928/888800 81.00%] train loss: 1.5129769053601194e-05 \n",
      "epoch: 27 [721039/888800 81.12%] train loss: 1.3311117982084397e-05 \n",
      "epoch: 27 [722150/888800 81.25%] train loss: 1.5327286746469326e-05 \n",
      "epoch: 27 [723261/888800 81.38%] train loss: 1.3034837138548028e-05 \n",
      "epoch: 27 [724372/888800 81.50%] train loss: 1.370669087918941e-05 \n",
      "epoch: 27 [725483/888800 81.62%] train loss: 1.3610554560727905e-05 \n",
      "epoch: 27 [726594/888800 81.75%] train loss: 1.5859384802752174e-05 \n",
      "epoch: 27 [727705/888800 81.88%] train loss: 1.4296259905677289e-05 \n",
      "epoch: 27 [728816/888800 82.00%] train loss: 1.4117948921921197e-05 \n",
      "epoch: 27 [729927/888800 82.12%] train loss: 1.695436003501527e-05 \n",
      "epoch: 27 [731038/888800 82.25%] train loss: 1.2576033441291656e-05 \n",
      "epoch: 27 [732149/888800 82.38%] train loss: 1.3668424799107015e-05 \n",
      "epoch: 27 [733260/888800 82.50%] train loss: 1.5163863281486556e-05 \n",
      "epoch: 27 [734371/888800 82.62%] train loss: 1.3543366549129132e-05 \n",
      "epoch: 27 [735482/888800 82.75%] train loss: 1.35391437652288e-05 \n",
      "epoch: 27 [736593/888800 82.88%] train loss: 1.4115517842583358e-05 \n",
      "epoch: 27 [737704/888800 83.00%] train loss: 1.4388208001037128e-05 \n",
      "epoch: 27 [738815/888800 83.12%] train loss: 1.4607007869926747e-05 \n",
      "epoch: 27 [739926/888800 83.25%] train loss: 1.4048049706616439e-05 \n",
      "epoch: 27 [741037/888800 83.38%] train loss: 1.5118211194931064e-05 \n",
      "epoch: 27 [742148/888800 83.50%] train loss: 1.3775322258879896e-05 \n",
      "epoch: 27 [743259/888800 83.62%] train loss: 1.5664965758332983e-05 \n",
      "epoch: 27 [744370/888800 83.75%] train loss: 1.490578506491147e-05 \n",
      "epoch: 27 [745481/888800 83.88%] train loss: 1.4665425624116324e-05 \n",
      "epoch: 27 [746592/888800 84.00%] train loss: 1.546640669403132e-05 \n",
      "epoch: 27 [747703/888800 84.12%] train loss: 1.71940446307417e-05 \n",
      "epoch: 27 [748814/888800 84.25%] train loss: 1.7575423044036143e-05 \n",
      "epoch: 27 [749925/888800 84.38%] train loss: 1.3905284504289739e-05 \n",
      "epoch: 27 [751036/888800 84.50%] train loss: 1.6251349734375253e-05 \n",
      "epoch: 27 [752147/888800 84.62%] train loss: 1.5089510270627216e-05 \n",
      "epoch: 27 [753258/888800 84.75%] train loss: 1.572008477523923e-05 \n",
      "epoch: 27 [754369/888800 84.88%] train loss: 1.6853899069246836e-05 \n",
      "epoch: 27 [755480/888800 85.00%] train loss: 1.4595258107874542e-05 \n",
      "epoch: 27 [756591/888800 85.12%] train loss: 1.4728453606949188e-05 \n",
      "epoch: 27 [757702/888800 85.25%] train loss: 1.5160850125539582e-05 \n",
      "epoch: 27 [758813/888800 85.38%] train loss: 1.632458770473022e-05 \n",
      "epoch: 27 [759924/888800 85.50%] train loss: 1.3501897228707094e-05 \n",
      "epoch: 27 [761035/888800 85.62%] train loss: 1.4184684005158488e-05 \n",
      "epoch: 27 [762146/888800 85.75%] train loss: 1.542687095934525e-05 \n",
      "epoch: 27 [763257/888800 85.88%] train loss: 1.4694888704980258e-05 \n",
      "epoch: 27 [764368/888800 86.00%] train loss: 1.3664630387211218e-05 \n",
      "epoch: 27 [765479/888800 86.12%] train loss: 1.2960595995537005e-05 \n",
      "epoch: 27 [766590/888800 86.25%] train loss: 1.3336217307369225e-05 \n",
      "epoch: 27 [767701/888800 86.38%] train loss: 1.3953903362562414e-05 \n",
      "epoch: 27 [768812/888800 86.50%] train loss: 1.3405639947450254e-05 \n",
      "epoch: 27 [769923/888800 86.62%] train loss: 1.3596015378425363e-05 \n",
      "epoch: 27 [771034/888800 86.75%] train loss: 1.5018648809927981e-05 \n",
      "epoch: 27 [772145/888800 86.88%] train loss: 1.3537223821913358e-05 \n",
      "epoch: 27 [773256/888800 87.00%] train loss: 1.453282038710313e-05 \n",
      "epoch: 27 [774367/888800 87.12%] train loss: 1.392364538332913e-05 \n",
      "epoch: 27 [775478/888800 87.25%] train loss: 1.3601576938526705e-05 \n",
      "epoch: 27 [776589/888800 87.38%] train loss: 1.4528416613757145e-05 \n",
      "epoch: 27 [777700/888800 87.50%] train loss: 1.4904667295922991e-05 \n",
      "epoch: 27 [778811/888800 87.62%] train loss: 1.4981468666519504e-05 \n",
      "epoch: 27 [779922/888800 87.75%] train loss: 1.4248984371079132e-05 \n",
      "epoch: 27 [781033/888800 87.88%] train loss: 1.4201031262928154e-05 \n",
      "epoch: 27 [782144/888800 88.00%] train loss: 1.4339658264361788e-05 \n",
      "epoch: 27 [783255/888800 88.12%] train loss: 1.3705183846468572e-05 \n",
      "epoch: 27 [784366/888800 88.25%] train loss: 1.5123153389140498e-05 \n",
      "epoch: 27 [785477/888800 88.38%] train loss: 1.350792263110634e-05 \n",
      "epoch: 27 [786588/888800 88.50%] train loss: 1.4609562640544027e-05 \n",
      "epoch: 27 [787699/888800 88.62%] train loss: 1.4999111954239197e-05 \n",
      "epoch: 27 [788810/888800 88.75%] train loss: 1.2564054486574605e-05 \n",
      "epoch: 27 [789921/888800 88.88%] train loss: 1.4344325791171286e-05 \n",
      "epoch: 27 [791032/888800 89.00%] train loss: 1.318448812526185e-05 \n",
      "epoch: 27 [792143/888800 89.12%] train loss: 1.3778610082226805e-05 \n",
      "epoch: 27 [793254/888800 89.25%] train loss: 1.3522234439733438e-05 \n",
      "epoch: 27 [794365/888800 89.38%] train loss: 1.4120285413810052e-05 \n",
      "epoch: 27 [795476/888800 89.50%] train loss: 1.5692972738179378e-05 \n",
      "epoch: 27 [796587/888800 89.62%] train loss: 1.4843833923805505e-05 \n",
      "epoch: 27 [797698/888800 89.75%] train loss: 1.4277956324804109e-05 \n",
      "epoch: 27 [798809/888800 89.88%] train loss: 1.481793060520431e-05 \n",
      "epoch: 27 [799920/888800 90.00%] train loss: 1.4670196833321825e-05 \n",
      "epoch: 27 [801031/888800 90.12%] train loss: 1.470902770961402e-05 \n",
      "epoch: 27 [802142/888800 90.25%] train loss: 1.5409334082505666e-05 \n",
      "epoch: 27 [803253/888800 90.38%] train loss: 1.3853950804332271e-05 \n",
      "epoch: 27 [804364/888800 90.50%] train loss: 1.3966458027425688e-05 \n",
      "epoch: 27 [805475/888800 90.62%] train loss: 1.4073309102968778e-05 \n",
      "epoch: 27 [806586/888800 90.75%] train loss: 1.3461977687256876e-05 \n",
      "epoch: 27 [807697/888800 90.88%] train loss: 1.4476413525699172e-05 \n",
      "epoch: 27 [808808/888800 91.00%] train loss: 1.286831684410572e-05 \n",
      "epoch: 27 [809919/888800 91.12%] train loss: 1.2222547411511187e-05 \n",
      "epoch: 27 [811030/888800 91.25%] train loss: 1.3289160051499493e-05 \n",
      "epoch: 27 [812141/888800 91.38%] train loss: 1.2977543519809842e-05 \n",
      "epoch: 27 [813252/888800 91.50%] train loss: 1.4094483958615456e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 [814363/888800 91.62%] train loss: 1.3951127584732603e-05 \n",
      "epoch: 27 [815474/888800 91.75%] train loss: 1.4255610039981548e-05 \n",
      "epoch: 27 [816585/888800 91.88%] train loss: 1.338927359029185e-05 \n",
      "epoch: 27 [817696/888800 92.00%] train loss: 1.4707265108881984e-05 \n",
      "epoch: 27 [818807/888800 92.12%] train loss: 1.4652432582806796e-05 \n",
      "epoch: 27 [819918/888800 92.25%] train loss: 1.4873113286739681e-05 \n",
      "epoch: 27 [821029/888800 92.38%] train loss: 1.3980119547341019e-05 \n",
      "epoch: 27 [822140/888800 92.50%] train loss: 1.388308828609297e-05 \n",
      "epoch: 27 [823251/888800 92.62%] train loss: 1.425726804882288e-05 \n",
      "epoch: 27 [824362/888800 92.75%] train loss: 1.462010641262168e-05 \n",
      "epoch: 27 [825473/888800 92.88%] train loss: 1.383155267831171e-05 \n",
      "epoch: 27 [826584/888800 93.00%] train loss: 1.5027506378828548e-05 \n",
      "epoch: 27 [827695/888800 93.12%] train loss: 1.4069997632759623e-05 \n",
      "epoch: 27 [828806/888800 93.25%] train loss: 1.4856501366011798e-05 \n",
      "epoch: 27 [829917/888800 93.38%] train loss: 1.4470526366494596e-05 \n",
      "epoch: 27 [831028/888800 93.50%] train loss: 1.5272109521902166e-05 \n",
      "epoch: 27 [832139/888800 93.62%] train loss: 1.4007294339535292e-05 \n",
      "epoch: 27 [833250/888800 93.75%] train loss: 1.3787744137516711e-05 \n",
      "epoch: 27 [834361/888800 93.88%] train loss: 1.408207208442036e-05 \n",
      "epoch: 27 [835472/888800 94.00%] train loss: 1.4385458598553669e-05 \n",
      "epoch: 27 [836583/888800 94.12%] train loss: 1.4894330888637342e-05 \n",
      "epoch: 27 [837694/888800 94.25%] train loss: 1.4077651030675042e-05 \n",
      "epoch: 27 [838805/888800 94.38%] train loss: 1.4559405826730654e-05 \n",
      "epoch: 27 [839916/888800 94.50%] train loss: 1.5418891052831896e-05 \n",
      "epoch: 27 [841027/888800 94.62%] train loss: 1.4023725270817522e-05 \n",
      "epoch: 27 [842138/888800 94.75%] train loss: 1.4385666872840375e-05 \n",
      "epoch: 27 [843249/888800 94.88%] train loss: 1.4376592844200786e-05 \n",
      "epoch: 27 [844360/888800 95.00%] train loss: 1.4455521522904746e-05 \n",
      "epoch: 27 [845471/888800 95.12%] train loss: 1.4223648577171843e-05 \n",
      "epoch: 27 [846582/888800 95.25%] train loss: 1.5255924154189415e-05 \n",
      "epoch: 27 [847693/888800 95.38%] train loss: 1.4042190741747618e-05 \n",
      "epoch: 27 [848804/888800 95.50%] train loss: 1.5735597116872668e-05 \n",
      "epoch: 27 [849915/888800 95.62%] train loss: 1.3958366253064014e-05 \n",
      "epoch: 27 [851026/888800 95.75%] train loss: 1.533135218778625e-05 \n",
      "epoch: 27 [852137/888800 95.88%] train loss: 1.605552461114712e-05 \n",
      "epoch: 27 [853248/888800 96.00%] train loss: 1.5137096852413379e-05 \n",
      "epoch: 27 [854359/888800 96.12%] train loss: 1.4929299140931107e-05 \n",
      "epoch: 27 [855470/888800 96.25%] train loss: 1.6044165022321977e-05 \n",
      "epoch: 27 [856581/888800 96.38%] train loss: 1.5648485714336857e-05 \n",
      "epoch: 27 [857692/888800 96.50%] train loss: 1.4306952834886033e-05 \n",
      "epoch: 27 [858803/888800 96.62%] train loss: 1.501937185821589e-05 \n",
      "epoch: 27 [859914/888800 96.75%] train loss: 1.4122465472610202e-05 \n",
      "epoch: 27 [861025/888800 96.88%] train loss: 1.6066607713582925e-05 \n",
      "epoch: 27 [862136/888800 97.00%] train loss: 1.3508932170225307e-05 \n",
      "epoch: 27 [863247/888800 97.12%] train loss: 1.3972330634715036e-05 \n",
      "epoch: 27 [864358/888800 97.25%] train loss: 1.3707525795325637e-05 \n",
      "epoch: 27 [865469/888800 97.38%] train loss: 1.4391212971531786e-05 \n",
      "epoch: 27 [866580/888800 97.50%] train loss: 1.4173261661198922e-05 \n",
      "epoch: 27 [867691/888800 97.62%] train loss: 1.3556068552134093e-05 \n",
      "epoch: 27 [868802/888800 97.75%] train loss: 1.339337723038625e-05 \n",
      "epoch: 27 [869913/888800 97.88%] train loss: 1.3646980733028613e-05 \n",
      "epoch: 27 [871024/888800 98.00%] train loss: 1.4738629943167325e-05 \n",
      "epoch: 27 [872135/888800 98.12%] train loss: 1.449714727641549e-05 \n",
      "epoch: 27 [873246/888800 98.25%] train loss: 1.4828778148512356e-05 \n",
      "epoch: 27 [874357/888800 98.38%] train loss: 1.5095935850695241e-05 \n",
      "epoch: 27 [875468/888800 98.50%] train loss: 1.4017695320944767e-05 \n",
      "epoch: 27 [876579/888800 98.62%] train loss: 1.455953770346241e-05 \n",
      "epoch: 27 [877690/888800 98.75%] train loss: 1.4397113773156889e-05 \n",
      "epoch: 27 [878801/888800 98.88%] train loss: 1.4537326933350414e-05 \n",
      "epoch: 27 [879912/888800 99.00%] train loss: 1.3707664948015008e-05 \n",
      "epoch: 27 [881023/888800 99.12%] train loss: 1.4464530067925807e-05 \n",
      "epoch: 27 [882134/888800 99.25%] train loss: 1.7007281712722033e-05 \n",
      "epoch: 27 [883245/888800 99.38%] train loss: 1.5399880794575438e-05 \n",
      "epoch: 27 [884356/888800 99.50%] train loss: 1.4315322005131748e-05 \n",
      "epoch: 27 [885467/888800 99.62%] train loss: 1.4586606084776577e-05 \n",
      "epoch: 27 [886578/888800 99.75%] train loss: 1.579803938511759e-05 \n",
      "epoch: 27 [887689/888800 99.88%] train loss: 1.344609700026922e-05 \n",
      "epoch: 28 [0/888800 0.00%] train loss: 1.5429464838234708e-05 \n",
      "epoch: 28 [1111/888800 0.12%] train loss: 1.5457544577657245e-05 \n",
      "epoch: 28 [2222/888800 0.25%] train loss: 1.4810821994615253e-05 \n",
      "epoch: 28 [3333/888800 0.38%] train loss: 1.4758262295799796e-05 \n",
      "epoch: 28 [4444/888800 0.50%] train loss: 1.4766757885809056e-05 \n",
      "epoch: 28 [5555/888800 0.62%] train loss: 1.4456222743319813e-05 \n",
      "epoch: 28 [6666/888800 0.75%] train loss: 1.4203628779796418e-05 \n",
      "epoch: 28 [7777/888800 0.88%] train loss: 1.516539396106964e-05 \n",
      "epoch: 28 [8888/888800 1.00%] train loss: 1.4838979950582143e-05 \n",
      "epoch: 28 [9999/888800 1.12%] train loss: 1.4368994925462175e-05 \n",
      "epoch: 28 [11110/888800 1.25%] train loss: 1.4475992429652251e-05 \n",
      "epoch: 28 [12221/888800 1.38%] train loss: 1.3702986507269088e-05 \n",
      "epoch: 28 [13332/888800 1.50%] train loss: 1.3394923371379264e-05 \n",
      "epoch: 28 [14443/888800 1.62%] train loss: 1.319192597293295e-05 \n",
      "epoch: 28 [15554/888800 1.75%] train loss: 1.2688670722127426e-05 \n",
      "epoch: 28 [16665/888800 1.88%] train loss: 1.3933944501332007e-05 \n",
      "epoch: 28 [17776/888800 2.00%] train loss: 1.248905755346641e-05 \n",
      "epoch: 28 [18887/888800 2.12%] train loss: 1.3518194464268163e-05 \n",
      "epoch: 28 [19998/888800 2.25%] train loss: 1.3905092600907665e-05 \n",
      "epoch: 28 [21109/888800 2.38%] train loss: 1.4904834642948117e-05 \n",
      "epoch: 28 [22220/888800 2.50%] train loss: 1.4036223547009286e-05 \n",
      "epoch: 28 [23331/888800 2.62%] train loss: 1.4562805517925881e-05 \n",
      "epoch: 28 [24442/888800 2.75%] train loss: 1.5603884094161913e-05 \n",
      "epoch: 28 [25553/888800 2.88%] train loss: 1.2844607226725202e-05 \n",
      "epoch: 28 [26664/888800 3.00%] train loss: 1.4880278286000248e-05 \n",
      "epoch: 28 [27775/888800 3.12%] train loss: 1.4241963071981445e-05 \n",
      "epoch: 28 [28886/888800 3.25%] train loss: 1.4176912372931838e-05 \n",
      "epoch: 28 [29997/888800 3.38%] train loss: 1.4425110748561565e-05 \n",
      "epoch: 28 [31108/888800 3.50%] train loss: 1.54654735524673e-05 \n",
      "epoch: 28 [32219/888800 3.62%] train loss: 1.3528713679988869e-05 \n",
      "epoch: 28 [33330/888800 3.75%] train loss: 1.6328129277098924e-05 \n",
      "epoch: 28 [34441/888800 3.88%] train loss: 1.2871074432041496e-05 \n",
      "epoch: 28 [35552/888800 4.00%] train loss: 1.6056081221904606e-05 \n",
      "epoch: 28 [36663/888800 4.12%] train loss: 1.4922309674147982e-05 \n",
      "epoch: 28 [37774/888800 4.25%] train loss: 1.4023441508470569e-05 \n",
      "epoch: 28 [38885/888800 4.38%] train loss: 1.4900635505910031e-05 \n",
      "epoch: 28 [39996/888800 4.50%] train loss: 1.5252182492986321e-05 \n",
      "epoch: 28 [41107/888800 4.62%] train loss: 1.4989314877311699e-05 \n",
      "epoch: 28 [42218/888800 4.75%] train loss: 1.3826671420247294e-05 \n",
      "epoch: 28 [43329/888800 4.88%] train loss: 1.3832048352924176e-05 \n",
      "epoch: 28 [44440/888800 5.00%] train loss: 1.4708190974488389e-05 \n",
      "epoch: 28 [45551/888800 5.12%] train loss: 1.3807338291371707e-05 \n",
      "epoch: 28 [46662/888800 5.25%] train loss: 1.599436109245289e-05 \n",
      "epoch: 28 [47773/888800 5.38%] train loss: 1.4372783880389761e-05 \n",
      "epoch: 28 [48884/888800 5.50%] train loss: 1.546628300275188e-05 \n",
      "epoch: 28 [49995/888800 5.62%] train loss: 1.268353753403062e-05 \n",
      "epoch: 28 [51106/888800 5.75%] train loss: 1.5310793969547376e-05 \n",
      "epoch: 28 [52217/888800 5.88%] train loss: 1.4668751646240707e-05 \n",
      "epoch: 28 [53328/888800 6.00%] train loss: 1.3825835594616365e-05 \n",
      "epoch: 28 [54439/888800 6.12%] train loss: 1.4455322343565058e-05 \n",
      "epoch: 28 [55550/888800 6.25%] train loss: 1.4571210158464964e-05 \n",
      "epoch: 28 [56661/888800 6.38%] train loss: 1.3937557923782151e-05 \n",
      "epoch: 28 [57772/888800 6.50%] train loss: 1.4014573025633581e-05 \n",
      "epoch: 28 [58883/888800 6.62%] train loss: 1.4753069081052672e-05 \n",
      "epoch: 28 [59994/888800 6.75%] train loss: 1.4243887562770396e-05 \n",
      "epoch: 28 [61105/888800 6.88%] train loss: 1.574219459143933e-05 \n",
      "epoch: 28 [62216/888800 7.00%] train loss: 1.5331333997892216e-05 \n",
      "epoch: 28 [63327/888800 7.12%] train loss: 1.4718055354023818e-05 \n",
      "epoch: 28 [64438/888800 7.25%] train loss: 1.4397554878087249e-05 \n",
      "epoch: 28 [65549/888800 7.38%] train loss: 1.450078980269609e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [66660/888800 7.50%] train loss: 1.3863680578651838e-05 \n",
      "epoch: 28 [67771/888800 7.62%] train loss: 1.4541520613420289e-05 \n",
      "epoch: 28 [68882/888800 7.75%] train loss: 1.4527677194564603e-05 \n",
      "epoch: 28 [69993/888800 7.88%] train loss: 1.4780104720557574e-05 \n",
      "epoch: 28 [71104/888800 8.00%] train loss: 1.4682171240565367e-05 \n",
      "epoch: 28 [72215/888800 8.12%] train loss: 1.4108224604569841e-05 \n",
      "epoch: 28 [73326/888800 8.25%] train loss: 1.3944073543825652e-05 \n",
      "epoch: 28 [74437/888800 8.38%] train loss: 1.2919012078782544e-05 \n",
      "epoch: 28 [75548/888800 8.50%] train loss: 1.3655985640070867e-05 \n",
      "epoch: 28 [76659/888800 8.62%] train loss: 1.36863200168591e-05 \n",
      "epoch: 28 [77770/888800 8.75%] train loss: 1.3487558135238942e-05 \n",
      "epoch: 28 [78881/888800 8.88%] train loss: 1.4986528185545467e-05 \n",
      "epoch: 28 [79992/888800 9.00%] train loss: 1.5615318261552602e-05 \n",
      "epoch: 28 [81103/888800 9.12%] train loss: 1.5095776689122431e-05 \n",
      "epoch: 28 [82214/888800 9.25%] train loss: 1.3709953236684669e-05 \n",
      "epoch: 28 [83325/888800 9.38%] train loss: 1.4393583114724606e-05 \n",
      "epoch: 28 [84436/888800 9.50%] train loss: 1.3381482858676463e-05 \n",
      "epoch: 28 [85547/888800 9.62%] train loss: 1.4431813724513631e-05 \n",
      "epoch: 28 [86658/888800 9.75%] train loss: 1.3842242879036348e-05 \n",
      "epoch: 28 [87769/888800 9.88%] train loss: 1.4282003576226998e-05 \n",
      "epoch: 28 [88880/888800 10.00%] train loss: 1.3793552170682233e-05 \n",
      "epoch: 28 [89991/888800 10.12%] train loss: 1.6001929907361045e-05 \n",
      "epoch: 28 [91102/888800 10.25%] train loss: 1.441622316633584e-05 \n",
      "epoch: 28 [92213/888800 10.38%] train loss: 1.423840512870811e-05 \n",
      "epoch: 28 [93324/888800 10.50%] train loss: 1.5172336134128273e-05 \n",
      "epoch: 28 [94435/888800 10.62%] train loss: 1.3188668162911199e-05 \n",
      "epoch: 28 [95546/888800 10.75%] train loss: 1.4524444850394502e-05 \n",
      "epoch: 28 [96657/888800 10.88%] train loss: 1.5233968042593915e-05 \n",
      "epoch: 28 [97768/888800 11.00%] train loss: 1.3594614756584633e-05 \n",
      "epoch: 28 [98879/888800 11.12%] train loss: 1.5089813132362906e-05 \n",
      "epoch: 28 [99990/888800 11.25%] train loss: 1.6205385691137053e-05 \n",
      "epoch: 28 [101101/888800 11.38%] train loss: 1.3627101907331962e-05 \n",
      "epoch: 28 [102212/888800 11.50%] train loss: 1.5394183719763532e-05 \n",
      "epoch: 28 [103323/888800 11.62%] train loss: 1.3667141502082814e-05 \n",
      "epoch: 28 [104434/888800 11.75%] train loss: 1.4637232197856065e-05 \n",
      "epoch: 28 [105545/888800 11.88%] train loss: 1.3744923307967838e-05 \n",
      "epoch: 28 [106656/888800 12.00%] train loss: 1.3768069948127959e-05 \n",
      "epoch: 28 [107767/888800 12.12%] train loss: 1.4641727830166928e-05 \n",
      "epoch: 28 [108878/888800 12.25%] train loss: 1.3218214007792994e-05 \n",
      "epoch: 28 [109989/888800 12.38%] train loss: 1.4013538020662963e-05 \n",
      "epoch: 28 [111100/888800 12.50%] train loss: 1.3359426702663768e-05 \n",
      "epoch: 28 [112211/888800 12.62%] train loss: 1.2730438356811646e-05 \n",
      "epoch: 28 [113322/888800 12.75%] train loss: 1.4678143998025917e-05 \n",
      "epoch: 28 [114433/888800 12.88%] train loss: 1.4992318938311655e-05 \n",
      "epoch: 28 [115544/888800 13.00%] train loss: 1.3455698535835836e-05 \n",
      "epoch: 28 [116655/888800 13.12%] train loss: 1.4130757335806265e-05 \n",
      "epoch: 28 [117766/888800 13.25%] train loss: 1.3668061001226306e-05 \n",
      "epoch: 28 [118877/888800 13.38%] train loss: 1.3946213584858924e-05 \n",
      "epoch: 28 [119988/888800 13.50%] train loss: 1.2832666470785625e-05 \n",
      "epoch: 28 [121099/888800 13.62%] train loss: 1.4363840818987228e-05 \n",
      "epoch: 28 [122210/888800 13.75%] train loss: 1.434305522707291e-05 \n",
      "epoch: 28 [123321/888800 13.88%] train loss: 1.5030818758532405e-05 \n",
      "epoch: 28 [124432/888800 14.00%] train loss: 1.3780543667962775e-05 \n",
      "epoch: 28 [125543/888800 14.12%] train loss: 1.4785154235141817e-05 \n",
      "epoch: 28 [126654/888800 14.25%] train loss: 1.4392326193046756e-05 \n",
      "epoch: 28 [127765/888800 14.38%] train loss: 1.4664702575828414e-05 \n",
      "epoch: 28 [128876/888800 14.50%] train loss: 1.417293242411688e-05 \n",
      "epoch: 28 [129987/888800 14.62%] train loss: 1.4914497114659753e-05 \n",
      "epoch: 28 [131098/888800 14.75%] train loss: 1.4439329788729083e-05 \n",
      "epoch: 28 [132209/888800 14.88%] train loss: 1.448743114451645e-05 \n",
      "epoch: 28 [133320/888800 15.00%] train loss: 1.3549823052017018e-05 \n",
      "epoch: 28 [134431/888800 15.12%] train loss: 1.3814781596011017e-05 \n",
      "epoch: 28 [135542/888800 15.25%] train loss: 1.4145598470349796e-05 \n",
      "epoch: 28 [136653/888800 15.38%] train loss: 1.3253411452751607e-05 \n",
      "epoch: 28 [137764/888800 15.50%] train loss: 1.3619794117403217e-05 \n",
      "epoch: 28 [138875/888800 15.62%] train loss: 1.5384022844955325e-05 \n",
      "epoch: 28 [139986/888800 15.75%] train loss: 1.3803875845042057e-05 \n",
      "epoch: 28 [141097/888800 15.88%] train loss: 1.500055532233091e-05 \n",
      "epoch: 28 [142208/888800 16.00%] train loss: 1.273715497518424e-05 \n",
      "epoch: 28 [143319/888800 16.12%] train loss: 1.4580739843950141e-05 \n",
      "epoch: 28 [144430/888800 16.25%] train loss: 1.4129186638456304e-05 \n",
      "epoch: 28 [145541/888800 16.38%] train loss: 1.3840516658092383e-05 \n",
      "epoch: 28 [146652/888800 16.50%] train loss: 1.44716568684089e-05 \n",
      "epoch: 28 [147763/888800 16.62%] train loss: 1.4173308045428712e-05 \n",
      "epoch: 28 [148874/888800 16.75%] train loss: 1.3809034498990513e-05 \n",
      "epoch: 28 [149985/888800 16.88%] train loss: 1.232872818945907e-05 \n",
      "epoch: 28 [151096/888800 17.00%] train loss: 1.478371905250242e-05 \n",
      "epoch: 28 [152207/888800 17.12%] train loss: 1.541194251331035e-05 \n",
      "epoch: 28 [153318/888800 17.25%] train loss: 1.4089891919866204e-05 \n",
      "epoch: 28 [154429/888800 17.38%] train loss: 1.4187099623086397e-05 \n",
      "epoch: 28 [155540/888800 17.50%] train loss: 1.4276615729613695e-05 \n",
      "epoch: 28 [156651/888800 17.62%] train loss: 1.4641835150541738e-05 \n",
      "epoch: 28 [157762/888800 17.75%] train loss: 1.4222016943676863e-05 \n",
      "epoch: 28 [158873/888800 17.88%] train loss: 1.447909016860649e-05 \n",
      "epoch: 28 [159984/888800 18.00%] train loss: 1.4641495909017976e-05 \n",
      "epoch: 28 [161095/888800 18.12%] train loss: 1.4341890164359938e-05 \n",
      "epoch: 28 [162206/888800 18.25%] train loss: 1.3769189536105841e-05 \n",
      "epoch: 28 [163317/888800 18.38%] train loss: 1.4431298950512428e-05 \n",
      "epoch: 28 [164428/888800 18.50%] train loss: 1.3388159459282178e-05 \n",
      "epoch: 28 [165539/888800 18.62%] train loss: 1.4409378309210297e-05 \n",
      "epoch: 28 [166650/888800 18.75%] train loss: 1.4782720427319873e-05 \n",
      "epoch: 28 [167761/888800 18.88%] train loss: 1.4865126104268711e-05 \n",
      "epoch: 28 [168872/888800 19.00%] train loss: 1.5202752365439665e-05 \n",
      "epoch: 28 [169983/888800 19.12%] train loss: 1.4322400602395646e-05 \n",
      "epoch: 28 [171094/888800 19.25%] train loss: 1.4557814211002551e-05 \n",
      "epoch: 28 [172205/888800 19.38%] train loss: 1.4065073628444225e-05 \n",
      "epoch: 28 [173316/888800 19.50%] train loss: 1.407777835993329e-05 \n",
      "epoch: 28 [174427/888800 19.62%] train loss: 1.442095799575327e-05 \n",
      "epoch: 28 [175538/888800 19.75%] train loss: 1.4488496162812226e-05 \n",
      "epoch: 28 [176649/888800 19.88%] train loss: 1.5158126188907772e-05 \n",
      "epoch: 28 [177760/888800 20.00%] train loss: 1.5888072084635496e-05 \n",
      "epoch: 28 [178871/888800 20.12%] train loss: 1.6458927348139696e-05 \n",
      "epoch: 28 [179982/888800 20.25%] train loss: 1.3624578969029244e-05 \n",
      "epoch: 28 [181093/888800 20.38%] train loss: 1.584986603120342e-05 \n",
      "epoch: 28 [182204/888800 20.50%] train loss: 1.457390590076102e-05 \n",
      "epoch: 28 [183315/888800 20.62%] train loss: 1.598991366336122e-05 \n",
      "epoch: 28 [184426/888800 20.75%] train loss: 1.5830259144422598e-05 \n",
      "epoch: 28 [185537/888800 20.88%] train loss: 1.4863456271996256e-05 \n",
      "epoch: 28 [186648/888800 21.00%] train loss: 1.5649433407816105e-05 \n",
      "epoch: 28 [187759/888800 21.12%] train loss: 1.604315548320301e-05 \n",
      "epoch: 28 [188870/888800 21.25%] train loss: 1.4927042684576008e-05 \n",
      "epoch: 28 [189981/888800 21.38%] train loss: 1.4267191545513924e-05 \n",
      "epoch: 28 [191092/888800 21.50%] train loss: 1.543918733659666e-05 \n",
      "epoch: 28 [192203/888800 21.62%] train loss: 1.3292850780999288e-05 \n",
      "epoch: 28 [193314/888800 21.75%] train loss: 1.5853645891183987e-05 \n",
      "epoch: 28 [194425/888800 21.88%] train loss: 1.3808441508444957e-05 \n",
      "epoch: 28 [195536/888800 22.00%] train loss: 1.5063968021422625e-05 \n",
      "epoch: 28 [196647/888800 22.12%] train loss: 1.4751184608030599e-05 \n",
      "epoch: 28 [197758/888800 22.25%] train loss: 1.35753607537481e-05 \n",
      "epoch: 28 [198869/888800 22.38%] train loss: 1.3756459338765126e-05 \n",
      "epoch: 28 [199980/888800 22.50%] train loss: 1.4704532986797858e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [201091/888800 22.62%] train loss: 1.3603606930701062e-05 \n",
      "epoch: 28 [202202/888800 22.75%] train loss: 1.3796093298878986e-05 \n",
      "epoch: 28 [203313/888800 22.88%] train loss: 1.3467385542753618e-05 \n",
      "epoch: 28 [204424/888800 23.00%] train loss: 1.403796522936318e-05 \n",
      "epoch: 28 [205535/888800 23.12%] train loss: 1.4163388186716475e-05 \n",
      "epoch: 28 [206646/888800 23.25%] train loss: 1.4657141946372576e-05 \n",
      "epoch: 28 [207757/888800 23.38%] train loss: 1.4574206034012605e-05 \n",
      "epoch: 28 [208868/888800 23.50%] train loss: 1.4224784536054358e-05 \n",
      "epoch: 28 [209979/888800 23.62%] train loss: 1.4048856428416912e-05 \n",
      "epoch: 28 [211090/888800 23.75%] train loss: 1.5221378816931974e-05 \n",
      "epoch: 28 [212201/888800 23.88%] train loss: 1.3993858374306e-05 \n",
      "epoch: 28 [213312/888800 24.00%] train loss: 1.3584752196038608e-05 \n",
      "epoch: 28 [214423/888800 24.12%] train loss: 1.397075266140746e-05 \n",
      "epoch: 28 [215534/888800 24.25%] train loss: 1.3043356375419535e-05 \n",
      "epoch: 28 [216645/888800 24.38%] train loss: 1.4386330803972669e-05 \n",
      "epoch: 28 [217756/888800 24.50%] train loss: 1.4746054148417898e-05 \n",
      "epoch: 28 [218867/888800 24.62%] train loss: 1.334586431767093e-05 \n",
      "epoch: 28 [219978/888800 24.75%] train loss: 1.286658789467765e-05 \n",
      "epoch: 28 [221089/888800 24.88%] train loss: 1.4038810149941128e-05 \n",
      "epoch: 28 [222200/888800 25.00%] train loss: 1.5746149074402638e-05 \n",
      "epoch: 28 [223311/888800 25.12%] train loss: 1.388730470353039e-05 \n",
      "epoch: 28 [224422/888800 25.25%] train loss: 1.566047103551682e-05 \n",
      "epoch: 28 [225533/888800 25.38%] train loss: 1.2527792932814918e-05 \n",
      "epoch: 28 [226644/888800 25.50%] train loss: 1.4976992133597378e-05 \n",
      "epoch: 28 [227755/888800 25.62%] train loss: 1.5520987290074117e-05 \n",
      "epoch: 28 [228866/888800 25.75%] train loss: 1.4552992979588453e-05 \n",
      "epoch: 28 [229977/888800 25.88%] train loss: 1.4178243873175234e-05 \n",
      "epoch: 28 [231088/888800 26.00%] train loss: 1.3878850040782709e-05 \n",
      "epoch: 28 [232199/888800 26.12%] train loss: 1.3145429875294212e-05 \n",
      "epoch: 28 [233310/888800 26.25%] train loss: 1.576284375914838e-05 \n",
      "epoch: 28 [234421/888800 26.38%] train loss: 1.5117318980628625e-05 \n",
      "epoch: 28 [235532/888800 26.50%] train loss: 1.5239488675433677e-05 \n",
      "epoch: 28 [236643/888800 26.62%] train loss: 1.438553590560332e-05 \n",
      "epoch: 28 [237754/888800 26.75%] train loss: 1.5031345355964731e-05 \n",
      "epoch: 28 [238865/888800 26.88%] train loss: 1.556390452606138e-05 \n",
      "epoch: 28 [239976/888800 27.00%] train loss: 1.5500991139560938e-05 \n",
      "epoch: 28 [241087/888800 27.12%] train loss: 1.3947277693659998e-05 \n",
      "epoch: 28 [242198/888800 27.25%] train loss: 1.3941412362328265e-05 \n",
      "epoch: 28 [243309/888800 27.38%] train loss: 1.291003809456015e-05 \n",
      "epoch: 28 [244420/888800 27.50%] train loss: 1.4868455764371902e-05 \n",
      "epoch: 28 [245531/888800 27.62%] train loss: 1.4925615687388927e-05 \n",
      "epoch: 28 [246642/888800 27.75%] train loss: 1.3657499948749319e-05 \n",
      "epoch: 28 [247753/888800 27.88%] train loss: 1.3818821571476292e-05 \n",
      "epoch: 28 [248864/888800 28.00%] train loss: 1.4283289601735305e-05 \n",
      "epoch: 28 [249975/888800 28.12%] train loss: 1.5048704881337471e-05 \n",
      "epoch: 28 [251086/888800 28.25%] train loss: 1.3935113202023786e-05 \n",
      "epoch: 28 [252197/888800 28.38%] train loss: 1.3874480828235392e-05 \n",
      "epoch: 28 [253308/888800 28.50%] train loss: 1.2451001566660125e-05 \n",
      "epoch: 28 [254419/888800 28.62%] train loss: 1.4551293133990839e-05 \n",
      "epoch: 28 [255530/888800 28.75%] train loss: 1.3317792763700709e-05 \n",
      "epoch: 28 [256641/888800 28.88%] train loss: 1.30703729155357e-05 \n",
      "epoch: 28 [257752/888800 29.00%] train loss: 1.562414581712801e-05 \n",
      "epoch: 28 [258863/888800 29.12%] train loss: 1.4555152120010462e-05 \n",
      "epoch: 28 [259974/888800 29.25%] train loss: 1.433105171599891e-05 \n",
      "epoch: 28 [261085/888800 29.38%] train loss: 1.352503113594139e-05 \n",
      "epoch: 28 [262196/888800 29.50%] train loss: 1.4845506484562065e-05 \n",
      "epoch: 28 [263307/888800 29.62%] train loss: 1.3316303920873906e-05 \n",
      "epoch: 28 [264418/888800 29.75%] train loss: 1.4898452718625776e-05 \n",
      "epoch: 28 [265529/888800 29.88%] train loss: 1.5044181054690853e-05 \n",
      "epoch: 28 [266640/888800 30.00%] train loss: 1.3408432096184697e-05 \n",
      "epoch: 28 [267751/888800 30.12%] train loss: 1.4603570889448747e-05 \n",
      "epoch: 28 [268862/888800 30.25%] train loss: 1.2475116818677634e-05 \n",
      "epoch: 28 [269973/888800 30.38%] train loss: 1.3955169379187282e-05 \n",
      "epoch: 28 [271084/888800 30.50%] train loss: 1.4530955922964495e-05 \n",
      "epoch: 28 [272195/888800 30.62%] train loss: 1.542283825983759e-05 \n",
      "epoch: 28 [273306/888800 30.75%] train loss: 1.51152034959523e-05 \n",
      "epoch: 28 [274417/888800 30.88%] train loss: 1.3754355677519925e-05 \n",
      "epoch: 28 [275528/888800 31.00%] train loss: 1.3847427908331156e-05 \n",
      "epoch: 28 [276639/888800 31.12%] train loss: 1.357190831186017e-05 \n",
      "epoch: 28 [277750/888800 31.25%] train loss: 1.3855657016392797e-05 \n",
      "epoch: 28 [278861/888800 31.38%] train loss: 1.286090900975978e-05 \n",
      "epoch: 28 [279972/888800 31.50%] train loss: 1.461533520341618e-05 \n",
      "epoch: 28 [281083/888800 31.62%] train loss: 1.267320567421848e-05 \n",
      "epoch: 28 [282194/888800 31.75%] train loss: 1.3667607163370121e-05 \n",
      "epoch: 28 [283305/888800 31.88%] train loss: 1.385725408908911e-05 \n",
      "epoch: 28 [284416/888800 32.00%] train loss: 1.3956931979919318e-05 \n",
      "epoch: 28 [285527/888800 32.12%] train loss: 1.5916881238808855e-05 \n",
      "epoch: 28 [286638/888800 32.25%] train loss: 1.481014805904124e-05 \n",
      "epoch: 28 [287749/888800 32.38%] train loss: 1.40188403747743e-05 \n",
      "epoch: 28 [288860/888800 32.50%] train loss: 1.5196229469438549e-05 \n",
      "epoch: 28 [289971/888800 32.62%] train loss: 1.494413118052762e-05 \n",
      "epoch: 28 [291082/888800 32.75%] train loss: 1.3435679647955112e-05 \n",
      "epoch: 28 [292193/888800 32.88%] train loss: 1.554612026666291e-05 \n",
      "epoch: 28 [293304/888800 33.00%] train loss: 1.4742229723196942e-05 \n",
      "epoch: 28 [294415/888800 33.12%] train loss: 1.4263215234677773e-05 \n",
      "epoch: 28 [295526/888800 33.25%] train loss: 1.448813418392092e-05 \n",
      "epoch: 28 [296637/888800 33.38%] train loss: 1.3562123967858497e-05 \n",
      "epoch: 28 [297748/888800 33.50%] train loss: 1.4185768122843001e-05 \n",
      "epoch: 28 [298859/888800 33.62%] train loss: 1.5001513020251878e-05 \n",
      "epoch: 28 [299970/888800 33.75%] train loss: 1.4315419321064837e-05 \n",
      "epoch: 28 [301081/888800 33.88%] train loss: 1.3905586456530727e-05 \n",
      "epoch: 28 [302192/888800 34.00%] train loss: 1.441790118406061e-05 \n",
      "epoch: 28 [303303/888800 34.12%] train loss: 1.409889773640316e-05 \n",
      "epoch: 28 [304414/888800 34.25%] train loss: 1.41907949000597e-05 \n",
      "epoch: 28 [305525/888800 34.38%] train loss: 1.4893741536070593e-05 \n",
      "epoch: 28 [306636/888800 34.50%] train loss: 1.386477470077807e-05 \n",
      "epoch: 28 [307747/888800 34.62%] train loss: 1.3465122719935607e-05 \n",
      "epoch: 28 [308858/888800 34.75%] train loss: 1.4663040019513573e-05 \n",
      "epoch: 28 [309969/888800 34.88%] train loss: 1.391775094816694e-05 \n",
      "epoch: 28 [311080/888800 35.00%] train loss: 1.4021978131495416e-05 \n",
      "epoch: 28 [312191/888800 35.12%] train loss: 1.409190554113593e-05 \n",
      "epoch: 28 [313302/888800 35.25%] train loss: 1.4125925190455746e-05 \n",
      "epoch: 28 [314413/888800 35.38%] train loss: 1.558892472530715e-05 \n",
      "epoch: 28 [315524/888800 35.50%] train loss: 1.3991662854095921e-05 \n",
      "epoch: 28 [316635/888800 35.62%] train loss: 1.3829729141434655e-05 \n",
      "epoch: 28 [317746/888800 35.75%] train loss: 1.5076577255968004e-05 \n",
      "epoch: 28 [318857/888800 35.88%] train loss: 1.447789509256836e-05 \n",
      "epoch: 28 [319968/888800 36.00%] train loss: 1.4410243238671683e-05 \n",
      "epoch: 28 [321079/888800 36.12%] train loss: 1.3939062228018884e-05 \n",
      "epoch: 28 [322190/888800 36.25%] train loss: 1.3562747881223913e-05 \n",
      "epoch: 28 [323301/888800 36.38%] train loss: 1.4677144463348668e-05 \n",
      "epoch: 28 [324412/888800 36.50%] train loss: 1.5391860870295204e-05 \n",
      "epoch: 28 [325523/888800 36.62%] train loss: 1.563841760798823e-05 \n",
      "epoch: 28 [326634/888800 36.75%] train loss: 1.4420797015191056e-05 \n",
      "epoch: 28 [327745/888800 36.88%] train loss: 1.3998626855027396e-05 \n",
      "epoch: 28 [328856/888800 37.00%] train loss: 1.4082248526392505e-05 \n",
      "epoch: 28 [329967/888800 37.12%] train loss: 1.4309581274574157e-05 \n",
      "epoch: 28 [331078/888800 37.25%] train loss: 1.3099612260702997e-05 \n",
      "epoch: 28 [332189/888800 37.38%] train loss: 1.253366735909367e-05 \n",
      "epoch: 28 [333300/888800 37.50%] train loss: 1.3586298337031621e-05 \n",
      "epoch: 28 [334411/888800 37.62%] train loss: 1.3070136446913239e-05 \n",
      "epoch: 28 [335522/888800 37.75%] train loss: 1.2768305168719962e-05 \n",
      "epoch: 28 [336633/888800 37.88%] train loss: 1.3367265637498349e-05 \n",
      "epoch: 28 [337744/888800 38.00%] train loss: 1.4349850061989855e-05 \n",
      "epoch: 28 [338855/888800 38.12%] train loss: 1.3748292985837907e-05 \n",
      "epoch: 28 [339966/888800 38.25%] train loss: 1.3665253391081933e-05 \n",
      "epoch: 28 [341077/888800 38.38%] train loss: 1.4209173059498426e-05 \n",
      "epoch: 28 [342188/888800 38.50%] train loss: 1.5192015780485235e-05 \n",
      "epoch: 28 [343299/888800 38.62%] train loss: 1.494304888183251e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [344410/888800 38.75%] train loss: 1.4394978279597126e-05 \n",
      "epoch: 28 [345521/888800 38.88%] train loss: 1.3248622963146772e-05 \n",
      "epoch: 28 [346632/888800 39.00%] train loss: 1.3312526789377443e-05 \n",
      "epoch: 28 [347743/888800 39.12%] train loss: 1.3853155905962922e-05 \n",
      "epoch: 28 [348854/888800 39.25%] train loss: 1.421376146026887e-05 \n",
      "epoch: 28 [349965/888800 39.38%] train loss: 1.3901505553803872e-05 \n",
      "epoch: 28 [351076/888800 39.50%] train loss: 1.474401869927533e-05 \n",
      "epoch: 28 [352187/888800 39.62%] train loss: 1.5152734704315662e-05 \n",
      "epoch: 28 [353298/888800 39.75%] train loss: 1.4267324331740383e-05 \n",
      "epoch: 28 [354409/888800 39.88%] train loss: 1.3237692655820865e-05 \n",
      "epoch: 28 [355520/888800 40.00%] train loss: 1.4544541045324877e-05 \n",
      "epoch: 28 [356631/888800 40.12%] train loss: 1.4368827578437049e-05 \n",
      "epoch: 28 [357742/888800 40.25%] train loss: 1.5195798368949909e-05 \n",
      "epoch: 28 [358853/888800 40.38%] train loss: 1.4721174011356197e-05 \n",
      "epoch: 28 [359964/888800 40.50%] train loss: 1.605054239917081e-05 \n",
      "epoch: 28 [361075/888800 40.62%] train loss: 1.3713645785173867e-05 \n",
      "epoch: 28 [362186/888800 40.75%] train loss: 1.4663574802398216e-05 \n",
      "epoch: 28 [363297/888800 40.88%] train loss: 1.4176850527292117e-05 \n",
      "epoch: 28 [364408/888800 41.00%] train loss: 1.4351330719364341e-05 \n",
      "epoch: 28 [365519/888800 41.12%] train loss: 1.4393911442311946e-05 \n",
      "epoch: 28 [366630/888800 41.25%] train loss: 1.432572662452003e-05 \n",
      "epoch: 28 [367741/888800 41.38%] train loss: 1.4481010111921933e-05 \n",
      "epoch: 28 [368852/888800 41.50%] train loss: 1.5878551494097337e-05 \n",
      "epoch: 28 [369963/888800 41.62%] train loss: 1.3315308024175465e-05 \n",
      "epoch: 28 [371074/888800 41.75%] train loss: 1.3981582924316172e-05 \n",
      "epoch: 28 [372185/888800 41.88%] train loss: 1.410346339980606e-05 \n",
      "epoch: 28 [373296/888800 42.00%] train loss: 1.510979654995026e-05 \n",
      "epoch: 28 [374407/888800 42.12%] train loss: 1.2782655176124536e-05 \n",
      "epoch: 28 [375518/888800 42.25%] train loss: 1.3844217392033897e-05 \n",
      "epoch: 28 [376629/888800 42.38%] train loss: 1.3616719115816522e-05 \n",
      "epoch: 28 [377740/888800 42.50%] train loss: 1.3537185623135883e-05 \n",
      "epoch: 28 [378851/888800 42.62%] train loss: 1.4544521036441438e-05 \n",
      "epoch: 28 [379962/888800 42.75%] train loss: 1.3102488082950003e-05 \n",
      "epoch: 28 [381073/888800 42.88%] train loss: 1.3358459000301082e-05 \n",
      "epoch: 28 [382184/888800 43.00%] train loss: 1.3709067388845142e-05 \n",
      "epoch: 28 [383295/888800 43.12%] train loss: 1.4216484487405978e-05 \n",
      "epoch: 28 [384406/888800 43.25%] train loss: 1.4100372027314734e-05 \n",
      "epoch: 28 [385517/888800 43.38%] train loss: 1.3444303476717323e-05 \n",
      "epoch: 28 [386628/888800 43.50%] train loss: 1.5404233636218123e-05 \n",
      "epoch: 28 [387739/888800 43.62%] train loss: 1.379491004627198e-05 \n",
      "epoch: 28 [388850/888800 43.75%] train loss: 1.5389352483907714e-05 \n",
      "epoch: 28 [389961/888800 43.88%] train loss: 1.5143124073802028e-05 \n",
      "epoch: 28 [391072/888800 44.00%] train loss: 1.6082849469967186e-05 \n",
      "epoch: 28 [392183/888800 44.12%] train loss: 1.4828163330093957e-05 \n",
      "epoch: 28 [393294/888800 44.25%] train loss: 1.5728886864962988e-05 \n",
      "epoch: 28 [394405/888800 44.38%] train loss: 1.5069003893586341e-05 \n",
      "epoch: 28 [395516/888800 44.50%] train loss: 1.4738367099198513e-05 \n",
      "epoch: 28 [396627/888800 44.62%] train loss: 1.5355470168287866e-05 \n",
      "epoch: 28 [397738/888800 44.75%] train loss: 1.439898187527433e-05 \n",
      "epoch: 28 [398849/888800 44.88%] train loss: 1.5203815564746037e-05 \n",
      "epoch: 28 [399960/888800 45.00%] train loss: 1.3144470358383842e-05 \n",
      "epoch: 28 [401071/888800 45.12%] train loss: 1.3598453733720817e-05 \n",
      "epoch: 28 [402182/888800 45.25%] train loss: 1.4177881894283928e-05 \n",
      "epoch: 28 [403293/888800 45.38%] train loss: 1.4781370737182442e-05 \n",
      "epoch: 28 [404404/888800 45.50%] train loss: 1.4761179954803083e-05 \n",
      "epoch: 28 [405515/888800 45.62%] train loss: 1.413634072378045e-05 \n",
      "epoch: 28 [406626/888800 45.75%] train loss: 1.3160999515093863e-05 \n",
      "epoch: 28 [407737/888800 45.88%] train loss: 1.3822824257658795e-05 \n",
      "epoch: 28 [408848/888800 46.00%] train loss: 1.4216288036550395e-05 \n",
      "epoch: 28 [409959/888800 46.12%] train loss: 1.4029074009158649e-05 \n",
      "epoch: 28 [411070/888800 46.25%] train loss: 1.494465413998114e-05 \n",
      "epoch: 28 [412181/888800 46.38%] train loss: 1.4261565411288757e-05 \n",
      "epoch: 28 [413292/888800 46.50%] train loss: 1.4321803064376581e-05 \n",
      "epoch: 28 [414403/888800 46.62%] train loss: 1.3999215298099443e-05 \n",
      "epoch: 28 [415514/888800 46.75%] train loss: 1.4587063560611568e-05 \n",
      "epoch: 28 [416625/888800 46.88%] train loss: 1.478337071603164e-05 \n",
      "epoch: 28 [417736/888800 47.00%] train loss: 1.35656655402272e-05 \n",
      "epoch: 28 [418847/888800 47.12%] train loss: 1.414342568750726e-05 \n",
      "epoch: 28 [419958/888800 47.25%] train loss: 1.5094125956238713e-05 \n",
      "epoch: 28 [421069/888800 47.38%] train loss: 1.2842139767599292e-05 \n",
      "epoch: 28 [422180/888800 47.50%] train loss: 1.4290601029642858e-05 \n",
      "epoch: 28 [423291/888800 47.62%] train loss: 1.2532940672826953e-05 \n",
      "epoch: 28 [424402/888800 47.75%] train loss: 1.3638546079164371e-05 \n",
      "epoch: 28 [425513/888800 47.88%] train loss: 1.3287376532389317e-05 \n",
      "epoch: 28 [426624/888800 48.00%] train loss: 1.623863681743387e-05 \n",
      "epoch: 28 [427735/888800 48.12%] train loss: 1.4854372238914948e-05 \n",
      "epoch: 28 [428846/888800 48.25%] train loss: 1.3647401829075534e-05 \n",
      "epoch: 28 [429957/888800 48.38%] train loss: 1.496758977737045e-05 \n",
      "epoch: 28 [431068/888800 48.50%] train loss: 1.4275349712988827e-05 \n",
      "epoch: 28 [432179/888800 48.62%] train loss: 1.509789490228286e-05 \n",
      "epoch: 28 [433290/888800 48.75%] train loss: 1.5345936844823882e-05 \n",
      "epoch: 28 [434401/888800 48.88%] train loss: 1.4549709703715052e-05 \n",
      "epoch: 28 [435512/888800 49.00%] train loss: 1.3970339750812855e-05 \n",
      "epoch: 28 [436623/888800 49.12%] train loss: 1.3072233741695527e-05 \n",
      "epoch: 28 [437734/888800 49.25%] train loss: 1.4286835721577518e-05 \n",
      "epoch: 28 [438845/888800 49.38%] train loss: 1.4899625966791064e-05 \n",
      "epoch: 28 [439956/888800 49.50%] train loss: 1.4448221918428317e-05 \n",
      "epoch: 28 [441067/888800 49.62%] train loss: 1.4491198271571193e-05 \n",
      "epoch: 28 [442178/888800 49.75%] train loss: 1.4545791600539815e-05 \n",
      "epoch: 28 [443289/888800 49.88%] train loss: 1.4384160749614239e-05 \n",
      "epoch: 28 [444400/888800 50.00%] train loss: 1.3764432878815569e-05 \n",
      "epoch: 28 [445511/888800 50.12%] train loss: 1.3845499779563397e-05 \n",
      "epoch: 28 [446622/888800 50.25%] train loss: 1.4880868548061699e-05 \n",
      "epoch: 28 [447733/888800 50.38%] train loss: 1.4768831533729099e-05 \n",
      "epoch: 28 [448844/888800 50.50%] train loss: 1.4147731235425454e-05 \n",
      "epoch: 28 [449955/888800 50.62%] train loss: 1.3552230484492611e-05 \n",
      "epoch: 28 [451066/888800 50.75%] train loss: 1.435634203517111e-05 \n",
      "epoch: 28 [452177/888800 50.88%] train loss: 1.3596406461147126e-05 \n",
      "epoch: 28 [453288/888800 51.00%] train loss: 1.4744022337254137e-05 \n",
      "epoch: 28 [454399/888800 51.12%] train loss: 1.37988190545002e-05 \n",
      "epoch: 28 [455510/888800 51.25%] train loss: 1.5421910575241782e-05 \n",
      "epoch: 28 [456621/888800 51.38%] train loss: 1.4651878700533416e-05 \n",
      "epoch: 28 [457732/888800 51.50%] train loss: 1.4827180166321341e-05 \n",
      "epoch: 28 [458843/888800 51.62%] train loss: 1.3780985682387836e-05 \n",
      "epoch: 28 [459954/888800 51.75%] train loss: 1.5438828995684162e-05 \n",
      "epoch: 28 [461065/888800 51.88%] train loss: 1.4697963706566952e-05 \n",
      "epoch: 28 [462176/888800 52.00%] train loss: 1.4127595022728201e-05 \n",
      "epoch: 28 [463287/888800 52.12%] train loss: 1.3897018106945325e-05 \n",
      "epoch: 28 [464398/888800 52.25%] train loss: 1.366057313134661e-05 \n",
      "epoch: 28 [465509/888800 52.38%] train loss: 1.4102631212153938e-05 \n",
      "epoch: 28 [466620/888800 52.50%] train loss: 1.4057403859624173e-05 \n",
      "epoch: 28 [467731/888800 52.62%] train loss: 1.648656507313717e-05 \n",
      "epoch: 28 [468842/888800 52.75%] train loss: 1.3566283996624406e-05 \n",
      "epoch: 28 [469953/888800 52.88%] train loss: 1.4930555153114256e-05 \n",
      "epoch: 28 [471064/888800 53.00%] train loss: 1.720858745102305e-05 \n",
      "epoch: 28 [472175/888800 53.12%] train loss: 1.4980109881435055e-05 \n",
      "epoch: 28 [473286/888800 53.25%] train loss: 1.3427877092908602e-05 \n",
      "epoch: 28 [474397/888800 53.38%] train loss: 1.3568272152042482e-05 \n",
      "epoch: 28 [475508/888800 53.50%] train loss: 1.4726676454301924e-05 \n",
      "epoch: 28 [476619/888800 53.62%] train loss: 1.4469219422608148e-05 \n",
      "epoch: 28 [477730/888800 53.75%] train loss: 1.3607726032205392e-05 \n",
      "epoch: 28 [478841/888800 53.88%] train loss: 1.3790351658826694e-05 \n",
      "epoch: 28 [479952/888800 54.00%] train loss: 1.3971151929581538e-05 \n",
      "epoch: 28 [481063/888800 54.12%] train loss: 1.364376748824725e-05 \n",
      "epoch: 28 [482174/888800 54.25%] train loss: 1.4549587831425015e-05 \n",
      "epoch: 28 [483285/888800 54.38%] train loss: 1.3288851732795592e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [484396/888800 54.50%] train loss: 1.364064337394666e-05 \n",
      "epoch: 28 [485507/888800 54.62%] train loss: 1.4523165191349108e-05 \n",
      "epoch: 28 [486618/888800 54.75%] train loss: 1.3937775293015875e-05 \n",
      "epoch: 28 [487729/888800 54.88%] train loss: 1.469466951675713e-05 \n",
      "epoch: 28 [488840/888800 55.00%] train loss: 1.4358141015691217e-05 \n",
      "epoch: 28 [489951/888800 55.12%] train loss: 1.4356645806401502e-05 \n",
      "epoch: 28 [491062/888800 55.25%] train loss: 1.3406373909674585e-05 \n",
      "epoch: 28 [492173/888800 55.38%] train loss: 1.492044157203054e-05 \n",
      "epoch: 28 [493284/888800 55.50%] train loss: 1.3821364518662449e-05 \n",
      "epoch: 28 [494395/888800 55.62%] train loss: 1.4617358829127625e-05 \n",
      "epoch: 28 [495506/888800 55.75%] train loss: 1.3983609278511722e-05 \n",
      "epoch: 28 [496617/888800 55.88%] train loss: 1.3741955626755953e-05 \n",
      "epoch: 28 [497728/888800 56.00%] train loss: 1.432933277101256e-05 \n",
      "epoch: 28 [498839/888800 56.12%] train loss: 1.2855500244768336e-05 \n",
      "epoch: 28 [499950/888800 56.25%] train loss: 1.41164109663805e-05 \n",
      "epoch: 28 [501061/888800 56.38%] train loss: 1.391089699609438e-05 \n",
      "epoch: 28 [502172/888800 56.50%] train loss: 1.4105714399192948e-05 \n",
      "epoch: 28 [503283/888800 56.62%] train loss: 1.5034249372547492e-05 \n",
      "epoch: 28 [504394/888800 56.75%] train loss: 1.4490500689134933e-05 \n",
      "epoch: 28 [505505/888800 56.88%] train loss: 1.3331335139810108e-05 \n",
      "epoch: 28 [506616/888800 57.00%] train loss: 1.3730926184507553e-05 \n",
      "epoch: 28 [507727/888800 57.12%] train loss: 1.4125699635769706e-05 \n",
      "epoch: 28 [508838/888800 57.25%] train loss: 1.6175683413166553e-05 \n",
      "epoch: 28 [509949/888800 57.38%] train loss: 1.4777391697862186e-05 \n",
      "epoch: 28 [511060/888800 57.50%] train loss: 1.3094794667267706e-05 \n",
      "epoch: 28 [512171/888800 57.62%] train loss: 1.510756464995211e-05 \n",
      "epoch: 28 [513282/888800 57.75%] train loss: 1.39874455271638e-05 \n",
      "epoch: 28 [514393/888800 57.88%] train loss: 1.3620644494949374e-05 \n",
      "epoch: 28 [515504/888800 58.00%] train loss: 1.4023608855495695e-05 \n",
      "epoch: 28 [516615/888800 58.12%] train loss: 1.4937053492758423e-05 \n",
      "epoch: 28 [517726/888800 58.25%] train loss: 1.5802104826434515e-05 \n",
      "epoch: 28 [518837/888800 58.38%] train loss: 1.4223018297343515e-05 \n",
      "epoch: 28 [519948/888800 58.50%] train loss: 1.3885535736335441e-05 \n",
      "epoch: 28 [521059/888800 58.62%] train loss: 1.3251115888124332e-05 \n",
      "epoch: 28 [522170/888800 58.75%] train loss: 1.4498400560114533e-05 \n",
      "epoch: 28 [523281/888800 58.88%] train loss: 1.4606697732233442e-05 \n",
      "epoch: 28 [524392/888800 59.00%] train loss: 1.4462077160715126e-05 \n",
      "epoch: 28 [525503/888800 59.12%] train loss: 1.468238860979909e-05 \n",
      "epoch: 28 [526614/888800 59.25%] train loss: 1.4178229321260005e-05 \n",
      "epoch: 28 [527725/888800 59.38%] train loss: 1.456571408198215e-05 \n",
      "epoch: 28 [528836/888800 59.50%] train loss: 1.392451213177992e-05 \n",
      "epoch: 28 [529947/888800 59.62%] train loss: 1.4842737073195167e-05 \n",
      "epoch: 28 [531058/888800 59.75%] train loss: 1.3992764252179768e-05 \n",
      "epoch: 28 [532169/888800 59.88%] train loss: 1.4357899999595247e-05 \n",
      "epoch: 28 [533280/888800 60.00%] train loss: 1.435809099348262e-05 \n",
      "epoch: 28 [534391/888800 60.12%] train loss: 1.4582634321413934e-05 \n",
      "epoch: 28 [535502/888800 60.25%] train loss: 1.4006459423399065e-05 \n",
      "epoch: 28 [536613/888800 60.38%] train loss: 1.56018249981571e-05 \n",
      "epoch: 28 [537724/888800 60.50%] train loss: 1.5069534128997475e-05 \n",
      "epoch: 28 [538835/888800 60.62%] train loss: 1.4502757039736025e-05 \n",
      "epoch: 28 [539946/888800 60.75%] train loss: 1.3615810530609451e-05 \n",
      "epoch: 28 [541057/888800 60.88%] train loss: 1.407885520166019e-05 \n",
      "epoch: 28 [542168/888800 61.00%] train loss: 1.3936104551248718e-05 \n",
      "epoch: 28 [543279/888800 61.12%] train loss: 1.4584763448510785e-05 \n",
      "epoch: 28 [544390/888800 61.25%] train loss: 1.392408648825949e-05 \n",
      "epoch: 28 [545501/888800 61.38%] train loss: 1.3992516869620886e-05 \n",
      "epoch: 28 [546612/888800 61.50%] train loss: 1.4200569239619654e-05 \n",
      "epoch: 28 [547723/888800 61.62%] train loss: 1.383051676384639e-05 \n",
      "epoch: 28 [548834/888800 61.75%] train loss: 1.3408909580903128e-05 \n",
      "epoch: 28 [549945/888800 61.88%] train loss: 1.455913206882542e-05 \n",
      "epoch: 28 [551056/888800 62.00%] train loss: 1.4825869584456086e-05 \n",
      "epoch: 28 [552167/888800 62.12%] train loss: 1.3663334357261192e-05 \n",
      "epoch: 28 [553278/888800 62.25%] train loss: 1.4889925296301953e-05 \n",
      "epoch: 28 [554389/888800 62.38%] train loss: 1.3883753126719967e-05 \n",
      "epoch: 28 [555500/888800 62.50%] train loss: 1.596028778294567e-05 \n",
      "epoch: 28 [556611/888800 62.62%] train loss: 1.554829577798955e-05 \n",
      "epoch: 28 [557722/888800 62.75%] train loss: 1.5243748748616781e-05 \n",
      "epoch: 28 [558833/888800 62.88%] train loss: 1.4894453670422081e-05 \n",
      "epoch: 28 [559944/888800 63.00%] train loss: 1.3646032130054664e-05 \n",
      "epoch: 28 [561055/888800 63.12%] train loss: 1.3757691704086028e-05 \n",
      "epoch: 28 [562166/888800 63.25%] train loss: 1.4771811038372107e-05 \n",
      "epoch: 28 [563277/888800 63.38%] train loss: 1.4411219126486685e-05 \n",
      "epoch: 28 [564388/888800 63.50%] train loss: 1.3388192201091442e-05 \n",
      "epoch: 28 [565499/888800 63.62%] train loss: 1.5749244994367473e-05 \n",
      "epoch: 28 [566610/888800 63.75%] train loss: 1.3774828403256834e-05 \n",
      "epoch: 28 [567721/888800 63.88%] train loss: 1.4511514564219397e-05 \n",
      "epoch: 28 [568832/888800 64.00%] train loss: 1.4370559256349225e-05 \n",
      "epoch: 28 [569943/888800 64.12%] train loss: 1.2430918104655575e-05 \n",
      "epoch: 28 [571054/888800 64.25%] train loss: 1.469145263399696e-05 \n",
      "epoch: 28 [572165/888800 64.38%] train loss: 1.4479258425126318e-05 \n",
      "epoch: 28 [573276/888800 64.50%] train loss: 1.4498121345241088e-05 \n",
      "epoch: 28 [574387/888800 64.62%] train loss: 1.4049091078049969e-05 \n",
      "epoch: 28 [575498/888800 64.75%] train loss: 1.459818122384604e-05 \n",
      "epoch: 28 [576609/888800 64.88%] train loss: 1.2599134606716689e-05 \n",
      "epoch: 28 [577720/888800 65.00%] train loss: 1.5228340089379344e-05 \n",
      "epoch: 28 [578831/888800 65.12%] train loss: 1.4093558093009051e-05 \n",
      "epoch: 28 [579942/888800 65.25%] train loss: 1.5147640624491032e-05 \n",
      "epoch: 28 [581053/888800 65.38%] train loss: 1.5317322322516702e-05 \n",
      "epoch: 28 [582164/888800 65.50%] train loss: 1.4344808732857928e-05 \n",
      "epoch: 28 [583275/888800 65.62%] train loss: 1.4887618817738257e-05 \n",
      "epoch: 28 [584386/888800 65.75%] train loss: 1.43366378324572e-05 \n",
      "epoch: 28 [585497/888800 65.88%] train loss: 1.4224422557163052e-05 \n",
      "epoch: 28 [586608/888800 66.00%] train loss: 1.3977339222037699e-05 \n",
      "epoch: 28 [587719/888800 66.12%] train loss: 1.3027124623476993e-05 \n",
      "epoch: 28 [588830/888800 66.25%] train loss: 1.4841751180938445e-05 \n",
      "epoch: 28 [589941/888800 66.38%] train loss: 1.5165442164288834e-05 \n",
      "epoch: 28 [591052/888800 66.50%] train loss: 1.4957097846490797e-05 \n",
      "epoch: 28 [592163/888800 66.62%] train loss: 1.4020261005498469e-05 \n",
      "epoch: 28 [593274/888800 66.75%] train loss: 1.4328667020890862e-05 \n",
      "epoch: 28 [594385/888800 66.88%] train loss: 1.5633720977348275e-05 \n",
      "epoch: 28 [595496/888800 67.00%] train loss: 1.5752884792163968e-05 \n",
      "epoch: 28 [596607/888800 67.12%] train loss: 1.448538932891097e-05 \n",
      "epoch: 28 [597718/888800 67.25%] train loss: 1.3288330592331477e-05 \n",
      "epoch: 28 [598829/888800 67.38%] train loss: 1.5076275303727016e-05 \n",
      "epoch: 28 [599940/888800 67.50%] train loss: 1.2604889889189508e-05 \n",
      "epoch: 28 [601051/888800 67.62%] train loss: 1.4386058865056839e-05 \n",
      "epoch: 28 [602162/888800 67.75%] train loss: 1.3989293620397802e-05 \n",
      "epoch: 28 [603273/888800 67.88%] train loss: 1.4825190191913862e-05 \n",
      "epoch: 28 [604384/888800 68.00%] train loss: 1.590497231518384e-05 \n",
      "epoch: 28 [605495/888800 68.12%] train loss: 1.4061561159905978e-05 \n",
      "epoch: 28 [606606/888800 68.25%] train loss: 1.6007117665139958e-05 \n",
      "epoch: 28 [607717/888800 68.38%] train loss: 1.5072434507601429e-05 \n",
      "epoch: 28 [608828/888800 68.50%] train loss: 1.3996862435305957e-05 \n",
      "epoch: 28 [609939/888800 68.62%] train loss: 1.4150045899441466e-05 \n",
      "epoch: 28 [611050/888800 68.75%] train loss: 1.3661469893122558e-05 \n",
      "epoch: 28 [612161/888800 68.88%] train loss: 1.3910660527471919e-05 \n",
      "epoch: 28 [613272/888800 69.00%] train loss: 1.3013637726544403e-05 \n",
      "epoch: 28 [614383/888800 69.12%] train loss: 1.4269666280597448e-05 \n",
      "epoch: 28 [615494/888800 69.25%] train loss: 1.6127140042954125e-05 \n",
      "epoch: 28 [616605/888800 69.38%] train loss: 1.480545415688539e-05 \n",
      "epoch: 28 [617716/888800 69.50%] train loss: 1.3660222975886427e-05 \n",
      "epoch: 28 [618827/888800 69.62%] train loss: 1.5610083210049197e-05 \n",
      "epoch: 28 [619938/888800 69.75%] train loss: 1.3513141311705112e-05 \n",
      "epoch: 28 [621049/888800 69.88%] train loss: 1.510529182269238e-05 \n",
      "epoch: 28 [622160/888800 70.00%] train loss: 1.3587686225946527e-05 \n",
      "epoch: 28 [623271/888800 70.12%] train loss: 1.4819194802839775e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [624382/888800 70.25%] train loss: 1.4118651051830966e-05 \n",
      "epoch: 28 [625493/888800 70.38%] train loss: 1.4993653167039156e-05 \n",
      "epoch: 28 [626604/888800 70.50%] train loss: 1.4145942259347066e-05 \n",
      "epoch: 28 [627715/888800 70.62%] train loss: 1.418583906342974e-05 \n",
      "epoch: 28 [628826/888800 70.75%] train loss: 1.5305726265069097e-05 \n",
      "epoch: 28 [629937/888800 70.88%] train loss: 1.326973688264843e-05 \n",
      "epoch: 28 [631048/888800 71.00%] train loss: 1.3171126738598105e-05 \n",
      "epoch: 28 [632159/888800 71.12%] train loss: 1.395083381794393e-05 \n",
      "epoch: 28 [633270/888800 71.25%] train loss: 1.3250878510007169e-05 \n",
      "epoch: 28 [634381/888800 71.38%] train loss: 1.2837030226364732e-05 \n",
      "epoch: 28 [635492/888800 71.50%] train loss: 1.450065610697493e-05 \n",
      "epoch: 28 [636603/888800 71.62%] train loss: 1.3511321412806865e-05 \n",
      "epoch: 28 [637714/888800 71.75%] train loss: 1.4191478840075433e-05 \n",
      "epoch: 28 [638825/888800 71.88%] train loss: 1.5636787793482654e-05 \n",
      "epoch: 28 [639936/888800 72.00%] train loss: 1.421702381776413e-05 \n",
      "epoch: 28 [641047/888800 72.12%] train loss: 1.3498995031113736e-05 \n",
      "epoch: 28 [642158/888800 72.25%] train loss: 1.3554182260122616e-05 \n",
      "epoch: 28 [643269/888800 72.38%] train loss: 1.4738458958163392e-05 \n",
      "epoch: 28 [644380/888800 72.50%] train loss: 1.4185094187268987e-05 \n",
      "epoch: 28 [645491/888800 72.62%] train loss: 1.4477715922112111e-05 \n",
      "epoch: 28 [646602/888800 72.75%] train loss: 1.3883387509849854e-05 \n",
      "epoch: 28 [647713/888800 72.88%] train loss: 1.3674673027708195e-05 \n",
      "epoch: 28 [648824/888800 73.00%] train loss: 1.2602297829289455e-05 \n",
      "epoch: 28 [649935/888800 73.12%] train loss: 1.4205632396624424e-05 \n",
      "epoch: 28 [651046/888800 73.25%] train loss: 1.5221219655359164e-05 \n",
      "epoch: 28 [652157/888800 73.38%] train loss: 1.351682294625789e-05 \n",
      "epoch: 28 [653268/888800 73.50%] train loss: 1.4650846424046904e-05 \n",
      "epoch: 28 [654379/888800 73.62%] train loss: 1.5026311302790418e-05 \n",
      "epoch: 28 [655490/888800 73.75%] train loss: 1.5827576135052368e-05 \n",
      "epoch: 28 [656601/888800 73.88%] train loss: 1.4151415598462336e-05 \n",
      "epoch: 28 [657712/888800 74.00%] train loss: 1.503199109720299e-05 \n",
      "epoch: 28 [658823/888800 74.12%] train loss: 1.560566852276679e-05 \n",
      "epoch: 28 [659934/888800 74.25%] train loss: 1.3950010725238826e-05 \n",
      "epoch: 28 [661045/888800 74.38%] train loss: 1.545028317195829e-05 \n",
      "epoch: 28 [662156/888800 74.50%] train loss: 1.4996124264143873e-05 \n",
      "epoch: 28 [663267/888800 74.62%] train loss: 1.3725694770982955e-05 \n",
      "epoch: 28 [664378/888800 74.75%] train loss: 1.4580783499695826e-05 \n",
      "epoch: 28 [665489/888800 74.88%] train loss: 1.4224853657651693e-05 \n",
      "epoch: 28 [666600/888800 75.00%] train loss: 1.34830734168645e-05 \n",
      "epoch: 28 [667711/888800 75.12%] train loss: 1.4568306141882204e-05 \n",
      "epoch: 28 [668822/888800 75.25%] train loss: 1.4466942047874909e-05 \n",
      "epoch: 28 [669933/888800 75.38%] train loss: 1.4614275642088614e-05 \n",
      "epoch: 28 [671044/888800 75.50%] train loss: 1.4757806638954207e-05 \n",
      "epoch: 28 [672155/888800 75.62%] train loss: 1.575580972712487e-05 \n",
      "epoch: 28 [673266/888800 75.75%] train loss: 1.4659044609288685e-05 \n",
      "epoch: 28 [674377/888800 75.88%] train loss: 1.5249484931700863e-05 \n",
      "epoch: 28 [675488/888800 76.00%] train loss: 1.3344902072276454e-05 \n",
      "epoch: 28 [676599/888800 76.12%] train loss: 1.4456280950980727e-05 \n",
      "epoch: 28 [677710/888800 76.25%] train loss: 1.4077442756388336e-05 \n",
      "epoch: 28 [678821/888800 76.38%] train loss: 1.568176958244294e-05 \n",
      "epoch: 28 [679932/888800 76.50%] train loss: 1.3879007383366115e-05 \n",
      "epoch: 28 [681043/888800 76.62%] train loss: 1.4775313502468634e-05 \n",
      "epoch: 28 [682154/888800 76.75%] train loss: 1.4141227438813075e-05 \n",
      "epoch: 28 [683265/888800 76.88%] train loss: 1.5113236258912366e-05 \n",
      "epoch: 28 [684376/888800 77.00%] train loss: 1.4469591405941173e-05 \n",
      "epoch: 28 [685487/888800 77.12%] train loss: 1.5126441212487407e-05 \n",
      "epoch: 28 [686598/888800 77.25%] train loss: 1.3016260709264316e-05 \n",
      "epoch: 28 [687709/888800 77.38%] train loss: 1.5609213733114302e-05 \n",
      "epoch: 28 [688820/888800 77.50%] train loss: 1.4528838619298767e-05 \n",
      "epoch: 28 [689931/888800 77.62%] train loss: 1.278896706935484e-05 \n",
      "epoch: 28 [691042/888800 77.75%] train loss: 1.551645436848048e-05 \n",
      "epoch: 28 [692153/888800 77.88%] train loss: 1.4989134797360748e-05 \n",
      "epoch: 28 [693264/888800 78.00%] train loss: 1.5585505025228485e-05 \n",
      "epoch: 28 [694375/888800 78.12%] train loss: 1.4063494745641947e-05 \n",
      "epoch: 28 [695486/888800 78.25%] train loss: 1.4398128769244067e-05 \n",
      "epoch: 28 [696597/888800 78.38%] train loss: 1.5196565982478205e-05 \n",
      "epoch: 28 [697708/888800 78.50%] train loss: 1.5941535821184516e-05 \n",
      "epoch: 28 [698819/888800 78.62%] train loss: 1.348423847957747e-05 \n",
      "epoch: 28 [699930/888800 78.75%] train loss: 1.5790630641276948e-05 \n",
      "epoch: 28 [701041/888800 78.88%] train loss: 1.6106758266687393e-05 \n",
      "epoch: 28 [702152/888800 79.00%] train loss: 1.3778767424810212e-05 \n",
      "epoch: 28 [703263/888800 79.12%] train loss: 1.469382277718978e-05 \n",
      "epoch: 28 [704374/888800 79.25%] train loss: 1.4877367902954575e-05 \n",
      "epoch: 28 [705485/888800 79.38%] train loss: 1.5401079508592375e-05 \n",
      "epoch: 28 [706596/888800 79.50%] train loss: 1.3883322026231326e-05 \n",
      "epoch: 28 [707707/888800 79.62%] train loss: 1.4255660062190145e-05 \n",
      "epoch: 28 [708818/888800 79.75%] train loss: 1.611797597433906e-05 \n",
      "epoch: 28 [709929/888800 79.88%] train loss: 1.46638230944518e-05 \n",
      "epoch: 28 [711040/888800 80.00%] train loss: 1.6111187505885027e-05 \n",
      "epoch: 28 [712151/888800 80.12%] train loss: 1.3375097296375316e-05 \n",
      "epoch: 28 [713262/888800 80.25%] train loss: 1.4788658518227749e-05 \n",
      "epoch: 28 [714373/888800 80.38%] train loss: 1.3198361557442695e-05 \n",
      "epoch: 28 [715484/888800 80.50%] train loss: 1.3572044736065436e-05 \n",
      "epoch: 28 [716595/888800 80.62%] train loss: 1.4403436580323614e-05 \n",
      "epoch: 28 [717706/888800 80.75%] train loss: 1.476959641877329e-05 \n",
      "epoch: 28 [718817/888800 80.88%] train loss: 1.6296120520564727e-05 \n",
      "epoch: 28 [719928/888800 81.00%] train loss: 1.4311043742054608e-05 \n",
      "epoch: 28 [721039/888800 81.12%] train loss: 1.5988873201422393e-05 \n",
      "epoch: 28 [722150/888800 81.25%] train loss: 1.3507838957593776e-05 \n",
      "epoch: 28 [723261/888800 81.38%] train loss: 1.3714472515857778e-05 \n",
      "epoch: 28 [724372/888800 81.50%] train loss: 1.4863794604025315e-05 \n",
      "epoch: 28 [725483/888800 81.62%] train loss: 1.4292133528215345e-05 \n",
      "epoch: 28 [726594/888800 81.75%] train loss: 1.4073772945266683e-05 \n",
      "epoch: 28 [727705/888800 81.88%] train loss: 1.3637692973134108e-05 \n",
      "epoch: 28 [728816/888800 82.00%] train loss: 1.3327552551345434e-05 \n",
      "epoch: 28 [729927/888800 82.12%] train loss: 1.493873969593551e-05 \n",
      "epoch: 28 [731038/888800 82.25%] train loss: 1.3158941328583751e-05 \n",
      "epoch: 28 [732149/888800 82.38%] train loss: 1.4323414688988123e-05 \n",
      "epoch: 28 [733260/888800 82.50%] train loss: 1.4395783182408195e-05 \n",
      "epoch: 28 [734371/888800 82.62%] train loss: 1.3360095181269571e-05 \n",
      "epoch: 28 [735482/888800 82.75%] train loss: 1.4948305761208758e-05 \n",
      "epoch: 28 [736593/888800 82.88%] train loss: 1.3757017768512014e-05 \n",
      "epoch: 28 [737704/888800 83.00%] train loss: 1.455431538488483e-05 \n",
      "epoch: 28 [738815/888800 83.12%] train loss: 1.327904192294227e-05 \n",
      "epoch: 28 [739926/888800 83.25%] train loss: 1.495739161327947e-05 \n",
      "epoch: 28 [741037/888800 83.38%] train loss: 1.3894294170313515e-05 \n",
      "epoch: 28 [742148/888800 83.50%] train loss: 1.4447959983954206e-05 \n",
      "epoch: 28 [743259/888800 83.62%] train loss: 1.4335049854707904e-05 \n",
      "epoch: 28 [744370/888800 83.75%] train loss: 1.5765150237712078e-05 \n",
      "epoch: 28 [745481/888800 83.88%] train loss: 1.5778163287905045e-05 \n",
      "epoch: 28 [746592/888800 84.00%] train loss: 1.4186202861310448e-05 \n",
      "epoch: 28 [747703/888800 84.12%] train loss: 1.527490167063661e-05 \n",
      "epoch: 28 [748814/888800 84.25%] train loss: 1.4514170288748574e-05 \n",
      "epoch: 28 [749925/888800 84.38%] train loss: 1.8706710761762224e-05 \n",
      "epoch: 28 [751036/888800 84.50%] train loss: 1.5565075955237262e-05 \n",
      "epoch: 28 [752147/888800 84.62%] train loss: 1.7383939848514274e-05 \n",
      "epoch: 28 [753258/888800 84.75%] train loss: 1.7529198885313235e-05 \n",
      "epoch: 28 [754369/888800 84.88%] train loss: 1.6359852452296764e-05 \n",
      "epoch: 28 [755480/888800 85.00%] train loss: 1.4965728951210622e-05 \n",
      "epoch: 28 [756591/888800 85.12%] train loss: 1.5840096239116974e-05 \n",
      "epoch: 28 [757702/888800 85.25%] train loss: 1.8762259060167708e-05 \n",
      "epoch: 28 [758813/888800 85.38%] train loss: 1.5824276488274336e-05 \n",
      "epoch: 28 [759924/888800 85.50%] train loss: 1.700797292869538e-05 \n",
      "epoch: 28 [761035/888800 85.62%] train loss: 1.4331725651572924e-05 \n",
      "epoch: 28 [762146/888800 85.75%] train loss: 1.8392802303424105e-05 \n",
      "epoch: 28 [763257/888800 85.88%] train loss: 1.4417729289561976e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 [764368/888800 86.00%] train loss: 1.872058965091128e-05 \n",
      "epoch: 28 [765479/888800 86.12%] train loss: 1.4296623703557998e-05 \n",
      "epoch: 28 [766590/888800 86.25%] train loss: 1.6596650311839767e-05 \n",
      "epoch: 28 [767701/888800 86.38%] train loss: 1.63078020705143e-05 \n",
      "epoch: 28 [768812/888800 86.50%] train loss: 1.557674477226101e-05 \n",
      "epoch: 28 [769923/888800 86.62%] train loss: 1.6407653674832545e-05 \n",
      "epoch: 28 [771034/888800 86.75%] train loss: 1.4699438906973228e-05 \n",
      "epoch: 28 [772145/888800 86.88%] train loss: 1.7695125279715285e-05 \n",
      "epoch: 28 [773256/888800 87.00%] train loss: 1.293848890782101e-05 \n",
      "epoch: 28 [774367/888800 87.12%] train loss: 1.6902806237339973e-05 \n",
      "epoch: 28 [775478/888800 87.25%] train loss: 1.3388194020080846e-05 \n",
      "epoch: 28 [776589/888800 87.38%] train loss: 1.5448527847183868e-05 \n",
      "epoch: 28 [777700/888800 87.50%] train loss: 1.3788336218567565e-05 \n",
      "epoch: 28 [778811/888800 87.62%] train loss: 1.7161230061901733e-05 \n",
      "epoch: 28 [779922/888800 87.75%] train loss: 1.4072616068006027e-05 \n",
      "epoch: 28 [781033/888800 87.88%] train loss: 1.6309810234815814e-05 \n",
      "epoch: 28 [782144/888800 88.00%] train loss: 1.3737920198764186e-05 \n",
      "epoch: 28 [783255/888800 88.12%] train loss: 1.5763916962896474e-05 \n",
      "epoch: 28 [784366/888800 88.25%] train loss: 1.2678851817327086e-05 \n",
      "epoch: 28 [785477/888800 88.38%] train loss: 1.5527240975643508e-05 \n",
      "epoch: 28 [786588/888800 88.50%] train loss: 1.5200832422124222e-05 \n",
      "epoch: 28 [787699/888800 88.62%] train loss: 1.3443411262414884e-05 \n",
      "epoch: 28 [788810/888800 88.75%] train loss: 1.4274341992859263e-05 \n",
      "epoch: 28 [789921/888800 88.88%] train loss: 1.4226038729248103e-05 \n",
      "epoch: 28 [791032/888800 89.00%] train loss: 1.5046711268951185e-05 \n",
      "epoch: 28 [792143/888800 89.12%] train loss: 1.3113107343087904e-05 \n",
      "epoch: 28 [793254/888800 89.25%] train loss: 1.4123370419838466e-05 \n",
      "epoch: 28 [794365/888800 89.38%] train loss: 1.4437810932577122e-05 \n",
      "epoch: 28 [795476/888800 89.50%] train loss: 1.4413768440135755e-05 \n",
      "epoch: 28 [796587/888800 89.62%] train loss: 1.399624852638226e-05 \n",
      "epoch: 28 [797698/888800 89.75%] train loss: 1.5111993889149744e-05 \n",
      "epoch: 28 [798809/888800 89.88%] train loss: 1.395417348248884e-05 \n",
      "epoch: 28 [799920/888800 90.00%] train loss: 1.4119965271675028e-05 \n",
      "epoch: 28 [801031/888800 90.12%] train loss: 1.4695486242999323e-05 \n",
      "epoch: 28 [802142/888800 90.25%] train loss: 1.4064151400816627e-05 \n",
      "epoch: 28 [803253/888800 90.38%] train loss: 1.4277733498602174e-05 \n",
      "epoch: 28 [804364/888800 90.50%] train loss: 1.50217874761438e-05 \n",
      "epoch: 28 [805475/888800 90.62%] train loss: 1.2832060747314245e-05 \n",
      "epoch: 28 [806586/888800 90.75%] train loss: 1.4314054169517476e-05 \n",
      "epoch: 28 [807697/888800 90.88%] train loss: 1.3039253644819837e-05 \n",
      "epoch: 28 [808808/888800 91.00%] train loss: 1.3511043107428122e-05 \n",
      "epoch: 28 [809919/888800 91.12%] train loss: 1.378406068397453e-05 \n",
      "epoch: 28 [811030/888800 91.25%] train loss: 1.6273157598334365e-05 \n",
      "epoch: 28 [812141/888800 91.38%] train loss: 1.3737574590777513e-05 \n",
      "epoch: 28 [813252/888800 91.50%] train loss: 1.4508846106764395e-05 \n",
      "epoch: 28 [814363/888800 91.62%] train loss: 1.5407291357405484e-05 \n",
      "epoch: 28 [815474/888800 91.75%] train loss: 1.505909222032642e-05 \n",
      "epoch: 28 [816585/888800 91.88%] train loss: 1.65807650773786e-05 \n",
      "epoch: 28 [817696/888800 92.00%] train loss: 1.5141900803428143e-05 \n",
      "epoch: 28 [818807/888800 92.12%] train loss: 1.5880408682278357e-05 \n",
      "epoch: 28 [819918/888800 92.25%] train loss: 1.4532331078953575e-05 \n",
      "epoch: 28 [821029/888800 92.38%] train loss: 1.3631359252030961e-05 \n",
      "epoch: 28 [822140/888800 92.50%] train loss: 1.2863695701526012e-05 \n",
      "epoch: 28 [823251/888800 92.62%] train loss: 1.432761473552091e-05 \n",
      "epoch: 28 [824362/888800 92.75%] train loss: 1.5876215911703184e-05 \n",
      "epoch: 28 [825473/888800 92.88%] train loss: 1.4063645721762441e-05 \n",
      "epoch: 28 [826584/888800 93.00%] train loss: 1.3847080481355079e-05 \n",
      "epoch: 28 [827695/888800 93.12%] train loss: 1.3427206795313396e-05 \n",
      "epoch: 28 [828806/888800 93.25%] train loss: 1.4354932318383362e-05 \n",
      "epoch: 28 [829917/888800 93.38%] train loss: 1.5102743418538012e-05 \n",
      "epoch: 28 [831028/888800 93.50%] train loss: 1.3434166248771362e-05 \n",
      "epoch: 28 [832139/888800 93.62%] train loss: 1.3963969649921637e-05 \n",
      "epoch: 28 [833250/888800 93.75%] train loss: 1.3927433428762015e-05 \n",
      "epoch: 28 [834361/888800 93.88%] train loss: 1.4245692909753416e-05 \n",
      "epoch: 28 [835472/888800 94.00%] train loss: 1.421233537257649e-05 \n",
      "epoch: 28 [836583/888800 94.12%] train loss: 1.4383542293217033e-05 \n",
      "epoch: 28 [837694/888800 94.25%] train loss: 1.373728628095705e-05 \n",
      "epoch: 28 [838805/888800 94.38%] train loss: 1.5335146599682048e-05 \n",
      "epoch: 28 [839916/888800 94.50%] train loss: 1.4103821740718558e-05 \n",
      "epoch: 28 [841027/888800 94.62%] train loss: 1.4567474863724783e-05 \n",
      "epoch: 28 [842138/888800 94.75%] train loss: 1.3494830454874318e-05 \n",
      "epoch: 28 [843249/888800 94.88%] train loss: 1.3858892998541705e-05 \n",
      "epoch: 28 [844360/888800 95.00%] train loss: 1.463834269088693e-05 \n",
      "epoch: 28 [845471/888800 95.12%] train loss: 1.2930586308357306e-05 \n",
      "epoch: 28 [846582/888800 95.25%] train loss: 1.5120835087145679e-05 \n",
      "epoch: 28 [847693/888800 95.38%] train loss: 1.2822221833630465e-05 \n",
      "epoch: 28 [848804/888800 95.50%] train loss: 1.3605892490886617e-05 \n",
      "epoch: 28 [849915/888800 95.62%] train loss: 1.417313251295127e-05 \n",
      "epoch: 28 [851026/888800 95.75%] train loss: 1.3457247405312955e-05 \n",
      "epoch: 28 [852137/888800 95.88%] train loss: 1.5557845472358167e-05 \n",
      "epoch: 28 [853248/888800 96.00%] train loss: 1.3932507499703206e-05 \n",
      "epoch: 28 [854359/888800 96.12%] train loss: 1.4178341189108323e-05 \n",
      "epoch: 28 [855470/888800 96.25%] train loss: 1.4660516171716154e-05 \n",
      "epoch: 28 [856581/888800 96.38%] train loss: 1.4057477528695017e-05 \n",
      "epoch: 28 [857692/888800 96.50%] train loss: 1.485803113610018e-05 \n",
      "epoch: 28 [858803/888800 96.62%] train loss: 1.40117099363124e-05 \n",
      "epoch: 28 [859914/888800 96.75%] train loss: 1.3989919352752622e-05 \n",
      "epoch: 28 [861025/888800 96.88%] train loss: 1.3473179933498614e-05 \n",
      "epoch: 28 [862136/888800 97.00%] train loss: 1.5300753148039803e-05 \n",
      "epoch: 28 [863247/888800 97.12%] train loss: 1.3593004950962495e-05 \n",
      "epoch: 28 [864358/888800 97.25%] train loss: 1.5066492778714746e-05 \n",
      "epoch: 28 [865469/888800 97.38%] train loss: 1.5038503988762386e-05 \n",
      "epoch: 28 [866580/888800 97.50%] train loss: 1.3994107575854287e-05 \n",
      "epoch: 28 [867691/888800 97.62%] train loss: 1.2767676707881037e-05 \n",
      "epoch: 28 [868802/888800 97.75%] train loss: 1.3929541637480725e-05 \n",
      "epoch: 28 [869913/888800 97.88%] train loss: 1.3245911759440787e-05 \n",
      "epoch: 28 [871024/888800 98.00%] train loss: 1.3188700904720463e-05 \n",
      "epoch: 28 [872135/888800 98.12%] train loss: 1.4642650967289228e-05 \n",
      "epoch: 28 [873246/888800 98.25%] train loss: 1.3556284102378413e-05 \n",
      "epoch: 28 [874357/888800 98.38%] train loss: 1.4605813703383319e-05 \n",
      "epoch: 28 [875468/888800 98.50%] train loss: 1.5873456504778005e-05 \n",
      "epoch: 28 [876579/888800 98.62%] train loss: 1.3180781934352126e-05 \n",
      "epoch: 28 [877690/888800 98.75%] train loss: 1.3846045476384461e-05 \n",
      "epoch: 28 [878801/888800 98.88%] train loss: 1.2204259292047936e-05 \n",
      "epoch: 28 [879912/888800 99.00%] train loss: 1.4070029465074185e-05 \n",
      "epoch: 28 [881023/888800 99.12%] train loss: 1.343063559033908e-05 \n",
      "epoch: 28 [882134/888800 99.25%] train loss: 1.4377674233401194e-05 \n",
      "epoch: 28 [883245/888800 99.38%] train loss: 1.4829863175691571e-05 \n",
      "epoch: 28 [884356/888800 99.50%] train loss: 1.476247598475311e-05 \n",
      "epoch: 28 [885467/888800 99.62%] train loss: 1.3430669241643045e-05 \n",
      "epoch: 28 [886578/888800 99.75%] train loss: 1.3273865079099778e-05 \n",
      "epoch: 28 [887689/888800 99.88%] train loss: 1.445388716092566e-05 \n",
      "epoch: 29 [0/888800 0.00%] train loss: 1.3509996279026382e-05 \n",
      "epoch: 29 [1111/888800 0.12%] train loss: 1.3401032447291072e-05 \n",
      "epoch: 29 [2222/888800 0.25%] train loss: 1.5119314412004314e-05 \n",
      "epoch: 29 [3333/888800 0.38%] train loss: 1.4433954675041605e-05 \n",
      "epoch: 29 [4444/888800 0.50%] train loss: 1.5023886589915492e-05 \n",
      "epoch: 29 [5555/888800 0.62%] train loss: 1.3277284779178444e-05 \n",
      "epoch: 29 [6666/888800 0.75%] train loss: 1.3859363207302522e-05 \n",
      "epoch: 29 [7777/888800 0.88%] train loss: 1.4571414794772863e-05 \n",
      "epoch: 29 [8888/888800 1.00%] train loss: 1.3047592801740393e-05 \n",
      "epoch: 29 [9999/888800 1.12%] train loss: 1.3920466699346434e-05 \n",
      "epoch: 29 [11110/888800 1.25%] train loss: 1.4405954061658122e-05 \n",
      "epoch: 29 [12221/888800 1.38%] train loss: 1.4478091543423943e-05 \n",
      "epoch: 29 [13332/888800 1.50%] train loss: 1.4090882359596435e-05 \n",
      "epoch: 29 [14443/888800 1.62%] train loss: 1.215132033394184e-05 \n",
      "epoch: 29 [15554/888800 1.75%] train loss: 1.4464087144006044e-05 \n",
      "epoch: 29 [16665/888800 1.88%] train loss: 1.3899893019697629e-05 \n",
      "epoch: 29 [17776/888800 2.00%] train loss: 1.4674377780465875e-05 \n",
      "epoch: 29 [18887/888800 2.12%] train loss: 1.4943182577553671e-05 \n",
      "epoch: 29 [19998/888800 2.25%] train loss: 1.4548842045769561e-05 \n",
      "epoch: 29 [21109/888800 2.38%] train loss: 1.3854620192432776e-05 \n",
      "epoch: 29 [22220/888800 2.50%] train loss: 1.3310896974871866e-05 \n",
      "epoch: 29 [23331/888800 2.62%] train loss: 1.4031486898602452e-05 \n",
      "epoch: 29 [24442/888800 2.75%] train loss: 1.3392877008300275e-05 \n",
      "epoch: 29 [25553/888800 2.88%] train loss: 1.412044366588816e-05 \n",
      "epoch: 29 [26664/888800 3.00%] train loss: 1.4062530681258067e-05 \n",
      "epoch: 29 [27775/888800 3.12%] train loss: 1.4020054550201166e-05 \n",
      "epoch: 29 [28886/888800 3.25%] train loss: 1.4034159903530963e-05 \n",
      "epoch: 29 [29997/888800 3.38%] train loss: 1.536706622573547e-05 \n",
      "epoch: 29 [31108/888800 3.50%] train loss: 1.2828310900658835e-05 \n",
      "epoch: 29 [32219/888800 3.62%] train loss: 1.4497083611786366e-05 \n",
      "epoch: 29 [33330/888800 3.75%] train loss: 1.3465702068060637e-05 \n",
      "epoch: 29 [34441/888800 3.88%] train loss: 1.4440628547163215e-05 \n",
      "epoch: 29 [35552/888800 4.00%] train loss: 1.4241704775486141e-05 \n",
      "epoch: 29 [36663/888800 4.12%] train loss: 1.4497758456855081e-05 \n",
      "epoch: 29 [37774/888800 4.25%] train loss: 1.511778373242123e-05 \n",
      "epoch: 29 [38885/888800 4.38%] train loss: 1.4695317986479495e-05 \n",
      "epoch: 29 [39996/888800 4.50%] train loss: 1.3194893654144835e-05 \n",
      "epoch: 29 [41107/888800 4.62%] train loss: 1.3296015822561458e-05 \n",
      "epoch: 29 [42218/888800 4.75%] train loss: 1.542431527923327e-05 \n",
      "epoch: 29 [43329/888800 4.88%] train loss: 1.4212727364792954e-05 \n",
      "epoch: 29 [44440/888800 5.00%] train loss: 1.3323990970093291e-05 \n",
      "epoch: 29 [45551/888800 5.12%] train loss: 1.434929890820058e-05 \n",
      "epoch: 29 [46662/888800 5.25%] train loss: 1.426629660272738e-05 \n",
      "epoch: 29 [47773/888800 5.38%] train loss: 1.5527044524787925e-05 \n",
      "epoch: 29 [48884/888800 5.50%] train loss: 1.3859556020179298e-05 \n",
      "epoch: 29 [49995/888800 5.62%] train loss: 1.441406857338734e-05 \n",
      "epoch: 29 [51106/888800 5.75%] train loss: 1.3781148481939454e-05 \n",
      "epoch: 29 [52217/888800 5.88%] train loss: 1.4903374903951772e-05 \n",
      "epoch: 29 [53328/888800 6.00%] train loss: 1.554142181703355e-05 \n",
      "epoch: 29 [54439/888800 6.12%] train loss: 1.5002918189566117e-05 \n",
      "epoch: 29 [55550/888800 6.25%] train loss: 1.4524189282383304e-05 \n",
      "epoch: 29 [56661/888800 6.38%] train loss: 1.4816301700193435e-05 \n",
      "epoch: 29 [57772/888800 6.50%] train loss: 1.3730166756431572e-05 \n",
      "epoch: 29 [58883/888800 6.62%] train loss: 1.4808992091275286e-05 \n",
      "epoch: 29 [59994/888800 6.75%] train loss: 1.3664387552125845e-05 \n",
      "epoch: 29 [61105/888800 6.88%] train loss: 1.5760204405523837e-05 \n",
      "epoch: 29 [62216/888800 7.00%] train loss: 1.5164247088250704e-05 \n",
      "epoch: 29 [63327/888800 7.12%] train loss: 1.3571920135291293e-05 \n",
      "epoch: 29 [64438/888800 7.25%] train loss: 1.3608100744022522e-05 \n",
      "epoch: 29 [65549/888800 7.38%] train loss: 1.511017035227269e-05 \n",
      "epoch: 29 [66660/888800 7.50%] train loss: 1.5979763702489436e-05 \n",
      "epoch: 29 [67771/888800 7.62%] train loss: 1.4892986655468121e-05 \n",
      "epoch: 29 [68882/888800 7.75%] train loss: 1.5348225133493543e-05 \n",
      "epoch: 29 [69993/888800 7.88%] train loss: 1.571686880197376e-05 \n",
      "epoch: 29 [71104/888800 8.00%] train loss: 1.5023717423900962e-05 \n",
      "epoch: 29 [72215/888800 8.12%] train loss: 1.4291040315583814e-05 \n",
      "epoch: 29 [73326/888800 8.25%] train loss: 1.4268224731495138e-05 \n",
      "epoch: 29 [74437/888800 8.38%] train loss: 1.3446810953610111e-05 \n",
      "epoch: 29 [75548/888800 8.50%] train loss: 1.4045853276911657e-05 \n",
      "epoch: 29 [76659/888800 8.62%] train loss: 1.3428812053462025e-05 \n",
      "epoch: 29 [77770/888800 8.75%] train loss: 1.3645877515955362e-05 \n",
      "epoch: 29 [78881/888800 8.88%] train loss: 1.4384278074430767e-05 \n",
      "epoch: 29 [79992/888800 9.00%] train loss: 1.4067377378523815e-05 \n",
      "epoch: 29 [81103/888800 9.12%] train loss: 1.4121364074526355e-05 \n",
      "epoch: 29 [82214/888800 9.25%] train loss: 1.5131046893657185e-05 \n",
      "epoch: 29 [83325/888800 9.38%] train loss: 1.4987574104452506e-05 \n",
      "epoch: 29 [84436/888800 9.50%] train loss: 1.5145352335821372e-05 \n",
      "epoch: 29 [85547/888800 9.62%] train loss: 1.4925039067748003e-05 \n",
      "epoch: 29 [86658/888800 9.75%] train loss: 1.3758132809016388e-05 \n",
      "epoch: 29 [87769/888800 9.88%] train loss: 1.4170431313687004e-05 \n",
      "epoch: 29 [88880/888800 10.00%] train loss: 1.2780750694219023e-05 \n",
      "epoch: 29 [89991/888800 10.12%] train loss: 1.3419699826044962e-05 \n",
      "epoch: 29 [91102/888800 10.25%] train loss: 1.3266792848298792e-05 \n",
      "epoch: 29 [92213/888800 10.38%] train loss: 1.3617906006402336e-05 \n",
      "epoch: 29 [93324/888800 10.50%] train loss: 1.3972869965073187e-05 \n",
      "epoch: 29 [94435/888800 10.62%] train loss: 1.562996840220876e-05 \n",
      "epoch: 29 [95546/888800 10.75%] train loss: 1.3676326489076018e-05 \n",
      "epoch: 29 [96657/888800 10.88%] train loss: 1.4654840015282389e-05 \n",
      "epoch: 29 [97768/888800 11.00%] train loss: 1.3733886589761823e-05 \n",
      "epoch: 29 [98879/888800 11.12%] train loss: 1.4658863619843032e-05 \n",
      "epoch: 29 [99990/888800 11.25%] train loss: 1.6153706383192912e-05 \n",
      "epoch: 29 [101101/888800 11.38%] train loss: 1.252365382242715e-05 \n",
      "epoch: 29 [102212/888800 11.50%] train loss: 1.3679363291885238e-05 \n",
      "epoch: 29 [103323/888800 11.62%] train loss: 1.4467897926806472e-05 \n",
      "epoch: 29 [104434/888800 11.75%] train loss: 1.3535102880268823e-05 \n",
      "epoch: 29 [105545/888800 11.88%] train loss: 1.4206115338311065e-05 \n",
      "epoch: 29 [106656/888800 12.00%] train loss: 1.4376767467183527e-05 \n",
      "epoch: 29 [107767/888800 12.12%] train loss: 1.345930650131777e-05 \n",
      "epoch: 29 [108878/888800 12.25%] train loss: 1.4034992091183085e-05 \n",
      "epoch: 29 [109989/888800 12.38%] train loss: 1.3883858628105372e-05 \n",
      "epoch: 29 [111100/888800 12.50%] train loss: 1.3949834283266682e-05 \n",
      "epoch: 29 [112211/888800 12.62%] train loss: 1.5061793419590686e-05 \n",
      "epoch: 29 [113322/888800 12.75%] train loss: 1.4278699381975457e-05 \n",
      "epoch: 29 [114433/888800 12.88%] train loss: 1.4731870578543749e-05 \n",
      "epoch: 29 [115544/888800 13.00%] train loss: 1.4645592273154762e-05 \n",
      "epoch: 29 [116655/888800 13.12%] train loss: 1.319719467574032e-05 \n",
      "epoch: 29 [117766/888800 13.25%] train loss: 1.357444216409931e-05 \n",
      "epoch: 29 [118877/888800 13.38%] train loss: 1.4779730918235146e-05 \n",
      "epoch: 29 [119988/888800 13.50%] train loss: 1.3450146070681512e-05 \n",
      "epoch: 29 [121099/888800 13.62%] train loss: 1.3312906958162785e-05 \n",
      "epoch: 29 [122210/888800 13.75%] train loss: 1.4677882063551806e-05 \n",
      "epoch: 29 [123321/888800 13.88%] train loss: 1.4466598258877639e-05 \n",
      "epoch: 29 [124432/888800 14.00%] train loss: 1.4581322830053978e-05 \n",
      "epoch: 29 [125543/888800 14.12%] train loss: 1.4516162082145456e-05 \n",
      "epoch: 29 [126654/888800 14.25%] train loss: 1.482694369769888e-05 \n",
      "epoch: 29 [127765/888800 14.38%] train loss: 1.3333296919881832e-05 \n",
      "epoch: 29 [128876/888800 14.50%] train loss: 1.3464566109178122e-05 \n",
      "epoch: 29 [129987/888800 14.62%] train loss: 1.404751128575299e-05 \n",
      "epoch: 29 [131098/888800 14.75%] train loss: 1.3364138794713654e-05 \n",
      "epoch: 29 [132209/888800 14.88%] train loss: 1.4622000890085474e-05 \n",
      "epoch: 29 [133320/888800 15.00%] train loss: 1.2741993486997671e-05 \n",
      "epoch: 29 [134431/888800 15.12%] train loss: 1.3472596947394777e-05 \n",
      "epoch: 29 [135542/888800 15.25%] train loss: 1.4418005775951315e-05 \n",
      "epoch: 29 [136653/888800 15.38%] train loss: 1.5349067325587384e-05 \n",
      "epoch: 29 [137764/888800 15.50%] train loss: 1.413149311702e-05 \n",
      "epoch: 29 [138875/888800 15.62%] train loss: 1.3156652130419388e-05 \n",
      "epoch: 29 [139986/888800 15.75%] train loss: 1.3827696420776192e-05 \n",
      "epoch: 29 [141097/888800 15.88%] train loss: 1.3291237337398343e-05 \n",
      "epoch: 29 [142208/888800 16.00%] train loss: 1.3413537089945748e-05 \n",
      "epoch: 29 [143319/888800 16.12%] train loss: 1.2808674910047557e-05 \n",
      "epoch: 29 [144430/888800 16.25%] train loss: 1.4250734238885343e-05 \n",
      "epoch: 29 [145541/888800 16.38%] train loss: 1.325322864431655e-05 \n",
      "epoch: 29 [146652/888800 16.50%] train loss: 1.4589625607186463e-05 \n",
      "epoch: 29 [147763/888800 16.62%] train loss: 1.4849702893116046e-05 \n",
      "epoch: 29 [148874/888800 16.75%] train loss: 1.4195697076502256e-05 \n",
      "epoch: 29 [149985/888800 16.88%] train loss: 1.3775407751381863e-05 \n",
      "epoch: 29 [151096/888800 17.00%] train loss: 1.3124583347234875e-05 \n",
      "epoch: 29 [152207/888800 17.12%] train loss: 1.3852022675564513e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [153318/888800 17.25%] train loss: 1.3091491382510867e-05 \n",
      "epoch: 29 [154429/888800 17.38%] train loss: 1.5175100998021662e-05 \n",
      "epoch: 29 [155540/888800 17.50%] train loss: 1.3603464140032884e-05 \n",
      "epoch: 29 [156651/888800 17.62%] train loss: 1.5065198567754123e-05 \n",
      "epoch: 29 [157762/888800 17.75%] train loss: 1.5416444512084126e-05 \n",
      "epoch: 29 [158873/888800 17.88%] train loss: 1.230167799803894e-05 \n",
      "epoch: 29 [159984/888800 18.00%] train loss: 1.4755970369151328e-05 \n",
      "epoch: 29 [161095/888800 18.12%] train loss: 1.4337713764689397e-05 \n",
      "epoch: 29 [162206/888800 18.25%] train loss: 1.358289682684699e-05 \n",
      "epoch: 29 [163317/888800 18.38%] train loss: 1.4659223779744934e-05 \n",
      "epoch: 29 [164428/888800 18.50%] train loss: 1.5404953956021927e-05 \n",
      "epoch: 29 [165539/888800 18.62%] train loss: 1.5619274563505314e-05 \n",
      "epoch: 29 [166650/888800 18.75%] train loss: 1.544268525321968e-05 \n",
      "epoch: 29 [167761/888800 18.88%] train loss: 1.4695147001475561e-05 \n",
      "epoch: 29 [168872/888800 19.00%] train loss: 1.5611120034009218e-05 \n",
      "epoch: 29 [169983/888800 19.12%] train loss: 1.4222139725461602e-05 \n",
      "epoch: 29 [171094/888800 19.25%] train loss: 1.3766154552286025e-05 \n",
      "epoch: 29 [172205/888800 19.38%] train loss: 1.426085418643197e-05 \n",
      "epoch: 29 [173316/888800 19.50%] train loss: 1.410551521985326e-05 \n",
      "epoch: 29 [174427/888800 19.62%] train loss: 1.5021842955320608e-05 \n",
      "epoch: 29 [175538/888800 19.75%] train loss: 1.4533833564200904e-05 \n",
      "epoch: 29 [176649/888800 19.88%] train loss: 1.4306003322417382e-05 \n",
      "epoch: 29 [177760/888800 20.00%] train loss: 1.4846653357381001e-05 \n",
      "epoch: 29 [178871/888800 20.12%] train loss: 1.3803291039948817e-05 \n",
      "epoch: 29 [179982/888800 20.25%] train loss: 1.4392146113095805e-05 \n",
      "epoch: 29 [181093/888800 20.38%] train loss: 1.517080090707168e-05 \n",
      "epoch: 29 [182204/888800 20.50%] train loss: 1.359191446681507e-05 \n",
      "epoch: 29 [183315/888800 20.62%] train loss: 1.4577331057807896e-05 \n",
      "epoch: 29 [184426/888800 20.75%] train loss: 1.412851270288229e-05 \n",
      "epoch: 29 [185537/888800 20.88%] train loss: 1.4388977433554828e-05 \n",
      "epoch: 29 [186648/888800 21.00%] train loss: 1.3828602277499158e-05 \n",
      "epoch: 29 [187759/888800 21.12%] train loss: 1.2292089195398148e-05 \n",
      "epoch: 29 [188870/888800 21.25%] train loss: 1.2613852049980778e-05 \n",
      "epoch: 29 [189981/888800 21.38%] train loss: 1.4211476809578016e-05 \n",
      "epoch: 29 [191092/888800 21.50%] train loss: 1.4199606994225178e-05 \n",
      "epoch: 29 [192203/888800 21.62%] train loss: 1.4151831237541046e-05 \n",
      "epoch: 29 [193314/888800 21.75%] train loss: 1.5256559890985955e-05 \n",
      "epoch: 29 [194425/888800 21.88%] train loss: 1.5265677575371228e-05 \n",
      "epoch: 29 [195536/888800 22.00%] train loss: 1.5219233318930492e-05 \n",
      "epoch: 29 [196647/888800 22.12%] train loss: 1.4973990801081527e-05 \n",
      "epoch: 29 [197758/888800 22.25%] train loss: 1.4372340956469998e-05 \n",
      "epoch: 29 [198869/888800 22.38%] train loss: 1.3981334632262588e-05 \n",
      "epoch: 29 [199980/888800 22.50%] train loss: 1.3469134501065128e-05 \n",
      "epoch: 29 [201091/888800 22.62%] train loss: 1.3553242752095684e-05 \n",
      "epoch: 29 [202202/888800 22.75%] train loss: 1.530413283035159e-05 \n",
      "epoch: 29 [203313/888800 22.88%] train loss: 1.50853475133772e-05 \n",
      "epoch: 29 [204424/888800 23.00%] train loss: 1.3843645319866482e-05 \n",
      "epoch: 29 [205535/888800 23.12%] train loss: 1.7027541616698727e-05 \n",
      "epoch: 29 [206646/888800 23.25%] train loss: 1.3610421774501447e-05 \n",
      "epoch: 29 [207757/888800 23.38%] train loss: 1.8228090993943624e-05 \n",
      "epoch: 29 [208868/888800 23.50%] train loss: 1.3641463738167658e-05 \n",
      "epoch: 29 [209979/888800 23.62%] train loss: 1.5538371371803805e-05 \n",
      "epoch: 29 [211090/888800 23.75%] train loss: 1.533452632429544e-05 \n",
      "epoch: 29 [212201/888800 23.88%] train loss: 1.3992967978992965e-05 \n",
      "epoch: 29 [213312/888800 24.00%] train loss: 1.5949075532262214e-05 \n",
      "epoch: 29 [214423/888800 24.12%] train loss: 1.2698794307652861e-05 \n",
      "epoch: 29 [215534/888800 24.25%] train loss: 1.4422578715311829e-05 \n",
      "epoch: 29 [216645/888800 24.38%] train loss: 1.4459389603871386e-05 \n",
      "epoch: 29 [217756/888800 24.50%] train loss: 1.5959032680257224e-05 \n",
      "epoch: 29 [218867/888800 24.62%] train loss: 1.3702180694963317e-05 \n",
      "epoch: 29 [219978/888800 24.75%] train loss: 1.4604399439122062e-05 \n",
      "epoch: 29 [221089/888800 24.88%] train loss: 1.3739957466896158e-05 \n",
      "epoch: 29 [222200/888800 25.00%] train loss: 1.5004668057372328e-05 \n",
      "epoch: 29 [223311/888800 25.12%] train loss: 1.4370199096447323e-05 \n",
      "epoch: 29 [224422/888800 25.25%] train loss: 1.36344060592819e-05 \n",
      "epoch: 29 [225533/888800 25.38%] train loss: 1.485369648435153e-05 \n",
      "epoch: 29 [226644/888800 25.50%] train loss: 1.4369608834385872e-05 \n",
      "epoch: 29 [227755/888800 25.62%] train loss: 1.4807118532189634e-05 \n",
      "epoch: 29 [228866/888800 25.75%] train loss: 1.4046343494555913e-05 \n",
      "epoch: 29 [229977/888800 25.88%] train loss: 1.3670105545315892e-05 \n",
      "epoch: 29 [231088/888800 26.00%] train loss: 1.449317187507404e-05 \n",
      "epoch: 29 [232199/888800 26.12%] train loss: 1.4469162124441937e-05 \n",
      "epoch: 29 [233310/888800 26.25%] train loss: 1.4350298442877829e-05 \n",
      "epoch: 29 [234421/888800 26.38%] train loss: 1.439743755327072e-05 \n",
      "epoch: 29 [235532/888800 26.50%] train loss: 1.427321694791317e-05 \n",
      "epoch: 29 [236643/888800 26.62%] train loss: 1.4057374755793717e-05 \n",
      "epoch: 29 [237754/888800 26.75%] train loss: 1.3069525266473647e-05 \n",
      "epoch: 29 [238865/888800 26.88%] train loss: 1.3768279131909367e-05 \n",
      "epoch: 29 [239976/888800 27.00%] train loss: 1.398259792040335e-05 \n",
      "epoch: 29 [241087/888800 27.12%] train loss: 1.3649263564730063e-05 \n",
      "epoch: 29 [242198/888800 27.25%] train loss: 1.3085330465401057e-05 \n",
      "epoch: 29 [243309/888800 27.38%] train loss: 1.377606804453535e-05 \n",
      "epoch: 29 [244420/888800 27.50%] train loss: 1.3909570043324493e-05 \n",
      "epoch: 29 [245531/888800 27.62%] train loss: 1.4293932508735452e-05 \n",
      "epoch: 29 [246642/888800 27.75%] train loss: 1.439718653273303e-05 \n",
      "epoch: 29 [247753/888800 27.88%] train loss: 1.2866591532656457e-05 \n",
      "epoch: 29 [248864/888800 28.00%] train loss: 1.3151679922884796e-05 \n",
      "epoch: 29 [249975/888800 28.12%] train loss: 1.4035197636985686e-05 \n",
      "epoch: 29 [251086/888800 28.25%] train loss: 1.3594709344033618e-05 \n",
      "epoch: 29 [252197/888800 28.38%] train loss: 1.4580112292605918e-05 \n",
      "epoch: 29 [253308/888800 28.50%] train loss: 1.3679376934305765e-05 \n",
      "epoch: 29 [254419/888800 28.62%] train loss: 1.372785209241556e-05 \n",
      "epoch: 29 [255530/888800 28.75%] train loss: 1.3978359675093088e-05 \n",
      "epoch: 29 [256641/888800 28.88%] train loss: 1.395710205542855e-05 \n",
      "epoch: 29 [257752/888800 29.00%] train loss: 1.3573283467849251e-05 \n",
      "epoch: 29 [258863/888800 29.12%] train loss: 1.5093895854079165e-05 \n",
      "epoch: 29 [259974/888800 29.25%] train loss: 1.4065449249756057e-05 \n",
      "epoch: 29 [261085/888800 29.38%] train loss: 1.4692094737256411e-05 \n",
      "epoch: 29 [262196/888800 29.50%] train loss: 1.4370742064784281e-05 \n",
      "epoch: 29 [263307/888800 29.62%] train loss: 1.5096618881216273e-05 \n",
      "epoch: 29 [264418/888800 29.75%] train loss: 1.3847597074345686e-05 \n",
      "epoch: 29 [265529/888800 29.88%] train loss: 1.5275069017661735e-05 \n",
      "epoch: 29 [266640/888800 30.00%] train loss: 1.4846909834886901e-05 \n",
      "epoch: 29 [267751/888800 30.12%] train loss: 1.5625759260728955e-05 \n",
      "epoch: 29 [268862/888800 30.25%] train loss: 1.4594108506571501e-05 \n",
      "epoch: 29 [269973/888800 30.38%] train loss: 1.5468092897208408e-05 \n",
      "epoch: 29 [271084/888800 30.50%] train loss: 1.3215981198300142e-05 \n",
      "epoch: 29 [272195/888800 30.62%] train loss: 1.3991606465424411e-05 \n",
      "epoch: 29 [273306/888800 30.75%] train loss: 1.5063223145261873e-05 \n",
      "epoch: 29 [274417/888800 30.88%] train loss: 1.4880462913424708e-05 \n",
      "epoch: 29 [275528/888800 31.00%] train loss: 1.4581943105440587e-05 \n",
      "epoch: 29 [276639/888800 31.12%] train loss: 1.4588045814889483e-05 \n",
      "epoch: 29 [277750/888800 31.25%] train loss: 1.4239565643947572e-05 \n",
      "epoch: 29 [278861/888800 31.38%] train loss: 1.4400012332771439e-05 \n",
      "epoch: 29 [279972/888800 31.50%] train loss: 1.3715085515286773e-05 \n",
      "epoch: 29 [281083/888800 31.62%] train loss: 1.5008953596407082e-05 \n",
      "epoch: 29 [282194/888800 31.75%] train loss: 1.3793897778668907e-05 \n",
      "epoch: 29 [283305/888800 31.88%] train loss: 1.4176933291309979e-05 \n",
      "epoch: 29 [284416/888800 32.00%] train loss: 1.3645638318848796e-05 \n",
      "epoch: 29 [285527/888800 32.12%] train loss: 1.3393958397500683e-05 \n",
      "epoch: 29 [286638/888800 32.25%] train loss: 1.4713260497956071e-05 \n",
      "epoch: 29 [287749/888800 32.38%] train loss: 1.4264111996453721e-05 \n",
      "epoch: 29 [288860/888800 32.50%] train loss: 1.4675360944238491e-05 \n",
      "epoch: 29 [289971/888800 32.62%] train loss: 1.4273296073952224e-05 \n",
      "epoch: 29 [291082/888800 32.75%] train loss: 1.4889573321852367e-05 \n",
      "epoch: 29 [292193/888800 32.88%] train loss: 1.4423403627006337e-05 \n",
      "epoch: 29 [293304/888800 33.00%] train loss: 1.377910484734457e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [294415/888800 33.12%] train loss: 1.4765002561034635e-05 \n",
      "epoch: 29 [295526/888800 33.25%] train loss: 1.4372956684383098e-05 \n",
      "epoch: 29 [296637/888800 33.38%] train loss: 1.543631515232846e-05 \n",
      "epoch: 29 [297748/888800 33.50%] train loss: 1.5249080206558574e-05 \n",
      "epoch: 29 [298859/888800 33.62%] train loss: 1.3323755410965532e-05 \n",
      "epoch: 29 [299970/888800 33.75%] train loss: 1.4509472748613916e-05 \n",
      "epoch: 29 [301081/888800 33.88%] train loss: 1.5685829566791654e-05 \n",
      "epoch: 29 [302192/888800 34.00%] train loss: 1.4538813957187813e-05 \n",
      "epoch: 29 [303303/888800 34.12%] train loss: 1.3806768947688397e-05 \n",
      "epoch: 29 [304414/888800 34.25%] train loss: 1.4727035704709124e-05 \n",
      "epoch: 29 [305525/888800 34.38%] train loss: 1.3950923857919406e-05 \n",
      "epoch: 29 [306636/888800 34.50%] train loss: 1.4617750821344089e-05 \n",
      "epoch: 29 [307747/888800 34.62%] train loss: 1.4855832887405995e-05 \n",
      "epoch: 29 [308858/888800 34.75%] train loss: 1.5088999134604819e-05 \n",
      "epoch: 29 [309969/888800 34.88%] train loss: 1.4918914530426264e-05 \n",
      "epoch: 29 [311080/888800 35.00%] train loss: 1.4720281797053758e-05 \n",
      "epoch: 29 [312191/888800 35.12%] train loss: 1.4640537301602308e-05 \n",
      "epoch: 29 [313302/888800 35.25%] train loss: 1.3849316019332036e-05 \n",
      "epoch: 29 [314413/888800 35.38%] train loss: 1.4648411706730258e-05 \n",
      "epoch: 29 [315524/888800 35.50%] train loss: 1.3672092791239265e-05 \n",
      "epoch: 29 [316635/888800 35.62%] train loss: 1.2765193787345197e-05 \n",
      "epoch: 29 [317746/888800 35.75%] train loss: 1.566378887218889e-05 \n",
      "epoch: 29 [318857/888800 35.88%] train loss: 1.3724085874855518e-05 \n",
      "epoch: 29 [319968/888800 36.00%] train loss: 1.4086208466324024e-05 \n",
      "epoch: 29 [321079/888800 36.12%] train loss: 1.3267140275274869e-05 \n",
      "epoch: 29 [322190/888800 36.25%] train loss: 1.432691715308465e-05 \n",
      "epoch: 29 [323301/888800 36.38%] train loss: 1.3831092473992612e-05 \n",
      "epoch: 29 [324412/888800 36.50%] train loss: 1.3432375453703571e-05 \n",
      "epoch: 29 [325523/888800 36.62%] train loss: 1.4795751667406876e-05 \n",
      "epoch: 29 [326634/888800 36.75%] train loss: 1.4605168871639762e-05 \n",
      "epoch: 29 [327745/888800 36.88%] train loss: 1.5213361621135846e-05 \n",
      "epoch: 29 [328856/888800 37.00%] train loss: 1.4572226064046845e-05 \n",
      "epoch: 29 [329967/888800 37.12%] train loss: 1.376792715745978e-05 \n",
      "epoch: 29 [331078/888800 37.25%] train loss: 1.4619216017308645e-05 \n",
      "epoch: 29 [332189/888800 37.38%] train loss: 1.4397234735952225e-05 \n",
      "epoch: 29 [333300/888800 37.50%] train loss: 1.3389761079452e-05 \n",
      "epoch: 29 [334411/888800 37.62%] train loss: 1.4113817996985745e-05 \n",
      "epoch: 29 [335522/888800 37.75%] train loss: 1.3868603673472535e-05 \n",
      "epoch: 29 [336633/888800 37.88%] train loss: 1.4705531611980405e-05 \n",
      "epoch: 29 [337744/888800 38.00%] train loss: 1.3664131984114647e-05 \n",
      "epoch: 29 [338855/888800 38.12%] train loss: 1.3989245417178608e-05 \n",
      "epoch: 29 [339966/888800 38.25%] train loss: 1.3543736713472754e-05 \n",
      "epoch: 29 [341077/888800 38.38%] train loss: 1.4124004337645601e-05 \n",
      "epoch: 29 [342188/888800 38.50%] train loss: 1.4335091691464186e-05 \n",
      "epoch: 29 [343299/888800 38.62%] train loss: 1.356257689621998e-05 \n",
      "epoch: 29 [344410/888800 38.75%] train loss: 1.4232715329853818e-05 \n",
      "epoch: 29 [345521/888800 38.88%] train loss: 1.4379500498762354e-05 \n",
      "epoch: 29 [346632/888800 39.00%] train loss: 1.3225922884885222e-05 \n",
      "epoch: 29 [347743/888800 39.12%] train loss: 1.3789018339593895e-05 \n",
      "epoch: 29 [348854/888800 39.25%] train loss: 1.4111773452896159e-05 \n",
      "epoch: 29 [349965/888800 39.38%] train loss: 1.3938365555077326e-05 \n",
      "epoch: 29 [351076/888800 39.50%] train loss: 1.4152205949358176e-05 \n",
      "epoch: 29 [352187/888800 39.62%] train loss: 1.4503876627713908e-05 \n",
      "epoch: 29 [353298/888800 39.75%] train loss: 1.6363617760362104e-05 \n",
      "epoch: 29 [354409/888800 39.88%] train loss: 1.4278021808422636e-05 \n",
      "epoch: 29 [355520/888800 40.00%] train loss: 1.395276194671169e-05 \n",
      "epoch: 29 [356631/888800 40.12%] train loss: 1.4082412235438824e-05 \n",
      "epoch: 29 [357742/888800 40.25%] train loss: 1.4621417903981637e-05 \n",
      "epoch: 29 [358853/888800 40.38%] train loss: 1.336413697572425e-05 \n",
      "epoch: 29 [359964/888800 40.50%] train loss: 1.5857116522965953e-05 \n",
      "epoch: 29 [361075/888800 40.62%] train loss: 1.4665332855656743e-05 \n",
      "epoch: 29 [362186/888800 40.75%] train loss: 1.3863249478163198e-05 \n",
      "epoch: 29 [363297/888800 40.88%] train loss: 1.3526164366339799e-05 \n",
      "epoch: 29 [364408/888800 41.00%] train loss: 1.324842651229119e-05 \n",
      "epoch: 29 [365519/888800 41.12%] train loss: 1.5083030120877083e-05 \n",
      "epoch: 29 [366630/888800 41.25%] train loss: 1.3718472473556176e-05 \n",
      "epoch: 29 [367741/888800 41.38%] train loss: 1.3910468624089845e-05 \n",
      "epoch: 29 [368852/888800 41.50%] train loss: 1.3576646779256407e-05 \n",
      "epoch: 29 [369963/888800 41.62%] train loss: 1.6033713109209202e-05 \n",
      "epoch: 29 [371074/888800 41.75%] train loss: 1.4387484043254517e-05 \n",
      "epoch: 29 [372185/888800 41.88%] train loss: 1.6543255696888082e-05 \n",
      "epoch: 29 [373296/888800 42.00%] train loss: 1.5290110241039656e-05 \n",
      "epoch: 29 [374407/888800 42.12%] train loss: 1.6240561308222823e-05 \n",
      "epoch: 29 [375518/888800 42.25%] train loss: 1.711277582217008e-05 \n",
      "epoch: 29 [376629/888800 42.38%] train loss: 1.2906686606584117e-05 \n",
      "epoch: 29 [377740/888800 42.50%] train loss: 1.628242534934543e-05 \n",
      "epoch: 29 [378851/888800 42.62%] train loss: 1.4641734196629841e-05 \n",
      "epoch: 29 [379962/888800 42.75%] train loss: 1.409287051501451e-05 \n",
      "epoch: 29 [381073/888800 42.88%] train loss: 1.4080665096116718e-05 \n",
      "epoch: 29 [382184/888800 43.00%] train loss: 1.519120814919006e-05 \n",
      "epoch: 29 [383295/888800 43.12%] train loss: 1.4984578228904866e-05 \n",
      "epoch: 29 [384406/888800 43.25%] train loss: 1.552788853587117e-05 \n",
      "epoch: 29 [385517/888800 43.38%] train loss: 1.392996546201175e-05 \n",
      "epoch: 29 [386628/888800 43.50%] train loss: 1.5342633560067043e-05 \n",
      "epoch: 29 [387739/888800 43.62%] train loss: 1.433713532605907e-05 \n",
      "epoch: 29 [388850/888800 43.75%] train loss: 1.6151327145053074e-05 \n",
      "epoch: 29 [389961/888800 43.88%] train loss: 1.5480245565413497e-05 \n",
      "epoch: 29 [391072/888800 44.00%] train loss: 1.3847556147084106e-05 \n",
      "epoch: 29 [392183/888800 44.12%] train loss: 1.4617068700317759e-05 \n",
      "epoch: 29 [393294/888800 44.25%] train loss: 1.4967747119953856e-05 \n",
      "epoch: 29 [394405/888800 44.38%] train loss: 1.4725908840773627e-05 \n",
      "epoch: 29 [395516/888800 44.50%] train loss: 1.4827515769866295e-05 \n",
      "epoch: 29 [396627/888800 44.62%] train loss: 1.4968953109928407e-05 \n",
      "epoch: 29 [397738/888800 44.75%] train loss: 1.3222722373029683e-05 \n",
      "epoch: 29 [398849/888800 44.88%] train loss: 1.4118408216745593e-05 \n",
      "epoch: 29 [399960/888800 45.00%] train loss: 1.3523341294785496e-05 \n",
      "epoch: 29 [401071/888800 45.12%] train loss: 1.518980752734933e-05 \n",
      "epoch: 29 [402182/888800 45.25%] train loss: 1.53110631799791e-05 \n",
      "epoch: 29 [403293/888800 45.38%] train loss: 1.3033047252974939e-05 \n",
      "epoch: 29 [404404/888800 45.50%] train loss: 1.4394952813745476e-05 \n",
      "epoch: 29 [405515/888800 45.62%] train loss: 1.5513023754465394e-05 \n",
      "epoch: 29 [406626/888800 45.75%] train loss: 1.5071495909069199e-05 \n",
      "epoch: 29 [407737/888800 45.88%] train loss: 1.4760546036995947e-05 \n",
      "epoch: 29 [408848/888800 46.00%] train loss: 1.38092327688355e-05 \n",
      "epoch: 29 [409959/888800 46.12%] train loss: 1.4247978469938971e-05 \n",
      "epoch: 29 [411070/888800 46.25%] train loss: 1.3841094187228009e-05 \n",
      "epoch: 29 [412181/888800 46.38%] train loss: 1.4780667697777972e-05 \n",
      "epoch: 29 [413292/888800 46.50%] train loss: 1.4696212019771338e-05 \n",
      "epoch: 29 [414403/888800 46.62%] train loss: 1.4503182683256455e-05 \n",
      "epoch: 29 [415514/888800 46.75%] train loss: 1.4534864021698013e-05 \n",
      "epoch: 29 [416625/888800 46.88%] train loss: 1.3897465578338597e-05 \n",
      "epoch: 29 [417736/888800 47.00%] train loss: 1.397789856127929e-05 \n",
      "epoch: 29 [418847/888800 47.12%] train loss: 1.439006609871285e-05 \n",
      "epoch: 29 [419958/888800 47.25%] train loss: 1.3526842849387322e-05 \n",
      "epoch: 29 [421069/888800 47.38%] train loss: 1.3276317076815758e-05 \n",
      "epoch: 29 [422180/888800 47.50%] train loss: 1.3310958820511587e-05 \n",
      "epoch: 29 [423291/888800 47.62%] train loss: 1.3360028788156342e-05 \n",
      "epoch: 29 [424402/888800 47.75%] train loss: 1.389245517202653e-05 \n",
      "epoch: 29 [425513/888800 47.88%] train loss: 1.3249368748802226e-05 \n",
      "epoch: 29 [426624/888800 48.00%] train loss: 1.4513471796817612e-05 \n",
      "epoch: 29 [427735/888800 48.12%] train loss: 1.4661609384347685e-05 \n",
      "epoch: 29 [428846/888800 48.25%] train loss: 1.4197557902662084e-05 \n",
      "epoch: 29 [429957/888800 48.38%] train loss: 1.4452605682890862e-05 \n",
      "epoch: 29 [431068/888800 48.50%] train loss: 1.4862279385852162e-05 \n",
      "epoch: 29 [432179/888800 48.62%] train loss: 1.3528870113077573e-05 \n",
      "epoch: 29 [433290/888800 48.75%] train loss: 1.387659358442761e-05 \n",
      "epoch: 29 [434401/888800 48.88%] train loss: 1.3914695045968983e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [435512/888800 49.00%] train loss: 1.3324917745194398e-05 \n",
      "epoch: 29 [436623/888800 49.12%] train loss: 1.4382303561433218e-05 \n",
      "epoch: 29 [437734/888800 49.25%] train loss: 1.2641625289688818e-05 \n",
      "epoch: 29 [438845/888800 49.38%] train loss: 1.3753314306086395e-05 \n",
      "epoch: 29 [439956/888800 49.50%] train loss: 1.3176321772334632e-05 \n",
      "epoch: 29 [441067/888800 49.62%] train loss: 1.3457064596877899e-05 \n",
      "epoch: 29 [442178/888800 49.75%] train loss: 1.445381531084422e-05 \n",
      "epoch: 29 [443289/888800 49.88%] train loss: 1.3905407286074478e-05 \n",
      "epoch: 29 [444400/888800 50.00%] train loss: 1.401377267029602e-05 \n",
      "epoch: 29 [445511/888800 50.12%] train loss: 1.4005388948135078e-05 \n",
      "epoch: 29 [446622/888800 50.25%] train loss: 1.2807909115508664e-05 \n",
      "epoch: 29 [447733/888800 50.38%] train loss: 1.3130247680237517e-05 \n",
      "epoch: 29 [448844/888800 50.50%] train loss: 1.2814381989301182e-05 \n",
      "epoch: 29 [449955/888800 50.62%] train loss: 1.4656265193480067e-05 \n",
      "epoch: 29 [451066/888800 50.75%] train loss: 1.368270932289306e-05 \n",
      "epoch: 29 [452177/888800 50.88%] train loss: 1.4111510608927347e-05 \n",
      "epoch: 29 [453288/888800 51.00%] train loss: 1.5163571333687287e-05 \n",
      "epoch: 29 [454399/888800 51.12%] train loss: 1.4548840226780158e-05 \n",
      "epoch: 29 [455510/888800 51.25%] train loss: 1.5472884115297347e-05 \n",
      "epoch: 29 [456621/888800 51.38%] train loss: 1.4548083527188282e-05 \n",
      "epoch: 29 [457732/888800 51.50%] train loss: 1.575431633682456e-05 \n",
      "epoch: 29 [458843/888800 51.62%] train loss: 1.4295585970103275e-05 \n",
      "epoch: 29 [459954/888800 51.75%] train loss: 1.4853983884677291e-05 \n",
      "epoch: 29 [461065/888800 51.88%] train loss: 1.2637114195968024e-05 \n",
      "epoch: 29 [462176/888800 52.00%] train loss: 1.4962536624807399e-05 \n",
      "epoch: 29 [463287/888800 52.12%] train loss: 1.293170134886168e-05 \n",
      "epoch: 29 [464398/888800 52.25%] train loss: 1.397803771396866e-05 \n",
      "epoch: 29 [465509/888800 52.38%] train loss: 1.4307664969237521e-05 \n",
      "epoch: 29 [466620/888800 52.50%] train loss: 1.4211952475307044e-05 \n",
      "epoch: 29 [467731/888800 52.62%] train loss: 1.3796236089547165e-05 \n",
      "epoch: 29 [468842/888800 52.75%] train loss: 1.4570729035767727e-05 \n",
      "epoch: 29 [469953/888800 52.88%] train loss: 1.4561268471879885e-05 \n",
      "epoch: 29 [471064/888800 53.00%] train loss: 1.4274625755206216e-05 \n",
      "epoch: 29 [472175/888800 53.12%] train loss: 1.4214075235940982e-05 \n",
      "epoch: 29 [473286/888800 53.25%] train loss: 1.3573689102486242e-05 \n",
      "epoch: 29 [474397/888800 53.38%] train loss: 1.3759120520262513e-05 \n",
      "epoch: 29 [475508/888800 53.50%] train loss: 1.2850026905653067e-05 \n",
      "epoch: 29 [476619/888800 53.62%] train loss: 1.3477024367603008e-05 \n",
      "epoch: 29 [477730/888800 53.75%] train loss: 1.3447017408907413e-05 \n",
      "epoch: 29 [478841/888800 53.88%] train loss: 1.4244342310121283e-05 \n",
      "epoch: 29 [479952/888800 54.00%] train loss: 1.3721770301344804e-05 \n",
      "epoch: 29 [481063/888800 54.12%] train loss: 1.2701590094366111e-05 \n",
      "epoch: 29 [482174/888800 54.25%] train loss: 1.473231259296881e-05 \n",
      "epoch: 29 [483285/888800 54.38%] train loss: 1.512474955234211e-05 \n",
      "epoch: 29 [484396/888800 54.50%] train loss: 1.3764812138106208e-05 \n",
      "epoch: 29 [485507/888800 54.62%] train loss: 1.4942944289941806e-05 \n",
      "epoch: 29 [486618/888800 54.75%] train loss: 1.5647463442292064e-05 \n",
      "epoch: 29 [487729/888800 54.88%] train loss: 1.4681535503768828e-05 \n",
      "epoch: 29 [488840/888800 55.00%] train loss: 1.4602762348658871e-05 \n",
      "epoch: 29 [489951/888800 55.12%] train loss: 1.3880936421628576e-05 \n",
      "epoch: 29 [491062/888800 55.25%] train loss: 1.3452696293825284e-05 \n",
      "epoch: 29 [492173/888800 55.38%] train loss: 1.4328771612781566e-05 \n",
      "epoch: 29 [493284/888800 55.50%] train loss: 1.3653610039909836e-05 \n",
      "epoch: 29 [494395/888800 55.62%] train loss: 1.5116114809643477e-05 \n",
      "epoch: 29 [495506/888800 55.75%] train loss: 1.5368090316769667e-05 \n",
      "epoch: 29 [496617/888800 55.88%] train loss: 1.3240628504718188e-05 \n",
      "epoch: 29 [497728/888800 56.00%] train loss: 1.4195659787219483e-05 \n",
      "epoch: 29 [498839/888800 56.12%] train loss: 1.3790310731565114e-05 \n",
      "epoch: 29 [499950/888800 56.25%] train loss: 1.3962723642180208e-05 \n",
      "epoch: 29 [501061/888800 56.38%] train loss: 1.55309808178572e-05 \n",
      "epoch: 29 [502172/888800 56.50%] train loss: 1.4122589163889643e-05 \n",
      "epoch: 29 [503283/888800 56.62%] train loss: 1.4724821994605009e-05 \n",
      "epoch: 29 [504394/888800 56.75%] train loss: 1.5002737200120464e-05 \n",
      "epoch: 29 [505505/888800 56.88%] train loss: 1.3451369341055397e-05 \n",
      "epoch: 29 [506616/888800 57.00%] train loss: 1.4236446986615192e-05 \n",
      "epoch: 29 [507727/888800 57.12%] train loss: 1.383992002956802e-05 \n",
      "epoch: 29 [508838/888800 57.25%] train loss: 1.4994692719483282e-05 \n",
      "epoch: 29 [509949/888800 57.38%] train loss: 1.3675692571268883e-05 \n",
      "epoch: 29 [511060/888800 57.50%] train loss: 1.3897936696594115e-05 \n",
      "epoch: 29 [512171/888800 57.62%] train loss: 1.3428803868009709e-05 \n",
      "epoch: 29 [513282/888800 57.75%] train loss: 1.38508366944734e-05 \n",
      "epoch: 29 [514393/888800 57.88%] train loss: 1.4420662409975193e-05 \n",
      "epoch: 29 [515504/888800 58.00%] train loss: 1.404307931807125e-05 \n",
      "epoch: 29 [516615/888800 58.12%] train loss: 1.3744210264121648e-05 \n",
      "epoch: 29 [517726/888800 58.25%] train loss: 1.2356934348645154e-05 \n",
      "epoch: 29 [518837/888800 58.38%] train loss: 1.4383317648025695e-05 \n",
      "epoch: 29 [519948/888800 58.50%] train loss: 1.4932767953723669e-05 \n",
      "epoch: 29 [521059/888800 58.62%] train loss: 1.4178911442286335e-05 \n",
      "epoch: 29 [522170/888800 58.75%] train loss: 1.406138835591264e-05 \n",
      "epoch: 29 [523281/888800 58.88%] train loss: 1.4207063941285014e-05 \n",
      "epoch: 29 [524392/888800 59.00%] train loss: 1.2600434274645522e-05 \n",
      "epoch: 29 [525503/888800 59.12%] train loss: 1.5019147213024553e-05 \n",
      "epoch: 29 [526614/888800 59.25%] train loss: 1.4483949598798063e-05 \n",
      "epoch: 29 [527725/888800 59.38%] train loss: 1.4390545402420685e-05 \n",
      "epoch: 29 [528836/888800 59.50%] train loss: 1.4451953575189691e-05 \n",
      "epoch: 29 [529947/888800 59.62%] train loss: 1.4146433386486024e-05 \n",
      "epoch: 29 [531058/888800 59.75%] train loss: 1.4086992450756952e-05 \n",
      "epoch: 29 [532169/888800 59.88%] train loss: 1.2934730875713285e-05 \n",
      "epoch: 29 [533280/888800 60.00%] train loss: 1.617331145098433e-05 \n",
      "epoch: 29 [534391/888800 60.12%] train loss: 1.4471730537479743e-05 \n",
      "epoch: 29 [535502/888800 60.25%] train loss: 1.3449131074594334e-05 \n",
      "epoch: 29 [536613/888800 60.38%] train loss: 1.20968716146308e-05 \n",
      "epoch: 29 [537724/888800 60.50%] train loss: 1.4830875443294644e-05 \n",
      "epoch: 29 [538835/888800 60.62%] train loss: 1.3340393707039766e-05 \n",
      "epoch: 29 [539946/888800 60.75%] train loss: 1.4219674994819798e-05 \n",
      "epoch: 29 [541057/888800 60.88%] train loss: 1.534570583316963e-05 \n",
      "epoch: 29 [542168/888800 61.00%] train loss: 1.4997113794379402e-05 \n",
      "epoch: 29 [543279/888800 61.12%] train loss: 1.498021447332576e-05 \n",
      "epoch: 29 [544390/888800 61.25%] train loss: 1.4178470337355975e-05 \n",
      "epoch: 29 [545501/888800 61.38%] train loss: 1.463438729842892e-05 \n",
      "epoch: 29 [546612/888800 61.50%] train loss: 1.4095895494392607e-05 \n",
      "epoch: 29 [547723/888800 61.62%] train loss: 1.3935917195340153e-05 \n",
      "epoch: 29 [548834/888800 61.75%] train loss: 1.4441073290072381e-05 \n",
      "epoch: 29 [549945/888800 61.88%] train loss: 1.6202146071009338e-05 \n",
      "epoch: 29 [551056/888800 62.00%] train loss: 1.4439483493333682e-05 \n",
      "epoch: 29 [552167/888800 62.12%] train loss: 1.5641580830560997e-05 \n",
      "epoch: 29 [553278/888800 62.25%] train loss: 1.399987559125293e-05 \n",
      "epoch: 29 [554389/888800 62.38%] train loss: 1.4404220564756542e-05 \n",
      "epoch: 29 [555500/888800 62.50%] train loss: 1.424680340278428e-05 \n",
      "epoch: 29 [556611/888800 62.62%] train loss: 1.49641273310408e-05 \n",
      "epoch: 29 [557722/888800 62.75%] train loss: 1.4178458513924852e-05 \n",
      "epoch: 29 [558833/888800 62.88%] train loss: 1.4562447177013382e-05 \n",
      "epoch: 29 [559944/888800 63.00%] train loss: 1.480236096540466e-05 \n",
      "epoch: 29 [561055/888800 63.12%] train loss: 1.4543936231348198e-05 \n",
      "epoch: 29 [562166/888800 63.25%] train loss: 1.4765495507162996e-05 \n",
      "epoch: 29 [563277/888800 63.38%] train loss: 1.3920355740992818e-05 \n",
      "epoch: 29 [564388/888800 63.50%] train loss: 1.4071732948650606e-05 \n",
      "epoch: 29 [565499/888800 63.62%] train loss: 1.4096352970227599e-05 \n",
      "epoch: 29 [566610/888800 63.75%] train loss: 1.4126572750683408e-05 \n",
      "epoch: 29 [567721/888800 63.88%] train loss: 1.4648896467406303e-05 \n",
      "epoch: 29 [568832/888800 64.00%] train loss: 1.564800550113432e-05 \n",
      "epoch: 29 [569943/888800 64.12%] train loss: 1.4289687896962278e-05 \n",
      "epoch: 29 [571054/888800 64.25%] train loss: 1.4265791833167896e-05 \n",
      "epoch: 29 [572165/888800 64.38%] train loss: 1.3749702702625655e-05 \n",
      "epoch: 29 [573276/888800 64.50%] train loss: 1.3951971595815849e-05 \n",
      "epoch: 29 [574387/888800 64.62%] train loss: 1.3801995919493493e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [575498/888800 64.75%] train loss: 1.4529487998515833e-05 \n",
      "epoch: 29 [576609/888800 64.88%] train loss: 1.3425035831460264e-05 \n",
      "epoch: 29 [577720/888800 65.00%] train loss: 1.5119124327611644e-05 \n",
      "epoch: 29 [578831/888800 65.12%] train loss: 1.3149398000678048e-05 \n",
      "epoch: 29 [579942/888800 65.25%] train loss: 1.528323809907306e-05 \n",
      "epoch: 29 [581053/888800 65.38%] train loss: 1.5366909792646766e-05 \n",
      "epoch: 29 [582164/888800 65.50%] train loss: 1.4191481568559539e-05 \n",
      "epoch: 29 [583275/888800 65.62%] train loss: 1.418123792973347e-05 \n",
      "epoch: 29 [584386/888800 65.75%] train loss: 1.496516870247433e-05 \n",
      "epoch: 29 [585497/888800 65.88%] train loss: 1.545115446788259e-05 \n",
      "epoch: 29 [586608/888800 66.00%] train loss: 1.6401481843786314e-05 \n",
      "epoch: 29 [587719/888800 66.12%] train loss: 1.4503260899800807e-05 \n",
      "epoch: 29 [588830/888800 66.25%] train loss: 1.6102789231808856e-05 \n",
      "epoch: 29 [589941/888800 66.38%] train loss: 1.4029827070771717e-05 \n",
      "epoch: 29 [591052/888800 66.50%] train loss: 1.3282865438668523e-05 \n",
      "epoch: 29 [592163/888800 66.62%] train loss: 1.4533100511471275e-05 \n",
      "epoch: 29 [593274/888800 66.75%] train loss: 1.5696496120654047e-05 \n",
      "epoch: 29 [594385/888800 66.88%] train loss: 1.357649944111472e-05 \n",
      "epoch: 29 [595496/888800 67.00%] train loss: 1.3448425306705758e-05 \n",
      "epoch: 29 [596607/888800 67.12%] train loss: 1.4144624401524197e-05 \n",
      "epoch: 29 [597718/888800 67.25%] train loss: 1.387860447721323e-05 \n",
      "epoch: 29 [598829/888800 67.38%] train loss: 1.4962057321099564e-05 \n",
      "epoch: 29 [599940/888800 67.50%] train loss: 1.4090000149735715e-05 \n",
      "epoch: 29 [601051/888800 67.62%] train loss: 1.4136428944766521e-05 \n",
      "epoch: 29 [602162/888800 67.75%] train loss: 1.451281968911644e-05 \n",
      "epoch: 29 [603273/888800 67.88%] train loss: 1.3482689610100351e-05 \n",
      "epoch: 29 [604384/888800 68.00%] train loss: 1.4841880329186097e-05 \n",
      "epoch: 29 [605495/888800 68.12%] train loss: 1.352276922261808e-05 \n",
      "epoch: 29 [606606/888800 68.25%] train loss: 1.3515362297766842e-05 \n",
      "epoch: 29 [607717/888800 68.38%] train loss: 1.4364756680151913e-05 \n",
      "epoch: 29 [608828/888800 68.50%] train loss: 1.3262778338685166e-05 \n",
      "epoch: 29 [609939/888800 68.62%] train loss: 1.4840319636277854e-05 \n",
      "epoch: 29 [611050/888800 68.75%] train loss: 1.5234494640026242e-05 \n",
      "epoch: 29 [612161/888800 68.88%] train loss: 1.4331552847579587e-05 \n",
      "epoch: 29 [613272/888800 69.00%] train loss: 1.3434613720164634e-05 \n",
      "epoch: 29 [614383/888800 69.12%] train loss: 1.4177546290738974e-05 \n",
      "epoch: 29 [615494/888800 69.25%] train loss: 1.590120155015029e-05 \n",
      "epoch: 29 [616605/888800 69.38%] train loss: 1.4200466466718353e-05 \n",
      "epoch: 29 [617716/888800 69.50%] train loss: 1.6599013179074973e-05 \n",
      "epoch: 29 [618827/888800 69.62%] train loss: 1.4466774700849783e-05 \n",
      "epoch: 29 [619938/888800 69.75%] train loss: 1.4627884411311243e-05 \n",
      "epoch: 29 [621049/888800 69.88%] train loss: 1.3816513273923192e-05 \n",
      "epoch: 29 [622160/888800 70.00%] train loss: 1.3868212590750773e-05 \n",
      "epoch: 29 [623271/888800 70.12%] train loss: 1.317395617661532e-05 \n",
      "epoch: 29 [624382/888800 70.25%] train loss: 1.3941094039182644e-05 \n",
      "epoch: 29 [625493/888800 70.38%] train loss: 1.6721269275876693e-05 \n",
      "epoch: 29 [626604/888800 70.50%] train loss: 1.602457632543519e-05 \n",
      "epoch: 29 [627715/888800 70.62%] train loss: 1.3249493349576369e-05 \n",
      "epoch: 29 [628826/888800 70.75%] train loss: 1.550511115055997e-05 \n",
      "epoch: 29 [629937/888800 70.88%] train loss: 1.4091049706621561e-05 \n",
      "epoch: 29 [631048/888800 71.00%] train loss: 1.559686461405363e-05 \n",
      "epoch: 29 [632159/888800 71.12%] train loss: 1.444120061933063e-05 \n",
      "epoch: 29 [633270/888800 71.25%] train loss: 1.4899161214998458e-05 \n",
      "epoch: 29 [634381/888800 71.38%] train loss: 1.3254783880256582e-05 \n",
      "epoch: 29 [635492/888800 71.50%] train loss: 1.4035555068403482e-05 \n",
      "epoch: 29 [636603/888800 71.62%] train loss: 1.5619227269780822e-05 \n",
      "epoch: 29 [637714/888800 71.75%] train loss: 1.4500308679998852e-05 \n",
      "epoch: 29 [638825/888800 71.88%] train loss: 1.3227800081949681e-05 \n",
      "epoch: 29 [639936/888800 72.00%] train loss: 1.3933142327005044e-05 \n",
      "epoch: 29 [641047/888800 72.12%] train loss: 1.4112119060882833e-05 \n",
      "epoch: 29 [642158/888800 72.25%] train loss: 1.438766503270017e-05 \n",
      "epoch: 29 [643269/888800 72.38%] train loss: 1.4906026990502141e-05 \n",
      "epoch: 29 [644380/888800 72.50%] train loss: 1.312000495090615e-05 \n",
      "epoch: 29 [645491/888800 72.62%] train loss: 1.447163685952546e-05 \n",
      "epoch: 29 [646602/888800 72.75%] train loss: 1.5172240637184586e-05 \n",
      "epoch: 29 [647713/888800 72.88%] train loss: 1.552054163767025e-05 \n",
      "epoch: 29 [648824/888800 73.00%] train loss: 1.364065428788308e-05 \n",
      "epoch: 29 [649935/888800 73.12%] train loss: 1.4230203305487521e-05 \n",
      "epoch: 29 [651046/888800 73.25%] train loss: 1.3885243788536172e-05 \n",
      "epoch: 29 [652157/888800 73.38%] train loss: 1.4386196198756807e-05 \n",
      "epoch: 29 [653268/888800 73.50%] train loss: 1.3754067367699463e-05 \n",
      "epoch: 29 [654379/888800 73.62%] train loss: 1.3621317521028686e-05 \n",
      "epoch: 29 [655490/888800 73.75%] train loss: 1.5104863450687844e-05 \n",
      "epoch: 29 [656601/888800 73.88%] train loss: 1.4481635844276752e-05 \n",
      "epoch: 29 [657712/888800 74.00%] train loss: 1.5022767911432311e-05 \n",
      "epoch: 29 [658823/888800 74.12%] train loss: 1.4574549823009875e-05 \n",
      "epoch: 29 [659934/888800 74.25%] train loss: 1.5746118151582778e-05 \n",
      "epoch: 29 [661045/888800 74.38%] train loss: 1.415577844454674e-05 \n",
      "epoch: 29 [662156/888800 74.50%] train loss: 1.4803928024775814e-05 \n",
      "epoch: 29 [663267/888800 74.62%] train loss: 1.3779676919511985e-05 \n",
      "epoch: 29 [664378/888800 74.75%] train loss: 1.59032078954624e-05 \n",
      "epoch: 29 [665489/888800 74.88%] train loss: 1.4458793884841725e-05 \n",
      "epoch: 29 [666600/888800 75.00%] train loss: 1.592123408045154e-05 \n",
      "epoch: 29 [667711/888800 75.12%] train loss: 1.508999957877677e-05 \n",
      "epoch: 29 [668822/888800 75.25%] train loss: 1.4907776858308353e-05 \n",
      "epoch: 29 [669933/888800 75.38%] train loss: 1.3900994417781476e-05 \n",
      "epoch: 29 [671044/888800 75.50%] train loss: 1.3900681551604066e-05 \n",
      "epoch: 29 [672155/888800 75.62%] train loss: 1.4640038898505736e-05 \n",
      "epoch: 29 [673266/888800 75.75%] train loss: 1.4060882676858455e-05 \n",
      "epoch: 29 [674377/888800 75.88%] train loss: 1.4178311175783165e-05 \n",
      "epoch: 29 [675488/888800 76.00%] train loss: 1.532349779154174e-05 \n",
      "epoch: 29 [676599/888800 76.12%] train loss: 1.3384839803620707e-05 \n",
      "epoch: 29 [677710/888800 76.25%] train loss: 1.6051713828346692e-05 \n",
      "epoch: 29 [678821/888800 76.38%] train loss: 1.4518429452436976e-05 \n",
      "epoch: 29 [679932/888800 76.50%] train loss: 1.4881616152706556e-05 \n",
      "epoch: 29 [681043/888800 76.62%] train loss: 1.3849386959918775e-05 \n",
      "epoch: 29 [682154/888800 76.75%] train loss: 1.44396981340833e-05 \n",
      "epoch: 29 [683265/888800 76.88%] train loss: 1.2390030860842671e-05 \n",
      "epoch: 29 [684376/888800 77.00%] train loss: 1.4305062904895749e-05 \n",
      "epoch: 29 [685487/888800 77.12%] train loss: 1.442013763153227e-05 \n",
      "epoch: 29 [686598/888800 77.25%] train loss: 1.3746943295700476e-05 \n",
      "epoch: 29 [687709/888800 77.38%] train loss: 1.4160537830321118e-05 \n",
      "epoch: 29 [688820/888800 77.50%] train loss: 1.4118712897470687e-05 \n",
      "epoch: 29 [689931/888800 77.62%] train loss: 1.4143020962364972e-05 \n",
      "epoch: 29 [691042/888800 77.75%] train loss: 1.4378291780303698e-05 \n",
      "epoch: 29 [692153/888800 77.88%] train loss: 1.3791383935313206e-05 \n",
      "epoch: 29 [693264/888800 78.00%] train loss: 1.3952161680208519e-05 \n",
      "epoch: 29 [694375/888800 78.12%] train loss: 1.5003766748122871e-05 \n",
      "epoch: 29 [695486/888800 78.25%] train loss: 1.3128625141689554e-05 \n",
      "epoch: 29 [696597/888800 78.38%] train loss: 1.4188419299898669e-05 \n",
      "epoch: 29 [697708/888800 78.50%] train loss: 1.40021174956928e-05 \n",
      "epoch: 29 [698819/888800 78.62%] train loss: 1.4987061149440706e-05 \n",
      "epoch: 29 [699930/888800 78.75%] train loss: 1.4105568880040664e-05 \n",
      "epoch: 29 [701041/888800 78.88%] train loss: 1.331807561655296e-05 \n",
      "epoch: 29 [702152/888800 79.00%] train loss: 1.4629292309109587e-05 \n",
      "epoch: 29 [703263/888800 79.12%] train loss: 1.3389134437602479e-05 \n",
      "epoch: 29 [704374/888800 79.25%] train loss: 1.3307378139870707e-05 \n",
      "epoch: 29 [705485/888800 79.38%] train loss: 1.4319705769594293e-05 \n",
      "epoch: 29 [706596/888800 79.50%] train loss: 1.4171031580190174e-05 \n",
      "epoch: 29 [707707/888800 79.62%] train loss: 1.4394119716598652e-05 \n",
      "epoch: 29 [708818/888800 79.75%] train loss: 1.3976601621834561e-05 \n",
      "epoch: 29 [709929/888800 79.88%] train loss: 1.4363750779011752e-05 \n",
      "epoch: 29 [711040/888800 80.00%] train loss: 1.5953497495502234e-05 \n",
      "epoch: 29 [712151/888800 80.12%] train loss: 1.4515781913360115e-05 \n",
      "epoch: 29 [713262/888800 80.25%] train loss: 1.440995492885122e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [714373/888800 80.38%] train loss: 1.4510378605336882e-05 \n",
      "epoch: 29 [715484/888800 80.50%] train loss: 1.4249902960727923e-05 \n",
      "epoch: 29 [716595/888800 80.62%] train loss: 1.4938979802536778e-05 \n",
      "epoch: 29 [717706/888800 80.75%] train loss: 1.487054760218598e-05 \n",
      "epoch: 29 [718817/888800 80.88%] train loss: 1.4214558177627623e-05 \n",
      "epoch: 29 [719928/888800 81.00%] train loss: 1.3961443073640112e-05 \n",
      "epoch: 29 [721039/888800 81.12%] train loss: 1.4643100257671904e-05 \n",
      "epoch: 29 [722150/888800 81.25%] train loss: 1.4294472748588305e-05 \n",
      "epoch: 29 [723261/888800 81.38%] train loss: 1.5586894733132794e-05 \n",
      "epoch: 29 [724372/888800 81.50%] train loss: 1.3334923096408602e-05 \n",
      "epoch: 29 [725483/888800 81.62%] train loss: 1.383473863825202e-05 \n",
      "epoch: 29 [726594/888800 81.75%] train loss: 1.2883524505014066e-05 \n",
      "epoch: 29 [727705/888800 81.88%] train loss: 1.453735058021266e-05 \n",
      "epoch: 29 [728816/888800 82.00%] train loss: 1.3513685189536773e-05 \n",
      "epoch: 29 [729927/888800 82.12%] train loss: 1.4221440324035939e-05 \n",
      "epoch: 29 [731038/888800 82.25%] train loss: 1.5761783288326114e-05 \n",
      "epoch: 29 [732149/888800 82.38%] train loss: 1.3622511687572114e-05 \n",
      "epoch: 29 [733260/888800 82.50%] train loss: 1.518758108431939e-05 \n",
      "epoch: 29 [734371/888800 82.62%] train loss: 1.5147986232477706e-05 \n",
      "epoch: 29 [735482/888800 82.75%] train loss: 1.4469283087237272e-05 \n",
      "epoch: 29 [736593/888800 82.88%] train loss: 1.527714812254999e-05 \n",
      "epoch: 29 [737704/888800 83.00%] train loss: 1.451692332921084e-05 \n",
      "epoch: 29 [738815/888800 83.12%] train loss: 1.4773216207686346e-05 \n",
      "epoch: 29 [739926/888800 83.25%] train loss: 1.6105723261716776e-05 \n",
      "epoch: 29 [741037/888800 83.38%] train loss: 1.3883759493182879e-05 \n",
      "epoch: 29 [742148/888800 83.50%] train loss: 1.604516182851512e-05 \n",
      "epoch: 29 [743259/888800 83.62%] train loss: 1.4015697161084972e-05 \n",
      "epoch: 29 [744370/888800 83.75%] train loss: 1.4573010957974475e-05 \n",
      "epoch: 29 [745481/888800 83.88%] train loss: 1.403813439537771e-05 \n",
      "epoch: 29 [746592/888800 84.00%] train loss: 1.4422438653127756e-05 \n",
      "epoch: 29 [747703/888800 84.12%] train loss: 1.4722038940817583e-05 \n",
      "epoch: 29 [748814/888800 84.25%] train loss: 1.4690918760607019e-05 \n",
      "epoch: 29 [749925/888800 84.38%] train loss: 1.550535853311885e-05 \n",
      "epoch: 29 [751036/888800 84.50%] train loss: 1.4311559425550513e-05 \n",
      "epoch: 29 [752147/888800 84.62%] train loss: 1.7077249140129425e-05 \n",
      "epoch: 29 [753258/888800 84.75%] train loss: 1.4606745025957935e-05 \n",
      "epoch: 29 [754369/888800 84.88%] train loss: 1.5064209037518594e-05 \n",
      "epoch: 29 [755480/888800 85.00%] train loss: 1.593150409462396e-05 \n",
      "epoch: 29 [756591/888800 85.12%] train loss: 1.3927619875175878e-05 \n",
      "epoch: 29 [757702/888800 85.25%] train loss: 1.6081719877547584e-05 \n",
      "epoch: 29 [758813/888800 85.38%] train loss: 1.3766795746050775e-05 \n",
      "epoch: 29 [759924/888800 85.50%] train loss: 1.5415458619827405e-05 \n",
      "epoch: 29 [761035/888800 85.62%] train loss: 1.5075531337060966e-05 \n",
      "epoch: 29 [762146/888800 85.75%] train loss: 1.493663603469031e-05 \n",
      "epoch: 29 [763257/888800 85.88%] train loss: 1.4606077456846833e-05 \n",
      "epoch: 29 [764368/888800 86.00%] train loss: 1.3687101272807922e-05 \n",
      "epoch: 29 [765479/888800 86.12%] train loss: 1.556704046379309e-05 \n",
      "epoch: 29 [766590/888800 86.25%] train loss: 1.4047534023120534e-05 \n",
      "epoch: 29 [767701/888800 86.38%] train loss: 1.509729463577969e-05 \n",
      "epoch: 29 [768812/888800 86.50%] train loss: 1.375965712213656e-05 \n",
      "epoch: 29 [769923/888800 86.62%] train loss: 1.299890300288098e-05 \n",
      "epoch: 29 [771034/888800 86.75%] train loss: 1.4287676094681956e-05 \n",
      "epoch: 29 [772145/888800 86.88%] train loss: 1.3698669135919772e-05 \n",
      "epoch: 29 [773256/888800 87.00%] train loss: 1.3820557796861976e-05 \n",
      "epoch: 29 [774367/888800 87.12%] train loss: 1.4652536265202798e-05 \n",
      "epoch: 29 [775478/888800 87.25%] train loss: 1.5041447113617323e-05 \n",
      "epoch: 29 [776589/888800 87.38%] train loss: 1.4382927474798635e-05 \n",
      "epoch: 29 [777700/888800 87.50%] train loss: 1.3303267223818693e-05 \n",
      "epoch: 29 [778811/888800 87.62%] train loss: 1.3765425137535203e-05 \n",
      "epoch: 29 [779922/888800 87.75%] train loss: 1.4464970263361465e-05 \n",
      "epoch: 29 [781033/888800 87.88%] train loss: 1.3359759577724617e-05 \n",
      "epoch: 29 [782144/888800 88.00%] train loss: 1.3646614206663799e-05 \n",
      "epoch: 29 [783255/888800 88.12%] train loss: 1.4610512153012678e-05 \n",
      "epoch: 29 [784366/888800 88.25%] train loss: 1.4713971722812857e-05 \n",
      "epoch: 29 [785477/888800 88.38%] train loss: 1.466792218707269e-05 \n",
      "epoch: 29 [786588/888800 88.50%] train loss: 1.4349217053677421e-05 \n",
      "epoch: 29 [787699/888800 88.62%] train loss: 1.5372961570392363e-05 \n",
      "epoch: 29 [788810/888800 88.75%] train loss: 1.34974889078876e-05 \n",
      "epoch: 29 [789921/888800 88.88%] train loss: 1.4845714758848771e-05 \n",
      "epoch: 29 [791032/888800 89.00%] train loss: 1.4106475646258332e-05 \n",
      "epoch: 29 [792143/888800 89.12%] train loss: 1.4118537364993244e-05 \n",
      "epoch: 29 [793254/888800 89.25%] train loss: 1.4847773854853585e-05 \n",
      "epoch: 29 [794365/888800 89.38%] train loss: 1.5254398931574542e-05 \n",
      "epoch: 29 [795476/888800 89.50%] train loss: 1.3444631804304663e-05 \n",
      "epoch: 29 [796587/888800 89.62%] train loss: 1.6512760339537635e-05 \n",
      "epoch: 29 [797698/888800 89.75%] train loss: 1.4150783499644604e-05 \n",
      "epoch: 29 [798809/888800 89.88%] train loss: 1.6505409803357907e-05 \n",
      "epoch: 29 [799920/888800 90.00%] train loss: 1.4512673260469455e-05 \n",
      "epoch: 29 [801031/888800 90.12%] train loss: 1.468225491407793e-05 \n",
      "epoch: 29 [802142/888800 90.25%] train loss: 1.4637752428825479e-05 \n",
      "epoch: 29 [803253/888800 90.38%] train loss: 1.4262442164181266e-05 \n",
      "epoch: 29 [804364/888800 90.50%] train loss: 1.400082965119509e-05 \n",
      "epoch: 29 [805475/888800 90.62%] train loss: 1.4476503565674648e-05 \n",
      "epoch: 29 [806586/888800 90.75%] train loss: 1.4425957488128915e-05 \n",
      "epoch: 29 [807697/888800 90.88%] train loss: 1.3044375918980222e-05 \n",
      "epoch: 29 [808808/888800 91.00%] train loss: 1.3659236174135003e-05 \n",
      "epoch: 29 [809919/888800 91.12%] train loss: 1.2994911230634898e-05 \n",
      "epoch: 29 [811030/888800 91.25%] train loss: 1.4203664250089787e-05 \n",
      "epoch: 29 [812141/888800 91.38%] train loss: 1.4868499420117587e-05 \n",
      "epoch: 29 [813252/888800 91.50%] train loss: 1.3820280400977936e-05 \n",
      "epoch: 29 [814363/888800 91.62%] train loss: 1.4430857845582068e-05 \n",
      "epoch: 29 [815474/888800 91.75%] train loss: 1.4566767276846804e-05 \n",
      "epoch: 29 [816585/888800 91.88%] train loss: 1.4091303455643356e-05 \n",
      "epoch: 29 [817696/888800 92.00%] train loss: 1.4967921742936596e-05 \n",
      "epoch: 29 [818807/888800 92.12%] train loss: 1.3801663953927346e-05 \n",
      "epoch: 29 [819918/888800 92.25%] train loss: 1.3897623830416705e-05 \n",
      "epoch: 29 [821029/888800 92.38%] train loss: 1.3389609193836804e-05 \n",
      "epoch: 29 [822140/888800 92.50%] train loss: 1.4283683412941173e-05 \n",
      "epoch: 29 [823251/888800 92.62%] train loss: 1.4281371477409266e-05 \n",
      "epoch: 29 [824362/888800 92.75%] train loss: 1.407143736287253e-05 \n",
      "epoch: 29 [825473/888800 92.88%] train loss: 1.2983071428607218e-05 \n",
      "epoch: 29 [826584/888800 93.00%] train loss: 1.3544475223170593e-05 \n",
      "epoch: 29 [827695/888800 93.12%] train loss: 1.4713944437971804e-05 \n",
      "epoch: 29 [828806/888800 93.25%] train loss: 1.3375190974329598e-05 \n",
      "epoch: 29 [829917/888800 93.38%] train loss: 1.4537798051605932e-05 \n",
      "epoch: 29 [831028/888800 93.50%] train loss: 1.4641816051153e-05 \n",
      "epoch: 29 [832139/888800 93.62%] train loss: 1.3175370440876577e-05 \n",
      "epoch: 29 [833250/888800 93.75%] train loss: 1.5147456906561274e-05 \n",
      "epoch: 29 [834361/888800 93.88%] train loss: 1.37282313517062e-05 \n",
      "epoch: 29 [835472/888800 94.00%] train loss: 1.5173439351201523e-05 \n",
      "epoch: 29 [836583/888800 94.12%] train loss: 1.3598889381682966e-05 \n",
      "epoch: 29 [837694/888800 94.25%] train loss: 1.4333199032989796e-05 \n",
      "epoch: 29 [838805/888800 94.38%] train loss: 1.4066079529584385e-05 \n",
      "epoch: 29 [839916/888800 94.50%] train loss: 1.2990030882065184e-05 \n",
      "epoch: 29 [841027/888800 94.62%] train loss: 1.3696756468561944e-05 \n",
      "epoch: 29 [842138/888800 94.75%] train loss: 1.3575931916420814e-05 \n",
      "epoch: 29 [843249/888800 94.88%] train loss: 1.3525770555133931e-05 \n",
      "epoch: 29 [844360/888800 95.00%] train loss: 1.4917632142896764e-05 \n",
      "epoch: 29 [845471/888800 95.12%] train loss: 1.4530684893543366e-05 \n",
      "epoch: 29 [846582/888800 95.25%] train loss: 1.550458910060115e-05 \n",
      "epoch: 29 [847693/888800 95.38%] train loss: 1.241086829395499e-05 \n",
      "epoch: 29 [848804/888800 95.50%] train loss: 1.3548170500143897e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 [849915/888800 95.62%] train loss: 1.4568645383405965e-05 \n",
      "epoch: 29 [851026/888800 95.75%] train loss: 1.4839501091046259e-05 \n",
      "epoch: 29 [852137/888800 95.88%] train loss: 1.3762480193690863e-05 \n",
      "epoch: 29 [853248/888800 96.00%] train loss: 1.5726720448583364e-05 \n",
      "epoch: 29 [854359/888800 96.12%] train loss: 1.5319872545660473e-05 \n",
      "epoch: 29 [855470/888800 96.25%] train loss: 1.4523172467306722e-05 \n",
      "epoch: 29 [856581/888800 96.38%] train loss: 1.4351106074173003e-05 \n",
      "epoch: 29 [857692/888800 96.50%] train loss: 1.4388647286978085e-05 \n",
      "epoch: 29 [858803/888800 96.62%] train loss: 1.4082454072195105e-05 \n",
      "epoch: 29 [859914/888800 96.75%] train loss: 1.4426024790736847e-05 \n",
      "epoch: 29 [861025/888800 96.88%] train loss: 1.4010578524903394e-05 \n",
      "epoch: 29 [862136/888800 97.00%] train loss: 1.4399755855265539e-05 \n",
      "epoch: 29 [863247/888800 97.12%] train loss: 1.489421720179962e-05 \n",
      "epoch: 29 [864358/888800 97.25%] train loss: 1.41129739859025e-05 \n",
      "epoch: 29 [865469/888800 97.38%] train loss: 1.3960921933175996e-05 \n",
      "epoch: 29 [866580/888800 97.50%] train loss: 1.4668403309769928e-05 \n",
      "epoch: 29 [867691/888800 97.62%] train loss: 1.4286875739344396e-05 \n",
      "epoch: 29 [868802/888800 97.75%] train loss: 1.3780629160464741e-05 \n",
      "epoch: 29 [869913/888800 97.88%] train loss: 1.2863005395047367e-05 \n",
      "epoch: 29 [871024/888800 98.00%] train loss: 1.4348104741657153e-05 \n",
      "epoch: 29 [872135/888800 98.12%] train loss: 1.4954040125303436e-05 \n",
      "epoch: 29 [873246/888800 98.25%] train loss: 1.3737058907281607e-05 \n",
      "epoch: 29 [874357/888800 98.38%] train loss: 1.4814212590863463e-05 \n",
      "epoch: 29 [875468/888800 98.50%] train loss: 1.420682565367315e-05 \n",
      "epoch: 29 [876579/888800 98.62%] train loss: 1.4548268154612742e-05 \n",
      "epoch: 29 [877690/888800 98.75%] train loss: 1.3189849596528802e-05 \n",
      "epoch: 29 [878801/888800 98.88%] train loss: 1.4517245290335268e-05 \n",
      "epoch: 29 [879912/888800 99.00%] train loss: 1.4965371519792825e-05 \n",
      "epoch: 29 [881023/888800 99.12%] train loss: 1.493117815698497e-05 \n",
      "epoch: 29 [882134/888800 99.25%] train loss: 1.547379360999912e-05 \n",
      "epoch: 29 [883245/888800 99.38%] train loss: 1.2976217476534657e-05 \n",
      "epoch: 29 [884356/888800 99.50%] train loss: 1.5642744983779266e-05 \n",
      "epoch: 29 [885467/888800 99.62%] train loss: 1.4423007087316364e-05 \n",
      "epoch: 29 [886578/888800 99.75%] train loss: 1.55550405906979e-05 \n",
      "epoch: 29 [887689/888800 99.88%] train loss: 1.4455330529017374e-05 \n",
      "epoch: 30 [0/888800 0.00%] train loss: 1.5126680409593973e-05 \n",
      "epoch: 30 [1111/888800 0.12%] train loss: 1.4150276001601014e-05 \n",
      "epoch: 30 [2222/888800 0.25%] train loss: 1.5176283341133967e-05 \n",
      "epoch: 30 [3333/888800 0.38%] train loss: 1.6462114217574708e-05 \n",
      "epoch: 30 [4444/888800 0.50%] train loss: 1.4991973330324981e-05 \n",
      "epoch: 30 [5555/888800 0.62%] train loss: 1.5736217392259277e-05 \n",
      "epoch: 30 [6666/888800 0.75%] train loss: 1.545133454783354e-05 \n",
      "epoch: 30 [7777/888800 0.88%] train loss: 1.5951834939187393e-05 \n",
      "epoch: 30 [8888/888800 1.00%] train loss: 1.4153532902128063e-05 \n",
      "epoch: 30 [9999/888800 1.12%] train loss: 1.608547790965531e-05 \n",
      "epoch: 30 [11110/888800 1.25%] train loss: 1.5317553334170952e-05 \n",
      "epoch: 30 [12221/888800 1.38%] train loss: 1.4794747585256118e-05 \n",
      "epoch: 30 [13332/888800 1.50%] train loss: 1.4774745068280026e-05 \n",
      "epoch: 30 [14443/888800 1.62%] train loss: 1.365642310702242e-05 \n",
      "epoch: 30 [15554/888800 1.75%] train loss: 1.4176804143062327e-05 \n",
      "epoch: 30 [16665/888800 1.88%] train loss: 1.4246445971366484e-05 \n",
      "epoch: 30 [17776/888800 2.00%] train loss: 1.4065254617889877e-05 \n",
      "epoch: 30 [18887/888800 2.12%] train loss: 1.4052781807549763e-05 \n",
      "epoch: 30 [19998/888800 2.25%] train loss: 1.427225288352929e-05 \n",
      "epoch: 30 [21109/888800 2.38%] train loss: 1.6661271729390137e-05 \n",
      "epoch: 30 [22220/888800 2.50%] train loss: 1.2617543688975275e-05 \n",
      "epoch: 30 [23331/888800 2.62%] train loss: 1.4207475942384917e-05 \n",
      "epoch: 30 [24442/888800 2.75%] train loss: 1.5025893844722304e-05 \n",
      "epoch: 30 [25553/888800 2.88%] train loss: 1.4065401956031565e-05 \n",
      "epoch: 30 [26664/888800 3.00%] train loss: 1.51204358189716e-05 \n",
      "epoch: 30 [27775/888800 3.12%] train loss: 1.4549778825312387e-05 \n",
      "epoch: 30 [28886/888800 3.25%] train loss: 1.5439907656400464e-05 \n",
      "epoch: 30 [29997/888800 3.38%] train loss: 1.3980095900478773e-05 \n",
      "epoch: 30 [31108/888800 3.50%] train loss: 1.5613497453159653e-05 \n",
      "epoch: 30 [32219/888800 3.62%] train loss: 1.4637531421612948e-05 \n",
      "epoch: 30 [33330/888800 3.75%] train loss: 1.4364736671268474e-05 \n",
      "epoch: 30 [34441/888800 3.88%] train loss: 1.3166752069082577e-05 \n",
      "epoch: 30 [35552/888800 4.00%] train loss: 1.3501847206498496e-05 \n",
      "epoch: 30 [36663/888800 4.12%] train loss: 1.5033579074952286e-05 \n",
      "epoch: 30 [37774/888800 4.25%] train loss: 1.3425315046333708e-05 \n",
      "epoch: 30 [38885/888800 4.38%] train loss: 1.581423384777736e-05 \n",
      "epoch: 30 [39996/888800 4.50%] train loss: 1.4557784197677393e-05 \n",
      "epoch: 30 [41107/888800 4.62%] train loss: 1.4967090464779176e-05 \n",
      "epoch: 30 [42218/888800 4.75%] train loss: 1.3578103789768647e-05 \n",
      "epoch: 30 [43329/888800 4.88%] train loss: 1.4048946468392387e-05 \n",
      "epoch: 30 [44440/888800 5.00%] train loss: 1.3016066986892838e-05 \n",
      "epoch: 30 [45551/888800 5.12%] train loss: 1.4357930012920406e-05 \n",
      "epoch: 30 [46662/888800 5.25%] train loss: 1.3961885088065173e-05 \n",
      "epoch: 30 [47773/888800 5.38%] train loss: 1.4273564374889247e-05 \n",
      "epoch: 30 [48884/888800 5.50%] train loss: 1.4389599527930841e-05 \n",
      "epoch: 30 [49995/888800 5.62%] train loss: 1.343467829428846e-05 \n",
      "epoch: 30 [51106/888800 5.75%] train loss: 1.3494218364940025e-05 \n",
      "epoch: 30 [52217/888800 5.88%] train loss: 1.427512506779749e-05 \n",
      "epoch: 30 [53328/888800 6.00%] train loss: 1.3101945114613045e-05 \n",
      "epoch: 30 [54439/888800 6.12%] train loss: 1.3393220797297545e-05 \n",
      "epoch: 30 [55550/888800 6.25%] train loss: 1.4129516785033047e-05 \n",
      "epoch: 30 [56661/888800 6.38%] train loss: 1.4989512237661984e-05 \n",
      "epoch: 30 [57772/888800 6.50%] train loss: 1.3861958905181382e-05 \n",
      "epoch: 30 [58883/888800 6.62%] train loss: 1.4205097613739781e-05 \n",
      "epoch: 30 [59994/888800 6.75%] train loss: 1.6360756490030326e-05 \n",
      "epoch: 30 [61105/888800 6.88%] train loss: 1.4072862541070208e-05 \n",
      "epoch: 30 [62216/888800 7.00%] train loss: 1.5282064850907773e-05 \n",
      "epoch: 30 [63327/888800 7.12%] train loss: 1.4716751138621476e-05 \n",
      "epoch: 30 [64438/888800 7.25%] train loss: 1.4680323147331364e-05 \n",
      "epoch: 30 [65549/888800 7.38%] train loss: 1.3723010852118023e-05 \n",
      "epoch: 30 [66660/888800 7.50%] train loss: 1.3779404980596155e-05 \n",
      "epoch: 30 [67771/888800 7.62%] train loss: 1.5502575479331426e-05 \n",
      "epoch: 30 [68882/888800 7.75%] train loss: 1.4047940567252226e-05 \n",
      "epoch: 30 [69993/888800 7.88%] train loss: 1.4195327821653336e-05 \n",
      "epoch: 30 [71104/888800 8.00%] train loss: 1.4118183571554255e-05 \n",
      "epoch: 30 [72215/888800 8.12%] train loss: 1.429938492947258e-05 \n",
      "epoch: 30 [73326/888800 8.25%] train loss: 1.5205740055534989e-05 \n",
      "epoch: 30 [74437/888800 8.38%] train loss: 1.4257830116548575e-05 \n",
      "epoch: 30 [75548/888800 8.50%] train loss: 1.6209018212975934e-05 \n",
      "epoch: 30 [76659/888800 8.62%] train loss: 1.562171382829547e-05 \n",
      "epoch: 30 [77770/888800 8.75%] train loss: 1.4095578080741689e-05 \n",
      "epoch: 30 [78881/888800 8.88%] train loss: 1.3616699106933083e-05 \n",
      "epoch: 30 [79992/888800 9.00%] train loss: 1.2855038221459836e-05 \n",
      "epoch: 30 [81103/888800 9.12%] train loss: 1.3538166058424395e-05 \n",
      "epoch: 30 [82214/888800 9.25%] train loss: 1.3225870134192519e-05 \n",
      "epoch: 30 [83325/888800 9.38%] train loss: 1.3156295608496293e-05 \n",
      "epoch: 30 [84436/888800 9.50%] train loss: 1.5112285836949013e-05 \n",
      "epoch: 30 [85547/888800 9.62%] train loss: 1.4198922144714743e-05 \n",
      "epoch: 30 [86658/888800 9.75%] train loss: 1.4622899470850825e-05 \n",
      "epoch: 30 [87769/888800 9.88%] train loss: 1.3435645087156445e-05 \n",
      "epoch: 30 [88880/888800 10.00%] train loss: 1.4869732694933191e-05 \n",
      "epoch: 30 [89991/888800 10.12%] train loss: 1.4012503015692346e-05 \n",
      "epoch: 30 [91102/888800 10.25%] train loss: 1.5930505469441414e-05 \n",
      "epoch: 30 [92213/888800 10.38%] train loss: 1.4414825272979215e-05 \n",
      "epoch: 30 [93324/888800 10.50%] train loss: 1.3416947695077397e-05 \n",
      "epoch: 30 [94435/888800 10.62%] train loss: 1.4785885468882043e-05 \n",
      "epoch: 30 [95546/888800 10.75%] train loss: 1.3352500900509767e-05 \n",
      "epoch: 30 [96657/888800 10.88%] train loss: 1.5012621588539332e-05 \n",
      "epoch: 30 [97768/888800 11.00%] train loss: 1.5685054677305743e-05 \n",
      "epoch: 30 [98879/888800 11.12%] train loss: 1.4987828762969002e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [99990/888800 11.25%] train loss: 1.5431103747687303e-05 \n",
      "epoch: 30 [101101/888800 11.38%] train loss: 1.4022056348039769e-05 \n",
      "epoch: 30 [102212/888800 11.50%] train loss: 1.546360545034986e-05 \n",
      "epoch: 30 [103323/888800 11.62%] train loss: 1.3598807527159806e-05 \n",
      "epoch: 30 [104434/888800 11.75%] train loss: 1.4215431292541325e-05 \n",
      "epoch: 30 [105545/888800 11.88%] train loss: 1.4553066648659296e-05 \n",
      "epoch: 30 [106656/888800 12.00%] train loss: 1.4149980415822938e-05 \n",
      "epoch: 30 [107767/888800 12.12%] train loss: 1.2963268090970814e-05 \n",
      "epoch: 30 [108878/888800 12.25%] train loss: 1.4765766536584124e-05 \n",
      "epoch: 30 [109989/888800 12.38%] train loss: 1.3416620276984759e-05 \n",
      "epoch: 30 [111100/888800 12.50%] train loss: 1.4075414583203383e-05 \n",
      "epoch: 30 [112211/888800 12.62%] train loss: 1.373821487504756e-05 \n",
      "epoch: 30 [113322/888800 12.75%] train loss: 1.5163209354795981e-05 \n",
      "epoch: 30 [114433/888800 12.88%] train loss: 1.3257200407679193e-05 \n",
      "epoch: 30 [115544/888800 13.00%] train loss: 1.65024302987149e-05 \n",
      "epoch: 30 [116655/888800 13.12%] train loss: 1.5168985555646941e-05 \n",
      "epoch: 30 [117766/888800 13.25%] train loss: 1.3940239114162978e-05 \n",
      "epoch: 30 [118877/888800 13.38%] train loss: 1.3981600204715505e-05 \n",
      "epoch: 30 [119988/888800 13.50%] train loss: 1.460304429201642e-05 \n",
      "epoch: 30 [121099/888800 13.62%] train loss: 1.3816220416629221e-05 \n",
      "epoch: 30 [122210/888800 13.75%] train loss: 1.4538338291458786e-05 \n",
      "epoch: 30 [123321/888800 13.88%] train loss: 1.5243821508192923e-05 \n",
      "epoch: 30 [124432/888800 14.00%] train loss: 1.4214435395842884e-05 \n",
      "epoch: 30 [125543/888800 14.12%] train loss: 1.5674319001846015e-05 \n",
      "epoch: 30 [126654/888800 14.25%] train loss: 1.4030201782588847e-05 \n",
      "epoch: 30 [127765/888800 14.38%] train loss: 1.5297831851057708e-05 \n",
      "epoch: 30 [128876/888800 14.50%] train loss: 1.4488673514279071e-05 \n",
      "epoch: 30 [129987/888800 14.62%] train loss: 1.4738313439011108e-05 \n",
      "epoch: 30 [131098/888800 14.75%] train loss: 1.4056136024009902e-05 \n",
      "epoch: 30 [132209/888800 14.88%] train loss: 1.392694321111776e-05 \n",
      "epoch: 30 [133320/888800 15.00%] train loss: 1.4231214663595892e-05 \n",
      "epoch: 30 [134431/888800 15.12%] train loss: 1.4586694305762649e-05 \n",
      "epoch: 30 [135542/888800 15.25%] train loss: 1.3657924682775047e-05 \n",
      "epoch: 30 [136653/888800 15.38%] train loss: 1.393811635352904e-05 \n",
      "epoch: 30 [137764/888800 15.50%] train loss: 1.4913024642737582e-05 \n",
      "epoch: 30 [138875/888800 15.62%] train loss: 1.3601316823041998e-05 \n",
      "epoch: 30 [139986/888800 15.75%] train loss: 1.4366010873345658e-05 \n",
      "epoch: 30 [141097/888800 15.88%] train loss: 1.4215806913853157e-05 \n",
      "epoch: 30 [142208/888800 16.00%] train loss: 1.4663252841273788e-05 \n",
      "epoch: 30 [143319/888800 16.12%] train loss: 1.3473069884639699e-05 \n",
      "epoch: 30 [144430/888800 16.25%] train loss: 1.464018987462623e-05 \n",
      "epoch: 30 [145541/888800 16.38%] train loss: 1.4348128388519399e-05 \n",
      "epoch: 30 [146652/888800 16.50%] train loss: 1.5355402865679935e-05 \n",
      "epoch: 30 [147763/888800 16.62%] train loss: 1.351816717942711e-05 \n",
      "epoch: 30 [148874/888800 16.75%] train loss: 1.4988558177719824e-05 \n",
      "epoch: 30 [149985/888800 16.88%] train loss: 1.3911903806729242e-05 \n",
      "epoch: 30 [151096/888800 17.00%] train loss: 1.4846084013697691e-05 \n",
      "epoch: 30 [152207/888800 17.12%] train loss: 1.4175309843267314e-05 \n",
      "epoch: 30 [153318/888800 17.25%] train loss: 1.3950319043942727e-05 \n",
      "epoch: 30 [154429/888800 17.38%] train loss: 1.6171246898011304e-05 \n",
      "epoch: 30 [155540/888800 17.50%] train loss: 1.2908031749248039e-05 \n",
      "epoch: 30 [156651/888800 17.62%] train loss: 1.4902713701303583e-05 \n",
      "epoch: 30 [157762/888800 17.75%] train loss: 1.3029357432969846e-05 \n",
      "epoch: 30 [158873/888800 17.88%] train loss: 1.607021113159135e-05 \n",
      "epoch: 30 [159984/888800 18.00%] train loss: 1.4390823707799427e-05 \n",
      "epoch: 30 [161095/888800 18.12%] train loss: 1.2460282050597016e-05 \n",
      "epoch: 30 [162206/888800 18.25%] train loss: 1.4715933502884582e-05 \n",
      "epoch: 30 [163317/888800 18.38%] train loss: 1.5052456546982285e-05 \n",
      "epoch: 30 [164428/888800 18.50%] train loss: 1.3813730220135767e-05 \n",
      "epoch: 30 [165539/888800 18.62%] train loss: 1.4461085811490193e-05 \n",
      "epoch: 30 [166650/888800 18.75%] train loss: 1.4882780305924825e-05 \n",
      "epoch: 30 [167761/888800 18.88%] train loss: 1.3061378012935165e-05 \n",
      "epoch: 30 [168872/888800 19.00%] train loss: 1.445353336748667e-05 \n",
      "epoch: 30 [169983/888800 19.12%] train loss: 1.414111193298595e-05 \n",
      "epoch: 30 [171094/888800 19.25%] train loss: 1.369947858620435e-05 \n",
      "epoch: 30 [172205/888800 19.38%] train loss: 1.533003887743689e-05 \n",
      "epoch: 30 [173316/888800 19.50%] train loss: 1.3817849321640097e-05 \n",
      "epoch: 30 [174427/888800 19.62%] train loss: 1.4222408026398625e-05 \n",
      "epoch: 30 [175538/888800 19.75%] train loss: 1.4119352272246033e-05 \n",
      "epoch: 30 [176649/888800 19.88%] train loss: 1.4610468497266993e-05 \n",
      "epoch: 30 [177760/888800 20.00%] train loss: 1.334132412011968e-05 \n",
      "epoch: 30 [178871/888800 20.12%] train loss: 1.4004111108079087e-05 \n",
      "epoch: 30 [179982/888800 20.25%] train loss: 1.4286070836533327e-05 \n",
      "epoch: 30 [181093/888800 20.38%] train loss: 1.4270429346652236e-05 \n",
      "epoch: 30 [182204/888800 20.50%] train loss: 1.3476669664669316e-05 \n",
      "epoch: 30 [183315/888800 20.62%] train loss: 1.3802090506942477e-05 \n",
      "epoch: 30 [184426/888800 20.75%] train loss: 1.48917961269035e-05 \n",
      "epoch: 30 [185537/888800 20.88%] train loss: 1.4604159332520794e-05 \n",
      "epoch: 30 [186648/888800 21.00%] train loss: 1.3003238564124331e-05 \n",
      "epoch: 30 [187759/888800 21.12%] train loss: 1.4176213881000876e-05 \n",
      "epoch: 30 [188870/888800 21.25%] train loss: 1.3595792552223429e-05 \n",
      "epoch: 30 [189981/888800 21.38%] train loss: 1.3748842320637777e-05 \n",
      "epoch: 30 [191092/888800 21.50%] train loss: 1.312057975155767e-05 \n",
      "epoch: 30 [192203/888800 21.62%] train loss: 1.4212938367563765e-05 \n",
      "epoch: 30 [193314/888800 21.75%] train loss: 1.4576688954548445e-05 \n",
      "epoch: 30 [194425/888800 21.88%] train loss: 1.359867565042805e-05 \n",
      "epoch: 30 [195536/888800 22.00%] train loss: 1.4305956938187592e-05 \n",
      "epoch: 30 [196647/888800 22.12%] train loss: 1.4061899491935037e-05 \n",
      "epoch: 30 [197758/888800 22.25%] train loss: 1.4115178601059597e-05 \n",
      "epoch: 30 [198869/888800 22.38%] train loss: 1.5667361367377453e-05 \n",
      "epoch: 30 [199980/888800 22.50%] train loss: 1.4965643458708655e-05 \n",
      "epoch: 30 [201091/888800 22.62%] train loss: 1.373397208226379e-05 \n",
      "epoch: 30 [202202/888800 22.75%] train loss: 1.4307559467852116e-05 \n",
      "epoch: 30 [203313/888800 22.88%] train loss: 1.493059880885994e-05 \n",
      "epoch: 30 [204424/888800 23.00%] train loss: 1.3438760106510017e-05 \n",
      "epoch: 30 [205535/888800 23.12%] train loss: 1.4129273949947674e-05 \n",
      "epoch: 30 [206646/888800 23.25%] train loss: 1.5611771232215688e-05 \n",
      "epoch: 30 [207757/888800 23.38%] train loss: 1.4867696336295921e-05 \n",
      "epoch: 30 [208868/888800 23.50%] train loss: 1.3766831216344144e-05 \n",
      "epoch: 30 [209979/888800 23.62%] train loss: 1.4870394807076082e-05 \n",
      "epoch: 30 [211090/888800 23.75%] train loss: 1.5951507521094754e-05 \n",
      "epoch: 30 [212201/888800 23.88%] train loss: 1.48415738294716e-05 \n",
      "epoch: 30 [213312/888800 24.00%] train loss: 1.409864125889726e-05 \n",
      "epoch: 30 [214423/888800 24.12%] train loss: 1.3977120033814572e-05 \n",
      "epoch: 30 [215534/888800 24.25%] train loss: 1.4533263311022893e-05 \n",
      "epoch: 30 [216645/888800 24.38%] train loss: 1.4652549907623325e-05 \n",
      "epoch: 30 [217756/888800 24.50%] train loss: 1.4093128811509814e-05 \n",
      "epoch: 30 [218867/888800 24.62%] train loss: 1.4656331586593296e-05 \n",
      "epoch: 30 [219978/888800 24.75%] train loss: 1.3621885045722593e-05 \n",
      "epoch: 30 [221089/888800 24.88%] train loss: 1.3479525478032883e-05 \n",
      "epoch: 30 [222200/888800 25.00%] train loss: 1.3687189493793994e-05 \n",
      "epoch: 30 [223311/888800 25.12%] train loss: 1.4108437426330056e-05 \n",
      "epoch: 30 [224422/888800 25.25%] train loss: 1.3611725080409087e-05 \n",
      "epoch: 30 [225533/888800 25.38%] train loss: 1.381131551170256e-05 \n",
      "epoch: 30 [226644/888800 25.50%] train loss: 1.368287848890759e-05 \n",
      "epoch: 30 [227755/888800 25.62%] train loss: 1.3581902749137953e-05 \n",
      "epoch: 30 [228866/888800 25.75%] train loss: 1.3919481716584414e-05 \n",
      "epoch: 30 [229977/888800 25.88%] train loss: 1.4981361346144695e-05 \n",
      "epoch: 30 [231088/888800 26.00%] train loss: 1.5058018107083626e-05 \n",
      "epoch: 30 [232199/888800 26.12%] train loss: 1.5485880794585682e-05 \n",
      "epoch: 30 [233310/888800 26.25%] train loss: 1.4480820937023964e-05 \n",
      "epoch: 30 [234421/888800 26.38%] train loss: 1.4447021385421976e-05 \n",
      "epoch: 30 [235532/888800 26.50%] train loss: 1.5153663298406173e-05 \n",
      "epoch: 30 [236643/888800 26.62%] train loss: 1.6147669157362543e-05 \n",
      "epoch: 30 [237754/888800 26.75%] train loss: 1.544909355288837e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [238865/888800 26.88%] train loss: 1.3203240996517707e-05 \n",
      "epoch: 30 [239976/888800 27.00%] train loss: 1.4515154362015892e-05 \n",
      "epoch: 30 [241087/888800 27.12%] train loss: 1.5541170796495862e-05 \n",
      "epoch: 30 [242198/888800 27.25%] train loss: 1.597070695424918e-05 \n",
      "epoch: 30 [243309/888800 27.38%] train loss: 1.2122403859393671e-05 \n",
      "epoch: 30 [244420/888800 27.50%] train loss: 1.5128162885957863e-05 \n",
      "epoch: 30 [245531/888800 27.62%] train loss: 1.4429610928345937e-05 \n",
      "epoch: 30 [246642/888800 27.75%] train loss: 1.4985709640313871e-05 \n",
      "epoch: 30 [247753/888800 27.88%] train loss: 1.4223432117432822e-05 \n",
      "epoch: 30 [248864/888800 28.00%] train loss: 1.4376807484950405e-05 \n",
      "epoch: 30 [249975/888800 28.12%] train loss: 1.4638986613135785e-05 \n",
      "epoch: 30 [251086/888800 28.25%] train loss: 1.5319623344112188e-05 \n",
      "epoch: 30 [252197/888800 28.38%] train loss: 1.3676315575139597e-05 \n",
      "epoch: 30 [253308/888800 28.50%] train loss: 1.3577365280070808e-05 \n",
      "epoch: 30 [254419/888800 28.62%] train loss: 1.4990989257057663e-05 \n",
      "epoch: 30 [255530/888800 28.75%] train loss: 1.417449220753042e-05 \n",
      "epoch: 30 [256641/888800 28.88%] train loss: 1.5547755538136698e-05 \n",
      "epoch: 30 [257752/888800 29.00%] train loss: 1.3950521861261223e-05 \n",
      "epoch: 30 [258863/888800 29.12%] train loss: 1.4846702470094897e-05 \n",
      "epoch: 30 [259974/888800 29.25%] train loss: 1.3838518498232588e-05 \n",
      "epoch: 30 [261085/888800 29.38%] train loss: 1.2989571587240789e-05 \n",
      "epoch: 30 [262196/888800 29.50%] train loss: 1.3051800124230795e-05 \n",
      "epoch: 30 [263307/888800 29.62%] train loss: 1.4462415492744185e-05 \n",
      "epoch: 30 [264418/888800 29.75%] train loss: 1.3589663467428181e-05 \n",
      "epoch: 30 [265529/888800 29.88%] train loss: 1.452368996979203e-05 \n",
      "epoch: 30 [266640/888800 30.00%] train loss: 1.4740360711584799e-05 \n",
      "epoch: 30 [267751/888800 30.12%] train loss: 1.2891572623630054e-05 \n",
      "epoch: 30 [268862/888800 30.25%] train loss: 1.505017644376494e-05 \n",
      "epoch: 30 [269973/888800 30.38%] train loss: 1.5028263987915125e-05 \n",
      "epoch: 30 [271084/888800 30.50%] train loss: 1.3412929547484964e-05 \n",
      "epoch: 30 [272195/888800 30.62%] train loss: 1.4334181287267711e-05 \n",
      "epoch: 30 [273306/888800 30.75%] train loss: 1.5224928574752994e-05 \n",
      "epoch: 30 [274417/888800 30.88%] train loss: 1.5057647033245303e-05 \n",
      "epoch: 30 [275528/888800 31.00%] train loss: 1.4221488527255133e-05 \n",
      "epoch: 30 [276639/888800 31.12%] train loss: 1.450393392588012e-05 \n",
      "epoch: 30 [277750/888800 31.25%] train loss: 1.308154605794698e-05 \n",
      "epoch: 30 [278861/888800 31.38%] train loss: 1.3913136172050145e-05 \n",
      "epoch: 30 [279972/888800 31.50%] train loss: 1.3357199350139126e-05 \n",
      "epoch: 30 [281083/888800 31.62%] train loss: 1.4932707927073352e-05 \n",
      "epoch: 30 [282194/888800 31.75%] train loss: 1.4401070984604303e-05 \n",
      "epoch: 30 [283305/888800 31.88%] train loss: 1.4871883649902884e-05 \n",
      "epoch: 30 [284416/888800 32.00%] train loss: 1.4627974451286718e-05 \n",
      "epoch: 30 [285527/888800 32.12%] train loss: 1.3637312804348767e-05 \n",
      "epoch: 30 [286638/888800 32.25%] train loss: 1.493450781708816e-05 \n",
      "epoch: 30 [287749/888800 32.38%] train loss: 1.389083899994148e-05 \n",
      "epoch: 30 [288860/888800 32.50%] train loss: 1.4996811842138413e-05 \n",
      "epoch: 30 [289971/888800 32.62%] train loss: 1.3998381291457918e-05 \n",
      "epoch: 30 [291082/888800 32.75%] train loss: 1.4744734471605625e-05 \n",
      "epoch: 30 [292193/888800 32.88%] train loss: 1.584581332281232e-05 \n",
      "epoch: 30 [293304/888800 33.00%] train loss: 1.435186368325958e-05 \n",
      "epoch: 30 [294415/888800 33.12%] train loss: 1.6157580830622464e-05 \n",
      "epoch: 30 [295526/888800 33.25%] train loss: 1.3320521247806028e-05 \n",
      "epoch: 30 [296637/888800 33.38%] train loss: 1.4786682186240796e-05 \n",
      "epoch: 30 [297748/888800 33.50%] train loss: 1.433008219464682e-05 \n",
      "epoch: 30 [298859/888800 33.62%] train loss: 1.4939695574867073e-05 \n",
      "epoch: 30 [299970/888800 33.75%] train loss: 1.5153465028561186e-05 \n",
      "epoch: 30 [301081/888800 33.88%] train loss: 1.309948493144475e-05 \n",
      "epoch: 30 [302192/888800 34.00%] train loss: 1.4351072422869038e-05 \n",
      "epoch: 30 [303303/888800 34.12%] train loss: 1.4829899555479642e-05 \n",
      "epoch: 30 [304414/888800 34.25%] train loss: 1.5017054465715773e-05 \n",
      "epoch: 30 [305525/888800 34.38%] train loss: 1.4357332474901341e-05 \n",
      "epoch: 30 [306636/888800 34.50%] train loss: 1.3689415027329233e-05 \n",
      "epoch: 30 [307747/888800 34.62%] train loss: 1.3530080650525633e-05 \n",
      "epoch: 30 [308858/888800 34.75%] train loss: 1.4091147022554651e-05 \n",
      "epoch: 30 [309969/888800 34.88%] train loss: 1.5029788301035296e-05 \n",
      "epoch: 30 [311080/888800 35.00%] train loss: 1.4548080798704177e-05 \n",
      "epoch: 30 [312191/888800 35.12%] train loss: 1.6316540495608933e-05 \n",
      "epoch: 30 [313302/888800 35.25%] train loss: 1.3678001778316684e-05 \n",
      "epoch: 30 [314413/888800 35.38%] train loss: 1.4127632312010974e-05 \n",
      "epoch: 30 [315524/888800 35.50%] train loss: 1.3313518138602376e-05 \n",
      "epoch: 30 [316635/888800 35.62%] train loss: 1.4325579286378343e-05 \n",
      "epoch: 30 [317746/888800 35.75%] train loss: 1.3404613127931952e-05 \n",
      "epoch: 30 [318857/888800 35.88%] train loss: 1.323407377640251e-05 \n",
      "epoch: 30 [319968/888800 36.00%] train loss: 1.5302268366212957e-05 \n",
      "epoch: 30 [321079/888800 36.12%] train loss: 1.4137614925857633e-05 \n",
      "epoch: 30 [322190/888800 36.25%] train loss: 1.3325760846782941e-05 \n",
      "epoch: 30 [323301/888800 36.38%] train loss: 1.5537278159172274e-05 \n",
      "epoch: 30 [324412/888800 36.50%] train loss: 1.3835370737069752e-05 \n",
      "epoch: 30 [325523/888800 36.62%] train loss: 1.33704725158168e-05 \n",
      "epoch: 30 [326634/888800 36.75%] train loss: 1.5302517567761242e-05 \n",
      "epoch: 30 [327745/888800 36.88%] train loss: 1.430232896382222e-05 \n",
      "epoch: 30 [328856/888800 37.00%] train loss: 1.435324884369038e-05 \n",
      "epoch: 30 [329967/888800 37.12%] train loss: 1.4114637451712042e-05 \n",
      "epoch: 30 [331078/888800 37.25%] train loss: 1.3708094229514245e-05 \n",
      "epoch: 30 [332189/888800 37.38%] train loss: 1.443381370336283e-05 \n",
      "epoch: 30 [333300/888800 37.50%] train loss: 1.4027622455614619e-05 \n",
      "epoch: 30 [334411/888800 37.62%] train loss: 1.3040164049016312e-05 \n",
      "epoch: 30 [335522/888800 37.75%] train loss: 1.503945532022044e-05 \n",
      "epoch: 30 [336633/888800 37.88%] train loss: 1.4318884495878592e-05 \n",
      "epoch: 30 [337744/888800 38.00%] train loss: 1.554299524286762e-05 \n",
      "epoch: 30 [338855/888800 38.12%] train loss: 1.4717013073095586e-05 \n",
      "epoch: 30 [339966/888800 38.25%] train loss: 1.4084682334214449e-05 \n",
      "epoch: 30 [341077/888800 38.38%] train loss: 1.6086833056760952e-05 \n",
      "epoch: 30 [342188/888800 38.50%] train loss: 1.4199243196344469e-05 \n",
      "epoch: 30 [343299/888800 38.62%] train loss: 1.3267179383547045e-05 \n",
      "epoch: 30 [344410/888800 38.75%] train loss: 1.4099710824666545e-05 \n",
      "epoch: 30 [345521/888800 38.88%] train loss: 1.3224093891039956e-05 \n",
      "epoch: 30 [346632/888800 39.00%] train loss: 1.28201882034773e-05 \n",
      "epoch: 30 [347743/888800 39.12%] train loss: 1.516400880063884e-05 \n",
      "epoch: 30 [348854/888800 39.25%] train loss: 1.3294582458911464e-05 \n",
      "epoch: 30 [349965/888800 39.38%] train loss: 1.4169586393109057e-05 \n",
      "epoch: 30 [351076/888800 39.50%] train loss: 1.3775876141153276e-05 \n",
      "epoch: 30 [352187/888800 39.62%] train loss: 1.4544787518389057e-05 \n",
      "epoch: 30 [353298/888800 39.75%] train loss: 1.430761312803952e-05 \n",
      "epoch: 30 [354409/888800 39.88%] train loss: 1.4216680938261561e-05 \n",
      "epoch: 30 [355520/888800 40.00%] train loss: 1.508774766989518e-05 \n",
      "epoch: 30 [356631/888800 40.12%] train loss: 1.3360348930291366e-05 \n",
      "epoch: 30 [357742/888800 40.25%] train loss: 1.4220873708836734e-05 \n",
      "epoch: 30 [358853/888800 40.38%] train loss: 1.592171611264348e-05 \n",
      "epoch: 30 [359964/888800 40.50%] train loss: 1.3595956261269748e-05 \n",
      "epoch: 30 [361075/888800 40.62%] train loss: 1.2734416486637201e-05 \n",
      "epoch: 30 [362186/888800 40.75%] train loss: 1.4578989066649228e-05 \n",
      "epoch: 30 [363297/888800 40.88%] train loss: 1.3199963177612517e-05 \n",
      "epoch: 30 [364408/888800 41.00%] train loss: 1.4257681868912186e-05 \n",
      "epoch: 30 [365519/888800 41.12%] train loss: 1.4452400137088262e-05 \n",
      "epoch: 30 [366630/888800 41.25%] train loss: 1.437488663214026e-05 \n",
      "epoch: 30 [367741/888800 41.38%] train loss: 1.3588755791715812e-05 \n",
      "epoch: 30 [368852/888800 41.50%] train loss: 1.4338013897940982e-05 \n",
      "epoch: 30 [369963/888800 41.62%] train loss: 1.517483815405285e-05 \n",
      "epoch: 30 [371074/888800 41.75%] train loss: 1.4155828466755338e-05 \n",
      "epoch: 30 [372185/888800 41.88%] train loss: 1.4435006050916854e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [373296/888800 42.00%] train loss: 1.4794662092754152e-05 \n",
      "epoch: 30 [374407/888800 42.12%] train loss: 1.4110923984844703e-05 \n",
      "epoch: 30 [375518/888800 42.25%] train loss: 1.4659981388831511e-05 \n",
      "epoch: 30 [376629/888800 42.38%] train loss: 1.4523934623866808e-05 \n",
      "epoch: 30 [377740/888800 42.50%] train loss: 1.338143465545727e-05 \n",
      "epoch: 30 [378851/888800 42.62%] train loss: 1.4954737707739696e-05 \n",
      "epoch: 30 [379962/888800 42.75%] train loss: 1.4069727512833197e-05 \n",
      "epoch: 30 [381073/888800 42.88%] train loss: 1.3608687368105166e-05 \n",
      "epoch: 30 [382184/888800 43.00%] train loss: 1.4327315511764027e-05 \n",
      "epoch: 30 [383295/888800 43.12%] train loss: 1.55845373228658e-05 \n",
      "epoch: 30 [384406/888800 43.25%] train loss: 1.3350333574635442e-05 \n",
      "epoch: 30 [385517/888800 43.38%] train loss: 1.6001144103938714e-05 \n",
      "epoch: 30 [386628/888800 43.50%] train loss: 1.4884325537423138e-05 \n",
      "epoch: 30 [387739/888800 43.62%] train loss: 1.4388087038241792e-05 \n",
      "epoch: 30 [388850/888800 43.75%] train loss: 1.5612115021212958e-05 \n",
      "epoch: 30 [389961/888800 43.88%] train loss: 1.3955314898339566e-05 \n",
      "epoch: 30 [391072/888800 44.00%] train loss: 1.353289553662762e-05 \n",
      "epoch: 30 [392183/888800 44.12%] train loss: 1.3647345440404024e-05 \n",
      "epoch: 30 [393294/888800 44.25%] train loss: 1.3994154869578779e-05 \n",
      "epoch: 30 [394405/888800 44.38%] train loss: 1.347115176031366e-05 \n",
      "epoch: 30 [395516/888800 44.50%] train loss: 1.4179949175741058e-05 \n",
      "epoch: 30 [396627/888800 44.62%] train loss: 1.4647644093201961e-05 \n",
      "epoch: 30 [397738/888800 44.75%] train loss: 1.4335920241137501e-05 \n",
      "epoch: 30 [398849/888800 44.88%] train loss: 1.315776626142906e-05 \n",
      "epoch: 30 [399960/888800 45.00%] train loss: 1.326670462731272e-05 \n",
      "epoch: 30 [401071/888800 45.12%] train loss: 1.5651676221750677e-05 \n",
      "epoch: 30 [402182/888800 45.25%] train loss: 1.4301430383056868e-05 \n",
      "epoch: 30 [403293/888800 45.38%] train loss: 1.4178951460053213e-05 \n",
      "epoch: 30 [404404/888800 45.50%] train loss: 1.2441068975022063e-05 \n",
      "epoch: 30 [405515/888800 45.62%] train loss: 1.5371695553767495e-05 \n",
      "epoch: 30 [406626/888800 45.75%] train loss: 1.561657336424105e-05 \n",
      "epoch: 30 [407737/888800 45.88%] train loss: 1.4032544640940614e-05 \n",
      "epoch: 30 [408848/888800 46.00%] train loss: 1.4515664588543586e-05 \n",
      "epoch: 30 [409959/888800 46.12%] train loss: 1.3563604625232983e-05 \n",
      "epoch: 30 [411070/888800 46.25%] train loss: 1.4084404028835706e-05 \n",
      "epoch: 30 [412181/888800 46.38%] train loss: 1.461176452721702e-05 \n",
      "epoch: 30 [413292/888800 46.50%] train loss: 1.4299295798991807e-05 \n",
      "epoch: 30 [414403/888800 46.62%] train loss: 1.4630210898758378e-05 \n",
      "epoch: 30 [415514/888800 46.75%] train loss: 1.3569315342465416e-05 \n",
      "epoch: 30 [416625/888800 46.88%] train loss: 1.405549392075045e-05 \n",
      "epoch: 30 [417736/888800 47.00%] train loss: 1.2944041372975335e-05 \n",
      "epoch: 30 [418847/888800 47.12%] train loss: 1.417612838849891e-05 \n",
      "epoch: 30 [419958/888800 47.25%] train loss: 1.3573464457294904e-05 \n",
      "epoch: 30 [421069/888800 47.38%] train loss: 1.3062137441011146e-05 \n",
      "epoch: 30 [422180/888800 47.50%] train loss: 1.5071031157276593e-05 \n",
      "epoch: 30 [423291/888800 47.62%] train loss: 1.4906297110428568e-05 \n",
      "epoch: 30 [424402/888800 47.75%] train loss: 1.4401975931832567e-05 \n",
      "epoch: 30 [425513/888800 47.88%] train loss: 1.4257891962188296e-05 \n",
      "epoch: 30 [426624/888800 48.00%] train loss: 1.4256590475270059e-05 \n",
      "epoch: 30 [427735/888800 48.12%] train loss: 1.3992604181112256e-05 \n",
      "epoch: 30 [428846/888800 48.25%] train loss: 1.4063783055462409e-05 \n",
      "epoch: 30 [429957/888800 48.38%] train loss: 1.5106144928722642e-05 \n",
      "epoch: 30 [431068/888800 48.50%] train loss: 1.3324357496458106e-05 \n",
      "epoch: 30 [432179/888800 48.62%] train loss: 1.3704117918678094e-05 \n",
      "epoch: 30 [433290/888800 48.75%] train loss: 1.6080104614957236e-05 \n",
      "epoch: 30 [434401/888800 48.88%] train loss: 1.3815451893606223e-05 \n",
      "epoch: 30 [435512/888800 49.00%] train loss: 1.4729756003362127e-05 \n",
      "epoch: 30 [436623/888800 49.12%] train loss: 1.4223855941963848e-05 \n",
      "epoch: 30 [437734/888800 49.25%] train loss: 1.4684878806292545e-05 \n",
      "epoch: 30 [438845/888800 49.38%] train loss: 1.3684256373380776e-05 \n",
      "epoch: 30 [439956/888800 49.50%] train loss: 1.3447182936943136e-05 \n",
      "epoch: 30 [441067/888800 49.62%] train loss: 1.2978085578652099e-05 \n",
      "epoch: 30 [442178/888800 49.75%] train loss: 1.3627985936182085e-05 \n",
      "epoch: 30 [443289/888800 49.88%] train loss: 1.4072947124077473e-05 \n",
      "epoch: 30 [444400/888800 50.00%] train loss: 1.4502071280730888e-05 \n",
      "epoch: 30 [445511/888800 50.12%] train loss: 1.3616895557788666e-05 \n",
      "epoch: 30 [446622/888800 50.25%] train loss: 1.3776535524812061e-05 \n",
      "epoch: 30 [447733/888800 50.38%] train loss: 1.3403005141299218e-05 \n",
      "epoch: 30 [448844/888800 50.50%] train loss: 1.4543654287990648e-05 \n",
      "epoch: 30 [449955/888800 50.62%] train loss: 1.374624753225362e-05 \n",
      "epoch: 30 [451066/888800 50.75%] train loss: 1.3184741874283645e-05 \n",
      "epoch: 30 [452177/888800 50.88%] train loss: 1.3684671102964785e-05 \n",
      "epoch: 30 [453288/888800 51.00%] train loss: 1.3658197531185579e-05 \n",
      "epoch: 30 [454399/888800 51.12%] train loss: 1.506183161836816e-05 \n",
      "epoch: 30 [455510/888800 51.25%] train loss: 1.2897143278678413e-05 \n",
      "epoch: 30 [456621/888800 51.38%] train loss: 1.49671541294083e-05 \n",
      "epoch: 30 [457732/888800 51.50%] train loss: 1.5310368326026946e-05 \n",
      "epoch: 30 [458843/888800 51.62%] train loss: 1.584928759257309e-05 \n",
      "epoch: 30 [459954/888800 51.75%] train loss: 1.4704501154483296e-05 \n",
      "epoch: 30 [461065/888800 51.88%] train loss: 1.5943060134304687e-05 \n",
      "epoch: 30 [462176/888800 52.00%] train loss: 1.5546947906841524e-05 \n",
      "epoch: 30 [463287/888800 52.12%] train loss: 1.4543999895977322e-05 \n",
      "epoch: 30 [464398/888800 52.25%] train loss: 1.641702328925021e-05 \n",
      "epoch: 30 [465509/888800 52.38%] train loss: 1.4815848771831952e-05 \n",
      "epoch: 30 [466620/888800 52.50%] train loss: 1.6123032764880918e-05 \n",
      "epoch: 30 [467731/888800 52.62%] train loss: 1.3555376426666044e-05 \n",
      "epoch: 30 [468842/888800 52.75%] train loss: 2.015193967963569e-05 \n",
      "epoch: 30 [469953/888800 52.88%] train loss: 1.5386582163046114e-05 \n",
      "epoch: 30 [471064/888800 53.00%] train loss: 1.627720848773606e-05 \n",
      "epoch: 30 [472175/888800 53.12%] train loss: 1.4537910828948952e-05 \n",
      "epoch: 30 [473286/888800 53.25%] train loss: 1.4978169019741472e-05 \n",
      "epoch: 30 [474397/888800 53.38%] train loss: 1.614163556951098e-05 \n",
      "epoch: 30 [475508/888800 53.50%] train loss: 1.3976521586300805e-05 \n",
      "epoch: 30 [476619/888800 53.62%] train loss: 1.672175494604744e-05 \n",
      "epoch: 30 [477730/888800 53.75%] train loss: 1.5097736650204752e-05 \n",
      "epoch: 30 [478841/888800 53.88%] train loss: 1.587563383509405e-05 \n",
      "epoch: 30 [479952/888800 54.00%] train loss: 1.3010063412366435e-05 \n",
      "epoch: 30 [481063/888800 54.12%] train loss: 1.737008642521687e-05 \n",
      "epoch: 30 [482174/888800 54.25%] train loss: 1.385540690534981e-05 \n",
      "epoch: 30 [483285/888800 54.38%] train loss: 1.76712783286348e-05 \n",
      "epoch: 30 [484396/888800 54.50%] train loss: 1.4321434719022363e-05 \n",
      "epoch: 30 [485507/888800 54.62%] train loss: 1.6713534932932816e-05 \n",
      "epoch: 30 [486618/888800 54.75%] train loss: 1.676641113590449e-05 \n",
      "epoch: 30 [487729/888800 54.88%] train loss: 1.4560791896656156e-05 \n",
      "epoch: 30 [488840/888800 55.00%] train loss: 1.486841392761562e-05 \n",
      "epoch: 30 [489951/888800 55.12%] train loss: 1.3350071640161332e-05 \n",
      "epoch: 30 [491062/888800 55.25%] train loss: 1.5475992768188007e-05 \n",
      "epoch: 30 [492173/888800 55.38%] train loss: 1.412362871633377e-05 \n",
      "epoch: 30 [493284/888800 55.50%] train loss: 1.5399093172163703e-05 \n",
      "epoch: 30 [494395/888800 55.62%] train loss: 1.380140474793734e-05 \n",
      "epoch: 30 [495506/888800 55.75%] train loss: 1.4242502402339596e-05 \n",
      "epoch: 30 [496617/888800 55.88%] train loss: 1.4095921869738959e-05 \n",
      "epoch: 30 [497728/888800 56.00%] train loss: 1.4486752661468927e-05 \n",
      "epoch: 30 [498839/888800 56.12%] train loss: 1.4312721759779379e-05 \n",
      "epoch: 30 [499950/888800 56.25%] train loss: 1.4005627235746942e-05 \n",
      "epoch: 30 [501061/888800 56.38%] train loss: 1.3724551536142826e-05 \n",
      "epoch: 30 [502172/888800 56.50%] train loss: 1.3926269275543746e-05 \n",
      "epoch: 30 [503283/888800 56.62%] train loss: 1.3550856237998232e-05 \n",
      "epoch: 30 [504394/888800 56.75%] train loss: 1.4814540918450803e-05 \n",
      "epoch: 30 [505505/888800 56.88%] train loss: 1.3536396181734744e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [506616/888800 57.00%] train loss: 1.338088077318389e-05 \n",
      "epoch: 30 [507727/888800 57.12%] train loss: 1.401752706442494e-05 \n",
      "epoch: 30 [508838/888800 57.25%] train loss: 1.5602714483975433e-05 \n",
      "epoch: 30 [509949/888800 57.38%] train loss: 1.459886334487237e-05 \n",
      "epoch: 30 [511060/888800 57.50%] train loss: 1.3556745216192212e-05 \n",
      "epoch: 30 [512171/888800 57.62%] train loss: 1.5255959624482784e-05 \n",
      "epoch: 30 [513282/888800 57.75%] train loss: 1.4894911146257073e-05 \n",
      "epoch: 30 [514393/888800 57.88%] train loss: 1.4040326277608983e-05 \n",
      "epoch: 30 [515504/888800 58.00%] train loss: 1.4124453628028277e-05 \n",
      "epoch: 30 [516615/888800 58.12%] train loss: 1.4739378457306884e-05 \n",
      "epoch: 30 [517726/888800 58.25%] train loss: 1.3291008144733496e-05 \n",
      "epoch: 30 [518837/888800 58.38%] train loss: 1.4438856851484161e-05 \n",
      "epoch: 30 [519948/888800 58.50%] train loss: 1.3657822819368448e-05 \n",
      "epoch: 30 [521059/888800 58.62%] train loss: 1.5079328477440868e-05 \n",
      "epoch: 30 [522170/888800 58.75%] train loss: 1.467805304855574e-05 \n",
      "epoch: 30 [523281/888800 58.88%] train loss: 1.3367370229389053e-05 \n",
      "epoch: 30 [524392/888800 59.00%] train loss: 1.6072439393610694e-05 \n",
      "epoch: 30 [525503/888800 59.12%] train loss: 1.4337763786897995e-05 \n",
      "epoch: 30 [526614/888800 59.25%] train loss: 1.529230212327093e-05 \n",
      "epoch: 30 [527725/888800 59.38%] train loss: 1.413516656612046e-05 \n",
      "epoch: 30 [528836/888800 59.50%] train loss: 1.539654658699874e-05 \n",
      "epoch: 30 [529947/888800 59.62%] train loss: 1.3979100913275033e-05 \n",
      "epoch: 30 [531058/888800 59.75%] train loss: 1.5171280210779514e-05 \n",
      "epoch: 30 [532169/888800 59.88%] train loss: 1.3768873031949624e-05 \n",
      "epoch: 30 [533280/888800 60.00%] train loss: 1.582208278705366e-05 \n",
      "epoch: 30 [534391/888800 60.12%] train loss: 1.5339135643444024e-05 \n",
      "epoch: 30 [535502/888800 60.25%] train loss: 1.4321122762339655e-05 \n",
      "epoch: 30 [536613/888800 60.38%] train loss: 1.644717667659279e-05 \n",
      "epoch: 30 [537724/888800 60.50%] train loss: 1.3482659596775193e-05 \n",
      "epoch: 30 [538835/888800 60.62%] train loss: 1.5689256542827934e-05 \n",
      "epoch: 30 [539946/888800 60.75%] train loss: 1.479468210163759e-05 \n",
      "epoch: 30 [541057/888800 60.88%] train loss: 1.3756162843492348e-05 \n",
      "epoch: 30 [542168/888800 61.00%] train loss: 1.5577159501845017e-05 \n",
      "epoch: 30 [543279/888800 61.12%] train loss: 1.345535201835446e-05 \n",
      "epoch: 30 [544390/888800 61.25%] train loss: 1.3526338079827838e-05 \n",
      "epoch: 30 [545501/888800 61.38%] train loss: 1.4301870578492526e-05 \n",
      "epoch: 30 [546612/888800 61.50%] train loss: 1.345097098237602e-05 \n",
      "epoch: 30 [547723/888800 61.62%] train loss: 1.3869524082110729e-05 \n",
      "epoch: 30 [548834/888800 61.75%] train loss: 1.3609319466922898e-05 \n",
      "epoch: 30 [549945/888800 61.88%] train loss: 1.4133979675534647e-05 \n",
      "epoch: 30 [551056/888800 62.00%] train loss: 1.2492932910390664e-05 \n",
      "epoch: 30 [552167/888800 62.12%] train loss: 1.4120639207249042e-05 \n",
      "epoch: 30 [553278/888800 62.25%] train loss: 1.2719460755761247e-05 \n",
      "epoch: 30 [554389/888800 62.38%] train loss: 1.3890768059354741e-05 \n",
      "epoch: 30 [555500/888800 62.50%] train loss: 1.4600823305954691e-05 \n",
      "epoch: 30 [556611/888800 62.62%] train loss: 1.4820039723417722e-05 \n",
      "epoch: 30 [557722/888800 62.75%] train loss: 1.4414432371268049e-05 \n",
      "epoch: 30 [558833/888800 62.88%] train loss: 1.4039404959476087e-05 \n",
      "epoch: 30 [559944/888800 63.00%] train loss: 1.5932906535454094e-05 \n",
      "epoch: 30 [561055/888800 63.12%] train loss: 1.3118741662765387e-05 \n",
      "epoch: 30 [562166/888800 63.25%] train loss: 1.684276867308654e-05 \n",
      "epoch: 30 [563277/888800 63.38%] train loss: 1.341887309536105e-05 \n",
      "epoch: 30 [564388/888800 63.50%] train loss: 1.4675464626634493e-05 \n",
      "epoch: 30 [565499/888800 63.62%] train loss: 1.3599754311144352e-05 \n",
      "epoch: 30 [566610/888800 63.75%] train loss: 1.4286250916484278e-05 \n",
      "epoch: 30 [567721/888800 63.88%] train loss: 1.5195285413938109e-05 \n",
      "epoch: 30 [568832/888800 64.00%] train loss: 1.4994961020420305e-05 \n",
      "epoch: 30 [569943/888800 64.12%] train loss: 1.3994879736856092e-05 \n",
      "epoch: 30 [571054/888800 64.25%] train loss: 1.4857956557534635e-05 \n",
      "epoch: 30 [572165/888800 64.38%] train loss: 1.5507499483646825e-05 \n",
      "epoch: 30 [573276/888800 64.50%] train loss: 1.3845178727933671e-05 \n",
      "epoch: 30 [574387/888800 64.62%] train loss: 1.4672124962089583e-05 \n",
      "epoch: 30 [575498/888800 64.75%] train loss: 1.4552192624250893e-05 \n",
      "epoch: 30 [576609/888800 64.88%] train loss: 1.4665509297628887e-05 \n",
      "epoch: 30 [577720/888800 65.00%] train loss: 1.3595165910373908e-05 \n",
      "epoch: 30 [578831/888800 65.12%] train loss: 1.3838277482136618e-05 \n",
      "epoch: 30 [579942/888800 65.25%] train loss: 1.397945834469283e-05 \n",
      "epoch: 30 [581053/888800 65.38%] train loss: 1.3823040717397816e-05 \n",
      "epoch: 30 [582164/888800 65.50%] train loss: 1.4528446627082303e-05 \n",
      "epoch: 30 [583275/888800 65.62%] train loss: 1.5072900168888737e-05 \n",
      "epoch: 30 [584386/888800 65.75%] train loss: 1.3440376278595068e-05 \n",
      "epoch: 30 [585497/888800 65.88%] train loss: 1.4178475794324186e-05 \n",
      "epoch: 30 [586608/888800 66.00%] train loss: 1.3759110515820794e-05 \n",
      "epoch: 30 [587719/888800 66.12%] train loss: 1.3185996976972092e-05 \n",
      "epoch: 30 [588830/888800 66.25%] train loss: 1.3311667316884268e-05 \n",
      "epoch: 30 [589941/888800 66.38%] train loss: 1.4735341210325714e-05 \n",
      "epoch: 30 [591052/888800 66.50%] train loss: 1.2803921890736092e-05 \n",
      "epoch: 30 [592163/888800 66.62%] train loss: 1.376294585497817e-05 \n",
      "epoch: 30 [593274/888800 66.75%] train loss: 1.4699448911414947e-05 \n",
      "epoch: 30 [594385/888800 66.88%] train loss: 1.528544999018777e-05 \n",
      "epoch: 30 [595496/888800 67.00%] train loss: 1.4422862477658782e-05 \n",
      "epoch: 30 [596607/888800 67.12%] train loss: 1.4572688996850047e-05 \n",
      "epoch: 30 [597718/888800 67.25%] train loss: 1.400591827405151e-05 \n",
      "epoch: 30 [598829/888800 67.38%] train loss: 1.3888367902836762e-05 \n",
      "epoch: 30 [599940/888800 67.50%] train loss: 1.3953606867289636e-05 \n",
      "epoch: 30 [601051/888800 67.62%] train loss: 1.4944631402613595e-05 \n",
      "epoch: 30 [602162/888800 67.75%] train loss: 1.3917567230237182e-05 \n",
      "epoch: 30 [603273/888800 67.88%] train loss: 1.5082640857144725e-05 \n",
      "epoch: 30 [604384/888800 68.00%] train loss: 1.4436623132496607e-05 \n",
      "epoch: 30 [605495/888800 68.12%] train loss: 1.4378299965756014e-05 \n",
      "epoch: 30 [606606/888800 68.25%] train loss: 1.4805929822614416e-05 \n",
      "epoch: 30 [607717/888800 68.38%] train loss: 1.6011652405722998e-05 \n",
      "epoch: 30 [608828/888800 68.50%] train loss: 1.460048406443093e-05 \n",
      "epoch: 30 [609939/888800 68.62%] train loss: 1.3878956451662816e-05 \n",
      "epoch: 30 [611050/888800 68.75%] train loss: 1.3836242942488752e-05 \n",
      "epoch: 30 [612161/888800 68.88%] train loss: 1.4959532563807443e-05 \n",
      "epoch: 30 [613272/888800 69.00%] train loss: 1.4914897292328533e-05 \n",
      "epoch: 30 [614383/888800 69.12%] train loss: 1.4828587154624984e-05 \n",
      "epoch: 30 [615494/888800 69.25%] train loss: 1.4440157428907696e-05 \n",
      "epoch: 30 [616605/888800 69.38%] train loss: 1.4428333088289946e-05 \n",
      "epoch: 30 [617716/888800 69.50%] train loss: 1.4132256183074787e-05 \n",
      "epoch: 30 [618827/888800 69.62%] train loss: 1.5927833374007605e-05 \n",
      "epoch: 30 [619938/888800 69.75%] train loss: 1.4341620044433512e-05 \n",
      "epoch: 30 [621049/888800 69.88%] train loss: 1.5762199836899526e-05 \n",
      "epoch: 30 [622160/888800 70.00%] train loss: 1.3525143003789708e-05 \n",
      "epoch: 30 [623271/888800 70.12%] train loss: 1.4756816199223977e-05 \n",
      "epoch: 30 [624382/888800 70.25%] train loss: 1.4137983271211851e-05 \n",
      "epoch: 30 [625493/888800 70.38%] train loss: 1.3122326890879776e-05 \n",
      "epoch: 30 [626604/888800 70.50%] train loss: 1.4857568203296978e-05 \n",
      "epoch: 30 [627715/888800 70.62%] train loss: 1.4302546333055943e-05 \n",
      "epoch: 30 [628826/888800 70.75%] train loss: 1.3872835552319884e-05 \n",
      "epoch: 30 [629937/888800 70.88%] train loss: 1.3786305316898506e-05 \n",
      "epoch: 30 [631048/888800 71.00%] train loss: 1.3930287423136178e-05 \n",
      "epoch: 30 [632159/888800 71.12%] train loss: 1.3998579561302904e-05 \n",
      "epoch: 30 [633270/888800 71.25%] train loss: 1.5039746358525008e-05 \n",
      "epoch: 30 [634381/888800 71.38%] train loss: 1.363145111099584e-05 \n",
      "epoch: 30 [635492/888800 71.50%] train loss: 1.3836264770361595e-05 \n",
      "epoch: 30 [636603/888800 71.62%] train loss: 1.3439037502394058e-05 \n",
      "epoch: 30 [637714/888800 71.75%] train loss: 1.3473641047312412e-05 \n",
      "epoch: 30 [638825/888800 71.88%] train loss: 1.4442315659835003e-05 \n",
      "epoch: 30 [639936/888800 72.00%] train loss: 1.4014914995641448e-05 \n",
      "epoch: 30 [641047/888800 72.12%] train loss: 1.3717793081013951e-05 \n",
      "epoch: 30 [642158/888800 72.25%] train loss: 1.3165657037461642e-05 \n",
      "epoch: 30 [643269/888800 72.38%] train loss: 1.3462101378536317e-05 \n",
      "epoch: 30 [644380/888800 72.50%] train loss: 1.4362132787937298e-05 \n",
      "epoch: 30 [645491/888800 72.62%] train loss: 1.4393674064194784e-05 \n",
      "epoch: 30 [646602/888800 72.75%] train loss: 1.3604470950667746e-05 \n",
      "epoch: 30 [647713/888800 72.88%] train loss: 1.5327290384448133e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [648824/888800 73.00%] train loss: 1.3581294297182467e-05 \n",
      "epoch: 30 [649935/888800 73.12%] train loss: 1.3371483873925172e-05 \n",
      "epoch: 30 [651046/888800 73.25%] train loss: 1.5619065379723907e-05 \n",
      "epoch: 30 [652157/888800 73.38%] train loss: 1.403619990014704e-05 \n",
      "epoch: 30 [653268/888800 73.50%] train loss: 1.455356596125057e-05 \n",
      "epoch: 30 [654379/888800 73.62%] train loss: 1.3294891687110066e-05 \n",
      "epoch: 30 [655490/888800 73.75%] train loss: 1.5017240912129637e-05 \n",
      "epoch: 30 [656601/888800 73.88%] train loss: 1.5274754332494922e-05 \n",
      "epoch: 30 [657712/888800 74.00%] train loss: 1.3887237400922459e-05 \n",
      "epoch: 30 [658823/888800 74.12%] train loss: 1.528822940599639e-05 \n",
      "epoch: 30 [659934/888800 74.25%] train loss: 1.5705159967183135e-05 \n",
      "epoch: 30 [661045/888800 74.38%] train loss: 1.4412310520128813e-05 \n",
      "epoch: 30 [662156/888800 74.50%] train loss: 1.5517558495048434e-05 \n",
      "epoch: 30 [663267/888800 74.62%] train loss: 1.5032217561383732e-05 \n",
      "epoch: 30 [664378/888800 74.75%] train loss: 1.4586729776056018e-05 \n",
      "epoch: 30 [665489/888800 74.88%] train loss: 1.472419171477668e-05 \n",
      "epoch: 30 [666600/888800 75.00%] train loss: 1.4577150068362243e-05 \n",
      "epoch: 30 [667711/888800 75.12%] train loss: 1.2924024304084014e-05 \n",
      "epoch: 30 [668822/888800 75.25%] train loss: 1.4084441318118479e-05 \n",
      "epoch: 30 [669933/888800 75.38%] train loss: 1.3836407561029773e-05 \n",
      "epoch: 30 [671044/888800 75.50%] train loss: 1.4165267202770337e-05 \n",
      "epoch: 30 [672155/888800 75.62%] train loss: 1.426730705134105e-05 \n",
      "epoch: 30 [673266/888800 75.75%] train loss: 1.6065354429883882e-05 \n",
      "epoch: 30 [674377/888800 75.88%] train loss: 1.4672228644485585e-05 \n",
      "epoch: 30 [675488/888800 76.00%] train loss: 1.4114260011410806e-05 \n",
      "epoch: 30 [676599/888800 76.12%] train loss: 1.5936866475385614e-05 \n",
      "epoch: 30 [677710/888800 76.25%] train loss: 1.4033146726433188e-05 \n",
      "epoch: 30 [678821/888800 76.38%] train loss: 1.5690553482272662e-05 \n",
      "epoch: 30 [679932/888800 76.50%] train loss: 1.424713173037162e-05 \n",
      "epoch: 30 [681043/888800 76.62%] train loss: 1.3850103641743772e-05 \n",
      "epoch: 30 [682154/888800 76.75%] train loss: 1.533592694613617e-05 \n",
      "epoch: 30 [683265/888800 76.88%] train loss: 1.4349078810482752e-05 \n",
      "epoch: 30 [684376/888800 77.00%] train loss: 1.4351969184644986e-05 \n",
      "epoch: 30 [685487/888800 77.12%] train loss: 1.5458339476026595e-05 \n",
      "epoch: 30 [686598/888800 77.25%] train loss: 1.4570871826435905e-05 \n",
      "epoch: 30 [687709/888800 77.38%] train loss: 1.423582034476567e-05 \n",
      "epoch: 30 [688820/888800 77.50%] train loss: 1.4596957043977454e-05 \n",
      "epoch: 30 [689931/888800 77.62%] train loss: 1.43696233863011e-05 \n",
      "epoch: 30 [691042/888800 77.75%] train loss: 1.483205778640695e-05 \n",
      "epoch: 30 [692153/888800 77.88%] train loss: 1.4682133951282594e-05 \n",
      "epoch: 30 [693264/888800 78.00%] train loss: 1.4782562175241765e-05 \n",
      "epoch: 30 [694375/888800 78.12%] train loss: 1.3780170775135048e-05 \n",
      "epoch: 30 [695486/888800 78.25%] train loss: 1.4057262887945399e-05 \n",
      "epoch: 30 [696597/888800 78.38%] train loss: 1.333949330728501e-05 \n",
      "epoch: 30 [697708/888800 78.50%] train loss: 1.4789843589824159e-05 \n",
      "epoch: 30 [698819/888800 78.62%] train loss: 1.6018879250623286e-05 \n",
      "epoch: 30 [699930/888800 78.75%] train loss: 1.4389277566806413e-05 \n",
      "epoch: 30 [701041/888800 78.88%] train loss: 1.3117282833263744e-05 \n",
      "epoch: 30 [702152/888800 79.00%] train loss: 1.3772434613201767e-05 \n",
      "epoch: 30 [703263/888800 79.12%] train loss: 1.2906639312859625e-05 \n",
      "epoch: 30 [704374/888800 79.25%] train loss: 1.4848193131911103e-05 \n",
      "epoch: 30 [705485/888800 79.38%] train loss: 1.4243418263504282e-05 \n",
      "epoch: 30 [706596/888800 79.50%] train loss: 1.5355280993389897e-05 \n",
      "epoch: 30 [707707/888800 79.62%] train loss: 1.4458270925388206e-05 \n",
      "epoch: 30 [708818/888800 79.75%] train loss: 1.480983519286383e-05 \n",
      "epoch: 30 [709929/888800 79.88%] train loss: 1.4277797163231298e-05 \n",
      "epoch: 30 [711040/888800 80.00%] train loss: 1.6118076018756256e-05 \n",
      "epoch: 30 [712151/888800 80.12%] train loss: 1.552813955640886e-05 \n",
      "epoch: 30 [713262/888800 80.25%] train loss: 1.5352341506513767e-05 \n",
      "epoch: 30 [714373/888800 80.38%] train loss: 1.5756735592731275e-05 \n",
      "epoch: 30 [715484/888800 80.50%] train loss: 1.4290636499936227e-05 \n",
      "epoch: 30 [716595/888800 80.62%] train loss: 1.5030827853479423e-05 \n",
      "epoch: 30 [717706/888800 80.75%] train loss: 1.4521093362418469e-05 \n",
      "epoch: 30 [718817/888800 80.88%] train loss: 1.4158675185171887e-05 \n",
      "epoch: 30 [719928/888800 81.00%] train loss: 1.3848333765054122e-05 \n",
      "epoch: 30 [721039/888800 81.12%] train loss: 1.570573658682406e-05 \n",
      "epoch: 30 [722150/888800 81.25%] train loss: 1.400812925567152e-05 \n",
      "epoch: 30 [723261/888800 81.38%] train loss: 1.4844237739453092e-05 \n",
      "epoch: 30 [724372/888800 81.50%] train loss: 1.42859034895082e-05 \n",
      "epoch: 30 [725483/888800 81.62%] train loss: 1.3999692782817874e-05 \n",
      "epoch: 30 [726594/888800 81.75%] train loss: 1.5296091078198515e-05 \n",
      "epoch: 30 [727705/888800 81.88%] train loss: 1.5758900190121494e-05 \n",
      "epoch: 30 [728816/888800 82.00%] train loss: 1.4535933587467298e-05 \n",
      "epoch: 30 [729927/888800 82.12%] train loss: 1.3393614608503412e-05 \n",
      "epoch: 30 [731038/888800 82.25%] train loss: 1.496859567851061e-05 \n",
      "epoch: 30 [732149/888800 82.38%] train loss: 1.3618332559417468e-05 \n",
      "epoch: 30 [733260/888800 82.50%] train loss: 1.3666299309988972e-05 \n",
      "epoch: 30 [734371/888800 82.62%] train loss: 1.3727673831454013e-05 \n",
      "epoch: 30 [735482/888800 82.75%] train loss: 1.3836843208991922e-05 \n",
      "epoch: 30 [736593/888800 82.88%] train loss: 1.382697701046709e-05 \n",
      "epoch: 30 [737704/888800 83.00%] train loss: 1.5095422895683441e-05 \n",
      "epoch: 30 [738815/888800 83.12%] train loss: 1.417583098373143e-05 \n",
      "epoch: 30 [739926/888800 83.25%] train loss: 1.4116042621026281e-05 \n",
      "epoch: 30 [741037/888800 83.38%] train loss: 1.523495575384004e-05 \n",
      "epoch: 30 [742148/888800 83.50%] train loss: 1.3178679182601627e-05 \n",
      "epoch: 30 [743259/888800 83.62%] train loss: 1.3997983842273243e-05 \n",
      "epoch: 30 [744370/888800 83.75%] train loss: 1.4863690921629313e-05 \n",
      "epoch: 30 [745481/888800 83.88%] train loss: 1.4605222531827167e-05 \n",
      "epoch: 30 [746592/888800 84.00%] train loss: 1.4936326806491707e-05 \n",
      "epoch: 30 [747703/888800 84.12%] train loss: 1.397765299770981e-05 \n",
      "epoch: 30 [748814/888800 84.25%] train loss: 1.3834121091349516e-05 \n",
      "epoch: 30 [749925/888800 84.38%] train loss: 1.4072758858674206e-05 \n",
      "epoch: 30 [751036/888800 84.50%] train loss: 1.3915051567892078e-05 \n",
      "epoch: 30 [752147/888800 84.62%] train loss: 1.2640045497391839e-05 \n",
      "epoch: 30 [753258/888800 84.75%] train loss: 1.434784189768834e-05 \n",
      "epoch: 30 [754369/888800 84.88%] train loss: 1.3021855920669623e-05 \n",
      "epoch: 30 [755480/888800 85.00%] train loss: 1.3369654880079906e-05 \n",
      "epoch: 30 [756591/888800 85.12%] train loss: 1.4001582712808158e-05 \n",
      "epoch: 30 [757702/888800 85.25%] train loss: 1.3594441043096595e-05 \n",
      "epoch: 30 [758813/888800 85.38%] train loss: 1.4087087038205937e-05 \n",
      "epoch: 30 [759924/888800 85.50%] train loss: 1.502098257333273e-05 \n",
      "epoch: 30 [761035/888800 85.62%] train loss: 1.4822512639511842e-05 \n",
      "epoch: 30 [762146/888800 85.75%] train loss: 1.5095131857378874e-05 \n",
      "epoch: 30 [763257/888800 85.88%] train loss: 1.3334397408470977e-05 \n",
      "epoch: 30 [764368/888800 86.00%] train loss: 1.3246197340777144e-05 \n",
      "epoch: 30 [765479/888800 86.12%] train loss: 1.3729038073506672e-05 \n",
      "epoch: 30 [766590/888800 86.25%] train loss: 1.4316224223875906e-05 \n",
      "epoch: 30 [767701/888800 86.38%] train loss: 1.2927651368954685e-05 \n",
      "epoch: 30 [768812/888800 86.50%] train loss: 1.3589818081527483e-05 \n",
      "epoch: 30 [769923/888800 86.62%] train loss: 1.3360938282858115e-05 \n",
      "epoch: 30 [771034/888800 86.75%] train loss: 1.3954310816188809e-05 \n",
      "epoch: 30 [772145/888800 86.88%] train loss: 1.368110861221794e-05 \n",
      "epoch: 30 [773256/888800 87.00%] train loss: 1.4756003110960592e-05 \n",
      "epoch: 30 [774367/888800 87.12%] train loss: 1.475628414482344e-05 \n",
      "epoch: 30 [775478/888800 87.25%] train loss: 1.4924031347618438e-05 \n",
      "epoch: 30 [776589/888800 87.38%] train loss: 1.301309293921804e-05 \n",
      "epoch: 30 [777700/888800 87.50%] train loss: 1.3011862392886542e-05 \n",
      "epoch: 30 [778811/888800 87.62%] train loss: 1.3709681297768839e-05 \n",
      "epoch: 30 [779922/888800 87.75%] train loss: 1.4657074643764645e-05 \n",
      "epoch: 30 [781033/888800 87.88%] train loss: 1.4494323295366485e-05 \n",
      "epoch: 30 [782144/888800 88.00%] train loss: 1.4443941836361773e-05 \n",
      "epoch: 30 [783255/888800 88.12%] train loss: 1.4927313713997137e-05 \n",
      "epoch: 30 [784366/888800 88.25%] train loss: 1.4923743037797976e-05 \n",
      "epoch: 30 [785477/888800 88.38%] train loss: 1.4417048078030348e-05 \n",
      "epoch: 30 [786588/888800 88.50%] train loss: 1.4636491869168822e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 [787699/888800 88.62%] train loss: 1.4846992598904762e-05 \n",
      "epoch: 30 [788810/888800 88.75%] train loss: 1.3652243978867773e-05 \n",
      "epoch: 30 [789921/888800 88.88%] train loss: 1.5175116459431592e-05 \n",
      "epoch: 30 [791032/888800 89.00%] train loss: 1.3981912161398213e-05 \n",
      "epoch: 30 [792143/888800 89.12%] train loss: 1.4769520930713043e-05 \n",
      "epoch: 30 [793254/888800 89.25%] train loss: 1.4699762687087059e-05 \n",
      "epoch: 30 [794365/888800 89.38%] train loss: 1.336301374976756e-05 \n",
      "epoch: 30 [795476/888800 89.50%] train loss: 1.546472412883304e-05 \n",
      "epoch: 30 [796587/888800 89.62%] train loss: 1.3514092643163167e-05 \n",
      "epoch: 30 [797698/888800 89.75%] train loss: 1.4970842130423989e-05 \n",
      "epoch: 30 [798809/888800 89.88%] train loss: 1.4632458260166459e-05 \n",
      "epoch: 30 [799920/888800 90.00%] train loss: 1.3294387827045284e-05 \n",
      "epoch: 30 [801031/888800 90.12%] train loss: 1.4253499102778733e-05 \n",
      "epoch: 30 [802142/888800 90.25%] train loss: 1.5639594494132325e-05 \n",
      "epoch: 30 [803253/888800 90.38%] train loss: 1.384401912218891e-05 \n",
      "epoch: 30 [804364/888800 90.50%] train loss: 1.3385661077336408e-05 \n",
      "epoch: 30 [805475/888800 90.62%] train loss: 1.4104717592999805e-05 \n",
      "epoch: 30 [806586/888800 90.75%] train loss: 1.4351014215208124e-05 \n",
      "epoch: 30 [807697/888800 90.88%] train loss: 1.4608724995923694e-05 \n",
      "epoch: 30 [808808/888800 91.00%] train loss: 1.3767130440101027e-05 \n",
      "epoch: 30 [809919/888800 91.12%] train loss: 1.4022736650076695e-05 \n",
      "epoch: 30 [811030/888800 91.25%] train loss: 1.4351481695484836e-05 \n",
      "epoch: 30 [812141/888800 91.38%] train loss: 1.409453761880286e-05 \n",
      "epoch: 30 [813252/888800 91.50%] train loss: 1.4476213436864782e-05 \n",
      "epoch: 30 [814363/888800 91.62%] train loss: 1.5183654795691837e-05 \n",
      "epoch: 30 [815474/888800 91.75%] train loss: 1.2984900422452483e-05 \n",
      "epoch: 30 [816585/888800 91.88%] train loss: 1.472062103857752e-05 \n",
      "epoch: 30 [817696/888800 92.00%] train loss: 1.4106561138760298e-05 \n",
      "epoch: 30 [818807/888800 92.12%] train loss: 1.316303496423643e-05 \n",
      "epoch: 30 [819918/888800 92.25%] train loss: 1.3379462870943826e-05 \n",
      "epoch: 30 [821029/888800 92.38%] train loss: 1.4576611647498794e-05 \n",
      "epoch: 30 [822140/888800 92.50%] train loss: 1.4370939425134566e-05 \n",
      "epoch: 30 [823251/888800 92.62%] train loss: 1.4649864169768989e-05 \n",
      "epoch: 30 [824362/888800 92.75%] train loss: 1.5025289940240327e-05 \n",
      "epoch: 30 [825473/888800 92.88%] train loss: 1.5094331502041314e-05 \n",
      "epoch: 30 [826584/888800 93.00%] train loss: 1.3684884834219702e-05 \n",
      "epoch: 30 [827695/888800 93.12%] train loss: 1.3833451703249011e-05 \n",
      "epoch: 30 [828806/888800 93.25%] train loss: 1.3923353435529862e-05 \n",
      "epoch: 30 [829917/888800 93.38%] train loss: 1.4965178706916049e-05 \n",
      "epoch: 30 [831028/888800 93.50%] train loss: 1.51570629896014e-05 \n",
      "epoch: 30 [832139/888800 93.62%] train loss: 1.4775983800063841e-05 \n",
      "epoch: 30 [833250/888800 93.75%] train loss: 1.3719647540710866e-05 \n",
      "epoch: 30 [834361/888800 93.88%] train loss: 1.4181386177369859e-05 \n",
      "epoch: 30 [835472/888800 94.00%] train loss: 1.4701789950777311e-05 \n",
      "epoch: 30 [836583/888800 94.12%] train loss: 1.4196206393535249e-05 \n",
      "epoch: 30 [837694/888800 94.25%] train loss: 1.3486478565027937e-05 \n",
      "epoch: 30 [838805/888800 94.38%] train loss: 1.3426553778117523e-05 \n",
      "epoch: 30 [839916/888800 94.50%] train loss: 1.4105441550782416e-05 \n",
      "epoch: 30 [841027/888800 94.62%] train loss: 1.4039753295946866e-05 \n",
      "epoch: 30 [842138/888800 94.75%] train loss: 1.4873528925818391e-05 \n",
      "epoch: 30 [843249/888800 94.88%] train loss: 1.4712953998241574e-05 \n",
      "epoch: 30 [844360/888800 95.00%] train loss: 1.3384387784753926e-05 \n",
      "epoch: 30 [845471/888800 95.12%] train loss: 1.524998606328154e-05 \n",
      "epoch: 30 [846582/888800 95.25%] train loss: 1.3237404346000403e-05 \n",
      "epoch: 30 [847693/888800 95.38%] train loss: 1.4572901818610262e-05 \n",
      "epoch: 30 [848804/888800 95.50%] train loss: 1.453210279578343e-05 \n",
      "epoch: 30 [849915/888800 95.62%] train loss: 1.4902821021678392e-05 \n",
      "epoch: 30 [851026/888800 95.75%] train loss: 1.4513430869556032e-05 \n",
      "epoch: 30 [852137/888800 95.88%] train loss: 1.5468298443011008e-05 \n",
      "epoch: 30 [853248/888800 96.00%] train loss: 1.432595763617428e-05 \n",
      "epoch: 30 [854359/888800 96.12%] train loss: 1.4147592992230784e-05 \n",
      "epoch: 30 [855470/888800 96.25%] train loss: 1.4302768249763176e-05 \n",
      "epoch: 30 [856581/888800 96.38%] train loss: 1.4460932106885593e-05 \n",
      "epoch: 30 [857692/888800 96.50%] train loss: 1.449625960958656e-05 \n",
      "epoch: 30 [858803/888800 96.62%] train loss: 1.5365016224677674e-05 \n",
      "epoch: 30 [859914/888800 96.75%] train loss: 1.3345239494810812e-05 \n",
      "epoch: 30 [861025/888800 96.88%] train loss: 1.4805043065280188e-05 \n",
      "epoch: 30 [862136/888800 97.00%] train loss: 1.4942188499844633e-05 \n",
      "epoch: 30 [863247/888800 97.12%] train loss: 1.3470329577103257e-05 \n",
      "epoch: 30 [864358/888800 97.25%] train loss: 1.4392197954293806e-05 \n",
      "epoch: 30 [865469/888800 97.38%] train loss: 1.5209985576802865e-05 \n",
      "epoch: 30 [866580/888800 97.50%] train loss: 1.530148074380122e-05 \n",
      "epoch: 30 [867691/888800 97.62%] train loss: 1.350632737739943e-05 \n",
      "epoch: 30 [868802/888800 97.75%] train loss: 1.4328135875985026e-05 \n",
      "epoch: 30 [869913/888800 97.88%] train loss: 1.4129828741715755e-05 \n",
      "epoch: 30 [871024/888800 98.00%] train loss: 1.3517718798539136e-05 \n",
      "epoch: 30 [872135/888800 98.12%] train loss: 1.4588463272957597e-05 \n",
      "epoch: 30 [873246/888800 98.25%] train loss: 1.4571518477168866e-05 \n",
      "epoch: 30 [874357/888800 98.38%] train loss: 1.3188771845307201e-05 \n",
      "epoch: 30 [875468/888800 98.50%] train loss: 1.4529605323332362e-05 \n",
      "epoch: 30 [876579/888800 98.62%] train loss: 1.3709247468796093e-05 \n",
      "epoch: 30 [877690/888800 98.75%] train loss: 1.3888116882299073e-05 \n",
      "epoch: 30 [878801/888800 98.88%] train loss: 1.5139901734073646e-05 \n",
      "epoch: 30 [879912/888800 99.00%] train loss: 1.6034833606681786e-05 \n",
      "epoch: 30 [881023/888800 99.12%] train loss: 1.5413961591548286e-05 \n",
      "epoch: 30 [882134/888800 99.25%] train loss: 1.5014452401374001e-05 \n",
      "epoch: 30 [883245/888800 99.38%] train loss: 1.3503032278094906e-05 \n",
      "epoch: 30 [884356/888800 99.50%] train loss: 1.4142473446554504e-05 \n",
      "epoch: 30 [885467/888800 99.62%] train loss: 1.421787601429969e-05 \n",
      "epoch: 30 [886578/888800 99.75%] train loss: 1.4967336937843356e-05 \n",
      "epoch: 30 [887689/888800 99.88%] train loss: 1.3622946426039562e-05 \n",
      "epoch: 31 [0/888800 0.00%] train loss: 1.4341073438117746e-05 \n",
      "epoch: 31 [1111/888800 0.12%] train loss: 1.320469436905114e-05 \n",
      "epoch: 31 [2222/888800 0.25%] train loss: 1.4077550076763146e-05 \n",
      "epoch: 31 [3333/888800 0.38%] train loss: 1.344348129350692e-05 \n",
      "epoch: 31 [4444/888800 0.50%] train loss: 1.2747140317515004e-05 \n",
      "epoch: 31 [5555/888800 0.62%] train loss: 1.3714007764065173e-05 \n",
      "epoch: 31 [6666/888800 0.75%] train loss: 1.4016389286553022e-05 \n",
      "epoch: 31 [7777/888800 0.88%] train loss: 1.5016300494608004e-05 \n",
      "epoch: 31 [8888/888800 1.00%] train loss: 1.4592175830330234e-05 \n",
      "epoch: 31 [9999/888800 1.12%] train loss: 1.5018769772723317e-05 \n",
      "epoch: 31 [11110/888800 1.25%] train loss: 1.4036314496479463e-05 \n",
      "epoch: 31 [12221/888800 1.38%] train loss: 1.4297188499767799e-05 \n",
      "epoch: 31 [13332/888800 1.50%] train loss: 1.5835594240343198e-05 \n",
      "epoch: 31 [14443/888800 1.62%] train loss: 1.557572431920562e-05 \n",
      "epoch: 31 [15554/888800 1.75%] train loss: 1.4227642168407328e-05 \n",
      "epoch: 31 [16665/888800 1.88%] train loss: 1.4541684322466608e-05 \n",
      "epoch: 31 [17776/888800 2.00%] train loss: 1.3772609236184508e-05 \n",
      "epoch: 31 [18887/888800 2.12%] train loss: 1.4237104551284574e-05 \n",
      "epoch: 31 [19998/888800 2.25%] train loss: 1.4701672625960782e-05 \n",
      "epoch: 31 [21109/888800 2.38%] train loss: 1.3562837011704687e-05 \n",
      "epoch: 31 [22220/888800 2.50%] train loss: 1.3341023077373393e-05 \n",
      "epoch: 31 [23331/888800 2.62%] train loss: 1.4122891116130631e-05 \n",
      "epoch: 31 [24442/888800 2.75%] train loss: 1.3598581062979065e-05 \n",
      "epoch: 31 [25553/888800 2.88%] train loss: 1.5516518033109605e-05 \n",
      "epoch: 31 [26664/888800 3.00%] train loss: 1.4313816791400313e-05 \n",
      "epoch: 31 [27775/888800 3.12%] train loss: 1.4942749658075627e-05 \n",
      "epoch: 31 [28886/888800 3.25%] train loss: 1.3341583326109685e-05 \n",
      "epoch: 31 [29997/888800 3.38%] train loss: 1.535726187285036e-05 \n",
      "epoch: 31 [31108/888800 3.50%] train loss: 1.3558497812482528e-05 \n",
      "epoch: 31 [32219/888800 3.62%] train loss: 1.385595624014968e-05 \n",
      "epoch: 31 [33330/888800 3.75%] train loss: 1.3948571904620621e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [34441/888800 3.88%] train loss: 1.4281987205322366e-05 \n",
      "epoch: 31 [35552/888800 4.00%] train loss: 1.457749749533832e-05 \n",
      "epoch: 31 [36663/888800 4.12%] train loss: 1.4827956874796655e-05 \n",
      "epoch: 31 [37774/888800 4.25%] train loss: 1.3965822290629148e-05 \n",
      "epoch: 31 [38885/888800 4.38%] train loss: 1.4216122508514673e-05 \n",
      "epoch: 31 [39996/888800 4.50%] train loss: 1.3757649867329746e-05 \n",
      "epoch: 31 [41107/888800 4.62%] train loss: 1.4175351680023596e-05 \n",
      "epoch: 31 [42218/888800 4.75%] train loss: 1.588313352840487e-05 \n",
      "epoch: 31 [43329/888800 4.88%] train loss: 1.475294993724674e-05 \n",
      "epoch: 31 [44440/888800 5.00%] train loss: 1.458494079997763e-05 \n",
      "epoch: 31 [45551/888800 5.12%] train loss: 1.5854469893383794e-05 \n",
      "epoch: 31 [46662/888800 5.25%] train loss: 1.3812347788189072e-05 \n",
      "epoch: 31 [47773/888800 5.38%] train loss: 1.5151478692132514e-05 \n",
      "epoch: 31 [48884/888800 5.50%] train loss: 1.3854604731022846e-05 \n",
      "epoch: 31 [49995/888800 5.62%] train loss: 1.6652720660204068e-05 \n",
      "epoch: 31 [51106/888800 5.75%] train loss: 1.386299936712021e-05 \n",
      "epoch: 31 [52217/888800 5.88%] train loss: 1.5083950529515278e-05 \n",
      "epoch: 31 [53328/888800 6.00%] train loss: 1.2545810932351742e-05 \n",
      "epoch: 31 [54439/888800 6.12%] train loss: 1.439570405636914e-05 \n",
      "epoch: 31 [55550/888800 6.25%] train loss: 1.4245702004700433e-05 \n",
      "epoch: 31 [56661/888800 6.38%] train loss: 1.536570562166162e-05 \n",
      "epoch: 31 [57772/888800 6.50%] train loss: 1.3846892215951812e-05 \n",
      "epoch: 31 [58883/888800 6.62%] train loss: 1.4591050785384141e-05 \n",
      "epoch: 31 [59994/888800 6.75%] train loss: 1.5021492799860425e-05 \n",
      "epoch: 31 [61105/888800 6.88%] train loss: 1.4606739568989724e-05 \n",
      "epoch: 31 [62216/888800 7.00%] train loss: 1.5739084119559266e-05 \n",
      "epoch: 31 [63327/888800 7.12%] train loss: 1.4797587937209755e-05 \n",
      "epoch: 31 [64438/888800 7.25%] train loss: 1.6157899153768085e-05 \n",
      "epoch: 31 [65549/888800 7.38%] train loss: 1.4594374988519121e-05 \n",
      "epoch: 31 [66660/888800 7.50%] train loss: 1.5107004401215818e-05 \n",
      "epoch: 31 [67771/888800 7.62%] train loss: 1.4113527868175879e-05 \n",
      "epoch: 31 [68882/888800 7.75%] train loss: 1.3681131349585485e-05 \n",
      "epoch: 31 [69993/888800 7.88%] train loss: 1.370981499349e-05 \n",
      "epoch: 31 [71104/888800 8.00%] train loss: 1.4152727089822292e-05 \n",
      "epoch: 31 [72215/888800 8.12%] train loss: 1.4944617760193069e-05 \n",
      "epoch: 31 [73326/888800 8.25%] train loss: 1.54665503941942e-05 \n",
      "epoch: 31 [74437/888800 8.38%] train loss: 1.7476282664574683e-05 \n",
      "epoch: 31 [75548/888800 8.50%] train loss: 1.4541948075930122e-05 \n",
      "epoch: 31 [76659/888800 8.62%] train loss: 1.4509365428239107e-05 \n",
      "epoch: 31 [77770/888800 8.75%] train loss: 1.3231164302851539e-05 \n",
      "epoch: 31 [78881/888800 8.88%] train loss: 1.3737400877289474e-05 \n",
      "epoch: 31 [79992/888800 9.00%] train loss: 1.4681553693662863e-05 \n",
      "epoch: 31 [81103/888800 9.12%] train loss: 1.5449895727215335e-05 \n",
      "epoch: 31 [82214/888800 9.25%] train loss: 1.4958719475544058e-05 \n",
      "epoch: 31 [83325/888800 9.38%] train loss: 1.5267034541466273e-05 \n",
      "epoch: 31 [84436/888800 9.50%] train loss: 1.4445214219449554e-05 \n",
      "epoch: 31 [85547/888800 9.62%] train loss: 1.4077771993470378e-05 \n",
      "epoch: 31 [86658/888800 9.75%] train loss: 1.4349141565617174e-05 \n",
      "epoch: 31 [87769/888800 9.88%] train loss: 1.4168312191031873e-05 \n",
      "epoch: 31 [88880/888800 10.00%] train loss: 1.3532601769838948e-05 \n",
      "epoch: 31 [89991/888800 10.12%] train loss: 1.3901587408327032e-05 \n",
      "epoch: 31 [91102/888800 10.25%] train loss: 1.4088139323575888e-05 \n",
      "epoch: 31 [92213/888800 10.38%] train loss: 1.4000810551806353e-05 \n",
      "epoch: 31 [93324/888800 10.50%] train loss: 1.5202962458715774e-05 \n",
      "epoch: 31 [94435/888800 10.62%] train loss: 1.4417332749872003e-05 \n",
      "epoch: 31 [95546/888800 10.75%] train loss: 1.4296047083917074e-05 \n",
      "epoch: 31 [96657/888800 10.88%] train loss: 1.4491158253804315e-05 \n",
      "epoch: 31 [97768/888800 11.00%] train loss: 1.453698132536374e-05 \n",
      "epoch: 31 [98879/888800 11.12%] train loss: 1.4137448488327209e-05 \n",
      "epoch: 31 [99990/888800 11.25%] train loss: 1.4614480278396513e-05 \n",
      "epoch: 31 [101101/888800 11.38%] train loss: 1.4736677258042619e-05 \n",
      "epoch: 31 [102212/888800 11.50%] train loss: 1.3369053704082035e-05 \n",
      "epoch: 31 [103323/888800 11.62%] train loss: 1.3609302186523564e-05 \n",
      "epoch: 31 [104434/888800 11.75%] train loss: 1.5202018403215334e-05 \n",
      "epoch: 31 [105545/888800 11.88%] train loss: 1.566983337397687e-05 \n",
      "epoch: 31 [106656/888800 12.00%] train loss: 1.6623636838630773e-05 \n",
      "epoch: 31 [107767/888800 12.12%] train loss: 1.564947160659358e-05 \n",
      "epoch: 31 [108878/888800 12.25%] train loss: 1.2710357623291202e-05 \n",
      "epoch: 31 [109989/888800 12.38%] train loss: 1.4095955521042924e-05 \n",
      "epoch: 31 [111100/888800 12.50%] train loss: 1.4454467418545391e-05 \n",
      "epoch: 31 [112211/888800 12.62%] train loss: 1.3763749848294538e-05 \n",
      "epoch: 31 [113322/888800 12.75%] train loss: 1.52634056576062e-05 \n",
      "epoch: 31 [114433/888800 12.88%] train loss: 1.5954805348883383e-05 \n",
      "epoch: 31 [115544/888800 13.00%] train loss: 1.4256558642955497e-05 \n",
      "epoch: 31 [116655/888800 13.12%] train loss: 1.4018776710145175e-05 \n",
      "epoch: 31 [117766/888800 13.25%] train loss: 1.5428688129759394e-05 \n",
      "epoch: 31 [118877/888800 13.38%] train loss: 1.5159440408751834e-05 \n",
      "epoch: 31 [119988/888800 13.50%] train loss: 1.3830498573952354e-05 \n",
      "epoch: 31 [121099/888800 13.62%] train loss: 1.2623434486158658e-05 \n",
      "epoch: 31 [122210/888800 13.75%] train loss: 1.3245120499050245e-05 \n",
      "epoch: 31 [123321/888800 13.88%] train loss: 1.3837311598763335e-05 \n",
      "epoch: 31 [124432/888800 14.00%] train loss: 1.3211775694799144e-05 \n",
      "epoch: 31 [125543/888800 14.12%] train loss: 1.4474154340859968e-05 \n",
      "epoch: 31 [126654/888800 14.25%] train loss: 1.3422955817077309e-05 \n",
      "epoch: 31 [127765/888800 14.38%] train loss: 1.4173288036545273e-05 \n",
      "epoch: 31 [128876/888800 14.50%] train loss: 1.559925112815108e-05 \n",
      "epoch: 31 [129987/888800 14.62%] train loss: 1.4212656424206216e-05 \n",
      "epoch: 31 [131098/888800 14.75%] train loss: 1.3684373698197305e-05 \n",
      "epoch: 31 [132209/888800 14.88%] train loss: 1.452322248951532e-05 \n",
      "epoch: 31 [133320/888800 15.00%] train loss: 1.4215735063771717e-05 \n",
      "epoch: 31 [134431/888800 15.12%] train loss: 1.502968279964989e-05 \n",
      "epoch: 31 [135542/888800 15.25%] train loss: 1.4724661014042795e-05 \n",
      "epoch: 31 [136653/888800 15.38%] train loss: 1.39057774504181e-05 \n",
      "epoch: 31 [137764/888800 15.50%] train loss: 1.460687053622678e-05 \n",
      "epoch: 31 [138875/888800 15.62%] train loss: 1.3796180610370357e-05 \n",
      "epoch: 31 [139986/888800 15.75%] train loss: 1.352940671495162e-05 \n",
      "epoch: 31 [141097/888800 15.88%] train loss: 1.5347717635449953e-05 \n",
      "epoch: 31 [142208/888800 16.00%] train loss: 1.3506349205272272e-05 \n",
      "epoch: 31 [143319/888800 16.12%] train loss: 1.4942109373805579e-05 \n",
      "epoch: 31 [144430/888800 16.25%] train loss: 1.4448376532527618e-05 \n",
      "epoch: 31 [145541/888800 16.38%] train loss: 1.4213806935003959e-05 \n",
      "epoch: 31 [146652/888800 16.50%] train loss: 1.4318457033368759e-05 \n",
      "epoch: 31 [147763/888800 16.62%] train loss: 1.384889765176922e-05 \n",
      "epoch: 31 [148874/888800 16.75%] train loss: 1.3966401638754178e-05 \n",
      "epoch: 31 [149985/888800 16.88%] train loss: 1.4928547898307443e-05 \n",
      "epoch: 31 [151096/888800 17.00%] train loss: 1.3969914107292425e-05 \n",
      "epoch: 31 [152207/888800 17.12%] train loss: 1.3297016266733408e-05 \n",
      "epoch: 31 [153318/888800 17.25%] train loss: 1.3647284504259005e-05 \n",
      "epoch: 31 [154429/888800 17.38%] train loss: 1.3461165508488193e-05 \n",
      "epoch: 31 [155540/888800 17.50%] train loss: 1.4304771866591182e-05 \n",
      "epoch: 31 [156651/888800 17.62%] train loss: 1.461840292904526e-05 \n",
      "epoch: 31 [157762/888800 17.75%] train loss: 1.3446920092974324e-05 \n",
      "epoch: 31 [158873/888800 17.88%] train loss: 1.3531570402847137e-05 \n",
      "epoch: 31 [159984/888800 18.00%] train loss: 1.4386128896148875e-05 \n",
      "epoch: 31 [161095/888800 18.12%] train loss: 1.4925778486940544e-05 \n",
      "epoch: 31 [162206/888800 18.25%] train loss: 1.410730601492105e-05 \n",
      "epoch: 31 [163317/888800 18.38%] train loss: 1.5221714420476928e-05 \n",
      "epoch: 31 [164428/888800 18.50%] train loss: 1.4181761798681691e-05 \n",
      "epoch: 31 [165539/888800 18.62%] train loss: 1.455194978916552e-05 \n",
      "epoch: 31 [166650/888800 18.75%] train loss: 1.5063414139149245e-05 \n",
      "epoch: 31 [167761/888800 18.88%] train loss: 1.4268942322814837e-05 \n",
      "epoch: 31 [168872/888800 19.00%] train loss: 1.3779365872323979e-05 \n",
      "epoch: 31 [169983/888800 19.12%] train loss: 1.450549916626187e-05 \n",
      "epoch: 31 [171094/888800 19.25%] train loss: 1.5045497093524318e-05 \n",
      "epoch: 31 [172205/888800 19.38%] train loss: 1.5030448594188783e-05 \n",
      "epoch: 31 [173316/888800 19.50%] train loss: 1.487196914240485e-05 \n",
      "epoch: 31 [174427/888800 19.62%] train loss: 1.4859365364827681e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [175538/888800 19.75%] train loss: 1.4281026778917294e-05 \n",
      "epoch: 31 [176649/888800 19.88%] train loss: 1.5049438843561802e-05 \n",
      "epoch: 31 [177760/888800 20.00%] train loss: 1.5499628716497682e-05 \n",
      "epoch: 31 [178871/888800 20.12%] train loss: 1.454719495086465e-05 \n",
      "epoch: 31 [179982/888800 20.25%] train loss: 1.578129558765795e-05 \n",
      "epoch: 31 [181093/888800 20.38%] train loss: 1.3405159734247718e-05 \n",
      "epoch: 31 [182204/888800 20.50%] train loss: 1.539388540550135e-05 \n",
      "epoch: 31 [183315/888800 20.62%] train loss: 1.6852000044309534e-05 \n",
      "epoch: 31 [184426/888800 20.75%] train loss: 1.4027354154677596e-05 \n",
      "epoch: 31 [185537/888800 20.88%] train loss: 1.5663608792237937e-05 \n",
      "epoch: 31 [186648/888800 21.00%] train loss: 1.4029114026925527e-05 \n",
      "epoch: 31 [187759/888800 21.12%] train loss: 1.5237711522786412e-05 \n",
      "epoch: 31 [188870/888800 21.25%] train loss: 1.4380982065631542e-05 \n",
      "epoch: 31 [189981/888800 21.38%] train loss: 1.6623929695924744e-05 \n",
      "epoch: 31 [191092/888800 21.50%] train loss: 1.4256715076044202e-05 \n",
      "epoch: 31 [192203/888800 21.62%] train loss: 1.607860940566752e-05 \n",
      "epoch: 31 [193314/888800 21.75%] train loss: 1.5750467355246656e-05 \n",
      "epoch: 31 [194425/888800 21.88%] train loss: 1.327807240159018e-05 \n",
      "epoch: 31 [195536/888800 22.00%] train loss: 1.533816976007074e-05 \n",
      "epoch: 31 [196647/888800 22.12%] train loss: 1.3528886483982205e-05 \n",
      "epoch: 31 [197758/888800 22.25%] train loss: 1.5486124539165758e-05 \n",
      "epoch: 31 [198869/888800 22.38%] train loss: 1.3802498870063573e-05 \n",
      "epoch: 31 [199980/888800 22.50%] train loss: 1.4008732250658795e-05 \n",
      "epoch: 31 [201091/888800 22.62%] train loss: 1.4243901205190923e-05 \n",
      "epoch: 31 [202202/888800 22.75%] train loss: 1.319664534094045e-05 \n",
      "epoch: 31 [203313/888800 22.88%] train loss: 1.3499765373126138e-05 \n",
      "epoch: 31 [204424/888800 23.00%] train loss: 1.4664507034467533e-05 \n",
      "epoch: 31 [205535/888800 23.12%] train loss: 1.4298442692961544e-05 \n",
      "epoch: 31 [206646/888800 23.25%] train loss: 1.4766670574317686e-05 \n",
      "epoch: 31 [207757/888800 23.38%] train loss: 1.292390425078338e-05 \n",
      "epoch: 31 [208868/888800 23.50%] train loss: 1.313013126491569e-05 \n",
      "epoch: 31 [209979/888800 23.62%] train loss: 1.3868397218175232e-05 \n",
      "epoch: 31 [211090/888800 23.75%] train loss: 1.4002791431266814e-05 \n",
      "epoch: 31 [212201/888800 23.88%] train loss: 1.3692279935639817e-05 \n",
      "epoch: 31 [213312/888800 24.00%] train loss: 1.4393088349606842e-05 \n",
      "epoch: 31 [214423/888800 24.12%] train loss: 1.3992964341014158e-05 \n",
      "epoch: 31 [215534/888800 24.25%] train loss: 1.5215926396194845e-05 \n",
      "epoch: 31 [216645/888800 24.38%] train loss: 1.4211982488632202e-05 \n",
      "epoch: 31 [217756/888800 24.50%] train loss: 1.3604155356006231e-05 \n",
      "epoch: 31 [218867/888800 24.62%] train loss: 1.4188185559760313e-05 \n",
      "epoch: 31 [219978/888800 24.75%] train loss: 1.2339950444584247e-05 \n",
      "epoch: 31 [221089/888800 24.88%] train loss: 1.4678907973575406e-05 \n",
      "epoch: 31 [222200/888800 25.00%] train loss: 1.4075912076805253e-05 \n",
      "epoch: 31 [223311/888800 25.12%] train loss: 1.3611904250865337e-05 \n",
      "epoch: 31 [224422/888800 25.25%] train loss: 1.4081275367061608e-05 \n",
      "epoch: 31 [225533/888800 25.38%] train loss: 1.462843738408992e-05 \n",
      "epoch: 31 [226644/888800 25.50%] train loss: 1.4587958503398113e-05 \n",
      "epoch: 31 [227755/888800 25.62%] train loss: 1.349281046714168e-05 \n",
      "epoch: 31 [228866/888800 25.75%] train loss: 1.5003840417193715e-05 \n",
      "epoch: 31 [229977/888800 25.88%] train loss: 1.3048017535766121e-05 \n",
      "epoch: 31 [231088/888800 26.00%] train loss: 1.4296190784079954e-05 \n",
      "epoch: 31 [232199/888800 26.12%] train loss: 1.3510950338968541e-05 \n",
      "epoch: 31 [233310/888800 26.25%] train loss: 1.353223342448473e-05 \n",
      "epoch: 31 [234421/888800 26.38%] train loss: 1.4940265828045085e-05 \n",
      "epoch: 31 [235532/888800 26.50%] train loss: 1.4794777598581277e-05 \n",
      "epoch: 31 [236643/888800 26.62%] train loss: 1.4252910659706686e-05 \n",
      "epoch: 31 [237754/888800 26.75%] train loss: 1.34632718982175e-05 \n",
      "epoch: 31 [238865/888800 26.88%] train loss: 1.3689430488739163e-05 \n",
      "epoch: 31 [239976/888800 27.00%] train loss: 1.4300244401965756e-05 \n",
      "epoch: 31 [241087/888800 27.12%] train loss: 1.4974193618400022e-05 \n",
      "epoch: 31 [242198/888800 27.25%] train loss: 1.407266336173052e-05 \n",
      "epoch: 31 [243309/888800 27.38%] train loss: 1.3959618627268355e-05 \n",
      "epoch: 31 [244420/888800 27.50%] train loss: 1.4813283996772952e-05 \n",
      "epoch: 31 [245531/888800 27.62%] train loss: 1.4748018656973727e-05 \n",
      "epoch: 31 [246642/888800 27.75%] train loss: 1.4048673619981855e-05 \n",
      "epoch: 31 [247753/888800 27.88%] train loss: 1.5325880667660385e-05 \n",
      "epoch: 31 [248864/888800 28.00%] train loss: 1.4656720850325655e-05 \n",
      "epoch: 31 [249975/888800 28.12%] train loss: 1.457715370634105e-05 \n",
      "epoch: 31 [251086/888800 28.25%] train loss: 1.3970936379337218e-05 \n",
      "epoch: 31 [252197/888800 28.38%] train loss: 1.4454777556238696e-05 \n",
      "epoch: 31 [253308/888800 28.50%] train loss: 1.3893059986003209e-05 \n",
      "epoch: 31 [254419/888800 28.62%] train loss: 1.4892223589413334e-05 \n",
      "epoch: 31 [255530/888800 28.75%] train loss: 1.3370274245971814e-05 \n",
      "epoch: 31 [256641/888800 28.88%] train loss: 1.3953848792880308e-05 \n",
      "epoch: 31 [257752/888800 29.00%] train loss: 1.3085134924040176e-05 \n",
      "epoch: 31 [258863/888800 29.12%] train loss: 1.477110981795704e-05 \n",
      "epoch: 31 [259974/888800 29.25%] train loss: 1.3963455785415135e-05 \n",
      "epoch: 31 [261085/888800 29.38%] train loss: 1.3019447578699328e-05 \n",
      "epoch: 31 [262196/888800 29.50%] train loss: 1.3430057151708752e-05 \n",
      "epoch: 31 [263307/888800 29.62%] train loss: 1.2420379789546132e-05 \n",
      "epoch: 31 [264418/888800 29.75%] train loss: 1.408484695275547e-05 \n",
      "epoch: 31 [265529/888800 29.88%] train loss: 1.4427845599129796e-05 \n",
      "epoch: 31 [266640/888800 30.00%] train loss: 1.3738227607973386e-05 \n",
      "epoch: 31 [267751/888800 30.12%] train loss: 1.4216117051546462e-05 \n",
      "epoch: 31 [268862/888800 30.25%] train loss: 1.4728507267136592e-05 \n",
      "epoch: 31 [269973/888800 30.38%] train loss: 1.411408720741747e-05 \n",
      "epoch: 31 [271084/888800 30.50%] train loss: 1.409105971106328e-05 \n",
      "epoch: 31 [272195/888800 30.62%] train loss: 1.3683139513887e-05 \n",
      "epoch: 31 [273306/888800 30.75%] train loss: 1.4448933143285103e-05 \n",
      "epoch: 31 [274417/888800 30.88%] train loss: 1.4670091331936419e-05 \n",
      "epoch: 31 [275528/888800 31.00%] train loss: 1.4089963769947644e-05 \n",
      "epoch: 31 [276639/888800 31.12%] train loss: 1.3607403161586262e-05 \n",
      "epoch: 31 [277750/888800 31.25%] train loss: 1.404512113367673e-05 \n",
      "epoch: 31 [278861/888800 31.38%] train loss: 1.3593492440122645e-05 \n",
      "epoch: 31 [279972/888800 31.50%] train loss: 1.4542457392963115e-05 \n",
      "epoch: 31 [281083/888800 31.62%] train loss: 1.3953464076621458e-05 \n",
      "epoch: 31 [282194/888800 31.75%] train loss: 1.3005171240365598e-05 \n",
      "epoch: 31 [283305/888800 31.88%] train loss: 1.3653838323079981e-05 \n",
      "epoch: 31 [284416/888800 32.00%] train loss: 1.5222507499856874e-05 \n",
      "epoch: 31 [285527/888800 32.12%] train loss: 1.3067193322058301e-05 \n",
      "epoch: 31 [286638/888800 32.25%] train loss: 1.4335824744193815e-05 \n",
      "epoch: 31 [287749/888800 32.38%] train loss: 1.449187948310282e-05 \n",
      "epoch: 31 [288860/888800 32.50%] train loss: 1.4984068911871873e-05 \n",
      "epoch: 31 [289971/888800 32.62%] train loss: 1.4800548342464026e-05 \n",
      "epoch: 31 [291082/888800 32.75%] train loss: 1.5228447409754153e-05 \n",
      "epoch: 31 [292193/888800 32.88%] train loss: 1.6032889107009396e-05 \n",
      "epoch: 31 [293304/888800 33.00%] train loss: 1.4463544175669085e-05 \n",
      "epoch: 31 [294415/888800 33.12%] train loss: 1.4460226338997018e-05 \n",
      "epoch: 31 [295526/888800 33.25%] train loss: 1.405661714670714e-05 \n",
      "epoch: 31 [296637/888800 33.38%] train loss: 1.5640220226487145e-05 \n",
      "epoch: 31 [297748/888800 33.50%] train loss: 1.5866356989135966e-05 \n",
      "epoch: 31 [298859/888800 33.62%] train loss: 1.3425629731500521e-05 \n",
      "epoch: 31 [299970/888800 33.75%] train loss: 1.3683907127415296e-05 \n",
      "epoch: 31 [301081/888800 33.88%] train loss: 1.418815281795105e-05 \n",
      "epoch: 31 [302192/888800 34.00%] train loss: 1.315473946306156e-05 \n",
      "epoch: 31 [303303/888800 34.12%] train loss: 1.4054782695893664e-05 \n",
      "epoch: 31 [304414/888800 34.25%] train loss: 1.3648349522554781e-05 \n",
      "epoch: 31 [305525/888800 34.38%] train loss: 1.5244877431541681e-05 \n",
      "epoch: 31 [306636/888800 34.50%] train loss: 1.3671147826244123e-05 \n",
      "epoch: 31 [307747/888800 34.62%] train loss: 1.4855016161163803e-05 \n",
      "epoch: 31 [308858/888800 34.75%] train loss: 1.4126859241514467e-05 \n",
      "epoch: 31 [309969/888800 34.88%] train loss: 1.355876520392485e-05 \n",
      "epoch: 31 [311080/888800 35.00%] train loss: 1.409590731782373e-05 \n",
      "epoch: 31 [312191/888800 35.12%] train loss: 1.6058067558333278e-05 \n",
      "epoch: 31 [313302/888800 35.25%] train loss: 1.5219501619867515e-05 \n",
      "epoch: 31 [314413/888800 35.38%] train loss: 1.5215031453408301e-05 \n",
      "epoch: 31 [315524/888800 35.50%] train loss: 1.3348859283723868e-05 \n",
      "epoch: 31 [316635/888800 35.62%] train loss: 1.2900908586743753e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [317746/888800 35.75%] train loss: 1.3984974430059083e-05 \n",
      "epoch: 31 [318857/888800 35.88%] train loss: 1.4147693946142681e-05 \n",
      "epoch: 31 [319968/888800 36.00%] train loss: 1.3581112398242112e-05 \n",
      "epoch: 31 [321079/888800 36.12%] train loss: 1.3466460586641915e-05 \n",
      "epoch: 31 [322190/888800 36.25%] train loss: 1.3680748452316038e-05 \n",
      "epoch: 31 [323301/888800 36.38%] train loss: 1.3823800145473797e-05 \n",
      "epoch: 31 [324412/888800 36.50%] train loss: 1.4635190382250585e-05 \n",
      "epoch: 31 [325523/888800 36.62%] train loss: 1.4557573194906581e-05 \n",
      "epoch: 31 [326634/888800 36.75%] train loss: 1.4813204870733898e-05 \n",
      "epoch: 31 [327745/888800 36.88%] train loss: 1.4365128663484938e-05 \n",
      "epoch: 31 [328856/888800 37.00%] train loss: 1.591626823937986e-05 \n",
      "epoch: 31 [329967/888800 37.12%] train loss: 1.3934548405813985e-05 \n",
      "epoch: 31 [331078/888800 37.25%] train loss: 1.7447386198909953e-05 \n",
      "epoch: 31 [332189/888800 37.38%] train loss: 1.540670018584933e-05 \n",
      "epoch: 31 [333300/888800 37.50%] train loss: 1.5436969988513738e-05 \n",
      "epoch: 31 [334411/888800 37.62%] train loss: 1.4989673218224198e-05 \n",
      "epoch: 31 [335522/888800 37.75%] train loss: 1.479198817833094e-05 \n",
      "epoch: 31 [336633/888800 37.88%] train loss: 1.5692350643803366e-05 \n",
      "epoch: 31 [337744/888800 38.00%] train loss: 1.3199858585721813e-05 \n",
      "epoch: 31 [338855/888800 38.12%] train loss: 1.8208753317594528e-05 \n",
      "epoch: 31 [339966/888800 38.25%] train loss: 1.3942303667136002e-05 \n",
      "epoch: 31 [341077/888800 38.38%] train loss: 1.5497456843149848e-05 \n",
      "epoch: 31 [342188/888800 38.50%] train loss: 1.4656890016340185e-05 \n",
      "epoch: 31 [343299/888800 38.62%] train loss: 1.3543815839511808e-05 \n",
      "epoch: 31 [344410/888800 38.75%] train loss: 1.4111572454567067e-05 \n",
      "epoch: 31 [345521/888800 38.88%] train loss: 1.4626675692852587e-05 \n",
      "epoch: 31 [346632/888800 39.00%] train loss: 1.58857146743685e-05 \n",
      "epoch: 31 [347743/888800 39.12%] train loss: 1.372213773720432e-05 \n",
      "epoch: 31 [348854/888800 39.25%] train loss: 1.542338213766925e-05 \n",
      "epoch: 31 [349965/888800 39.38%] train loss: 1.529796099930536e-05 \n",
      "epoch: 31 [351076/888800 39.50%] train loss: 1.3503768968803342e-05 \n",
      "epoch: 31 [352187/888800 39.62%] train loss: 1.3526648217521142e-05 \n",
      "epoch: 31 [353298/888800 39.75%] train loss: 1.3848359230905771e-05 \n",
      "epoch: 31 [354409/888800 39.88%] train loss: 1.3937697985966224e-05 \n",
      "epoch: 31 [355520/888800 40.00%] train loss: 1.3731070794165134e-05 \n",
      "epoch: 31 [356631/888800 40.12%] train loss: 1.4898455447109882e-05 \n",
      "epoch: 31 [357742/888800 40.25%] train loss: 1.5341245671152137e-05 \n",
      "epoch: 31 [358853/888800 40.38%] train loss: 1.3989826584293041e-05 \n",
      "epoch: 31 [359964/888800 40.50%] train loss: 1.4173930139804725e-05 \n",
      "epoch: 31 [361075/888800 40.62%] train loss: 1.3553825738199521e-05 \n",
      "epoch: 31 [362186/888800 40.75%] train loss: 1.4941564586479217e-05 \n",
      "epoch: 31 [363297/888800 40.88%] train loss: 1.4500335964839906e-05 \n",
      "epoch: 31 [364408/888800 41.00%] train loss: 1.4280632058216725e-05 \n",
      "epoch: 31 [365519/888800 41.12%] train loss: 1.4515273505821824e-05 \n",
      "epoch: 31 [366630/888800 41.25%] train loss: 1.4045282114238944e-05 \n",
      "epoch: 31 [367741/888800 41.38%] train loss: 1.4191659829521086e-05 \n",
      "epoch: 31 [368852/888800 41.50%] train loss: 1.3675464288098738e-05 \n",
      "epoch: 31 [369963/888800 41.62%] train loss: 1.437427090422716e-05 \n",
      "epoch: 31 [371074/888800 41.75%] train loss: 1.4304508113127667e-05 \n",
      "epoch: 31 [372185/888800 41.88%] train loss: 1.3143609066901263e-05 \n",
      "epoch: 31 [373296/888800 42.00%] train loss: 1.478492958995048e-05 \n",
      "epoch: 31 [374407/888800 42.12%] train loss: 1.571030770719517e-05 \n",
      "epoch: 31 [375518/888800 42.25%] train loss: 1.352531853626715e-05 \n",
      "epoch: 31 [376629/888800 42.38%] train loss: 1.4838355127722025e-05 \n",
      "epoch: 31 [377740/888800 42.50%] train loss: 1.5209267985483166e-05 \n",
      "epoch: 31 [378851/888800 42.62%] train loss: 1.4020729395269882e-05 \n",
      "epoch: 31 [379962/888800 42.75%] train loss: 1.376064210489858e-05 \n",
      "epoch: 31 [381073/888800 42.88%] train loss: 1.4913366612745449e-05 \n",
      "epoch: 31 [382184/888800 43.00%] train loss: 1.4220915545593016e-05 \n",
      "epoch: 31 [383295/888800 43.12%] train loss: 1.420906755811302e-05 \n",
      "epoch: 31 [384406/888800 43.25%] train loss: 1.4224322512745857e-05 \n",
      "epoch: 31 [385517/888800 43.38%] train loss: 1.3221642802818678e-05 \n",
      "epoch: 31 [386628/888800 43.50%] train loss: 1.3991417290526442e-05 \n",
      "epoch: 31 [387739/888800 43.62%] train loss: 1.5242007066262886e-05 \n",
      "epoch: 31 [388850/888800 43.75%] train loss: 1.3772222700936254e-05 \n",
      "epoch: 31 [389961/888800 43.88%] train loss: 1.5531804820057005e-05 \n",
      "epoch: 31 [391072/888800 44.00%] train loss: 1.3106865480949637e-05 \n",
      "epoch: 31 [392183/888800 44.12%] train loss: 1.4910634490661323e-05 \n",
      "epoch: 31 [393294/888800 44.25%] train loss: 1.3536232472688425e-05 \n",
      "epoch: 31 [394405/888800 44.38%] train loss: 1.3540404324885458e-05 \n",
      "epoch: 31 [395516/888800 44.50%] train loss: 1.3423476957541425e-05 \n",
      "epoch: 31 [396627/888800 44.62%] train loss: 1.4969846233725548e-05 \n",
      "epoch: 31 [397738/888800 44.75%] train loss: 1.5778054148540832e-05 \n",
      "epoch: 31 [398849/888800 44.88%] train loss: 1.3171335922379512e-05 \n",
      "epoch: 31 [399960/888800 45.00%] train loss: 1.4362783076649066e-05 \n",
      "epoch: 31 [401071/888800 45.12%] train loss: 1.3968970961286686e-05 \n",
      "epoch: 31 [402182/888800 45.25%] train loss: 1.3959561329102144e-05 \n",
      "epoch: 31 [403293/888800 45.38%] train loss: 1.4391831427928992e-05 \n",
      "epoch: 31 [404404/888800 45.50%] train loss: 1.3320641301106662e-05 \n",
      "epoch: 31 [405515/888800 45.62%] train loss: 1.2737676115648355e-05 \n",
      "epoch: 31 [406626/888800 45.75%] train loss: 1.4738076970388647e-05 \n",
      "epoch: 31 [407737/888800 45.88%] train loss: 1.5232902114803437e-05 \n",
      "epoch: 31 [408848/888800 46.00%] train loss: 1.4123970686341636e-05 \n",
      "epoch: 31 [409959/888800 46.12%] train loss: 1.4526389350066893e-05 \n",
      "epoch: 31 [411070/888800 46.25%] train loss: 1.4715508768858854e-05 \n",
      "epoch: 31 [412181/888800 46.38%] train loss: 1.323343258263776e-05 \n",
      "epoch: 31 [413292/888800 46.50%] train loss: 1.427260667696828e-05 \n",
      "epoch: 31 [414403/888800 46.62%] train loss: 1.4352695870911703e-05 \n",
      "epoch: 31 [415514/888800 46.75%] train loss: 1.4987645045039244e-05 \n",
      "epoch: 31 [416625/888800 46.88%] train loss: 1.3470611520460807e-05 \n",
      "epoch: 31 [417736/888800 47.00%] train loss: 1.5242563677020371e-05 \n",
      "epoch: 31 [418847/888800 47.12%] train loss: 1.3652236702910159e-05 \n",
      "epoch: 31 [419958/888800 47.25%] train loss: 1.5215068742691074e-05 \n",
      "epoch: 31 [421069/888800 47.38%] train loss: 1.3855149518349208e-05 \n",
      "epoch: 31 [422180/888800 47.50%] train loss: 1.436385173292365e-05 \n",
      "epoch: 31 [423291/888800 47.62%] train loss: 1.3575303455581889e-05 \n",
      "epoch: 31 [424402/888800 47.75%] train loss: 1.3999145267007407e-05 \n",
      "epoch: 31 [425513/888800 47.88%] train loss: 1.4465130334428977e-05 \n",
      "epoch: 31 [426624/888800 48.00%] train loss: 1.4875909073452931e-05 \n",
      "epoch: 31 [427735/888800 48.12%] train loss: 1.4609898244088981e-05 \n",
      "epoch: 31 [428846/888800 48.25%] train loss: 1.5157029338297434e-05 \n",
      "epoch: 31 [429957/888800 48.38%] train loss: 1.3674496585736051e-05 \n",
      "epoch: 31 [431068/888800 48.50%] train loss: 1.4271362488216255e-05 \n",
      "epoch: 31 [432179/888800 48.62%] train loss: 1.4775886484130751e-05 \n",
      "epoch: 31 [433290/888800 48.75%] train loss: 1.3841095096722711e-05 \n",
      "epoch: 31 [434401/888800 48.88%] train loss: 1.3276726349431556e-05 \n",
      "epoch: 31 [435512/888800 49.00%] train loss: 1.4414426004805136e-05 \n",
      "epoch: 31 [436623/888800 49.12%] train loss: 1.3326722182682715e-05 \n",
      "epoch: 31 [437734/888800 49.25%] train loss: 1.530323970655445e-05 \n",
      "epoch: 31 [438845/888800 49.38%] train loss: 1.4407677554117981e-05 \n",
      "epoch: 31 [439956/888800 49.50%] train loss: 1.3648042113345582e-05 \n",
      "epoch: 31 [441067/888800 49.62%] train loss: 1.4392016055353452e-05 \n",
      "epoch: 31 [442178/888800 49.75%] train loss: 1.3238674000604078e-05 \n",
      "epoch: 31 [443289/888800 49.88%] train loss: 1.299594350712141e-05 \n",
      "epoch: 31 [444400/888800 50.00%] train loss: 1.4154547898215242e-05 \n",
      "epoch: 31 [445511/888800 50.12%] train loss: 1.3583427971752826e-05 \n",
      "epoch: 31 [446622/888800 50.25%] train loss: 1.3429008504317608e-05 \n",
      "epoch: 31 [447733/888800 50.38%] train loss: 1.4053293853066862e-05 \n",
      "epoch: 31 [448844/888800 50.50%] train loss: 1.3236883205536287e-05 \n",
      "epoch: 31 [449955/888800 50.62%] train loss: 1.4841737538517918e-05 \n",
      "epoch: 31 [451066/888800 50.75%] train loss: 1.358260942652123e-05 \n",
      "epoch: 31 [452177/888800 50.88%] train loss: 1.3704883713216987e-05 \n",
      "epoch: 31 [453288/888800 51.00%] train loss: 1.6183108527911827e-05 \n",
      "epoch: 31 [454399/888800 51.12%] train loss: 1.3982842574478127e-05 \n",
      "epoch: 31 [455510/888800 51.25%] train loss: 1.3437678717309609e-05 \n",
      "epoch: 31 [456621/888800 51.38%] train loss: 1.5020276805444155e-05 \n",
      "epoch: 31 [457732/888800 51.50%] train loss: 1.648608667892404e-05 \n",
      "epoch: 31 [458843/888800 51.62%] train loss: 1.537722891953308e-05 \n",
      "epoch: 31 [459954/888800 51.75%] train loss: 1.3685270459973253e-05 \n",
      "epoch: 31 [461065/888800 51.88%] train loss: 1.4754007679584902e-05 \n",
      "epoch: 31 [462176/888800 52.00%] train loss: 1.5043528946989682e-05 \n",
      "epoch: 31 [463287/888800 52.12%] train loss: 1.3963260244054254e-05 \n",
      "epoch: 31 [464398/888800 52.25%] train loss: 1.5703872122685425e-05 \n",
      "epoch: 31 [465509/888800 52.38%] train loss: 1.4727555026183836e-05 \n",
      "epoch: 31 [466620/888800 52.50%] train loss: 1.4685849237139337e-05 \n",
      "epoch: 31 [467731/888800 52.62%] train loss: 1.653550316405017e-05 \n",
      "epoch: 31 [468842/888800 52.75%] train loss: 1.419478121533757e-05 \n",
      "epoch: 31 [469953/888800 52.88%] train loss: 1.4992539945524186e-05 \n",
      "epoch: 31 [471064/888800 53.00%] train loss: 1.360532405669801e-05 \n",
      "epoch: 31 [472175/888800 53.12%] train loss: 1.5564733985229395e-05 \n",
      "epoch: 31 [473286/888800 53.25%] train loss: 1.4208252650860231e-05 \n",
      "epoch: 31 [474397/888800 53.38%] train loss: 1.4909787751093972e-05 \n",
      "epoch: 31 [475508/888800 53.50%] train loss: 1.3028973626205698e-05 \n",
      "epoch: 31 [476619/888800 53.62%] train loss: 1.7311333067482337e-05 \n",
      "epoch: 31 [477730/888800 53.75%] train loss: 1.607617741683498e-05 \n",
      "epoch: 31 [478841/888800 53.88%] train loss: 1.3812567885906901e-05 \n",
      "epoch: 31 [479952/888800 54.00%] train loss: 1.5711295418441296e-05 \n",
      "epoch: 31 [481063/888800 54.12%] train loss: 1.5097180039447267e-05 \n",
      "epoch: 31 [482174/888800 54.25%] train loss: 1.703544876363594e-05 \n",
      "epoch: 31 [483285/888800 54.38%] train loss: 1.4914573512214702e-05 \n",
      "epoch: 31 [484396/888800 54.50%] train loss: 1.601494659553282e-05 \n",
      "epoch: 31 [485507/888800 54.62%] train loss: 1.5108460502233356e-05 \n",
      "epoch: 31 [486618/888800 54.75%] train loss: 1.539406002848409e-05 \n",
      "epoch: 31 [487729/888800 54.88%] train loss: 1.4644364455307368e-05 \n",
      "epoch: 31 [488840/888800 55.00%] train loss: 1.3261695130495355e-05 \n",
      "epoch: 31 [489951/888800 55.12%] train loss: 1.5489853467443027e-05 \n",
      "epoch: 31 [491062/888800 55.25%] train loss: 1.4664389709651005e-05 \n",
      "epoch: 31 [492173/888800 55.38%] train loss: 1.3784555449092295e-05 \n",
      "epoch: 31 [493284/888800 55.50%] train loss: 1.4093518075242173e-05 \n",
      "epoch: 31 [494395/888800 55.62%] train loss: 1.5406092643388547e-05 \n",
      "epoch: 31 [495506/888800 55.75%] train loss: 1.3926704014011193e-05 \n",
      "epoch: 31 [496617/888800 55.88%] train loss: 1.6340991351171397e-05 \n",
      "epoch: 31 [497728/888800 56.00%] train loss: 1.3831380783813074e-05 \n",
      "epoch: 31 [498839/888800 56.12%] train loss: 1.4450197340920568e-05 \n",
      "epoch: 31 [499950/888800 56.25%] train loss: 1.2951360986335203e-05 \n",
      "epoch: 31 [501061/888800 56.38%] train loss: 1.604143835720606e-05 \n",
      "epoch: 31 [502172/888800 56.50%] train loss: 1.5306095519918017e-05 \n",
      "epoch: 31 [503283/888800 56.62%] train loss: 1.5294717741198838e-05 \n",
      "epoch: 31 [504394/888800 56.75%] train loss: 1.657833308854606e-05 \n",
      "epoch: 31 [505505/888800 56.88%] train loss: 1.4286270925367717e-05 \n",
      "epoch: 31 [506616/888800 57.00%] train loss: 1.5032549526949879e-05 \n",
      "epoch: 31 [507727/888800 57.12%] train loss: 1.5839010302443057e-05 \n",
      "epoch: 31 [508838/888800 57.25%] train loss: 1.62571195687633e-05 \n",
      "epoch: 31 [509949/888800 57.38%] train loss: 1.314694236498326e-05 \n",
      "epoch: 31 [511060/888800 57.50%] train loss: 1.4875598935759626e-05 \n",
      "epoch: 31 [512171/888800 57.62%] train loss: 1.378862634737743e-05 \n",
      "epoch: 31 [513282/888800 57.75%] train loss: 1.439514926460106e-05 \n",
      "epoch: 31 [514393/888800 57.88%] train loss: 1.4396610822586808e-05 \n",
      "epoch: 31 [515504/888800 58.00%] train loss: 1.5052060916787013e-05 \n",
      "epoch: 31 [516615/888800 58.12%] train loss: 1.4108995856076945e-05 \n",
      "epoch: 31 [517726/888800 58.25%] train loss: 1.4424663277168293e-05 \n",
      "epoch: 31 [518837/888800 58.38%] train loss: 1.4415016266866587e-05 \n",
      "epoch: 31 [519948/888800 58.50%] train loss: 1.6314350432367064e-05 \n",
      "epoch: 31 [521059/888800 58.62%] train loss: 1.5081453966558911e-05 \n",
      "epoch: 31 [522170/888800 58.75%] train loss: 1.4523889149131719e-05 \n",
      "epoch: 31 [523281/888800 58.88%] train loss: 1.4536582966684364e-05 \n",
      "epoch: 31 [524392/888800 59.00%] train loss: 1.540221092000138e-05 \n",
      "epoch: 31 [525503/888800 59.12%] train loss: 1.3767722521151882e-05 \n",
      "epoch: 31 [526614/888800 59.25%] train loss: 1.4429027032747399e-05 \n",
      "epoch: 31 [527725/888800 59.38%] train loss: 1.5223471564240754e-05 \n",
      "epoch: 31 [528836/888800 59.50%] train loss: 1.4899910638632718e-05 \n",
      "epoch: 31 [529947/888800 59.62%] train loss: 1.4122381799097639e-05 \n",
      "epoch: 31 [531058/888800 59.75%] train loss: 1.72345698956633e-05 \n",
      "epoch: 31 [532169/888800 59.88%] train loss: 1.5483046809094958e-05 \n",
      "epoch: 31 [533280/888800 60.00%] train loss: 1.3876468983653467e-05 \n",
      "epoch: 31 [534391/888800 60.12%] train loss: 1.5193697436188813e-05 \n",
      "epoch: 31 [535502/888800 60.25%] train loss: 1.3413682609098032e-05 \n",
      "epoch: 31 [536613/888800 60.38%] train loss: 1.5807900126674213e-05 \n",
      "epoch: 31 [537724/888800 60.50%] train loss: 1.4571609426639043e-05 \n",
      "epoch: 31 [538835/888800 60.62%] train loss: 1.4958506653783843e-05 \n",
      "epoch: 31 [539946/888800 60.75%] train loss: 1.4642849237134214e-05 \n",
      "epoch: 31 [541057/888800 60.88%] train loss: 1.6834235793794505e-05 \n",
      "epoch: 31 [542168/888800 61.00%] train loss: 1.442958182451548e-05 \n",
      "epoch: 31 [543279/888800 61.12%] train loss: 1.4518006537400652e-05 \n",
      "epoch: 31 [544390/888800 61.25%] train loss: 1.6070727724581957e-05 \n",
      "epoch: 31 [545501/888800 61.38%] train loss: 1.4812173503742088e-05 \n",
      "epoch: 31 [546612/888800 61.50%] train loss: 1.468720529373968e-05 \n",
      "epoch: 31 [547723/888800 61.62%] train loss: 1.4891336832079105e-05 \n",
      "epoch: 31 [548834/888800 61.75%] train loss: 1.4323130017146468e-05 \n",
      "epoch: 31 [549945/888800 61.88%] train loss: 1.3718708942178637e-05 \n",
      "epoch: 31 [551056/888800 62.00%] train loss: 1.4674395060865209e-05 \n",
      "epoch: 31 [552167/888800 62.12%] train loss: 1.402125690219691e-05 \n",
      "epoch: 31 [553278/888800 62.25%] train loss: 1.276235889235977e-05 \n",
      "epoch: 31 [554389/888800 62.38%] train loss: 1.4194409232004546e-05 \n",
      "epoch: 31 [555500/888800 62.50%] train loss: 1.3570998817158397e-05 \n",
      "epoch: 31 [556611/888800 62.62%] train loss: 1.4471480426436756e-05 \n",
      "epoch: 31 [557722/888800 62.75%] train loss: 1.3233393474365585e-05 \n",
      "epoch: 31 [558833/888800 62.88%] train loss: 1.4998676306277048e-05 \n",
      "epoch: 31 [559944/888800 63.00%] train loss: 1.4967750757932663e-05 \n",
      "epoch: 31 [561055/888800 63.12%] train loss: 1.3650714208779391e-05 \n",
      "epoch: 31 [562166/888800 63.25%] train loss: 1.476569286751328e-05 \n",
      "epoch: 31 [563277/888800 63.38%] train loss: 1.3592466530099045e-05 \n",
      "epoch: 31 [564388/888800 63.50%] train loss: 1.4830218788119964e-05 \n",
      "epoch: 31 [565499/888800 63.62%] train loss: 1.5187043572950643e-05 \n",
      "epoch: 31 [566610/888800 63.75%] train loss: 1.3048377695668023e-05 \n",
      "epoch: 31 [567721/888800 63.88%] train loss: 1.489984515501419e-05 \n",
      "epoch: 31 [568832/888800 64.00%] train loss: 1.4451920833380427e-05 \n",
      "epoch: 31 [569943/888800 64.12%] train loss: 1.4054721759748645e-05 \n",
      "epoch: 31 [571054/888800 64.25%] train loss: 1.3959166608401574e-05 \n",
      "epoch: 31 [572165/888800 64.38%] train loss: 1.4595419088436756e-05 \n",
      "epoch: 31 [573276/888800 64.50%] train loss: 1.4805281352892052e-05 \n",
      "epoch: 31 [574387/888800 64.62%] train loss: 1.3567011592385825e-05 \n",
      "epoch: 31 [575498/888800 64.75%] train loss: 1.3962297089165077e-05 \n",
      "epoch: 31 [576609/888800 64.88%] train loss: 1.4806225408392493e-05 \n",
      "epoch: 31 [577720/888800 65.00%] train loss: 1.3141281669959426e-05 \n",
      "epoch: 31 [578831/888800 65.12%] train loss: 1.3811845747113694e-05 \n",
      "epoch: 31 [579942/888800 65.25%] train loss: 1.3471124475472607e-05 \n",
      "epoch: 31 [581053/888800 65.38%] train loss: 1.656122913118452e-05 \n",
      "epoch: 31 [582164/888800 65.50%] train loss: 1.4624024515796918e-05 \n",
      "epoch: 31 [583275/888800 65.62%] train loss: 1.3689553270523902e-05 \n",
      "epoch: 31 [584386/888800 65.75%] train loss: 1.2895147847302724e-05 \n",
      "epoch: 31 [585497/888800 65.88%] train loss: 1.5281821106327698e-05 \n",
      "epoch: 31 [586608/888800 66.00%] train loss: 1.4342514077725355e-05 \n",
      "epoch: 31 [587719/888800 66.12%] train loss: 1.4389452189789154e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [588830/888800 66.25%] train loss: 1.339367008768022e-05 \n",
      "epoch: 31 [589941/888800 66.38%] train loss: 1.3783646863885224e-05 \n",
      "epoch: 31 [591052/888800 66.50%] train loss: 1.4874950466037262e-05 \n",
      "epoch: 31 [592163/888800 66.62%] train loss: 1.3427568774204701e-05 \n",
      "epoch: 31 [593274/888800 66.75%] train loss: 1.5543830159003846e-05 \n",
      "epoch: 31 [594385/888800 66.88%] train loss: 1.4645539522462059e-05 \n",
      "epoch: 31 [595496/888800 67.00%] train loss: 1.4499043572868686e-05 \n",
      "epoch: 31 [596607/888800 67.12%] train loss: 1.4117174032435287e-05 \n",
      "epoch: 31 [597718/888800 67.25%] train loss: 1.3635915820486844e-05 \n",
      "epoch: 31 [598829/888800 67.38%] train loss: 1.3714772649109364e-05 \n",
      "epoch: 31 [599940/888800 67.50%] train loss: 1.5732393876533024e-05 \n",
      "epoch: 31 [601051/888800 67.62%] train loss: 1.4489522072835825e-05 \n",
      "epoch: 31 [602162/888800 67.75%] train loss: 1.4275504327088129e-05 \n",
      "epoch: 31 [603273/888800 67.88%] train loss: 1.5411498679895885e-05 \n",
      "epoch: 31 [604384/888800 68.00%] train loss: 1.4103117791819386e-05 \n",
      "epoch: 31 [605495/888800 68.12%] train loss: 1.4915362044121139e-05 \n",
      "epoch: 31 [606606/888800 68.25%] train loss: 1.4097182429395616e-05 \n",
      "epoch: 31 [607717/888800 68.38%] train loss: 1.3443146599456668e-05 \n",
      "epoch: 31 [608828/888800 68.50%] train loss: 1.4299290342023596e-05 \n",
      "epoch: 31 [609939/888800 68.62%] train loss: 1.4854082110105082e-05 \n",
      "epoch: 31 [611050/888800 68.75%] train loss: 1.3904876141168643e-05 \n",
      "epoch: 31 [612161/888800 68.88%] train loss: 1.4090096556174103e-05 \n",
      "epoch: 31 [613272/888800 69.00%] train loss: 1.4052214282855857e-05 \n",
      "epoch: 31 [614383/888800 69.12%] train loss: 1.4677261788165197e-05 \n",
      "epoch: 31 [615494/888800 69.25%] train loss: 1.3731558283325285e-05 \n",
      "epoch: 31 [616605/888800 69.38%] train loss: 1.3669574400410056e-05 \n",
      "epoch: 31 [617716/888800 69.50%] train loss: 1.4282615666161291e-05 \n",
      "epoch: 31 [618827/888800 69.62%] train loss: 1.4275507055572234e-05 \n",
      "epoch: 31 [619938/888800 69.75%] train loss: 1.484458516642917e-05 \n",
      "epoch: 31 [621049/888800 69.88%] train loss: 1.309546860284172e-05 \n",
      "epoch: 31 [622160/888800 70.00%] train loss: 1.5700003132224083e-05 \n",
      "epoch: 31 [623271/888800 70.12%] train loss: 1.3486220268532634e-05 \n",
      "epoch: 31 [624382/888800 70.25%] train loss: 1.4496396033791825e-05 \n",
      "epoch: 31 [625493/888800 70.38%] train loss: 1.3678778486791998e-05 \n",
      "epoch: 31 [626604/888800 70.50%] train loss: 1.3291859431774355e-05 \n",
      "epoch: 31 [627715/888800 70.62%] train loss: 1.4942652342142537e-05 \n",
      "epoch: 31 [628826/888800 70.75%] train loss: 1.5312885807361454e-05 \n",
      "epoch: 31 [629937/888800 70.88%] train loss: 1.4908203411323484e-05 \n",
      "epoch: 31 [631048/888800 71.00%] train loss: 1.5659154087188654e-05 \n",
      "epoch: 31 [632159/888800 71.12%] train loss: 1.3955442227597814e-05 \n",
      "epoch: 31 [633270/888800 71.25%] train loss: 1.4928457858331967e-05 \n",
      "epoch: 31 [634381/888800 71.38%] train loss: 1.3998719623486977e-05 \n",
      "epoch: 31 [635492/888800 71.50%] train loss: 1.3917464457335882e-05 \n",
      "epoch: 31 [636603/888800 71.62%] train loss: 1.4409772120416164e-05 \n",
      "epoch: 31 [637714/888800 71.75%] train loss: 1.3220128494140226e-05 \n",
      "epoch: 31 [638825/888800 71.88%] train loss: 1.4417581041925587e-05 \n",
      "epoch: 31 [639936/888800 72.00%] train loss: 1.5652172805857845e-05 \n",
      "epoch: 31 [641047/888800 72.12%] train loss: 1.328932285105111e-05 \n",
      "epoch: 31 [642158/888800 72.25%] train loss: 1.3775383195024915e-05 \n",
      "epoch: 31 [643269/888800 72.38%] train loss: 1.3779091204924043e-05 \n",
      "epoch: 31 [644380/888800 72.50%] train loss: 1.367359345749719e-05 \n",
      "epoch: 31 [645491/888800 72.62%] train loss: 1.3809579286316875e-05 \n",
      "epoch: 31 [646602/888800 72.75%] train loss: 1.3512044461094774e-05 \n",
      "epoch: 31 [647713/888800 72.88%] train loss: 1.4657422070740722e-05 \n",
      "epoch: 31 [648824/888800 73.00%] train loss: 1.4995940546214115e-05 \n",
      "epoch: 31 [649935/888800 73.12%] train loss: 1.358719055133406e-05 \n",
      "epoch: 31 [651046/888800 73.25%] train loss: 1.6244948710664175e-05 \n",
      "epoch: 31 [652157/888800 73.38%] train loss: 1.55833586177323e-05 \n",
      "epoch: 31 [653268/888800 73.50%] train loss: 1.4955723599996418e-05 \n",
      "epoch: 31 [654379/888800 73.62%] train loss: 1.3581243365479168e-05 \n",
      "epoch: 31 [655490/888800 73.75%] train loss: 1.38988007165608e-05 \n",
      "epoch: 31 [656601/888800 73.88%] train loss: 1.3920984201831743e-05 \n",
      "epoch: 31 [657712/888800 74.00%] train loss: 1.4000956070958637e-05 \n",
      "epoch: 31 [658823/888800 74.12%] train loss: 1.3528154340747278e-05 \n",
      "epoch: 31 [659934/888800 74.25%] train loss: 1.314336623181589e-05 \n",
      "epoch: 31 [661045/888800 74.38%] train loss: 1.3565171684604138e-05 \n",
      "epoch: 31 [662156/888800 74.50%] train loss: 1.2795482689398341e-05 \n",
      "epoch: 31 [663267/888800 74.62%] train loss: 1.5099420124897733e-05 \n",
      "epoch: 31 [664378/888800 74.75%] train loss: 1.4138599908619653e-05 \n",
      "epoch: 31 [665489/888800 74.88%] train loss: 1.374729436065536e-05 \n",
      "epoch: 31 [666600/888800 75.00%] train loss: 1.3146589481038973e-05 \n",
      "epoch: 31 [667711/888800 75.12%] train loss: 1.475878252676921e-05 \n",
      "epoch: 31 [668822/888800 75.25%] train loss: 1.3672007298737299e-05 \n",
      "epoch: 31 [669933/888800 75.38%] train loss: 1.4266841390053742e-05 \n",
      "epoch: 31 [671044/888800 75.50%] train loss: 1.3989417311677244e-05 \n",
      "epoch: 31 [672155/888800 75.62%] train loss: 1.4365460629051086e-05 \n",
      "epoch: 31 [673266/888800 75.75%] train loss: 1.4482592632703017e-05 \n",
      "epoch: 31 [674377/888800 75.88%] train loss: 1.4085099792282563e-05 \n",
      "epoch: 31 [675488/888800 76.00%] train loss: 1.3155896340322215e-05 \n",
      "epoch: 31 [676599/888800 76.12%] train loss: 1.4992692740634084e-05 \n",
      "epoch: 31 [677710/888800 76.25%] train loss: 1.5958474250510335e-05 \n",
      "epoch: 31 [678821/888800 76.38%] train loss: 1.446577334718313e-05 \n",
      "epoch: 31 [679932/888800 76.50%] train loss: 1.4825011021457613e-05 \n",
      "epoch: 31 [681043/888800 76.62%] train loss: 1.4761525562789757e-05 \n",
      "epoch: 31 [682154/888800 76.75%] train loss: 1.4426665075006895e-05 \n",
      "epoch: 31 [683265/888800 76.88%] train loss: 1.3436277185974177e-05 \n",
      "epoch: 31 [684376/888800 77.00%] train loss: 1.4064276911085472e-05 \n",
      "epoch: 31 [685487/888800 77.12%] train loss: 1.4485812243947294e-05 \n",
      "epoch: 31 [686598/888800 77.25%] train loss: 1.4964685760787688e-05 \n",
      "epoch: 31 [687709/888800 77.38%] train loss: 1.4578141417587176e-05 \n",
      "epoch: 31 [688820/888800 77.50%] train loss: 1.4706058209412731e-05 \n",
      "epoch: 31 [689931/888800 77.62%] train loss: 1.4892004401190206e-05 \n",
      "epoch: 31 [691042/888800 77.75%] train loss: 1.3405408935796004e-05 \n",
      "epoch: 31 [692153/888800 77.88%] train loss: 1.3394508641795255e-05 \n",
      "epoch: 31 [693264/888800 78.00%] train loss: 1.4140494386083446e-05 \n",
      "epoch: 31 [694375/888800 78.12%] train loss: 1.529867950011976e-05 \n",
      "epoch: 31 [695486/888800 78.25%] train loss: 1.4635113075200934e-05 \n",
      "epoch: 31 [696597/888800 78.38%] train loss: 1.4367082258104347e-05 \n",
      "epoch: 31 [697708/888800 78.50%] train loss: 1.3453884093905799e-05 \n",
      "epoch: 31 [698819/888800 78.62%] train loss: 1.461374540667748e-05 \n",
      "epoch: 31 [699930/888800 78.75%] train loss: 1.4593601918022614e-05 \n",
      "epoch: 31 [701041/888800 78.88%] train loss: 1.4655543964181561e-05 \n",
      "epoch: 31 [702152/888800 79.00%] train loss: 1.5235133105306886e-05 \n",
      "epoch: 31 [703263/888800 79.12%] train loss: 1.506392436567694e-05 \n",
      "epoch: 31 [704374/888800 79.25%] train loss: 1.4545696103596129e-05 \n",
      "epoch: 31 [705485/888800 79.38%] train loss: 1.4086543160374276e-05 \n",
      "epoch: 31 [706596/888800 79.50%] train loss: 1.4427910173253622e-05 \n",
      "epoch: 31 [707707/888800 79.62%] train loss: 1.2887986486020964e-05 \n",
      "epoch: 31 [708818/888800 79.75%] train loss: 1.4612814084102865e-05 \n",
      "epoch: 31 [709929/888800 79.88%] train loss: 1.3089941603539046e-05 \n",
      "epoch: 31 [711040/888800 80.00%] train loss: 1.3824348570778966e-05 \n",
      "epoch: 31 [712151/888800 80.12%] train loss: 1.421266370016383e-05 \n",
      "epoch: 31 [713262/888800 80.25%] train loss: 1.4501665646093898e-05 \n",
      "epoch: 31 [714373/888800 80.38%] train loss: 1.3922679499955848e-05 \n",
      "epoch: 31 [715484/888800 80.50%] train loss: 1.367030472465558e-05 \n",
      "epoch: 31 [716595/888800 80.62%] train loss: 1.3169449630368035e-05 \n",
      "epoch: 31 [717706/888800 80.75%] train loss: 1.5356294170487672e-05 \n",
      "epoch: 31 [718817/888800 80.88%] train loss: 1.462316322431434e-05 \n",
      "epoch: 31 [719928/888800 81.00%] train loss: 1.4099704458203632e-05 \n",
      "epoch: 31 [721039/888800 81.12%] train loss: 1.4264261153584812e-05 \n",
      "epoch: 31 [722150/888800 81.25%] train loss: 1.436947422917001e-05 \n",
      "epoch: 31 [723261/888800 81.38%] train loss: 1.4937302694306709e-05 \n",
      "epoch: 31 [724372/888800 81.50%] train loss: 1.5036193872219883e-05 \n",
      "epoch: 31 [725483/888800 81.62%] train loss: 1.5128803170227911e-05 \n",
      "epoch: 31 [726594/888800 81.75%] train loss: 1.4620704860135447e-05 \n",
      "epoch: 31 [727705/888800 81.88%] train loss: 1.4384524547494948e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [728816/888800 82.00%] train loss: 1.3254352779767942e-05 \n",
      "epoch: 31 [729927/888800 82.12%] train loss: 1.5739131413283758e-05 \n",
      "epoch: 31 [731038/888800 82.25%] train loss: 1.3666193808603566e-05 \n",
      "epoch: 31 [732149/888800 82.38%] train loss: 1.5800462279003114e-05 \n",
      "epoch: 31 [733260/888800 82.50%] train loss: 1.4663491128885653e-05 \n",
      "epoch: 31 [734371/888800 82.62%] train loss: 1.311467985942727e-05 \n",
      "epoch: 31 [735482/888800 82.75%] train loss: 1.5003749467723537e-05 \n",
      "epoch: 31 [736593/888800 82.88%] train loss: 1.3687302271137014e-05 \n",
      "epoch: 31 [737704/888800 83.00%] train loss: 1.2937846804561559e-05 \n",
      "epoch: 31 [738815/888800 83.12%] train loss: 1.4170524991641287e-05 \n",
      "epoch: 31 [739926/888800 83.25%] train loss: 1.4188046407070942e-05 \n",
      "epoch: 31 [741037/888800 83.38%] train loss: 1.3728020348935388e-05 \n",
      "epoch: 31 [742148/888800 83.50%] train loss: 1.4137192010821309e-05 \n",
      "epoch: 31 [743259/888800 83.62%] train loss: 1.447187787562143e-05 \n",
      "epoch: 31 [744370/888800 83.75%] train loss: 1.3837815458828118e-05 \n",
      "epoch: 31 [745481/888800 83.88%] train loss: 1.407291983923642e-05 \n",
      "epoch: 31 [746592/888800 84.00%] train loss: 1.3991992091177963e-05 \n",
      "epoch: 31 [747703/888800 84.12%] train loss: 1.4691767319163773e-05 \n",
      "epoch: 31 [748814/888800 84.25%] train loss: 1.4747177374374587e-05 \n",
      "epoch: 31 [749925/888800 84.38%] train loss: 1.4929307326383423e-05 \n",
      "epoch: 31 [751036/888800 84.50%] train loss: 1.3177987057133578e-05 \n",
      "epoch: 31 [752147/888800 84.62%] train loss: 1.6179248632397503e-05 \n",
      "epoch: 31 [753258/888800 84.75%] train loss: 1.610165782039985e-05 \n",
      "epoch: 31 [754369/888800 84.88%] train loss: 1.3741282600676641e-05 \n",
      "epoch: 31 [755480/888800 85.00%] train loss: 1.4607180673920084e-05 \n",
      "epoch: 31 [756591/888800 85.12%] train loss: 1.426567632734077e-05 \n",
      "epoch: 31 [757702/888800 85.25%] train loss: 1.4275850844569504e-05 \n",
      "epoch: 31 [758813/888800 85.38%] train loss: 1.3681710697710514e-05 \n",
      "epoch: 31 [759924/888800 85.50%] train loss: 1.5177540262811817e-05 \n",
      "epoch: 31 [761035/888800 85.62%] train loss: 1.4295768778538331e-05 \n",
      "epoch: 31 [762146/888800 85.75%] train loss: 1.4032472790859174e-05 \n",
      "epoch: 31 [763257/888800 85.88%] train loss: 1.5709818399045616e-05 \n",
      "epoch: 31 [764368/888800 86.00%] train loss: 1.429736312275054e-05 \n",
      "epoch: 31 [765479/888800 86.12%] train loss: 1.4816559996688738e-05 \n",
      "epoch: 31 [766590/888800 86.25%] train loss: 1.4287285011960194e-05 \n",
      "epoch: 31 [767701/888800 86.38%] train loss: 1.5006579815235455e-05 \n",
      "epoch: 31 [768812/888800 86.50%] train loss: 1.348309433524264e-05 \n",
      "epoch: 31 [769923/888800 86.62%] train loss: 1.461636657040799e-05 \n",
      "epoch: 31 [771034/888800 86.75%] train loss: 1.3552276868722402e-05 \n",
      "epoch: 31 [772145/888800 86.88%] train loss: 1.547964166093152e-05 \n",
      "epoch: 31 [773256/888800 87.00%] train loss: 1.4511120753013529e-05 \n",
      "epoch: 31 [774367/888800 87.12%] train loss: 1.4596601431549061e-05 \n",
      "epoch: 31 [775478/888800 87.25%] train loss: 1.4983838809712324e-05 \n",
      "epoch: 31 [776589/888800 87.38%] train loss: 1.5049130524857901e-05 \n",
      "epoch: 31 [777700/888800 87.50%] train loss: 1.4587240002583712e-05 \n",
      "epoch: 31 [778811/888800 87.62%] train loss: 1.4941423614800442e-05 \n",
      "epoch: 31 [779922/888800 87.75%] train loss: 1.3652994311996736e-05 \n",
      "epoch: 31 [781033/888800 87.88%] train loss: 1.4180875950842164e-05 \n",
      "epoch: 31 [782144/888800 88.00%] train loss: 1.2825777048419695e-05 \n",
      "epoch: 31 [783255/888800 88.12%] train loss: 1.4132700925983954e-05 \n",
      "epoch: 31 [784366/888800 88.25%] train loss: 1.3723933989240322e-05 \n",
      "epoch: 31 [785477/888800 88.38%] train loss: 1.513971892563859e-05 \n",
      "epoch: 31 [786588/888800 88.50%] train loss: 1.4438021935347933e-05 \n",
      "epoch: 31 [787699/888800 88.62%] train loss: 1.5092378816916607e-05 \n",
      "epoch: 31 [788810/888800 88.75%] train loss: 1.3129219951224513e-05 \n",
      "epoch: 31 [789921/888800 88.88%] train loss: 1.4859190741844941e-05 \n",
      "epoch: 31 [791032/888800 89.00%] train loss: 1.6034397049224935e-05 \n",
      "epoch: 31 [792143/888800 89.12%] train loss: 1.3606695574708283e-05 \n",
      "epoch: 31 [793254/888800 89.25%] train loss: 1.3039231816946995e-05 \n",
      "epoch: 31 [794365/888800 89.38%] train loss: 1.3984397810418159e-05 \n",
      "epoch: 31 [795476/888800 89.50%] train loss: 1.4658937288913876e-05 \n",
      "epoch: 31 [796587/888800 89.62%] train loss: 1.4911324797139969e-05 \n",
      "epoch: 31 [797698/888800 89.75%] train loss: 1.3874497199140023e-05 \n",
      "epoch: 31 [798809/888800 89.88%] train loss: 1.395007438986795e-05 \n",
      "epoch: 31 [799920/888800 90.00%] train loss: 1.4639078472100664e-05 \n",
      "epoch: 31 [801031/888800 90.12%] train loss: 1.4461174941970967e-05 \n",
      "epoch: 31 [802142/888800 90.25%] train loss: 1.552520006953273e-05 \n",
      "epoch: 31 [803253/888800 90.38%] train loss: 1.4428698705160059e-05 \n",
      "epoch: 31 [804364/888800 90.50%] train loss: 1.3950742868473753e-05 \n",
      "epoch: 31 [805475/888800 90.62%] train loss: 1.4138448023004457e-05 \n",
      "epoch: 31 [806586/888800 90.75%] train loss: 1.4701847248943523e-05 \n",
      "epoch: 31 [807697/888800 90.88%] train loss: 1.4454535630648024e-05 \n",
      "epoch: 31 [808808/888800 91.00%] train loss: 1.5075525880092755e-05 \n",
      "epoch: 31 [809919/888800 91.12%] train loss: 1.3467595636029728e-05 \n",
      "epoch: 31 [811030/888800 91.25%] train loss: 1.3468257748172618e-05 \n",
      "epoch: 31 [812141/888800 91.38%] train loss: 1.4265994650486391e-05 \n",
      "epoch: 31 [813252/888800 91.50%] train loss: 1.4609852769353893e-05 \n",
      "epoch: 31 [814363/888800 91.62%] train loss: 1.5130610336200334e-05 \n",
      "epoch: 31 [815474/888800 91.75%] train loss: 1.4702108273922931e-05 \n",
      "epoch: 31 [816585/888800 91.88%] train loss: 1.4577378351532388e-05 \n",
      "epoch: 31 [817696/888800 92.00%] train loss: 1.2854348824475892e-05 \n",
      "epoch: 31 [818807/888800 92.12%] train loss: 1.4491752153844573e-05 \n",
      "epoch: 31 [819918/888800 92.25%] train loss: 1.388535565638449e-05 \n",
      "epoch: 31 [821029/888800 92.38%] train loss: 1.381762558594346e-05 \n",
      "epoch: 31 [822140/888800 92.50%] train loss: 1.2923836948175449e-05 \n",
      "epoch: 31 [823251/888800 92.62%] train loss: 1.282169068872463e-05 \n",
      "epoch: 31 [824362/888800 92.75%] train loss: 1.3725089957006276e-05 \n",
      "epoch: 31 [825473/888800 92.88%] train loss: 1.4285386896517593e-05 \n",
      "epoch: 31 [826584/888800 93.00%] train loss: 1.397889445797773e-05 \n",
      "epoch: 31 [827695/888800 93.12%] train loss: 1.4119192201178521e-05 \n",
      "epoch: 31 [828806/888800 93.25%] train loss: 1.3438341738947202e-05 \n",
      "epoch: 31 [829917/888800 93.38%] train loss: 1.4364094568009023e-05 \n",
      "epoch: 31 [831028/888800 93.50%] train loss: 1.3763965398538858e-05 \n",
      "epoch: 31 [832139/888800 93.62%] train loss: 1.512625840405235e-05 \n",
      "epoch: 31 [833250/888800 93.75%] train loss: 1.3909530935052317e-05 \n",
      "epoch: 31 [834361/888800 93.88%] train loss: 1.4652120626124088e-05 \n",
      "epoch: 31 [835472/888800 94.00%] train loss: 1.3613815099233761e-05 \n",
      "epoch: 31 [836583/888800 94.12%] train loss: 1.3770299119642004e-05 \n",
      "epoch: 31 [837694/888800 94.25%] train loss: 1.4765453670406714e-05 \n",
      "epoch: 31 [838805/888800 94.38%] train loss: 1.617967791389674e-05 \n",
      "epoch: 31 [839916/888800 94.50%] train loss: 1.434914429410128e-05 \n",
      "epoch: 31 [841027/888800 94.62%] train loss: 1.3780858353129588e-05 \n",
      "epoch: 31 [842138/888800 94.75%] train loss: 1.5292029274860397e-05 \n",
      "epoch: 31 [843249/888800 94.88%] train loss: 1.4520541299134493e-05 \n",
      "epoch: 31 [844360/888800 95.00%] train loss: 1.2824657460441813e-05 \n",
      "epoch: 31 [845471/888800 95.12%] train loss: 1.3859329555998556e-05 \n",
      "epoch: 31 [846582/888800 95.25%] train loss: 1.4329433724924456e-05 \n",
      "epoch: 31 [847693/888800 95.38%] train loss: 1.4541853488481138e-05 \n",
      "epoch: 31 [848804/888800 95.50%] train loss: 1.3828253941028379e-05 \n",
      "epoch: 31 [849915/888800 95.62%] train loss: 1.4540801203111187e-05 \n",
      "epoch: 31 [851026/888800 95.75%] train loss: 1.3795903214486316e-05 \n",
      "epoch: 31 [852137/888800 95.88%] train loss: 1.3905979358241893e-05 \n",
      "epoch: 31 [853248/888800 96.00%] train loss: 1.4490496141661424e-05 \n",
      "epoch: 31 [854359/888800 96.12%] train loss: 1.540418088552542e-05 \n",
      "epoch: 31 [855470/888800 96.25%] train loss: 1.4553744222212117e-05 \n",
      "epoch: 31 [856581/888800 96.38%] train loss: 1.4139482118480373e-05 \n",
      "epoch: 31 [857692/888800 96.50%] train loss: 1.4817582268733531e-05 \n",
      "epoch: 31 [858803/888800 96.62%] train loss: 1.3825236237607896e-05 \n",
      "epoch: 31 [859914/888800 96.75%] train loss: 1.4703883607580792e-05 \n",
      "epoch: 31 [861025/888800 96.88%] train loss: 1.4632229976996314e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 [862136/888800 97.00%] train loss: 1.3768554708804004e-05 \n",
      "epoch: 31 [863247/888800 97.12%] train loss: 1.3065110579191241e-05 \n",
      "epoch: 31 [864358/888800 97.25%] train loss: 1.5263627574313432e-05 \n",
      "epoch: 31 [865469/888800 97.38%] train loss: 1.3823400877299719e-05 \n",
      "epoch: 31 [866580/888800 97.50%] train loss: 1.4383379493665416e-05 \n",
      "epoch: 31 [867691/888800 97.62%] train loss: 1.3361194760364015e-05 \n",
      "epoch: 31 [868802/888800 97.75%] train loss: 1.4030600141268224e-05 \n",
      "epoch: 31 [869913/888800 97.88%] train loss: 1.3561580090026837e-05 \n",
      "epoch: 31 [871024/888800 98.00%] train loss: 1.379689001623774e-05 \n",
      "epoch: 31 [872135/888800 98.12%] train loss: 1.5182741663011257e-05 \n",
      "epoch: 31 [873246/888800 98.25%] train loss: 1.4829726751486305e-05 \n",
      "epoch: 31 [874357/888800 98.38%] train loss: 1.4618693057855126e-05 \n",
      "epoch: 31 [875468/888800 98.50%] train loss: 1.4648218893853482e-05 \n",
      "epoch: 31 [876579/888800 98.62%] train loss: 1.4982614629843738e-05 \n",
      "epoch: 31 [877690/888800 98.75%] train loss: 1.5230019926093519e-05 \n",
      "epoch: 31 [878801/888800 98.88%] train loss: 1.4292547348304652e-05 \n",
      "epoch: 31 [879912/888800 99.00%] train loss: 1.457513189961901e-05 \n",
      "epoch: 31 [881023/888800 99.12%] train loss: 1.4218903743312694e-05 \n",
      "epoch: 31 [882134/888800 99.25%] train loss: 1.56040314323036e-05 \n",
      "epoch: 31 [883245/888800 99.38%] train loss: 1.4955123333493248e-05 \n",
      "epoch: 31 [884356/888800 99.50%] train loss: 1.582298136781901e-05 \n",
      "epoch: 31 [885467/888800 99.62%] train loss: 1.4525002370646689e-05 \n",
      "epoch: 31 [886578/888800 99.75%] train loss: 1.4501226360152941e-05 \n",
      "epoch: 31 [887689/888800 99.88%] train loss: 1.4094661310082301e-05 \n",
      "epoch: 32 [0/888800 0.00%] train loss: 1.6945645256782882e-05 \n",
      "epoch: 32 [1111/888800 0.12%] train loss: 1.4646041563537437e-05 \n",
      "epoch: 32 [2222/888800 0.25%] train loss: 1.4948026546335313e-05 \n",
      "epoch: 32 [3333/888800 0.38%] train loss: 1.502169561717892e-05 \n",
      "epoch: 32 [4444/888800 0.50%] train loss: 1.4194663890521042e-05 \n",
      "epoch: 32 [5555/888800 0.62%] train loss: 1.577402144903317e-05 \n",
      "epoch: 32 [6666/888800 0.75%] train loss: 1.3413442502496764e-05 \n",
      "epoch: 32 [7777/888800 0.88%] train loss: 1.4023408766661305e-05 \n",
      "epoch: 32 [8888/888800 1.00%] train loss: 1.38460145535646e-05 \n",
      "epoch: 32 [9999/888800 1.12%] train loss: 1.4620344700233545e-05 \n",
      "epoch: 32 [11110/888800 1.25%] train loss: 1.375247575197136e-05 \n",
      "epoch: 32 [12221/888800 1.38%] train loss: 1.5912572052911855e-05 \n",
      "epoch: 32 [13332/888800 1.50%] train loss: 1.475301178288646e-05 \n",
      "epoch: 32 [14443/888800 1.62%] train loss: 1.3165094060241245e-05 \n",
      "epoch: 32 [15554/888800 1.75%] train loss: 1.2968602277396712e-05 \n",
      "epoch: 32 [16665/888800 1.88%] train loss: 1.3632096852234099e-05 \n",
      "epoch: 32 [17776/888800 2.00%] train loss: 1.4503095371765085e-05 \n",
      "epoch: 32 [18887/888800 2.12%] train loss: 1.4621690752392169e-05 \n",
      "epoch: 32 [19998/888800 2.25%] train loss: 1.5299421647796407e-05 \n",
      "epoch: 32 [21109/888800 2.38%] train loss: 1.5311219613067806e-05 \n",
      "epoch: 32 [22220/888800 2.50%] train loss: 1.4882603863952681e-05 \n",
      "epoch: 32 [23331/888800 2.62%] train loss: 1.3082118130114395e-05 \n",
      "epoch: 32 [24442/888800 2.75%] train loss: 1.615849760128185e-05 \n",
      "epoch: 32 [25553/888800 2.88%] train loss: 1.396639254380716e-05 \n",
      "epoch: 32 [26664/888800 3.00%] train loss: 1.3840637620887719e-05 \n",
      "epoch: 32 [27775/888800 3.12%] train loss: 1.4879537047818303e-05 \n",
      "epoch: 32 [28886/888800 3.25%] train loss: 1.4740851838723756e-05 \n",
      "epoch: 32 [29997/888800 3.38%] train loss: 1.4754118637938518e-05 \n",
      "epoch: 32 [31108/888800 3.50%] train loss: 1.4332920727611054e-05 \n",
      "epoch: 32 [32219/888800 3.62%] train loss: 1.4868170183035545e-05 \n",
      "epoch: 32 [33330/888800 3.75%] train loss: 1.3700571798835881e-05 \n",
      "epoch: 32 [34441/888800 3.88%] train loss: 1.506425269326428e-05 \n",
      "epoch: 32 [35552/888800 4.00%] train loss: 1.4251158972911071e-05 \n",
      "epoch: 32 [36663/888800 4.12%] train loss: 1.484722179156961e-05 \n",
      "epoch: 32 [37774/888800 4.25%] train loss: 1.551334025862161e-05 \n",
      "epoch: 32 [38885/888800 4.38%] train loss: 1.3350468179851305e-05 \n",
      "epoch: 32 [39996/888800 4.50%] train loss: 1.460003295505885e-05 \n",
      "epoch: 32 [41107/888800 4.62%] train loss: 1.445738598704338e-05 \n",
      "epoch: 32 [42218/888800 4.75%] train loss: 1.4823111087025609e-05 \n",
      "epoch: 32 [43329/888800 4.88%] train loss: 1.4064711649552919e-05 \n",
      "epoch: 32 [44440/888800 5.00%] train loss: 1.2814834917662665e-05 \n",
      "epoch: 32 [45551/888800 5.12%] train loss: 1.4036218999535777e-05 \n",
      "epoch: 32 [46662/888800 5.25%] train loss: 1.5487776181544177e-05 \n",
      "epoch: 32 [47773/888800 5.38%] train loss: 1.459366103517823e-05 \n",
      "epoch: 32 [48884/888800 5.50%] train loss: 1.4841514712315984e-05 \n",
      "epoch: 32 [49995/888800 5.62%] train loss: 1.4412536984309554e-05 \n",
      "epoch: 32 [51106/888800 5.75%] train loss: 1.632725434319582e-05 \n",
      "epoch: 32 [52217/888800 5.88%] train loss: 1.2881611837656237e-05 \n",
      "epoch: 32 [53328/888800 6.00%] train loss: 1.5434747183462605e-05 \n",
      "epoch: 32 [54439/888800 6.12%] train loss: 1.3691628737433348e-05 \n",
      "epoch: 32 [55550/888800 6.25%] train loss: 1.5425912351929583e-05 \n",
      "epoch: 32 [56661/888800 6.38%] train loss: 1.3498985026672017e-05 \n",
      "epoch: 32 [57772/888800 6.50%] train loss: 1.539087315904908e-05 \n",
      "epoch: 32 [58883/888800 6.62%] train loss: 1.4787005056859925e-05 \n",
      "epoch: 32 [59994/888800 6.75%] train loss: 1.4322625247586984e-05 \n",
      "epoch: 32 [61105/888800 6.88%] train loss: 1.5322340914281085e-05 \n",
      "epoch: 32 [62216/888800 7.00%] train loss: 1.4496694348054007e-05 \n",
      "epoch: 32 [63327/888800 7.12%] train loss: 1.4312290659290738e-05 \n",
      "epoch: 32 [64438/888800 7.25%] train loss: 1.3506097275239881e-05 \n",
      "epoch: 32 [65549/888800 7.38%] train loss: 1.4285998986451887e-05 \n",
      "epoch: 32 [66660/888800 7.50%] train loss: 1.4564228877134155e-05 \n",
      "epoch: 32 [67771/888800 7.62%] train loss: 1.3539721294364426e-05 \n",
      "epoch: 32 [68882/888800 7.75%] train loss: 1.3901216334488709e-05 \n",
      "epoch: 32 [69993/888800 7.88%] train loss: 1.5341833204729483e-05 \n",
      "epoch: 32 [71104/888800 8.00%] train loss: 1.451944172004005e-05 \n",
      "epoch: 32 [72215/888800 8.12%] train loss: 1.325851735600736e-05 \n",
      "epoch: 32 [73326/888800 8.25%] train loss: 1.3889032743463758e-05 \n",
      "epoch: 32 [74437/888800 8.38%] train loss: 1.431208602298284e-05 \n",
      "epoch: 32 [75548/888800 8.50%] train loss: 1.3903118087910116e-05 \n",
      "epoch: 32 [76659/888800 8.62%] train loss: 1.4962633940740488e-05 \n",
      "epoch: 32 [77770/888800 8.75%] train loss: 1.392010562994983e-05 \n",
      "epoch: 32 [78881/888800 8.88%] train loss: 1.4066423318581656e-05 \n",
      "epoch: 32 [79992/888800 9.00%] train loss: 1.4515364455292001e-05 \n",
      "epoch: 32 [81103/888800 9.12%] train loss: 1.3002628293179441e-05 \n",
      "epoch: 32 [82214/888800 9.25%] train loss: 1.4368270967679564e-05 \n",
      "epoch: 32 [83325/888800 9.38%] train loss: 1.4672768884338439e-05 \n",
      "epoch: 32 [84436/888800 9.50%] train loss: 1.3934824892203324e-05 \n",
      "epoch: 32 [85547/888800 9.62%] train loss: 1.4430034752876963e-05 \n",
      "epoch: 32 [86658/888800 9.75%] train loss: 1.4336803360492922e-05 \n",
      "epoch: 32 [87769/888800 9.88%] train loss: 1.3978208698972594e-05 \n",
      "epoch: 32 [88880/888800 10.00%] train loss: 1.3036208656558301e-05 \n",
      "epoch: 32 [89991/888800 10.12%] train loss: 1.4814986570854671e-05 \n",
      "epoch: 32 [91102/888800 10.25%] train loss: 1.3476213098329026e-05 \n",
      "epoch: 32 [92213/888800 10.38%] train loss: 1.3327469787327573e-05 \n",
      "epoch: 32 [93324/888800 10.50%] train loss: 1.3248400136944838e-05 \n",
      "epoch: 32 [94435/888800 10.62%] train loss: 1.5119444469746668e-05 \n",
      "epoch: 32 [95546/888800 10.75%] train loss: 1.5104345948202536e-05 \n",
      "epoch: 32 [96657/888800 10.88%] train loss: 1.4758093129785266e-05 \n",
      "epoch: 32 [97768/888800 11.00%] train loss: 1.4159047168504912e-05 \n",
      "epoch: 32 [98879/888800 11.12%] train loss: 1.557833638798911e-05 \n",
      "epoch: 32 [99990/888800 11.25%] train loss: 1.3348599168239161e-05 \n",
      "epoch: 32 [101101/888800 11.38%] train loss: 1.4043818737263791e-05 \n",
      "epoch: 32 [102212/888800 11.50%] train loss: 1.2975615391042084e-05 \n",
      "epoch: 32 [103323/888800 11.62%] train loss: 1.3645384569827002e-05 \n",
      "epoch: 32 [104434/888800 11.75%] train loss: 1.4263871889852453e-05 \n",
      "epoch: 32 [105545/888800 11.88%] train loss: 1.4298506357590668e-05 \n",
      "epoch: 32 [106656/888800 12.00%] train loss: 1.5479296052944846e-05 \n",
      "epoch: 32 [107767/888800 12.12%] train loss: 1.3631663023261353e-05 \n",
      "epoch: 32 [108878/888800 12.25%] train loss: 1.3141414456185885e-05 \n",
      "epoch: 32 [109989/888800 12.38%] train loss: 1.4027978068043012e-05 \n",
      "epoch: 32 [111100/888800 12.50%] train loss: 1.3285007298691198e-05 \n",
      "epoch: 32 [112211/888800 12.62%] train loss: 1.4791461580898613e-05 \n",
      "epoch: 32 [113322/888800 12.75%] train loss: 1.4775175259273965e-05 \n",
      "epoch: 32 [114433/888800 12.88%] train loss: 1.4383987945620902e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [115544/888800 13.00%] train loss: 1.5442483345395885e-05 \n",
      "epoch: 32 [116655/888800 13.12%] train loss: 1.5594052456435747e-05 \n",
      "epoch: 32 [117766/888800 13.25%] train loss: 1.489847545599332e-05 \n",
      "epoch: 32 [118877/888800 13.38%] train loss: 1.509730464022141e-05 \n",
      "epoch: 32 [119988/888800 13.50%] train loss: 1.5978568626451306e-05 \n",
      "epoch: 32 [121099/888800 13.62%] train loss: 1.3828251212544274e-05 \n",
      "epoch: 32 [122210/888800 13.75%] train loss: 1.2735335985780694e-05 \n",
      "epoch: 32 [123321/888800 13.88%] train loss: 1.5070107110659592e-05 \n",
      "epoch: 32 [124432/888800 14.00%] train loss: 1.4316632586997002e-05 \n",
      "epoch: 32 [125543/888800 14.12%] train loss: 1.450641684641596e-05 \n",
      "epoch: 32 [126654/888800 14.25%] train loss: 1.4710723917232826e-05 \n",
      "epoch: 32 [127765/888800 14.38%] train loss: 1.3871510418539401e-05 \n",
      "epoch: 32 [128876/888800 14.50%] train loss: 1.5161963347054552e-05 \n",
      "epoch: 32 [129987/888800 14.62%] train loss: 1.4227254723664373e-05 \n",
      "epoch: 32 [131098/888800 14.75%] train loss: 1.4358995940710884e-05 \n",
      "epoch: 32 [132209/888800 14.88%] train loss: 1.4433493561227806e-05 \n",
      "epoch: 32 [133320/888800 15.00%] train loss: 1.637185960134957e-05 \n",
      "epoch: 32 [134431/888800 15.12%] train loss: 1.3983240023662802e-05 \n",
      "epoch: 32 [135542/888800 15.25%] train loss: 1.518564204161521e-05 \n",
      "epoch: 32 [136653/888800 15.38%] train loss: 1.4951760022086091e-05 \n",
      "epoch: 32 [137764/888800 15.50%] train loss: 1.5475268810405396e-05 \n",
      "epoch: 32 [138875/888800 15.62%] train loss: 1.3873646821593866e-05 \n",
      "epoch: 32 [139986/888800 15.75%] train loss: 1.4108883078733925e-05 \n",
      "epoch: 32 [141097/888800 15.88%] train loss: 1.534405237180181e-05 \n",
      "epoch: 32 [142208/888800 16.00%] train loss: 1.3654716894961894e-05 \n",
      "epoch: 32 [143319/888800 16.12%] train loss: 1.5121479918889236e-05 \n",
      "epoch: 32 [144430/888800 16.25%] train loss: 1.357789005851373e-05 \n",
      "epoch: 32 [145541/888800 16.38%] train loss: 1.6236308510997333e-05 \n",
      "epoch: 32 [146652/888800 16.50%] train loss: 1.428473842679523e-05 \n",
      "epoch: 32 [147763/888800 16.62%] train loss: 1.6025645891204476e-05 \n",
      "epoch: 32 [148874/888800 16.75%] train loss: 1.4728027963428758e-05 \n",
      "epoch: 32 [149985/888800 16.88%] train loss: 1.5214109225780703e-05 \n",
      "epoch: 32 [151096/888800 17.00%] train loss: 1.6340405636583455e-05 \n",
      "epoch: 32 [152207/888800 17.12%] train loss: 1.4890772035869304e-05 \n",
      "epoch: 32 [153318/888800 17.25%] train loss: 1.2816974049201235e-05 \n",
      "epoch: 32 [154429/888800 17.38%] train loss: 1.3375603884924203e-05 \n",
      "epoch: 32 [155540/888800 17.50%] train loss: 1.3856877558282577e-05 \n",
      "epoch: 32 [156651/888800 17.62%] train loss: 1.426416747563053e-05 \n",
      "epoch: 32 [157762/888800 17.75%] train loss: 1.3583777217718307e-05 \n",
      "epoch: 32 [158873/888800 17.88%] train loss: 1.38627892738441e-05 \n",
      "epoch: 32 [159984/888800 18.00%] train loss: 1.3615552234114148e-05 \n",
      "epoch: 32 [161095/888800 18.12%] train loss: 1.4732423551322427e-05 \n",
      "epoch: 32 [162206/888800 18.25%] train loss: 1.4368641132023185e-05 \n",
      "epoch: 32 [163317/888800 18.38%] train loss: 1.4779623597860336e-05 \n",
      "epoch: 32 [164428/888800 18.50%] train loss: 1.4935529179638252e-05 \n",
      "epoch: 32 [165539/888800 18.62%] train loss: 1.448261446057586e-05 \n",
      "epoch: 32 [166650/888800 18.75%] train loss: 1.4097484381636605e-05 \n",
      "epoch: 32 [167761/888800 18.88%] train loss: 1.4024570191395469e-05 \n",
      "epoch: 32 [168872/888800 19.00%] train loss: 1.334602802671725e-05 \n",
      "epoch: 32 [169983/888800 19.12%] train loss: 1.428146606485825e-05 \n",
      "epoch: 32 [171094/888800 19.25%] train loss: 1.4685694623040035e-05 \n",
      "epoch: 32 [172205/888800 19.38%] train loss: 1.4032092622073833e-05 \n",
      "epoch: 32 [173316/888800 19.50%] train loss: 1.3303684681886807e-05 \n",
      "epoch: 32 [174427/888800 19.62%] train loss: 1.5411882486660033e-05 \n",
      "epoch: 32 [175538/888800 19.75%] train loss: 1.5155887922446709e-05 \n",
      "epoch: 32 [176649/888800 19.88%] train loss: 1.4683897461509332e-05 \n",
      "epoch: 32 [177760/888800 20.00%] train loss: 1.491701459599426e-05 \n",
      "epoch: 32 [178871/888800 20.12%] train loss: 1.3299248166731559e-05 \n",
      "epoch: 32 [179982/888800 20.25%] train loss: 1.3251898963062558e-05 \n",
      "epoch: 32 [181093/888800 20.38%] train loss: 1.50575433508493e-05 \n",
      "epoch: 32 [182204/888800 20.50%] train loss: 1.314361816184828e-05 \n",
      "epoch: 32 [183315/888800 20.62%] train loss: 1.53768796735676e-05 \n",
      "epoch: 32 [184426/888800 20.75%] train loss: 1.2525914826255757e-05 \n",
      "epoch: 32 [185537/888800 20.88%] train loss: 1.563724254083354e-05 \n",
      "epoch: 32 [186648/888800 21.00%] train loss: 1.3412452062766533e-05 \n",
      "epoch: 32 [187759/888800 21.12%] train loss: 1.3971175576443784e-05 \n",
      "epoch: 32 [188870/888800 21.25%] train loss: 1.3957525879959576e-05 \n",
      "epoch: 32 [189981/888800 21.38%] train loss: 1.303145290876273e-05 \n",
      "epoch: 32 [191092/888800 21.50%] train loss: 1.5526864444836974e-05 \n",
      "epoch: 32 [192203/888800 21.62%] train loss: 1.367752793157706e-05 \n",
      "epoch: 32 [193314/888800 21.75%] train loss: 1.4925669347576331e-05 \n",
      "epoch: 32 [194425/888800 21.88%] train loss: 1.4470176211034413e-05 \n",
      "epoch: 32 [195536/888800 22.00%] train loss: 1.4830966392764822e-05 \n",
      "epoch: 32 [196647/888800 22.12%] train loss: 1.4842904420220293e-05 \n",
      "epoch: 32 [197758/888800 22.25%] train loss: 1.423725643689977e-05 \n",
      "epoch: 32 [198869/888800 22.38%] train loss: 1.3663550817000214e-05 \n",
      "epoch: 32 [199980/888800 22.50%] train loss: 1.3425476026895922e-05 \n",
      "epoch: 32 [201091/888800 22.62%] train loss: 1.3516551916836761e-05 \n",
      "epoch: 32 [202202/888800 22.75%] train loss: 1.4619632565882057e-05 \n",
      "epoch: 32 [203313/888800 22.88%] train loss: 1.3047327229287475e-05 \n",
      "epoch: 32 [204424/888800 23.00%] train loss: 1.4062065929465462e-05 \n",
      "epoch: 32 [205535/888800 23.12%] train loss: 1.4643827853433322e-05 \n",
      "epoch: 32 [206646/888800 23.25%] train loss: 1.3729049896937795e-05 \n",
      "epoch: 32 [207757/888800 23.38%] train loss: 1.3798035070067272e-05 \n",
      "epoch: 32 [208868/888800 23.50%] train loss: 1.3003159438085277e-05 \n",
      "epoch: 32 [209979/888800 23.62%] train loss: 1.4725569599249866e-05 \n",
      "epoch: 32 [211090/888800 23.75%] train loss: 1.4155979442875832e-05 \n",
      "epoch: 32 [212201/888800 23.88%] train loss: 1.3901326383347623e-05 \n",
      "epoch: 32 [213312/888800 24.00%] train loss: 1.4008074685989413e-05 \n",
      "epoch: 32 [214423/888800 24.12%] train loss: 1.436190814274596e-05 \n",
      "epoch: 32 [215534/888800 24.25%] train loss: 1.4632540114689618e-05 \n",
      "epoch: 32 [216645/888800 24.38%] train loss: 1.3629610293719452e-05 \n",
      "epoch: 32 [217756/888800 24.50%] train loss: 1.375817464577267e-05 \n",
      "epoch: 32 [218867/888800 24.62%] train loss: 1.3874319847673178e-05 \n",
      "epoch: 32 [219978/888800 24.75%] train loss: 1.4448406545852777e-05 \n",
      "epoch: 32 [221089/888800 24.88%] train loss: 1.2902508387924172e-05 \n",
      "epoch: 32 [222200/888800 25.00%] train loss: 1.3895624761062209e-05 \n",
      "epoch: 32 [223311/888800 25.12%] train loss: 1.3516044418793172e-05 \n",
      "epoch: 32 [224422/888800 25.25%] train loss: 1.4994947377999779e-05 \n",
      "epoch: 32 [225533/888800 25.38%] train loss: 1.4310567166830879e-05 \n",
      "epoch: 32 [226644/888800 25.50%] train loss: 1.382383288728306e-05 \n",
      "epoch: 32 [227755/888800 25.62%] train loss: 1.3624387975141872e-05 \n",
      "epoch: 32 [228866/888800 25.75%] train loss: 1.4400512554857414e-05 \n",
      "epoch: 32 [229977/888800 25.88%] train loss: 1.4669928532384802e-05 \n",
      "epoch: 32 [231088/888800 26.00%] train loss: 1.3297626537678298e-05 \n",
      "epoch: 32 [232199/888800 26.12%] train loss: 1.4266312973632012e-05 \n",
      "epoch: 32 [233310/888800 26.25%] train loss: 1.4816381735727191e-05 \n",
      "epoch: 32 [234421/888800 26.38%] train loss: 1.4782483958697412e-05 \n",
      "epoch: 32 [235532/888800 26.50%] train loss: 1.358339432044886e-05 \n",
      "epoch: 32 [236643/888800 26.62%] train loss: 1.4068108612264041e-05 \n",
      "epoch: 32 [237754/888800 26.75%] train loss: 1.3275111086841207e-05 \n",
      "epoch: 32 [238865/888800 26.88%] train loss: 1.4469359484792221e-05 \n",
      "epoch: 32 [239976/888800 27.00%] train loss: 1.3171865248295944e-05 \n",
      "epoch: 32 [241087/888800 27.12%] train loss: 1.4737307537870947e-05 \n",
      "epoch: 32 [242198/888800 27.25%] train loss: 1.4282763004302979e-05 \n",
      "epoch: 32 [243309/888800 27.38%] train loss: 1.4835668480372988e-05 \n",
      "epoch: 32 [244420/888800 27.50%] train loss: 1.4336982530949172e-05 \n",
      "epoch: 32 [245531/888800 27.62%] train loss: 1.6868745660758577e-05 \n",
      "epoch: 32 [246642/888800 27.75%] train loss: 1.5542362234555185e-05 \n",
      "epoch: 32 [247753/888800 27.88%] train loss: 1.3833119737682864e-05 \n",
      "epoch: 32 [248864/888800 28.00%] train loss: 1.45339336086181e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [249975/888800 28.12%] train loss: 1.3902860700909514e-05 \n",
      "epoch: 32 [251086/888800 28.25%] train loss: 1.4980795640440192e-05 \n",
      "epoch: 32 [252197/888800 28.38%] train loss: 1.4261820069805253e-05 \n",
      "epoch: 32 [253308/888800 28.50%] train loss: 1.3928088264947291e-05 \n",
      "epoch: 32 [254419/888800 28.62%] train loss: 1.3544475223170593e-05 \n",
      "epoch: 32 [255530/888800 28.75%] train loss: 1.405771490681218e-05 \n",
      "epoch: 32 [256641/888800 28.88%] train loss: 1.376414638798451e-05 \n",
      "epoch: 32 [257752/888800 29.00%] train loss: 1.3345103070605546e-05 \n",
      "epoch: 32 [258863/888800 29.12%] train loss: 1.4469432244368363e-05 \n",
      "epoch: 32 [259974/888800 29.25%] train loss: 1.4018444744579028e-05 \n",
      "epoch: 32 [261085/888800 29.38%] train loss: 1.3243454304756597e-05 \n",
      "epoch: 32 [262196/888800 29.50%] train loss: 1.2792613233614247e-05 \n",
      "epoch: 32 [263307/888800 29.62%] train loss: 1.386965323035838e-05 \n",
      "epoch: 32 [264418/888800 29.75%] train loss: 1.528340180811938e-05 \n",
      "epoch: 32 [265529/888800 29.88%] train loss: 1.4847539205220528e-05 \n",
      "epoch: 32 [266640/888800 30.00%] train loss: 1.4893204934196547e-05 \n",
      "epoch: 32 [267751/888800 30.12%] train loss: 1.347066972812172e-05 \n",
      "epoch: 32 [268862/888800 30.25%] train loss: 1.4913344784872606e-05 \n",
      "epoch: 32 [269973/888800 30.38%] train loss: 1.3326824955584016e-05 \n",
      "epoch: 32 [271084/888800 30.50%] train loss: 1.3376759852690157e-05 \n",
      "epoch: 32 [272195/888800 30.62%] train loss: 1.345689543086337e-05 \n",
      "epoch: 32 [273306/888800 30.75%] train loss: 1.3926864994573407e-05 \n",
      "epoch: 32 [274417/888800 30.88%] train loss: 1.4610935977543704e-05 \n",
      "epoch: 32 [275528/888800 31.00%] train loss: 1.3921636309532914e-05 \n",
      "epoch: 32 [276639/888800 31.12%] train loss: 1.4616027328884229e-05 \n",
      "epoch: 32 [277750/888800 31.25%] train loss: 1.455540223105345e-05 \n",
      "epoch: 32 [278861/888800 31.38%] train loss: 1.3953971574665047e-05 \n",
      "epoch: 32 [279972/888800 31.50%] train loss: 1.3276589015731588e-05 \n",
      "epoch: 32 [281083/888800 31.62%] train loss: 1.4664857189927716e-05 \n",
      "epoch: 32 [282194/888800 31.75%] train loss: 1.3841055078955833e-05 \n",
      "epoch: 32 [283305/888800 31.88%] train loss: 1.4281267795013264e-05 \n",
      "epoch: 32 [284416/888800 32.00%] train loss: 1.4561700481863227e-05 \n",
      "epoch: 32 [285527/888800 32.12%] train loss: 1.3198541637393646e-05 \n",
      "epoch: 32 [286638/888800 32.25%] train loss: 1.3608896551886573e-05 \n",
      "epoch: 32 [287749/888800 32.38%] train loss: 1.3191487596486695e-05 \n",
      "epoch: 32 [288860/888800 32.50%] train loss: 1.4677764738735277e-05 \n",
      "epoch: 32 [289971/888800 32.62%] train loss: 1.4658627151220571e-05 \n",
      "epoch: 32 [291082/888800 32.75%] train loss: 1.552925823489204e-05 \n",
      "epoch: 32 [292193/888800 32.88%] train loss: 1.3972114174976014e-05 \n",
      "epoch: 32 [293304/888800 33.00%] train loss: 1.4673551959276665e-05 \n",
      "epoch: 32 [294415/888800 33.12%] train loss: 1.4637715139542706e-05 \n",
      "epoch: 32 [295526/888800 33.25%] train loss: 1.4294093489297666e-05 \n",
      "epoch: 32 [296637/888800 33.38%] train loss: 1.3637670235766564e-05 \n",
      "epoch: 32 [297748/888800 33.50%] train loss: 1.341623647022061e-05 \n",
      "epoch: 32 [298859/888800 33.62%] train loss: 1.442333814338781e-05 \n",
      "epoch: 32 [299970/888800 33.75%] train loss: 1.4030754755367525e-05 \n",
      "epoch: 32 [301081/888800 33.88%] train loss: 1.4690399439132307e-05 \n",
      "epoch: 32 [302192/888800 34.00%] train loss: 1.3500867680704687e-05 \n",
      "epoch: 32 [303303/888800 34.12%] train loss: 1.555728340463247e-05 \n",
      "epoch: 32 [304414/888800 34.25%] train loss: 1.3698203474632464e-05 \n",
      "epoch: 32 [305525/888800 34.38%] train loss: 1.3662986930285115e-05 \n",
      "epoch: 32 [306636/888800 34.50%] train loss: 1.3527923329093028e-05 \n",
      "epoch: 32 [307747/888800 34.62%] train loss: 1.5065755178511608e-05 \n",
      "epoch: 32 [308858/888800 34.75%] train loss: 1.4516646842821501e-05 \n",
      "epoch: 32 [309969/888800 34.88%] train loss: 1.4500459656119347e-05 \n",
      "epoch: 32 [311080/888800 35.00%] train loss: 1.3529290299629793e-05 \n",
      "epoch: 32 [312191/888800 35.12%] train loss: 1.456795052945381e-05 \n",
      "epoch: 32 [313302/888800 35.25%] train loss: 1.5703390090493485e-05 \n",
      "epoch: 32 [314413/888800 35.38%] train loss: 1.5795803847140633e-05 \n",
      "epoch: 32 [315524/888800 35.50%] train loss: 1.4200722944224253e-05 \n",
      "epoch: 32 [316635/888800 35.62%] train loss: 1.5709252693341114e-05 \n",
      "epoch: 32 [317746/888800 35.75%] train loss: 1.4110784832155332e-05 \n",
      "epoch: 32 [318857/888800 35.88%] train loss: 1.4293868844106328e-05 \n",
      "epoch: 32 [319968/888800 36.00%] train loss: 1.4834614376013633e-05 \n",
      "epoch: 32 [321079/888800 36.12%] train loss: 1.4053830454940908e-05 \n",
      "epoch: 32 [322190/888800 36.25%] train loss: 1.5395420632557943e-05 \n",
      "epoch: 32 [323301/888800 36.38%] train loss: 1.4065539289731532e-05 \n",
      "epoch: 32 [324412/888800 36.50%] train loss: 1.5431032807100564e-05 \n",
      "epoch: 32 [325523/888800 36.62%] train loss: 1.4732013369211927e-05 \n",
      "epoch: 32 [326634/888800 36.75%] train loss: 1.4586594261345454e-05 \n",
      "epoch: 32 [327745/888800 36.88%] train loss: 1.4214679140422959e-05 \n",
      "epoch: 32 [328856/888800 37.00%] train loss: 1.3880940969102085e-05 \n",
      "epoch: 32 [329967/888800 37.12%] train loss: 1.4334035768115427e-05 \n",
      "epoch: 32 [331078/888800 37.25%] train loss: 1.55212856043363e-05 \n",
      "epoch: 32 [332189/888800 37.38%] train loss: 1.3909474546380807e-05 \n",
      "epoch: 32 [333300/888800 37.50%] train loss: 1.4235100934456568e-05 \n",
      "epoch: 32 [334411/888800 37.62%] train loss: 1.3755661711911671e-05 \n",
      "epoch: 32 [335522/888800 37.75%] train loss: 1.486866494815331e-05 \n",
      "epoch: 32 [336633/888800 37.88%] train loss: 1.5090105080162175e-05 \n",
      "epoch: 32 [337744/888800 38.00%] train loss: 1.4133858712739311e-05 \n",
      "epoch: 32 [338855/888800 38.12%] train loss: 1.4307861420093104e-05 \n",
      "epoch: 32 [339966/888800 38.25%] train loss: 1.3200788998801727e-05 \n",
      "epoch: 32 [341077/888800 38.38%] train loss: 1.447756130801281e-05 \n",
      "epoch: 32 [342188/888800 38.50%] train loss: 1.4342743270390201e-05 \n",
      "epoch: 32 [343299/888800 38.62%] train loss: 1.4044360796106048e-05 \n",
      "epoch: 32 [344410/888800 38.75%] train loss: 1.5192699720500968e-05 \n",
      "epoch: 32 [345521/888800 38.88%] train loss: 1.4227018255041912e-05 \n",
      "epoch: 32 [346632/888800 39.00%] train loss: 1.5614226867910475e-05 \n",
      "epoch: 32 [347743/888800 39.12%] train loss: 1.5401115888380446e-05 \n",
      "epoch: 32 [348854/888800 39.25%] train loss: 1.3634126844408456e-05 \n",
      "epoch: 32 [349965/888800 39.38%] train loss: 1.625224103918299e-05 \n",
      "epoch: 32 [351076/888800 39.50%] train loss: 1.2636682185984682e-05 \n",
      "epoch: 32 [352187/888800 39.62%] train loss: 1.4405325600819197e-05 \n",
      "epoch: 32 [353298/888800 39.75%] train loss: 1.3931060493632685e-05 \n",
      "epoch: 32 [354409/888800 39.88%] train loss: 1.6049401892814785e-05 \n",
      "epoch: 32 [355520/888800 40.00%] train loss: 1.4288018064689822e-05 \n",
      "epoch: 32 [356631/888800 40.12%] train loss: 1.4211848792911042e-05 \n",
      "epoch: 32 [357742/888800 40.25%] train loss: 1.4720322724315338e-05 \n",
      "epoch: 32 [358853/888800 40.38%] train loss: 1.4028671103005763e-05 \n",
      "epoch: 32 [359964/888800 40.50%] train loss: 1.3436332665150985e-05 \n",
      "epoch: 32 [361075/888800 40.62%] train loss: 1.3642391422763467e-05 \n",
      "epoch: 32 [362186/888800 40.75%] train loss: 1.4117003047431353e-05 \n",
      "epoch: 32 [363297/888800 40.88%] train loss: 1.4603067938878667e-05 \n",
      "epoch: 32 [364408/888800 41.00%] train loss: 1.5236595572787337e-05 \n",
      "epoch: 32 [365519/888800 41.12%] train loss: 1.3750672223977745e-05 \n",
      "epoch: 32 [366630/888800 41.25%] train loss: 1.5124417586775962e-05 \n",
      "epoch: 32 [367741/888800 41.38%] train loss: 1.4578559785149992e-05 \n",
      "epoch: 32 [368852/888800 41.50%] train loss: 1.3260758350952528e-05 \n",
      "epoch: 32 [369963/888800 41.62%] train loss: 1.4724116226716433e-05 \n",
      "epoch: 32 [371074/888800 41.75%] train loss: 1.5792706108186394e-05 \n",
      "epoch: 32 [372185/888800 41.88%] train loss: 1.4491624824586324e-05 \n",
      "epoch: 32 [373296/888800 42.00%] train loss: 1.4368019037647173e-05 \n",
      "epoch: 32 [374407/888800 42.12%] train loss: 1.3831851902068593e-05 \n",
      "epoch: 32 [375518/888800 42.25%] train loss: 1.284106110688299e-05 \n",
      "epoch: 32 [376629/888800 42.38%] train loss: 1.3284132364788093e-05 \n",
      "epoch: 32 [377740/888800 42.50%] train loss: 1.3992150343256071e-05 \n",
      "epoch: 32 [378851/888800 42.62%] train loss: 1.4654927326773759e-05 \n",
      "epoch: 32 [379962/888800 42.75%] train loss: 1.3597794350062031e-05 \n",
      "epoch: 32 [381073/888800 42.88%] train loss: 1.4133906006463803e-05 \n",
      "epoch: 32 [382184/888800 43.00%] train loss: 1.4350472156365868e-05 \n",
      "epoch: 32 [383295/888800 43.12%] train loss: 1.2448936104192398e-05 \n",
      "epoch: 32 [384406/888800 43.25%] train loss: 1.449696264899103e-05 \n",
      "epoch: 32 [385517/888800 43.38%] train loss: 1.4998320693848655e-05 \n",
      "epoch: 32 [386628/888800 43.50%] train loss: 1.3300985301611945e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [387739/888800 43.62%] train loss: 1.4463888874161057e-05 \n",
      "epoch: 32 [388850/888800 43.75%] train loss: 1.2999583304917905e-05 \n",
      "epoch: 32 [389961/888800 43.88%] train loss: 1.392066496919142e-05 \n",
      "epoch: 32 [391072/888800 44.00%] train loss: 1.4168103916745167e-05 \n",
      "epoch: 32 [392183/888800 44.12%] train loss: 1.4954696780478116e-05 \n",
      "epoch: 32 [393294/888800 44.25%] train loss: 1.3381462849793024e-05 \n",
      "epoch: 32 [394405/888800 44.38%] train loss: 1.465945206291508e-05 \n",
      "epoch: 32 [395516/888800 44.50%] train loss: 1.3923678125138395e-05 \n",
      "epoch: 32 [396627/888800 44.62%] train loss: 1.4370210010383744e-05 \n",
      "epoch: 32 [397738/888800 44.75%] train loss: 1.3684398254554253e-05 \n",
      "epoch: 32 [398849/888800 44.88%] train loss: 1.4387498595169745e-05 \n",
      "epoch: 32 [399960/888800 45.00%] train loss: 1.3626403415401e-05 \n",
      "epoch: 32 [401071/888800 45.12%] train loss: 1.392624108120799e-05 \n",
      "epoch: 32 [402182/888800 45.25%] train loss: 1.4307593119156081e-05 \n",
      "epoch: 32 [403293/888800 45.38%] train loss: 1.4301430383056868e-05 \n",
      "epoch: 32 [404404/888800 45.50%] train loss: 1.3998032045492437e-05 \n",
      "epoch: 32 [405515/888800 45.62%] train loss: 1.3391235370363574e-05 \n",
      "epoch: 32 [406626/888800 45.75%] train loss: 1.3753549865214154e-05 \n",
      "epoch: 32 [407737/888800 45.88%] train loss: 1.4145137356535997e-05 \n",
      "epoch: 32 [408848/888800 46.00%] train loss: 1.4971009477449115e-05 \n",
      "epoch: 32 [409959/888800 46.12%] train loss: 1.4397050108527765e-05 \n",
      "epoch: 32 [411070/888800 46.25%] train loss: 1.3469856639858335e-05 \n",
      "epoch: 32 [412181/888800 46.38%] train loss: 1.4956686754885595e-05 \n",
      "epoch: 32 [413292/888800 46.50%] train loss: 1.4214407201507129e-05 \n",
      "epoch: 32 [414403/888800 46.62%] train loss: 1.4590248611057177e-05 \n",
      "epoch: 32 [415514/888800 46.75%] train loss: 1.5098350559128448e-05 \n",
      "epoch: 32 [416625/888800 46.88%] train loss: 1.2966522263013758e-05 \n",
      "epoch: 32 [417736/888800 47.00%] train loss: 1.4213139365892857e-05 \n",
      "epoch: 32 [418847/888800 47.12%] train loss: 1.4261816431826446e-05 \n",
      "epoch: 32 [419958/888800 47.25%] train loss: 1.3704210687137675e-05 \n",
      "epoch: 32 [421069/888800 47.38%] train loss: 1.4489730347122531e-05 \n",
      "epoch: 32 [422180/888800 47.50%] train loss: 1.5265912225004286e-05 \n",
      "epoch: 32 [423291/888800 47.62%] train loss: 1.4402752640307881e-05 \n",
      "epoch: 32 [424402/888800 47.75%] train loss: 1.3681096788786817e-05 \n",
      "epoch: 32 [425513/888800 47.88%] train loss: 1.3402775948634371e-05 \n",
      "epoch: 32 [426624/888800 48.00%] train loss: 1.2895219697384164e-05 \n",
      "epoch: 32 [427735/888800 48.12%] train loss: 1.4637113963544834e-05 \n",
      "epoch: 32 [428846/888800 48.25%] train loss: 1.372492806694936e-05 \n",
      "epoch: 32 [429957/888800 48.38%] train loss: 1.431130658602342e-05 \n",
      "epoch: 32 [431068/888800 48.50%] train loss: 1.4151351933833212e-05 \n",
      "epoch: 32 [432179/888800 48.62%] train loss: 1.5088257896422874e-05 \n",
      "epoch: 32 [433290/888800 48.75%] train loss: 1.366153264825698e-05 \n",
      "epoch: 32 [434401/888800 48.88%] train loss: 1.3761754416918848e-05 \n",
      "epoch: 32 [435512/888800 49.00%] train loss: 1.4748171452083625e-05 \n",
      "epoch: 32 [436623/888800 49.12%] train loss: 1.4375644241226837e-05 \n",
      "epoch: 32 [437734/888800 49.25%] train loss: 1.5377512681880035e-05 \n",
      "epoch: 32 [438845/888800 49.38%] train loss: 1.500373582530301e-05 \n",
      "epoch: 32 [439956/888800 49.50%] train loss: 1.39515877890517e-05 \n",
      "epoch: 32 [441067/888800 49.62%] train loss: 1.4164831554808188e-05 \n",
      "epoch: 32 [442178/888800 49.75%] train loss: 1.4538801224261988e-05 \n",
      "epoch: 32 [443289/888800 49.88%] train loss: 1.4844537872704677e-05 \n",
      "epoch: 32 [444400/888800 50.00%] train loss: 1.5701200027251616e-05 \n",
      "epoch: 32 [445511/888800 50.12%] train loss: 1.4038624613021966e-05 \n",
      "epoch: 32 [446622/888800 50.25%] train loss: 1.5821849956410006e-05 \n",
      "epoch: 32 [447733/888800 50.38%] train loss: 1.37384404297336e-05 \n",
      "epoch: 32 [448844/888800 50.50%] train loss: 1.4622020898968913e-05 \n",
      "epoch: 32 [449955/888800 50.62%] train loss: 1.319263446930563e-05 \n",
      "epoch: 32 [451066/888800 50.75%] train loss: 1.379108834953513e-05 \n",
      "epoch: 32 [452177/888800 50.88%] train loss: 1.4229224689188413e-05 \n",
      "epoch: 32 [453288/888800 51.00%] train loss: 1.35785412567202e-05 \n",
      "epoch: 32 [454399/888800 51.12%] train loss: 1.445232737751212e-05 \n",
      "epoch: 32 [455510/888800 51.25%] train loss: 1.4072496014705393e-05 \n",
      "epoch: 32 [456621/888800 51.38%] train loss: 1.3332353773876093e-05 \n",
      "epoch: 32 [457732/888800 51.50%] train loss: 1.4036912034498528e-05 \n",
      "epoch: 32 [458843/888800 51.62%] train loss: 1.569033156556543e-05 \n",
      "epoch: 32 [459954/888800 51.75%] train loss: 1.5302241081371903e-05 \n",
      "epoch: 32 [461065/888800 51.88%] train loss: 1.4611705410061404e-05 \n",
      "epoch: 32 [462176/888800 52.00%] train loss: 1.3758109162154142e-05 \n",
      "epoch: 32 [463287/888800 52.12%] train loss: 1.4181474398355931e-05 \n",
      "epoch: 32 [464398/888800 52.25%] train loss: 1.3798672625853214e-05 \n",
      "epoch: 32 [465509/888800 52.38%] train loss: 1.276099374081241e-05 \n",
      "epoch: 32 [466620/888800 52.50%] train loss: 1.4993262993812095e-05 \n",
      "epoch: 32 [467731/888800 52.62%] train loss: 1.289250940317288e-05 \n",
      "epoch: 32 [468842/888800 52.75%] train loss: 1.4393945093615912e-05 \n",
      "epoch: 32 [469953/888800 52.88%] train loss: 1.4569563973054755e-05 \n",
      "epoch: 32 [471064/888800 53.00%] train loss: 1.3432557352643926e-05 \n",
      "epoch: 32 [472175/888800 53.12%] train loss: 1.4680133972433396e-05 \n",
      "epoch: 32 [473286/888800 53.25%] train loss: 1.3438167115964461e-05 \n",
      "epoch: 32 [474397/888800 53.38%] train loss: 1.449841420253506e-05 \n",
      "epoch: 32 [475508/888800 53.50%] train loss: 1.3359685908653773e-05 \n",
      "epoch: 32 [476619/888800 53.62%] train loss: 1.509116464148974e-05 \n",
      "epoch: 32 [477730/888800 53.75%] train loss: 1.4231964087230153e-05 \n",
      "epoch: 32 [478841/888800 53.88%] train loss: 1.4246030332287773e-05 \n",
      "epoch: 32 [479952/888800 54.00%] train loss: 1.4206845662556589e-05 \n",
      "epoch: 32 [481063/888800 54.12%] train loss: 1.534088733023964e-05 \n",
      "epoch: 32 [482174/888800 54.25%] train loss: 1.527462518424727e-05 \n",
      "epoch: 32 [483285/888800 54.38%] train loss: 1.4957168787077535e-05 \n",
      "epoch: 32 [484396/888800 54.50%] train loss: 1.3804796253680252e-05 \n",
      "epoch: 32 [485507/888800 54.62%] train loss: 1.2831387721234933e-05 \n",
      "epoch: 32 [486618/888800 54.75%] train loss: 1.3741868315264583e-05 \n",
      "epoch: 32 [487729/888800 54.88%] train loss: 1.4838023162155878e-05 \n",
      "epoch: 32 [488840/888800 55.00%] train loss: 1.4042931070434861e-05 \n",
      "epoch: 32 [489951/888800 55.12%] train loss: 1.5308223737520166e-05 \n",
      "epoch: 32 [491062/888800 55.25%] train loss: 1.4151657524053007e-05 \n",
      "epoch: 32 [492173/888800 55.38%] train loss: 1.3918741387897171e-05 \n",
      "epoch: 32 [493284/888800 55.50%] train loss: 1.477352088841144e-05 \n",
      "epoch: 32 [494395/888800 55.62%] train loss: 1.4824023310211487e-05 \n",
      "epoch: 32 [495506/888800 55.75%] train loss: 1.4727153939020354e-05 \n",
      "epoch: 32 [496617/888800 55.88%] train loss: 1.5164533579081763e-05 \n",
      "epoch: 32 [497728/888800 56.00%] train loss: 1.5471976439584978e-05 \n",
      "epoch: 32 [498839/888800 56.12%] train loss: 1.3412699445325416e-05 \n",
      "epoch: 32 [499950/888800 56.25%] train loss: 1.439418520021718e-05 \n",
      "epoch: 32 [501061/888800 56.38%] train loss: 1.3279949598654639e-05 \n",
      "epoch: 32 [502172/888800 56.50%] train loss: 1.4232021385396365e-05 \n",
      "epoch: 32 [503283/888800 56.62%] train loss: 1.330900067841867e-05 \n",
      "epoch: 32 [504394/888800 56.75%] train loss: 1.4009316146257333e-05 \n",
      "epoch: 32 [505505/888800 56.88%] train loss: 1.3016366210649721e-05 \n",
      "epoch: 32 [506616/888800 57.00%] train loss: 1.5165197510214057e-05 \n",
      "epoch: 32 [507727/888800 57.12%] train loss: 1.386944768455578e-05 \n",
      "epoch: 32 [508838/888800 57.25%] train loss: 1.3824582310917322e-05 \n",
      "epoch: 32 [509949/888800 57.38%] train loss: 1.4293419553723652e-05 \n",
      "epoch: 32 [511060/888800 57.50%] train loss: 1.4152795301924925e-05 \n",
      "epoch: 32 [512171/888800 57.62%] train loss: 1.587000588187948e-05 \n",
      "epoch: 32 [513282/888800 57.75%] train loss: 1.5454666936420836e-05 \n",
      "epoch: 32 [514393/888800 57.88%] train loss: 1.5648012777091935e-05 \n",
      "epoch: 32 [515504/888800 58.00%] train loss: 1.538071228424087e-05 \n",
      "epoch: 32 [516615/888800 58.12%] train loss: 1.68363876582589e-05 \n",
      "epoch: 32 [517726/888800 58.25%] train loss: 1.4785408893658314e-05 \n",
      "epoch: 32 [518837/888800 58.38%] train loss: 1.4659158296126407e-05 \n",
      "epoch: 32 [519948/888800 58.50%] train loss: 1.4588495105272159e-05 \n",
      "epoch: 32 [521059/888800 58.62%] train loss: 1.5547877410426736e-05 \n",
      "epoch: 32 [522170/888800 58.75%] train loss: 1.4315932276076637e-05 \n",
      "epoch: 32 [523281/888800 58.88%] train loss: 1.3486250281857792e-05 \n",
      "epoch: 32 [524392/888800 59.00%] train loss: 1.3309316273080185e-05 \n",
      "epoch: 32 [525503/888800 59.12%] train loss: 1.4201802514435258e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [526614/888800 59.25%] train loss: 1.4544113582815044e-05 \n",
      "epoch: 32 [527725/888800 59.38%] train loss: 1.3726627003052272e-05 \n",
      "epoch: 32 [528836/888800 59.50%] train loss: 1.3222303095972165e-05 \n",
      "epoch: 32 [529947/888800 59.62%] train loss: 1.460261864849599e-05 \n",
      "epoch: 32 [531058/888800 59.75%] train loss: 1.388794589729514e-05 \n",
      "epoch: 32 [532169/888800 59.88%] train loss: 1.3947821571491659e-05 \n",
      "epoch: 32 [533280/888800 60.00%] train loss: 1.3815396414429415e-05 \n",
      "epoch: 32 [534391/888800 60.12%] train loss: 1.3874549040338024e-05 \n",
      "epoch: 32 [535502/888800 60.25%] train loss: 1.3987058991915546e-05 \n",
      "epoch: 32 [536613/888800 60.38%] train loss: 1.442777102056425e-05 \n",
      "epoch: 32 [537724/888800 60.50%] train loss: 1.3190847312216647e-05 \n",
      "epoch: 32 [538835/888800 60.62%] train loss: 1.5341494872700423e-05 \n",
      "epoch: 32 [539946/888800 60.75%] train loss: 1.4243515579437371e-05 \n",
      "epoch: 32 [541057/888800 60.88%] train loss: 1.4157271834847052e-05 \n",
      "epoch: 32 [542168/888800 61.00%] train loss: 1.4424032997339964e-05 \n",
      "epoch: 32 [543279/888800 61.12%] train loss: 1.3515297723643016e-05 \n",
      "epoch: 32 [544390/888800 61.25%] train loss: 1.4542195458489005e-05 \n",
      "epoch: 32 [545501/888800 61.38%] train loss: 1.51436743180966e-05 \n",
      "epoch: 32 [546612/888800 61.50%] train loss: 1.3910297639085911e-05 \n",
      "epoch: 32 [547723/888800 61.62%] train loss: 1.3981688425701577e-05 \n",
      "epoch: 32 [548834/888800 61.75%] train loss: 1.3722124094783794e-05 \n",
      "epoch: 32 [549945/888800 61.88%] train loss: 1.4651657693320885e-05 \n",
      "epoch: 32 [551056/888800 62.00%] train loss: 1.4193717106536496e-05 \n",
      "epoch: 32 [552167/888800 62.12%] train loss: 1.4375248611031566e-05 \n",
      "epoch: 32 [553278/888800 62.25%] train loss: 1.2821077689295635e-05 \n",
      "epoch: 32 [554389/888800 62.38%] train loss: 1.3885100088373292e-05 \n",
      "epoch: 32 [555500/888800 62.50%] train loss: 1.3544636203732807e-05 \n",
      "epoch: 32 [556611/888800 62.62%] train loss: 1.478769445384387e-05 \n",
      "epoch: 32 [557722/888800 62.75%] train loss: 1.370519294141559e-05 \n",
      "epoch: 32 [558833/888800 62.88%] train loss: 1.4637088497693185e-05 \n",
      "epoch: 32 [559944/888800 63.00%] train loss: 1.638698267925065e-05 \n",
      "epoch: 32 [561055/888800 63.12%] train loss: 1.5854477169341408e-05 \n",
      "epoch: 32 [562166/888800 63.25%] train loss: 1.4968122741265688e-05 \n",
      "epoch: 32 [563277/888800 63.38%] train loss: 1.4717663361807354e-05 \n",
      "epoch: 32 [564388/888800 63.50%] train loss: 1.4580781680706423e-05 \n",
      "epoch: 32 [565499/888800 63.62%] train loss: 1.5086037819855846e-05 \n",
      "epoch: 32 [566610/888800 63.75%] train loss: 1.4507045307254884e-05 \n",
      "epoch: 32 [567721/888800 63.88%] train loss: 1.4629556972067803e-05 \n",
      "epoch: 32 [568832/888800 64.00%] train loss: 1.4561100215360057e-05 \n",
      "epoch: 32 [569943/888800 64.12%] train loss: 1.4706242836837191e-05 \n",
      "epoch: 32 [571054/888800 64.25%] train loss: 1.5398674804600887e-05 \n",
      "epoch: 32 [572165/888800 64.38%] train loss: 1.4881446986692026e-05 \n",
      "epoch: 32 [573276/888800 64.50%] train loss: 1.3400488569459412e-05 \n",
      "epoch: 32 [574387/888800 64.62%] train loss: 1.612577761989087e-05 \n",
      "epoch: 32 [575498/888800 64.75%] train loss: 1.4620698493672535e-05 \n",
      "epoch: 32 [576609/888800 64.88%] train loss: 1.5835346857784316e-05 \n",
      "epoch: 32 [577720/888800 65.00%] train loss: 1.3648049389303196e-05 \n",
      "epoch: 32 [578831/888800 65.12%] train loss: 1.3549847608373966e-05 \n",
      "epoch: 32 [579942/888800 65.25%] train loss: 1.4119342267804313e-05 \n",
      "epoch: 32 [581053/888800 65.38%] train loss: 1.5671937944716774e-05 \n",
      "epoch: 32 [582164/888800 65.50%] train loss: 1.3044093975622673e-05 \n",
      "epoch: 32 [583275/888800 65.62%] train loss: 1.4575122804671992e-05 \n",
      "epoch: 32 [584386/888800 65.75%] train loss: 1.3588870388048235e-05 \n",
      "epoch: 32 [585497/888800 65.88%] train loss: 1.5137609807425179e-05 \n",
      "epoch: 32 [586608/888800 66.00%] train loss: 1.4185765394358896e-05 \n",
      "epoch: 32 [587719/888800 66.12%] train loss: 1.490319482400082e-05 \n",
      "epoch: 32 [588830/888800 66.25%] train loss: 1.309745402977569e-05 \n",
      "epoch: 32 [589941/888800 66.38%] train loss: 1.4268940503825434e-05 \n",
      "epoch: 32 [591052/888800 66.50%] train loss: 1.5257226550602354e-05 \n",
      "epoch: 32 [592163/888800 66.62%] train loss: 1.336777404503664e-05 \n",
      "epoch: 32 [593274/888800 66.75%] train loss: 1.4240325072023552e-05 \n",
      "epoch: 32 [594385/888800 66.88%] train loss: 1.3999842849443667e-05 \n",
      "epoch: 32 [595496/888800 67.00%] train loss: 1.4749380170542281e-05 \n",
      "epoch: 32 [596607/888800 67.12%] train loss: 1.400281962560257e-05 \n",
      "epoch: 32 [597718/888800 67.25%] train loss: 1.4086516785027925e-05 \n",
      "epoch: 32 [598829/888800 67.38%] train loss: 1.3625699466501828e-05 \n",
      "epoch: 32 [599940/888800 67.50%] train loss: 1.452746528229909e-05 \n",
      "epoch: 32 [601051/888800 67.62%] train loss: 1.4268740414991044e-05 \n",
      "epoch: 32 [602162/888800 67.75%] train loss: 1.41513455673703e-05 \n",
      "epoch: 32 [603273/888800 67.88%] train loss: 1.3667286111740395e-05 \n",
      "epoch: 32 [604384/888800 68.00%] train loss: 1.4811606888542883e-05 \n",
      "epoch: 32 [605495/888800 68.12%] train loss: 1.4435530829359777e-05 \n",
      "epoch: 32 [606606/888800 68.25%] train loss: 1.3697859685635194e-05 \n",
      "epoch: 32 [607717/888800 68.38%] train loss: 1.4861045201541856e-05 \n",
      "epoch: 32 [608828/888800 68.50%] train loss: 1.3790952834824566e-05 \n",
      "epoch: 32 [609939/888800 68.62%] train loss: 1.3375870366871823e-05 \n",
      "epoch: 32 [611050/888800 68.75%] train loss: 1.4123149412625935e-05 \n",
      "epoch: 32 [612161/888800 68.88%] train loss: 1.3866991139366291e-05 \n",
      "epoch: 32 [613272/888800 69.00%] train loss: 1.4822863704466727e-05 \n",
      "epoch: 32 [614383/888800 69.12%] train loss: 1.3474467777996324e-05 \n",
      "epoch: 32 [615494/888800 69.25%] train loss: 1.4988301700213924e-05 \n",
      "epoch: 32 [616605/888800 69.38%] train loss: 1.564357808092609e-05 \n",
      "epoch: 32 [617716/888800 69.50%] train loss: 1.4048796401766594e-05 \n",
      "epoch: 32 [618827/888800 69.62%] train loss: 1.4217193893273361e-05 \n",
      "epoch: 32 [619938/888800 69.75%] train loss: 1.3300988939590752e-05 \n",
      "epoch: 32 [621049/888800 69.88%] train loss: 1.4097249732003547e-05 \n",
      "epoch: 32 [622160/888800 70.00%] train loss: 1.4011057828611229e-05 \n",
      "epoch: 32 [623271/888800 70.12%] train loss: 1.539007826067973e-05 \n",
      "epoch: 32 [624382/888800 70.25%] train loss: 1.3988688806421123e-05 \n",
      "epoch: 32 [625493/888800 70.38%] train loss: 1.3762345588475e-05 \n",
      "epoch: 32 [626604/888800 70.50%] train loss: 1.443937435396947e-05 \n",
      "epoch: 32 [627715/888800 70.62%] train loss: 1.4397194718185347e-05 \n",
      "epoch: 32 [628826/888800 70.75%] train loss: 1.3145799130143132e-05 \n",
      "epoch: 32 [629937/888800 70.88%] train loss: 1.5649704437237233e-05 \n",
      "epoch: 32 [631048/888800 71.00%] train loss: 1.3434626453090459e-05 \n",
      "epoch: 32 [632159/888800 71.12%] train loss: 1.4614440260629635e-05 \n",
      "epoch: 32 [633270/888800 71.25%] train loss: 1.515944859420415e-05 \n",
      "epoch: 32 [634381/888800 71.38%] train loss: 1.6272548236884177e-05 \n",
      "epoch: 32 [635492/888800 71.50%] train loss: 1.3147755453246646e-05 \n",
      "epoch: 32 [636603/888800 71.62%] train loss: 1.4075762919674162e-05 \n",
      "epoch: 32 [637714/888800 71.75%] train loss: 1.5014597011031583e-05 \n",
      "epoch: 32 [638825/888800 71.88%] train loss: 1.3643197235069238e-05 \n",
      "epoch: 32 [639936/888800 72.00%] train loss: 1.4410643416340463e-05 \n",
      "epoch: 32 [641047/888800 72.12%] train loss: 1.515960775577696e-05 \n",
      "epoch: 32 [642158/888800 72.25%] train loss: 1.4643886970588937e-05 \n",
      "epoch: 32 [643269/888800 72.38%] train loss: 1.4405128240468912e-05 \n",
      "epoch: 32 [644380/888800 72.50%] train loss: 1.352326671621995e-05 \n",
      "epoch: 32 [645491/888800 72.62%] train loss: 1.3732875231653452e-05 \n",
      "epoch: 32 [646602/888800 72.75%] train loss: 1.431698001397308e-05 \n",
      "epoch: 32 [647713/888800 72.88%] train loss: 1.3589327863883227e-05 \n",
      "epoch: 32 [648824/888800 73.00%] train loss: 1.390622401231667e-05 \n",
      "epoch: 32 [649935/888800 73.12%] train loss: 1.3550436960940715e-05 \n",
      "epoch: 32 [651046/888800 73.25%] train loss: 1.4378844753082376e-05 \n",
      "epoch: 32 [652157/888800 73.38%] train loss: 1.3452921848511323e-05 \n",
      "epoch: 32 [653268/888800 73.50%] train loss: 1.4722672858624719e-05 \n",
      "epoch: 32 [654379/888800 73.62%] train loss: 1.3901159036322497e-05 \n",
      "epoch: 32 [655490/888800 73.75%] train loss: 1.5745135897304863e-05 \n",
      "epoch: 32 [656601/888800 73.88%] train loss: 1.4792779438721482e-05 \n",
      "epoch: 32 [657712/888800 74.00%] train loss: 1.420596436219057e-05 \n",
      "epoch: 32 [658823/888800 74.12%] train loss: 1.2578053429024294e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [659934/888800 74.25%] train loss: 1.5325565982493572e-05 \n",
      "epoch: 32 [661045/888800 74.38%] train loss: 1.4500265024253167e-05 \n",
      "epoch: 32 [662156/888800 74.50%] train loss: 1.3043351827946026e-05 \n",
      "epoch: 32 [663267/888800 74.62%] train loss: 1.3677901733899489e-05 \n",
      "epoch: 32 [664378/888800 74.75%] train loss: 1.3870373550162185e-05 \n",
      "epoch: 32 [665489/888800 74.88%] train loss: 1.526507912785746e-05 \n",
      "epoch: 32 [666600/888800 75.00%] train loss: 1.3167880752007477e-05 \n",
      "epoch: 32 [667711/888800 75.12%] train loss: 1.4443277905229479e-05 \n",
      "epoch: 32 [668822/888800 75.25%] train loss: 1.538127071398776e-05 \n",
      "epoch: 32 [669933/888800 75.38%] train loss: 1.4146156900096685e-05 \n",
      "epoch: 32 [671044/888800 75.50%] train loss: 1.4327054486784618e-05 \n",
      "epoch: 32 [672155/888800 75.62%] train loss: 1.424894708179636e-05 \n",
      "epoch: 32 [673266/888800 75.75%] train loss: 1.3744752322963905e-05 \n",
      "epoch: 32 [674377/888800 75.88%] train loss: 1.4886362805555109e-05 \n",
      "epoch: 32 [675488/888800 76.00%] train loss: 1.6166573914233595e-05 \n",
      "epoch: 32 [676599/888800 76.12%] train loss: 1.5435563909704797e-05 \n",
      "epoch: 32 [677710/888800 76.25%] train loss: 1.4202817510522436e-05 \n",
      "epoch: 32 [678821/888800 76.38%] train loss: 1.5006257854111027e-05 \n",
      "epoch: 32 [679932/888800 76.50%] train loss: 1.3599141311715357e-05 \n",
      "epoch: 32 [681043/888800 76.62%] train loss: 1.377181524730986e-05 \n",
      "epoch: 32 [682154/888800 76.75%] train loss: 1.3820899766869843e-05 \n",
      "epoch: 32 [683265/888800 76.88%] train loss: 1.3013239367865026e-05 \n",
      "epoch: 32 [684376/888800 77.00%] train loss: 1.4009087863087188e-05 \n",
      "epoch: 32 [685487/888800 77.12%] train loss: 1.3716617104364559e-05 \n",
      "epoch: 32 [686598/888800 77.25%] train loss: 1.3470074009092059e-05 \n",
      "epoch: 32 [687709/888800 77.38%] train loss: 1.3990844308864325e-05 \n",
      "epoch: 32 [688820/888800 77.50%] train loss: 1.40373085741885e-05 \n",
      "epoch: 32 [689931/888800 77.62%] train loss: 1.5363761121989228e-05 \n",
      "epoch: 32 [691042/888800 77.75%] train loss: 1.440756386728026e-05 \n",
      "epoch: 32 [692153/888800 77.88%] train loss: 1.426506059942767e-05 \n",
      "epoch: 32 [693264/888800 78.00%] train loss: 1.3272572687128559e-05 \n",
      "epoch: 32 [694375/888800 78.12%] train loss: 1.427791630703723e-05 \n",
      "epoch: 32 [695486/888800 78.25%] train loss: 1.3384459634835366e-05 \n",
      "epoch: 32 [696597/888800 78.38%] train loss: 1.464611978008179e-05 \n",
      "epoch: 32 [697708/888800 78.50%] train loss: 1.3963051969767548e-05 \n",
      "epoch: 32 [698819/888800 78.62%] train loss: 1.4338687833514996e-05 \n",
      "epoch: 32 [699930/888800 78.75%] train loss: 1.3451690392685123e-05 \n",
      "epoch: 32 [701041/888800 78.88%] train loss: 1.5235928003676236e-05 \n",
      "epoch: 32 [702152/888800 79.00%] train loss: 1.4757920325791929e-05 \n",
      "epoch: 32 [703263/888800 79.12%] train loss: 1.4538718460244127e-05 \n",
      "epoch: 32 [704374/888800 79.25%] train loss: 1.4046743672224693e-05 \n",
      "epoch: 32 [705485/888800 79.38%] train loss: 1.3631596630148124e-05 \n",
      "epoch: 32 [706596/888800 79.50%] train loss: 1.432614772056695e-05 \n",
      "epoch: 32 [707707/888800 79.62%] train loss: 1.4754733456356917e-05 \n",
      "epoch: 32 [708818/888800 79.75%] train loss: 1.3343877981242258e-05 \n",
      "epoch: 32 [709929/888800 79.88%] train loss: 1.4022931281942874e-05 \n",
      "epoch: 32 [711040/888800 80.00%] train loss: 1.4886559256410692e-05 \n",
      "epoch: 32 [712151/888800 80.12%] train loss: 1.2869895726907998e-05 \n",
      "epoch: 32 [713262/888800 80.25%] train loss: 1.4268509403336793e-05 \n",
      "epoch: 32 [714373/888800 80.38%] train loss: 1.4571052815881558e-05 \n",
      "epoch: 32 [715484/888800 80.50%] train loss: 1.4183972780301701e-05 \n",
      "epoch: 32 [716595/888800 80.62%] train loss: 1.445749330741819e-05 \n",
      "epoch: 32 [717706/888800 80.75%] train loss: 1.4795968127145898e-05 \n",
      "epoch: 32 [718817/888800 80.88%] train loss: 1.2742583749059122e-05 \n",
      "epoch: 32 [719928/888800 81.00%] train loss: 1.4816228031122591e-05 \n",
      "epoch: 32 [721039/888800 81.12%] train loss: 1.369977599097183e-05 \n",
      "epoch: 32 [722150/888800 81.25%] train loss: 1.286958377022529e-05 \n",
      "epoch: 32 [723261/888800 81.38%] train loss: 1.4273421584221069e-05 \n",
      "epoch: 32 [724372/888800 81.50%] train loss: 1.4583264601242263e-05 \n",
      "epoch: 32 [725483/888800 81.62%] train loss: 1.5366895240731537e-05 \n",
      "epoch: 32 [726594/888800 81.75%] train loss: 1.4878904039505869e-05 \n",
      "epoch: 32 [727705/888800 81.88%] train loss: 1.4351004210766405e-05 \n",
      "epoch: 32 [728816/888800 82.00%] train loss: 1.5257214727171231e-05 \n",
      "epoch: 32 [729927/888800 82.12%] train loss: 1.3656534065376036e-05 \n",
      "epoch: 32 [731038/888800 82.25%] train loss: 1.4556000678567216e-05 \n",
      "epoch: 32 [732149/888800 82.38%] train loss: 1.5213931874313857e-05 \n",
      "epoch: 32 [733260/888800 82.50%] train loss: 1.4849845683784224e-05 \n",
      "epoch: 32 [734371/888800 82.62%] train loss: 1.3901882084610406e-05 \n",
      "epoch: 32 [735482/888800 82.75%] train loss: 1.4540740266966168e-05 \n",
      "epoch: 32 [736593/888800 82.88%] train loss: 1.3833521734341048e-05 \n",
      "epoch: 32 [737704/888800 83.00%] train loss: 1.482062361901626e-05 \n",
      "epoch: 32 [738815/888800 83.12%] train loss: 1.4802812074776739e-05 \n",
      "epoch: 32 [739926/888800 83.25%] train loss: 1.3561490959546063e-05 \n",
      "epoch: 32 [741037/888800 83.38%] train loss: 1.4408434253709856e-05 \n",
      "epoch: 32 [742148/888800 83.50%] train loss: 1.4159842066874262e-05 \n",
      "epoch: 32 [743259/888800 83.62%] train loss: 1.2955302736372687e-05 \n",
      "epoch: 32 [744370/888800 83.75%] train loss: 1.3683251381735317e-05 \n",
      "epoch: 32 [745481/888800 83.88%] train loss: 1.359492125629913e-05 \n",
      "epoch: 32 [746592/888800 84.00%] train loss: 1.5003451153461356e-05 \n",
      "epoch: 32 [747703/888800 84.12%] train loss: 1.509122557763476e-05 \n",
      "epoch: 32 [748814/888800 84.25%] train loss: 1.3546512491302565e-05 \n",
      "epoch: 32 [749925/888800 84.38%] train loss: 1.3268216207507066e-05 \n",
      "epoch: 32 [751036/888800 84.50%] train loss: 1.3925467101216782e-05 \n",
      "epoch: 32 [752147/888800 84.62%] train loss: 1.3791224773740396e-05 \n",
      "epoch: 32 [753258/888800 84.75%] train loss: 1.414109647157602e-05 \n",
      "epoch: 32 [754369/888800 84.88%] train loss: 1.3797191058984026e-05 \n",
      "epoch: 32 [755480/888800 85.00%] train loss: 1.535380033601541e-05 \n",
      "epoch: 32 [756591/888800 85.12%] train loss: 1.2889078789157793e-05 \n",
      "epoch: 32 [757702/888800 85.25%] train loss: 1.434640489605954e-05 \n",
      "epoch: 32 [758813/888800 85.38%] train loss: 1.4883245967212133e-05 \n",
      "epoch: 32 [759924/888800 85.50%] train loss: 1.646437158342451e-05 \n",
      "epoch: 32 [761035/888800 85.62%] train loss: 1.3511890756490175e-05 \n",
      "epoch: 32 [762146/888800 85.75%] train loss: 1.5747717043268494e-05 \n",
      "epoch: 32 [763257/888800 85.88%] train loss: 1.6676351151545532e-05 \n",
      "epoch: 32 [764368/888800 86.00%] train loss: 1.420495846105041e-05 \n",
      "epoch: 32 [765479/888800 86.12%] train loss: 1.5792276826687157e-05 \n",
      "epoch: 32 [766590/888800 86.25%] train loss: 1.3329389730643015e-05 \n",
      "epoch: 32 [767701/888800 86.38%] train loss: 1.4807241313974373e-05 \n",
      "epoch: 32 [768812/888800 86.50%] train loss: 1.3934493836131878e-05 \n",
      "epoch: 32 [769923/888800 86.62%] train loss: 1.4269255188992247e-05 \n",
      "epoch: 32 [771034/888800 86.75%] train loss: 1.544290716992691e-05 \n",
      "epoch: 32 [772145/888800 86.88%] train loss: 1.4074327737034764e-05 \n",
      "epoch: 32 [773256/888800 87.00%] train loss: 1.6918802430154756e-05 \n",
      "epoch: 32 [774367/888800 87.12%] train loss: 1.4891239516146015e-05 \n",
      "epoch: 32 [775478/888800 87.25%] train loss: 1.518778117315378e-05 \n",
      "epoch: 32 [776589/888800 87.38%] train loss: 1.3075260540063027e-05 \n",
      "epoch: 32 [777700/888800 87.50%] train loss: 1.664623232500162e-05 \n",
      "epoch: 32 [778811/888800 87.62%] train loss: 1.4825557627773378e-05 \n",
      "epoch: 32 [779922/888800 87.75%] train loss: 1.3852432857675012e-05 \n",
      "epoch: 32 [781033/888800 87.88%] train loss: 1.5139427887334023e-05 \n",
      "epoch: 32 [782144/888800 88.00%] train loss: 1.5817402527318336e-05 \n",
      "epoch: 32 [783255/888800 88.12%] train loss: 1.6656926163705066e-05 \n",
      "epoch: 32 [784366/888800 88.25%] train loss: 1.306087779084919e-05 \n",
      "epoch: 32 [785477/888800 88.38%] train loss: 1.51980511873262e-05 \n",
      "epoch: 32 [786588/888800 88.50%] train loss: 1.3766776646662038e-05 \n",
      "epoch: 32 [787699/888800 88.62%] train loss: 1.4905679563526064e-05 \n",
      "epoch: 32 [788810/888800 88.75%] train loss: 1.4416562407859601e-05 \n",
      "epoch: 32 [789921/888800 88.88%] train loss: 1.494980460847728e-05 \n",
      "epoch: 32 [791032/888800 89.00%] train loss: 1.4671571989310905e-05 \n",
      "epoch: 32 [792143/888800 89.12%] train loss: 1.3158629371901043e-05 \n",
      "epoch: 32 [793254/888800 89.25%] train loss: 1.508713739895029e-05 \n",
      "epoch: 32 [794365/888800 89.38%] train loss: 1.4715989891556092e-05 \n",
      "epoch: 32 [795476/888800 89.50%] train loss: 1.5640211131540127e-05 \n",
      "epoch: 32 [796587/888800 89.62%] train loss: 1.410811091773212e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 [797698/888800 89.75%] train loss: 1.5002306099631824e-05 \n",
      "epoch: 32 [798809/888800 89.88%] train loss: 1.5520961824222468e-05 \n",
      "epoch: 32 [799920/888800 90.00%] train loss: 1.4530621228914242e-05 \n",
      "epoch: 32 [801031/888800 90.12%] train loss: 1.4288943020801526e-05 \n",
      "epoch: 32 [802142/888800 90.25%] train loss: 1.379404329782119e-05 \n",
      "epoch: 32 [803253/888800 90.38%] train loss: 1.525805510027567e-05 \n",
      "epoch: 32 [804364/888800 90.50%] train loss: 1.2883943782071583e-05 \n",
      "epoch: 32 [805475/888800 90.62%] train loss: 1.363423143629916e-05 \n",
      "epoch: 32 [806586/888800 90.75%] train loss: 1.4886602002661675e-05 \n",
      "epoch: 32 [807697/888800 90.88%] train loss: 1.5020143109722994e-05 \n",
      "epoch: 32 [808808/888800 91.00%] train loss: 1.4205608749762177e-05 \n",
      "epoch: 32 [809919/888800 91.12%] train loss: 1.3991309060656931e-05 \n",
      "epoch: 32 [811030/888800 91.25%] train loss: 1.2964823326910846e-05 \n",
      "epoch: 32 [812141/888800 91.38%] train loss: 1.4260532225307543e-05 \n",
      "epoch: 32 [813252/888800 91.50%] train loss: 1.4040027963346802e-05 \n",
      "epoch: 32 [814363/888800 91.62%] train loss: 1.494072512286948e-05 \n",
      "epoch: 32 [815474/888800 91.75%] train loss: 1.4540801203111187e-05 \n",
      "epoch: 32 [816585/888800 91.88%] train loss: 1.3827898328599986e-05 \n",
      "epoch: 32 [817696/888800 92.00%] train loss: 1.4641142115578987e-05 \n",
      "epoch: 32 [818807/888800 92.12%] train loss: 1.383609287586296e-05 \n",
      "epoch: 32 [819918/888800 92.25%] train loss: 1.4592204024665989e-05 \n",
      "epoch: 32 [821029/888800 92.38%] train loss: 1.368799257761566e-05 \n",
      "epoch: 32 [822140/888800 92.50%] train loss: 1.4280784853326622e-05 \n",
      "epoch: 32 [823251/888800 92.62%] train loss: 1.4317174645839259e-05 \n",
      "epoch: 32 [824362/888800 92.75%] train loss: 1.4829368410573807e-05 \n",
      "epoch: 32 [825473/888800 92.88%] train loss: 1.4916877262294292e-05 \n",
      "epoch: 32 [826584/888800 93.00%] train loss: 1.3582051906269044e-05 \n",
      "epoch: 32 [827695/888800 93.12%] train loss: 1.4079227184993215e-05 \n",
      "epoch: 32 [828806/888800 93.25%] train loss: 1.509032790636411e-05 \n",
      "epoch: 32 [829917/888800 93.38%] train loss: 1.3454419786285143e-05 \n",
      "epoch: 32 [831028/888800 93.50%] train loss: 1.4016370187164284e-05 \n",
      "epoch: 32 [832139/888800 93.62%] train loss: 1.4015728993399534e-05 \n",
      "epoch: 32 [833250/888800 93.75%] train loss: 1.4643408576375805e-05 \n",
      "epoch: 32 [834361/888800 93.88%] train loss: 1.5458936104550958e-05 \n",
      "epoch: 32 [835472/888800 94.00%] train loss: 1.4815039321547374e-05 \n",
      "epoch: 32 [836583/888800 94.12%] train loss: 1.361711292702239e-05 \n",
      "epoch: 32 [837694/888800 94.25%] train loss: 1.2761750440404285e-05 \n",
      "epoch: 32 [838805/888800 94.38%] train loss: 1.5110655112948734e-05 \n",
      "epoch: 32 [839916/888800 94.50%] train loss: 1.6079782653832808e-05 \n",
      "epoch: 32 [841027/888800 94.62%] train loss: 1.3415346984402277e-05 \n",
      "epoch: 32 [842138/888800 94.75%] train loss: 1.3735711945628282e-05 \n",
      "epoch: 32 [843249/888800 94.88%] train loss: 1.47504160850076e-05 \n",
      "epoch: 32 [844360/888800 95.00%] train loss: 1.3634977221954614e-05 \n",
      "epoch: 32 [845471/888800 95.12%] train loss: 1.4405112779058982e-05 \n",
      "epoch: 32 [846582/888800 95.25%] train loss: 1.462295858800644e-05 \n",
      "epoch: 32 [847693/888800 95.38%] train loss: 1.4679738342238124e-05 \n",
      "epoch: 32 [848804/888800 95.50%] train loss: 1.3030371519562323e-05 \n",
      "epoch: 32 [849915/888800 95.62%] train loss: 1.3806053175358102e-05 \n",
      "epoch: 32 [851026/888800 95.75%] train loss: 1.3658283023687545e-05 \n",
      "epoch: 32 [852137/888800 95.88%] train loss: 1.557496034365613e-05 \n",
      "epoch: 32 [853248/888800 96.00%] train loss: 1.3701485841011163e-05 \n",
      "epoch: 32 [854359/888800 96.12%] train loss: 1.4583562915504444e-05 \n",
      "epoch: 32 [855470/888800 96.25%] train loss: 1.4540998563461471e-05 \n",
      "epoch: 32 [856581/888800 96.38%] train loss: 1.4612201994168572e-05 \n",
      "epoch: 32 [857692/888800 96.50%] train loss: 1.6101552319014445e-05 \n",
      "epoch: 32 [858803/888800 96.62%] train loss: 1.4518986972689163e-05 \n",
      "epoch: 32 [859914/888800 96.75%] train loss: 1.5235375030897558e-05 \n",
      "epoch: 32 [861025/888800 96.88%] train loss: 1.54408498929115e-05 \n",
      "epoch: 32 [862136/888800 97.00%] train loss: 1.4707664377056062e-05 \n",
      "epoch: 32 [863247/888800 97.12%] train loss: 1.4195938092598226e-05 \n",
      "epoch: 32 [864358/888800 97.25%] train loss: 1.4898311746947002e-05 \n",
      "epoch: 32 [865469/888800 97.38%] train loss: 1.4050951904209796e-05 \n",
      "epoch: 32 [866580/888800 97.50%] train loss: 1.4641675079474226e-05 \n",
      "epoch: 32 [867691/888800 97.62%] train loss: 1.539563891128637e-05 \n",
      "epoch: 32 [868802/888800 97.75%] train loss: 1.3708308870263863e-05 \n",
      "epoch: 32 [869913/888800 97.88%] train loss: 1.43504375955672e-05 \n",
      "epoch: 32 [871024/888800 98.00%] train loss: 1.3942786608822644e-05 \n",
      "epoch: 32 [872135/888800 98.12%] train loss: 1.5679735952289775e-05 \n",
      "epoch: 32 [873246/888800 98.25%] train loss: 1.5032530427561142e-05 \n",
      "epoch: 32 [874357/888800 98.38%] train loss: 1.3881791346648242e-05 \n",
      "epoch: 32 [875468/888800 98.50%] train loss: 1.3825242604070809e-05 \n",
      "epoch: 32 [876579/888800 98.62%] train loss: 1.5595302102155983e-05 \n",
      "epoch: 32 [877690/888800 98.75%] train loss: 1.3563016182160936e-05 \n",
      "epoch: 32 [878801/888800 98.88%] train loss: 1.6085245079011656e-05 \n",
      "epoch: 32 [879912/888800 99.00%] train loss: 1.3479829249263275e-05 \n",
      "epoch: 32 [881023/888800 99.12%] train loss: 1.4361465218826197e-05 \n",
      "epoch: 32 [882134/888800 99.25%] train loss: 1.4043630471860524e-05 \n",
      "epoch: 32 [883245/888800 99.38%] train loss: 1.3839295206707902e-05 \n",
      "epoch: 32 [884356/888800 99.50%] train loss: 1.3651655535795726e-05 \n",
      "epoch: 32 [885467/888800 99.62%] train loss: 1.4023389667272568e-05 \n",
      "epoch: 32 [886578/888800 99.75%] train loss: 1.5359495591837913e-05 \n",
      "epoch: 32 [887689/888800 99.88%] train loss: 1.450303170713596e-05 \n",
      "epoch: 33 [0/888800 0.00%] train loss: 1.5530384189332835e-05 \n",
      "epoch: 33 [1111/888800 0.12%] train loss: 1.3778911124973092e-05 \n",
      "epoch: 33 [2222/888800 0.25%] train loss: 1.4013596228323877e-05 \n",
      "epoch: 33 [3333/888800 0.38%] train loss: 1.4060680769034661e-05 \n",
      "epoch: 33 [4444/888800 0.50%] train loss: 1.3943373232905287e-05 \n",
      "epoch: 33 [5555/888800 0.62%] train loss: 1.4160577848087996e-05 \n",
      "epoch: 33 [6666/888800 0.75%] train loss: 1.4563063814421184e-05 \n",
      "epoch: 33 [7777/888800 0.88%] train loss: 1.450989566365024e-05 \n",
      "epoch: 33 [8888/888800 1.00%] train loss: 1.5168696336331777e-05 \n",
      "epoch: 33 [9999/888800 1.12%] train loss: 1.4807300431129988e-05 \n",
      "epoch: 33 [11110/888800 1.25%] train loss: 1.269967106054537e-05 \n",
      "epoch: 33 [12221/888800 1.38%] train loss: 1.5072675523697399e-05 \n",
      "epoch: 33 [13332/888800 1.50%] train loss: 1.3629129171022214e-05 \n",
      "epoch: 33 [14443/888800 1.62%] train loss: 1.3839616258337628e-05 \n",
      "epoch: 33 [15554/888800 1.75%] train loss: 1.4318812645797152e-05 \n",
      "epoch: 33 [16665/888800 1.88%] train loss: 1.3971617590868846e-05 \n",
      "epoch: 33 [17776/888800 2.00%] train loss: 1.3523201232601423e-05 \n",
      "epoch: 33 [18887/888800 2.12%] train loss: 1.4739158359589055e-05 \n",
      "epoch: 33 [19998/888800 2.25%] train loss: 1.4028845725988504e-05 \n",
      "epoch: 33 [21109/888800 2.38%] train loss: 1.4498558812192641e-05 \n",
      "epoch: 33 [22220/888800 2.50%] train loss: 1.3815408237860538e-05 \n",
      "epoch: 33 [23331/888800 2.62%] train loss: 1.461024658055976e-05 \n",
      "epoch: 33 [24442/888800 2.75%] train loss: 1.3542147826228756e-05 \n",
      "epoch: 33 [25553/888800 2.88%] train loss: 1.465274726797361e-05 \n",
      "epoch: 33 [26664/888800 3.00%] train loss: 1.469527978770202e-05 \n",
      "epoch: 33 [27775/888800 3.12%] train loss: 1.3795138329442125e-05 \n",
      "epoch: 33 [28886/888800 3.25%] train loss: 1.3444275282381568e-05 \n",
      "epoch: 33 [29997/888800 3.38%] train loss: 1.453317963751033e-05 \n",
      "epoch: 33 [31108/888800 3.50%] train loss: 1.420193711965112e-05 \n",
      "epoch: 33 [32219/888800 3.62%] train loss: 1.3866119843441993e-05 \n",
      "epoch: 33 [33330/888800 3.75%] train loss: 1.4398998246178962e-05 \n",
      "epoch: 33 [34441/888800 3.88%] train loss: 1.448428156436421e-05 \n",
      "epoch: 33 [35552/888800 4.00%] train loss: 1.3756613043369725e-05 \n",
      "epoch: 33 [36663/888800 4.12%] train loss: 1.4161927538225427e-05 \n",
      "epoch: 33 [37774/888800 4.25%] train loss: 1.3416078218142502e-05 \n",
      "epoch: 33 [38885/888800 4.38%] train loss: 1.5339344827225432e-05 \n",
      "epoch: 33 [39996/888800 4.50%] train loss: 1.4363500667968765e-05 \n",
      "epoch: 33 [41107/888800 4.62%] train loss: 1.4679293599328957e-05 \n",
      "epoch: 33 [42218/888800 4.75%] train loss: 1.5225648894556798e-05 \n",
      "epoch: 33 [43329/888800 4.88%] train loss: 1.4813875168329105e-05 \n",
      "epoch: 33 [44440/888800 5.00%] train loss: 1.291120224777842e-05 \n",
      "epoch: 33 [45551/888800 5.12%] train loss: 1.3199248314776924e-05 \n",
      "epoch: 33 [46662/888800 5.25%] train loss: 1.3495299754140433e-05 \n",
      "epoch: 33 [47773/888800 5.38%] train loss: 1.3665408914675936e-05 \n",
      "epoch: 33 [48884/888800 5.50%] train loss: 1.4820261640124954e-05 \n",
      "epoch: 33 [49995/888800 5.62%] train loss: 1.565695674798917e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [51106/888800 5.75%] train loss: 1.4126731912256218e-05 \n",
      "epoch: 33 [52217/888800 5.88%] train loss: 1.3708628102904186e-05 \n",
      "epoch: 33 [53328/888800 6.00%] train loss: 1.4832155102340039e-05 \n",
      "epoch: 33 [54439/888800 6.12%] train loss: 1.541738492960576e-05 \n",
      "epoch: 33 [55550/888800 6.25%] train loss: 1.493361469329102e-05 \n",
      "epoch: 33 [56661/888800 6.38%] train loss: 1.4629815268563107e-05 \n",
      "epoch: 33 [57772/888800 6.50%] train loss: 1.5474803149118088e-05 \n",
      "epoch: 33 [58883/888800 6.62%] train loss: 1.4579438357031904e-05 \n",
      "epoch: 33 [59994/888800 6.75%] train loss: 1.629700454941485e-05 \n",
      "epoch: 33 [61105/888800 6.88%] train loss: 1.37553179229144e-05 \n",
      "epoch: 33 [62216/888800 7.00%] train loss: 1.4554887457052246e-05 \n",
      "epoch: 33 [63327/888800 7.12%] train loss: 1.4747073691978585e-05 \n",
      "epoch: 33 [64438/888800 7.25%] train loss: 1.3978505194245372e-05 \n",
      "epoch: 33 [65549/888800 7.38%] train loss: 1.4008895050210413e-05 \n",
      "epoch: 33 [66660/888800 7.50%] train loss: 1.4069381904846523e-05 \n",
      "epoch: 33 [67771/888800 7.62%] train loss: 1.4485426618193742e-05 \n",
      "epoch: 33 [68882/888800 7.75%] train loss: 1.4547788850904908e-05 \n",
      "epoch: 33 [69993/888800 7.88%] train loss: 1.3712347936234437e-05 \n",
      "epoch: 33 [71104/888800 8.00%] train loss: 1.4407612979994155e-05 \n",
      "epoch: 33 [72215/888800 8.12%] train loss: 1.4031391401658766e-05 \n",
      "epoch: 33 [73326/888800 8.25%] train loss: 1.401182271365542e-05 \n",
      "epoch: 33 [74437/888800 8.38%] train loss: 1.3962736375106033e-05 \n",
      "epoch: 33 [75548/888800 8.50%] train loss: 1.5768489902256988e-05 \n",
      "epoch: 33 [76659/888800 8.62%] train loss: 1.53075743583031e-05 \n",
      "epoch: 33 [77770/888800 8.75%] train loss: 1.415073529642541e-05 \n",
      "epoch: 33 [78881/888800 8.88%] train loss: 1.4825654943706468e-05 \n",
      "epoch: 33 [79992/888800 9.00%] train loss: 1.4159795682644472e-05 \n",
      "epoch: 33 [81103/888800 9.12%] train loss: 1.528541906736791e-05 \n",
      "epoch: 33 [82214/888800 9.25%] train loss: 1.5564117347821593e-05 \n",
      "epoch: 33 [83325/888800 9.38%] train loss: 1.4329797522805165e-05 \n",
      "epoch: 33 [84436/888800 9.50%] train loss: 1.5081194760568906e-05 \n",
      "epoch: 33 [85547/888800 9.62%] train loss: 1.3850301002094056e-05 \n",
      "epoch: 33 [86658/888800 9.75%] train loss: 1.5909716239548288e-05 \n",
      "epoch: 33 [87769/888800 9.88%] train loss: 1.4380623724719044e-05 \n",
      "epoch: 33 [88880/888800 10.00%] train loss: 1.7198290152009577e-05 \n",
      "epoch: 33 [89991/888800 10.12%] train loss: 1.5041475307953078e-05 \n",
      "epoch: 33 [91102/888800 10.25%] train loss: 1.608084494364448e-05 \n",
      "epoch: 33 [92213/888800 10.38%] train loss: 1.581314609211404e-05 \n",
      "epoch: 33 [93324/888800 10.50%] train loss: 1.59396804519929e-05 \n",
      "epoch: 33 [94435/888800 10.62%] train loss: 1.800351674319245e-05 \n",
      "epoch: 33 [95546/888800 10.75%] train loss: 1.3687912542081904e-05 \n",
      "epoch: 33 [96657/888800 10.88%] train loss: 1.7058657249435782e-05 \n",
      "epoch: 33 [97768/888800 11.00%] train loss: 1.4944894246582408e-05 \n",
      "epoch: 33 [98879/888800 11.12%] train loss: 1.643208997847978e-05 \n",
      "epoch: 33 [99990/888800 11.25%] train loss: 1.439082552678883e-05 \n",
      "epoch: 33 [101101/888800 11.38%] train loss: 1.5139851711865049e-05 \n",
      "epoch: 33 [102212/888800 11.50%] train loss: 1.411222001479473e-05 \n",
      "epoch: 33 [103323/888800 11.62%] train loss: 1.4815027498116251e-05 \n",
      "epoch: 33 [104434/888800 11.75%] train loss: 1.481262643210357e-05 \n",
      "epoch: 33 [105545/888800 11.88%] train loss: 1.5203275324893184e-05 \n",
      "epoch: 33 [106656/888800 12.00%] train loss: 1.40439260576386e-05 \n",
      "epoch: 33 [107767/888800 12.12%] train loss: 1.299885752814589e-05 \n",
      "epoch: 33 [108878/888800 12.25%] train loss: 1.4541827113134786e-05 \n",
      "epoch: 33 [109989/888800 12.38%] train loss: 1.3781337656837422e-05 \n",
      "epoch: 33 [111100/888800 12.50%] train loss: 1.541306119179353e-05 \n",
      "epoch: 33 [112211/888800 12.62%] train loss: 1.5533123587374575e-05 \n",
      "epoch: 33 [113322/888800 12.75%] train loss: 1.4385163922270294e-05 \n",
      "epoch: 33 [114433/888800 12.88%] train loss: 1.4545597878168337e-05 \n",
      "epoch: 33 [115544/888800 13.00%] train loss: 1.4467136679741088e-05 \n",
      "epoch: 33 [116655/888800 13.12%] train loss: 1.5057509699545335e-05 \n",
      "epoch: 33 [117766/888800 13.25%] train loss: 1.705848080746364e-05 \n",
      "epoch: 33 [118877/888800 13.38%] train loss: 1.3917178875999525e-05 \n",
      "epoch: 33 [119988/888800 13.50%] train loss: 1.8819815522874705e-05 \n",
      "epoch: 33 [121099/888800 13.62%] train loss: 1.3424537428363692e-05 \n",
      "epoch: 33 [122210/888800 13.75%] train loss: 1.5755493222968653e-05 \n",
      "epoch: 33 [123321/888800 13.88%] train loss: 1.5004369743110146e-05 \n",
      "epoch: 33 [124432/888800 14.00%] train loss: 1.413844438502565e-05 \n",
      "epoch: 33 [125543/888800 14.12%] train loss: 1.3738494999415707e-05 \n",
      "epoch: 33 [126654/888800 14.25%] train loss: 1.636468732613139e-05 \n",
      "epoch: 33 [127765/888800 14.38%] train loss: 1.4043753253645264e-05 \n",
      "epoch: 33 [128876/888800 14.50%] train loss: 1.6020334442146122e-05 \n",
      "epoch: 33 [129987/888800 14.62%] train loss: 1.727055678202305e-05 \n",
      "epoch: 33 [131098/888800 14.75%] train loss: 1.4210140761861112e-05 \n",
      "epoch: 33 [132209/888800 14.88%] train loss: 1.5999168681446463e-05 \n",
      "epoch: 33 [133320/888800 15.00%] train loss: 1.4178418496157974e-05 \n",
      "epoch: 33 [134431/888800 15.12%] train loss: 1.5593153875670396e-05 \n",
      "epoch: 33 [135542/888800 15.25%] train loss: 1.3954447240394074e-05 \n",
      "epoch: 33 [136653/888800 15.38%] train loss: 1.527014683233574e-05 \n",
      "epoch: 33 [137764/888800 15.50%] train loss: 1.4979680599935818e-05 \n",
      "epoch: 33 [138875/888800 15.62%] train loss: 1.4969960830057971e-05 \n",
      "epoch: 33 [139986/888800 15.75%] train loss: 1.549054286442697e-05 \n",
      "epoch: 33 [141097/888800 15.88%] train loss: 1.4756323253095616e-05 \n",
      "epoch: 33 [142208/888800 16.00%] train loss: 1.3501336979970802e-05 \n",
      "epoch: 33 [143319/888800 16.12%] train loss: 1.4022778486832976e-05 \n",
      "epoch: 33 [144430/888800 16.25%] train loss: 1.3738644156546798e-05 \n",
      "epoch: 33 [145541/888800 16.38%] train loss: 1.420323496859055e-05 \n",
      "epoch: 33 [146652/888800 16.50%] train loss: 1.3593769836006686e-05 \n",
      "epoch: 33 [147763/888800 16.62%] train loss: 1.3608069821202662e-05 \n",
      "epoch: 33 [148874/888800 16.75%] train loss: 1.4212715541361831e-05 \n",
      "epoch: 33 [149985/888800 16.88%] train loss: 1.4319640285975765e-05 \n",
      "epoch: 33 [151096/888800 17.00%] train loss: 1.5261870430549607e-05 \n",
      "epoch: 33 [152207/888800 17.12%] train loss: 1.3735459106101189e-05 \n",
      "epoch: 33 [153318/888800 17.25%] train loss: 1.4223809557734057e-05 \n",
      "epoch: 33 [154429/888800 17.38%] train loss: 1.4416880731005222e-05 \n",
      "epoch: 33 [155540/888800 17.50%] train loss: 1.2974173841939773e-05 \n",
      "epoch: 33 [156651/888800 17.62%] train loss: 1.3546095033234451e-05 \n",
      "epoch: 33 [157762/888800 17.75%] train loss: 1.3726332326768897e-05 \n",
      "epoch: 33 [158873/888800 17.88%] train loss: 1.4041297617950477e-05 \n",
      "epoch: 33 [159984/888800 18.00%] train loss: 1.449268438591389e-05 \n",
      "epoch: 33 [161095/888800 18.12%] train loss: 1.4328593351820018e-05 \n",
      "epoch: 33 [162206/888800 18.25%] train loss: 1.386607709719101e-05 \n",
      "epoch: 33 [163317/888800 18.38%] train loss: 1.420255739503773e-05 \n",
      "epoch: 33 [164428/888800 18.50%] train loss: 1.4774735973333009e-05 \n",
      "epoch: 33 [165539/888800 18.62%] train loss: 1.319592774962075e-05 \n",
      "epoch: 33 [166650/888800 18.75%] train loss: 1.3324485735211056e-05 \n",
      "epoch: 33 [167761/888800 18.88%] train loss: 1.3683982615475543e-05 \n",
      "epoch: 33 [168872/888800 19.00%] train loss: 1.5002204236225225e-05 \n",
      "epoch: 33 [169983/888800 19.12%] train loss: 1.4249779269448482e-05 \n",
      "epoch: 33 [171094/888800 19.25%] train loss: 1.4608694073103834e-05 \n",
      "epoch: 33 [172205/888800 19.38%] train loss: 1.4447484318225179e-05 \n",
      "epoch: 33 [173316/888800 19.50%] train loss: 1.3473492799676023e-05 \n",
      "epoch: 33 [174427/888800 19.62%] train loss: 1.4616909538744949e-05 \n",
      "epoch: 33 [175538/888800 19.75%] train loss: 1.4535358786815777e-05 \n",
      "epoch: 33 [176649/888800 19.88%] train loss: 1.4347873730002902e-05 \n",
      "epoch: 33 [177760/888800 20.00%] train loss: 1.4321297385322396e-05 \n",
      "epoch: 33 [178871/888800 20.12%] train loss: 1.3760768524662126e-05 \n",
      "epoch: 33 [179982/888800 20.25%] train loss: 1.4433721844397951e-05 \n",
      "epoch: 33 [181093/888800 20.38%] train loss: 1.4871258827042766e-05 \n",
      "epoch: 33 [182204/888800 20.50%] train loss: 1.3489227058016695e-05 \n",
      "epoch: 33 [183315/888800 20.62%] train loss: 1.4706634829053655e-05 \n",
      "epoch: 33 [184426/888800 20.75%] train loss: 1.4246135833673179e-05 \n",
      "epoch: 33 [185537/888800 20.88%] train loss: 1.6812100511742756e-05 \n",
      "epoch: 33 [186648/888800 21.00%] train loss: 1.2293709005462006e-05 \n",
      "epoch: 33 [187759/888800 21.12%] train loss: 1.304743182117818e-05 \n",
      "epoch: 33 [188870/888800 21.25%] train loss: 1.491719922341872e-05 \n",
      "epoch: 33 [189981/888800 21.38%] train loss: 1.509055437054485e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [191092/888800 21.50%] train loss: 1.477926161896903e-05 \n",
      "epoch: 33 [192203/888800 21.62%] train loss: 1.454228004149627e-05 \n",
      "epoch: 33 [193314/888800 21.75%] train loss: 1.3633479284180794e-05 \n",
      "epoch: 33 [194425/888800 21.88%] train loss: 1.547633837617468e-05 \n",
      "epoch: 33 [195536/888800 22.00%] train loss: 1.4055541214474943e-05 \n",
      "epoch: 33 [196647/888800 22.12%] train loss: 1.6524803868378513e-05 \n",
      "epoch: 33 [197758/888800 22.25%] train loss: 1.5743004041723907e-05 \n",
      "epoch: 33 [198869/888800 22.38%] train loss: 1.5375266229966655e-05 \n",
      "epoch: 33 [199980/888800 22.50%] train loss: 1.4777975593460724e-05 \n",
      "epoch: 33 [201091/888800 22.62%] train loss: 1.349652393400902e-05 \n",
      "epoch: 33 [202202/888800 22.75%] train loss: 1.7064143321476877e-05 \n",
      "epoch: 33 [203313/888800 22.88%] train loss: 1.3328822205949109e-05 \n",
      "epoch: 33 [204424/888800 23.00%] train loss: 1.4855942026770208e-05 \n",
      "epoch: 33 [205535/888800 23.12%] train loss: 1.4093566278461367e-05 \n",
      "epoch: 33 [206646/888800 23.25%] train loss: 1.592615262779873e-05 \n",
      "epoch: 33 [207757/888800 23.38%] train loss: 1.3814933481626213e-05 \n",
      "epoch: 33 [208868/888800 23.50%] train loss: 1.3855005818186328e-05 \n",
      "epoch: 33 [209979/888800 23.62%] train loss: 1.4016356544743758e-05 \n",
      "epoch: 33 [211090/888800 23.75%] train loss: 1.4428210306505207e-05 \n",
      "epoch: 33 [212201/888800 23.88%] train loss: 1.2453806448320393e-05 \n",
      "epoch: 33 [213312/888800 24.00%] train loss: 1.564800004416611e-05 \n",
      "epoch: 33 [214423/888800 24.12%] train loss: 1.4521049706672784e-05 \n",
      "epoch: 33 [215534/888800 24.25%] train loss: 1.5884092135820538e-05 \n",
      "epoch: 33 [216645/888800 24.38%] train loss: 1.5258168787113391e-05 \n",
      "epoch: 33 [217756/888800 24.50%] train loss: 1.4258061128202826e-05 \n",
      "epoch: 33 [218867/888800 24.62%] train loss: 1.4965313312131912e-05 \n",
      "epoch: 33 [219978/888800 24.75%] train loss: 1.3916236639488488e-05 \n",
      "epoch: 33 [221089/888800 24.88%] train loss: 1.4195245967130177e-05 \n",
      "epoch: 33 [222200/888800 25.00%] train loss: 1.4027131328475662e-05 \n",
      "epoch: 33 [223311/888800 25.12%] train loss: 1.2480250916269142e-05 \n",
      "epoch: 33 [224422/888800 25.25%] train loss: 1.4122282664175145e-05 \n",
      "epoch: 33 [225533/888800 25.38%] train loss: 1.3687650607607793e-05 \n",
      "epoch: 33 [226644/888800 25.50%] train loss: 1.4545166777679697e-05 \n",
      "epoch: 33 [227755/888800 25.62%] train loss: 1.3978835340822116e-05 \n",
      "epoch: 33 [228866/888800 25.75%] train loss: 1.2968635928700678e-05 \n",
      "epoch: 33 [229977/888800 25.88%] train loss: 1.558108488097787e-05 \n",
      "epoch: 33 [231088/888800 26.00%] train loss: 1.4694124729430769e-05 \n",
      "epoch: 33 [232199/888800 26.12%] train loss: 1.5821629858692177e-05 \n",
      "epoch: 33 [233310/888800 26.25%] train loss: 1.3659641808771994e-05 \n",
      "epoch: 33 [234421/888800 26.38%] train loss: 1.478087233408587e-05 \n",
      "epoch: 33 [235532/888800 26.50%] train loss: 1.4010582162882201e-05 \n",
      "epoch: 33 [236643/888800 26.62%] train loss: 1.4079485481488518e-05 \n",
      "epoch: 33 [237754/888800 26.75%] train loss: 1.551757668494247e-05 \n",
      "epoch: 33 [238865/888800 26.88%] train loss: 1.4057199223316275e-05 \n",
      "epoch: 33 [239976/888800 27.00%] train loss: 1.3485944691637997e-05 \n",
      "epoch: 33 [241087/888800 27.12%] train loss: 1.4393865058082156e-05 \n",
      "epoch: 33 [242198/888800 27.25%] train loss: 1.289338615606539e-05 \n",
      "epoch: 33 [243309/888800 27.38%] train loss: 1.3514196325559169e-05 \n",
      "epoch: 33 [244420/888800 27.50%] train loss: 1.56155219883658e-05 \n",
      "epoch: 33 [245531/888800 27.62%] train loss: 1.4629886209149845e-05 \n",
      "epoch: 33 [246642/888800 27.75%] train loss: 1.4096257473283913e-05 \n",
      "epoch: 33 [247753/888800 27.88%] train loss: 1.5061028534546494e-05 \n",
      "epoch: 33 [248864/888800 28.00%] train loss: 1.3370380656851921e-05 \n",
      "epoch: 33 [249975/888800 28.12%] train loss: 1.3101604963594582e-05 \n",
      "epoch: 33 [251086/888800 28.25%] train loss: 1.5188992620096542e-05 \n",
      "epoch: 33 [252197/888800 28.38%] train loss: 1.4105168702371884e-05 \n",
      "epoch: 33 [253308/888800 28.50%] train loss: 1.4278683011070825e-05 \n",
      "epoch: 33 [254419/888800 28.62%] train loss: 1.4024588381289504e-05 \n",
      "epoch: 33 [255530/888800 28.75%] train loss: 1.2567516023409553e-05 \n",
      "epoch: 33 [256641/888800 28.88%] train loss: 1.4480629943136591e-05 \n",
      "epoch: 33 [257752/888800 29.00%] train loss: 1.4912797269062139e-05 \n",
      "epoch: 33 [258863/888800 29.12%] train loss: 1.547517422295641e-05 \n",
      "epoch: 33 [259974/888800 29.25%] train loss: 1.5716284906375222e-05 \n",
      "epoch: 33 [261085/888800 29.38%] train loss: 1.3454609870677814e-05 \n",
      "epoch: 33 [262196/888800 29.50%] train loss: 1.3562405911216047e-05 \n",
      "epoch: 33 [263307/888800 29.62%] train loss: 1.4423530956264585e-05 \n",
      "epoch: 33 [264418/888800 29.75%] train loss: 1.3963325727672782e-05 \n",
      "epoch: 33 [265529/888800 29.88%] train loss: 1.4879151422064751e-05 \n",
      "epoch: 33 [266640/888800 30.00%] train loss: 1.5061435988172889e-05 \n",
      "epoch: 33 [267751/888800 30.12%] train loss: 1.3684733858099207e-05 \n",
      "epoch: 33 [268862/888800 30.25%] train loss: 1.444051304133609e-05 \n",
      "epoch: 33 [269973/888800 30.38%] train loss: 1.5281475498341024e-05 \n",
      "epoch: 33 [271084/888800 30.50%] train loss: 1.436371348972898e-05 \n",
      "epoch: 33 [272195/888800 30.62%] train loss: 1.557370887894649e-05 \n",
      "epoch: 33 [273306/888800 30.75%] train loss: 1.4364387425302994e-05 \n",
      "epoch: 33 [274417/888800 30.88%] train loss: 1.6135845726239495e-05 \n",
      "epoch: 33 [275528/888800 31.00%] train loss: 1.4948112948331982e-05 \n",
      "epoch: 33 [276639/888800 31.12%] train loss: 1.4673814803245477e-05 \n",
      "epoch: 33 [277750/888800 31.25%] train loss: 1.5141816220420878e-05 \n",
      "epoch: 33 [278861/888800 31.38%] train loss: 1.4357238796947058e-05 \n",
      "epoch: 33 [279972/888800 31.50%] train loss: 1.5096159586391877e-05 \n",
      "epoch: 33 [281083/888800 31.62%] train loss: 1.375842111883685e-05 \n",
      "epoch: 33 [282194/888800 31.75%] train loss: 1.4630719306296669e-05 \n",
      "epoch: 33 [283305/888800 31.88%] train loss: 1.655108280829154e-05 \n",
      "epoch: 33 [284416/888800 32.00%] train loss: 1.533265458419919e-05 \n",
      "epoch: 33 [285527/888800 32.12%] train loss: 1.4411873962671962e-05 \n",
      "epoch: 33 [286638/888800 32.25%] train loss: 1.4089100659475662e-05 \n",
      "epoch: 33 [287749/888800 32.38%] train loss: 1.447687373001827e-05 \n",
      "epoch: 33 [288860/888800 32.50%] train loss: 1.3804768059344497e-05 \n",
      "epoch: 33 [289971/888800 32.62%] train loss: 1.3510182725440245e-05 \n",
      "epoch: 33 [291082/888800 32.75%] train loss: 1.4824545360170305e-05 \n",
      "epoch: 33 [292193/888800 32.88%] train loss: 1.5003944099589717e-05 \n",
      "epoch: 33 [293304/888800 33.00%] train loss: 1.368690482195234e-05 \n",
      "epoch: 33 [294415/888800 33.12%] train loss: 1.559613701829221e-05 \n",
      "epoch: 33 [295526/888800 33.25%] train loss: 1.4755995835002977e-05 \n",
      "epoch: 33 [296637/888800 33.38%] train loss: 1.4337876564241014e-05 \n",
      "epoch: 33 [297748/888800 33.50%] train loss: 1.3587864486908074e-05 \n",
      "epoch: 33 [298859/888800 33.62%] train loss: 1.4083232599659823e-05 \n",
      "epoch: 33 [299970/888800 33.75%] train loss: 1.385957784805214e-05 \n",
      "epoch: 33 [301081/888800 33.88%] train loss: 1.4382440895133186e-05 \n",
      "epoch: 33 [302192/888800 34.00%] train loss: 1.365638763672905e-05 \n",
      "epoch: 33 [303303/888800 34.12%] train loss: 1.3533733181247953e-05 \n",
      "epoch: 33 [304414/888800 34.25%] train loss: 1.4746857232239563e-05 \n",
      "epoch: 33 [305525/888800 34.38%] train loss: 1.3783926078758668e-05 \n",
      "epoch: 33 [306636/888800 34.50%] train loss: 1.4000422197568696e-05 \n",
      "epoch: 33 [307747/888800 34.62%] train loss: 1.4179595382302068e-05 \n",
      "epoch: 33 [308858/888800 34.75%] train loss: 1.4782042853767052e-05 \n",
      "epoch: 33 [309969/888800 34.88%] train loss: 1.3702891010325402e-05 \n",
      "epoch: 33 [311080/888800 35.00%] train loss: 1.2373553545330651e-05 \n",
      "epoch: 33 [312191/888800 35.12%] train loss: 1.4366411051014438e-05 \n",
      "epoch: 33 [313302/888800 35.25%] train loss: 1.4255571841204073e-05 \n",
      "epoch: 33 [314413/888800 35.38%] train loss: 1.3659165233548265e-05 \n",
      "epoch: 33 [315524/888800 35.50%] train loss: 1.4369947166414931e-05 \n",
      "epoch: 33 [316635/888800 35.62%] train loss: 1.2969526324013714e-05 \n",
      "epoch: 33 [317746/888800 35.75%] train loss: 1.3927329746366013e-05 \n",
      "epoch: 33 [318857/888800 35.88%] train loss: 1.3249221410660539e-05 \n",
      "epoch: 33 [319968/888800 36.00%] train loss: 1.3975578440295067e-05 \n",
      "epoch: 33 [321079/888800 36.12%] train loss: 1.3777067579212599e-05 \n",
      "epoch: 33 [322190/888800 36.25%] train loss: 1.3430176295514684e-05 \n",
      "epoch: 33 [323301/888800 36.38%] train loss: 1.4722795640409458e-05 \n",
      "epoch: 33 [324412/888800 36.50%] train loss: 1.4143744010652881e-05 \n",
      "epoch: 33 [325523/888800 36.62%] train loss: 1.3729407328355592e-05 \n",
      "epoch: 33 [326634/888800 36.75%] train loss: 1.3469245459418744e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [327745/888800 36.88%] train loss: 1.4422888853005134e-05 \n",
      "epoch: 33 [328856/888800 37.00%] train loss: 1.3847036825609393e-05 \n",
      "epoch: 33 [329967/888800 37.12%] train loss: 1.4889770682202652e-05 \n",
      "epoch: 33 [331078/888800 37.25%] train loss: 1.4589561942557339e-05 \n",
      "epoch: 33 [332189/888800 37.38%] train loss: 1.5055293260957114e-05 \n",
      "epoch: 33 [333300/888800 37.50%] train loss: 1.425005029886961e-05 \n",
      "epoch: 33 [334411/888800 37.62%] train loss: 1.4168365851219278e-05 \n",
      "epoch: 33 [335522/888800 37.75%] train loss: 1.4969400581321679e-05 \n",
      "epoch: 33 [336633/888800 37.88%] train loss: 1.4156653378449846e-05 \n",
      "epoch: 33 [337744/888800 38.00%] train loss: 1.4698864106321707e-05 \n",
      "epoch: 33 [338855/888800 38.12%] train loss: 1.3820644198858645e-05 \n",
      "epoch: 33 [339966/888800 38.25%] train loss: 1.3566069355874788e-05 \n",
      "epoch: 33 [341077/888800 38.38%] train loss: 1.311966116190888e-05 \n",
      "epoch: 33 [342188/888800 38.50%] train loss: 1.450897707400145e-05 \n",
      "epoch: 33 [343299/888800 38.62%] train loss: 1.426724065822782e-05 \n",
      "epoch: 33 [344410/888800 38.75%] train loss: 1.368938774248818e-05 \n",
      "epoch: 33 [345521/888800 38.88%] train loss: 1.4369826203619596e-05 \n",
      "epoch: 33 [346632/888800 39.00%] train loss: 1.393523325532442e-05 \n",
      "epoch: 33 [347743/888800 39.12%] train loss: 1.4157251825963613e-05 \n",
      "epoch: 33 [348854/888800 39.25%] train loss: 1.39373778438312e-05 \n",
      "epoch: 33 [349965/888800 39.38%] train loss: 1.2494821930886246e-05 \n",
      "epoch: 33 [351076/888800 39.50%] train loss: 1.3237073289928958e-05 \n",
      "epoch: 33 [352187/888800 39.62%] train loss: 1.369398978567915e-05 \n",
      "epoch: 33 [353298/888800 39.75%] train loss: 1.4413205462915357e-05 \n",
      "epoch: 33 [354409/888800 39.88%] train loss: 1.3566672350862063e-05 \n",
      "epoch: 33 [355520/888800 40.00%] train loss: 1.3745853721047752e-05 \n",
      "epoch: 33 [356631/888800 40.12%] train loss: 1.3003306776226964e-05 \n",
      "epoch: 33 [357742/888800 40.25%] train loss: 1.3294243217387702e-05 \n",
      "epoch: 33 [358853/888800 40.38%] train loss: 1.4749383808521088e-05 \n",
      "epoch: 33 [359964/888800 40.50%] train loss: 1.3942560144641902e-05 \n",
      "epoch: 33 [361075/888800 40.62%] train loss: 1.4207751519279554e-05 \n",
      "epoch: 33 [362186/888800 40.75%] train loss: 1.3283377484185621e-05 \n",
      "epoch: 33 [363297/888800 40.88%] train loss: 1.4153838492347859e-05 \n",
      "epoch: 33 [364408/888800 41.00%] train loss: 1.4861371710139792e-05 \n",
      "epoch: 33 [365519/888800 41.12%] train loss: 1.4350716810440645e-05 \n",
      "epoch: 33 [366630/888800 41.25%] train loss: 1.374326711811591e-05 \n",
      "epoch: 33 [367741/888800 41.38%] train loss: 1.3338095413928386e-05 \n",
      "epoch: 33 [368852/888800 41.50%] train loss: 1.590874308021739e-05 \n",
      "epoch: 33 [369963/888800 41.62%] train loss: 1.3533539458876476e-05 \n",
      "epoch: 33 [371074/888800 41.75%] train loss: 1.3794616279483307e-05 \n",
      "epoch: 33 [372185/888800 41.88%] train loss: 1.341170627711108e-05 \n",
      "epoch: 33 [373296/888800 42.00%] train loss: 1.5372492271126248e-05 \n",
      "epoch: 33 [374407/888800 42.12%] train loss: 1.5551733667962253e-05 \n",
      "epoch: 33 [375518/888800 42.25%] train loss: 1.448924740543589e-05 \n",
      "epoch: 33 [376629/888800 42.38%] train loss: 1.432269527867902e-05 \n",
      "epoch: 33 [377740/888800 42.50%] train loss: 1.3477671018335968e-05 \n",
      "epoch: 33 [378851/888800 42.62%] train loss: 1.4407168237084989e-05 \n",
      "epoch: 33 [379962/888800 42.75%] train loss: 1.5684569007134996e-05 \n",
      "epoch: 33 [381073/888800 42.88%] train loss: 1.3010499969823286e-05 \n",
      "epoch: 33 [382184/888800 43.00%] train loss: 1.4423828361032065e-05 \n",
      "epoch: 33 [383295/888800 43.12%] train loss: 1.450337003916502e-05 \n",
      "epoch: 33 [384406/888800 43.25%] train loss: 1.6492913346155547e-05 \n",
      "epoch: 33 [385517/888800 43.38%] train loss: 1.4692263903270941e-05 \n",
      "epoch: 33 [386628/888800 43.50%] train loss: 1.4705986359331291e-05 \n",
      "epoch: 33 [387739/888800 43.62%] train loss: 1.3738338566327002e-05 \n",
      "epoch: 33 [388850/888800 43.75%] train loss: 1.4940409528207965e-05 \n",
      "epoch: 33 [389961/888800 43.88%] train loss: 1.4479355741059408e-05 \n",
      "epoch: 33 [391072/888800 44.00%] train loss: 1.2399862498568837e-05 \n",
      "epoch: 33 [392183/888800 44.12%] train loss: 1.4229573025659192e-05 \n",
      "epoch: 33 [393294/888800 44.25%] train loss: 1.460392104490893e-05 \n",
      "epoch: 33 [394405/888800 44.38%] train loss: 1.4174140233080834e-05 \n",
      "epoch: 33 [395516/888800 44.50%] train loss: 1.4418751561606769e-05 \n",
      "epoch: 33 [396627/888800 44.62%] train loss: 1.524314757261891e-05 \n",
      "epoch: 33 [397738/888800 44.75%] train loss: 1.3869351278117392e-05 \n",
      "epoch: 33 [398849/888800 44.88%] train loss: 1.4298170754045714e-05 \n",
      "epoch: 33 [399960/888800 45.00%] train loss: 1.605480065336451e-05 \n",
      "epoch: 33 [401071/888800 45.12%] train loss: 1.4366003597388044e-05 \n",
      "epoch: 33 [402182/888800 45.25%] train loss: 1.3068486623524223e-05 \n",
      "epoch: 33 [403293/888800 45.38%] train loss: 1.5159505892370362e-05 \n",
      "epoch: 33 [404404/888800 45.50%] train loss: 1.4400143300008494e-05 \n",
      "epoch: 33 [405515/888800 45.62%] train loss: 1.5490226360270754e-05 \n",
      "epoch: 33 [406626/888800 45.75%] train loss: 1.3998565009387676e-05 \n",
      "epoch: 33 [407737/888800 45.88%] train loss: 1.486813653173158e-05 \n",
      "epoch: 33 [408848/888800 46.00%] train loss: 1.353815332549857e-05 \n",
      "epoch: 33 [409959/888800 46.12%] train loss: 1.3671075066667981e-05 \n",
      "epoch: 33 [411070/888800 46.25%] train loss: 1.6089903510874137e-05 \n",
      "epoch: 33 [412181/888800 46.38%] train loss: 1.4494072274828795e-05 \n",
      "epoch: 33 [413292/888800 46.50%] train loss: 1.552417961647734e-05 \n",
      "epoch: 33 [414403/888800 46.62%] train loss: 1.3832644981448539e-05 \n",
      "epoch: 33 [415514/888800 46.75%] train loss: 1.4604030184273142e-05 \n",
      "epoch: 33 [416625/888800 46.88%] train loss: 1.456800146115711e-05 \n",
      "epoch: 33 [417736/888800 47.00%] train loss: 1.4555655070580542e-05 \n",
      "epoch: 33 [418847/888800 47.12%] train loss: 1.3148785910743754e-05 \n",
      "epoch: 33 [419958/888800 47.25%] train loss: 1.6413507182733156e-05 \n",
      "epoch: 33 [421069/888800 47.38%] train loss: 1.4548001672665123e-05 \n",
      "epoch: 33 [422180/888800 47.50%] train loss: 1.438849631085759e-05 \n",
      "epoch: 33 [423291/888800 47.62%] train loss: 1.466379762860015e-05 \n",
      "epoch: 33 [424402/888800 47.75%] train loss: 1.584417259437032e-05 \n",
      "epoch: 33 [425513/888800 47.88%] train loss: 1.4360479326569475e-05 \n",
      "epoch: 33 [426624/888800 48.00%] train loss: 1.3089746971672866e-05 \n",
      "epoch: 33 [427735/888800 48.12%] train loss: 1.4239120901038405e-05 \n",
      "epoch: 33 [428846/888800 48.25%] train loss: 1.4334552361106034e-05 \n",
      "epoch: 33 [429957/888800 48.38%] train loss: 1.596431502548512e-05 \n",
      "epoch: 33 [431068/888800 48.50%] train loss: 1.4812972040090244e-05 \n",
      "epoch: 33 [432179/888800 48.62%] train loss: 1.3907104403187986e-05 \n",
      "epoch: 33 [433290/888800 48.75%] train loss: 1.4251200809667353e-05 \n",
      "epoch: 33 [434401/888800 48.88%] train loss: 1.3450367987388745e-05 \n",
      "epoch: 33 [435512/888800 49.00%] train loss: 1.4505204489978496e-05 \n",
      "epoch: 33 [436623/888800 49.12%] train loss: 1.5147715203056578e-05 \n",
      "epoch: 33 [437734/888800 49.25%] train loss: 1.3430260878521949e-05 \n",
      "epoch: 33 [438845/888800 49.38%] train loss: 1.3925628081778996e-05 \n",
      "epoch: 33 [439956/888800 49.50%] train loss: 1.3886787201045081e-05 \n",
      "epoch: 33 [441067/888800 49.62%] train loss: 1.3933837180957198e-05 \n",
      "epoch: 33 [442178/888800 49.75%] train loss: 1.4097786333877593e-05 \n",
      "epoch: 33 [443289/888800 49.88%] train loss: 1.4503900274576154e-05 \n",
      "epoch: 33 [444400/888800 50.00%] train loss: 1.411609810020309e-05 \n",
      "epoch: 33 [445511/888800 50.12%] train loss: 1.3651612789544743e-05 \n",
      "epoch: 33 [446622/888800 50.25%] train loss: 1.390329998685047e-05 \n",
      "epoch: 33 [447733/888800 50.38%] train loss: 1.3700388080906123e-05 \n",
      "epoch: 33 [448844/888800 50.50%] train loss: 1.4054476196179166e-05 \n",
      "epoch: 33 [449955/888800 50.62%] train loss: 1.435523427062435e-05 \n",
      "epoch: 33 [451066/888800 50.75%] train loss: 1.3811733879265375e-05 \n",
      "epoch: 33 [452177/888800 50.88%] train loss: 1.2619693734450266e-05 \n",
      "epoch: 33 [453288/888800 51.00%] train loss: 1.5722493117209524e-05 \n",
      "epoch: 33 [454399/888800 51.12%] train loss: 1.4193679817253724e-05 \n",
      "epoch: 33 [455510/888800 51.25%] train loss: 1.2993526070204098e-05 \n",
      "epoch: 33 [456621/888800 51.38%] train loss: 1.4929210010450333e-05 \n",
      "epoch: 33 [457732/888800 51.50%] train loss: 1.3882367056794465e-05 \n",
      "epoch: 33 [458843/888800 51.62%] train loss: 1.3753489838563837e-05 \n",
      "epoch: 33 [459954/888800 51.75%] train loss: 1.5118603187147528e-05 \n",
      "epoch: 33 [461065/888800 51.88%] train loss: 1.4282893971540034e-05 \n",
      "epoch: 33 [462176/888800 52.00%] train loss: 1.3910947927797679e-05 \n",
      "epoch: 33 [463287/888800 52.12%] train loss: 1.3537456652557012e-05 \n",
      "epoch: 33 [464398/888800 52.25%] train loss: 1.3218812455306761e-05 \n",
      "epoch: 33 [465509/888800 52.38%] train loss: 1.4826042388449423e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [466620/888800 52.50%] train loss: 1.4723603271704633e-05 \n",
      "epoch: 33 [467731/888800 52.62%] train loss: 1.435498234059196e-05 \n",
      "epoch: 33 [468842/888800 52.75%] train loss: 1.3664360267284792e-05 \n",
      "epoch: 33 [469953/888800 52.88%] train loss: 1.3118816241330933e-05 \n",
      "epoch: 33 [471064/888800 53.00%] train loss: 1.4593796549888793e-05 \n",
      "epoch: 33 [472175/888800 53.12%] train loss: 1.4364166418090463e-05 \n",
      "epoch: 33 [473286/888800 53.25%] train loss: 1.3946890248917043e-05 \n",
      "epoch: 33 [474397/888800 53.38%] train loss: 1.38477071232046e-05 \n",
      "epoch: 33 [475508/888800 53.50%] train loss: 1.463790704292478e-05 \n",
      "epoch: 33 [476619/888800 53.62%] train loss: 1.5044496649352368e-05 \n",
      "epoch: 33 [477730/888800 53.75%] train loss: 1.418484953319421e-05 \n",
      "epoch: 33 [478841/888800 53.88%] train loss: 1.6259999028989114e-05 \n",
      "epoch: 33 [479952/888800 54.00%] train loss: 1.4155868484522216e-05 \n",
      "epoch: 33 [481063/888800 54.12%] train loss: 1.4716631994815543e-05 \n",
      "epoch: 33 [482174/888800 54.25%] train loss: 1.3761301488557365e-05 \n",
      "epoch: 33 [483285/888800 54.38%] train loss: 1.4117184036877006e-05 \n",
      "epoch: 33 [484396/888800 54.50%] train loss: 1.4272145563154481e-05 \n",
      "epoch: 33 [485507/888800 54.62%] train loss: 1.1999332855339162e-05 \n",
      "epoch: 33 [486618/888800 54.75%] train loss: 1.4328313227451872e-05 \n",
      "epoch: 33 [487729/888800 54.88%] train loss: 1.277094634133391e-05 \n",
      "epoch: 33 [488840/888800 55.00%] train loss: 1.440951837139437e-05 \n",
      "epoch: 33 [489951/888800 55.12%] train loss: 1.5139982679102104e-05 \n",
      "epoch: 33 [491062/888800 55.25%] train loss: 1.4043948795006145e-05 \n",
      "epoch: 33 [492173/888800 55.38%] train loss: 1.4412505151994992e-05 \n",
      "epoch: 33 [493284/888800 55.50%] train loss: 1.43989145726664e-05 \n",
      "epoch: 33 [494395/888800 55.62%] train loss: 1.521029571449617e-05 \n",
      "epoch: 33 [495506/888800 55.75%] train loss: 1.4547526916430797e-05 \n",
      "epoch: 33 [496617/888800 55.88%] train loss: 1.483033429394709e-05 \n",
      "epoch: 33 [497728/888800 56.00%] train loss: 1.3773393220617436e-05 \n",
      "epoch: 33 [498839/888800 56.12%] train loss: 1.3692232641915325e-05 \n",
      "epoch: 33 [499950/888800 56.25%] train loss: 1.4274997738539241e-05 \n",
      "epoch: 33 [501061/888800 56.38%] train loss: 1.3346986634132918e-05 \n",
      "epoch: 33 [502172/888800 56.50%] train loss: 1.3333092283573933e-05 \n",
      "epoch: 33 [503283/888800 56.62%] train loss: 1.4877522517053876e-05 \n",
      "epoch: 33 [504394/888800 56.75%] train loss: 1.3111829503031913e-05 \n",
      "epoch: 33 [505505/888800 56.88%] train loss: 1.4264028322941158e-05 \n",
      "epoch: 33 [506616/888800 57.00%] train loss: 1.4372684745467268e-05 \n",
      "epoch: 33 [507727/888800 57.12%] train loss: 1.532924397906754e-05 \n",
      "epoch: 33 [508838/888800 57.25%] train loss: 1.3651299013872631e-05 \n",
      "epoch: 33 [509949/888800 57.38%] train loss: 1.2908622920804191e-05 \n",
      "epoch: 33 [511060/888800 57.50%] train loss: 1.4209107575879898e-05 \n",
      "epoch: 33 [512171/888800 57.62%] train loss: 1.4018752153788228e-05 \n",
      "epoch: 33 [513282/888800 57.75%] train loss: 1.4623350580222905e-05 \n",
      "epoch: 33 [514393/888800 57.88%] train loss: 1.4978837498347275e-05 \n",
      "epoch: 33 [515504/888800 58.00%] train loss: 1.443705605197465e-05 \n",
      "epoch: 33 [516615/888800 58.12%] train loss: 1.4261219803302083e-05 \n",
      "epoch: 33 [517726/888800 58.25%] train loss: 1.3947773368272465e-05 \n",
      "epoch: 33 [518837/888800 58.38%] train loss: 1.392717422277201e-05 \n",
      "epoch: 33 [519948/888800 58.50%] train loss: 1.4445410670305137e-05 \n",
      "epoch: 33 [521059/888800 58.62%] train loss: 1.3418199159787036e-05 \n",
      "epoch: 33 [522170/888800 58.75%] train loss: 1.3903647413826548e-05 \n",
      "epoch: 33 [523281/888800 58.88%] train loss: 1.544950282550417e-05 \n",
      "epoch: 33 [524392/888800 59.00%] train loss: 1.5402511053252965e-05 \n",
      "epoch: 33 [525503/888800 59.12%] train loss: 1.3325234249350615e-05 \n",
      "epoch: 33 [526614/888800 59.25%] train loss: 1.5104620615602471e-05 \n",
      "epoch: 33 [527725/888800 59.38%] train loss: 1.4714192730025388e-05 \n",
      "epoch: 33 [528836/888800 59.50%] train loss: 1.4869960978103336e-05 \n",
      "epoch: 33 [529947/888800 59.62%] train loss: 1.5104171325219795e-05 \n",
      "epoch: 33 [531058/888800 59.75%] train loss: 1.5486277334275655e-05 \n",
      "epoch: 33 [532169/888800 59.88%] train loss: 1.3927524378232192e-05 \n",
      "epoch: 33 [533280/888800 60.00%] train loss: 1.784939377103001e-05 \n",
      "epoch: 33 [534391/888800 60.12%] train loss: 1.3612709153676406e-05 \n",
      "epoch: 33 [535502/888800 60.25%] train loss: 1.5745865312055685e-05 \n",
      "epoch: 33 [536613/888800 60.38%] train loss: 1.4842633390799165e-05 \n",
      "epoch: 33 [537724/888800 60.50%] train loss: 1.533482463855762e-05 \n",
      "epoch: 33 [538835/888800 60.62%] train loss: 1.5639698176528327e-05 \n",
      "epoch: 33 [539946/888800 60.75%] train loss: 1.540301673230715e-05 \n",
      "epoch: 33 [541057/888800 60.88%] train loss: 1.558847179694567e-05 \n",
      "epoch: 33 [542168/888800 61.00%] train loss: 1.5297269783332013e-05 \n",
      "epoch: 33 [543279/888800 61.12%] train loss: 1.5045399777591228e-05 \n",
      "epoch: 33 [544390/888800 61.25%] train loss: 1.4485791325569153e-05 \n",
      "epoch: 33 [545501/888800 61.38%] train loss: 1.5229131349769887e-05 \n",
      "epoch: 33 [546612/888800 61.50%] train loss: 1.4975945305195637e-05 \n",
      "epoch: 33 [547723/888800 61.62%] train loss: 1.4910748177499045e-05 \n",
      "epoch: 33 [548834/888800 61.75%] train loss: 1.6148771464941092e-05 \n",
      "epoch: 33 [549945/888800 61.88%] train loss: 1.3713220141653437e-05 \n",
      "epoch: 33 [551056/888800 62.00%] train loss: 1.4980288142396603e-05 \n",
      "epoch: 33 [552167/888800 62.12%] train loss: 1.318332851951709e-05 \n",
      "epoch: 33 [553278/888800 62.25%] train loss: 1.4102320164965931e-05 \n",
      "epoch: 33 [554389/888800 62.38%] train loss: 1.3519656931748614e-05 \n",
      "epoch: 33 [555500/888800 62.50%] train loss: 1.5701234588050283e-05 \n",
      "epoch: 33 [556611/888800 62.62%] train loss: 1.4872177416691557e-05 \n",
      "epoch: 33 [557722/888800 62.75%] train loss: 1.4627572454628535e-05 \n",
      "epoch: 33 [558833/888800 62.88%] train loss: 1.6553913155803457e-05 \n",
      "epoch: 33 [559944/888800 63.00%] train loss: 1.43310981002287e-05 \n",
      "epoch: 33 [561055/888800 63.12%] train loss: 1.5273648386937566e-05 \n",
      "epoch: 33 [562166/888800 63.25%] train loss: 1.5359260942204855e-05 \n",
      "epoch: 33 [563277/888800 63.38%] train loss: 1.4149447451927699e-05 \n",
      "epoch: 33 [564388/888800 63.50%] train loss: 1.5306735804188065e-05 \n",
      "epoch: 33 [565499/888800 63.62%] train loss: 1.4803831618337426e-05 \n",
      "epoch: 33 [566610/888800 63.75%] train loss: 1.479668208048679e-05 \n",
      "epoch: 33 [567721/888800 63.88%] train loss: 1.6449759641545825e-05 \n",
      "epoch: 33 [568832/888800 64.00%] train loss: 1.3917854630562942e-05 \n",
      "epoch: 33 [569943/888800 64.12%] train loss: 1.4079922948440071e-05 \n",
      "epoch: 33 [571054/888800 64.25%] train loss: 1.4432245734496973e-05 \n",
      "epoch: 33 [572165/888800 64.38%] train loss: 1.4306211596704088e-05 \n",
      "epoch: 33 [573276/888800 64.50%] train loss: 1.3403645425569266e-05 \n",
      "epoch: 33 [574387/888800 64.62%] train loss: 1.5115374480956234e-05 \n",
      "epoch: 33 [575498/888800 64.75%] train loss: 1.3732535080634989e-05 \n",
      "epoch: 33 [576609/888800 64.88%] train loss: 1.3644459613715298e-05 \n",
      "epoch: 33 [577720/888800 65.00%] train loss: 1.4106568414717913e-05 \n",
      "epoch: 33 [578831/888800 65.12%] train loss: 1.4848013051960152e-05 \n",
      "epoch: 33 [579942/888800 65.25%] train loss: 1.3305747415870428e-05 \n",
      "epoch: 33 [581053/888800 65.38%] train loss: 1.5906774933682755e-05 \n",
      "epoch: 33 [582164/888800 65.50%] train loss: 1.4209253095032182e-05 \n",
      "epoch: 33 [583275/888800 65.62%] train loss: 1.526108644611668e-05 \n",
      "epoch: 33 [584386/888800 65.75%] train loss: 1.3272576325107366e-05 \n",
      "epoch: 33 [585497/888800 65.88%] train loss: 1.4322245988296345e-05 \n",
      "epoch: 33 [586608/888800 66.00%] train loss: 1.4710977666254621e-05 \n",
      "epoch: 33 [587719/888800 66.12%] train loss: 1.49970101119834e-05 \n",
      "epoch: 33 [588830/888800 66.25%] train loss: 1.5457795598194934e-05 \n",
      "epoch: 33 [589941/888800 66.38%] train loss: 1.4470893802354112e-05 \n",
      "epoch: 33 [591052/888800 66.50%] train loss: 1.4366835785040166e-05 \n",
      "epoch: 33 [592163/888800 66.62%] train loss: 1.3692319953406695e-05 \n",
      "epoch: 33 [593274/888800 66.75%] train loss: 1.3280137864057906e-05 \n",
      "epoch: 33 [594385/888800 66.88%] train loss: 1.4642473615822382e-05 \n",
      "epoch: 33 [595496/888800 67.00%] train loss: 1.490543672844069e-05 \n",
      "epoch: 33 [596607/888800 67.12%] train loss: 1.4359646229422651e-05 \n",
      "epoch: 33 [597718/888800 67.25%] train loss: 1.460863040847471e-05 \n",
      "epoch: 33 [598829/888800 67.38%] train loss: 1.4928593373042531e-05 \n",
      "epoch: 33 [599940/888800 67.50%] train loss: 1.4219550394045655e-05 \n",
      "epoch: 33 [601051/888800 67.62%] train loss: 1.3199060958868358e-05 \n",
      "epoch: 33 [602162/888800 67.75%] train loss: 1.3537329323298763e-05 \n",
      "epoch: 33 [603273/888800 67.88%] train loss: 1.4348845979839098e-05 \n",
      "epoch: 33 [604384/888800 68.00%] train loss: 1.3445222975860815e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [605495/888800 68.12%] train loss: 1.381021775159752e-05 \n",
      "epoch: 33 [606606/888800 68.25%] train loss: 1.4771151654713321e-05 \n",
      "epoch: 33 [607717/888800 68.38%] train loss: 1.4679163541586604e-05 \n",
      "epoch: 33 [608828/888800 68.50%] train loss: 1.58020975504769e-05 \n",
      "epoch: 33 [609939/888800 68.62%] train loss: 1.4578366972273216e-05 \n",
      "epoch: 33 [611050/888800 68.75%] train loss: 1.3499221495294478e-05 \n",
      "epoch: 33 [612161/888800 68.88%] train loss: 1.3441323062579613e-05 \n",
      "epoch: 33 [613272/888800 69.00%] train loss: 1.4900454516464379e-05 \n",
      "epoch: 33 [614383/888800 69.12%] train loss: 1.431969940313138e-05 \n",
      "epoch: 33 [615494/888800 69.25%] train loss: 1.4000098417454865e-05 \n",
      "epoch: 33 [616605/888800 69.38%] train loss: 1.4809018466621637e-05 \n",
      "epoch: 33 [617716/888800 69.50%] train loss: 1.4273773558670655e-05 \n",
      "epoch: 33 [618827/888800 69.62%] train loss: 1.3377820323512424e-05 \n",
      "epoch: 33 [619938/888800 69.75%] train loss: 1.4478262528427877e-05 \n",
      "epoch: 33 [621049/888800 69.88%] train loss: 1.4218442629498895e-05 \n",
      "epoch: 33 [622160/888800 70.00%] train loss: 1.321719628322171e-05 \n",
      "epoch: 33 [623271/888800 70.12%] train loss: 1.5016249562904704e-05 \n",
      "epoch: 33 [624382/888800 70.25%] train loss: 1.4802877558395267e-05 \n",
      "epoch: 33 [625493/888800 70.38%] train loss: 1.3385758393269498e-05 \n",
      "epoch: 33 [626604/888800 70.50%] train loss: 1.4596192158933263e-05 \n",
      "epoch: 33 [627715/888800 70.62%] train loss: 1.4824231584498193e-05 \n",
      "epoch: 33 [628826/888800 70.75%] train loss: 1.2464995961636305e-05 \n",
      "epoch: 33 [629937/888800 70.88%] train loss: 1.4500632460112683e-05 \n",
      "epoch: 33 [631048/888800 71.00%] train loss: 1.4805386854277458e-05 \n",
      "epoch: 33 [632159/888800 71.12%] train loss: 1.3924534869147465e-05 \n",
      "epoch: 33 [633270/888800 71.25%] train loss: 1.5017833902675193e-05 \n",
      "epoch: 33 [634381/888800 71.38%] train loss: 1.3961528566142078e-05 \n",
      "epoch: 33 [635492/888800 71.50%] train loss: 1.3477863831212744e-05 \n",
      "epoch: 33 [636603/888800 71.62%] train loss: 1.381327001581667e-05 \n",
      "epoch: 33 [637714/888800 71.75%] train loss: 1.4713267773913685e-05 \n",
      "epoch: 33 [638825/888800 71.88%] train loss: 1.3349775144888554e-05 \n",
      "epoch: 33 [639936/888800 72.00%] train loss: 1.3864937500329688e-05 \n",
      "epoch: 33 [641047/888800 72.12%] train loss: 1.3757437955064233e-05 \n",
      "epoch: 33 [642158/888800 72.25%] train loss: 1.3906830645282753e-05 \n",
      "epoch: 33 [643269/888800 72.38%] train loss: 1.4228208783606533e-05 \n",
      "epoch: 33 [644380/888800 72.50%] train loss: 1.4911579455656465e-05 \n",
      "epoch: 33 [645491/888800 72.62%] train loss: 1.4670880773337558e-05 \n",
      "epoch: 33 [646602/888800 72.75%] train loss: 1.536894887976814e-05 \n",
      "epoch: 33 [647713/888800 72.88%] train loss: 1.4359854503709357e-05 \n",
      "epoch: 33 [648824/888800 73.00%] train loss: 1.3916786883783061e-05 \n",
      "epoch: 33 [649935/888800 73.12%] train loss: 1.3177024811739102e-05 \n",
      "epoch: 33 [651046/888800 73.25%] train loss: 1.394395440001972e-05 \n",
      "epoch: 33 [652157/888800 73.38%] train loss: 1.675902421993669e-05 \n",
      "epoch: 33 [653268/888800 73.50%] train loss: 1.4460470993071795e-05 \n",
      "epoch: 33 [654379/888800 73.62%] train loss: 1.5819996406207792e-05 \n",
      "epoch: 33 [655490/888800 73.75%] train loss: 1.445433827029774e-05 \n",
      "epoch: 33 [656601/888800 73.88%] train loss: 1.495066680945456e-05 \n",
      "epoch: 33 [657712/888800 74.00%] train loss: 1.4479447600024287e-05 \n",
      "epoch: 33 [658823/888800 74.12%] train loss: 1.4253298104449641e-05 \n",
      "epoch: 33 [659934/888800 74.25%] train loss: 1.402317502652295e-05 \n",
      "epoch: 33 [661045/888800 74.38%] train loss: 1.4152121366350912e-05 \n",
      "epoch: 33 [662156/888800 74.50%] train loss: 1.4149159142107237e-05 \n",
      "epoch: 33 [663267/888800 74.62%] train loss: 1.468252139602555e-05 \n",
      "epoch: 33 [664378/888800 74.75%] train loss: 1.4588236808776855e-05 \n",
      "epoch: 33 [665489/888800 74.88%] train loss: 1.4281526091508567e-05 \n",
      "epoch: 33 [666600/888800 75.00%] train loss: 1.515012718300568e-05 \n",
      "epoch: 33 [667711/888800 75.12%] train loss: 1.389846784149995e-05 \n",
      "epoch: 33 [668822/888800 75.25%] train loss: 1.4850073966954369e-05 \n",
      "epoch: 33 [669933/888800 75.38%] train loss: 1.3701829630008433e-05 \n",
      "epoch: 33 [671044/888800 75.50%] train loss: 1.3233800018497277e-05 \n",
      "epoch: 33 [672155/888800 75.62%] train loss: 1.447245176677825e-05 \n",
      "epoch: 33 [673266/888800 75.75%] train loss: 1.4886310964357108e-05 \n",
      "epoch: 33 [674377/888800 75.88%] train loss: 1.4040272617421579e-05 \n",
      "epoch: 33 [675488/888800 76.00%] train loss: 1.4558861948898993e-05 \n",
      "epoch: 33 [676599/888800 76.12%] train loss: 1.5539653759333305e-05 \n",
      "epoch: 33 [677710/888800 76.25%] train loss: 1.3889892215956934e-05 \n",
      "epoch: 33 [678821/888800 76.38%] train loss: 1.5173528481682297e-05 \n",
      "epoch: 33 [679932/888800 76.50%] train loss: 1.3322205631993711e-05 \n",
      "epoch: 33 [681043/888800 76.62%] train loss: 1.4576601643057074e-05 \n",
      "epoch: 33 [682154/888800 76.75%] train loss: 1.404823979100911e-05 \n",
      "epoch: 33 [683265/888800 76.88%] train loss: 1.4520564945996739e-05 \n",
      "epoch: 33 [684376/888800 77.00%] train loss: 1.325069388258271e-05 \n",
      "epoch: 33 [685487/888800 77.12%] train loss: 1.4212715541361831e-05 \n",
      "epoch: 33 [686598/888800 77.25%] train loss: 1.3262849279271904e-05 \n",
      "epoch: 33 [687709/888800 77.38%] train loss: 1.4780550372961443e-05 \n",
      "epoch: 33 [688820/888800 77.50%] train loss: 1.4099634427111596e-05 \n",
      "epoch: 33 [689931/888800 77.62%] train loss: 1.4909261153661646e-05 \n",
      "epoch: 33 [691042/888800 77.75%] train loss: 1.4401436601474416e-05 \n",
      "epoch: 33 [692153/888800 77.88%] train loss: 1.4249225387175102e-05 \n",
      "epoch: 33 [693264/888800 78.00%] train loss: 1.3968005077913404e-05 \n",
      "epoch: 33 [694375/888800 78.12%] train loss: 1.510071615484776e-05 \n",
      "epoch: 33 [695486/888800 78.25%] train loss: 1.3567208043241408e-05 \n",
      "epoch: 33 [696597/888800 78.38%] train loss: 1.3477381799020804e-05 \n",
      "epoch: 33 [697708/888800 78.50%] train loss: 1.3282108739076648e-05 \n",
      "epoch: 33 [698819/888800 78.62%] train loss: 1.4915527572156861e-05 \n",
      "epoch: 33 [699930/888800 78.75%] train loss: 1.4733077478013001e-05 \n",
      "epoch: 33 [701041/888800 78.88%] train loss: 1.3365215636440553e-05 \n",
      "epoch: 33 [702152/888800 79.00%] train loss: 1.4792710317124147e-05 \n",
      "epoch: 33 [703263/888800 79.12%] train loss: 1.3122201380610932e-05 \n",
      "epoch: 33 [704374/888800 79.25%] train loss: 1.4064620700082742e-05 \n",
      "epoch: 33 [705485/888800 79.38%] train loss: 1.3130211300449446e-05 \n",
      "epoch: 33 [706596/888800 79.50%] train loss: 1.335109664069023e-05 \n",
      "epoch: 33 [707707/888800 79.62%] train loss: 1.383965809509391e-05 \n",
      "epoch: 33 [708818/888800 79.75%] train loss: 1.5178046851360705e-05 \n",
      "epoch: 33 [709929/888800 79.88%] train loss: 1.4134178854874335e-05 \n",
      "epoch: 33 [711040/888800 80.00%] train loss: 1.3226765986473765e-05 \n",
      "epoch: 33 [712151/888800 80.12%] train loss: 1.4633837963629048e-05 \n",
      "epoch: 33 [713262/888800 80.25%] train loss: 1.4800216376897879e-05 \n",
      "epoch: 33 [714373/888800 80.38%] train loss: 1.524082381365588e-05 \n",
      "epoch: 33 [715484/888800 80.50%] train loss: 1.4709954484715126e-05 \n",
      "epoch: 33 [716595/888800 80.62%] train loss: 1.4158829799271189e-05 \n",
      "epoch: 33 [717706/888800 80.75%] train loss: 1.4703275155625306e-05 \n",
      "epoch: 33 [718817/888800 80.88%] train loss: 1.2978157428733539e-05 \n",
      "epoch: 33 [719928/888800 81.00%] train loss: 1.4074585124035366e-05 \n",
      "epoch: 33 [721039/888800 81.12%] train loss: 1.396883908455493e-05 \n",
      "epoch: 33 [722150/888800 81.25%] train loss: 1.3871737792214844e-05 \n",
      "epoch: 33 [723261/888800 81.38%] train loss: 1.37648075906327e-05 \n",
      "epoch: 33 [724372/888800 81.50%] train loss: 1.42663584483671e-05 \n",
      "epoch: 33 [725483/888800 81.62%] train loss: 1.4408766219276004e-05 \n",
      "epoch: 33 [726594/888800 81.75%] train loss: 1.4240824384614825e-05 \n",
      "epoch: 33 [727705/888800 81.88%] train loss: 1.4989655028330162e-05 \n",
      "epoch: 33 [728816/888800 82.00%] train loss: 1.4617923625337426e-05 \n",
      "epoch: 33 [729927/888800 82.12%] train loss: 1.4895047570462339e-05 \n",
      "epoch: 33 [731038/888800 82.25%] train loss: 1.413781865267083e-05 \n",
      "epoch: 33 [732149/888800 82.38%] train loss: 1.337253979727393e-05 \n",
      "epoch: 33 [733260/888800 82.50%] train loss: 1.3821479114994872e-05 \n",
      "epoch: 33 [734371/888800 82.62%] train loss: 1.3364096957957372e-05 \n",
      "epoch: 33 [735482/888800 82.75%] train loss: 1.3748537639912684e-05 \n",
      "epoch: 33 [736593/888800 82.88%] train loss: 1.4715446923219133e-05 \n",
      "epoch: 33 [737704/888800 83.00%] train loss: 1.4238249605114106e-05 \n",
      "epoch: 33 [738815/888800 83.12%] train loss: 1.4256649592425674e-05 \n",
      "epoch: 33 [739926/888800 83.25%] train loss: 1.3734272215515375e-05 \n",
      "epoch: 33 [741037/888800 83.38%] train loss: 1.4445316082856152e-05 \n",
      "epoch: 33 [742148/888800 83.50%] train loss: 1.4399695828615222e-05 \n",
      "epoch: 33 [743259/888800 83.62%] train loss: 1.4490418834611773e-05 \n",
      "epoch: 33 [744370/888800 83.75%] train loss: 1.4374601050803903e-05 \n",
      "epoch: 33 [745481/888800 83.88%] train loss: 1.424146284989547e-05 \n",
      "epoch: 33 [746592/888800 84.00%] train loss: 1.4297878806246445e-05 \n",
      "epoch: 33 [747703/888800 84.12%] train loss: 1.3534870959119871e-05 \n",
      "epoch: 33 [748814/888800 84.25%] train loss: 1.4740578080818523e-05 \n",
      "epoch: 33 [749925/888800 84.38%] train loss: 1.5417865142808296e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 [751036/888800 84.50%] train loss: 1.5286939742509276e-05 \n",
      "epoch: 33 [752147/888800 84.62%] train loss: 1.2702994354185648e-05 \n",
      "epoch: 33 [753258/888800 84.75%] train loss: 1.443886685592588e-05 \n",
      "epoch: 33 [754369/888800 84.88%] train loss: 1.3671745364263188e-05 \n",
      "epoch: 33 [755480/888800 85.00%] train loss: 1.4492949048872106e-05 \n",
      "epoch: 33 [756591/888800 85.12%] train loss: 1.3898851648264099e-05 \n",
      "epoch: 33 [757702/888800 85.25%] train loss: 1.4288138117990457e-05 \n",
      "epoch: 33 [758813/888800 85.38%] train loss: 1.3964214303996414e-05 \n",
      "epoch: 33 [759924/888800 85.50%] train loss: 1.3999622751725838e-05 \n",
      "epoch: 33 [761035/888800 85.62%] train loss: 1.3107161976222415e-05 \n",
      "epoch: 33 [762146/888800 85.75%] train loss: 1.3448038771457504e-05 \n",
      "epoch: 33 [763257/888800 85.88%] train loss: 1.434118803445017e-05 \n",
      "epoch: 33 [764368/888800 86.00%] train loss: 1.5160164366534445e-05 \n",
      "epoch: 33 [765479/888800 86.12%] train loss: 1.4074338650971185e-05 \n",
      "epoch: 33 [766590/888800 86.25%] train loss: 1.5794757928233594e-05 \n",
      "epoch: 33 [767701/888800 86.38%] train loss: 1.364000763715012e-05 \n",
      "epoch: 33 [768812/888800 86.50%] train loss: 1.5074901966727339e-05 \n",
      "epoch: 33 [769923/888800 86.62%] train loss: 1.3494381164491642e-05 \n",
      "epoch: 33 [771034/888800 86.75%] train loss: 1.4727570487593766e-05 \n",
      "epoch: 33 [772145/888800 86.88%] train loss: 1.4160155842546374e-05 \n",
      "epoch: 33 [773256/888800 87.00%] train loss: 1.5552852346445434e-05 \n",
      "epoch: 33 [774367/888800 87.12%] train loss: 1.5340141544584185e-05 \n",
      "epoch: 33 [775478/888800 87.25%] train loss: 1.4774125702388119e-05 \n",
      "epoch: 33 [776589/888800 87.38%] train loss: 1.3941900760983117e-05 \n",
      "epoch: 33 [777700/888800 87.50%] train loss: 1.3212954399932642e-05 \n",
      "epoch: 33 [778811/888800 87.62%] train loss: 1.3645585568156093e-05 \n",
      "epoch: 33 [779922/888800 87.75%] train loss: 1.5029940186650492e-05 \n",
      "epoch: 33 [781033/888800 87.88%] train loss: 1.4463981642620638e-05 \n",
      "epoch: 33 [782144/888800 88.00%] train loss: 1.4575643035641406e-05 \n",
      "epoch: 33 [783255/888800 88.12%] train loss: 1.3538062376028392e-05 \n",
      "epoch: 33 [784366/888800 88.25%] train loss: 1.417328621755587e-05 \n",
      "epoch: 33 [785477/888800 88.38%] train loss: 1.3466656128002796e-05 \n",
      "epoch: 33 [786588/888800 88.50%] train loss: 1.4107909009908326e-05 \n",
      "epoch: 33 [787699/888800 88.62%] train loss: 1.4275182365963701e-05 \n",
      "epoch: 33 [788810/888800 88.75%] train loss: 1.4155206372379325e-05 \n",
      "epoch: 33 [789921/888800 88.88%] train loss: 1.4537239621859044e-05 \n",
      "epoch: 33 [791032/888800 89.00%] train loss: 1.4690292118757498e-05 \n",
      "epoch: 33 [792143/888800 89.12%] train loss: 1.4025234122527763e-05 \n",
      "epoch: 33 [793254/888800 89.25%] train loss: 1.3861582374374848e-05 \n",
      "epoch: 33 [794365/888800 89.38%] train loss: 1.4486549844150431e-05 \n",
      "epoch: 33 [795476/888800 89.50%] train loss: 1.3586668501375243e-05 \n",
      "epoch: 33 [796587/888800 89.62%] train loss: 1.373717805108754e-05 \n",
      "epoch: 33 [797698/888800 89.75%] train loss: 1.3297563782543875e-05 \n",
      "epoch: 33 [798809/888800 89.88%] train loss: 1.4445862689171918e-05 \n",
      "epoch: 33 [799920/888800 90.00%] train loss: 1.4581515642930754e-05 \n",
      "epoch: 33 [801031/888800 90.12%] train loss: 1.3144583135726862e-05 \n",
      "epoch: 33 [802142/888800 90.25%] train loss: 1.5596322555211373e-05 \n",
      "epoch: 33 [803253/888800 90.38%] train loss: 1.4358880434883758e-05 \n",
      "epoch: 33 [804364/888800 90.50%] train loss: 1.5408902982017025e-05 \n",
      "epoch: 33 [805475/888800 90.62%] train loss: 1.258075462828856e-05 \n",
      "epoch: 33 [806586/888800 90.75%] train loss: 1.3614459021482617e-05 \n",
      "epoch: 33 [807697/888800 90.88%] train loss: 1.4739250218553934e-05 \n",
      "epoch: 33 [808808/888800 91.00%] train loss: 1.4655162885901518e-05 \n",
      "epoch: 33 [809919/888800 91.12%] train loss: 1.3367966857913416e-05 \n",
      "epoch: 33 [811030/888800 91.25%] train loss: 1.4230308806872927e-05 \n",
      "epoch: 33 [812141/888800 91.38%] train loss: 1.3293922165757976e-05 \n",
      "epoch: 33 [813252/888800 91.50%] train loss: 1.372213228023611e-05 \n",
      "epoch: 33 [814363/888800 91.62%] train loss: 1.3819510968460236e-05 \n",
      "epoch: 33 [815474/888800 91.75%] train loss: 1.3758534805674572e-05 \n",
      "epoch: 33 [816585/888800 91.88%] train loss: 1.368646371702198e-05 \n",
      "epoch: 33 [817696/888800 92.00%] train loss: 1.4624703908339143e-05 \n",
      "epoch: 33 [818807/888800 92.12%] train loss: 1.4456745702773333e-05 \n",
      "epoch: 33 [819918/888800 92.25%] train loss: 1.492415049142437e-05 \n",
      "epoch: 33 [821029/888800 92.38%] train loss: 1.4053589438844938e-05 \n",
      "epoch: 33 [822140/888800 92.50%] train loss: 1.674044870014768e-05 \n",
      "epoch: 33 [823251/888800 92.62%] train loss: 1.5230039934976958e-05 \n",
      "epoch: 33 [824362/888800 92.75%] train loss: 1.4662255125585943e-05 \n",
      "epoch: 33 [825473/888800 92.88%] train loss: 1.3948866580903996e-05 \n",
      "epoch: 33 [826584/888800 93.00%] train loss: 1.4894451851432677e-05 \n",
      "epoch: 33 [827695/888800 93.12%] train loss: 1.5228805750666652e-05 \n",
      "epoch: 33 [828806/888800 93.25%] train loss: 1.4524041944241617e-05 \n",
      "epoch: 33 [829917/888800 93.38%] train loss: 1.4985461348260287e-05 \n",
      "epoch: 33 [831028/888800 93.50%] train loss: 1.4284325516200624e-05 \n",
      "epoch: 33 [832139/888800 93.62%] train loss: 1.4715121324115898e-05 \n",
      "epoch: 33 [833250/888800 93.75%] train loss: 1.3864842912880704e-05 \n",
      "epoch: 33 [834361/888800 93.88%] train loss: 1.3961588592792396e-05 \n",
      "epoch: 33 [835472/888800 94.00%] train loss: 1.4726153494848404e-05 \n",
      "epoch: 33 [836583/888800 94.12%] train loss: 1.3683797988051083e-05 \n",
      "epoch: 33 [837694/888800 94.25%] train loss: 1.364788749924628e-05 \n",
      "epoch: 33 [838805/888800 94.38%] train loss: 1.4406929949473124e-05 \n",
      "epoch: 33 [839916/888800 94.50%] train loss: 1.4026724784343969e-05 \n",
      "epoch: 33 [841027/888800 94.62%] train loss: 1.3411075997282751e-05 \n",
      "epoch: 33 [842138/888800 94.75%] train loss: 1.443419296265347e-05 \n",
      "epoch: 33 [843249/888800 94.88%] train loss: 1.455003166483948e-05 \n",
      "epoch: 33 [844360/888800 95.00%] train loss: 1.3102098819217645e-05 \n",
      "epoch: 33 [845471/888800 95.12%] train loss: 1.3092109838908073e-05 \n",
      "epoch: 33 [846582/888800 95.25%] train loss: 1.445653924747603e-05 \n",
      "epoch: 33 [847693/888800 95.38%] train loss: 1.42100834636949e-05 \n",
      "epoch: 33 [848804/888800 95.50%] train loss: 1.3946426406619139e-05 \n",
      "epoch: 33 [849915/888800 95.62%] train loss: 1.5026416804175824e-05 \n",
      "epoch: 33 [851026/888800 95.75%] train loss: 1.3689908882952295e-05 \n",
      "epoch: 33 [852137/888800 95.88%] train loss: 1.3488484910340048e-05 \n",
      "epoch: 33 [853248/888800 96.00%] train loss: 1.3505155038728844e-05 \n",
      "epoch: 33 [854359/888800 96.12%] train loss: 1.3749959180131555e-05 \n",
      "epoch: 33 [855470/888800 96.25%] train loss: 1.4764752449991647e-05 \n",
      "epoch: 33 [856581/888800 96.38%] train loss: 1.3938910342403688e-05 \n",
      "epoch: 33 [857692/888800 96.50%] train loss: 1.5764908312121406e-05 \n",
      "epoch: 33 [858803/888800 96.62%] train loss: 1.3396806025411934e-05 \n",
      "epoch: 33 [859914/888800 96.75%] train loss: 1.4549341358360834e-05 \n",
      "epoch: 33 [861025/888800 96.88%] train loss: 1.3967774975753855e-05 \n",
      "epoch: 33 [862136/888800 97.00%] train loss: 1.3449192010739353e-05 \n",
      "epoch: 33 [863247/888800 97.12%] train loss: 1.4113688848738093e-05 \n",
      "epoch: 33 [864358/888800 97.25%] train loss: 1.474820510338759e-05 \n",
      "epoch: 33 [865469/888800 97.38%] train loss: 1.4213585927791428e-05 \n",
      "epoch: 33 [866580/888800 97.50%] train loss: 1.4291733350546565e-05 \n",
      "epoch: 33 [867691/888800 97.62%] train loss: 1.531240195618011e-05 \n",
      "epoch: 33 [868802/888800 97.75%] train loss: 1.502129998698365e-05 \n",
      "epoch: 33 [869913/888800 97.88%] train loss: 1.4312746316136327e-05 \n",
      "epoch: 33 [871024/888800 98.00%] train loss: 1.6061863789218478e-05 \n",
      "epoch: 33 [872135/888800 98.12%] train loss: 1.5221567082335241e-05 \n",
      "epoch: 33 [873246/888800 98.25%] train loss: 1.3716603461944032e-05 \n",
      "epoch: 33 [874357/888800 98.38%] train loss: 1.4441002349485643e-05 \n",
      "epoch: 33 [875468/888800 98.50%] train loss: 1.4503249985864386e-05 \n",
      "epoch: 33 [876579/888800 98.62%] train loss: 1.592266562511213e-05 \n",
      "epoch: 33 [877690/888800 98.75%] train loss: 1.3905131709179841e-05 \n",
      "epoch: 33 [878801/888800 98.88%] train loss: 1.542119207442738e-05 \n",
      "epoch: 33 [879912/888800 99.00%] train loss: 1.2741044884023722e-05 \n",
      "epoch: 33 [881023/888800 99.12%] train loss: 1.404151953465771e-05 \n",
      "epoch: 33 [882134/888800 99.25%] train loss: 1.4475462194241118e-05 \n",
      "epoch: 33 [883245/888800 99.38%] train loss: 1.384738425258547e-05 \n",
      "epoch: 33 [884356/888800 99.50%] train loss: 1.587191945873201e-05 \n",
      "epoch: 33 [885467/888800 99.62%] train loss: 1.3805162780045066e-05 \n",
      "epoch: 33 [886578/888800 99.75%] train loss: 1.316561520070536e-05 \n",
      "epoch: 33 [887689/888800 99.88%] train loss: 1.483794221712742e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [0/888800 0.00%] train loss: 1.5221247849694919e-05 \n",
      "epoch: 34 [1111/888800 0.12%] train loss: 1.6224830687860958e-05 \n",
      "epoch: 34 [2222/888800 0.25%] train loss: 1.5039533536764793e-05 \n",
      "epoch: 34 [3333/888800 0.38%] train loss: 1.3980749827169348e-05 \n",
      "epoch: 34 [4444/888800 0.50%] train loss: 1.4875223314447794e-05 \n",
      "epoch: 34 [5555/888800 0.62%] train loss: 1.3415628927759826e-05 \n",
      "epoch: 34 [6666/888800 0.75%] train loss: 1.5800766050233506e-05 \n",
      "epoch: 34 [7777/888800 0.88%] train loss: 1.4048914636077825e-05 \n",
      "epoch: 34 [8888/888800 1.00%] train loss: 1.5527466530329548e-05 \n",
      "epoch: 34 [9999/888800 1.12%] train loss: 1.4632005331804976e-05 \n",
      "epoch: 34 [11110/888800 1.25%] train loss: 1.5374702343251556e-05 \n",
      "epoch: 34 [12221/888800 1.38%] train loss: 1.4671452845504973e-05 \n",
      "epoch: 34 [13332/888800 1.50%] train loss: 1.5487457858398557e-05 \n",
      "epoch: 34 [14443/888800 1.62%] train loss: 1.45718440762721e-05 \n",
      "epoch: 34 [15554/888800 1.75%] train loss: 1.451229582016822e-05 \n",
      "epoch: 34 [16665/888800 1.88%] train loss: 1.4163921150611714e-05 \n",
      "epoch: 34 [17776/888800 2.00%] train loss: 1.4243656551116146e-05 \n",
      "epoch: 34 [18887/888800 2.12%] train loss: 1.5172218809311744e-05 \n",
      "epoch: 34 [19998/888800 2.25%] train loss: 1.4187648048391566e-05 \n",
      "epoch: 34 [21109/888800 2.38%] train loss: 1.415757378708804e-05 \n",
      "epoch: 34 [22220/888800 2.50%] train loss: 1.3849418792233337e-05 \n",
      "epoch: 34 [23331/888800 2.62%] train loss: 1.5028719644760713e-05 \n",
      "epoch: 34 [24442/888800 2.75%] train loss: 1.5240609172906261e-05 \n",
      "epoch: 34 [25553/888800 2.88%] train loss: 1.4689499039377552e-05 \n",
      "epoch: 34 [26664/888800 3.00%] train loss: 1.6234309441642836e-05 \n",
      "epoch: 34 [27775/888800 3.12%] train loss: 1.3919251614424866e-05 \n",
      "epoch: 34 [28886/888800 3.25%] train loss: 1.6113172023324296e-05 \n",
      "epoch: 34 [29997/888800 3.38%] train loss: 1.339271602773806e-05 \n",
      "epoch: 34 [31108/888800 3.50%] train loss: 1.68910719366977e-05 \n",
      "epoch: 34 [32219/888800 3.62%] train loss: 1.5266297850757837e-05 \n",
      "epoch: 34 [33330/888800 3.75%] train loss: 1.5379775504698046e-05 \n",
      "epoch: 34 [34441/888800 3.88%] train loss: 1.570399763295427e-05 \n",
      "epoch: 34 [35552/888800 4.00%] train loss: 1.3411454347078688e-05 \n",
      "epoch: 34 [36663/888800 4.12%] train loss: 1.4935076251276769e-05 \n",
      "epoch: 34 [37774/888800 4.25%] train loss: 1.4180923244566657e-05 \n",
      "epoch: 34 [38885/888800 4.38%] train loss: 1.428773975931108e-05 \n",
      "epoch: 34 [39996/888800 4.50%] train loss: 1.3814186786476057e-05 \n",
      "epoch: 34 [41107/888800 4.62%] train loss: 1.419255477230763e-05 \n",
      "epoch: 34 [42218/888800 4.75%] train loss: 1.5200132111203857e-05 \n",
      "epoch: 34 [43329/888800 4.88%] train loss: 1.46540251080296e-05 \n",
      "epoch: 34 [44440/888800 5.00%] train loss: 1.3957196642877534e-05 \n",
      "epoch: 34 [45551/888800 5.12%] train loss: 1.4099147847446147e-05 \n",
      "epoch: 34 [46662/888800 5.25%] train loss: 1.38633531605592e-05 \n",
      "epoch: 34 [47773/888800 5.38%] train loss: 1.373773193336092e-05 \n",
      "epoch: 34 [48884/888800 5.50%] train loss: 1.4559843293682206e-05 \n",
      "epoch: 34 [49995/888800 5.62%] train loss: 1.4116248166828882e-05 \n",
      "epoch: 34 [51106/888800 5.75%] train loss: 1.4818670024396852e-05 \n",
      "epoch: 34 [52217/888800 5.88%] train loss: 1.454867742722854e-05 \n",
      "epoch: 34 [53328/888800 6.00%] train loss: 1.3690292689716443e-05 \n",
      "epoch: 34 [54439/888800 6.12%] train loss: 1.4304917385743465e-05 \n",
      "epoch: 34 [55550/888800 6.25%] train loss: 1.409685137332417e-05 \n",
      "epoch: 34 [56661/888800 6.38%] train loss: 1.4589959391742013e-05 \n",
      "epoch: 34 [57772/888800 6.50%] train loss: 1.5097199138836004e-05 \n",
      "epoch: 34 [58883/888800 6.62%] train loss: 1.3705910532735288e-05 \n",
      "epoch: 34 [59994/888800 6.75%] train loss: 1.3586853128799703e-05 \n",
      "epoch: 34 [61105/888800 6.88%] train loss: 1.3828548617311753e-05 \n",
      "epoch: 34 [62216/888800 7.00%] train loss: 1.3422476513369475e-05 \n",
      "epoch: 34 [63327/888800 7.12%] train loss: 1.3458292414725292e-05 \n",
      "epoch: 34 [64438/888800 7.25%] train loss: 1.4922540685802232e-05 \n",
      "epoch: 34 [65549/888800 7.38%] train loss: 1.3654671420226805e-05 \n",
      "epoch: 34 [66660/888800 7.50%] train loss: 1.3652689631271642e-05 \n",
      "epoch: 34 [67771/888800 7.62%] train loss: 1.4052786355023272e-05 \n",
      "epoch: 34 [68882/888800 7.75%] train loss: 1.3424241842585616e-05 \n",
      "epoch: 34 [69993/888800 7.88%] train loss: 1.411479024682194e-05 \n",
      "epoch: 34 [71104/888800 8.00%] train loss: 1.4897511391609441e-05 \n",
      "epoch: 34 [72215/888800 8.12%] train loss: 1.445387169951573e-05 \n",
      "epoch: 34 [73326/888800 8.25%] train loss: 1.4429106158786453e-05 \n",
      "epoch: 34 [74437/888800 8.38%] train loss: 1.4682656910736114e-05 \n",
      "epoch: 34 [75548/888800 8.50%] train loss: 1.4870073755446356e-05 \n",
      "epoch: 34 [76659/888800 8.62%] train loss: 1.3912227586843073e-05 \n",
      "epoch: 34 [77770/888800 8.75%] train loss: 1.383811923005851e-05 \n",
      "epoch: 34 [78881/888800 8.88%] train loss: 1.4670890777779277e-05 \n",
      "epoch: 34 [79992/888800 9.00%] train loss: 1.4352975085785147e-05 \n",
      "epoch: 34 [81103/888800 9.12%] train loss: 1.3747619050263893e-05 \n",
      "epoch: 34 [82214/888800 9.25%] train loss: 1.3616119758808054e-05 \n",
      "epoch: 34 [83325/888800 9.38%] train loss: 1.6070025594672188e-05 \n",
      "epoch: 34 [84436/888800 9.50%] train loss: 1.4381931578100193e-05 \n",
      "epoch: 34 [85547/888800 9.62%] train loss: 1.4248292245611083e-05 \n",
      "epoch: 34 [86658/888800 9.75%] train loss: 1.4068719792703632e-05 \n",
      "epoch: 34 [87769/888800 9.88%] train loss: 1.3203117305238266e-05 \n",
      "epoch: 34 [88880/888800 10.00%] train loss: 1.3830292118655052e-05 \n",
      "epoch: 34 [89991/888800 10.12%] train loss: 1.401066310791066e-05 \n",
      "epoch: 34 [91102/888800 10.25%] train loss: 1.5438799891853705e-05 \n",
      "epoch: 34 [92213/888800 10.38%] train loss: 1.526230335002765e-05 \n",
      "epoch: 34 [93324/888800 10.50%] train loss: 1.3357007446757052e-05 \n",
      "epoch: 34 [94435/888800 10.62%] train loss: 1.6261483324342407e-05 \n",
      "epoch: 34 [95546/888800 10.75%] train loss: 1.4380972061189823e-05 \n",
      "epoch: 34 [96657/888800 10.88%] train loss: 1.542226891615428e-05 \n",
      "epoch: 34 [97768/888800 11.00%] train loss: 1.4554911103914492e-05 \n",
      "epoch: 34 [98879/888800 11.12%] train loss: 1.382592563459184e-05 \n",
      "epoch: 34 [99990/888800 11.25%] train loss: 1.3614015188068151e-05 \n",
      "epoch: 34 [101101/888800 11.38%] train loss: 1.5267994967871346e-05 \n",
      "epoch: 34 [102212/888800 11.50%] train loss: 1.4041429494682234e-05 \n",
      "epoch: 34 [103323/888800 11.62%] train loss: 1.4660588931292295e-05 \n",
      "epoch: 34 [104434/888800 11.75%] train loss: 1.3531054719351232e-05 \n",
      "epoch: 34 [105545/888800 11.88%] train loss: 1.358528697892325e-05 \n",
      "epoch: 34 [106656/888800 12.00%] train loss: 1.4215685951057822e-05 \n",
      "epoch: 34 [107767/888800 12.12%] train loss: 1.436484217265388e-05 \n",
      "epoch: 34 [108878/888800 12.25%] train loss: 1.2526149475888815e-05 \n",
      "epoch: 34 [109989/888800 12.38%] train loss: 1.5689975043642335e-05 \n",
      "epoch: 34 [111100/888800 12.50%] train loss: 1.301250267715659e-05 \n",
      "epoch: 34 [112211/888800 12.62%] train loss: 1.4758814359083772e-05 \n",
      "epoch: 34 [113322/888800 12.75%] train loss: 1.4511199879052583e-05 \n",
      "epoch: 34 [114433/888800 12.88%] train loss: 1.4207217645889614e-05 \n",
      "epoch: 34 [115544/888800 13.00%] train loss: 1.4890951206325553e-05 \n",
      "epoch: 34 [116655/888800 13.12%] train loss: 1.355411222903058e-05 \n",
      "epoch: 34 [117766/888800 13.25%] train loss: 1.575308669998776e-05 \n",
      "epoch: 34 [118877/888800 13.38%] train loss: 1.4264499441196676e-05 \n",
      "epoch: 34 [119988/888800 13.50%] train loss: 1.4103396097198129e-05 \n",
      "epoch: 34 [121099/888800 13.62%] train loss: 1.5047162378323264e-05 \n",
      "epoch: 34 [122210/888800 13.75%] train loss: 1.5637890101061203e-05 \n",
      "epoch: 34 [123321/888800 13.88%] train loss: 1.5178794456005562e-05 \n",
      "epoch: 34 [124432/888800 14.00%] train loss: 1.4896862921887077e-05 \n",
      "epoch: 34 [125543/888800 14.12%] train loss: 1.4185223335516639e-05 \n",
      "epoch: 34 [126654/888800 14.25%] train loss: 1.4719406863150652e-05 \n",
      "epoch: 34 [127765/888800 14.38%] train loss: 1.4288089914771263e-05 \n",
      "epoch: 34 [128876/888800 14.50%] train loss: 1.4490722605842166e-05 \n",
      "epoch: 34 [129987/888800 14.62%] train loss: 1.2738600162265357e-05 \n",
      "epoch: 34 [131098/888800 14.75%] train loss: 1.4063179150980432e-05 \n",
      "epoch: 34 [132209/888800 14.88%] train loss: 1.3680571100849193e-05 \n",
      "epoch: 34 [133320/888800 15.00%] train loss: 1.3364705409912858e-05 \n",
      "epoch: 34 [134431/888800 15.12%] train loss: 1.4682172150060069e-05 \n",
      "epoch: 34 [135542/888800 15.25%] train loss: 1.3621387552120723e-05 \n",
      "epoch: 34 [136653/888800 15.38%] train loss: 1.478356534789782e-05 \n",
      "epoch: 34 [137764/888800 15.50%] train loss: 1.425410300726071e-05 \n",
      "epoch: 34 [138875/888800 15.62%] train loss: 1.396792140440084e-05 \n",
      "epoch: 34 [139986/888800 15.75%] train loss: 1.4725509572599549e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [141097/888800 15.88%] train loss: 1.4658802683698013e-05 \n",
      "epoch: 34 [142208/888800 16.00%] train loss: 1.3793147445539944e-05 \n",
      "epoch: 34 [143319/888800 16.12%] train loss: 1.4323847608466167e-05 \n",
      "epoch: 34 [144430/888800 16.25%] train loss: 1.448200418963097e-05 \n",
      "epoch: 34 [145541/888800 16.38%] train loss: 1.3594819392892532e-05 \n",
      "epoch: 34 [146652/888800 16.50%] train loss: 1.3187318472773768e-05 \n",
      "epoch: 34 [147763/888800 16.62%] train loss: 1.4453249605139717e-05 \n",
      "epoch: 34 [148874/888800 16.75%] train loss: 1.4829482097411528e-05 \n",
      "epoch: 34 [149985/888800 16.88%] train loss: 1.4572102372767404e-05 \n",
      "epoch: 34 [151096/888800 17.00%] train loss: 1.5722338503110223e-05 \n",
      "epoch: 34 [152207/888800 17.12%] train loss: 1.3731691979046445e-05 \n",
      "epoch: 34 [153318/888800 17.25%] train loss: 1.5047812667035032e-05 \n",
      "epoch: 34 [154429/888800 17.38%] train loss: 1.5409816114697605e-05 \n",
      "epoch: 34 [155540/888800 17.50%] train loss: 1.4587894838768989e-05 \n",
      "epoch: 34 [156651/888800 17.62%] train loss: 1.4379002095665783e-05 \n",
      "epoch: 34 [157762/888800 17.75%] train loss: 1.3814006706525106e-05 \n",
      "epoch: 34 [158873/888800 17.88%] train loss: 1.5497609638259746e-05 \n",
      "epoch: 34 [159984/888800 18.00%] train loss: 1.587393126101233e-05 \n",
      "epoch: 34 [161095/888800 18.12%] train loss: 1.4194132745615207e-05 \n",
      "epoch: 34 [162206/888800 18.25%] train loss: 1.5269570212694816e-05 \n",
      "epoch: 34 [163317/888800 18.38%] train loss: 1.4061482033866923e-05 \n",
      "epoch: 34 [164428/888800 18.50%] train loss: 1.4020551134308334e-05 \n",
      "epoch: 34 [165539/888800 18.62%] train loss: 1.3585809028882068e-05 \n",
      "epoch: 34 [166650/888800 18.75%] train loss: 1.4571657629858237e-05 \n",
      "epoch: 34 [167761/888800 18.88%] train loss: 1.39726198540302e-05 \n",
      "epoch: 34 [168872/888800 19.00%] train loss: 1.4364381058840081e-05 \n",
      "epoch: 34 [169983/888800 19.12%] train loss: 1.417671319359215e-05 \n",
      "epoch: 34 [171094/888800 19.25%] train loss: 1.4125680536380969e-05 \n",
      "epoch: 34 [172205/888800 19.38%] train loss: 1.4355377970787231e-05 \n",
      "epoch: 34 [173316/888800 19.50%] train loss: 1.4549319530487992e-05 \n",
      "epoch: 34 [174427/888800 19.62%] train loss: 1.3339506949705537e-05 \n",
      "epoch: 34 [175538/888800 19.75%] train loss: 1.497392076998949e-05 \n",
      "epoch: 34 [176649/888800 19.88%] train loss: 1.4476026080956217e-05 \n",
      "epoch: 34 [177760/888800 20.00%] train loss: 1.3434766515274532e-05 \n",
      "epoch: 34 [178871/888800 20.12%] train loss: 1.3582663996203337e-05 \n",
      "epoch: 34 [179982/888800 20.25%] train loss: 1.3665895494341385e-05 \n",
      "epoch: 34 [181093/888800 20.38%] train loss: 1.4648860997112934e-05 \n",
      "epoch: 34 [182204/888800 20.50%] train loss: 1.3636967196362093e-05 \n",
      "epoch: 34 [183315/888800 20.62%] train loss: 1.4277673471951857e-05 \n",
      "epoch: 34 [184426/888800 20.75%] train loss: 1.3791891433356795e-05 \n",
      "epoch: 34 [185537/888800 20.88%] train loss: 1.350352704321267e-05 \n",
      "epoch: 34 [186648/888800 21.00%] train loss: 1.4878731235512532e-05 \n",
      "epoch: 34 [187759/888800 21.12%] train loss: 1.4080779692449141e-05 \n",
      "epoch: 34 [188870/888800 21.25%] train loss: 1.280543438042514e-05 \n",
      "epoch: 34 [189981/888800 21.38%] train loss: 1.3962435332359746e-05 \n",
      "epoch: 34 [191092/888800 21.50%] train loss: 1.5010083188826684e-05 \n",
      "epoch: 34 [192203/888800 21.62%] train loss: 1.4056809050089214e-05 \n",
      "epoch: 34 [193314/888800 21.75%] train loss: 1.4121085769147612e-05 \n",
      "epoch: 34 [194425/888800 21.88%] train loss: 1.4662336980109103e-05 \n",
      "epoch: 34 [195536/888800 22.00%] train loss: 1.5251895092660561e-05 \n",
      "epoch: 34 [196647/888800 22.12%] train loss: 1.4257246220950037e-05 \n",
      "epoch: 34 [197758/888800 22.25%] train loss: 1.4637338608736172e-05 \n",
      "epoch: 34 [198869/888800 22.38%] train loss: 1.3886619854019955e-05 \n",
      "epoch: 34 [199980/888800 22.50%] train loss: 1.3006811059312895e-05 \n",
      "epoch: 34 [201091/888800 22.62%] train loss: 1.4288953025243245e-05 \n",
      "epoch: 34 [202202/888800 22.75%] train loss: 1.3177633263694588e-05 \n",
      "epoch: 34 [203313/888800 22.88%] train loss: 1.3707682228414342e-05 \n",
      "epoch: 34 [204424/888800 23.00%] train loss: 1.450210766051896e-05 \n",
      "epoch: 34 [205535/888800 23.12%] train loss: 1.3480358575179707e-05 \n",
      "epoch: 34 [206646/888800 23.25%] train loss: 1.3549117284128442e-05 \n",
      "epoch: 34 [207757/888800 23.38%] train loss: 1.4056724467081949e-05 \n",
      "epoch: 34 [208868/888800 23.50%] train loss: 1.2376139238767792e-05 \n",
      "epoch: 34 [209979/888800 23.62%] train loss: 1.389632870996138e-05 \n",
      "epoch: 34 [211090/888800 23.75%] train loss: 1.382948084938107e-05 \n",
      "epoch: 34 [212201/888800 23.88%] train loss: 1.3425699762592558e-05 \n",
      "epoch: 34 [213312/888800 24.00%] train loss: 1.398519907525042e-05 \n",
      "epoch: 34 [214423/888800 24.12%] train loss: 1.3648925232701004e-05 \n",
      "epoch: 34 [215534/888800 24.25%] train loss: 1.5440662537002936e-05 \n",
      "epoch: 34 [216645/888800 24.38%] train loss: 1.3655421753355768e-05 \n",
      "epoch: 34 [217756/888800 24.50%] train loss: 1.4840021322015673e-05 \n",
      "epoch: 34 [218867/888800 24.62%] train loss: 1.4419048056879546e-05 \n",
      "epoch: 34 [219978/888800 24.75%] train loss: 1.4890392776578665e-05 \n",
      "epoch: 34 [221089/888800 24.88%] train loss: 1.5228626580210403e-05 \n",
      "epoch: 34 [222200/888800 25.00%] train loss: 1.3871404917153995e-05 \n",
      "epoch: 34 [223311/888800 25.12%] train loss: 1.3760900401393883e-05 \n",
      "epoch: 34 [224422/888800 25.25%] train loss: 1.3648791536979843e-05 \n",
      "epoch: 34 [225533/888800 25.38%] train loss: 1.5280917068594135e-05 \n",
      "epoch: 34 [226644/888800 25.50%] train loss: 1.4080259461479727e-05 \n",
      "epoch: 34 [227755/888800 25.62%] train loss: 1.4078784261073451e-05 \n",
      "epoch: 34 [228866/888800 25.75%] train loss: 1.3389952073339373e-05 \n",
      "epoch: 34 [229977/888800 25.88%] train loss: 1.4662656212749425e-05 \n",
      "epoch: 34 [231088/888800 26.00%] train loss: 1.4810191714786924e-05 \n",
      "epoch: 34 [232199/888800 26.12%] train loss: 1.431569216947537e-05 \n",
      "epoch: 34 [233310/888800 26.25%] train loss: 1.43155029945774e-05 \n",
      "epoch: 34 [234421/888800 26.38%] train loss: 1.3924746781412978e-05 \n",
      "epoch: 34 [235532/888800 26.50%] train loss: 1.4052837286726572e-05 \n",
      "epoch: 34 [236643/888800 26.62%] train loss: 1.5227048606902827e-05 \n",
      "epoch: 34 [237754/888800 26.75%] train loss: 1.4954123798816e-05 \n",
      "epoch: 34 [238865/888800 26.88%] train loss: 1.4380862012330908e-05 \n",
      "epoch: 34 [239976/888800 27.00%] train loss: 1.5381987395812757e-05 \n",
      "epoch: 34 [241087/888800 27.12%] train loss: 1.542851714475546e-05 \n",
      "epoch: 34 [242198/888800 27.25%] train loss: 1.4021105926076416e-05 \n",
      "epoch: 34 [243309/888800 27.38%] train loss: 1.4347038813866675e-05 \n",
      "epoch: 34 [244420/888800 27.50%] train loss: 1.5531604731222615e-05 \n",
      "epoch: 34 [245531/888800 27.62%] train loss: 1.553269976284355e-05 \n",
      "epoch: 34 [246642/888800 27.75%] train loss: 1.3943881640443578e-05 \n",
      "epoch: 34 [247753/888800 27.88%] train loss: 1.711253571556881e-05 \n",
      "epoch: 34 [248864/888800 28.00%] train loss: 1.5821009583305568e-05 \n",
      "epoch: 34 [249975/888800 28.12%] train loss: 1.4296341760200448e-05 \n",
      "epoch: 34 [251086/888800 28.25%] train loss: 1.5318715668399818e-05 \n",
      "epoch: 34 [252197/888800 28.38%] train loss: 1.3685312296729535e-05 \n",
      "epoch: 34 [253308/888800 28.50%] train loss: 1.5176737178990152e-05 \n",
      "epoch: 34 [254419/888800 28.62%] train loss: 1.531499765405897e-05 \n",
      "epoch: 34 [255530/888800 28.75%] train loss: 1.4776107491343282e-05 \n",
      "epoch: 34 [256641/888800 28.88%] train loss: 1.3585991837317124e-05 \n",
      "epoch: 34 [257752/888800 29.00%] train loss: 1.4020141861692537e-05 \n",
      "epoch: 34 [258863/888800 29.12%] train loss: 1.4041744179849047e-05 \n",
      "epoch: 34 [259974/888800 29.25%] train loss: 1.4820820069871843e-05 \n",
      "epoch: 34 [261085/888800 29.38%] train loss: 1.4324579751701094e-05 \n",
      "epoch: 34 [262196/888800 29.50%] train loss: 1.3364433470997028e-05 \n",
      "epoch: 34 [263307/888800 29.62%] train loss: 1.5449530110345222e-05 \n",
      "epoch: 34 [264418/888800 29.75%] train loss: 1.3988400496600661e-05 \n",
      "epoch: 34 [265529/888800 29.88%] train loss: 1.4481477592198644e-05 \n",
      "epoch: 34 [266640/888800 30.00%] train loss: 1.468594291509362e-05 \n",
      "epoch: 34 [267751/888800 30.12%] train loss: 1.515858184575336e-05 \n",
      "epoch: 34 [268862/888800 30.25%] train loss: 1.4881928109389264e-05 \n",
      "epoch: 34 [269973/888800 30.38%] train loss: 1.3926446627010591e-05 \n",
      "epoch: 34 [271084/888800 30.50%] train loss: 1.532553869765252e-05 \n",
      "epoch: 34 [272195/888800 30.62%] train loss: 1.3842292901244946e-05 \n",
      "epoch: 34 [273306/888800 30.75%] train loss: 1.4035726962902118e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [274417/888800 30.88%] train loss: 1.3672251952812076e-05 \n",
      "epoch: 34 [275528/888800 31.00%] train loss: 1.5738996808067895e-05 \n",
      "epoch: 34 [276639/888800 31.12%] train loss: 1.4464373634837102e-05 \n",
      "epoch: 34 [277750/888800 31.25%] train loss: 1.3210631550464313e-05 \n",
      "epoch: 34 [278861/888800 31.38%] train loss: 1.3602547369373497e-05 \n",
      "epoch: 34 [279972/888800 31.50%] train loss: 1.4411490155907813e-05 \n",
      "epoch: 34 [281083/888800 31.62%] train loss: 1.3861245861335192e-05 \n",
      "epoch: 34 [282194/888800 31.75%] train loss: 1.4004156582814176e-05 \n",
      "epoch: 34 [283305/888800 31.88%] train loss: 1.4766054846404586e-05 \n",
      "epoch: 34 [284416/888800 32.00%] train loss: 1.4280902178143151e-05 \n",
      "epoch: 34 [285527/888800 32.12%] train loss: 1.3164853953639977e-05 \n",
      "epoch: 34 [286638/888800 32.25%] train loss: 1.5000151506683324e-05 \n",
      "epoch: 34 [287749/888800 32.38%] train loss: 1.464854631194612e-05 \n",
      "epoch: 34 [288860/888800 32.50%] train loss: 1.5635681847925298e-05 \n",
      "epoch: 34 [289971/888800 32.62%] train loss: 1.4476974683930166e-05 \n",
      "epoch: 34 [291082/888800 32.75%] train loss: 1.4441562598221935e-05 \n",
      "epoch: 34 [292193/888800 32.88%] train loss: 1.5028094821900595e-05 \n",
      "epoch: 34 [293304/888800 33.00%] train loss: 1.364857416774612e-05 \n",
      "epoch: 34 [294415/888800 33.12%] train loss: 1.4162484148982912e-05 \n",
      "epoch: 34 [295526/888800 33.25%] train loss: 1.5455123502761126e-05 \n",
      "epoch: 34 [296637/888800 33.38%] train loss: 1.4281392395787407e-05 \n",
      "epoch: 34 [297748/888800 33.50%] train loss: 1.419714044459397e-05 \n",
      "epoch: 34 [298859/888800 33.62%] train loss: 1.3706507161259651e-05 \n",
      "epoch: 34 [299970/888800 33.75%] train loss: 1.5677351257181726e-05 \n",
      "epoch: 34 [301081/888800 33.88%] train loss: 1.2987884474569e-05 \n",
      "epoch: 34 [302192/888800 34.00%] train loss: 1.40147876663832e-05 \n",
      "epoch: 34 [303303/888800 34.12%] train loss: 1.4740424376213923e-05 \n",
      "epoch: 34 [304414/888800 34.25%] train loss: 1.539155528007541e-05 \n",
      "epoch: 34 [305525/888800 34.38%] train loss: 1.4285098586697131e-05 \n",
      "epoch: 34 [306636/888800 34.50%] train loss: 1.4378528248926159e-05 \n",
      "epoch: 34 [307747/888800 34.62%] train loss: 1.441198128304677e-05 \n",
      "epoch: 34 [308858/888800 34.75%] train loss: 1.4498208656732459e-05 \n",
      "epoch: 34 [309969/888800 34.88%] train loss: 1.4349131561175454e-05 \n",
      "epoch: 34 [311080/888800 35.00%] train loss: 1.5704137695138343e-05 \n",
      "epoch: 34 [312191/888800 35.12%] train loss: 1.5555853678961284e-05 \n",
      "epoch: 34 [313302/888800 35.25%] train loss: 1.532046553620603e-05 \n",
      "epoch: 34 [314413/888800 35.38%] train loss: 1.4293154890765436e-05 \n",
      "epoch: 34 [315524/888800 35.50%] train loss: 1.528048414911609e-05 \n",
      "epoch: 34 [316635/888800 35.62%] train loss: 1.4608771380153485e-05 \n",
      "epoch: 34 [317746/888800 35.75%] train loss: 1.3717898582399357e-05 \n",
      "epoch: 34 [318857/888800 35.88%] train loss: 1.3777934327663388e-05 \n",
      "epoch: 34 [319968/888800 36.00%] train loss: 1.489505848439876e-05 \n",
      "epoch: 34 [321079/888800 36.12%] train loss: 1.4086425835557748e-05 \n",
      "epoch: 34 [322190/888800 36.25%] train loss: 1.261830038856715e-05 \n",
      "epoch: 34 [323301/888800 36.38%] train loss: 1.3993494576425292e-05 \n",
      "epoch: 34 [324412/888800 36.50%] train loss: 1.277219780604355e-05 \n",
      "epoch: 34 [325523/888800 36.62%] train loss: 1.515380063210614e-05 \n",
      "epoch: 34 [326634/888800 36.75%] train loss: 1.4706439287692774e-05 \n",
      "epoch: 34 [327745/888800 36.88%] train loss: 1.448791408620309e-05 \n",
      "epoch: 34 [328856/888800 37.00%] train loss: 1.6599051377852447e-05 \n",
      "epoch: 34 [329967/888800 37.12%] train loss: 1.4384019777935464e-05 \n",
      "epoch: 34 [331078/888800 37.25%] train loss: 1.4246686077967752e-05 \n",
      "epoch: 34 [332189/888800 37.38%] train loss: 1.353115658275783e-05 \n",
      "epoch: 34 [333300/888800 37.50%] train loss: 1.5410671039717272e-05 \n",
      "epoch: 34 [334411/888800 37.62%] train loss: 1.4828260646027047e-05 \n",
      "epoch: 34 [335522/888800 37.75%] train loss: 1.4767099855816923e-05 \n",
      "epoch: 34 [336633/888800 37.88%] train loss: 1.3656230294145644e-05 \n",
      "epoch: 34 [337744/888800 38.00%] train loss: 1.4754621588508599e-05 \n",
      "epoch: 34 [338855/888800 38.12%] train loss: 1.4676829778181855e-05 \n",
      "epoch: 34 [339966/888800 38.25%] train loss: 1.4734509022673592e-05 \n",
      "epoch: 34 [341077/888800 38.38%] train loss: 1.563504702062346e-05 \n",
      "epoch: 34 [342188/888800 38.50%] train loss: 1.4216395356925204e-05 \n",
      "epoch: 34 [343299/888800 38.62%] train loss: 1.323117976426147e-05 \n",
      "epoch: 34 [344410/888800 38.75%] train loss: 1.3007792404096108e-05 \n",
      "epoch: 34 [345521/888800 38.88%] train loss: 1.3759908142674249e-05 \n",
      "epoch: 34 [346632/888800 39.00%] train loss: 1.5028818779683206e-05 \n",
      "epoch: 34 [347743/888800 39.12%] train loss: 1.4965262380428612e-05 \n",
      "epoch: 34 [348854/888800 39.25%] train loss: 1.4123330402071588e-05 \n",
      "epoch: 34 [349965/888800 39.38%] train loss: 1.378090564685408e-05 \n",
      "epoch: 34 [351076/888800 39.50%] train loss: 1.4207704225555062e-05 \n",
      "epoch: 34 [352187/888800 39.62%] train loss: 1.5122244803933427e-05 \n",
      "epoch: 34 [353298/888800 39.75%] train loss: 1.414272264810279e-05 \n",
      "epoch: 34 [354409/888800 39.88%] train loss: 1.5006512512627523e-05 \n",
      "epoch: 34 [355520/888800 40.00%] train loss: 1.3306382243172266e-05 \n",
      "epoch: 34 [356631/888800 40.12%] train loss: 1.5468958736164495e-05 \n",
      "epoch: 34 [357742/888800 40.25%] train loss: 1.4058605302125216e-05 \n",
      "epoch: 34 [358853/888800 40.38%] train loss: 1.5002448890300002e-05 \n",
      "epoch: 34 [359964/888800 40.50%] train loss: 1.453589902666863e-05 \n",
      "epoch: 34 [361075/888800 40.62%] train loss: 1.4812393601459917e-05 \n",
      "epoch: 34 [362186/888800 40.75%] train loss: 1.4771514543099329e-05 \n",
      "epoch: 34 [363297/888800 40.88%] train loss: 1.4164485946821515e-05 \n",
      "epoch: 34 [364408/888800 41.00%] train loss: 1.439012248738436e-05 \n",
      "epoch: 34 [365519/888800 41.12%] train loss: 1.3735707398154773e-05 \n",
      "epoch: 34 [366630/888800 41.25%] train loss: 1.3515851605916396e-05 \n",
      "epoch: 34 [367741/888800 41.38%] train loss: 1.326875644735992e-05 \n",
      "epoch: 34 [368852/888800 41.50%] train loss: 1.3088852938381024e-05 \n",
      "epoch: 34 [369963/888800 41.62%] train loss: 1.5324618289014325e-05 \n",
      "epoch: 34 [371074/888800 41.75%] train loss: 1.3030450645601377e-05 \n",
      "epoch: 34 [372185/888800 41.88%] train loss: 1.618009810044896e-05 \n",
      "epoch: 34 [373296/888800 42.00%] train loss: 1.379966579406755e-05 \n",
      "epoch: 34 [374407/888800 42.12%] train loss: 1.53424571180949e-05 \n",
      "epoch: 34 [375518/888800 42.25%] train loss: 1.382860318699386e-05 \n",
      "epoch: 34 [376629/888800 42.38%] train loss: 1.5120797797862906e-05 \n",
      "epoch: 34 [377740/888800 42.50%] train loss: 1.4885317796142772e-05 \n",
      "epoch: 34 [378851/888800 42.62%] train loss: 1.5224694834614638e-05 \n",
      "epoch: 34 [379962/888800 42.75%] train loss: 1.468080790800741e-05 \n",
      "epoch: 34 [381073/888800 42.88%] train loss: 1.3494512131728698e-05 \n",
      "epoch: 34 [382184/888800 43.00%] train loss: 1.4250415915739723e-05 \n",
      "epoch: 34 [383295/888800 43.12%] train loss: 1.3201249203120824e-05 \n",
      "epoch: 34 [384406/888800 43.25%] train loss: 1.4643087524746079e-05 \n",
      "epoch: 34 [385517/888800 43.38%] train loss: 1.352044000668684e-05 \n",
      "epoch: 34 [386628/888800 43.50%] train loss: 1.3163796211301815e-05 \n",
      "epoch: 34 [387739/888800 43.62%] train loss: 1.416163649992086e-05 \n",
      "epoch: 34 [388850/888800 43.75%] train loss: 1.4807867955823895e-05 \n",
      "epoch: 34 [389961/888800 43.88%] train loss: 1.4207254935172386e-05 \n",
      "epoch: 34 [391072/888800 44.00%] train loss: 1.4783759979764e-05 \n",
      "epoch: 34 [392183/888800 44.12%] train loss: 1.3424569260678254e-05 \n",
      "epoch: 34 [393294/888800 44.25%] train loss: 1.451353728043614e-05 \n",
      "epoch: 34 [394405/888800 44.38%] train loss: 1.555113703943789e-05 \n",
      "epoch: 34 [395516/888800 44.50%] train loss: 1.4069701137486845e-05 \n",
      "epoch: 34 [396627/888800 44.62%] train loss: 1.3373159163165838e-05 \n",
      "epoch: 34 [397738/888800 44.75%] train loss: 1.522474212833913e-05 \n",
      "epoch: 34 [398849/888800 44.88%] train loss: 1.5350615285569802e-05 \n",
      "epoch: 34 [399960/888800 45.00%] train loss: 1.4197076779964846e-05 \n",
      "epoch: 34 [401071/888800 45.12%] train loss: 1.4436342098633759e-05 \n",
      "epoch: 34 [402182/888800 45.25%] train loss: 1.367573713650927e-05 \n",
      "epoch: 34 [403293/888800 45.38%] train loss: 1.5142447409743909e-05 \n",
      "epoch: 34 [404404/888800 45.50%] train loss: 1.4004534932610113e-05 \n",
      "epoch: 34 [405515/888800 45.62%] train loss: 1.5103900295798667e-05 \n",
      "epoch: 34 [406626/888800 45.75%] train loss: 1.434857495041797e-05 \n",
      "epoch: 34 [407737/888800 45.88%] train loss: 1.3742203918809537e-05 \n",
      "epoch: 34 [408848/888800 46.00%] train loss: 1.430204156349646e-05 \n",
      "epoch: 34 [409959/888800 46.12%] train loss: 1.432944554835558e-05 \n",
      "epoch: 34 [411070/888800 46.25%] train loss: 1.4051943253434729e-05 \n",
      "epoch: 34 [412181/888800 46.38%] train loss: 1.4776200259802863e-05 \n",
      "epoch: 34 [413292/888800 46.50%] train loss: 1.377789430989651e-05 \n",
      "epoch: 34 [414403/888800 46.62%] train loss: 1.4116219972493127e-05 \n",
      "epoch: 34 [415514/888800 46.75%] train loss: 1.5071884263306856e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [416625/888800 46.88%] train loss: 1.4187156921252608e-05 \n",
      "epoch: 34 [417736/888800 47.00%] train loss: 1.3341998055693693e-05 \n",
      "epoch: 34 [418847/888800 47.12%] train loss: 1.4704262866871431e-05 \n",
      "epoch: 34 [419958/888800 47.25%] train loss: 1.438836261513643e-05 \n",
      "epoch: 34 [421069/888800 47.38%] train loss: 1.4951944649510551e-05 \n",
      "epoch: 34 [422180/888800 47.50%] train loss: 1.416943359799916e-05 \n",
      "epoch: 34 [423291/888800 47.62%] train loss: 1.4875936358293984e-05 \n",
      "epoch: 34 [424402/888800 47.75%] train loss: 1.487764802732272e-05 \n",
      "epoch: 34 [425513/888800 47.88%] train loss: 1.3541782209358644e-05 \n",
      "epoch: 34 [426624/888800 48.00%] train loss: 1.5007230103947222e-05 \n",
      "epoch: 34 [427735/888800 48.12%] train loss: 1.3802879948343616e-05 \n",
      "epoch: 34 [428846/888800 48.25%] train loss: 1.4045098396309186e-05 \n",
      "epoch: 34 [429957/888800 48.38%] train loss: 1.450312356610084e-05 \n",
      "epoch: 34 [431068/888800 48.50%] train loss: 1.4502463272947352e-05 \n",
      "epoch: 34 [432179/888800 48.62%] train loss: 1.3838332961313426e-05 \n",
      "epoch: 34 [433290/888800 48.75%] train loss: 1.393408456351608e-05 \n",
      "epoch: 34 [434401/888800 48.88%] train loss: 1.3965061043563765e-05 \n",
      "epoch: 34 [435512/888800 49.00%] train loss: 1.4010419363330584e-05 \n",
      "epoch: 34 [436623/888800 49.12%] train loss: 1.5339448509621434e-05 \n",
      "epoch: 34 [437734/888800 49.25%] train loss: 1.4965442460379563e-05 \n",
      "epoch: 34 [438845/888800 49.38%] train loss: 1.452665946999332e-05 \n",
      "epoch: 34 [439956/888800 49.50%] train loss: 1.6124271496664733e-05 \n",
      "epoch: 34 [441067/888800 49.62%] train loss: 1.425296431989409e-05 \n",
      "epoch: 34 [442178/888800 49.75%] train loss: 1.4936573279555887e-05 \n",
      "epoch: 34 [443289/888800 49.88%] train loss: 1.4463274055742659e-05 \n",
      "epoch: 34 [444400/888800 50.00%] train loss: 1.4362663023348432e-05 \n",
      "epoch: 34 [445511/888800 50.12%] train loss: 1.3983015378471464e-05 \n",
      "epoch: 34 [446622/888800 50.25%] train loss: 1.4542058124789037e-05 \n",
      "epoch: 34 [447733/888800 50.38%] train loss: 1.348205296380911e-05 \n",
      "epoch: 34 [448844/888800 50.50%] train loss: 1.3891117305320222e-05 \n",
      "epoch: 34 [449955/888800 50.62%] train loss: 1.4297335837909486e-05 \n",
      "epoch: 34 [451066/888800 50.75%] train loss: 1.3976218724565115e-05 \n",
      "epoch: 34 [452177/888800 50.88%] train loss: 1.4482361621048767e-05 \n",
      "epoch: 34 [453288/888800 51.00%] train loss: 1.435574176866794e-05 \n",
      "epoch: 34 [454399/888800 51.12%] train loss: 1.3985948498884682e-05 \n",
      "epoch: 34 [455510/888800 51.25%] train loss: 1.381156653224025e-05 \n",
      "epoch: 34 [456621/888800 51.38%] train loss: 1.4760549674974754e-05 \n",
      "epoch: 34 [457732/888800 51.50%] train loss: 1.4188249224389438e-05 \n",
      "epoch: 34 [458843/888800 51.62%] train loss: 1.3694758308702148e-05 \n",
      "epoch: 34 [459954/888800 51.75%] train loss: 1.4981950698711444e-05 \n",
      "epoch: 34 [461065/888800 51.88%] train loss: 1.4238858057069592e-05 \n",
      "epoch: 34 [462176/888800 52.00%] train loss: 1.3698969269171357e-05 \n",
      "epoch: 34 [463287/888800 52.12%] train loss: 1.401433655701112e-05 \n",
      "epoch: 34 [464398/888800 52.25%] train loss: 1.2912345482618548e-05 \n",
      "epoch: 34 [465509/888800 52.38%] train loss: 1.4752894458069932e-05 \n",
      "epoch: 34 [466620/888800 52.50%] train loss: 1.5042196537251584e-05 \n",
      "epoch: 34 [467731/888800 52.62%] train loss: 1.3831309843226336e-05 \n",
      "epoch: 34 [468842/888800 52.75%] train loss: 1.6617283108644187e-05 \n",
      "epoch: 34 [469953/888800 52.88%] train loss: 1.3802383364236448e-05 \n",
      "epoch: 34 [471064/888800 53.00%] train loss: 1.4052884580451064e-05 \n",
      "epoch: 34 [472175/888800 53.12%] train loss: 1.4469857887888793e-05 \n",
      "epoch: 34 [473286/888800 53.25%] train loss: 1.4763557373953518e-05 \n",
      "epoch: 34 [474397/888800 53.38%] train loss: 1.5143936252570711e-05 \n",
      "epoch: 34 [475508/888800 53.50%] train loss: 1.4352276593854185e-05 \n",
      "epoch: 34 [476619/888800 53.62%] train loss: 1.343042004009476e-05 \n",
      "epoch: 34 [477730/888800 53.75%] train loss: 1.4275765352067538e-05 \n",
      "epoch: 34 [478841/888800 53.88%] train loss: 1.4268740414991044e-05 \n",
      "epoch: 34 [479952/888800 54.00%] train loss: 1.5180249647528399e-05 \n",
      "epoch: 34 [481063/888800 54.12%] train loss: 1.3514212696463801e-05 \n",
      "epoch: 34 [482174/888800 54.25%] train loss: 1.5116579561436083e-05 \n",
      "epoch: 34 [483285/888800 54.38%] train loss: 1.437729224562645e-05 \n",
      "epoch: 34 [484396/888800 54.50%] train loss: 1.4227685824153014e-05 \n",
      "epoch: 34 [485507/888800 54.62%] train loss: 1.5401366908918135e-05 \n",
      "epoch: 34 [486618/888800 54.75%] train loss: 1.5467086996068247e-05 \n",
      "epoch: 34 [487729/888800 54.88%] train loss: 1.546430394228082e-05 \n",
      "epoch: 34 [488840/888800 55.00%] train loss: 1.4219094737200066e-05 \n",
      "epoch: 34 [489951/888800 55.12%] train loss: 1.4192727576300967e-05 \n",
      "epoch: 34 [491062/888800 55.25%] train loss: 1.3553335520555265e-05 \n",
      "epoch: 34 [492173/888800 55.38%] train loss: 1.2795299880963285e-05 \n",
      "epoch: 34 [493284/888800 55.50%] train loss: 1.490251270297449e-05 \n",
      "epoch: 34 [494395/888800 55.62%] train loss: 1.3695716916117817e-05 \n",
      "epoch: 34 [495506/888800 55.75%] train loss: 1.4131468560663052e-05 \n",
      "epoch: 34 [496617/888800 55.88%] train loss: 1.4449812624661718e-05 \n",
      "epoch: 34 [497728/888800 56.00%] train loss: 1.4334618754219264e-05 \n",
      "epoch: 34 [498839/888800 56.12%] train loss: 1.3434805623546708e-05 \n",
      "epoch: 34 [499950/888800 56.25%] train loss: 1.4576032299373765e-05 \n",
      "epoch: 34 [501061/888800 56.38%] train loss: 1.4466208085650578e-05 \n",
      "epoch: 34 [502172/888800 56.50%] train loss: 1.3919770935899578e-05 \n",
      "epoch: 34 [503283/888800 56.62%] train loss: 1.3490456694853492e-05 \n",
      "epoch: 34 [504394/888800 56.75%] train loss: 1.5064551007526461e-05 \n",
      "epoch: 34 [505505/888800 56.88%] train loss: 1.5032227565825451e-05 \n",
      "epoch: 34 [506616/888800 57.00%] train loss: 1.4759124496777076e-05 \n",
      "epoch: 34 [507727/888800 57.12%] train loss: 1.3434599168249406e-05 \n",
      "epoch: 34 [508838/888800 57.25%] train loss: 1.4726388144481461e-05 \n",
      "epoch: 34 [509949/888800 57.38%] train loss: 1.4396557162399404e-05 \n",
      "epoch: 34 [511060/888800 57.50%] train loss: 1.3963762285129633e-05 \n",
      "epoch: 34 [512171/888800 57.62%] train loss: 1.5050027286633849e-05 \n",
      "epoch: 34 [513282/888800 57.75%] train loss: 1.5184471521934029e-05 \n",
      "epoch: 34 [514393/888800 57.88%] train loss: 1.408724801876815e-05 \n",
      "epoch: 34 [515504/888800 58.00%] train loss: 1.468542996008182e-05 \n",
      "epoch: 34 [516615/888800 58.12%] train loss: 1.4184606698108837e-05 \n",
      "epoch: 34 [517726/888800 58.25%] train loss: 1.3553490134654567e-05 \n",
      "epoch: 34 [518837/888800 58.38%] train loss: 1.4558348084392492e-05 \n",
      "epoch: 34 [519948/888800 58.50%] train loss: 1.4464888408838306e-05 \n",
      "epoch: 34 [521059/888800 58.62%] train loss: 1.3873082025384065e-05 \n",
      "epoch: 34 [522170/888800 58.75%] train loss: 1.5043083294585813e-05 \n",
      "epoch: 34 [523281/888800 58.88%] train loss: 1.3215827493695542e-05 \n",
      "epoch: 34 [524392/888800 59.00%] train loss: 1.3748055607720744e-05 \n",
      "epoch: 34 [525503/888800 59.12%] train loss: 1.528691609564703e-05 \n",
      "epoch: 34 [526614/888800 59.25%] train loss: 1.378297292831121e-05 \n",
      "epoch: 34 [527725/888800 59.38%] train loss: 1.410781351296464e-05 \n",
      "epoch: 34 [528836/888800 59.50%] train loss: 1.3731698345509358e-05 \n",
      "epoch: 34 [529947/888800 59.62%] train loss: 1.3500924978870898e-05 \n",
      "epoch: 34 [531058/888800 59.75%] train loss: 1.4046455362404231e-05 \n",
      "epoch: 34 [532169/888800 59.88%] train loss: 1.5140700270421803e-05 \n",
      "epoch: 34 [533280/888800 60.00%] train loss: 1.3085979844618123e-05 \n",
      "epoch: 34 [534391/888800 60.12%] train loss: 1.3821645552525297e-05 \n",
      "epoch: 34 [535502/888800 60.25%] train loss: 1.4946391274861526e-05 \n",
      "epoch: 34 [536613/888800 60.38%] train loss: 1.5005441127868835e-05 \n",
      "epoch: 34 [537724/888800 60.50%] train loss: 1.4007428944751155e-05 \n",
      "epoch: 34 [538835/888800 60.62%] train loss: 1.3911228052165825e-05 \n",
      "epoch: 34 [539946/888800 60.75%] train loss: 1.5686358892708085e-05 \n",
      "epoch: 34 [541057/888800 60.88%] train loss: 1.3561106243287213e-05 \n",
      "epoch: 34 [542168/888800 61.00%] train loss: 1.4366520190378651e-05 \n",
      "epoch: 34 [543279/888800 61.12%] train loss: 1.4678343177365605e-05 \n",
      "epoch: 34 [544390/888800 61.25%] train loss: 1.3131558262102772e-05 \n",
      "epoch: 34 [545501/888800 61.38%] train loss: 1.4208320862962864e-05 \n",
      "epoch: 34 [546612/888800 61.50%] train loss: 1.5104580597835593e-05 \n",
      "epoch: 34 [547723/888800 61.62%] train loss: 1.3996420420880895e-05 \n",
      "epoch: 34 [548834/888800 61.75%] train loss: 1.4056961845199112e-05 \n",
      "epoch: 34 [549945/888800 61.88%] train loss: 1.4185614418238401e-05 \n",
      "epoch: 34 [551056/888800 62.00%] train loss: 1.487679128331365e-05 \n",
      "epoch: 34 [552167/888800 62.12%] train loss: 1.4252863365982193e-05 \n",
      "epoch: 34 [553278/888800 62.25%] train loss: 1.4320840818982106e-05 \n",
      "epoch: 34 [554389/888800 62.38%] train loss: 1.4178324818203691e-05 \n",
      "epoch: 34 [555500/888800 62.50%] train loss: 1.5028634152258746e-05 \n",
      "epoch: 34 [556611/888800 62.62%] train loss: 1.3277273865242023e-05 \n",
      "epoch: 34 [557722/888800 62.75%] train loss: 1.4012178326083813e-05 \n",
      "epoch: 34 [558833/888800 62.88%] train loss: 1.363842238788493e-05 \n",
      "epoch: 34 [559944/888800 63.00%] train loss: 1.4528049177897628e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [561055/888800 63.12%] train loss: 1.6094612874439918e-05 \n",
      "epoch: 34 [562166/888800 63.25%] train loss: 1.4125749657978304e-05 \n",
      "epoch: 34 [563277/888800 63.38%] train loss: 1.74573106050957e-05 \n",
      "epoch: 34 [564388/888800 63.50%] train loss: 1.4974103578424547e-05 \n",
      "epoch: 34 [565499/888800 63.62%] train loss: 1.5760331734782085e-05 \n",
      "epoch: 34 [566610/888800 63.75%] train loss: 1.5005808563728351e-05 \n",
      "epoch: 34 [567721/888800 63.88%] train loss: 1.532730857434217e-05 \n",
      "epoch: 34 [568832/888800 64.00%] train loss: 1.6057460015872493e-05 \n",
      "epoch: 34 [569943/888800 64.12%] train loss: 1.4869062397337984e-05 \n",
      "epoch: 34 [571054/888800 64.25%] train loss: 1.6606416465947405e-05 \n",
      "epoch: 34 [572165/888800 64.38%] train loss: 1.403040369041264e-05 \n",
      "epoch: 34 [573276/888800 64.50%] train loss: 1.4801584256929345e-05 \n",
      "epoch: 34 [574387/888800 64.62%] train loss: 1.3776466403214727e-05 \n",
      "epoch: 34 [575498/888800 64.75%] train loss: 1.5666455510654487e-05 \n",
      "epoch: 34 [576609/888800 64.88%] train loss: 1.5051061382109765e-05 \n",
      "epoch: 34 [577720/888800 65.00%] train loss: 1.634447107790038e-05 \n",
      "epoch: 34 [578831/888800 65.12%] train loss: 1.3769551514997147e-05 \n",
      "epoch: 34 [579942/888800 65.25%] train loss: 1.380403136863606e-05 \n",
      "epoch: 34 [581053/888800 65.38%] train loss: 1.3887291061109863e-05 \n",
      "epoch: 34 [582164/888800 65.50%] train loss: 1.4480267054750584e-05 \n",
      "epoch: 34 [583275/888800 65.62%] train loss: 1.4698262020829134e-05 \n",
      "epoch: 34 [584386/888800 65.75%] train loss: 1.3462403330777306e-05 \n",
      "epoch: 34 [585497/888800 65.88%] train loss: 1.4333368199004326e-05 \n",
      "epoch: 34 [586608/888800 66.00%] train loss: 1.5461357179447077e-05 \n",
      "epoch: 34 [587719/888800 66.12%] train loss: 1.3522945664590225e-05 \n",
      "epoch: 34 [588830/888800 66.25%] train loss: 1.3305713764566462e-05 \n",
      "epoch: 34 [589941/888800 66.38%] train loss: 1.2843079275626224e-05 \n",
      "epoch: 34 [591052/888800 66.50%] train loss: 1.4550263585988432e-05 \n",
      "epoch: 34 [592163/888800 66.62%] train loss: 1.5054805771796964e-05 \n",
      "epoch: 34 [593274/888800 66.75%] train loss: 1.5428498954861425e-05 \n",
      "epoch: 34 [594385/888800 66.88%] train loss: 1.3058294825896155e-05 \n",
      "epoch: 34 [595496/888800 67.00%] train loss: 1.3230835065769497e-05 \n",
      "epoch: 34 [596607/888800 67.12%] train loss: 1.557122595841065e-05 \n",
      "epoch: 34 [597718/888800 67.25%] train loss: 1.4062693480809685e-05 \n",
      "epoch: 34 [598829/888800 67.38%] train loss: 1.4325883967103437e-05 \n",
      "epoch: 34 [599940/888800 67.50%] train loss: 1.3576664969150443e-05 \n",
      "epoch: 34 [601051/888800 67.62%] train loss: 1.540294397273101e-05 \n",
      "epoch: 34 [602162/888800 67.75%] train loss: 1.4418000318983104e-05 \n",
      "epoch: 34 [603273/888800 67.88%] train loss: 1.4253455447033048e-05 \n",
      "epoch: 34 [604384/888800 68.00%] train loss: 1.2754490853694733e-05 \n",
      "epoch: 34 [605495/888800 68.12%] train loss: 1.5277653801604174e-05 \n",
      "epoch: 34 [606606/888800 68.25%] train loss: 1.5028265806904528e-05 \n",
      "epoch: 34 [607717/888800 68.38%] train loss: 1.3379564734350424e-05 \n",
      "epoch: 34 [608828/888800 68.50%] train loss: 1.5443156371475197e-05 \n",
      "epoch: 34 [609939/888800 68.62%] train loss: 1.3121440133545548e-05 \n",
      "epoch: 34 [611050/888800 68.75%] train loss: 1.5308116417145357e-05 \n",
      "epoch: 34 [612161/888800 68.88%] train loss: 1.473300017096335e-05 \n",
      "epoch: 34 [613272/888800 69.00%] train loss: 1.4124912922852673e-05 \n",
      "epoch: 34 [614383/888800 69.12%] train loss: 1.5204794181045145e-05 \n",
      "epoch: 34 [615494/888800 69.25%] train loss: 1.4246161299524829e-05 \n",
      "epoch: 34 [616605/888800 69.38%] train loss: 1.5356301446445286e-05 \n",
      "epoch: 34 [617716/888800 69.50%] train loss: 1.2993843483855017e-05 \n",
      "epoch: 34 [618827/888800 69.62%] train loss: 1.463808621338103e-05 \n",
      "epoch: 34 [619938/888800 69.75%] train loss: 1.380808862450067e-05 \n",
      "epoch: 34 [621049/888800 69.88%] train loss: 1.4389177522389218e-05 \n",
      "epoch: 34 [622160/888800 70.00%] train loss: 1.3990793377161026e-05 \n",
      "epoch: 34 [623271/888800 70.12%] train loss: 1.4068611562834121e-05 \n",
      "epoch: 34 [624382/888800 70.25%] train loss: 1.3684680197911803e-05 \n",
      "epoch: 34 [625493/888800 70.38%] train loss: 1.392847207171144e-05 \n",
      "epoch: 34 [626604/888800 70.50%] train loss: 1.3863372259947937e-05 \n",
      "epoch: 34 [627715/888800 70.62%] train loss: 1.4263253433455247e-05 \n",
      "epoch: 34 [628826/888800 70.75%] train loss: 1.3797324754705187e-05 \n",
      "epoch: 34 [629937/888800 70.88%] train loss: 1.3497666259354446e-05 \n",
      "epoch: 34 [631048/888800 71.00%] train loss: 1.3654451322508976e-05 \n",
      "epoch: 34 [632159/888800 71.12%] train loss: 1.3863708772987593e-05 \n",
      "epoch: 34 [633270/888800 71.25%] train loss: 1.3204795322963037e-05 \n",
      "epoch: 34 [634381/888800 71.38%] train loss: 1.536011404823512e-05 \n",
      "epoch: 34 [635492/888800 71.50%] train loss: 1.43381766974926e-05 \n",
      "epoch: 34 [636603/888800 71.62%] train loss: 1.3856755685992539e-05 \n",
      "epoch: 34 [637714/888800 71.75%] train loss: 1.3614258023153525e-05 \n",
      "epoch: 34 [638825/888800 71.88%] train loss: 1.527545646240469e-05 \n",
      "epoch: 34 [639936/888800 72.00%] train loss: 1.46663878695108e-05 \n",
      "epoch: 34 [641047/888800 72.12%] train loss: 1.4697898222948425e-05 \n",
      "epoch: 34 [642158/888800 72.25%] train loss: 1.3281657629704569e-05 \n",
      "epoch: 34 [643269/888800 72.38%] train loss: 1.451231673854636e-05 \n",
      "epoch: 34 [644380/888800 72.50%] train loss: 1.533855356683489e-05 \n",
      "epoch: 34 [645491/888800 72.62%] train loss: 1.3899772966396995e-05 \n",
      "epoch: 34 [646602/888800 72.75%] train loss: 1.4598789675801527e-05 \n",
      "epoch: 34 [647713/888800 72.88%] train loss: 1.4065036339161452e-05 \n",
      "epoch: 34 [648824/888800 73.00%] train loss: 1.5341660400736146e-05 \n",
      "epoch: 34 [649935/888800 73.12%] train loss: 1.4525296137435362e-05 \n",
      "epoch: 34 [651046/888800 73.25%] train loss: 1.53021883306792e-05 \n",
      "epoch: 34 [652157/888800 73.38%] train loss: 1.574193811393343e-05 \n",
      "epoch: 34 [653268/888800 73.50%] train loss: 1.3418946764431894e-05 \n",
      "epoch: 34 [654379/888800 73.62%] train loss: 1.5249640455294866e-05 \n",
      "epoch: 34 [655490/888800 73.75%] train loss: 1.3742102055402938e-05 \n",
      "epoch: 34 [656601/888800 73.88%] train loss: 1.4511488188873045e-05 \n",
      "epoch: 34 [657712/888800 74.00%] train loss: 1.4107346032687929e-05 \n",
      "epoch: 34 [658823/888800 74.12%] train loss: 1.3798796317132656e-05 \n",
      "epoch: 34 [659934/888800 74.25%] train loss: 1.4504544196825009e-05 \n",
      "epoch: 34 [661045/888800 74.38%] train loss: 1.3649414540850557e-05 \n",
      "epoch: 34 [662156/888800 74.50%] train loss: 1.3914121154812165e-05 \n",
      "epoch: 34 [663267/888800 74.62%] train loss: 1.498703750257846e-05 \n",
      "epoch: 34 [664378/888800 74.75%] train loss: 1.3816485079587437e-05 \n",
      "epoch: 34 [665489/888800 74.88%] train loss: 1.3953985217085574e-05 \n",
      "epoch: 34 [666600/888800 75.00%] train loss: 1.5012326912255958e-05 \n",
      "epoch: 34 [667711/888800 75.12%] train loss: 1.3965651305625215e-05 \n",
      "epoch: 34 [668822/888800 75.25%] train loss: 1.4013138752488885e-05 \n",
      "epoch: 34 [669933/888800 75.38%] train loss: 1.5448424164787866e-05 \n",
      "epoch: 34 [671044/888800 75.50%] train loss: 1.3433230378723238e-05 \n",
      "epoch: 34 [672155/888800 75.62%] train loss: 1.4407833987206686e-05 \n",
      "epoch: 34 [673266/888800 75.75%] train loss: 1.4718652892042883e-05 \n",
      "epoch: 34 [674377/888800 75.88%] train loss: 1.3702082469535526e-05 \n",
      "epoch: 34 [675488/888800 76.00%] train loss: 1.5393188732559793e-05 \n",
      "epoch: 34 [676599/888800 76.12%] train loss: 1.3930510249338113e-05 \n",
      "epoch: 34 [677710/888800 76.25%] train loss: 1.6265023077721708e-05 \n",
      "epoch: 34 [678821/888800 76.38%] train loss: 1.2906079973618034e-05 \n",
      "epoch: 34 [679932/888800 76.50%] train loss: 1.5184340554696973e-05 \n",
      "epoch: 34 [681043/888800 76.62%] train loss: 1.445904217689531e-05 \n",
      "epoch: 34 [682154/888800 76.75%] train loss: 1.3563399079430383e-05 \n",
      "epoch: 34 [683265/888800 76.88%] train loss: 1.3698477232537698e-05 \n",
      "epoch: 34 [684376/888800 77.00%] train loss: 1.3671083252120297e-05 \n",
      "epoch: 34 [685487/888800 77.12%] train loss: 1.4056313375476748e-05 \n",
      "epoch: 34 [686598/888800 77.25%] train loss: 1.4599602764064912e-05 \n",
      "epoch: 34 [687709/888800 77.38%] train loss: 1.420765693183057e-05 \n",
      "epoch: 34 [688820/888800 77.50%] train loss: 1.4827430277364329e-05 \n",
      "epoch: 34 [689931/888800 77.62%] train loss: 1.3911613677919377e-05 \n",
      "epoch: 34 [691042/888800 77.75%] train loss: 1.3485055205819663e-05 \n",
      "epoch: 34 [692153/888800 77.88%] train loss: 1.5275551049853675e-05 \n",
      "epoch: 34 [693264/888800 78.00%] train loss: 1.3588526599050965e-05 \n",
      "epoch: 34 [694375/888800 78.12%] train loss: 1.4482578080787789e-05 \n",
      "epoch: 34 [695486/888800 78.25%] train loss: 1.2982671250938438e-05 \n",
      "epoch: 34 [696597/888800 78.38%] train loss: 1.4108570212556515e-05 \n",
      "epoch: 34 [697708/888800 78.50%] train loss: 1.409519427397754e-05 \n",
      "epoch: 34 [698819/888800 78.62%] train loss: 1.3262456377560738e-05 \n",
      "epoch: 34 [699930/888800 78.75%] train loss: 1.4195337826095056e-05 \n",
      "epoch: 34 [701041/888800 78.88%] train loss: 1.3245235095382668e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [702152/888800 79.00%] train loss: 1.3615985153592192e-05 \n",
      "epoch: 34 [703263/888800 79.12%] train loss: 1.4199178622220643e-05 \n",
      "epoch: 34 [704374/888800 79.25%] train loss: 1.5168819118116517e-05 \n",
      "epoch: 34 [705485/888800 79.38%] train loss: 1.4446884051722009e-05 \n",
      "epoch: 34 [706596/888800 79.50%] train loss: 1.3859513273928314e-05 \n",
      "epoch: 34 [707707/888800 79.62%] train loss: 1.572281507833395e-05 \n",
      "epoch: 34 [708818/888800 79.75%] train loss: 1.4152478797768708e-05 \n",
      "epoch: 34 [709929/888800 79.88%] train loss: 1.3944479178462643e-05 \n",
      "epoch: 34 [711040/888800 80.00%] train loss: 1.4120014384388924e-05 \n",
      "epoch: 34 [712151/888800 80.12%] train loss: 1.4758124962099828e-05 \n",
      "epoch: 34 [713262/888800 80.25%] train loss: 1.450155923521379e-05 \n",
      "epoch: 34 [714373/888800 80.38%] train loss: 1.4857286259939428e-05 \n",
      "epoch: 34 [715484/888800 80.50%] train loss: 1.440903088223422e-05 \n",
      "epoch: 34 [716595/888800 80.62%] train loss: 1.3707098332815804e-05 \n",
      "epoch: 34 [717706/888800 80.75%] train loss: 1.3932153706264216e-05 \n",
      "epoch: 34 [718817/888800 80.88%] train loss: 1.4072120393393561e-05 \n",
      "epoch: 34 [719928/888800 81.00%] train loss: 1.4031389582669362e-05 \n",
      "epoch: 34 [721039/888800 81.12%] train loss: 1.535978117317427e-05 \n",
      "epoch: 34 [722150/888800 81.25%] train loss: 1.3546816262532957e-05 \n",
      "epoch: 34 [723261/888800 81.38%] train loss: 1.4390656360774301e-05 \n",
      "epoch: 34 [724372/888800 81.50%] train loss: 1.4606499462388456e-05 \n",
      "epoch: 34 [725483/888800 81.62%] train loss: 1.5179631191131193e-05 \n",
      "epoch: 34 [726594/888800 81.75%] train loss: 1.384452116326429e-05 \n",
      "epoch: 34 [727705/888800 81.88%] train loss: 1.6982045053737238e-05 \n",
      "epoch: 34 [728816/888800 82.00%] train loss: 1.536020135972649e-05 \n",
      "epoch: 34 [729927/888800 82.12%] train loss: 1.4580692550225649e-05 \n",
      "epoch: 34 [731038/888800 82.25%] train loss: 1.4922579794074409e-05 \n",
      "epoch: 34 [732149/888800 82.38%] train loss: 1.591209729667753e-05 \n",
      "epoch: 34 [733260/888800 82.50%] train loss: 1.509477624495048e-05 \n",
      "epoch: 34 [734371/888800 82.62%] train loss: 1.4578833543055225e-05 \n",
      "epoch: 34 [735482/888800 82.75%] train loss: 1.526853156974539e-05 \n",
      "epoch: 34 [736593/888800 82.88%] train loss: 1.4012932297191583e-05 \n",
      "epoch: 34 [737704/888800 83.00%] train loss: 1.6113101082737558e-05 \n",
      "epoch: 34 [738815/888800 83.12%] train loss: 1.4059318345971406e-05 \n",
      "epoch: 34 [739926/888800 83.25%] train loss: 1.3768404642178211e-05 \n",
      "epoch: 34 [741037/888800 83.38%] train loss: 1.2960898857272696e-05 \n",
      "epoch: 34 [742148/888800 83.50%] train loss: 1.50131181726465e-05 \n",
      "epoch: 34 [743259/888800 83.62%] train loss: 1.3238205610832665e-05 \n",
      "epoch: 34 [744370/888800 83.75%] train loss: 1.4206443665898405e-05 \n",
      "epoch: 34 [745481/888800 83.88%] train loss: 1.4408655260922387e-05 \n",
      "epoch: 34 [746592/888800 84.00%] train loss: 1.3433515050564893e-05 \n",
      "epoch: 34 [747703/888800 84.12%] train loss: 1.4246221326175146e-05 \n",
      "epoch: 34 [748814/888800 84.25%] train loss: 1.3695551388082094e-05 \n",
      "epoch: 34 [749925/888800 84.38%] train loss: 1.508039167674724e-05 \n",
      "epoch: 34 [751036/888800 84.50%] train loss: 1.4747750356036704e-05 \n",
      "epoch: 34 [752147/888800 84.62%] train loss: 1.3209760254540015e-05 \n",
      "epoch: 34 [753258/888800 84.75%] train loss: 1.4318477042252198e-05 \n",
      "epoch: 34 [754369/888800 84.88%] train loss: 1.3925914572610054e-05 \n",
      "epoch: 34 [755480/888800 85.00%] train loss: 1.3241970918898005e-05 \n",
      "epoch: 34 [756591/888800 85.12%] train loss: 1.4087224371905904e-05 \n",
      "epoch: 34 [757702/888800 85.25%] train loss: 1.4807159459451213e-05 \n",
      "epoch: 34 [758813/888800 85.38%] train loss: 1.2966426766070072e-05 \n",
      "epoch: 34 [759924/888800 85.50%] train loss: 1.4395692232938018e-05 \n",
      "epoch: 34 [761035/888800 85.62%] train loss: 1.537360731163062e-05 \n",
      "epoch: 34 [762146/888800 85.75%] train loss: 1.4721790648764e-05 \n",
      "epoch: 34 [763257/888800 85.88%] train loss: 1.3860635590390302e-05 \n",
      "epoch: 34 [764368/888800 86.00%] train loss: 1.3910973393649329e-05 \n",
      "epoch: 34 [765479/888800 86.12%] train loss: 1.3305292668519542e-05 \n",
      "epoch: 34 [766590/888800 86.25%] train loss: 1.4282521988207009e-05 \n",
      "epoch: 34 [767701/888800 86.38%] train loss: 1.3653693713422399e-05 \n",
      "epoch: 34 [768812/888800 86.50%] train loss: 1.406389674230013e-05 \n",
      "epoch: 34 [769923/888800 86.62%] train loss: 1.3673055036633741e-05 \n",
      "epoch: 34 [771034/888800 86.75%] train loss: 1.4182193808665033e-05 \n",
      "epoch: 34 [772145/888800 86.88%] train loss: 1.3860499166185036e-05 \n",
      "epoch: 34 [773256/888800 87.00%] train loss: 1.4215996088751126e-05 \n",
      "epoch: 34 [774367/888800 87.12%] train loss: 1.479863203712739e-05 \n",
      "epoch: 34 [775478/888800 87.25%] train loss: 1.5145014003792312e-05 \n",
      "epoch: 34 [776589/888800 87.38%] train loss: 1.3062738617009018e-05 \n",
      "epoch: 34 [777700/888800 87.50%] train loss: 1.4275276043917984e-05 \n",
      "epoch: 34 [778811/888800 87.62%] train loss: 1.393390448356513e-05 \n",
      "epoch: 34 [779922/888800 87.75%] train loss: 1.402403722750023e-05 \n",
      "epoch: 34 [781033/888800 87.88%] train loss: 1.3786278941552155e-05 \n",
      "epoch: 34 [782144/888800 88.00%] train loss: 1.3995066183269955e-05 \n",
      "epoch: 34 [783255/888800 88.12%] train loss: 1.4958070096326992e-05 \n",
      "epoch: 34 [784366/888800 88.25%] train loss: 1.3664507605426479e-05 \n",
      "epoch: 34 [785477/888800 88.38%] train loss: 1.3210359611548483e-05 \n",
      "epoch: 34 [786588/888800 88.50%] train loss: 1.4302395356935449e-05 \n",
      "epoch: 34 [787699/888800 88.62%] train loss: 1.4768207620363683e-05 \n",
      "epoch: 34 [788810/888800 88.75%] train loss: 1.4563561308023054e-05 \n",
      "epoch: 34 [789921/888800 88.88%] train loss: 1.329905353486538e-05 \n",
      "epoch: 34 [791032/888800 89.00%] train loss: 1.4392218872671947e-05 \n",
      "epoch: 34 [792143/888800 89.12%] train loss: 1.4687872862850782e-05 \n",
      "epoch: 34 [793254/888800 89.25%] train loss: 1.4666427887277678e-05 \n",
      "epoch: 34 [794365/888800 89.38%] train loss: 1.3652846973855048e-05 \n",
      "epoch: 34 [795476/888800 89.50%] train loss: 1.4627636119257659e-05 \n",
      "epoch: 34 [796587/888800 89.62%] train loss: 1.4025312339072116e-05 \n",
      "epoch: 34 [797698/888800 89.75%] train loss: 1.358381996396929e-05 \n",
      "epoch: 34 [798809/888800 89.88%] train loss: 1.5462213923456147e-05 \n",
      "epoch: 34 [799920/888800 90.00%] train loss: 1.4106918570178095e-05 \n",
      "epoch: 34 [801031/888800 90.12%] train loss: 1.518819681223249e-05 \n",
      "epoch: 34 [802142/888800 90.25%] train loss: 1.3073055015411228e-05 \n",
      "epoch: 34 [803253/888800 90.38%] train loss: 1.3827094335283618e-05 \n",
      "epoch: 34 [804364/888800 90.50%] train loss: 1.4196659321896732e-05 \n",
      "epoch: 34 [805475/888800 90.62%] train loss: 1.3347652384254616e-05 \n",
      "epoch: 34 [806586/888800 90.75%] train loss: 1.4668406038254034e-05 \n",
      "epoch: 34 [807697/888800 90.88%] train loss: 1.4403429304366e-05 \n",
      "epoch: 34 [808808/888800 91.00%] train loss: 1.4316218766907696e-05 \n",
      "epoch: 34 [809919/888800 91.12%] train loss: 1.634687214391306e-05 \n",
      "epoch: 34 [811030/888800 91.25%] train loss: 1.5063566934259143e-05 \n",
      "epoch: 34 [812141/888800 91.38%] train loss: 1.3603491424873937e-05 \n",
      "epoch: 34 [813252/888800 91.50%] train loss: 1.5102803445188329e-05 \n",
      "epoch: 34 [814363/888800 91.62%] train loss: 1.4810098036832642e-05 \n",
      "epoch: 34 [815474/888800 91.75%] train loss: 1.4226197890820913e-05 \n",
      "epoch: 34 [816585/888800 91.88%] train loss: 1.2700060324277729e-05 \n",
      "epoch: 34 [817696/888800 92.00%] train loss: 1.534757757326588e-05 \n",
      "epoch: 34 [818807/888800 92.12%] train loss: 1.383805738441879e-05 \n",
      "epoch: 34 [819918/888800 92.25%] train loss: 1.396309380652383e-05 \n",
      "epoch: 34 [821029/888800 92.38%] train loss: 1.4599905625800602e-05 \n",
      "epoch: 34 [822140/888800 92.50%] train loss: 1.377579064865131e-05 \n",
      "epoch: 34 [823251/888800 92.62%] train loss: 1.3254689292807598e-05 \n",
      "epoch: 34 [824362/888800 92.75%] train loss: 1.458609494875418e-05 \n",
      "epoch: 34 [825473/888800 92.88%] train loss: 1.3996500456414651e-05 \n",
      "epoch: 34 [826584/888800 93.00%] train loss: 1.4218725482351147e-05 \n",
      "epoch: 34 [827695/888800 93.12%] train loss: 1.3996945199323818e-05 \n",
      "epoch: 34 [828806/888800 93.25%] train loss: 1.4417524653254077e-05 \n",
      "epoch: 34 [829917/888800 93.38%] train loss: 1.4823772289673798e-05 \n",
      "epoch: 34 [831028/888800 93.50%] train loss: 1.5007846741355024e-05 \n",
      "epoch: 34 [832139/888800 93.62%] train loss: 1.3319323443283793e-05 \n",
      "epoch: 34 [833250/888800 93.75%] train loss: 1.3977727576275356e-05 \n",
      "epoch: 34 [834361/888800 93.88%] train loss: 1.4083264431974385e-05 \n",
      "epoch: 34 [835472/888800 94.00%] train loss: 1.3785831470158882e-05 \n",
      "epoch: 34 [836583/888800 94.12%] train loss: 1.3320857760845684e-05 \n",
      "epoch: 34 [837694/888800 94.25%] train loss: 1.4951686353015248e-05 \n",
      "epoch: 34 [838805/888800 94.38%] train loss: 1.578587580297608e-05 \n",
      "epoch: 34 [839916/888800 94.50%] train loss: 1.5118686860660091e-05 \n",
      "epoch: 34 [841027/888800 94.62%] train loss: 1.4332030332298018e-05 \n",
      "epoch: 34 [842138/888800 94.75%] train loss: 1.518265071354108e-05 \n",
      "epoch: 34 [843249/888800 94.88%] train loss: 1.4817218470852822e-05 \n",
      "epoch: 34 [844360/888800 95.00%] train loss: 1.4404490684682969e-05 \n",
      "epoch: 34 [845471/888800 95.12%] train loss: 1.6983576642815024e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 [846582/888800 95.25%] train loss: 1.3923659025749657e-05 \n",
      "epoch: 34 [847693/888800 95.38%] train loss: 1.4065482901060022e-05 \n",
      "epoch: 34 [848804/888800 95.50%] train loss: 1.3641776604345068e-05 \n",
      "epoch: 34 [849915/888800 95.62%] train loss: 1.4333632861962542e-05 \n",
      "epoch: 34 [851026/888800 95.75%] train loss: 1.2901270565635059e-05 \n",
      "epoch: 34 [852137/888800 95.88%] train loss: 1.4485303836409003e-05 \n",
      "epoch: 34 [853248/888800 96.00%] train loss: 1.3520136235456448e-05 \n",
      "epoch: 34 [854359/888800 96.12%] train loss: 1.5533769328612834e-05 \n",
      "epoch: 34 [855470/888800 96.25%] train loss: 1.2893549865111709e-05 \n",
      "epoch: 34 [856581/888800 96.38%] train loss: 1.4784607628826052e-05 \n",
      "epoch: 34 [857692/888800 96.50%] train loss: 1.4019837180967443e-05 \n",
      "epoch: 34 [858803/888800 96.62%] train loss: 1.4767049833608326e-05 \n",
      "epoch: 34 [859914/888800 96.75%] train loss: 1.3930384739069268e-05 \n",
      "epoch: 34 [861025/888800 96.88%] train loss: 1.3669383406522684e-05 \n",
      "epoch: 34 [862136/888800 97.00%] train loss: 1.5603784049744718e-05 \n",
      "epoch: 34 [863247/888800 97.12%] train loss: 1.4191639820637647e-05 \n",
      "epoch: 34 [864358/888800 97.25%] train loss: 1.4554664630850311e-05 \n",
      "epoch: 34 [865469/888800 97.38%] train loss: 1.4407699381990824e-05 \n",
      "epoch: 34 [866580/888800 97.50%] train loss: 1.5138895832933486e-05 \n",
      "epoch: 34 [867691/888800 97.62%] train loss: 1.4436422134167515e-05 \n",
      "epoch: 34 [868802/888800 97.75%] train loss: 1.4336865206132643e-05 \n",
      "epoch: 34 [869913/888800 97.88%] train loss: 1.3814488738717046e-05 \n",
      "epoch: 34 [871024/888800 98.00%] train loss: 1.4756387827219442e-05 \n",
      "epoch: 34 [872135/888800 98.12%] train loss: 1.3933745321992319e-05 \n",
      "epoch: 34 [873246/888800 98.25%] train loss: 1.4914159692125395e-05 \n",
      "epoch: 34 [874357/888800 98.38%] train loss: 1.6290758139803074e-05 \n",
      "epoch: 34 [875468/888800 98.50%] train loss: 1.4086741430219263e-05 \n",
      "epoch: 34 [876579/888800 98.62%] train loss: 1.5234479178616311e-05 \n",
      "epoch: 34 [877690/888800 98.75%] train loss: 1.4770652342122048e-05 \n",
      "epoch: 34 [878801/888800 98.88%] train loss: 1.5230975805025082e-05 \n",
      "epoch: 34 [879912/888800 99.00%] train loss: 1.3893679351895116e-05 \n",
      "epoch: 34 [881023/888800 99.12%] train loss: 1.4368151823873632e-05 \n",
      "epoch: 34 [882134/888800 99.25%] train loss: 1.4021067727298941e-05 \n",
      "epoch: 34 [883245/888800 99.38%] train loss: 1.3996504094393458e-05 \n",
      "epoch: 34 [884356/888800 99.50%] train loss: 1.4857606402074452e-05 \n",
      "epoch: 34 [885467/888800 99.62%] train loss: 1.3355183909879997e-05 \n",
      "epoch: 34 [886578/888800 99.75%] train loss: 1.4366474715643562e-05 \n",
      "epoch: 34 [887689/888800 99.88%] train loss: 1.3418495655059814e-05 \n",
      "epoch: 35 [0/888800 0.00%] train loss: 1.2080539818271063e-05 \n",
      "epoch: 35 [1111/888800 0.12%] train loss: 1.4786452084081247e-05 \n",
      "epoch: 35 [2222/888800 0.25%] train loss: 1.653997242101468e-05 \n",
      "epoch: 35 [3333/888800 0.38%] train loss: 1.4025409655005205e-05 \n",
      "epoch: 35 [4444/888800 0.50%] train loss: 1.5365130821010098e-05 \n",
      "epoch: 35 [5555/888800 0.62%] train loss: 1.4392644516192377e-05 \n",
      "epoch: 35 [6666/888800 0.75%] train loss: 1.4177194316289388e-05 \n",
      "epoch: 35 [7777/888800 0.88%] train loss: 1.430497104593087e-05 \n",
      "epoch: 35 [8888/888800 1.00%] train loss: 1.3257176760816947e-05 \n",
      "epoch: 35 [9999/888800 1.12%] train loss: 1.387355132465018e-05 \n",
      "epoch: 35 [11110/888800 1.25%] train loss: 1.4257019756769296e-05 \n",
      "epoch: 35 [12221/888800 1.38%] train loss: 1.5006928151706234e-05 \n",
      "epoch: 35 [13332/888800 1.50%] train loss: 1.3932849469711073e-05 \n",
      "epoch: 35 [14443/888800 1.62%] train loss: 1.4512215784634463e-05 \n",
      "epoch: 35 [15554/888800 1.75%] train loss: 1.3255306839710101e-05 \n",
      "epoch: 35 [16665/888800 1.88%] train loss: 1.3183147530071437e-05 \n",
      "epoch: 35 [17776/888800 2.00%] train loss: 1.3255170415504836e-05 \n",
      "epoch: 35 [18887/888800 2.12%] train loss: 1.4822903722233605e-05 \n",
      "epoch: 35 [19998/888800 2.25%] train loss: 1.44598070619395e-05 \n",
      "epoch: 35 [21109/888800 2.38%] train loss: 1.4929944882169366e-05 \n",
      "epoch: 35 [22220/888800 2.50%] train loss: 1.5195154446701054e-05 \n",
      "epoch: 35 [23331/888800 2.62%] train loss: 1.3357564057514537e-05 \n",
      "epoch: 35 [24442/888800 2.75%] train loss: 1.4336403182824142e-05 \n",
      "epoch: 35 [25553/888800 2.88%] train loss: 1.4678978914162144e-05 \n",
      "epoch: 35 [26664/888800 3.00%] train loss: 1.4635755178460386e-05 \n",
      "epoch: 35 [27775/888800 3.12%] train loss: 1.398203312419355e-05 \n",
      "epoch: 35 [28886/888800 3.25%] train loss: 1.4007177014718764e-05 \n",
      "epoch: 35 [29997/888800 3.38%] train loss: 1.4569121049134992e-05 \n",
      "epoch: 35 [31108/888800 3.50%] train loss: 1.3593169569503516e-05 \n",
      "epoch: 35 [32219/888800 3.62%] train loss: 1.5029840142233297e-05 \n",
      "epoch: 35 [33330/888800 3.75%] train loss: 1.3642724297824316e-05 \n",
      "epoch: 35 [34441/888800 3.88%] train loss: 1.549690932733938e-05 \n",
      "epoch: 35 [35552/888800 4.00%] train loss: 1.549654007249046e-05 \n",
      "epoch: 35 [36663/888800 4.12%] train loss: 1.533371687401086e-05 \n",
      "epoch: 35 [37774/888800 4.25%] train loss: 1.5997911759768613e-05 \n",
      "epoch: 35 [38885/888800 4.38%] train loss: 1.4434638615057338e-05 \n",
      "epoch: 35 [39996/888800 4.50%] train loss: 1.4930802535673138e-05 \n",
      "epoch: 35 [41107/888800 4.62%] train loss: 1.4563614968210459e-05 \n",
      "epoch: 35 [42218/888800 4.75%] train loss: 1.4084132999414578e-05 \n",
      "epoch: 35 [43329/888800 4.88%] train loss: 1.4842717064311728e-05 \n",
      "epoch: 35 [44440/888800 5.00%] train loss: 1.403073656547349e-05 \n",
      "epoch: 35 [45551/888800 5.12%] train loss: 1.5965131751727313e-05 \n",
      "epoch: 35 [46662/888800 5.25%] train loss: 1.5150447325140703e-05 \n",
      "epoch: 35 [47773/888800 5.38%] train loss: 1.470474398956867e-05 \n",
      "epoch: 35 [48884/888800 5.50%] train loss: 1.3604996638605371e-05 \n",
      "epoch: 35 [49995/888800 5.62%] train loss: 1.5222488400468137e-05 \n",
      "epoch: 35 [51106/888800 5.75%] train loss: 1.3866655535821337e-05 \n",
      "epoch: 35 [52217/888800 5.88%] train loss: 1.5167970559559762e-05 \n",
      "epoch: 35 [53328/888800 6.00%] train loss: 1.5181384696916211e-05 \n",
      "epoch: 35 [54439/888800 6.12%] train loss: 1.3253343240648974e-05 \n",
      "epoch: 35 [55550/888800 6.25%] train loss: 1.5156349036260508e-05 \n",
      "epoch: 35 [56661/888800 6.38%] train loss: 1.4326050404633861e-05 \n",
      "epoch: 35 [57772/888800 6.50%] train loss: 1.3440937436826061e-05 \n",
      "epoch: 35 [58883/888800 6.62%] train loss: 1.4779073353565764e-05 \n",
      "epoch: 35 [59994/888800 6.75%] train loss: 1.4317596651380882e-05 \n",
      "epoch: 35 [61105/888800 6.88%] train loss: 1.4045888747205026e-05 \n",
      "epoch: 35 [62216/888800 7.00%] train loss: 1.3605670574179385e-05 \n",
      "epoch: 35 [63327/888800 7.12%] train loss: 1.4178443052514922e-05 \n",
      "epoch: 35 [64438/888800 7.25%] train loss: 1.4181446204020176e-05 \n",
      "epoch: 35 [65549/888800 7.38%] train loss: 1.3990578736411408e-05 \n",
      "epoch: 35 [66660/888800 7.50%] train loss: 1.3375793969316874e-05 \n",
      "epoch: 35 [67771/888800 7.62%] train loss: 1.3504094567906577e-05 \n",
      "epoch: 35 [68882/888800 7.75%] train loss: 1.540666380606126e-05 \n",
      "epoch: 35 [69993/888800 7.88%] train loss: 1.3291661161929369e-05 \n",
      "epoch: 35 [71104/888800 8.00%] train loss: 1.2699361832346767e-05 \n",
      "epoch: 35 [72215/888800 8.12%] train loss: 1.3701039279112592e-05 \n",
      "epoch: 35 [73326/888800 8.25%] train loss: 1.4257977454690263e-05 \n",
      "epoch: 35 [74437/888800 8.38%] train loss: 1.4131951502349693e-05 \n",
      "epoch: 35 [75548/888800 8.50%] train loss: 1.3851546100340784e-05 \n",
      "epoch: 35 [76659/888800 8.62%] train loss: 1.407497165928362e-05 \n",
      "epoch: 35 [77770/888800 8.75%] train loss: 1.5404948499053717e-05 \n",
      "epoch: 35 [78881/888800 8.88%] train loss: 1.4383762390934862e-05 \n",
      "epoch: 35 [79992/888800 9.00%] train loss: 1.4194962204783224e-05 \n",
      "epoch: 35 [81103/888800 9.12%] train loss: 1.4165674656396732e-05 \n",
      "epoch: 35 [82214/888800 9.25%] train loss: 1.4150198694551364e-05 \n",
      "epoch: 35 [83325/888800 9.38%] train loss: 1.3738436791754793e-05 \n",
      "epoch: 35 [84436/888800 9.50%] train loss: 1.5657104086130857e-05 \n",
      "epoch: 35 [85547/888800 9.62%] train loss: 1.5268953575287014e-05 \n",
      "epoch: 35 [86658/888800 9.75%] train loss: 1.4549337720382027e-05 \n",
      "epoch: 35 [87769/888800 9.88%] train loss: 1.4760500562260859e-05 \n",
      "epoch: 35 [88880/888800 10.00%] train loss: 1.3370504348131362e-05 \n",
      "epoch: 35 [89991/888800 10.12%] train loss: 1.4487363841908518e-05 \n",
      "epoch: 35 [91102/888800 10.25%] train loss: 1.4466251741396263e-05 \n",
      "epoch: 35 [92213/888800 10.38%] train loss: 1.5614477888448164e-05 \n",
      "epoch: 35 [93324/888800 10.50%] train loss: 1.45579415402608e-05 \n",
      "epoch: 35 [94435/888800 10.62%] train loss: 1.4174504940456245e-05 \n",
      "epoch: 35 [95546/888800 10.75%] train loss: 1.4279695278673898e-05 \n",
      "epoch: 35 [96657/888800 10.88%] train loss: 1.3999450857227203e-05 \n",
      "epoch: 35 [97768/888800 11.00%] train loss: 1.422400055162143e-05 \n",
      "epoch: 35 [98879/888800 11.12%] train loss: 1.3957313058199361e-05 \n",
      "epoch: 35 [99990/888800 11.25%] train loss: 1.4735069271409884e-05 \n",
      "epoch: 35 [101101/888800 11.38%] train loss: 1.3708423466596287e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [102212/888800 11.50%] train loss: 1.4526178347296081e-05 \n",
      "epoch: 35 [103323/888800 11.62%] train loss: 1.3932361980550922e-05 \n",
      "epoch: 35 [104434/888800 11.75%] train loss: 1.4430199371417984e-05 \n",
      "epoch: 35 [105545/888800 11.88%] train loss: 1.4421787454921287e-05 \n",
      "epoch: 35 [106656/888800 12.00%] train loss: 1.3471802049025428e-05 \n",
      "epoch: 35 [107767/888800 12.12%] train loss: 1.4716959412908182e-05 \n",
      "epoch: 35 [108878/888800 12.25%] train loss: 1.4693618140881881e-05 \n",
      "epoch: 35 [109989/888800 12.38%] train loss: 1.4299458598543424e-05 \n",
      "epoch: 35 [111100/888800 12.50%] train loss: 1.3030100490141194e-05 \n",
      "epoch: 35 [112211/888800 12.62%] train loss: 1.498411347711226e-05 \n",
      "epoch: 35 [113322/888800 12.75%] train loss: 1.4188633940648288e-05 \n",
      "epoch: 35 [114433/888800 12.88%] train loss: 1.4159392776491586e-05 \n",
      "epoch: 35 [115544/888800 13.00%] train loss: 1.3511651559383608e-05 \n",
      "epoch: 35 [116655/888800 13.12%] train loss: 1.3622139704239089e-05 \n",
      "epoch: 35 [117766/888800 13.25%] train loss: 1.4839866707916372e-05 \n",
      "epoch: 35 [118877/888800 13.38%] train loss: 1.4567337530024815e-05 \n",
      "epoch: 35 [119988/888800 13.50%] train loss: 1.432221233699238e-05 \n",
      "epoch: 35 [121099/888800 13.62%] train loss: 1.4012613974045962e-05 \n",
      "epoch: 35 [122210/888800 13.75%] train loss: 1.4127675967756659e-05 \n",
      "epoch: 35 [123321/888800 13.88%] train loss: 1.461232932342682e-05 \n",
      "epoch: 35 [124432/888800 14.00%] train loss: 1.589487146702595e-05 \n",
      "epoch: 35 [125543/888800 14.12%] train loss: 1.5466783224837855e-05 \n",
      "epoch: 35 [126654/888800 14.25%] train loss: 1.4851119885861408e-05 \n",
      "epoch: 35 [127765/888800 14.38%] train loss: 1.4160712453303859e-05 \n",
      "epoch: 35 [128876/888800 14.50%] train loss: 1.4554640983988065e-05 \n",
      "epoch: 35 [129987/888800 14.62%] train loss: 1.4521884622809011e-05 \n",
      "epoch: 35 [131098/888800 14.75%] train loss: 1.5564763089059852e-05 \n",
      "epoch: 35 [132209/888800 14.88%] train loss: 1.3854819371772464e-05 \n",
      "epoch: 35 [133320/888800 15.00%] train loss: 1.4325817573990207e-05 \n",
      "epoch: 35 [134431/888800 15.12%] train loss: 1.4123014807410073e-05 \n",
      "epoch: 35 [135542/888800 15.25%] train loss: 1.405306738888612e-05 \n",
      "epoch: 35 [136653/888800 15.38%] train loss: 1.4097823623160366e-05 \n",
      "epoch: 35 [137764/888800 15.50%] train loss: 1.3365086488192901e-05 \n",
      "epoch: 35 [138875/888800 15.62%] train loss: 1.40906595333945e-05 \n",
      "epoch: 35 [139986/888800 15.75%] train loss: 1.407728086633142e-05 \n",
      "epoch: 35 [141097/888800 15.88%] train loss: 1.3048644177615643e-05 \n",
      "epoch: 35 [142208/888800 16.00%] train loss: 1.331428939010948e-05 \n",
      "epoch: 35 [143319/888800 16.12%] train loss: 1.3988218597660307e-05 \n",
      "epoch: 35 [144430/888800 16.25%] train loss: 1.4913799532223493e-05 \n",
      "epoch: 35 [145541/888800 16.38%] train loss: 1.415550650563091e-05 \n",
      "epoch: 35 [146652/888800 16.50%] train loss: 1.4747110071766656e-05 \n",
      "epoch: 35 [147763/888800 16.62%] train loss: 1.4188413842930458e-05 \n",
      "epoch: 35 [148874/888800 16.75%] train loss: 1.5424455341417342e-05 \n",
      "epoch: 35 [149985/888800 16.88%] train loss: 1.4650699085905217e-05 \n",
      "epoch: 35 [151096/888800 17.00%] train loss: 1.7045869753928855e-05 \n",
      "epoch: 35 [152207/888800 17.12%] train loss: 1.4170045687933452e-05 \n",
      "epoch: 35 [153318/888800 17.25%] train loss: 1.3434602806228213e-05 \n",
      "epoch: 35 [154429/888800 17.38%] train loss: 1.532185524411034e-05 \n",
      "epoch: 35 [155540/888800 17.50%] train loss: 1.5246550901792943e-05 \n",
      "epoch: 35 [156651/888800 17.62%] train loss: 1.3727968507737387e-05 \n",
      "epoch: 35 [157762/888800 17.75%] train loss: 1.2968702321813907e-05 \n",
      "epoch: 35 [158873/888800 17.88%] train loss: 1.5067139429447707e-05 \n",
      "epoch: 35 [159984/888800 18.00%] train loss: 1.402741236233851e-05 \n",
      "epoch: 35 [161095/888800 18.12%] train loss: 1.4805780665483326e-05 \n",
      "epoch: 35 [162206/888800 18.25%] train loss: 1.3759762623521965e-05 \n",
      "epoch: 35 [163317/888800 18.38%] train loss: 1.4606176591769326e-05 \n",
      "epoch: 35 [164428/888800 18.50%] train loss: 1.4673952136945445e-05 \n",
      "epoch: 35 [165539/888800 18.62%] train loss: 1.504778083472047e-05 \n",
      "epoch: 35 [166650/888800 18.75%] train loss: 1.2766527106577996e-05 \n",
      "epoch: 35 [167761/888800 18.88%] train loss: 1.4733771422470454e-05 \n",
      "epoch: 35 [168872/888800 19.00%] train loss: 1.468053596909158e-05 \n",
      "epoch: 35 [169983/888800 19.12%] train loss: 1.4353220649354625e-05 \n",
      "epoch: 35 [171094/888800 19.25%] train loss: 1.5269550203811377e-05 \n",
      "epoch: 35 [172205/888800 19.38%] train loss: 1.3091827895550523e-05 \n",
      "epoch: 35 [173316/888800 19.50%] train loss: 1.3870795555703808e-05 \n",
      "epoch: 35 [174427/888800 19.62%] train loss: 1.4217210264177993e-05 \n",
      "epoch: 35 [175538/888800 19.75%] train loss: 1.5115923815756105e-05 \n",
      "epoch: 35 [176649/888800 19.88%] train loss: 1.543699727335479e-05 \n",
      "epoch: 35 [177760/888800 20.00%] train loss: 1.45474768942222e-05 \n",
      "epoch: 35 [178871/888800 20.12%] train loss: 1.3823289918946102e-05 \n",
      "epoch: 35 [179982/888800 20.25%] train loss: 1.3976819900562987e-05 \n",
      "epoch: 35 [181093/888800 20.38%] train loss: 1.438906019757269e-05 \n",
      "epoch: 35 [182204/888800 20.50%] train loss: 1.4875332453812007e-05 \n",
      "epoch: 35 [183315/888800 20.62%] train loss: 1.621615228941664e-05 \n",
      "epoch: 35 [184426/888800 20.75%] train loss: 1.376859381707618e-05 \n",
      "epoch: 35 [185537/888800 20.88%] train loss: 1.544990300317295e-05 \n",
      "epoch: 35 [186648/888800 21.00%] train loss: 1.4565885066986084e-05 \n",
      "epoch: 35 [187759/888800 21.12%] train loss: 1.3504622074833605e-05 \n",
      "epoch: 35 [188870/888800 21.25%] train loss: 1.3741756447416265e-05 \n",
      "epoch: 35 [189981/888800 21.38%] train loss: 1.5740113667561673e-05 \n",
      "epoch: 35 [191092/888800 21.50%] train loss: 1.373955819872208e-05 \n",
      "epoch: 35 [192203/888800 21.62%] train loss: 1.519163379271049e-05 \n",
      "epoch: 35 [193314/888800 21.75%] train loss: 1.4177362572809216e-05 \n",
      "epoch: 35 [194425/888800 21.88%] train loss: 1.3336598385649268e-05 \n",
      "epoch: 35 [195536/888800 22.00%] train loss: 1.6071277059381828e-05 \n",
      "epoch: 35 [196647/888800 22.12%] train loss: 1.6284924640785903e-05 \n",
      "epoch: 35 [197758/888800 22.25%] train loss: 1.4556662790710106e-05 \n",
      "epoch: 35 [198869/888800 22.38%] train loss: 1.479042384744389e-05 \n",
      "epoch: 35 [199980/888800 22.50%] train loss: 1.4215446753951255e-05 \n",
      "epoch: 35 [201091/888800 22.62%] train loss: 1.3751598999078851e-05 \n",
      "epoch: 35 [202202/888800 22.75%] train loss: 1.4539028597937431e-05 \n",
      "epoch: 35 [203313/888800 22.88%] train loss: 1.4895914318913128e-05 \n",
      "epoch: 35 [204424/888800 23.00%] train loss: 1.3802849935018457e-05 \n",
      "epoch: 35 [205535/888800 23.12%] train loss: 1.2936574421473779e-05 \n",
      "epoch: 35 [206646/888800 23.25%] train loss: 1.4154036762192845e-05 \n",
      "epoch: 35 [207757/888800 23.38%] train loss: 1.4084670510783326e-05 \n",
      "epoch: 35 [208868/888800 23.50%] train loss: 1.4374579222931061e-05 \n",
      "epoch: 35 [209979/888800 23.62%] train loss: 1.3845688954461366e-05 \n",
      "epoch: 35 [211090/888800 23.75%] train loss: 1.4470726455328986e-05 \n",
      "epoch: 35 [212201/888800 23.88%] train loss: 1.4143262887955643e-05 \n",
      "epoch: 35 [213312/888800 24.00%] train loss: 1.472960411774693e-05 \n",
      "epoch: 35 [214423/888800 24.12%] train loss: 1.3482830581779126e-05 \n",
      "epoch: 35 [215534/888800 24.25%] train loss: 1.3922461221227422e-05 \n",
      "epoch: 35 [216645/888800 24.38%] train loss: 1.3935789866081905e-05 \n",
      "epoch: 35 [217756/888800 24.50%] train loss: 1.39747744469787e-05 \n",
      "epoch: 35 [218867/888800 24.62%] train loss: 1.4159493730403483e-05 \n",
      "epoch: 35 [219978/888800 24.75%] train loss: 1.4888662917655893e-05 \n",
      "epoch: 35 [221089/888800 24.88%] train loss: 1.2305563359404914e-05 \n",
      "epoch: 35 [222200/888800 25.00%] train loss: 1.4004903277964331e-05 \n",
      "epoch: 35 [223311/888800 25.12%] train loss: 1.3462361494021025e-05 \n",
      "epoch: 35 [224422/888800 25.25%] train loss: 1.3686244528798852e-05 \n",
      "epoch: 35 [225533/888800 25.38%] train loss: 1.364815943816211e-05 \n",
      "epoch: 35 [226644/888800 25.50%] train loss: 1.4118672879703809e-05 \n",
      "epoch: 35 [227755/888800 25.62%] train loss: 1.4041354916116688e-05 \n",
      "epoch: 35 [228866/888800 25.75%] train loss: 1.428796531399712e-05 \n",
      "epoch: 35 [229977/888800 25.88%] train loss: 1.4778049262531567e-05 \n",
      "epoch: 35 [231088/888800 26.00%] train loss: 1.5208956028800458e-05 \n",
      "epoch: 35 [232199/888800 26.12%] train loss: 1.4530181942973286e-05 \n",
      "epoch: 35 [233310/888800 26.25%] train loss: 1.337453522864962e-05 \n",
      "epoch: 35 [234421/888800 26.38%] train loss: 1.3116061381879263e-05 \n",
      "epoch: 35 [235532/888800 26.50%] train loss: 1.2741968930640724e-05 \n",
      "epoch: 35 [236643/888800 26.62%] train loss: 1.4709131392010022e-05 \n",
      "epoch: 35 [237754/888800 26.75%] train loss: 1.4864539480186068e-05 \n",
      "epoch: 35 [238865/888800 26.88%] train loss: 1.3618298908113502e-05 \n",
      "epoch: 35 [239976/888800 27.00%] train loss: 1.356882512482116e-05 \n",
      "epoch: 35 [241087/888800 27.12%] train loss: 1.425366190233035e-05 \n",
      "epoch: 35 [242198/888800 27.25%] train loss: 1.4579710295947734e-05 \n",
      "epoch: 35 [243309/888800 27.38%] train loss: 1.536900526843965e-05 \n",
      "epoch: 35 [244420/888800 27.50%] train loss: 1.320469436905114e-05 \n",
      "epoch: 35 [245531/888800 27.62%] train loss: 1.4010164704814088e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [246642/888800 27.75%] train loss: 1.3873755051463377e-05 \n",
      "epoch: 35 [247753/888800 27.88%] train loss: 1.4776216630707495e-05 \n",
      "epoch: 35 [248864/888800 28.00%] train loss: 1.3191402103984728e-05 \n",
      "epoch: 35 [249975/888800 28.12%] train loss: 1.403416354150977e-05 \n",
      "epoch: 35 [251086/888800 28.25%] train loss: 1.380755566060543e-05 \n",
      "epoch: 35 [252197/888800 28.38%] train loss: 1.4588679732696619e-05 \n",
      "epoch: 35 [253308/888800 28.50%] train loss: 1.4401067346625496e-05 \n",
      "epoch: 35 [254419/888800 28.62%] train loss: 1.4737711353518534e-05 \n",
      "epoch: 35 [255530/888800 28.75%] train loss: 1.37805564008886e-05 \n",
      "epoch: 35 [256641/888800 28.88%] train loss: 1.4329833902593236e-05 \n",
      "epoch: 35 [257752/888800 29.00%] train loss: 1.303490989812417e-05 \n",
      "epoch: 35 [258863/888800 29.12%] train loss: 1.4941110748623032e-05 \n",
      "epoch: 35 [259974/888800 29.25%] train loss: 1.439323114027502e-05 \n",
      "epoch: 35 [261085/888800 29.38%] train loss: 1.426790731784422e-05 \n",
      "epoch: 35 [262196/888800 29.50%] train loss: 1.4312924577097874e-05 \n",
      "epoch: 35 [263307/888800 29.62%] train loss: 1.3955374015495181e-05 \n",
      "epoch: 35 [264418/888800 29.75%] train loss: 1.5055466064950451e-05 \n",
      "epoch: 35 [265529/888800 29.88%] train loss: 1.3322644008439966e-05 \n",
      "epoch: 35 [266640/888800 30.00%] train loss: 1.3810521522827912e-05 \n",
      "epoch: 35 [267751/888800 30.12%] train loss: 1.5520328815910034e-05 \n",
      "epoch: 35 [268862/888800 30.25%] train loss: 1.4604503121518064e-05 \n",
      "epoch: 35 [269973/888800 30.38%] train loss: 1.400371729687322e-05 \n",
      "epoch: 35 [271084/888800 30.50%] train loss: 1.5005093700892758e-05 \n",
      "epoch: 35 [272195/888800 30.62%] train loss: 1.4451718925556634e-05 \n",
      "epoch: 35 [273306/888800 30.75%] train loss: 1.3347807907848619e-05 \n",
      "epoch: 35 [274417/888800 30.88%] train loss: 1.484555014030775e-05 \n",
      "epoch: 35 [275528/888800 31.00%] train loss: 1.4963623470976017e-05 \n",
      "epoch: 35 [276639/888800 31.12%] train loss: 1.4741036466148216e-05 \n",
      "epoch: 35 [277750/888800 31.25%] train loss: 1.42990356835071e-05 \n",
      "epoch: 35 [278861/888800 31.38%] train loss: 1.5431745850946754e-05 \n",
      "epoch: 35 [279972/888800 31.50%] train loss: 1.2421868632372934e-05 \n",
      "epoch: 35 [281083/888800 31.62%] train loss: 1.3774500075669494e-05 \n",
      "epoch: 35 [282194/888800 31.75%] train loss: 1.4242650649975985e-05 \n",
      "epoch: 35 [283305/888800 31.88%] train loss: 1.4758678844373208e-05 \n",
      "epoch: 35 [284416/888800 32.00%] train loss: 1.3949549611425027e-05 \n",
      "epoch: 35 [285527/888800 32.12%] train loss: 1.3789251170237549e-05 \n",
      "epoch: 35 [286638/888800 32.25%] train loss: 1.3736726032220758e-05 \n",
      "epoch: 35 [287749/888800 32.38%] train loss: 1.293489731324371e-05 \n",
      "epoch: 35 [288860/888800 32.50%] train loss: 1.3827263501298148e-05 \n",
      "epoch: 35 [289971/888800 32.62%] train loss: 1.3319117897481192e-05 \n",
      "epoch: 35 [291082/888800 32.75%] train loss: 1.4168111192702781e-05 \n",
      "epoch: 35 [292193/888800 32.88%] train loss: 1.5190302292467095e-05 \n",
      "epoch: 35 [293304/888800 33.00%] train loss: 1.558818985358812e-05 \n",
      "epoch: 35 [294415/888800 33.12%] train loss: 1.4425611880142242e-05 \n",
      "epoch: 35 [295526/888800 33.25%] train loss: 1.4240356904338114e-05 \n",
      "epoch: 35 [296637/888800 33.38%] train loss: 1.3832031982019544e-05 \n",
      "epoch: 35 [297748/888800 33.50%] train loss: 1.4941029803594574e-05 \n",
      "epoch: 35 [298859/888800 33.62%] train loss: 1.4406690752366558e-05 \n",
      "epoch: 35 [299970/888800 33.75%] train loss: 1.4072172234591562e-05 \n",
      "epoch: 35 [301081/888800 33.88%] train loss: 1.4084920621826313e-05 \n",
      "epoch: 35 [302192/888800 34.00%] train loss: 1.3827489055984188e-05 \n",
      "epoch: 35 [303303/888800 34.12%] train loss: 1.3728352314501535e-05 \n",
      "epoch: 35 [304414/888800 34.25%] train loss: 1.4853574612061493e-05 \n",
      "epoch: 35 [305525/888800 34.38%] train loss: 1.4957919120206498e-05 \n",
      "epoch: 35 [306636/888800 34.50%] train loss: 1.45107469506911e-05 \n",
      "epoch: 35 [307747/888800 34.62%] train loss: 1.4737077435711399e-05 \n",
      "epoch: 35 [308858/888800 34.75%] train loss: 1.46352494994062e-05 \n",
      "epoch: 35 [309969/888800 34.88%] train loss: 1.4150476999930106e-05 \n",
      "epoch: 35 [311080/888800 35.00%] train loss: 1.3358169780985918e-05 \n",
      "epoch: 35 [312191/888800 35.12%] train loss: 1.3936163668404333e-05 \n",
      "epoch: 35 [313302/888800 35.25%] train loss: 1.2965062524017412e-05 \n",
      "epoch: 35 [314413/888800 35.38%] train loss: 1.5052347407618072e-05 \n",
      "epoch: 35 [315524/888800 35.50%] train loss: 1.4498618838842958e-05 \n",
      "epoch: 35 [316635/888800 35.62%] train loss: 1.2940648957737722e-05 \n",
      "epoch: 35 [317746/888800 35.75%] train loss: 1.3857022167940158e-05 \n",
      "epoch: 35 [318857/888800 35.88%] train loss: 1.4755788470210973e-05 \n",
      "epoch: 35 [319968/888800 36.00%] train loss: 1.4855218978482299e-05 \n",
      "epoch: 35 [321079/888800 36.12%] train loss: 1.5464864191017114e-05 \n",
      "epoch: 35 [322190/888800 36.25%] train loss: 1.3598692930827383e-05 \n",
      "epoch: 35 [323301/888800 36.38%] train loss: 1.3944128113507759e-05 \n",
      "epoch: 35 [324412/888800 36.50%] train loss: 1.3994269465911202e-05 \n",
      "epoch: 35 [325523/888800 36.62%] train loss: 1.4612902305088937e-05 \n",
      "epoch: 35 [326634/888800 36.75%] train loss: 1.3427304111246485e-05 \n",
      "epoch: 35 [327745/888800 36.88%] train loss: 1.4232698049454484e-05 \n",
      "epoch: 35 [328856/888800 37.00%] train loss: 1.4204423678165767e-05 \n",
      "epoch: 35 [329967/888800 37.12%] train loss: 1.3754314750258345e-05 \n",
      "epoch: 35 [331078/888800 37.25%] train loss: 1.4531875422107987e-05 \n",
      "epoch: 35 [332189/888800 37.38%] train loss: 1.3894130461267196e-05 \n",
      "epoch: 35 [333300/888800 37.50%] train loss: 1.6097903426270932e-05 \n",
      "epoch: 35 [334411/888800 37.62%] train loss: 1.4057281077839434e-05 \n",
      "epoch: 35 [335522/888800 37.75%] train loss: 1.3871929695596918e-05 \n",
      "epoch: 35 [336633/888800 37.88%] train loss: 1.4715237739437725e-05 \n",
      "epoch: 35 [337744/888800 38.00%] train loss: 1.4201831618265714e-05 \n",
      "epoch: 35 [338855/888800 38.12%] train loss: 1.490117301727878e-05 \n",
      "epoch: 35 [339966/888800 38.25%] train loss: 1.4779806406295393e-05 \n",
      "epoch: 35 [341077/888800 38.38%] train loss: 1.3764189134235494e-05 \n",
      "epoch: 35 [342188/888800 38.50%] train loss: 1.4444241969613358e-05 \n",
      "epoch: 35 [343299/888800 38.62%] train loss: 1.522681941423798e-05 \n",
      "epoch: 35 [344410/888800 38.75%] train loss: 1.3989259969093837e-05 \n",
      "epoch: 35 [345521/888800 38.88%] train loss: 1.5882666048128158e-05 \n",
      "epoch: 35 [346632/888800 39.00%] train loss: 1.4126339920039754e-05 \n",
      "epoch: 35 [347743/888800 39.12%] train loss: 1.4230511624191422e-05 \n",
      "epoch: 35 [348854/888800 39.25%] train loss: 1.4450120033870917e-05 \n",
      "epoch: 35 [349965/888800 39.38%] train loss: 1.3909190784033854e-05 \n",
      "epoch: 35 [351076/888800 39.50%] train loss: 1.4469668712990824e-05 \n",
      "epoch: 35 [352187/888800 39.62%] train loss: 1.3939874406787567e-05 \n",
      "epoch: 35 [353298/888800 39.75%] train loss: 1.3765315088676289e-05 \n",
      "epoch: 35 [354409/888800 39.88%] train loss: 1.370782501908252e-05 \n",
      "epoch: 35 [355520/888800 40.00%] train loss: 1.5834426449146122e-05 \n",
      "epoch: 35 [356631/888800 40.12%] train loss: 1.4336456843011547e-05 \n",
      "epoch: 35 [357742/888800 40.25%] train loss: 1.3752217455476057e-05 \n",
      "epoch: 35 [358853/888800 40.38%] train loss: 1.5004141459940001e-05 \n",
      "epoch: 35 [359964/888800 40.50%] train loss: 1.4588703379558865e-05 \n",
      "epoch: 35 [361075/888800 40.62%] train loss: 1.4671591998194344e-05 \n",
      "epoch: 35 [362186/888800 40.75%] train loss: 1.531376619823277e-05 \n",
      "epoch: 35 [363297/888800 40.88%] train loss: 1.5699692085036077e-05 \n",
      "epoch: 35 [364408/888800 41.00%] train loss: 1.5342255210271105e-05 \n",
      "epoch: 35 [365519/888800 41.12%] train loss: 1.4335239029605873e-05 \n",
      "epoch: 35 [366630/888800 41.25%] train loss: 1.6712952856323682e-05 \n",
      "epoch: 35 [367741/888800 41.38%] train loss: 1.3484781447914429e-05 \n",
      "epoch: 35 [368852/888800 41.50%] train loss: 1.5540552340098657e-05 \n",
      "epoch: 35 [369963/888800 41.62%] train loss: 1.4618724890169688e-05 \n",
      "epoch: 35 [371074/888800 41.75%] train loss: 1.4918185115675442e-05 \n",
      "epoch: 35 [372185/888800 41.88%] train loss: 1.541717938380316e-05 \n",
      "epoch: 35 [373296/888800 42.00%] train loss: 1.3162856703274883e-05 \n",
      "epoch: 35 [374407/888800 42.12%] train loss: 1.527639506093692e-05 \n",
      "epoch: 35 [375518/888800 42.25%] train loss: 1.3765765288553666e-05 \n",
      "epoch: 35 [376629/888800 42.38%] train loss: 1.4967576134949923e-05 \n",
      "epoch: 35 [377740/888800 42.50%] train loss: 1.401095596520463e-05 \n",
      "epoch: 35 [378851/888800 42.62%] train loss: 1.4905943316989578e-05 \n",
      "epoch: 35 [379962/888800 42.75%] train loss: 1.5615903976140544e-05 \n",
      "epoch: 35 [381073/888800 42.88%] train loss: 1.3432485502562486e-05 \n",
      "epoch: 35 [382184/888800 43.00%] train loss: 1.530462031951174e-05 \n",
      "epoch: 35 [383295/888800 43.12%] train loss: 1.4824962818238419e-05 \n",
      "epoch: 35 [384406/888800 43.25%] train loss: 1.474136661272496e-05 \n",
      "epoch: 35 [385517/888800 43.38%] train loss: 1.2664743735513184e-05 \n",
      "epoch: 35 [386628/888800 43.50%] train loss: 1.3638446944241878e-05 \n",
      "epoch: 35 [387739/888800 43.62%] train loss: 1.4331068086903542e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [388850/888800 43.75%] train loss: 1.3922216567152645e-05 \n",
      "epoch: 35 [389961/888800 43.88%] train loss: 1.4277838090492878e-05 \n",
      "epoch: 35 [391072/888800 44.00%] train loss: 1.4075652870815247e-05 \n",
      "epoch: 35 [392183/888800 44.12%] train loss: 1.4992050637374632e-05 \n",
      "epoch: 35 [393294/888800 44.25%] train loss: 1.4785744497203268e-05 \n",
      "epoch: 35 [394405/888800 44.38%] train loss: 1.5974719644873403e-05 \n",
      "epoch: 35 [395516/888800 44.50%] train loss: 1.3444606338453013e-05 \n",
      "epoch: 35 [396627/888800 44.62%] train loss: 1.4172878763929475e-05 \n",
      "epoch: 35 [397738/888800 44.75%] train loss: 1.4364005437528249e-05 \n",
      "epoch: 35 [398849/888800 44.88%] train loss: 1.4300329894467723e-05 \n",
      "epoch: 35 [399960/888800 45.00%] train loss: 1.4122961147222668e-05 \n",
      "epoch: 35 [401071/888800 45.12%] train loss: 1.4641613233834505e-05 \n",
      "epoch: 35 [402182/888800 45.25%] train loss: 1.5720001101726666e-05 \n",
      "epoch: 35 [403293/888800 45.38%] train loss: 1.4367794392455835e-05 \n",
      "epoch: 35 [404404/888800 45.50%] train loss: 1.528829670860432e-05 \n",
      "epoch: 35 [405515/888800 45.62%] train loss: 1.5406470993184485e-05 \n",
      "epoch: 35 [406626/888800 45.75%] train loss: 1.4653904145234264e-05 \n",
      "epoch: 35 [407737/888800 45.88%] train loss: 1.458377573726466e-05 \n",
      "epoch: 35 [408848/888800 46.00%] train loss: 1.5583833373966627e-05 \n",
      "epoch: 35 [409959/888800 46.12%] train loss: 1.6184927517315373e-05 \n",
      "epoch: 35 [411070/888800 46.25%] train loss: 1.4625584299210459e-05 \n",
      "epoch: 35 [412181/888800 46.38%] train loss: 1.7183689124067314e-05 \n",
      "epoch: 35 [413292/888800 46.50%] train loss: 1.4190695765137207e-05 \n",
      "epoch: 35 [414403/888800 46.62%] train loss: 1.4415727491723374e-05 \n",
      "epoch: 35 [415514/888800 46.75%] train loss: 1.3814835256198421e-05 \n",
      "epoch: 35 [416625/888800 46.88%] train loss: 1.6670490367687307e-05 \n",
      "epoch: 35 [417736/888800 47.00%] train loss: 1.493893432780169e-05 \n",
      "epoch: 35 [418847/888800 47.12%] train loss: 1.3921407116868068e-05 \n",
      "epoch: 35 [419958/888800 47.25%] train loss: 1.637687091715634e-05 \n",
      "epoch: 35 [421069/888800 47.38%] train loss: 1.389193676004652e-05 \n",
      "epoch: 35 [422180/888800 47.50%] train loss: 1.6644500647089444e-05 \n",
      "epoch: 35 [423291/888800 47.62%] train loss: 1.3224697795521934e-05 \n",
      "epoch: 35 [424402/888800 47.75%] train loss: 1.851005436037667e-05 \n",
      "epoch: 35 [425513/888800 47.88%] train loss: 1.4622684830101207e-05 \n",
      "epoch: 35 [426624/888800 48.00%] train loss: 1.4987476788519416e-05 \n",
      "epoch: 35 [427735/888800 48.12%] train loss: 1.4426567759073805e-05 \n",
      "epoch: 35 [428846/888800 48.25%] train loss: 1.426736889698077e-05 \n",
      "epoch: 35 [429957/888800 48.38%] train loss: 1.5455409084097482e-05 \n",
      "epoch: 35 [431068/888800 48.50%] train loss: 1.4673491023131646e-05 \n",
      "epoch: 35 [432179/888800 48.62%] train loss: 1.4077114428800996e-05 \n",
      "epoch: 35 [433290/888800 48.75%] train loss: 1.3983135431772098e-05 \n",
      "epoch: 35 [434401/888800 48.88%] train loss: 1.3969233805255499e-05 \n",
      "epoch: 35 [435512/888800 49.00%] train loss: 1.5151767001952976e-05 \n",
      "epoch: 35 [436623/888800 49.12%] train loss: 1.4983053006289992e-05 \n",
      "epoch: 35 [437734/888800 49.25%] train loss: 1.3765770745521877e-05 \n",
      "epoch: 35 [438845/888800 49.38%] train loss: 1.3419407878245693e-05 \n",
      "epoch: 35 [439956/888800 49.50%] train loss: 1.4344647752295714e-05 \n",
      "epoch: 35 [441067/888800 49.62%] train loss: 1.3948133528174367e-05 \n",
      "epoch: 35 [442178/888800 49.75%] train loss: 1.4495631148747634e-05 \n",
      "epoch: 35 [443289/888800 49.88%] train loss: 1.457312100683339e-05 \n",
      "epoch: 35 [444400/888800 50.00%] train loss: 1.3767050404567271e-05 \n",
      "epoch: 35 [445511/888800 50.12%] train loss: 1.3035977644904051e-05 \n",
      "epoch: 35 [446622/888800 50.25%] train loss: 1.4442149222304579e-05 \n",
      "epoch: 35 [447733/888800 50.38%] train loss: 1.4956783161323983e-05 \n",
      "epoch: 35 [448844/888800 50.50%] train loss: 1.384231018164428e-05 \n",
      "epoch: 35 [449955/888800 50.62%] train loss: 1.3626473446493037e-05 \n",
      "epoch: 35 [451066/888800 50.75%] train loss: 1.4417836609936785e-05 \n",
      "epoch: 35 [452177/888800 50.88%] train loss: 1.3627226508106105e-05 \n",
      "epoch: 35 [453288/888800 51.00%] train loss: 1.593947126821149e-05 \n",
      "epoch: 35 [454399/888800 51.12%] train loss: 1.4951320736145135e-05 \n",
      "epoch: 35 [455510/888800 51.25%] train loss: 1.53221426444361e-05 \n",
      "epoch: 35 [456621/888800 51.38%] train loss: 1.4522562196361832e-05 \n",
      "epoch: 35 [457732/888800 51.50%] train loss: 1.5293629985535517e-05 \n",
      "epoch: 35 [458843/888800 51.62%] train loss: 1.4559702322003432e-05 \n",
      "epoch: 35 [459954/888800 51.75%] train loss: 1.4471279428107664e-05 \n",
      "epoch: 35 [461065/888800 51.88%] train loss: 1.687619078438729e-05 \n",
      "epoch: 35 [462176/888800 52.00%] train loss: 1.4197748896549456e-05 \n",
      "epoch: 35 [463287/888800 52.12%] train loss: 1.592153603269253e-05 \n",
      "epoch: 35 [464398/888800 52.25%] train loss: 1.455492565582972e-05 \n",
      "epoch: 35 [465509/888800 52.38%] train loss: 1.553381298435852e-05 \n",
      "epoch: 35 [466620/888800 52.50%] train loss: 1.4032895705895498e-05 \n",
      "epoch: 35 [467731/888800 52.62%] train loss: 1.3867306734027807e-05 \n",
      "epoch: 35 [468842/888800 52.75%] train loss: 1.4645253031631e-05 \n",
      "epoch: 35 [469953/888800 52.88%] train loss: 1.5273324606823735e-05 \n",
      "epoch: 35 [471064/888800 53.00%] train loss: 1.498734582128236e-05 \n",
      "epoch: 35 [472175/888800 53.12%] train loss: 1.3833145203534514e-05 \n",
      "epoch: 35 [473286/888800 53.25%] train loss: 1.3507844414561987e-05 \n",
      "epoch: 35 [474397/888800 53.38%] train loss: 1.4155581993691158e-05 \n",
      "epoch: 35 [475508/888800 53.50%] train loss: 1.4702265616506338e-05 \n",
      "epoch: 35 [476619/888800 53.62%] train loss: 1.3186845535528846e-05 \n",
      "epoch: 35 [477730/888800 53.75%] train loss: 1.4319441106636077e-05 \n",
      "epoch: 35 [478841/888800 53.88%] train loss: 1.3728474186791573e-05 \n",
      "epoch: 35 [479952/888800 54.00%] train loss: 1.4683924746350385e-05 \n",
      "epoch: 35 [481063/888800 54.12%] train loss: 1.2455466276151128e-05 \n",
      "epoch: 35 [482174/888800 54.25%] train loss: 1.3664276593772229e-05 \n",
      "epoch: 35 [483285/888800 54.38%] train loss: 1.4273713532020338e-05 \n",
      "epoch: 35 [484396/888800 54.50%] train loss: 1.2875118045485578e-05 \n",
      "epoch: 35 [485507/888800 54.62%] train loss: 1.3955038411950227e-05 \n",
      "epoch: 35 [486618/888800 54.75%] train loss: 1.3113327440805733e-05 \n",
      "epoch: 35 [487729/888800 54.88%] train loss: 1.4327259123092517e-05 \n",
      "epoch: 35 [488840/888800 55.00%] train loss: 1.4123615073913243e-05 \n",
      "epoch: 35 [489951/888800 55.12%] train loss: 1.3921133358962834e-05 \n",
      "epoch: 35 [491062/888800 55.25%] train loss: 1.4649967852164991e-05 \n",
      "epoch: 35 [492173/888800 55.38%] train loss: 1.449697265343275e-05 \n",
      "epoch: 35 [493284/888800 55.50%] train loss: 1.4583061783923768e-05 \n",
      "epoch: 35 [494395/888800 55.62%] train loss: 1.3619009223475587e-05 \n",
      "epoch: 35 [495506/888800 55.75%] train loss: 1.4847754755464848e-05 \n",
      "epoch: 35 [496617/888800 55.88%] train loss: 1.5489405996049754e-05 \n",
      "epoch: 35 [497728/888800 56.00%] train loss: 1.41119999170769e-05 \n",
      "epoch: 35 [498839/888800 56.12%] train loss: 1.4861148883937858e-05 \n",
      "epoch: 35 [499950/888800 56.25%] train loss: 1.3959524949314073e-05 \n",
      "epoch: 35 [501061/888800 56.38%] train loss: 1.4015640772413462e-05 \n",
      "epoch: 35 [502172/888800 56.50%] train loss: 1.456237441743724e-05 \n",
      "epoch: 35 [503283/888800 56.62%] train loss: 1.428975610906491e-05 \n",
      "epoch: 35 [504394/888800 56.75%] train loss: 1.4719424143549986e-05 \n",
      "epoch: 35 [505505/888800 56.88%] train loss: 1.5294439435820095e-05 \n",
      "epoch: 35 [506616/888800 57.00%] train loss: 1.3946778381068725e-05 \n",
      "epoch: 35 [507727/888800 57.12%] train loss: 1.3869128451915458e-05 \n",
      "epoch: 35 [508838/888800 57.25%] train loss: 1.3658426723850425e-05 \n",
      "epoch: 35 [509949/888800 57.38%] train loss: 1.4448245565290563e-05 \n",
      "epoch: 35 [511060/888800 57.50%] train loss: 1.4635889783676248e-05 \n",
      "epoch: 35 [512171/888800 57.62%] train loss: 1.3364598089538049e-05 \n",
      "epoch: 35 [513282/888800 57.75%] train loss: 1.4557344911736436e-05 \n",
      "epoch: 35 [514393/888800 57.88%] train loss: 1.4457350516750012e-05 \n",
      "epoch: 35 [515504/888800 58.00%] train loss: 1.3663252502738032e-05 \n",
      "epoch: 35 [516615/888800 58.12%] train loss: 1.387321299262112e-05 \n",
      "epoch: 35 [517726/888800 58.25%] train loss: 1.320948103966657e-05 \n",
      "epoch: 35 [518837/888800 58.38%] train loss: 1.5050401088956278e-05 \n",
      "epoch: 35 [519948/888800 58.50%] train loss: 1.323223204963142e-05 \n",
      "epoch: 35 [521059/888800 58.62%] train loss: 1.5417279428220354e-05 \n",
      "epoch: 35 [522170/888800 58.75%] train loss: 1.3925814528192859e-05 \n",
      "epoch: 35 [523281/888800 58.88%] train loss: 1.535757473902777e-05 \n",
      "epoch: 35 [524392/888800 59.00%] train loss: 1.4005552657181397e-05 \n",
      "epoch: 35 [525503/888800 59.12%] train loss: 1.3810964446747676e-05 \n",
      "epoch: 35 [526614/888800 59.25%] train loss: 1.4645815099356696e-05 \n",
      "epoch: 35 [527725/888800 59.38%] train loss: 1.4476840988209005e-05 \n",
      "epoch: 35 [528836/888800 59.50%] train loss: 1.3922300240665209e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [529947/888800 59.62%] train loss: 1.3244549336377531e-05 \n",
      "epoch: 35 [531058/888800 59.75%] train loss: 1.3847470654582139e-05 \n",
      "epoch: 35 [532169/888800 59.88%] train loss: 1.354458618152421e-05 \n",
      "epoch: 35 [533280/888800 60.00%] train loss: 1.5243257621477824e-05 \n",
      "epoch: 35 [534391/888800 60.12%] train loss: 1.4210150766302831e-05 \n",
      "epoch: 35 [535502/888800 60.25%] train loss: 1.422734021616634e-05 \n",
      "epoch: 35 [536613/888800 60.38%] train loss: 1.2890869584225584e-05 \n",
      "epoch: 35 [537724/888800 60.50%] train loss: 1.4253182598622516e-05 \n",
      "epoch: 35 [538835/888800 60.62%] train loss: 1.5854015146032907e-05 \n",
      "epoch: 35 [539946/888800 60.75%] train loss: 1.3243792636785656e-05 \n",
      "epoch: 35 [541057/888800 60.88%] train loss: 1.4895424101268873e-05 \n",
      "epoch: 35 [542168/888800 61.00%] train loss: 1.3878243407816626e-05 \n",
      "epoch: 35 [543279/888800 61.12%] train loss: 1.499534846516326e-05 \n",
      "epoch: 35 [544390/888800 61.25%] train loss: 1.4100725820753723e-05 \n",
      "epoch: 35 [545501/888800 61.38%] train loss: 1.3682597455044743e-05 \n",
      "epoch: 35 [546612/888800 61.50%] train loss: 1.383532344334526e-05 \n",
      "epoch: 35 [547723/888800 61.62%] train loss: 1.4613987332268152e-05 \n",
      "epoch: 35 [548834/888800 61.75%] train loss: 1.3718638001591899e-05 \n",
      "epoch: 35 [549945/888800 61.88%] train loss: 1.3853671589458827e-05 \n",
      "epoch: 35 [551056/888800 62.00%] train loss: 1.5651843568775803e-05 \n",
      "epoch: 35 [552167/888800 62.12%] train loss: 1.6257798051810823e-05 \n",
      "epoch: 35 [553278/888800 62.25%] train loss: 1.3491056961356662e-05 \n",
      "epoch: 35 [554389/888800 62.38%] train loss: 1.6057321772677824e-05 \n",
      "epoch: 35 [555500/888800 62.50%] train loss: 1.3913429938838817e-05 \n",
      "epoch: 35 [556611/888800 62.62%] train loss: 1.583978701091837e-05 \n",
      "epoch: 35 [557722/888800 62.75%] train loss: 1.5217788131849375e-05 \n",
      "epoch: 35 [558833/888800 62.88%] train loss: 1.397252799506532e-05 \n",
      "epoch: 35 [559944/888800 63.00%] train loss: 1.5243694178934675e-05 \n",
      "epoch: 35 [561055/888800 63.12%] train loss: 1.4066749827179592e-05 \n",
      "epoch: 35 [562166/888800 63.25%] train loss: 1.3901860256737564e-05 \n",
      "epoch: 35 [563277/888800 63.38%] train loss: 1.4677865692647174e-05 \n",
      "epoch: 35 [564388/888800 63.50%] train loss: 1.5925410480122082e-05 \n",
      "epoch: 35 [565499/888800 63.62%] train loss: 1.3803629371977877e-05 \n",
      "epoch: 35 [566610/888800 63.75%] train loss: 1.4474660929408856e-05 \n",
      "epoch: 35 [567721/888800 63.88%] train loss: 1.4710892173752654e-05 \n",
      "epoch: 35 [568832/888800 64.00%] train loss: 1.4126461792329792e-05 \n",
      "epoch: 35 [569943/888800 64.12%] train loss: 1.230937778018415e-05 \n",
      "epoch: 35 [571054/888800 64.25%] train loss: 1.4231431123334914e-05 \n",
      "epoch: 35 [572165/888800 64.38%] train loss: 1.3499282431439497e-05 \n",
      "epoch: 35 [573276/888800 64.50%] train loss: 1.3967450286145322e-05 \n",
      "epoch: 35 [574387/888800 64.62%] train loss: 1.4729789654666092e-05 \n",
      "epoch: 35 [575498/888800 64.75%] train loss: 1.2186971616756637e-05 \n",
      "epoch: 35 [576609/888800 64.88%] train loss: 1.4462735634879209e-05 \n",
      "epoch: 35 [577720/888800 65.00%] train loss: 1.3528993804357015e-05 \n",
      "epoch: 35 [578831/888800 65.12%] train loss: 1.291229546040995e-05 \n",
      "epoch: 35 [579942/888800 65.25%] train loss: 1.4078128515393473e-05 \n",
      "epoch: 35 [581053/888800 65.38%] train loss: 1.3681447853741702e-05 \n",
      "epoch: 35 [582164/888800 65.50%] train loss: 1.484745826019207e-05 \n",
      "epoch: 35 [583275/888800 65.62%] train loss: 1.3762966773356311e-05 \n",
      "epoch: 35 [584386/888800 65.75%] train loss: 1.3970317922940012e-05 \n",
      "epoch: 35 [585497/888800 65.88%] train loss: 1.5104888916539494e-05 \n",
      "epoch: 35 [586608/888800 66.00%] train loss: 1.4884033589623868e-05 \n",
      "epoch: 35 [587719/888800 66.12%] train loss: 1.4359797205543146e-05 \n",
      "epoch: 35 [588830/888800 66.25%] train loss: 1.4644720067735761e-05 \n",
      "epoch: 35 [589941/888800 66.38%] train loss: 1.4560981981048826e-05 \n",
      "epoch: 35 [591052/888800 66.50%] train loss: 1.3465807569446042e-05 \n",
      "epoch: 35 [592163/888800 66.62%] train loss: 1.379865534545388e-05 \n",
      "epoch: 35 [593274/888800 66.75%] train loss: 1.4900204405421391e-05 \n",
      "epoch: 35 [594385/888800 66.88%] train loss: 1.5196408639894798e-05 \n",
      "epoch: 35 [595496/888800 67.00%] train loss: 1.5247741430357564e-05 \n",
      "epoch: 35 [596607/888800 67.12%] train loss: 1.4939922039047815e-05 \n",
      "epoch: 35 [597718/888800 67.25%] train loss: 1.535364572191611e-05 \n",
      "epoch: 35 [598829/888800 67.38%] train loss: 1.4665000890090596e-05 \n",
      "epoch: 35 [599940/888800 67.50%] train loss: 1.445651378162438e-05 \n",
      "epoch: 35 [601051/888800 67.62%] train loss: 1.5213639926514588e-05 \n",
      "epoch: 35 [602162/888800 67.75%] train loss: 1.4327223652799148e-05 \n",
      "epoch: 35 [603273/888800 67.88%] train loss: 1.4818792806181591e-05 \n",
      "epoch: 35 [604384/888800 68.00%] train loss: 1.4168606867315248e-05 \n",
      "epoch: 35 [605495/888800 68.12%] train loss: 1.5135003195609897e-05 \n",
      "epoch: 35 [606606/888800 68.25%] train loss: 1.3876175216864794e-05 \n",
      "epoch: 35 [607717/888800 68.38%] train loss: 1.6200323443626985e-05 \n",
      "epoch: 35 [608828/888800 68.50%] train loss: 1.409059768775478e-05 \n",
      "epoch: 35 [609939/888800 68.62%] train loss: 1.4071957593841944e-05 \n",
      "epoch: 35 [611050/888800 68.75%] train loss: 1.3539668543671723e-05 \n",
      "epoch: 35 [612161/888800 68.88%] train loss: 1.4910414392943494e-05 \n",
      "epoch: 35 [613272/888800 69.00%] train loss: 1.3711633073398843e-05 \n",
      "epoch: 35 [614383/888800 69.12%] train loss: 1.3365697668632492e-05 \n",
      "epoch: 35 [615494/888800 69.25%] train loss: 1.500112921348773e-05 \n",
      "epoch: 35 [616605/888800 69.38%] train loss: 1.4379471394931898e-05 \n",
      "epoch: 35 [617716/888800 69.50%] train loss: 1.3853670679964125e-05 \n",
      "epoch: 35 [618827/888800 69.62%] train loss: 1.4325533811643254e-05 \n",
      "epoch: 35 [619938/888800 69.75%] train loss: 1.5364337741630152e-05 \n",
      "epoch: 35 [621049/888800 69.88%] train loss: 1.4415998521144502e-05 \n",
      "epoch: 35 [622160/888800 70.00%] train loss: 1.4260988791647833e-05 \n",
      "epoch: 35 [623271/888800 70.12%] train loss: 1.3971796761325095e-05 \n",
      "epoch: 35 [624382/888800 70.25%] train loss: 1.3250189113023225e-05 \n",
      "epoch: 35 [625493/888800 70.38%] train loss: 1.3931102330388967e-05 \n",
      "epoch: 35 [626604/888800 70.50%] train loss: 1.5162292584136594e-05 \n",
      "epoch: 35 [627715/888800 70.62%] train loss: 1.4075744729780126e-05 \n",
      "epoch: 35 [628826/888800 70.75%] train loss: 1.5164750038820785e-05 \n",
      "epoch: 35 [629937/888800 70.88%] train loss: 1.341266579402145e-05 \n",
      "epoch: 35 [631048/888800 71.00%] train loss: 1.5863990483921953e-05 \n",
      "epoch: 35 [632159/888800 71.12%] train loss: 1.395304479956394e-05 \n",
      "epoch: 35 [633270/888800 71.25%] train loss: 1.4918849046807736e-05 \n",
      "epoch: 35 [634381/888800 71.38%] train loss: 1.3692305401491467e-05 \n",
      "epoch: 35 [635492/888800 71.50%] train loss: 1.4136675417830702e-05 \n",
      "epoch: 35 [636603/888800 71.62%] train loss: 1.4901074791850988e-05 \n",
      "epoch: 35 [637714/888800 71.75%] train loss: 1.4074432328925468e-05 \n",
      "epoch: 35 [638825/888800 71.88%] train loss: 1.4985440429882146e-05 \n",
      "epoch: 35 [639936/888800 72.00%] train loss: 1.3850986761099193e-05 \n",
      "epoch: 35 [641047/888800 72.12%] train loss: 1.4147271031106357e-05 \n",
      "epoch: 35 [642158/888800 72.25%] train loss: 1.3588479305326473e-05 \n",
      "epoch: 35 [643269/888800 72.38%] train loss: 1.4062530681258067e-05 \n",
      "epoch: 35 [644380/888800 72.50%] train loss: 1.406265528203221e-05 \n",
      "epoch: 35 [645491/888800 72.62%] train loss: 1.3811708413413726e-05 \n",
      "epoch: 35 [646602/888800 72.75%] train loss: 1.4391155673365574e-05 \n",
      "epoch: 35 [647713/888800 72.88%] train loss: 1.371593043586472e-05 \n",
      "epoch: 35 [648824/888800 73.00%] train loss: 1.3658657735504676e-05 \n",
      "epoch: 35 [649935/888800 73.12%] train loss: 1.4251793800212909e-05 \n",
      "epoch: 35 [651046/888800 73.25%] train loss: 1.5071736925165169e-05 \n",
      "epoch: 35 [652157/888800 73.38%] train loss: 1.3574672266258858e-05 \n",
      "epoch: 35 [653268/888800 73.50%] train loss: 1.3607729670184199e-05 \n",
      "epoch: 35 [654379/888800 73.62%] train loss: 1.509925914433552e-05 \n",
      "epoch: 35 [655490/888800 73.75%] train loss: 1.4107322385825682e-05 \n",
      "epoch: 35 [656601/888800 73.88%] train loss: 1.552668800286483e-05 \n",
      "epoch: 35 [657712/888800 74.00%] train loss: 1.2549527127703186e-05 \n",
      "epoch: 35 [658823/888800 74.12%] train loss: 1.3122348718752619e-05 \n",
      "epoch: 35 [659934/888800 74.25%] train loss: 1.2916848390887026e-05 \n",
      "epoch: 35 [661045/888800 74.38%] train loss: 1.3129663784638979e-05 \n",
      "epoch: 35 [662156/888800 74.50%] train loss: 1.3311453585629351e-05 \n",
      "epoch: 35 [663267/888800 74.62%] train loss: 1.389624594594352e-05 \n",
      "epoch: 35 [664378/888800 74.75%] train loss: 1.4302444469649345e-05 \n",
      "epoch: 35 [665489/888800 74.88%] train loss: 1.4172766896081157e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [666600/888800 75.00%] train loss: 1.5697552953497507e-05 \n",
      "epoch: 35 [667711/888800 75.12%] train loss: 1.4043190276424866e-05 \n",
      "epoch: 35 [668822/888800 75.25%] train loss: 1.3813197256240528e-05 \n",
      "epoch: 35 [669933/888800 75.38%] train loss: 1.345504915661877e-05 \n",
      "epoch: 35 [671044/888800 75.50%] train loss: 1.4617851775255986e-05 \n",
      "epoch: 35 [672155/888800 75.62%] train loss: 1.464182605559472e-05 \n",
      "epoch: 35 [673266/888800 75.75%] train loss: 1.4661995010101236e-05 \n",
      "epoch: 35 [674377/888800 75.88%] train loss: 1.3768020835414063e-05 \n",
      "epoch: 35 [675488/888800 76.00%] train loss: 1.330972918367479e-05 \n",
      "epoch: 35 [676599/888800 76.12%] train loss: 1.3369180123845581e-05 \n",
      "epoch: 35 [677710/888800 76.25%] train loss: 1.4624551113229245e-05 \n",
      "epoch: 35 [678821/888800 76.38%] train loss: 1.453545246477006e-05 \n",
      "epoch: 35 [679932/888800 76.50%] train loss: 1.4032528270035982e-05 \n",
      "epoch: 35 [681043/888800 76.62%] train loss: 1.436113871022826e-05 \n",
      "epoch: 35 [682154/888800 76.75%] train loss: 1.3365144695853814e-05 \n",
      "epoch: 35 [683265/888800 76.88%] train loss: 1.4045838724996429e-05 \n",
      "epoch: 35 [684376/888800 77.00%] train loss: 1.4402264241653029e-05 \n",
      "epoch: 35 [685487/888800 77.12%] train loss: 1.4268405720940791e-05 \n",
      "epoch: 35 [686598/888800 77.25%] train loss: 1.4234067748475354e-05 \n",
      "epoch: 35 [687709/888800 77.38%] train loss: 1.2902495654998347e-05 \n",
      "epoch: 35 [688820/888800 77.50%] train loss: 1.4854640539851971e-05 \n",
      "epoch: 35 [689931/888800 77.62%] train loss: 1.5081682249729056e-05 \n",
      "epoch: 35 [691042/888800 77.75%] train loss: 1.4676671526103746e-05 \n",
      "epoch: 35 [692153/888800 77.88%] train loss: 1.259881173609756e-05 \n",
      "epoch: 35 [693264/888800 78.00%] train loss: 1.373873237753287e-05 \n",
      "epoch: 35 [694375/888800 78.12%] train loss: 1.4081158042245079e-05 \n",
      "epoch: 35 [695486/888800 78.25%] train loss: 1.3417859008768573e-05 \n",
      "epoch: 35 [696597/888800 78.38%] train loss: 1.395984145347029e-05 \n",
      "epoch: 35 [697708/888800 78.50%] train loss: 1.4475908756139688e-05 \n",
      "epoch: 35 [698819/888800 78.62%] train loss: 1.4595711036236025e-05 \n",
      "epoch: 35 [699930/888800 78.75%] train loss: 1.4417386410059407e-05 \n",
      "epoch: 35 [701041/888800 78.88%] train loss: 1.4802482837694697e-05 \n",
      "epoch: 35 [702152/888800 79.00%] train loss: 1.4587722034775652e-05 \n",
      "epoch: 35 [703263/888800 79.12%] train loss: 1.5052623894007411e-05 \n",
      "epoch: 35 [704374/888800 79.25%] train loss: 1.5720268493168987e-05 \n",
      "epoch: 35 [705485/888800 79.38%] train loss: 1.4525357983075082e-05 \n",
      "epoch: 35 [706596/888800 79.50%] train loss: 1.594836066942662e-05 \n",
      "epoch: 35 [707707/888800 79.62%] train loss: 1.4476401702268049e-05 \n",
      "epoch: 35 [708818/888800 79.75%] train loss: 1.6062000213423744e-05 \n",
      "epoch: 35 [709929/888800 79.88%] train loss: 1.4723197637067642e-05 \n",
      "epoch: 35 [711040/888800 80.00%] train loss: 1.536164927529171e-05 \n",
      "epoch: 35 [712151/888800 80.12%] train loss: 1.4503926649922505e-05 \n",
      "epoch: 35 [713262/888800 80.25%] train loss: 1.4685570931760594e-05 \n",
      "epoch: 35 [714373/888800 80.38%] train loss: 1.4304605429060757e-05 \n",
      "epoch: 35 [715484/888800 80.50%] train loss: 1.4041315807844512e-05 \n",
      "epoch: 35 [716595/888800 80.62%] train loss: 1.5416582755278796e-05 \n",
      "epoch: 35 [717706/888800 80.75%] train loss: 1.4455786185862962e-05 \n",
      "epoch: 35 [718817/888800 80.88%] train loss: 1.5173647625488229e-05 \n",
      "epoch: 35 [719928/888800 81.00%] train loss: 1.5391091437777504e-05 \n",
      "epoch: 35 [721039/888800 81.12%] train loss: 1.3003897038288414e-05 \n",
      "epoch: 35 [722150/888800 81.25%] train loss: 1.4124835615803022e-05 \n",
      "epoch: 35 [723261/888800 81.38%] train loss: 1.4560540876118466e-05 \n",
      "epoch: 35 [724372/888800 81.50%] train loss: 1.397289179294603e-05 \n",
      "epoch: 35 [725483/888800 81.62%] train loss: 1.4880693925078958e-05 \n",
      "epoch: 35 [726594/888800 81.75%] train loss: 1.4179791833157651e-05 \n",
      "epoch: 35 [727705/888800 81.88%] train loss: 1.4892579201841727e-05 \n",
      "epoch: 35 [728816/888800 82.00%] train loss: 1.269892709387932e-05 \n",
      "epoch: 35 [729927/888800 82.12%] train loss: 1.5582694686600007e-05 \n",
      "epoch: 35 [731038/888800 82.25%] train loss: 1.3467721146298572e-05 \n",
      "epoch: 35 [732149/888800 82.38%] train loss: 1.396002608089475e-05 \n",
      "epoch: 35 [733260/888800 82.50%] train loss: 1.2641527973755728e-05 \n",
      "epoch: 35 [734371/888800 82.62%] train loss: 1.4226734492694959e-05 \n",
      "epoch: 35 [735482/888800 82.75%] train loss: 1.3304738786246162e-05 \n",
      "epoch: 35 [736593/888800 82.88%] train loss: 1.532169699203223e-05 \n",
      "epoch: 35 [737704/888800 83.00%] train loss: 1.4639841538155451e-05 \n",
      "epoch: 35 [738815/888800 83.12%] train loss: 1.5614043149980716e-05 \n",
      "epoch: 35 [739926/888800 83.25%] train loss: 1.4621949048887473e-05 \n",
      "epoch: 35 [741037/888800 83.38%] train loss: 1.3422009942587465e-05 \n",
      "epoch: 35 [742148/888800 83.50%] train loss: 1.4747171007911675e-05 \n",
      "epoch: 35 [743259/888800 83.62%] train loss: 1.3647441846842412e-05 \n",
      "epoch: 35 [744370/888800 83.75%] train loss: 1.3727324585488532e-05 \n",
      "epoch: 35 [745481/888800 83.88%] train loss: 1.4347887372423429e-05 \n",
      "epoch: 35 [746592/888800 84.00%] train loss: 1.487981262471294e-05 \n",
      "epoch: 35 [747703/888800 84.12%] train loss: 1.4291636034613475e-05 \n",
      "epoch: 35 [748814/888800 84.25%] train loss: 1.3395415408012923e-05 \n",
      "epoch: 35 [749925/888800 84.38%] train loss: 1.4026026292413007e-05 \n",
      "epoch: 35 [751036/888800 84.50%] train loss: 1.3751237020187546e-05 \n",
      "epoch: 35 [752147/888800 84.62%] train loss: 1.323840842815116e-05 \n",
      "epoch: 35 [753258/888800 84.75%] train loss: 1.4399352039617952e-05 \n",
      "epoch: 35 [754369/888800 84.88%] train loss: 1.3545904039347079e-05 \n",
      "epoch: 35 [755480/888800 85.00%] train loss: 1.3217670129961334e-05 \n",
      "epoch: 35 [756591/888800 85.12%] train loss: 1.3067597137705889e-05 \n",
      "epoch: 35 [757702/888800 85.25%] train loss: 1.3967444829177111e-05 \n",
      "epoch: 35 [758813/888800 85.38%] train loss: 1.4015651686349884e-05 \n",
      "epoch: 35 [759924/888800 85.50%] train loss: 1.3696039786736947e-05 \n",
      "epoch: 35 [761035/888800 85.62%] train loss: 1.3780816516373307e-05 \n",
      "epoch: 35 [762146/888800 85.75%] train loss: 1.4085483599046711e-05 \n",
      "epoch: 35 [763257/888800 85.88%] train loss: 1.363309274893254e-05 \n",
      "epoch: 35 [764368/888800 86.00%] train loss: 1.5157641428231727e-05 \n",
      "epoch: 35 [765479/888800 86.12%] train loss: 1.6310848877765238e-05 \n",
      "epoch: 35 [766590/888800 86.25%] train loss: 1.3377614777709823e-05 \n",
      "epoch: 35 [767701/888800 86.38%] train loss: 1.4110102711129002e-05 \n",
      "epoch: 35 [768812/888800 86.50%] train loss: 1.5553074263152666e-05 \n",
      "epoch: 35 [769923/888800 86.62%] train loss: 1.643805626372341e-05 \n",
      "epoch: 35 [771034/888800 86.75%] train loss: 1.653463186812587e-05 \n",
      "epoch: 35 [772145/888800 86.88%] train loss: 1.3919693628849927e-05 \n",
      "epoch: 35 [773256/888800 87.00%] train loss: 1.5022476873127744e-05 \n",
      "epoch: 35 [774367/888800 87.12%] train loss: 1.491205421189079e-05 \n",
      "epoch: 35 [775478/888800 87.25%] train loss: 1.3777931599179283e-05 \n",
      "epoch: 35 [776589/888800 87.38%] train loss: 1.4887257748341653e-05 \n",
      "epoch: 35 [777700/888800 87.50%] train loss: 1.5123789125937037e-05 \n",
      "epoch: 35 [778811/888800 87.62%] train loss: 1.3679001312993933e-05 \n",
      "epoch: 35 [779922/888800 87.75%] train loss: 1.4755536540178582e-05 \n",
      "epoch: 35 [781033/888800 87.88%] train loss: 1.4304647265817039e-05 \n",
      "epoch: 35 [782144/888800 88.00%] train loss: 1.475951648899354e-05 \n",
      "epoch: 35 [783255/888800 88.12%] train loss: 1.569778032717295e-05 \n",
      "epoch: 35 [784366/888800 88.25%] train loss: 1.3806833521812223e-05 \n",
      "epoch: 35 [785477/888800 88.38%] train loss: 1.3734608728555031e-05 \n",
      "epoch: 35 [786588/888800 88.50%] train loss: 1.2746944776154123e-05 \n",
      "epoch: 35 [787699/888800 88.62%] train loss: 1.5427402104251087e-05 \n",
      "epoch: 35 [788810/888800 88.75%] train loss: 1.4147043657430913e-05 \n",
      "epoch: 35 [789921/888800 88.88%] train loss: 1.545852683193516e-05 \n",
      "epoch: 35 [791032/888800 89.00%] train loss: 1.3916530406277161e-05 \n",
      "epoch: 35 [792143/888800 89.12%] train loss: 1.3969717656436842e-05 \n",
      "epoch: 35 [793254/888800 89.25%] train loss: 1.2791052540706005e-05 \n",
      "epoch: 35 [794365/888800 89.38%] train loss: 1.5101401913852897e-05 \n",
      "epoch: 35 [795476/888800 89.50%] train loss: 1.3648768799612299e-05 \n",
      "epoch: 35 [796587/888800 89.62%] train loss: 1.4101656233833637e-05 \n",
      "epoch: 35 [797698/888800 89.75%] train loss: 1.4392684533959255e-05 \n",
      "epoch: 35 [798809/888800 89.88%] train loss: 1.3810036762151867e-05 \n",
      "epoch: 35 [799920/888800 90.00%] train loss: 1.4266720427258406e-05 \n",
      "epoch: 35 [801031/888800 90.12%] train loss: 1.4714975804963615e-05 \n",
      "epoch: 35 [802142/888800 90.25%] train loss: 1.3264644621813204e-05 \n",
      "epoch: 35 [803253/888800 90.38%] train loss: 1.480964056099765e-05 \n",
      "epoch: 35 [804364/888800 90.50%] train loss: 1.4007088793732692e-05 \n",
      "epoch: 35 [805475/888800 90.62%] train loss: 1.4285824363469146e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 [806586/888800 90.75%] train loss: 1.3962789125798736e-05 \n",
      "epoch: 35 [807697/888800 90.88%] train loss: 1.4089886462897994e-05 \n",
      "epoch: 35 [808808/888800 91.00%] train loss: 1.4511734661937226e-05 \n",
      "epoch: 35 [809919/888800 91.12%] train loss: 1.609873288543895e-05 \n",
      "epoch: 35 [811030/888800 91.25%] train loss: 1.3895098163629882e-05 \n",
      "epoch: 35 [812141/888800 91.38%] train loss: 1.582316508574877e-05 \n",
      "epoch: 35 [813252/888800 91.50%] train loss: 1.4120406376605388e-05 \n",
      "epoch: 35 [814363/888800 91.62%] train loss: 1.3261791536933742e-05 \n",
      "epoch: 35 [815474/888800 91.75%] train loss: 1.5249580428644549e-05 \n",
      "epoch: 35 [816585/888800 91.88%] train loss: 1.4067742995393928e-05 \n",
      "epoch: 35 [817696/888800 92.00%] train loss: 1.5110659660422243e-05 \n",
      "epoch: 35 [818807/888800 92.12%] train loss: 1.3638927157444414e-05 \n",
      "epoch: 35 [819918/888800 92.25%] train loss: 1.435448484699009e-05 \n",
      "epoch: 35 [821029/888800 92.38%] train loss: 1.4243116311263293e-05 \n",
      "epoch: 35 [822140/888800 92.50%] train loss: 1.4960672160668764e-05 \n",
      "epoch: 35 [823251/888800 92.62%] train loss: 1.3989224498800468e-05 \n",
      "epoch: 35 [824362/888800 92.75%] train loss: 1.3627288353745826e-05 \n",
      "epoch: 35 [825473/888800 92.88%] train loss: 1.4300194379757158e-05 \n",
      "epoch: 35 [826584/888800 93.00%] train loss: 1.4587804798793513e-05 \n",
      "epoch: 35 [827695/888800 93.12%] train loss: 1.414561029378092e-05 \n",
      "epoch: 35 [828806/888800 93.25%] train loss: 1.455890105717117e-05 \n",
      "epoch: 35 [829917/888800 93.38%] train loss: 1.3385919373831712e-05 \n",
      "epoch: 35 [831028/888800 93.50%] train loss: 1.3097180271870457e-05 \n",
      "epoch: 35 [832139/888800 93.62%] train loss: 1.3827851034875493e-05 \n",
      "epoch: 35 [833250/888800 93.75%] train loss: 1.2896129192085937e-05 \n",
      "epoch: 35 [834361/888800 93.88%] train loss: 1.6069910998339765e-05 \n",
      "epoch: 35 [835472/888800 94.00%] train loss: 1.3949819731351454e-05 \n",
      "epoch: 35 [836583/888800 94.12%] train loss: 1.388157943438273e-05 \n",
      "epoch: 35 [837694/888800 94.25%] train loss: 1.33450794237433e-05 \n",
      "epoch: 35 [838805/888800 94.38%] train loss: 1.398814310960006e-05 \n",
      "epoch: 35 [839916/888800 94.50%] train loss: 1.4733478565176483e-05 \n",
      "epoch: 35 [841027/888800 94.62%] train loss: 1.4368342817761004e-05 \n",
      "epoch: 35 [842138/888800 94.75%] train loss: 1.4394622667168733e-05 \n",
      "epoch: 35 [843249/888800 94.88%] train loss: 1.4095472579356283e-05 \n",
      "epoch: 35 [844360/888800 95.00%] train loss: 1.4895630556566175e-05 \n",
      "epoch: 35 [845471/888800 95.12%] train loss: 1.5207469004963059e-05 \n",
      "epoch: 35 [846582/888800 95.25%] train loss: 1.4270412066252902e-05 \n",
      "epoch: 35 [847693/888800 95.38%] train loss: 1.3873026546207257e-05 \n",
      "epoch: 35 [848804/888800 95.50%] train loss: 1.395078197674593e-05 \n",
      "epoch: 35 [849915/888800 95.62%] train loss: 1.4989666851761285e-05 \n",
      "epoch: 35 [851026/888800 95.75%] train loss: 1.3132930689607747e-05 \n",
      "epoch: 35 [852137/888800 95.88%] train loss: 1.5224896742438432e-05 \n",
      "epoch: 35 [853248/888800 96.00%] train loss: 1.3565956578531768e-05 \n",
      "epoch: 35 [854359/888800 96.12%] train loss: 1.32008781292825e-05 \n",
      "epoch: 35 [855470/888800 96.25%] train loss: 1.4392034245247487e-05 \n",
      "epoch: 35 [856581/888800 96.38%] train loss: 1.3330467481864616e-05 \n",
      "epoch: 35 [857692/888800 96.50%] train loss: 1.4947979252610821e-05 \n",
      "epoch: 35 [858803/888800 96.62%] train loss: 1.3566630514105782e-05 \n",
      "epoch: 35 [859914/888800 96.75%] train loss: 1.4736639968759846e-05 \n",
      "epoch: 35 [861025/888800 96.88%] train loss: 1.601966141606681e-05 \n",
      "epoch: 35 [862136/888800 97.00%] train loss: 1.3469319128489587e-05 \n",
      "epoch: 35 [863247/888800 97.12%] train loss: 1.3529094758268911e-05 \n",
      "epoch: 35 [864358/888800 97.25%] train loss: 1.4327344615594484e-05 \n",
      "epoch: 35 [865469/888800 97.38%] train loss: 1.3971511179988738e-05 \n",
      "epoch: 35 [866580/888800 97.50%] train loss: 1.2996126315556467e-05 \n",
      "epoch: 35 [867691/888800 97.62%] train loss: 1.4851897503831424e-05 \n",
      "epoch: 35 [868802/888800 97.75%] train loss: 1.4438714060815983e-05 \n",
      "epoch: 35 [869913/888800 97.88%] train loss: 1.4823684978182428e-05 \n",
      "epoch: 35 [871024/888800 98.00%] train loss: 1.4267795449995901e-05 \n",
      "epoch: 35 [872135/888800 98.12%] train loss: 1.3492842299456242e-05 \n",
      "epoch: 35 [873246/888800 98.25%] train loss: 1.4330249541671947e-05 \n",
      "epoch: 35 [874357/888800 98.38%] train loss: 1.5106085811567027e-05 \n",
      "epoch: 35 [875468/888800 98.50%] train loss: 1.4201094018062577e-05 \n",
      "epoch: 35 [876579/888800 98.62%] train loss: 1.3847632544639055e-05 \n",
      "epoch: 35 [877690/888800 98.75%] train loss: 1.5099493793968577e-05 \n",
      "epoch: 35 [878801/888800 98.88%] train loss: 1.2922132555104326e-05 \n",
      "epoch: 35 [879912/888800 99.00%] train loss: 1.5154732864175458e-05 \n",
      "epoch: 35 [881023/888800 99.12%] train loss: 1.5189175428531598e-05 \n",
      "epoch: 35 [882134/888800 99.25%] train loss: 1.5050723050080705e-05 \n",
      "epoch: 35 [883245/888800 99.38%] train loss: 1.4242014913179446e-05 \n",
      "epoch: 35 [884356/888800 99.50%] train loss: 1.4970057236496359e-05 \n",
      "epoch: 35 [885467/888800 99.62%] train loss: 1.4206552805262618e-05 \n",
      "epoch: 35 [886578/888800 99.75%] train loss: 1.3485671843227465e-05 \n",
      "epoch: 35 [887689/888800 99.88%] train loss: 1.5737334251753055e-05 \n",
      "epoch: 36 [0/888800 0.00%] train loss: 1.4029878002475016e-05 \n",
      "epoch: 36 [1111/888800 0.12%] train loss: 1.5158454516495112e-05 \n",
      "epoch: 36 [2222/888800 0.25%] train loss: 1.388701275573112e-05 \n",
      "epoch: 36 [3333/888800 0.38%] train loss: 1.5796342268004082e-05 \n",
      "epoch: 36 [4444/888800 0.50%] train loss: 1.464347315049963e-05 \n",
      "epoch: 36 [5555/888800 0.62%] train loss: 1.3720458809984848e-05 \n",
      "epoch: 36 [6666/888800 0.75%] train loss: 1.6626981960143894e-05 \n",
      "epoch: 36 [7777/888800 0.88%] train loss: 1.3211123587097973e-05 \n",
      "epoch: 36 [8888/888800 1.00%] train loss: 1.553758374939207e-05 \n",
      "epoch: 36 [9999/888800 1.12%] train loss: 1.5173975953075569e-05 \n",
      "epoch: 36 [11110/888800 1.25%] train loss: 1.4734876458533108e-05 \n",
      "epoch: 36 [12221/888800 1.38%] train loss: 1.4533829926222097e-05 \n",
      "epoch: 36 [13332/888800 1.50%] train loss: 1.4224531696527265e-05 \n",
      "epoch: 36 [14443/888800 1.62%] train loss: 1.4775206182093825e-05 \n",
      "epoch: 36 [15554/888800 1.75%] train loss: 1.5309689842979424e-05 \n",
      "epoch: 36 [16665/888800 1.88%] train loss: 1.5278063074219972e-05 \n",
      "epoch: 36 [17776/888800 2.00%] train loss: 1.5275923942681402e-05 \n",
      "epoch: 36 [18887/888800 2.12%] train loss: 1.5395000446005724e-05 \n",
      "epoch: 36 [19998/888800 2.25%] train loss: 1.4533849935105536e-05 \n",
      "epoch: 36 [21109/888800 2.38%] train loss: 1.5162847375904676e-05 \n",
      "epoch: 36 [22220/888800 2.50%] train loss: 1.3952024346508551e-05 \n",
      "epoch: 36 [23331/888800 2.62%] train loss: 1.4781559912080411e-05 \n",
      "epoch: 36 [24442/888800 2.75%] train loss: 1.4844254110357724e-05 \n",
      "epoch: 36 [25553/888800 2.88%] train loss: 1.4823466699454002e-05 \n",
      "epoch: 36 [26664/888800 3.00%] train loss: 1.495475044066552e-05 \n",
      "epoch: 36 [27775/888800 3.12%] train loss: 1.3614263480121735e-05 \n",
      "epoch: 36 [28886/888800 3.25%] train loss: 1.4674546036985703e-05 \n",
      "epoch: 36 [29997/888800 3.38%] train loss: 1.4857588212180417e-05 \n",
      "epoch: 36 [31108/888800 3.50%] train loss: 1.5263900422723964e-05 \n",
      "epoch: 36 [32219/888800 3.62%] train loss: 1.4456618373515084e-05 \n",
      "epoch: 36 [33330/888800 3.75%] train loss: 1.5329336747527122e-05 \n",
      "epoch: 36 [34441/888800 3.88%] train loss: 1.430588963557966e-05 \n",
      "epoch: 36 [35552/888800 4.00%] train loss: 1.4960284715925809e-05 \n",
      "epoch: 36 [36663/888800 4.12%] train loss: 1.3392787877819501e-05 \n",
      "epoch: 36 [37774/888800 4.25%] train loss: 1.4684947018395178e-05 \n",
      "epoch: 36 [38885/888800 4.38%] train loss: 1.4114685654931236e-05 \n",
      "epoch: 36 [39996/888800 4.50%] train loss: 1.3414824024948757e-05 \n",
      "epoch: 36 [41107/888800 4.62%] train loss: 1.40226366056595e-05 \n",
      "epoch: 36 [42218/888800 4.75%] train loss: 1.5433424778166227e-05 \n",
      "epoch: 36 [43329/888800 4.88%] train loss: 1.2968013834324665e-05 \n",
      "epoch: 36 [44440/888800 5.00%] train loss: 1.362946568406187e-05 \n",
      "epoch: 36 [45551/888800 5.12%] train loss: 1.3219080756243784e-05 \n",
      "epoch: 36 [46662/888800 5.25%] train loss: 1.611057814443484e-05 \n",
      "epoch: 36 [47773/888800 5.38%] train loss: 1.447401700716e-05 \n",
      "epoch: 36 [48884/888800 5.50%] train loss: 1.5243113921314944e-05 \n",
      "epoch: 36 [49995/888800 5.62%] train loss: 1.6037458408391103e-05 \n",
      "epoch: 36 [51106/888800 5.75%] train loss: 1.3308370398590341e-05 \n",
      "epoch: 36 [52217/888800 5.88%] train loss: 1.3770662917522714e-05 \n",
      "epoch: 36 [53328/888800 6.00%] train loss: 1.2646537470573094e-05 \n",
      "epoch: 36 [54439/888800 6.12%] train loss: 1.5020976206869818e-05 \n",
      "epoch: 36 [55550/888800 6.25%] train loss: 1.4366929462994449e-05 \n",
      "epoch: 36 [56661/888800 6.38%] train loss: 1.3884115105611272e-05 \n",
      "epoch: 36 [57772/888800 6.50%] train loss: 1.4399588508240413e-05 \n",
      "epoch: 36 [58883/888800 6.62%] train loss: 1.3064656741335057e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [59994/888800 6.75%] train loss: 1.507658544142032e-05 \n",
      "epoch: 36 [61105/888800 6.88%] train loss: 1.4179541722114664e-05 \n",
      "epoch: 36 [62216/888800 7.00%] train loss: 1.5237736988638062e-05 \n",
      "epoch: 36 [63327/888800 7.12%] train loss: 1.3991412743052933e-05 \n",
      "epoch: 36 [64438/888800 7.25%] train loss: 1.2584553587657865e-05 \n",
      "epoch: 36 [65549/888800 7.38%] train loss: 1.3624819985125214e-05 \n",
      "epoch: 36 [66660/888800 7.50%] train loss: 1.4407391063286923e-05 \n",
      "epoch: 36 [67771/888800 7.62%] train loss: 1.4309889593278058e-05 \n",
      "epoch: 36 [68882/888800 7.75%] train loss: 1.4447242392634507e-05 \n",
      "epoch: 36 [69993/888800 7.88%] train loss: 1.456857626180863e-05 \n",
      "epoch: 36 [71104/888800 8.00%] train loss: 1.4758876204723492e-05 \n",
      "epoch: 36 [72215/888800 8.12%] train loss: 1.3754156498180237e-05 \n",
      "epoch: 36 [73326/888800 8.25%] train loss: 1.4515084330923855e-05 \n",
      "epoch: 36 [74437/888800 8.38%] train loss: 1.396655170537997e-05 \n",
      "epoch: 36 [75548/888800 8.50%] train loss: 1.4398183338926174e-05 \n",
      "epoch: 36 [76659/888800 8.62%] train loss: 1.297646031162003e-05 \n",
      "epoch: 36 [77770/888800 8.75%] train loss: 1.553251604491379e-05 \n",
      "epoch: 36 [78881/888800 8.88%] train loss: 1.328754206042504e-05 \n",
      "epoch: 36 [79992/888800 9.00%] train loss: 1.4800122698943596e-05 \n",
      "epoch: 36 [81103/888800 9.12%] train loss: 1.401380268362118e-05 \n",
      "epoch: 36 [82214/888800 9.25%] train loss: 1.37991783049074e-05 \n",
      "epoch: 36 [83325/888800 9.38%] train loss: 1.3790897355647758e-05 \n",
      "epoch: 36 [84436/888800 9.50%] train loss: 1.5015521967143286e-05 \n",
      "epoch: 36 [85547/888800 9.62%] train loss: 1.4719987120770384e-05 \n",
      "epoch: 36 [86658/888800 9.75%] train loss: 1.4597275367123075e-05 \n",
      "epoch: 36 [87769/888800 9.88%] train loss: 1.442299981135875e-05 \n",
      "epoch: 36 [88880/888800 10.00%] train loss: 1.3962676348455716e-05 \n",
      "epoch: 36 [89991/888800 10.12%] train loss: 1.3807495633955114e-05 \n",
      "epoch: 36 [91102/888800 10.25%] train loss: 1.3234479411039501e-05 \n",
      "epoch: 36 [92213/888800 10.38%] train loss: 1.4311817722045816e-05 \n",
      "epoch: 36 [93324/888800 10.50%] train loss: 1.5154769243963528e-05 \n",
      "epoch: 36 [94435/888800 10.62%] train loss: 1.425932532583829e-05 \n",
      "epoch: 36 [95546/888800 10.75%] train loss: 1.3765336916549131e-05 \n",
      "epoch: 36 [96657/888800 10.88%] train loss: 1.3902328646508977e-05 \n",
      "epoch: 36 [97768/888800 11.00%] train loss: 1.4503946658805944e-05 \n",
      "epoch: 36 [98879/888800 11.12%] train loss: 1.414825237588957e-05 \n",
      "epoch: 36 [99990/888800 11.25%] train loss: 1.4543940778821707e-05 \n",
      "epoch: 36 [101101/888800 11.38%] train loss: 1.4436483070312534e-05 \n",
      "epoch: 36 [102212/888800 11.50%] train loss: 1.3517149454855826e-05 \n",
      "epoch: 36 [103323/888800 11.62%] train loss: 1.354380674456479e-05 \n",
      "epoch: 36 [104434/888800 11.75%] train loss: 1.3721228242502548e-05 \n",
      "epoch: 36 [105545/888800 11.88%] train loss: 1.4202173588273581e-05 \n",
      "epoch: 36 [106656/888800 12.00%] train loss: 1.375666124658892e-05 \n",
      "epoch: 36 [107767/888800 12.12%] train loss: 1.3307463632372674e-05 \n",
      "epoch: 36 [108878/888800 12.25%] train loss: 1.4294155334937386e-05 \n",
      "epoch: 36 [109989/888800 12.38%] train loss: 1.3306070286489557e-05 \n",
      "epoch: 36 [111100/888800 12.50%] train loss: 1.3898743418394588e-05 \n",
      "epoch: 36 [112211/888800 12.62%] train loss: 1.2920875633426476e-05 \n",
      "epoch: 36 [113322/888800 12.75%] train loss: 1.3506421055353712e-05 \n",
      "epoch: 36 [114433/888800 12.88%] train loss: 1.4100844055064954e-05 \n",
      "epoch: 36 [115544/888800 13.00%] train loss: 1.5265590263879858e-05 \n",
      "epoch: 36 [116655/888800 13.12%] train loss: 1.3334260984265711e-05 \n",
      "epoch: 36 [117766/888800 13.25%] train loss: 1.409460401191609e-05 \n",
      "epoch: 36 [118877/888800 13.38%] train loss: 1.3103654055157676e-05 \n",
      "epoch: 36 [119988/888800 13.50%] train loss: 1.3483009752235375e-05 \n",
      "epoch: 36 [121099/888800 13.62%] train loss: 1.334367334493436e-05 \n",
      "epoch: 36 [122210/888800 13.75%] train loss: 1.4427384485315997e-05 \n",
      "epoch: 36 [123321/888800 13.88%] train loss: 1.3971157386549748e-05 \n",
      "epoch: 36 [124432/888800 14.00%] train loss: 1.4302367162599694e-05 \n",
      "epoch: 36 [125543/888800 14.12%] train loss: 1.5681347576901317e-05 \n",
      "epoch: 36 [126654/888800 14.25%] train loss: 1.4727615052834153e-05 \n",
      "epoch: 36 [127765/888800 14.38%] train loss: 1.550473643874284e-05 \n",
      "epoch: 36 [128876/888800 14.50%] train loss: 1.5224183698592242e-05 \n",
      "epoch: 36 [129987/888800 14.62%] train loss: 1.3785613191430457e-05 \n",
      "epoch: 36 [131098/888800 14.75%] train loss: 1.384583447361365e-05 \n",
      "epoch: 36 [132209/888800 14.88%] train loss: 1.4843981261947192e-05 \n",
      "epoch: 36 [133320/888800 15.00%] train loss: 1.3693734217667952e-05 \n",
      "epoch: 36 [134431/888800 15.12%] train loss: 1.5659714335924946e-05 \n",
      "epoch: 36 [135542/888800 15.25%] train loss: 1.3968863640911877e-05 \n",
      "epoch: 36 [136653/888800 15.38%] train loss: 1.3730836144532077e-05 \n",
      "epoch: 36 [137764/888800 15.50%] train loss: 1.4509448192256968e-05 \n",
      "epoch: 36 [138875/888800 15.62%] train loss: 1.4091345292399637e-05 \n",
      "epoch: 36 [139986/888800 15.75%] train loss: 1.3239750842330977e-05 \n",
      "epoch: 36 [141097/888800 15.88%] train loss: 1.4184254723659251e-05 \n",
      "epoch: 36 [142208/888800 16.00%] train loss: 1.437563059880631e-05 \n",
      "epoch: 36 [143319/888800 16.12%] train loss: 1.325182802247582e-05 \n",
      "epoch: 36 [144430/888800 16.25%] train loss: 1.4374813872564118e-05 \n",
      "epoch: 36 [145541/888800 16.38%] train loss: 1.5158080714172684e-05 \n",
      "epoch: 36 [146652/888800 16.50%] train loss: 1.4614102838095278e-05 \n",
      "epoch: 36 [147763/888800 16.62%] train loss: 1.506252920080442e-05 \n",
      "epoch: 36 [148874/888800 16.75%] train loss: 1.4294693755800836e-05 \n",
      "epoch: 36 [149985/888800 16.88%] train loss: 1.3805550224788021e-05 \n",
      "epoch: 36 [151096/888800 17.00%] train loss: 1.3600513739220332e-05 \n",
      "epoch: 36 [152207/888800 17.12%] train loss: 1.4651365745521616e-05 \n",
      "epoch: 36 [153318/888800 17.25%] train loss: 1.391368277836591e-05 \n",
      "epoch: 36 [154429/888800 17.38%] train loss: 1.4304418073152192e-05 \n",
      "epoch: 36 [155540/888800 17.50%] train loss: 1.3207714800955728e-05 \n",
      "epoch: 36 [156651/888800 17.62%] train loss: 1.3894916264689527e-05 \n",
      "epoch: 36 [157762/888800 17.75%] train loss: 1.3873494026483968e-05 \n",
      "epoch: 36 [158873/888800 17.88%] train loss: 1.4002120224176906e-05 \n",
      "epoch: 36 [159984/888800 18.00%] train loss: 1.4445210581470747e-05 \n",
      "epoch: 36 [161095/888800 18.12%] train loss: 1.356468055746518e-05 \n",
      "epoch: 36 [162206/888800 18.25%] train loss: 1.48373674164759e-05 \n",
      "epoch: 36 [163317/888800 18.38%] train loss: 1.355426138616167e-05 \n",
      "epoch: 36 [164428/888800 18.50%] train loss: 1.427175993740093e-05 \n",
      "epoch: 36 [165539/888800 18.62%] train loss: 1.4484067833109293e-05 \n",
      "epoch: 36 [166650/888800 18.75%] train loss: 1.4304199794423766e-05 \n",
      "epoch: 36 [167761/888800 18.88%] train loss: 1.4364713024406228e-05 \n",
      "epoch: 36 [168872/888800 19.00%] train loss: 1.3228598618297838e-05 \n",
      "epoch: 36 [169983/888800 19.12%] train loss: 1.4175927390169818e-05 \n",
      "epoch: 36 [171094/888800 19.25%] train loss: 1.3799812222714536e-05 \n",
      "epoch: 36 [172205/888800 19.38%] train loss: 1.568023071740754e-05 \n",
      "epoch: 36 [173316/888800 19.50%] train loss: 1.2783158126694616e-05 \n",
      "epoch: 36 [174427/888800 19.62%] train loss: 1.3595666132459883e-05 \n",
      "epoch: 36 [175538/888800 19.75%] train loss: 1.341365623375168e-05 \n",
      "epoch: 36 [176649/888800 19.88%] train loss: 1.3515814316633623e-05 \n",
      "epoch: 36 [177760/888800 20.00%] train loss: 1.4295530490926467e-05 \n",
      "epoch: 36 [178871/888800 20.12%] train loss: 1.4909311175870243e-05 \n",
      "epoch: 36 [179982/888800 20.25%] train loss: 1.3771316844213288e-05 \n",
      "epoch: 36 [181093/888800 20.38%] train loss: 1.473575957788853e-05 \n",
      "epoch: 36 [182204/888800 20.50%] train loss: 1.3531657714338508e-05 \n",
      "epoch: 36 [183315/888800 20.62%] train loss: 1.3381843928073067e-05 \n",
      "epoch: 36 [184426/888800 20.75%] train loss: 1.4512183952319901e-05 \n",
      "epoch: 36 [185537/888800 20.88%] train loss: 1.3543305612984113e-05 \n",
      "epoch: 36 [186648/888800 21.00%] train loss: 1.4437770005315542e-05 \n",
      "epoch: 36 [187759/888800 21.12%] train loss: 1.2489400432968978e-05 \n",
      "epoch: 36 [188870/888800 21.25%] train loss: 1.4305295735539403e-05 \n",
      "epoch: 36 [189981/888800 21.38%] train loss: 1.5495659681619145e-05 \n",
      "epoch: 36 [191092/888800 21.50%] train loss: 1.5031269867904484e-05 \n",
      "epoch: 36 [192203/888800 21.62%] train loss: 1.5009595699666534e-05 \n",
      "epoch: 36 [193314/888800 21.75%] train loss: 1.59339360834565e-05 \n",
      "epoch: 36 [194425/888800 21.88%] train loss: 1.6410789612564258e-05 \n",
      "epoch: 36 [195536/888800 22.00%] train loss: 1.4228902728063986e-05 \n",
      "epoch: 36 [196647/888800 22.12%] train loss: 1.546021485410165e-05 \n",
      "epoch: 36 [197758/888800 22.25%] train loss: 1.4094302969169803e-05 \n",
      "epoch: 36 [198869/888800 22.38%] train loss: 1.5916393749648705e-05 \n",
      "epoch: 36 [199980/888800 22.50%] train loss: 1.3826403119310271e-05 \n",
      "epoch: 36 [201091/888800 22.62%] train loss: 1.59904157044366e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [202202/888800 22.75%] train loss: 1.5429730410687625e-05 \n",
      "epoch: 36 [203313/888800 22.88%] train loss: 1.4901463146088645e-05 \n",
      "epoch: 36 [204424/888800 23.00%] train loss: 1.6044670701376162e-05 \n",
      "epoch: 36 [205535/888800 23.12%] train loss: 1.4545596059178934e-05 \n",
      "epoch: 36 [206646/888800 23.25%] train loss: 1.571076427353546e-05 \n",
      "epoch: 36 [207757/888800 23.38%] train loss: 1.3467491044139024e-05 \n",
      "epoch: 36 [208868/888800 23.50%] train loss: 1.5980787793523632e-05 \n",
      "epoch: 36 [209979/888800 23.62%] train loss: 1.378172601107508e-05 \n",
      "epoch: 36 [211090/888800 23.75%] train loss: 1.5624011211912148e-05 \n",
      "epoch: 36 [212201/888800 23.88%] train loss: 1.4870021004753653e-05 \n",
      "epoch: 36 [213312/888800 24.00%] train loss: 1.4963421563152224e-05 \n",
      "epoch: 36 [214423/888800 24.12%] train loss: 1.6191663235076703e-05 \n",
      "epoch: 36 [215534/888800 24.25%] train loss: 1.4794482922297902e-05 \n",
      "epoch: 36 [216645/888800 24.38%] train loss: 1.5915416952339e-05 \n",
      "epoch: 36 [217756/888800 24.50%] train loss: 1.3924695849709678e-05 \n",
      "epoch: 36 [218867/888800 24.62%] train loss: 1.4764149455004372e-05 \n",
      "epoch: 36 [219978/888800 24.75%] train loss: 1.3371643035497982e-05 \n",
      "epoch: 36 [221089/888800 24.88%] train loss: 1.5818412066437304e-05 \n",
      "epoch: 36 [222200/888800 25.00%] train loss: 1.3487858268490527e-05 \n",
      "epoch: 36 [223311/888800 25.12%] train loss: 1.5344163330155425e-05 \n",
      "epoch: 36 [224422/888800 25.25%] train loss: 1.492638693889603e-05 \n",
      "epoch: 36 [225533/888800 25.38%] train loss: 1.4142104191705585e-05 \n",
      "epoch: 36 [226644/888800 25.50%] train loss: 1.5035046999400947e-05 \n",
      "epoch: 36 [227755/888800 25.62%] train loss: 1.3214119462645613e-05 \n",
      "epoch: 36 [228866/888800 25.75%] train loss: 1.5562778571620584e-05 \n",
      "epoch: 36 [229977/888800 25.88%] train loss: 1.468368645873852e-05 \n",
      "epoch: 36 [231088/888800 26.00%] train loss: 1.6229168977588415e-05 \n",
      "epoch: 36 [232199/888800 26.12%] train loss: 1.5141382391448133e-05 \n",
      "epoch: 36 [233310/888800 26.25%] train loss: 1.4670480595668778e-05 \n",
      "epoch: 36 [234421/888800 26.38%] train loss: 1.4270065548771527e-05 \n",
      "epoch: 36 [235532/888800 26.50%] train loss: 1.3780488188785966e-05 \n",
      "epoch: 36 [236643/888800 26.62%] train loss: 1.3570219380198978e-05 \n",
      "epoch: 36 [237754/888800 26.75%] train loss: 1.37674242068897e-05 \n",
      "epoch: 36 [238865/888800 26.88%] train loss: 1.483544929214986e-05 \n",
      "epoch: 36 [239976/888800 27.00%] train loss: 1.4850952538836282e-05 \n",
      "epoch: 36 [241087/888800 27.12%] train loss: 1.4535340596921742e-05 \n",
      "epoch: 36 [242198/888800 27.25%] train loss: 1.449133560527116e-05 \n",
      "epoch: 36 [243309/888800 27.38%] train loss: 1.3424244571069721e-05 \n",
      "epoch: 36 [244420/888800 27.50%] train loss: 1.5514038750552572e-05 \n",
      "epoch: 36 [245531/888800 27.62%] train loss: 1.4145383829600178e-05 \n",
      "epoch: 36 [246642/888800 27.75%] train loss: 1.438423805666389e-05 \n",
      "epoch: 36 [247753/888800 27.88%] train loss: 1.4835261936241295e-05 \n",
      "epoch: 36 [248864/888800 28.00%] train loss: 1.4687332622997928e-05 \n",
      "epoch: 36 [249975/888800 28.12%] train loss: 1.3203650269133504e-05 \n",
      "epoch: 36 [251086/888800 28.25%] train loss: 1.4318869943963364e-05 \n",
      "epoch: 36 [252197/888800 28.38%] train loss: 1.3779914297629148e-05 \n",
      "epoch: 36 [253308/888800 28.50%] train loss: 1.473115298722405e-05 \n",
      "epoch: 36 [254419/888800 28.62%] train loss: 1.4686978829558939e-05 \n",
      "epoch: 36 [255530/888800 28.75%] train loss: 1.3647286323248409e-05 \n",
      "epoch: 36 [256641/888800 28.88%] train loss: 1.488573707320029e-05 \n",
      "epoch: 36 [257752/888800 29.00%] train loss: 1.4629838915425353e-05 \n",
      "epoch: 36 [258863/888800 29.12%] train loss: 1.2997858902963344e-05 \n",
      "epoch: 36 [259974/888800 29.25%] train loss: 1.3781118468614295e-05 \n",
      "epoch: 36 [261085/888800 29.38%] train loss: 1.3702509022550657e-05 \n",
      "epoch: 36 [262196/888800 29.50%] train loss: 1.4065970390220173e-05 \n",
      "epoch: 36 [263307/888800 29.62%] train loss: 1.4129684132058173e-05 \n",
      "epoch: 36 [264418/888800 29.75%] train loss: 1.488811267336132e-05 \n",
      "epoch: 36 [265529/888800 29.88%] train loss: 1.3973891327623278e-05 \n",
      "epoch: 36 [266640/888800 30.00%] train loss: 1.3582479368778877e-05 \n",
      "epoch: 36 [267751/888800 30.12%] train loss: 1.3228416719357483e-05 \n",
      "epoch: 36 [268862/888800 30.25%] train loss: 1.4486888176179491e-05 \n",
      "epoch: 36 [269973/888800 30.38%] train loss: 1.5052613889565691e-05 \n",
      "epoch: 36 [271084/888800 30.50%] train loss: 1.484229778725421e-05 \n",
      "epoch: 36 [272195/888800 30.62%] train loss: 1.4488629858533386e-05 \n",
      "epoch: 36 [273306/888800 30.75%] train loss: 1.3948768355476204e-05 \n",
      "epoch: 36 [274417/888800 30.88%] train loss: 1.3841300642525312e-05 \n",
      "epoch: 36 [275528/888800 31.00%] train loss: 1.4129684132058173e-05 \n",
      "epoch: 36 [276639/888800 31.12%] train loss: 1.4611611732107121e-05 \n",
      "epoch: 36 [277750/888800 31.25%] train loss: 1.4020027265360113e-05 \n",
      "epoch: 36 [278861/888800 31.38%] train loss: 1.4540220945491455e-05 \n",
      "epoch: 36 [279972/888800 31.50%] train loss: 1.3610196219815407e-05 \n",
      "epoch: 36 [281083/888800 31.62%] train loss: 1.4152890798868611e-05 \n",
      "epoch: 36 [282194/888800 31.75%] train loss: 1.3910104826209135e-05 \n",
      "epoch: 36 [283305/888800 31.88%] train loss: 1.3203941307438072e-05 \n",
      "epoch: 36 [284416/888800 32.00%] train loss: 1.5461535440408625e-05 \n",
      "epoch: 36 [285527/888800 32.12%] train loss: 1.4461898899753578e-05 \n",
      "epoch: 36 [286638/888800 32.25%] train loss: 1.4974654732213821e-05 \n",
      "epoch: 36 [287749/888800 32.38%] train loss: 1.5360421457444318e-05 \n",
      "epoch: 36 [288860/888800 32.50%] train loss: 1.595289541000966e-05 \n",
      "epoch: 36 [289971/888800 32.62%] train loss: 1.3828817827743478e-05 \n",
      "epoch: 36 [291082/888800 32.75%] train loss: 1.5454641470569186e-05 \n",
      "epoch: 36 [292193/888800 32.88%] train loss: 1.3804945410811342e-05 \n",
      "epoch: 36 [293304/888800 33.00%] train loss: 1.622241506993305e-05 \n",
      "epoch: 36 [294415/888800 33.12%] train loss: 1.4520662261929829e-05 \n",
      "epoch: 36 [295526/888800 33.25%] train loss: 1.5855697711231187e-05 \n",
      "epoch: 36 [296637/888800 33.38%] train loss: 1.5358658856712282e-05 \n",
      "epoch: 36 [297748/888800 33.50%] train loss: 1.5002349755377509e-05 \n",
      "epoch: 36 [298859/888800 33.62%] train loss: 1.4739505786565132e-05 \n",
      "epoch: 36 [299970/888800 33.75%] train loss: 1.5303667169064283e-05 \n",
      "epoch: 36 [301081/888800 33.88%] train loss: 1.4006999663251918e-05 \n",
      "epoch: 36 [302192/888800 34.00%] train loss: 1.471546056563966e-05 \n",
      "epoch: 36 [303303/888800 34.12%] train loss: 1.5010724382591434e-05 \n",
      "epoch: 36 [304414/888800 34.25%] train loss: 1.3609622328658588e-05 \n",
      "epoch: 36 [305525/888800 34.38%] train loss: 1.5696372429374605e-05 \n",
      "epoch: 36 [306636/888800 34.50%] train loss: 1.4190429283189587e-05 \n",
      "epoch: 36 [307747/888800 34.62%] train loss: 1.3991008017910644e-05 \n",
      "epoch: 36 [308858/888800 34.75%] train loss: 1.4361232388182543e-05 \n",
      "epoch: 36 [309969/888800 34.88%] train loss: 1.433131274097832e-05 \n",
      "epoch: 36 [311080/888800 35.00%] train loss: 1.3917271644459106e-05 \n",
      "epoch: 36 [312191/888800 35.12%] train loss: 1.388388864143053e-05 \n",
      "epoch: 36 [313302/888800 35.25%] train loss: 1.4478829143627081e-05 \n",
      "epoch: 36 [314413/888800 35.38%] train loss: 1.4144316082820296e-05 \n",
      "epoch: 36 [315524/888800 35.50%] train loss: 1.3851430594513658e-05 \n",
      "epoch: 36 [316635/888800 35.62%] train loss: 1.3560199477069546e-05 \n",
      "epoch: 36 [317746/888800 35.75%] train loss: 1.321523086517118e-05 \n",
      "epoch: 36 [318857/888800 35.88%] train loss: 1.5118564988370053e-05 \n",
      "epoch: 36 [319968/888800 36.00%] train loss: 1.4075625585974194e-05 \n",
      "epoch: 36 [321079/888800 36.12%] train loss: 1.4649936019850429e-05 \n",
      "epoch: 36 [322190/888800 36.25%] train loss: 1.414871985616628e-05 \n",
      "epoch: 36 [323301/888800 36.38%] train loss: 1.3731634680880234e-05 \n",
      "epoch: 36 [324412/888800 36.50%] train loss: 1.4187025954015553e-05 \n",
      "epoch: 36 [325523/888800 36.62%] train loss: 1.3647793821291998e-05 \n",
      "epoch: 36 [326634/888800 36.75%] train loss: 1.3908468645240646e-05 \n",
      "epoch: 36 [327745/888800 36.88%] train loss: 1.508090463175904e-05 \n",
      "epoch: 36 [328856/888800 37.00%] train loss: 1.4505029866995756e-05 \n",
      "epoch: 36 [329967/888800 37.12%] train loss: 1.5015624740044586e-05 \n",
      "epoch: 36 [331078/888800 37.25%] train loss: 1.3111669431964401e-05 \n",
      "epoch: 36 [332189/888800 37.38%] train loss: 1.5062908460095059e-05 \n",
      "epoch: 36 [333300/888800 37.50%] train loss: 1.4035334970685653e-05 \n",
      "epoch: 36 [334411/888800 37.62%] train loss: 1.4581483810616191e-05 \n",
      "epoch: 36 [335522/888800 37.75%] train loss: 1.435177637176821e-05 \n",
      "epoch: 36 [336633/888800 37.88%] train loss: 1.560929922561627e-05 \n",
      "epoch: 36 [337744/888800 38.00%] train loss: 1.3040576050116215e-05 \n",
      "epoch: 36 [338855/888800 38.12%] train loss: 1.5214226550597232e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [339966/888800 38.25%] train loss: 1.4169029782351572e-05 \n",
      "epoch: 36 [341077/888800 38.38%] train loss: 1.5019378224678803e-05 \n",
      "epoch: 36 [342188/888800 38.50%] train loss: 1.4985814232204575e-05 \n",
      "epoch: 36 [343299/888800 38.62%] train loss: 1.3202222362451721e-05 \n",
      "epoch: 36 [344410/888800 38.75%] train loss: 1.3148426660336554e-05 \n",
      "epoch: 36 [345521/888800 38.88%] train loss: 1.3821586435369682e-05 \n",
      "epoch: 36 [346632/888800 39.00%] train loss: 1.440437335986644e-05 \n",
      "epoch: 36 [347743/888800 39.12%] train loss: 1.3732154911849648e-05 \n",
      "epoch: 36 [348854/888800 39.25%] train loss: 1.3348426364245825e-05 \n",
      "epoch: 36 [349965/888800 39.38%] train loss: 1.3632885384140536e-05 \n",
      "epoch: 36 [351076/888800 39.50%] train loss: 1.3671557098859921e-05 \n",
      "epoch: 36 [352187/888800 39.62%] train loss: 1.2678176062763669e-05 \n",
      "epoch: 36 [353298/888800 39.75%] train loss: 1.3102630873618182e-05 \n",
      "epoch: 36 [354409/888800 39.88%] train loss: 1.4749920410395134e-05 \n",
      "epoch: 36 [355520/888800 40.00%] train loss: 1.4061482033866923e-05 \n",
      "epoch: 36 [356631/888800 40.12%] train loss: 1.473947850172408e-05 \n",
      "epoch: 36 [357742/888800 40.25%] train loss: 1.4541411474056076e-05 \n",
      "epoch: 36 [358853/888800 40.38%] train loss: 1.6457555830129422e-05 \n",
      "epoch: 36 [359964/888800 40.50%] train loss: 1.4796683899476193e-05 \n",
      "epoch: 36 [361075/888800 40.62%] train loss: 1.578621959197335e-05 \n",
      "epoch: 36 [362186/888800 40.75%] train loss: 1.5169598555075936e-05 \n",
      "epoch: 36 [363297/888800 40.88%] train loss: 1.471156701882137e-05 \n",
      "epoch: 36 [364408/888800 41.00%] train loss: 1.4187616216077004e-05 \n",
      "epoch: 36 [365519/888800 41.12%] train loss: 1.4252612345444504e-05 \n",
      "epoch: 36 [366630/888800 41.25%] train loss: 1.556081770104356e-05 \n",
      "epoch: 36 [367741/888800 41.38%] train loss: 1.5071975212777033e-05 \n",
      "epoch: 36 [368852/888800 41.50%] train loss: 1.558504482090939e-05 \n",
      "epoch: 36 [369963/888800 41.62%] train loss: 1.3799327462038491e-05 \n",
      "epoch: 36 [371074/888800 41.75%] train loss: 1.5885445463936776e-05 \n",
      "epoch: 36 [372185/888800 41.88%] train loss: 1.4981093045207672e-05 \n",
      "epoch: 36 [373296/888800 42.00%] train loss: 1.4193747119861655e-05 \n",
      "epoch: 36 [374407/888800 42.12%] train loss: 1.4955777260183822e-05 \n",
      "epoch: 36 [375518/888800 42.25%] train loss: 1.4410804396902677e-05 \n",
      "epoch: 36 [376629/888800 42.38%] train loss: 1.5873685697442852e-05 \n",
      "epoch: 36 [377740/888800 42.50%] train loss: 1.3394876077654772e-05 \n",
      "epoch: 36 [378851/888800 42.62%] train loss: 1.708803029032424e-05 \n",
      "epoch: 36 [379962/888800 42.75%] train loss: 1.4902251677995082e-05 \n",
      "epoch: 36 [381073/888800 42.88%] train loss: 1.4810998436587397e-05 \n",
      "epoch: 36 [382184/888800 43.00%] train loss: 1.4863660908304155e-05 \n",
      "epoch: 36 [383295/888800 43.12%] train loss: 1.5447119949385524e-05 \n",
      "epoch: 36 [384406/888800 43.25%] train loss: 1.6097046682261862e-05 \n",
      "epoch: 36 [385517/888800 43.38%] train loss: 1.3696496353077237e-05 \n",
      "epoch: 36 [386628/888800 43.50%] train loss: 1.4754778931092005e-05 \n",
      "epoch: 36 [387739/888800 43.62%] train loss: 1.5294492186512798e-05 \n",
      "epoch: 36 [388850/888800 43.75%] train loss: 1.416221584804589e-05 \n",
      "epoch: 36 [389961/888800 43.88%] train loss: 1.3898230463382788e-05 \n",
      "epoch: 36 [391072/888800 44.00%] train loss: 1.3179760571802035e-05 \n",
      "epoch: 36 [392183/888800 44.12%] train loss: 1.3926457540947013e-05 \n",
      "epoch: 36 [393294/888800 44.25%] train loss: 1.4973708857723977e-05 \n",
      "epoch: 36 [394405/888800 44.38%] train loss: 1.4089046999288257e-05 \n",
      "epoch: 36 [395516/888800 44.50%] train loss: 1.5763209376018494e-05 \n",
      "epoch: 36 [396627/888800 44.62%] train loss: 1.4898958397679962e-05 \n",
      "epoch: 36 [397738/888800 44.75%] train loss: 1.366295327898115e-05 \n",
      "epoch: 36 [398849/888800 44.88%] train loss: 1.3387336366577074e-05 \n",
      "epoch: 36 [399960/888800 45.00%] train loss: 1.3888535249861889e-05 \n",
      "epoch: 36 [401071/888800 45.12%] train loss: 1.4851819287287071e-05 \n",
      "epoch: 36 [402182/888800 45.25%] train loss: 1.370330573990941e-05 \n",
      "epoch: 36 [403293/888800 45.38%] train loss: 1.4703473425470293e-05 \n",
      "epoch: 36 [404404/888800 45.50%] train loss: 1.5313353287638165e-05 \n",
      "epoch: 36 [405515/888800 45.62%] train loss: 1.4491782167169731e-05 \n",
      "epoch: 36 [406626/888800 45.75%] train loss: 1.4396624465007335e-05 \n",
      "epoch: 36 [407737/888800 45.88%] train loss: 1.4058545275474899e-05 \n",
      "epoch: 36 [408848/888800 46.00%] train loss: 1.3985863006382715e-05 \n",
      "epoch: 36 [409959/888800 46.12%] train loss: 1.427663391950773e-05 \n",
      "epoch: 36 [411070/888800 46.25%] train loss: 1.4546293641615193e-05 \n",
      "epoch: 36 [412181/888800 46.38%] train loss: 1.4074653336137999e-05 \n",
      "epoch: 36 [413292/888800 46.50%] train loss: 1.4894009837007616e-05 \n",
      "epoch: 36 [414403/888800 46.62%] train loss: 1.3500001841748599e-05 \n",
      "epoch: 36 [415514/888800 46.75%] train loss: 1.3828532246407121e-05 \n",
      "epoch: 36 [416625/888800 46.88%] train loss: 1.5307390640373342e-05 \n",
      "epoch: 36 [417736/888800 47.00%] train loss: 1.5132082808122505e-05 \n",
      "epoch: 36 [418847/888800 47.12%] train loss: 1.3560823390434962e-05 \n",
      "epoch: 36 [419958/888800 47.25%] train loss: 1.4559363989974372e-05 \n",
      "epoch: 36 [421069/888800 47.38%] train loss: 1.4108315554040018e-05 \n",
      "epoch: 36 [422180/888800 47.50%] train loss: 1.4596871551475488e-05 \n",
      "epoch: 36 [423291/888800 47.62%] train loss: 1.2811359738407191e-05 \n",
      "epoch: 36 [424402/888800 47.75%] train loss: 1.5306120985769667e-05 \n",
      "epoch: 36 [425513/888800 47.88%] train loss: 1.4029035810381174e-05 \n",
      "epoch: 36 [426624/888800 48.00%] train loss: 1.4145485693006776e-05 \n",
      "epoch: 36 [427735/888800 48.12%] train loss: 1.461318061046768e-05 \n",
      "epoch: 36 [428846/888800 48.25%] train loss: 1.5532717952737585e-05 \n",
      "epoch: 36 [429957/888800 48.38%] train loss: 1.3750199286732823e-05 \n",
      "epoch: 36 [431068/888800 48.50%] train loss: 1.4304179785540327e-05 \n",
      "epoch: 36 [432179/888800 48.62%] train loss: 1.5520330634899437e-05 \n",
      "epoch: 36 [433290/888800 48.75%] train loss: 1.3240673069958575e-05 \n",
      "epoch: 36 [434401/888800 48.88%] train loss: 1.525610059616156e-05 \n",
      "epoch: 36 [435512/888800 49.00%] train loss: 1.370449535897933e-05 \n",
      "epoch: 36 [436623/888800 49.12%] train loss: 1.73782082129037e-05 \n",
      "epoch: 36 [437734/888800 49.25%] train loss: 1.4284754797699861e-05 \n",
      "epoch: 36 [438845/888800 49.38%] train loss: 1.4196126358001493e-05 \n",
      "epoch: 36 [439956/888800 49.50%] train loss: 1.4339204426505603e-05 \n",
      "epoch: 36 [441067/888800 49.62%] train loss: 1.5980744137777947e-05 \n",
      "epoch: 36 [442178/888800 49.75%] train loss: 1.4464457308349665e-05 \n",
      "epoch: 36 [443289/888800 49.88%] train loss: 1.415001770510571e-05 \n",
      "epoch: 36 [444400/888800 50.00%] train loss: 1.5756357242935337e-05 \n",
      "epoch: 36 [445511/888800 50.12%] train loss: 1.4895904314471409e-05 \n",
      "epoch: 36 [446622/888800 50.25%] train loss: 1.4669853044324555e-05 \n",
      "epoch: 36 [447733/888800 50.38%] train loss: 1.4224778169591445e-05 \n",
      "epoch: 36 [448844/888800 50.50%] train loss: 1.4122961147222668e-05 \n",
      "epoch: 36 [449955/888800 50.62%] train loss: 1.4238083167583682e-05 \n",
      "epoch: 36 [451066/888800 50.75%] train loss: 1.4598130292142741e-05 \n",
      "epoch: 36 [452177/888800 50.88%] train loss: 1.4494678907794878e-05 \n",
      "epoch: 36 [453288/888800 51.00%] train loss: 1.49158549902495e-05 \n",
      "epoch: 36 [454399/888800 51.12%] train loss: 1.4111118616710883e-05 \n",
      "epoch: 36 [455510/888800 51.25%] train loss: 1.4229432053980418e-05 \n",
      "epoch: 36 [456621/888800 51.38%] train loss: 1.3220939763414208e-05 \n",
      "epoch: 36 [457732/888800 51.50%] train loss: 1.5246590919559821e-05 \n",
      "epoch: 36 [458843/888800 51.62%] train loss: 1.4963287867431063e-05 \n",
      "epoch: 36 [459954/888800 51.75%] train loss: 1.3489293451129925e-05 \n",
      "epoch: 36 [461065/888800 51.88%] train loss: 1.553618858451955e-05 \n",
      "epoch: 36 [462176/888800 52.00%] train loss: 1.3778344509773888e-05 \n",
      "epoch: 36 [463287/888800 52.12%] train loss: 1.4102113709668629e-05 \n",
      "epoch: 36 [464398/888800 52.25%] train loss: 1.4979459592723288e-05 \n",
      "epoch: 36 [465509/888800 52.38%] train loss: 1.4706118236063048e-05 \n",
      "epoch: 36 [466620/888800 52.50%] train loss: 1.420116223016521e-05 \n",
      "epoch: 36 [467731/888800 52.62%] train loss: 1.2091176358808298e-05 \n",
      "epoch: 36 [468842/888800 52.75%] train loss: 1.4541833479597699e-05 \n",
      "epoch: 36 [469953/888800 52.88%] train loss: 1.4554015251633245e-05 \n",
      "epoch: 36 [471064/888800 53.00%] train loss: 1.5177872228377964e-05 \n",
      "epoch: 36 [472175/888800 53.12%] train loss: 1.4241295502870344e-05 \n",
      "epoch: 36 [473286/888800 53.25%] train loss: 1.3373692127061076e-05 \n",
      "epoch: 36 [474397/888800 53.38%] train loss: 1.5328248991863802e-05 \n",
      "epoch: 36 [475508/888800 53.50%] train loss: 1.4136176105239429e-05 \n",
      "epoch: 36 [476619/888800 53.62%] train loss: 1.3844032764609437e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [477730/888800 53.75%] train loss: 1.4396477126865648e-05 \n",
      "epoch: 36 [478841/888800 53.88%] train loss: 1.3800125088891946e-05 \n",
      "epoch: 36 [479952/888800 54.00%] train loss: 1.3946848412160762e-05 \n",
      "epoch: 36 [481063/888800 54.12%] train loss: 1.384830738970777e-05 \n",
      "epoch: 36 [482174/888800 54.25%] train loss: 1.3382962606556248e-05 \n",
      "epoch: 36 [483285/888800 54.38%] train loss: 1.4070297766011208e-05 \n",
      "epoch: 36 [484396/888800 54.50%] train loss: 1.445285579393385e-05 \n",
      "epoch: 36 [485507/888800 54.62%] train loss: 1.663518742134329e-05 \n",
      "epoch: 36 [486618/888800 54.75%] train loss: 1.418583906342974e-05 \n",
      "epoch: 36 [487729/888800 54.88%] train loss: 1.4114397345110774e-05 \n",
      "epoch: 36 [488840/888800 55.00%] train loss: 1.3406365724222269e-05 \n",
      "epoch: 36 [489951/888800 55.12%] train loss: 1.5048492059577256e-05 \n",
      "epoch: 36 [491062/888800 55.25%] train loss: 1.4477574950433336e-05 \n",
      "epoch: 36 [492173/888800 55.38%] train loss: 1.520753085060278e-05 \n",
      "epoch: 36 [493284/888800 55.50%] train loss: 1.6887401216081344e-05 \n",
      "epoch: 36 [494395/888800 55.62%] train loss: 1.5443642041645944e-05 \n",
      "epoch: 36 [495506/888800 55.75%] train loss: 1.3834523997502401e-05 \n",
      "epoch: 36 [496617/888800 55.88%] train loss: 1.4838441529718693e-05 \n",
      "epoch: 36 [497728/888800 56.00%] train loss: 1.40330503199948e-05 \n",
      "epoch: 36 [498839/888800 56.12%] train loss: 1.4142479813017417e-05 \n",
      "epoch: 36 [499950/888800 56.25%] train loss: 1.5069168512127362e-05 \n",
      "epoch: 36 [501061/888800 56.38%] train loss: 1.510417860117741e-05 \n",
      "epoch: 36 [502172/888800 56.50%] train loss: 1.3793553080176935e-05 \n",
      "epoch: 36 [503283/888800 56.62%] train loss: 1.4065482901060022e-05 \n",
      "epoch: 36 [504394/888800 56.75%] train loss: 1.3452890016196761e-05 \n",
      "epoch: 36 [505505/888800 56.88%] train loss: 1.5275762052624486e-05 \n",
      "epoch: 36 [506616/888800 57.00%] train loss: 1.4875884517095983e-05 \n",
      "epoch: 36 [507727/888800 57.12%] train loss: 1.4808636478846893e-05 \n",
      "epoch: 36 [508838/888800 57.25%] train loss: 1.4018838555784896e-05 \n",
      "epoch: 36 [509949/888800 57.38%] train loss: 1.61026073328685e-05 \n",
      "epoch: 36 [511060/888800 57.50%] train loss: 1.422363129677251e-05 \n",
      "epoch: 36 [512171/888800 57.62%] train loss: 1.4945776456443127e-05 \n",
      "epoch: 36 [513282/888800 57.75%] train loss: 1.6371606761822477e-05 \n",
      "epoch: 36 [514393/888800 57.88%] train loss: 1.5341249309130944e-05 \n",
      "epoch: 36 [515504/888800 58.00%] train loss: 1.4537098650180269e-05 \n",
      "epoch: 36 [516615/888800 58.12%] train loss: 1.473755037295632e-05 \n",
      "epoch: 36 [517726/888800 58.25%] train loss: 1.4842688869975973e-05 \n",
      "epoch: 36 [518837/888800 58.38%] train loss: 1.4659631233371329e-05 \n",
      "epoch: 36 [519948/888800 58.50%] train loss: 1.540034827485215e-05 \n",
      "epoch: 36 [521059/888800 58.62%] train loss: 1.3229275282355957e-05 \n",
      "epoch: 36 [522170/888800 58.75%] train loss: 1.3971652151667513e-05 \n",
      "epoch: 36 [523281/888800 58.88%] train loss: 1.3161537935957313e-05 \n",
      "epoch: 36 [524392/888800 59.00%] train loss: 1.504705778643256e-05 \n",
      "epoch: 36 [525503/888800 59.12%] train loss: 1.4193778952176217e-05 \n",
      "epoch: 36 [526614/888800 59.25%] train loss: 1.5159758731897455e-05 \n",
      "epoch: 36 [527725/888800 59.38%] train loss: 1.5000523490016349e-05 \n",
      "epoch: 36 [528836/888800 59.50%] train loss: 1.449816318199737e-05 \n",
      "epoch: 36 [529947/888800 59.62%] train loss: 1.4876465684210416e-05 \n",
      "epoch: 36 [531058/888800 59.75%] train loss: 1.4950988770578988e-05 \n",
      "epoch: 36 [532169/888800 59.88%] train loss: 1.5551442629657686e-05 \n",
      "epoch: 36 [533280/888800 60.00%] train loss: 1.3940069038653746e-05 \n",
      "epoch: 36 [534391/888800 60.12%] train loss: 1.5215967323456425e-05 \n",
      "epoch: 36 [535502/888800 60.25%] train loss: 1.3405522622633725e-05 \n",
      "epoch: 36 [536613/888800 60.38%] train loss: 1.4499952158075757e-05 \n",
      "epoch: 36 [537724/888800 60.50%] train loss: 1.36204525915673e-05 \n",
      "epoch: 36 [538835/888800 60.62%] train loss: 1.4385784197656903e-05 \n",
      "epoch: 36 [539946/888800 60.75%] train loss: 1.4040885616850574e-05 \n",
      "epoch: 36 [541057/888800 60.88%] train loss: 1.4214896509656683e-05 \n",
      "epoch: 36 [542168/888800 61.00%] train loss: 1.5212691323540639e-05 \n",
      "epoch: 36 [543279/888800 61.12%] train loss: 1.3655989278049674e-05 \n",
      "epoch: 36 [544390/888800 61.25%] train loss: 1.4004250260768458e-05 \n",
      "epoch: 36 [545501/888800 61.38%] train loss: 1.3459813089866657e-05 \n",
      "epoch: 36 [546612/888800 61.50%] train loss: 1.5096645256562624e-05 \n",
      "epoch: 36 [547723/888800 61.62%] train loss: 1.4300883776741102e-05 \n",
      "epoch: 36 [548834/888800 61.75%] train loss: 1.4534332876792178e-05 \n",
      "epoch: 36 [549945/888800 61.88%] train loss: 1.4180631296767388e-05 \n",
      "epoch: 36 [551056/888800 62.00%] train loss: 1.3810255040880293e-05 \n",
      "epoch: 36 [552167/888800 62.12%] train loss: 1.3178356311982498e-05 \n",
      "epoch: 36 [553278/888800 62.25%] train loss: 1.386160420224769e-05 \n",
      "epoch: 36 [554389/888800 62.38%] train loss: 1.3612258044304326e-05 \n",
      "epoch: 36 [555500/888800 62.50%] train loss: 1.3631858564622235e-05 \n",
      "epoch: 36 [556611/888800 62.62%] train loss: 1.3179987035982776e-05 \n",
      "epoch: 36 [557722/888800 62.75%] train loss: 1.3610856512968894e-05 \n",
      "epoch: 36 [558833/888800 62.88%] train loss: 1.4488100532616954e-05 \n",
      "epoch: 36 [559944/888800 63.00%] train loss: 1.3547209164244123e-05 \n",
      "epoch: 36 [561055/888800 63.12%] train loss: 1.5550689568044618e-05 \n",
      "epoch: 36 [562166/888800 63.25%] train loss: 1.3549751201935578e-05 \n",
      "epoch: 36 [563277/888800 63.38%] train loss: 1.4877626199449878e-05 \n",
      "epoch: 36 [564388/888800 63.50%] train loss: 1.4129037481325213e-05 \n",
      "epoch: 36 [565499/888800 63.62%] train loss: 1.444771532987943e-05 \n",
      "epoch: 36 [566610/888800 63.75%] train loss: 1.3726941688219085e-05 \n",
      "epoch: 36 [567721/888800 63.88%] train loss: 1.4725503206136636e-05 \n",
      "epoch: 36 [568832/888800 64.00%] train loss: 1.438922936358722e-05 \n",
      "epoch: 36 [569943/888800 64.12%] train loss: 1.3720495189772919e-05 \n",
      "epoch: 36 [571054/888800 64.25%] train loss: 1.4530852240568493e-05 \n",
      "epoch: 36 [572165/888800 64.38%] train loss: 1.4068637938180473e-05 \n",
      "epoch: 36 [573276/888800 64.50%] train loss: 1.3496963219949976e-05 \n",
      "epoch: 36 [574387/888800 64.62%] train loss: 1.4180607649905141e-05 \n",
      "epoch: 36 [575498/888800 64.75%] train loss: 1.4786931387789082e-05 \n",
      "epoch: 36 [576609/888800 64.88%] train loss: 1.4420820662053302e-05 \n",
      "epoch: 36 [577720/888800 65.00%] train loss: 1.5334144336520694e-05 \n",
      "epoch: 36 [578831/888800 65.12%] train loss: 1.4014220141689293e-05 \n",
      "epoch: 36 [579942/888800 65.25%] train loss: 1.5247855117195286e-05 \n",
      "epoch: 36 [581053/888800 65.38%] train loss: 1.4227784049580805e-05 \n",
      "epoch: 36 [582164/888800 65.50%] train loss: 1.5791743862791918e-05 \n",
      "epoch: 36 [583275/888800 65.62%] train loss: 1.4174102943798061e-05 \n",
      "epoch: 36 [584386/888800 65.75%] train loss: 1.3058877811999992e-05 \n",
      "epoch: 36 [585497/888800 65.88%] train loss: 1.508048353571212e-05 \n",
      "epoch: 36 [586608/888800 66.00%] train loss: 1.5770991012686864e-05 \n",
      "epoch: 36 [587719/888800 66.12%] train loss: 1.3934194612374995e-05 \n",
      "epoch: 36 [588830/888800 66.25%] train loss: 1.4907971490174532e-05 \n",
      "epoch: 36 [589941/888800 66.38%] train loss: 1.3828447663399857e-05 \n",
      "epoch: 36 [591052/888800 66.50%] train loss: 1.4757622011529747e-05 \n",
      "epoch: 36 [592163/888800 66.62%] train loss: 1.5555622667307034e-05 \n",
      "epoch: 36 [593274/888800 66.75%] train loss: 1.4644562725152355e-05 \n",
      "epoch: 36 [594385/888800 66.88%] train loss: 1.431138844054658e-05 \n",
      "epoch: 36 [595496/888800 67.00%] train loss: 1.4283253221947234e-05 \n",
      "epoch: 36 [596607/888800 67.12%] train loss: 1.2365085240162443e-05 \n",
      "epoch: 36 [597718/888800 67.25%] train loss: 1.3363523976295255e-05 \n",
      "epoch: 36 [598829/888800 67.38%] train loss: 1.4492257832898758e-05 \n",
      "epoch: 36 [599940/888800 67.50%] train loss: 1.3875443983124569e-05 \n",
      "epoch: 36 [601051/888800 67.62%] train loss: 1.4722520063514821e-05 \n",
      "epoch: 36 [602162/888800 67.75%] train loss: 1.5432751752086915e-05 \n",
      "epoch: 36 [603273/888800 67.88%] train loss: 1.4543607903760858e-05 \n",
      "epoch: 36 [604384/888800 68.00%] train loss: 1.3538746316044126e-05 \n",
      "epoch: 36 [605495/888800 68.12%] train loss: 1.4242130419006571e-05 \n",
      "epoch: 36 [606606/888800 68.25%] train loss: 1.52147231347044e-05 \n",
      "epoch: 36 [607717/888800 68.38%] train loss: 1.2722711289825384e-05 \n",
      "epoch: 36 [608828/888800 68.50%] train loss: 1.3781324923911598e-05 \n",
      "epoch: 36 [609939/888800 68.62%] train loss: 1.4801353245275095e-05 \n",
      "epoch: 36 [611050/888800 68.75%] train loss: 1.4241017197491601e-05 \n",
      "epoch: 36 [612161/888800 68.88%] train loss: 1.480440823797835e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [613272/888800 69.00%] train loss: 1.5039178833831102e-05 \n",
      "epoch: 36 [614383/888800 69.12%] train loss: 1.5023222658783197e-05 \n",
      "epoch: 36 [615494/888800 69.25%] train loss: 1.3131483683537226e-05 \n",
      "epoch: 36 [616605/888800 69.38%] train loss: 1.4028345503902528e-05 \n",
      "epoch: 36 [617716/888800 69.50%] train loss: 1.4211258530849591e-05 \n",
      "epoch: 36 [618827/888800 69.62%] train loss: 1.4257680959417485e-05 \n",
      "epoch: 36 [619938/888800 69.75%] train loss: 1.4788668522669468e-05 \n",
      "epoch: 36 [621049/888800 69.88%] train loss: 1.4230042324925307e-05 \n",
      "epoch: 36 [622160/888800 70.00%] train loss: 1.3594823940366041e-05 \n",
      "epoch: 36 [623271/888800 70.12%] train loss: 1.3491275240085088e-05 \n",
      "epoch: 36 [624382/888800 70.25%] train loss: 1.5163546777330339e-05 \n",
      "epoch: 36 [625493/888800 70.38%] train loss: 1.4911140169715509e-05 \n",
      "epoch: 36 [626604/888800 70.50%] train loss: 1.3248073628346901e-05 \n",
      "epoch: 36 [627715/888800 70.62%] train loss: 1.304734541918151e-05 \n",
      "epoch: 36 [628826/888800 70.75%] train loss: 1.4593796549888793e-05 \n",
      "epoch: 36 [629937/888800 70.88%] train loss: 1.4920971807441674e-05 \n",
      "epoch: 36 [631048/888800 71.00%] train loss: 1.4567843209079001e-05 \n",
      "epoch: 36 [632159/888800 71.12%] train loss: 1.4989098417572677e-05 \n",
      "epoch: 36 [633270/888800 71.25%] train loss: 1.4300065231509507e-05 \n",
      "epoch: 36 [634381/888800 71.38%] train loss: 1.4117911632638425e-05 \n",
      "epoch: 36 [635492/888800 71.50%] train loss: 1.2848989172198344e-05 \n",
      "epoch: 36 [636603/888800 71.62%] train loss: 1.4749952242709696e-05 \n",
      "epoch: 36 [637714/888800 71.75%] train loss: 1.407808576914249e-05 \n",
      "epoch: 36 [638825/888800 71.88%] train loss: 1.366598007734865e-05 \n",
      "epoch: 36 [639936/888800 72.00%] train loss: 1.5051425179990474e-05 \n",
      "epoch: 36 [641047/888800 72.12%] train loss: 1.4507259948004503e-05 \n",
      "epoch: 36 [642158/888800 72.25%] train loss: 1.3632858099299483e-05 \n",
      "epoch: 36 [643269/888800 72.38%] train loss: 1.3147611753083766e-05 \n",
      "epoch: 36 [644380/888800 72.50%] train loss: 1.3579431652033236e-05 \n",
      "epoch: 36 [645491/888800 72.62%] train loss: 1.2920765584567562e-05 \n",
      "epoch: 36 [646602/888800 72.75%] train loss: 1.437478385923896e-05 \n",
      "epoch: 36 [647713/888800 72.88%] train loss: 1.4589113561669365e-05 \n",
      "epoch: 36 [648824/888800 73.00%] train loss: 1.46437141665956e-05 \n",
      "epoch: 36 [649935/888800 73.12%] train loss: 1.408032221661415e-05 \n",
      "epoch: 36 [651046/888800 73.25%] train loss: 1.4121925232757349e-05 \n",
      "epoch: 36 [652157/888800 73.38%] train loss: 1.4080356777412817e-05 \n",
      "epoch: 36 [653268/888800 73.50%] train loss: 1.4296982044470496e-05 \n",
      "epoch: 36 [654379/888800 73.62%] train loss: 1.3664606740348972e-05 \n",
      "epoch: 36 [655490/888800 73.75%] train loss: 1.4213091162673663e-05 \n",
      "epoch: 36 [656601/888800 73.88%] train loss: 1.3492782272805925e-05 \n",
      "epoch: 36 [657712/888800 74.00%] train loss: 1.5980167518137023e-05 \n",
      "epoch: 36 [658823/888800 74.12%] train loss: 1.5661627912777476e-05 \n",
      "epoch: 36 [659934/888800 74.25%] train loss: 1.6791524103609845e-05 \n",
      "epoch: 36 [661045/888800 74.38%] train loss: 1.4571421161235776e-05 \n",
      "epoch: 36 [662156/888800 74.50%] train loss: 1.5408499166369438e-05 \n",
      "epoch: 36 [663267/888800 74.62%] train loss: 1.4273000488174148e-05 \n",
      "epoch: 36 [664378/888800 74.75%] train loss: 1.6048574252636172e-05 \n",
      "epoch: 36 [665489/888800 74.88%] train loss: 1.629571124794893e-05 \n",
      "epoch: 36 [666600/888800 75.00%] train loss: 1.3770918485533912e-05 \n",
      "epoch: 36 [667711/888800 75.12%] train loss: 1.4574405213352293e-05 \n",
      "epoch: 36 [668822/888800 75.25%] train loss: 1.4022552022652235e-05 \n",
      "epoch: 36 [669933/888800 75.38%] train loss: 1.6987880371743813e-05 \n",
      "epoch: 36 [671044/888800 75.50%] train loss: 1.2891466212749947e-05 \n",
      "epoch: 36 [672155/888800 75.62%] train loss: 1.4235295566322748e-05 \n",
      "epoch: 36 [673266/888800 75.75%] train loss: 1.4295703294919804e-05 \n",
      "epoch: 36 [674377/888800 75.88%] train loss: 1.4418153114093002e-05 \n",
      "epoch: 36 [675488/888800 76.00%] train loss: 1.3401083378994372e-05 \n",
      "epoch: 36 [676599/888800 76.12%] train loss: 1.5456684195669368e-05 \n",
      "epoch: 36 [677710/888800 76.25%] train loss: 1.4469792404270265e-05 \n",
      "epoch: 36 [678821/888800 76.38%] train loss: 1.5463372619706206e-05 \n",
      "epoch: 36 [679932/888800 76.50%] train loss: 1.4553016626450699e-05 \n",
      "epoch: 36 [681043/888800 76.62%] train loss: 1.4228479813027661e-05 \n",
      "epoch: 36 [682154/888800 76.75%] train loss: 1.4396107872016728e-05 \n",
      "epoch: 36 [683265/888800 76.88%] train loss: 1.590824467712082e-05 \n",
      "epoch: 36 [684376/888800 77.00%] train loss: 1.4033152183401398e-05 \n",
      "epoch: 36 [685487/888800 77.12%] train loss: 1.5241836081258953e-05 \n",
      "epoch: 36 [686598/888800 77.25%] train loss: 1.5497214917559177e-05 \n",
      "epoch: 36 [687709/888800 77.38%] train loss: 1.4210588233254384e-05 \n",
      "epoch: 36 [688820/888800 77.50%] train loss: 1.463523403799627e-05 \n",
      "epoch: 36 [689931/888800 77.62%] train loss: 1.3233428944658954e-05 \n",
      "epoch: 36 [691042/888800 77.75%] train loss: 1.4254886082198936e-05 \n",
      "epoch: 36 [692153/888800 77.88%] train loss: 1.4247111721488182e-05 \n",
      "epoch: 36 [693264/888800 78.00%] train loss: 1.603614873602055e-05 \n",
      "epoch: 36 [694375/888800 78.12%] train loss: 1.3934374692325946e-05 \n",
      "epoch: 36 [695486/888800 78.25%] train loss: 1.5769066521897912e-05 \n",
      "epoch: 36 [696597/888800 78.38%] train loss: 1.3462647984852083e-05 \n",
      "epoch: 36 [697708/888800 78.50%] train loss: 1.4242834367905743e-05 \n",
      "epoch: 36 [698819/888800 78.62%] train loss: 1.3995058907312341e-05 \n",
      "epoch: 36 [699930/888800 78.75%] train loss: 1.4769029803574085e-05 \n",
      "epoch: 36 [701041/888800 78.88%] train loss: 1.5588095266139135e-05 \n",
      "epoch: 36 [702152/888800 79.00%] train loss: 1.3663229765370488e-05 \n",
      "epoch: 36 [703263/888800 79.12%] train loss: 1.520858313597273e-05 \n",
      "epoch: 36 [704374/888800 79.25%] train loss: 1.5471989172510803e-05 \n",
      "epoch: 36 [705485/888800 79.38%] train loss: 1.3479074368660804e-05 \n",
      "epoch: 36 [706596/888800 79.50%] train loss: 1.4238552466849796e-05 \n",
      "epoch: 36 [707707/888800 79.62%] train loss: 1.5055417861731257e-05 \n",
      "epoch: 36 [708818/888800 79.75%] train loss: 1.620415787328966e-05 \n",
      "epoch: 36 [709929/888800 79.88%] train loss: 1.4972924873291049e-05 \n",
      "epoch: 36 [711040/888800 80.00%] train loss: 1.4603721865569241e-05 \n",
      "epoch: 36 [712151/888800 80.12%] train loss: 1.4925043615221512e-05 \n",
      "epoch: 36 [713262/888800 80.25%] train loss: 1.3380483323999215e-05 \n",
      "epoch: 36 [714373/888800 80.38%] train loss: 1.473309748689644e-05 \n",
      "epoch: 36 [715484/888800 80.50%] train loss: 1.4602323972212616e-05 \n",
      "epoch: 36 [716595/888800 80.62%] train loss: 1.6124744433909655e-05 \n",
      "epoch: 36 [717706/888800 80.75%] train loss: 1.4073613783693872e-05 \n",
      "epoch: 36 [718817/888800 80.88%] train loss: 1.3697585018235259e-05 \n",
      "epoch: 36 [719928/888800 81.00%] train loss: 1.4505913895845879e-05 \n",
      "epoch: 36 [721039/888800 81.12%] train loss: 1.4767543689231388e-05 \n",
      "epoch: 36 [722150/888800 81.25%] train loss: 1.4823324818280526e-05 \n",
      "epoch: 36 [723261/888800 81.38%] train loss: 1.5182074093900155e-05 \n",
      "epoch: 36 [724372/888800 81.50%] train loss: 1.3790008779324125e-05 \n",
      "epoch: 36 [725483/888800 81.62%] train loss: 1.5043538951431401e-05 \n",
      "epoch: 36 [726594/888800 81.75%] train loss: 1.404926570103271e-05 \n",
      "epoch: 36 [727705/888800 81.88%] train loss: 1.5283598258974962e-05 \n",
      "epoch: 36 [728816/888800 82.00%] train loss: 1.4667461073258892e-05 \n",
      "epoch: 36 [729927/888800 82.12%] train loss: 1.3891284652345348e-05 \n",
      "epoch: 36 [731038/888800 82.25%] train loss: 1.3776141713606194e-05 \n",
      "epoch: 36 [732149/888800 82.38%] train loss: 1.4697436199639924e-05 \n",
      "epoch: 36 [733260/888800 82.50%] train loss: 1.4705865396535955e-05 \n",
      "epoch: 36 [734371/888800 82.62%] train loss: 1.4122758329904173e-05 \n",
      "epoch: 36 [735482/888800 82.75%] train loss: 1.3430826584226452e-05 \n",
      "epoch: 36 [736593/888800 82.88%] train loss: 1.4856618690828327e-05 \n",
      "epoch: 36 [737704/888800 83.00%] train loss: 1.444968529540347e-05 \n",
      "epoch: 36 [738815/888800 83.12%] train loss: 1.6435184079455212e-05 \n",
      "epoch: 36 [739926/888800 83.25%] train loss: 1.4879896298225503e-05 \n",
      "epoch: 36 [741037/888800 83.38%] train loss: 1.407895251759328e-05 \n",
      "epoch: 36 [742148/888800 83.50%] train loss: 1.3374480658967514e-05 \n",
      "epoch: 36 [743259/888800 83.62%] train loss: 1.4152265976008493e-05 \n",
      "epoch: 36 [744370/888800 83.75%] train loss: 1.2997996236663312e-05 \n",
      "epoch: 36 [745481/888800 83.88%] train loss: 1.3991112609801348e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [746592/888800 84.00%] train loss: 1.265980699827196e-05 \n",
      "epoch: 36 [747703/888800 84.12%] train loss: 1.385366795148002e-05 \n",
      "epoch: 36 [748814/888800 84.25%] train loss: 1.3213500096753705e-05 \n",
      "epoch: 36 [749925/888800 84.38%] train loss: 1.394502669427311e-05 \n",
      "epoch: 36 [751036/888800 84.50%] train loss: 1.5960264136083424e-05 \n",
      "epoch: 36 [752147/888800 84.62%] train loss: 1.3954922906123102e-05 \n",
      "epoch: 36 [753258/888800 84.75%] train loss: 1.4040450878383126e-05 \n",
      "epoch: 36 [754369/888800 84.88%] train loss: 1.4646731870016083e-05 \n",
      "epoch: 36 [755480/888800 85.00%] train loss: 1.5772131519042887e-05 \n",
      "epoch: 36 [756591/888800 85.12%] train loss: 1.4552915672538802e-05 \n",
      "epoch: 36 [757702/888800 85.25%] train loss: 1.343802796327509e-05 \n",
      "epoch: 36 [758813/888800 85.38%] train loss: 1.3988546925247647e-05 \n",
      "epoch: 36 [759924/888800 85.50%] train loss: 1.4110288248048164e-05 \n",
      "epoch: 36 [761035/888800 85.62%] train loss: 1.5152667401707731e-05 \n",
      "epoch: 36 [762146/888800 85.75%] train loss: 1.405024613632122e-05 \n",
      "epoch: 36 [763257/888800 85.88%] train loss: 1.3997871064930223e-05 \n",
      "epoch: 36 [764368/888800 86.00%] train loss: 1.4521781849907711e-05 \n",
      "epoch: 36 [765479/888800 86.12%] train loss: 1.4863127034914214e-05 \n",
      "epoch: 36 [766590/888800 86.25%] train loss: 1.3753708117292263e-05 \n",
      "epoch: 36 [767701/888800 86.38%] train loss: 1.4210802874004003e-05 \n",
      "epoch: 36 [768812/888800 86.50%] train loss: 1.433993656974053e-05 \n",
      "epoch: 36 [769923/888800 86.62%] train loss: 1.503336079622386e-05 \n",
      "epoch: 36 [771034/888800 86.75%] train loss: 1.4590096725441981e-05 \n",
      "epoch: 36 [772145/888800 86.88%] train loss: 1.3674593901669141e-05 \n",
      "epoch: 36 [773256/888800 87.00%] train loss: 1.4024065421835985e-05 \n",
      "epoch: 36 [774367/888800 87.12%] train loss: 1.512826383986976e-05 \n",
      "epoch: 36 [775478/888800 87.25%] train loss: 1.5042803170217667e-05 \n",
      "epoch: 36 [776589/888800 87.38%] train loss: 1.3866814697394148e-05 \n",
      "epoch: 36 [777700/888800 87.50%] train loss: 1.4662497960671317e-05 \n",
      "epoch: 36 [778811/888800 87.62%] train loss: 1.4522751371259801e-05 \n",
      "epoch: 36 [779922/888800 87.75%] train loss: 1.3944115380581934e-05 \n",
      "epoch: 36 [781033/888800 87.88%] train loss: 1.397102005284978e-05 \n",
      "epoch: 36 [782144/888800 88.00%] train loss: 1.3796232451568358e-05 \n",
      "epoch: 36 [783255/888800 88.12%] train loss: 1.367918503092369e-05 \n",
      "epoch: 36 [784366/888800 88.25%] train loss: 1.4303552234196104e-05 \n",
      "epoch: 36 [785477/888800 88.38%] train loss: 1.3566740562964696e-05 \n",
      "epoch: 36 [786588/888800 88.50%] train loss: 1.300792155234376e-05 \n",
      "epoch: 36 [787699/888800 88.62%] train loss: 1.2616136700671632e-05 \n",
      "epoch: 36 [788810/888800 88.75%] train loss: 1.4957839084672742e-05 \n",
      "epoch: 36 [789921/888800 88.88%] train loss: 1.482275274611311e-05 \n",
      "epoch: 36 [791032/888800 89.00%] train loss: 1.4789195120101795e-05 \n",
      "epoch: 36 [792143/888800 89.12%] train loss: 1.321574927715119e-05 \n",
      "epoch: 36 [793254/888800 89.25%] train loss: 1.3343978025659453e-05 \n",
      "epoch: 36 [794365/888800 89.38%] train loss: 1.3759363355347887e-05 \n",
      "epoch: 36 [795476/888800 89.50%] train loss: 1.3600946658698376e-05 \n",
      "epoch: 36 [796587/888800 89.62%] train loss: 1.3004169886698946e-05 \n",
      "epoch: 36 [797698/888800 89.75%] train loss: 1.3537644008465577e-05 \n",
      "epoch: 36 [798809/888800 89.88%] train loss: 1.4477107470156625e-05 \n",
      "epoch: 36 [799920/888800 90.00%] train loss: 1.3874904652766418e-05 \n",
      "epoch: 36 [801031/888800 90.12%] train loss: 1.535939190944191e-05 \n",
      "epoch: 36 [802142/888800 90.25%] train loss: 1.4560829185938928e-05 \n",
      "epoch: 36 [803253/888800 90.38%] train loss: 1.4050083336769603e-05 \n",
      "epoch: 36 [804364/888800 90.50%] train loss: 1.4407329217647202e-05 \n",
      "epoch: 36 [805475/888800 90.62%] train loss: 1.5176569831965026e-05 \n",
      "epoch: 36 [806586/888800 90.75%] train loss: 1.4402755368791986e-05 \n",
      "epoch: 36 [807697/888800 90.88%] train loss: 1.5234552847687155e-05 \n",
      "epoch: 36 [808808/888800 91.00%] train loss: 1.4322152310342062e-05 \n",
      "epoch: 36 [809919/888800 91.12%] train loss: 1.405435978085734e-05 \n",
      "epoch: 36 [811030/888800 91.25%] train loss: 1.3870248949388042e-05 \n",
      "epoch: 36 [812141/888800 91.38%] train loss: 1.4430609553528484e-05 \n",
      "epoch: 36 [813252/888800 91.50%] train loss: 1.4137535799818579e-05 \n",
      "epoch: 36 [814363/888800 91.62%] train loss: 1.2575750588439405e-05 \n",
      "epoch: 36 [815474/888800 91.75%] train loss: 1.4288933016359806e-05 \n",
      "epoch: 36 [816585/888800 91.88%] train loss: 1.4829978681518696e-05 \n",
      "epoch: 36 [817696/888800 92.00%] train loss: 1.6045103620854206e-05 \n",
      "epoch: 36 [818807/888800 92.12%] train loss: 1.380825324304169e-05 \n",
      "epoch: 36 [819918/888800 92.25%] train loss: 1.492812043579761e-05 \n",
      "epoch: 36 [821029/888800 92.38%] train loss: 1.385796167596709e-05 \n",
      "epoch: 36 [822140/888800 92.50%] train loss: 1.4724161701451521e-05 \n",
      "epoch: 36 [823251/888800 92.62%] train loss: 1.4343816474138293e-05 \n",
      "epoch: 36 [824362/888800 92.75%] train loss: 1.451124990126118e-05 \n",
      "epoch: 36 [825473/888800 92.88%] train loss: 1.4603842828364577e-05 \n",
      "epoch: 36 [826584/888800 93.00%] train loss: 1.3749503523285966e-05 \n",
      "epoch: 36 [827695/888800 93.12%] train loss: 1.4069813005335163e-05 \n",
      "epoch: 36 [828806/888800 93.25%] train loss: 1.346026601822814e-05 \n",
      "epoch: 36 [829917/888800 93.38%] train loss: 1.3636121366289444e-05 \n",
      "epoch: 36 [831028/888800 93.50%] train loss: 1.3989389117341489e-05 \n",
      "epoch: 36 [832139/888800 93.62%] train loss: 1.3598729310615454e-05 \n",
      "epoch: 36 [833250/888800 93.75%] train loss: 1.340311882813694e-05 \n",
      "epoch: 36 [834361/888800 93.88%] train loss: 1.2343622984190006e-05 \n",
      "epoch: 36 [835472/888800 94.00%] train loss: 1.4495189134322572e-05 \n",
      "epoch: 36 [836583/888800 94.12%] train loss: 1.4951223420212045e-05 \n",
      "epoch: 36 [837694/888800 94.25%] train loss: 1.4409500181500334e-05 \n",
      "epoch: 36 [838805/888800 94.38%] train loss: 1.3831238902639598e-05 \n",
      "epoch: 36 [839916/888800 94.50%] train loss: 1.4095418919168878e-05 \n",
      "epoch: 36 [841027/888800 94.62%] train loss: 1.593069282534998e-05 \n",
      "epoch: 36 [842138/888800 94.75%] train loss: 1.3968720850243699e-05 \n",
      "epoch: 36 [843249/888800 94.88%] train loss: 1.3835566278430633e-05 \n",
      "epoch: 36 [844360/888800 95.00%] train loss: 1.4061164620216005e-05 \n",
      "epoch: 36 [845471/888800 95.12%] train loss: 1.4401768567040563e-05 \n",
      "epoch: 36 [846582/888800 95.25%] train loss: 1.5243814232235309e-05 \n",
      "epoch: 36 [847693/888800 95.38%] train loss: 1.587919359735679e-05 \n",
      "epoch: 36 [848804/888800 95.50%] train loss: 1.4911331163602881e-05 \n",
      "epoch: 36 [849915/888800 95.62%] train loss: 1.4237392861105036e-05 \n",
      "epoch: 36 [851026/888800 95.75%] train loss: 1.4833439308858942e-05 \n",
      "epoch: 36 [852137/888800 95.88%] train loss: 1.3872980161977466e-05 \n",
      "epoch: 36 [853248/888800 96.00%] train loss: 1.470548795623472e-05 \n",
      "epoch: 36 [854359/888800 96.12%] train loss: 1.4198154531186447e-05 \n",
      "epoch: 36 [855470/888800 96.25%] train loss: 1.3791449418931734e-05 \n",
      "epoch: 36 [856581/888800 96.38%] train loss: 1.4667692084913142e-05 \n",
      "epoch: 36 [857692/888800 96.50%] train loss: 1.4493339222099166e-05 \n",
      "epoch: 36 [858803/888800 96.62%] train loss: 1.4223098332877271e-05 \n",
      "epoch: 36 [859914/888800 96.75%] train loss: 1.606133628229145e-05 \n",
      "epoch: 36 [861025/888800 96.88%] train loss: 1.536204399599228e-05 \n",
      "epoch: 36 [862136/888800 97.00%] train loss: 1.4088947864365764e-05 \n",
      "epoch: 36 [863247/888800 97.12%] train loss: 1.4548731087415945e-05 \n",
      "epoch: 36 [864358/888800 97.25%] train loss: 1.4655161976406816e-05 \n",
      "epoch: 36 [865469/888800 97.38%] train loss: 1.3972114174976014e-05 \n",
      "epoch: 36 [866580/888800 97.50%] train loss: 1.3938703887106385e-05 \n",
      "epoch: 36 [867691/888800 97.62%] train loss: 1.4146564353723079e-05 \n",
      "epoch: 36 [868802/888800 97.75%] train loss: 1.3755988220509607e-05 \n",
      "epoch: 36 [869913/888800 97.88%] train loss: 1.4023911717231385e-05 \n",
      "epoch: 36 [871024/888800 98.00%] train loss: 1.380162484565517e-05 \n",
      "epoch: 36 [872135/888800 98.12%] train loss: 1.3562399544753134e-05 \n",
      "epoch: 36 [873246/888800 98.25%] train loss: 1.4801476936554536e-05 \n",
      "epoch: 36 [874357/888800 98.38%] train loss: 1.502993382018758e-05 \n",
      "epoch: 36 [875468/888800 98.50%] train loss: 1.4097521670919377e-05 \n",
      "epoch: 36 [876579/888800 98.62%] train loss: 1.370147401758004e-05 \n",
      "epoch: 36 [877690/888800 98.75%] train loss: 1.3919020602770615e-05 \n",
      "epoch: 36 [878801/888800 98.88%] train loss: 1.444496592739597e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 [879912/888800 99.00%] train loss: 1.4305832337413449e-05 \n",
      "epoch: 36 [881023/888800 99.12%] train loss: 1.3631202818942256e-05 \n",
      "epoch: 36 [882134/888800 99.25%] train loss: 1.3877001038054004e-05 \n",
      "epoch: 36 [883245/888800 99.38%] train loss: 1.352549315924989e-05 \n",
      "epoch: 36 [884356/888800 99.50%] train loss: 1.424129914084915e-05 \n",
      "epoch: 36 [885467/888800 99.62%] train loss: 1.267086645384552e-05 \n",
      "epoch: 36 [886578/888800 99.75%] train loss: 1.5078305295901373e-05 \n",
      "epoch: 36 [887689/888800 99.88%] train loss: 1.4197239579516463e-05 \n",
      "epoch: 37 [0/888800 0.00%] train loss: 1.4610478501708712e-05 \n",
      "epoch: 37 [1111/888800 0.12%] train loss: 1.4860609553579707e-05 \n",
      "epoch: 37 [2222/888800 0.25%] train loss: 1.6018211681512184e-05 \n",
      "epoch: 37 [3333/888800 0.38%] train loss: 1.3722815310757142e-05 \n",
      "epoch: 37 [4444/888800 0.50%] train loss: 1.4711674339196179e-05 \n",
      "epoch: 37 [5555/888800 0.62%] train loss: 1.4363316040544305e-05 \n",
      "epoch: 37 [6666/888800 0.75%] train loss: 1.5779072782606818e-05 \n",
      "epoch: 37 [7777/888800 0.88%] train loss: 1.44994610309368e-05 \n",
      "epoch: 37 [8888/888800 1.00%] train loss: 1.4394468053069431e-05 \n",
      "epoch: 37 [9999/888800 1.12%] train loss: 1.4754234143765643e-05 \n",
      "epoch: 37 [11110/888800 1.25%] train loss: 1.4987773283792194e-05 \n",
      "epoch: 37 [12221/888800 1.38%] train loss: 1.5017148143670056e-05 \n",
      "epoch: 37 [13332/888800 1.50%] train loss: 1.4363921764015686e-05 \n",
      "epoch: 37 [14443/888800 1.62%] train loss: 1.573852750880178e-05 \n",
      "epoch: 37 [15554/888800 1.75%] train loss: 1.4931380064808764e-05 \n",
      "epoch: 37 [16665/888800 1.88%] train loss: 1.4226582607079763e-05 \n",
      "epoch: 37 [17776/888800 2.00%] train loss: 1.421539309376385e-05 \n",
      "epoch: 37 [18887/888800 2.12%] train loss: 1.493637955718441e-05 \n",
      "epoch: 37 [19998/888800 2.25%] train loss: 1.3684789337276015e-05 \n",
      "epoch: 37 [21109/888800 2.38%] train loss: 1.3684812984138262e-05 \n",
      "epoch: 37 [22220/888800 2.50%] train loss: 1.5924033505143598e-05 \n",
      "epoch: 37 [23331/888800 2.62%] train loss: 1.3798961845168378e-05 \n",
      "epoch: 37 [24442/888800 2.75%] train loss: 1.3813730220135767e-05 \n",
      "epoch: 37 [25553/888800 2.88%] train loss: 1.3814018529956229e-05 \n",
      "epoch: 37 [26664/888800 3.00%] train loss: 1.342289488093229e-05 \n",
      "epoch: 37 [27775/888800 3.12%] train loss: 1.439078369003255e-05 \n",
      "epoch: 37 [28886/888800 3.25%] train loss: 1.4105763511906844e-05 \n",
      "epoch: 37 [29997/888800 3.38%] train loss: 1.5603141946485266e-05 \n",
      "epoch: 37 [31108/888800 3.50%] train loss: 1.3713623047806323e-05 \n",
      "epoch: 37 [32219/888800 3.62%] train loss: 1.3543130990001373e-05 \n",
      "epoch: 37 [33330/888800 3.75%] train loss: 1.4416850717680063e-05 \n",
      "epoch: 37 [34441/888800 3.88%] train loss: 1.488984162278939e-05 \n",
      "epoch: 37 [35552/888800 4.00%] train loss: 1.4591667422791943e-05 \n",
      "epoch: 37 [36663/888800 4.12%] train loss: 1.3267923350213096e-05 \n",
      "epoch: 37 [37774/888800 4.25%] train loss: 1.4943013411539141e-05 \n",
      "epoch: 37 [38885/888800 4.38%] train loss: 1.4642340829595923e-05 \n",
      "epoch: 37 [39996/888800 4.50%] train loss: 1.3943520571046975e-05 \n",
      "epoch: 37 [41107/888800 4.62%] train loss: 1.3762542039330583e-05 \n",
      "epoch: 37 [42218/888800 4.75%] train loss: 1.3632185073220171e-05 \n",
      "epoch: 37 [43329/888800 4.88%] train loss: 1.4052970982447732e-05 \n",
      "epoch: 37 [44440/888800 5.00%] train loss: 1.3916379430156667e-05 \n",
      "epoch: 37 [45551/888800 5.12%] train loss: 1.4030099919182248e-05 \n",
      "epoch: 37 [46662/888800 5.25%] train loss: 1.3816956197842956e-05 \n",
      "epoch: 37 [47773/888800 5.38%] train loss: 1.5153495951381046e-05 \n",
      "epoch: 37 [48884/888800 5.50%] train loss: 1.425510345143266e-05 \n",
      "epoch: 37 [49995/888800 5.62%] train loss: 1.5249286661855876e-05 \n",
      "epoch: 37 [51106/888800 5.75%] train loss: 1.511350001237588e-05 \n",
      "epoch: 37 [52217/888800 5.88%] train loss: 1.302768214372918e-05 \n",
      "epoch: 37 [53328/888800 6.00%] train loss: 1.4439101505558938e-05 \n",
      "epoch: 37 [54439/888800 6.12%] train loss: 1.4660120541520882e-05 \n",
      "epoch: 37 [55550/888800 6.25%] train loss: 1.528736720501911e-05 \n",
      "epoch: 37 [56661/888800 6.38%] train loss: 1.53313776536379e-05 \n",
      "epoch: 37 [57772/888800 6.50%] train loss: 1.3610098903882317e-05 \n",
      "epoch: 37 [58883/888800 6.62%] train loss: 1.6291010979330167e-05 \n",
      "epoch: 37 [59994/888800 6.75%] train loss: 1.4917095541022718e-05 \n",
      "epoch: 37 [61105/888800 6.88%] train loss: 1.5897054254310206e-05 \n",
      "epoch: 37 [62216/888800 7.00%] train loss: 1.386613348586252e-05 \n",
      "epoch: 37 [63327/888800 7.12%] train loss: 1.4116974853095599e-05 \n",
      "epoch: 37 [64438/888800 7.25%] train loss: 1.4162595107336529e-05 \n",
      "epoch: 37 [65549/888800 7.38%] train loss: 1.4047247532289475e-05 \n",
      "epoch: 37 [66660/888800 7.50%] train loss: 1.3557633792515844e-05 \n",
      "epoch: 37 [67771/888800 7.62%] train loss: 1.3370989108807407e-05 \n",
      "epoch: 37 [68882/888800 7.75%] train loss: 1.5035022443044e-05 \n",
      "epoch: 37 [69993/888800 7.88%] train loss: 1.4251232641981915e-05 \n",
      "epoch: 37 [71104/888800 8.00%] train loss: 1.48387016452034e-05 \n",
      "epoch: 37 [72215/888800 8.12%] train loss: 1.370722475257935e-05 \n",
      "epoch: 37 [73326/888800 8.25%] train loss: 1.4710393770656083e-05 \n",
      "epoch: 37 [74437/888800 8.38%] train loss: 1.3990245861350559e-05 \n",
      "epoch: 37 [75548/888800 8.50%] train loss: 1.3889209185435902e-05 \n",
      "epoch: 37 [76659/888800 8.62%] train loss: 1.4494734386971686e-05 \n",
      "epoch: 37 [77770/888800 8.75%] train loss: 1.3610916539619211e-05 \n",
      "epoch: 37 [78881/888800 8.88%] train loss: 1.4227598512661643e-05 \n",
      "epoch: 37 [79992/888800 9.00%] train loss: 1.4483310224022716e-05 \n",
      "epoch: 37 [81103/888800 9.12%] train loss: 1.4550424566550646e-05 \n",
      "epoch: 37 [82214/888800 9.25%] train loss: 1.446042733732611e-05 \n",
      "epoch: 37 [83325/888800 9.38%] train loss: 1.4286478290159721e-05 \n",
      "epoch: 37 [84436/888800 9.50%] train loss: 1.319123839493841e-05 \n",
      "epoch: 37 [85547/888800 9.62%] train loss: 1.4383614143298473e-05 \n",
      "epoch: 37 [86658/888800 9.75%] train loss: 1.4658943655376788e-05 \n",
      "epoch: 37 [87769/888800 9.88%] train loss: 1.4129624105407856e-05 \n",
      "epoch: 37 [88880/888800 10.00%] train loss: 1.4847366401227191e-05 \n",
      "epoch: 37 [89991/888800 10.12%] train loss: 1.435074045730289e-05 \n",
      "epoch: 37 [91102/888800 10.25%] train loss: 1.5107440958672669e-05 \n",
      "epoch: 37 [92213/888800 10.38%] train loss: 1.3993890206620563e-05 \n",
      "epoch: 37 [93324/888800 10.50%] train loss: 1.3912223948864266e-05 \n",
      "epoch: 37 [94435/888800 10.62%] train loss: 1.4690510397485923e-05 \n",
      "epoch: 37 [95546/888800 10.75%] train loss: 1.414189136994537e-05 \n",
      "epoch: 37 [96657/888800 10.88%] train loss: 1.4334397747006733e-05 \n",
      "epoch: 37 [97768/888800 11.00%] train loss: 1.4708224625792354e-05 \n",
      "epoch: 37 [98879/888800 11.12%] train loss: 1.4178255696606357e-05 \n",
      "epoch: 37 [99990/888800 11.25%] train loss: 1.4250189451558981e-05 \n",
      "epoch: 37 [101101/888800 11.38%] train loss: 1.4867446225252934e-05 \n",
      "epoch: 37 [102212/888800 11.50%] train loss: 1.2873909327026922e-05 \n",
      "epoch: 37 [103323/888800 11.62%] train loss: 1.476023953728145e-05 \n",
      "epoch: 37 [104434/888800 11.75%] train loss: 1.4332509636005852e-05 \n",
      "epoch: 37 [105545/888800 11.88%] train loss: 1.421289471181808e-05 \n",
      "epoch: 37 [106656/888800 12.00%] train loss: 1.3533558558265213e-05 \n",
      "epoch: 37 [107767/888800 12.12%] train loss: 1.4321260096039623e-05 \n",
      "epoch: 37 [108878/888800 12.25%] train loss: 1.2869909369328525e-05 \n",
      "epoch: 37 [109989/888800 12.38%] train loss: 1.4626987649535295e-05 \n",
      "epoch: 37 [111100/888800 12.50%] train loss: 1.3504012713383418e-05 \n",
      "epoch: 37 [112211/888800 12.62%] train loss: 1.543951111671049e-05 \n",
      "epoch: 37 [113322/888800 12.75%] train loss: 1.4633540558861569e-05 \n",
      "epoch: 37 [114433/888800 12.88%] train loss: 1.4737233868800104e-05 \n",
      "epoch: 37 [115544/888800 13.00%] train loss: 1.42484041134594e-05 \n",
      "epoch: 37 [116655/888800 13.12%] train loss: 1.5216461179079488e-05 \n",
      "epoch: 37 [117766/888800 13.25%] train loss: 1.3942288205726072e-05 \n",
      "epoch: 37 [118877/888800 13.38%] train loss: 1.3495772691385355e-05 \n",
      "epoch: 37 [119988/888800 13.50%] train loss: 1.5505525880143978e-05 \n",
      "epoch: 37 [121099/888800 13.62%] train loss: 1.5175547559920233e-05 \n",
      "epoch: 37 [122210/888800 13.75%] train loss: 1.525954394310247e-05 \n",
      "epoch: 37 [123321/888800 13.88%] train loss: 1.479033198847901e-05 \n",
      "epoch: 37 [124432/888800 14.00%] train loss: 1.40268948598532e-05 \n",
      "epoch: 37 [125543/888800 14.12%] train loss: 1.4473494047706481e-05 \n",
      "epoch: 37 [126654/888800 14.25%] train loss: 1.5461355360457674e-05 \n",
      "epoch: 37 [127765/888800 14.38%] train loss: 1.436601723980857e-05 \n",
      "epoch: 37 [128876/888800 14.50%] train loss: 1.4934769751562271e-05 \n",
      "epoch: 37 [129987/888800 14.62%] train loss: 1.3880948245059699e-05 \n",
      "epoch: 37 [131098/888800 14.75%] train loss: 1.4391668628377374e-05 \n",
      "epoch: 37 [132209/888800 14.88%] train loss: 1.4190893125487491e-05 \n",
      "epoch: 37 [133320/888800 15.00%] train loss: 1.3854987628292292e-05 \n",
      "epoch: 37 [134431/888800 15.12%] train loss: 1.3205394679971505e-05 \n",
      "epoch: 37 [135542/888800 15.25%] train loss: 1.4408142305910587e-05 \n",
      "epoch: 37 [136653/888800 15.38%] train loss: 1.4519778233079705e-05 \n",
      "epoch: 37 [137764/888800 15.50%] train loss: 1.4708240996696986e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [138875/888800 15.62%] train loss: 1.4296108929556794e-05 \n",
      "epoch: 37 [139986/888800 15.75%] train loss: 1.3806752576783765e-05 \n",
      "epoch: 37 [141097/888800 15.88%] train loss: 1.4627437849412672e-05 \n",
      "epoch: 37 [142208/888800 16.00%] train loss: 1.4167363588057924e-05 \n",
      "epoch: 37 [143319/888800 16.12%] train loss: 1.4679513697046787e-05 \n",
      "epoch: 37 [144430/888800 16.25%] train loss: 1.4632269994763192e-05 \n",
      "epoch: 37 [145541/888800 16.38%] train loss: 1.2931717719766311e-05 \n",
      "epoch: 37 [146652/888800 16.50%] train loss: 1.353866173303686e-05 \n",
      "epoch: 37 [147763/888800 16.62%] train loss: 1.5026748769741971e-05 \n",
      "epoch: 37 [148874/888800 16.75%] train loss: 1.4611618098570034e-05 \n",
      "epoch: 37 [149985/888800 16.88%] train loss: 1.497599259892013e-05 \n",
      "epoch: 37 [151096/888800 17.00%] train loss: 1.3945553291705437e-05 \n",
      "epoch: 37 [152207/888800 17.12%] train loss: 1.4540672054863535e-05 \n",
      "epoch: 37 [153318/888800 17.25%] train loss: 1.3985006262373645e-05 \n",
      "epoch: 37 [154429/888800 17.38%] train loss: 1.5447485566255637e-05 \n",
      "epoch: 37 [155540/888800 17.50%] train loss: 1.4189872672432102e-05 \n",
      "epoch: 37 [156651/888800 17.62%] train loss: 1.5159683243837208e-05 \n",
      "epoch: 37 [157762/888800 17.75%] train loss: 1.4433456271945033e-05 \n",
      "epoch: 37 [158873/888800 17.88%] train loss: 1.4804089005338028e-05 \n",
      "epoch: 37 [159984/888800 18.00%] train loss: 1.382270875183167e-05 \n",
      "epoch: 37 [161095/888800 18.12%] train loss: 1.529608925920911e-05 \n",
      "epoch: 37 [162206/888800 18.25%] train loss: 1.5844318113522604e-05 \n",
      "epoch: 37 [163317/888800 18.38%] train loss: 1.3631767615152057e-05 \n",
      "epoch: 37 [164428/888800 18.50%] train loss: 1.6122878150781617e-05 \n",
      "epoch: 37 [165539/888800 18.62%] train loss: 1.4259097042668145e-05 \n",
      "epoch: 37 [166650/888800 18.75%] train loss: 1.4651220226369333e-05 \n",
      "epoch: 37 [167761/888800 18.88%] train loss: 1.3096358088660054e-05 \n",
      "epoch: 37 [168872/888800 19.00%] train loss: 1.463566513848491e-05 \n",
      "epoch: 37 [169983/888800 19.12%] train loss: 1.3464019502862357e-05 \n",
      "epoch: 37 [171094/888800 19.25%] train loss: 1.3767529708275106e-05 \n",
      "epoch: 37 [172205/888800 19.38%] train loss: 1.4447574358200654e-05 \n",
      "epoch: 37 [173316/888800 19.50%] train loss: 1.407081708748592e-05 \n",
      "epoch: 37 [174427/888800 19.62%] train loss: 1.5108743355085608e-05 \n",
      "epoch: 37 [175538/888800 19.75%] train loss: 1.4027904398972169e-05 \n",
      "epoch: 37 [176649/888800 19.88%] train loss: 1.4885718883306254e-05 \n",
      "epoch: 37 [177760/888800 20.00%] train loss: 1.6101912478916347e-05 \n",
      "epoch: 37 [178871/888800 20.12%] train loss: 1.5077227544679772e-05 \n",
      "epoch: 37 [179982/888800 20.25%] train loss: 1.4807360457780305e-05 \n",
      "epoch: 37 [181093/888800 20.38%] train loss: 1.4454551092057955e-05 \n",
      "epoch: 37 [182204/888800 20.50%] train loss: 1.3494845916284248e-05 \n",
      "epoch: 37 [183315/888800 20.62%] train loss: 1.416392933606403e-05 \n",
      "epoch: 37 [184426/888800 20.75%] train loss: 1.3188517186790705e-05 \n",
      "epoch: 37 [185537/888800 20.88%] train loss: 1.4966684830142185e-05 \n",
      "epoch: 37 [186648/888800 21.00%] train loss: 1.3824198504153173e-05 \n",
      "epoch: 37 [187759/888800 21.12%] train loss: 1.2743887964461464e-05 \n",
      "epoch: 37 [188870/888800 21.25%] train loss: 1.3583391591964755e-05 \n",
      "epoch: 37 [189981/888800 21.38%] train loss: 1.5072846508701332e-05 \n",
      "epoch: 37 [191092/888800 21.50%] train loss: 1.327500012848759e-05 \n",
      "epoch: 37 [192203/888800 21.62%] train loss: 1.2826905731344596e-05 \n",
      "epoch: 37 [193314/888800 21.75%] train loss: 1.4401523003471084e-05 \n",
      "epoch: 37 [194425/888800 21.88%] train loss: 1.3108781786286272e-05 \n",
      "epoch: 37 [195536/888800 22.00%] train loss: 1.5581144907628186e-05 \n",
      "epoch: 37 [196647/888800 22.12%] train loss: 1.336458808509633e-05 \n",
      "epoch: 37 [197758/888800 22.25%] train loss: 1.3946219951321837e-05 \n",
      "epoch: 37 [198869/888800 22.38%] train loss: 1.4088984244153835e-05 \n",
      "epoch: 37 [199980/888800 22.50%] train loss: 1.3409799066721462e-05 \n",
      "epoch: 37 [201091/888800 22.62%] train loss: 1.4591900253435597e-05 \n",
      "epoch: 37 [202202/888800 22.75%] train loss: 1.3365012819122057e-05 \n",
      "epoch: 37 [203313/888800 22.88%] train loss: 1.3273566764837597e-05 \n",
      "epoch: 37 [204424/888800 23.00%] train loss: 1.4008774996909779e-05 \n",
      "epoch: 37 [205535/888800 23.12%] train loss: 1.4740595361217856e-05 \n",
      "epoch: 37 [206646/888800 23.25%] train loss: 1.4404088688024785e-05 \n",
      "epoch: 37 [207757/888800 23.38%] train loss: 1.6122188753797673e-05 \n",
      "epoch: 37 [208868/888800 23.50%] train loss: 1.4337128959596157e-05 \n",
      "epoch: 37 [209979/888800 23.62%] train loss: 1.2800434888049494e-05 \n",
      "epoch: 37 [211090/888800 23.75%] train loss: 1.5769113815622404e-05 \n",
      "epoch: 37 [212201/888800 23.88%] train loss: 1.4772682334296405e-05 \n",
      "epoch: 37 [213312/888800 24.00%] train loss: 1.5739287846372463e-05 \n",
      "epoch: 37 [214423/888800 24.12%] train loss: 1.2955466445419006e-05 \n",
      "epoch: 37 [215534/888800 24.25%] train loss: 1.5048441127873957e-05 \n",
      "epoch: 37 [216645/888800 24.38%] train loss: 1.3861780644219834e-05 \n",
      "epoch: 37 [217756/888800 24.50%] train loss: 1.3722640687774401e-05 \n",
      "epoch: 37 [218867/888800 24.62%] train loss: 1.3983186363475397e-05 \n",
      "epoch: 37 [219978/888800 24.75%] train loss: 1.4043803275853861e-05 \n",
      "epoch: 37 [221089/888800 24.88%] train loss: 1.4439077858696692e-05 \n",
      "epoch: 37 [222200/888800 25.00%] train loss: 1.489676196797518e-05 \n",
      "epoch: 37 [223311/888800 25.12%] train loss: 1.5837982573430054e-05 \n",
      "epoch: 37 [224422/888800 25.25%] train loss: 1.3812708857585676e-05 \n",
      "epoch: 37 [225533/888800 25.38%] train loss: 1.5178229659795761e-05 \n",
      "epoch: 37 [226644/888800 25.50%] train loss: 1.3696945643459912e-05 \n",
      "epoch: 37 [227755/888800 25.62%] train loss: 1.4894491869199555e-05 \n",
      "epoch: 37 [228866/888800 25.75%] train loss: 1.4107530660112388e-05 \n",
      "epoch: 37 [229977/888800 25.88%] train loss: 1.6610489183221944e-05 \n",
      "epoch: 37 [231088/888800 26.00%] train loss: 1.496106506237993e-05 \n",
      "epoch: 37 [232199/888800 26.12%] train loss: 1.5165043805609457e-05 \n",
      "epoch: 37 [233310/888800 26.25%] train loss: 1.4323579307529144e-05 \n",
      "epoch: 37 [234421/888800 26.38%] train loss: 1.7230797311640345e-05 \n",
      "epoch: 37 [235532/888800 26.50%] train loss: 1.6793153918115422e-05 \n",
      "epoch: 37 [236643/888800 26.62%] train loss: 1.5031931070552673e-05 \n",
      "epoch: 37 [237754/888800 26.75%] train loss: 1.5803525457158685e-05 \n",
      "epoch: 37 [238865/888800 26.88%] train loss: 1.404996328346897e-05 \n",
      "epoch: 37 [239976/888800 27.00%] train loss: 1.6705116649973206e-05 \n",
      "epoch: 37 [241087/888800 27.12%] train loss: 1.4263268894865178e-05 \n",
      "epoch: 37 [242198/888800 27.25%] train loss: 1.650581180001609e-05 \n",
      "epoch: 37 [243309/888800 27.38%] train loss: 1.4691720025439281e-05 \n",
      "epoch: 37 [244420/888800 27.50%] train loss: 1.4136444406176452e-05 \n",
      "epoch: 37 [245531/888800 27.62%] train loss: 1.3523853340302594e-05 \n",
      "epoch: 37 [246642/888800 27.75%] train loss: 1.635273110878188e-05 \n",
      "epoch: 37 [247753/888800 27.88%] train loss: 1.5379575415863656e-05 \n",
      "epoch: 37 [248864/888800 28.00%] train loss: 1.418957435816992e-05 \n",
      "epoch: 37 [249975/888800 28.12%] train loss: 1.4310758160718251e-05 \n",
      "epoch: 37 [251086/888800 28.25%] train loss: 1.4609602658310905e-05 \n",
      "epoch: 37 [252197/888800 28.38%] train loss: 1.3974314242659602e-05 \n",
      "epoch: 37 [253308/888800 28.50%] train loss: 1.4766660569875967e-05 \n",
      "epoch: 37 [254419/888800 28.62%] train loss: 1.329772021563258e-05 \n",
      "epoch: 37 [255530/888800 28.75%] train loss: 1.4984003428253345e-05 \n",
      "epoch: 37 [256641/888800 28.88%] train loss: 1.3296141332830302e-05 \n",
      "epoch: 37 [257752/888800 29.00%] train loss: 1.2556547517306171e-05 \n",
      "epoch: 37 [258863/888800 29.12%] train loss: 1.3933614354755264e-05 \n",
      "epoch: 37 [259974/888800 29.25%] train loss: 1.4525580809277017e-05 \n",
      "epoch: 37 [261085/888800 29.38%] train loss: 1.3178088920540176e-05 \n",
      "epoch: 37 [262196/888800 29.50%] train loss: 1.3988132195663638e-05 \n",
      "epoch: 37 [263307/888800 29.62%] train loss: 1.5035404430818744e-05 \n",
      "epoch: 37 [264418/888800 29.75%] train loss: 1.3799584849039093e-05 \n",
      "epoch: 37 [265529/888800 29.88%] train loss: 1.3743095223617274e-05 \n",
      "epoch: 37 [266640/888800 30.00%] train loss: 1.5589361282764003e-05 \n",
      "epoch: 37 [267751/888800 30.12%] train loss: 1.3814304111292586e-05 \n",
      "epoch: 37 [268862/888800 30.25%] train loss: 1.5818304746062495e-05 \n",
      "epoch: 37 [269973/888800 30.38%] train loss: 1.6441643310827203e-05 \n",
      "epoch: 37 [271084/888800 30.50%] train loss: 1.6352574675693177e-05 \n",
      "epoch: 37 [272195/888800 30.62%] train loss: 1.6609437807346694e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [273306/888800 30.75%] train loss: 1.2765681276505347e-05 \n",
      "epoch: 37 [274417/888800 30.88%] train loss: 1.613951644685585e-05 \n",
      "epoch: 37 [275528/888800 31.00%] train loss: 1.4125441339274403e-05 \n",
      "epoch: 37 [276639/888800 31.12%] train loss: 1.6236084775300696e-05 \n",
      "epoch: 37 [277750/888800 31.25%] train loss: 1.3743156159762293e-05 \n",
      "epoch: 37 [278861/888800 31.38%] train loss: 1.4503048078040592e-05 \n",
      "epoch: 37 [279972/888800 31.50%] train loss: 1.441133917978732e-05 \n",
      "epoch: 37 [281083/888800 31.62%] train loss: 1.3766154552286025e-05 \n",
      "epoch: 37 [282194/888800 31.75%] train loss: 1.4934736100258306e-05 \n",
      "epoch: 37 [283305/888800 31.88%] train loss: 1.489676196797518e-05 \n",
      "epoch: 37 [284416/888800 32.00%] train loss: 1.5173228348430712e-05 \n",
      "epoch: 37 [285527/888800 32.12%] train loss: 1.4273695342126302e-05 \n",
      "epoch: 37 [286638/888800 32.25%] train loss: 1.4746610759175383e-05 \n",
      "epoch: 37 [287749/888800 32.38%] train loss: 1.4262007425713819e-05 \n",
      "epoch: 37 [288860/888800 32.50%] train loss: 1.4051108337298501e-05 \n",
      "epoch: 37 [289971/888800 32.62%] train loss: 1.5087617612152826e-05 \n",
      "epoch: 37 [291082/888800 32.75%] train loss: 1.5048731256683823e-05 \n",
      "epoch: 37 [292193/888800 32.88%] train loss: 1.5699117284384556e-05 \n",
      "epoch: 37 [293304/888800 33.00%] train loss: 1.3768322787655052e-05 \n",
      "epoch: 37 [294415/888800 33.12%] train loss: 1.3462341485137586e-05 \n",
      "epoch: 37 [295526/888800 33.25%] train loss: 1.3744926945946645e-05 \n",
      "epoch: 37 [296637/888800 33.38%] train loss: 1.370434711134294e-05 \n",
      "epoch: 37 [297748/888800 33.50%] train loss: 1.5367693777079694e-05 \n",
      "epoch: 37 [298859/888800 33.62%] train loss: 1.4504256796499249e-05 \n",
      "epoch: 37 [299970/888800 33.75%] train loss: 1.4387281225936022e-05 \n",
      "epoch: 37 [301081/888800 33.88%] train loss: 1.4075782019062899e-05 \n",
      "epoch: 37 [302192/888800 34.00%] train loss: 1.38544783112593e-05 \n",
      "epoch: 37 [303303/888800 34.12%] train loss: 1.3744793250225484e-05 \n",
      "epoch: 37 [304414/888800 34.25%] train loss: 1.3866194422007538e-05 \n",
      "epoch: 37 [305525/888800 34.38%] train loss: 1.5318344594561495e-05 \n",
      "epoch: 37 [306636/888800 34.50%] train loss: 1.4123535038379487e-05 \n",
      "epoch: 37 [307747/888800 34.62%] train loss: 1.492012870585313e-05 \n",
      "epoch: 37 [308858/888800 34.75%] train loss: 1.3821599168295506e-05 \n",
      "epoch: 37 [309969/888800 34.88%] train loss: 1.4849493709334638e-05 \n",
      "epoch: 37 [311080/888800 35.00%] train loss: 1.389333283441374e-05 \n",
      "epoch: 37 [312191/888800 35.12%] train loss: 1.3540799045586027e-05 \n",
      "epoch: 37 [313302/888800 35.25%] train loss: 1.4179776371747721e-05 \n",
      "epoch: 37 [314413/888800 35.38%] train loss: 1.3582810424850322e-05 \n",
      "epoch: 37 [315524/888800 35.50%] train loss: 1.4430819646804594e-05 \n",
      "epoch: 37 [316635/888800 35.62%] train loss: 1.552617504785303e-05 \n",
      "epoch: 37 [317746/888800 35.75%] train loss: 1.5836660168133676e-05 \n",
      "epoch: 37 [318857/888800 35.88%] train loss: 1.3640128599945456e-05 \n",
      "epoch: 37 [319968/888800 36.00%] train loss: 1.625637014512904e-05 \n",
      "epoch: 37 [321079/888800 36.12%] train loss: 1.5121155229280703e-05 \n",
      "epoch: 37 [322190/888800 36.25%] train loss: 1.5055648873385508e-05 \n",
      "epoch: 37 [323301/888800 36.38%] train loss: 1.4778985132579692e-05 \n",
      "epoch: 37 [324412/888800 36.50%] train loss: 1.4538805771735497e-05 \n",
      "epoch: 37 [325523/888800 36.62%] train loss: 1.4450317394221202e-05 \n",
      "epoch: 37 [326634/888800 36.75%] train loss: 1.4243480109144002e-05 \n",
      "epoch: 37 [327745/888800 36.88%] train loss: 1.6167090507224202e-05 \n",
      "epoch: 37 [328856/888800 37.00%] train loss: 1.4534849469782785e-05 \n",
      "epoch: 37 [329967/888800 37.12%] train loss: 1.6794838302303106e-05 \n",
      "epoch: 37 [331078/888800 37.25%] train loss: 1.4307770470622927e-05 \n",
      "epoch: 37 [332189/888800 37.38%] train loss: 1.4729791473655496e-05 \n",
      "epoch: 37 [333300/888800 37.50%] train loss: 1.4256588656280655e-05 \n",
      "epoch: 37 [334411/888800 37.62%] train loss: 1.5166639968811069e-05 \n",
      "epoch: 37 [335522/888800 37.75%] train loss: 1.445656471332768e-05 \n",
      "epoch: 37 [336633/888800 37.88%] train loss: 1.6168354704859667e-05 \n",
      "epoch: 37 [337744/888800 38.00%] train loss: 1.4992911928857211e-05 \n",
      "epoch: 37 [338855/888800 38.12%] train loss: 1.4443614418269135e-05 \n",
      "epoch: 37 [339966/888800 38.25%] train loss: 1.3865181244909763e-05 \n",
      "epoch: 37 [341077/888800 38.38%] train loss: 1.520994192105718e-05 \n",
      "epoch: 37 [342188/888800 38.50%] train loss: 1.408736625307938e-05 \n",
      "epoch: 37 [343299/888800 38.62%] train loss: 1.6477082681376487e-05 \n",
      "epoch: 37 [344410/888800 38.75%] train loss: 1.4646921044914052e-05 \n",
      "epoch: 37 [345521/888800 38.88%] train loss: 1.3764098184765317e-05 \n",
      "epoch: 37 [346632/888800 39.00%] train loss: 1.243286988028558e-05 \n",
      "epoch: 37 [347743/888800 39.12%] train loss: 1.5633737348252907e-05 \n",
      "epoch: 37 [348854/888800 39.25%] train loss: 1.3657327144755982e-05 \n",
      "epoch: 37 [349965/888800 39.38%] train loss: 1.5191970305750147e-05 \n",
      "epoch: 37 [351076/888800 39.50%] train loss: 1.539065306133125e-05 \n",
      "epoch: 37 [352187/888800 39.62%] train loss: 1.5675415852456354e-05 \n",
      "epoch: 37 [353298/888800 39.75%] train loss: 1.3513082194549497e-05 \n",
      "epoch: 37 [354409/888800 39.88%] train loss: 1.4933585589460563e-05 \n",
      "epoch: 37 [355520/888800 40.00%] train loss: 1.3916221178078558e-05 \n",
      "epoch: 37 [356631/888800 40.12%] train loss: 1.4397584891412407e-05 \n",
      "epoch: 37 [357742/888800 40.25%] train loss: 1.4959042346163187e-05 \n",
      "epoch: 37 [358853/888800 40.38%] train loss: 1.3933441550761927e-05 \n",
      "epoch: 37 [359964/888800 40.50%] train loss: 1.4175407159200404e-05 \n",
      "epoch: 37 [361075/888800 40.62%] train loss: 1.4065632058191113e-05 \n",
      "epoch: 37 [362186/888800 40.75%] train loss: 1.479711318097543e-05 \n",
      "epoch: 37 [363297/888800 40.88%] train loss: 1.3887281966162845e-05 \n",
      "epoch: 37 [364408/888800 41.00%] train loss: 1.389671797369374e-05 \n",
      "epoch: 37 [365519/888800 41.12%] train loss: 1.4311636732600164e-05 \n",
      "epoch: 37 [366630/888800 41.25%] train loss: 1.5415498637594283e-05 \n",
      "epoch: 37 [367741/888800 41.38%] train loss: 1.3819862942909822e-05 \n",
      "epoch: 37 [368852/888800 41.50%] train loss: 1.5501287634833716e-05 \n",
      "epoch: 37 [369963/888800 41.62%] train loss: 1.3756702173850499e-05 \n",
      "epoch: 37 [371074/888800 41.75%] train loss: 1.3324555766303092e-05 \n",
      "epoch: 37 [372185/888800 41.88%] train loss: 1.3673126886715181e-05 \n",
      "epoch: 37 [373296/888800 42.00%] train loss: 1.4345611816679593e-05 \n",
      "epoch: 37 [374407/888800 42.12%] train loss: 1.4273310625867452e-05 \n",
      "epoch: 37 [375518/888800 42.25%] train loss: 1.4446371096710209e-05 \n",
      "epoch: 37 [376629/888800 42.38%] train loss: 1.5171697668847628e-05 \n",
      "epoch: 37 [377740/888800 42.50%] train loss: 1.4150077731756028e-05 \n",
      "epoch: 37 [378851/888800 42.62%] train loss: 1.4160484170133714e-05 \n",
      "epoch: 37 [379962/888800 42.75%] train loss: 1.3462029528454877e-05 \n",
      "epoch: 37 [381073/888800 42.88%] train loss: 1.385933137498796e-05 \n",
      "epoch: 37 [382184/888800 43.00%] train loss: 1.424482798029203e-05 \n",
      "epoch: 37 [383295/888800 43.12%] train loss: 1.3165427844796795e-05 \n",
      "epoch: 37 [384406/888800 43.25%] train loss: 1.394926403008867e-05 \n",
      "epoch: 37 [385517/888800 43.38%] train loss: 1.3175137610232923e-05 \n",
      "epoch: 37 [386628/888800 43.50%] train loss: 1.3590584785561077e-05 \n",
      "epoch: 37 [387739/888800 43.62%] train loss: 1.408638581779087e-05 \n",
      "epoch: 37 [388850/888800 43.75%] train loss: 1.4710560208186507e-05 \n",
      "epoch: 37 [389961/888800 43.88%] train loss: 1.4926106814527884e-05 \n",
      "epoch: 37 [391072/888800 44.00%] train loss: 1.2055993465764914e-05 \n",
      "epoch: 37 [392183/888800 44.12%] train loss: 1.4316143278847449e-05 \n",
      "epoch: 37 [393294/888800 44.25%] train loss: 1.3971291082270909e-05 \n",
      "epoch: 37 [394405/888800 44.38%] train loss: 1.2837546819355339e-05 \n",
      "epoch: 37 [395516/888800 44.50%] train loss: 1.3703454897040501e-05 \n",
      "epoch: 37 [396627/888800 44.62%] train loss: 1.3658982425113209e-05 \n",
      "epoch: 37 [397738/888800 44.75%] train loss: 1.39229623528081e-05 \n",
      "epoch: 37 [398849/888800 44.88%] train loss: 1.4145864952297416e-05 \n",
      "epoch: 37 [399960/888800 45.00%] train loss: 1.4791860849072691e-05 \n",
      "epoch: 37 [401071/888800 45.12%] train loss: 1.3411529835138936e-05 \n",
      "epoch: 37 [402182/888800 45.25%] train loss: 1.4918755368853454e-05 \n",
      "epoch: 37 [403293/888800 45.38%] train loss: 1.2943621186423115e-05 \n",
      "epoch: 37 [404404/888800 45.50%] train loss: 1.3820294043398462e-05 \n",
      "epoch: 37 [405515/888800 45.62%] train loss: 1.3314570423972327e-05 \n",
      "epoch: 37 [406626/888800 45.75%] train loss: 1.4414546967600472e-05 \n",
      "epoch: 37 [407737/888800 45.88%] train loss: 1.532773967483081e-05 \n",
      "epoch: 37 [408848/888800 46.00%] train loss: 1.423710273229517e-05 \n",
      "epoch: 37 [409959/888800 46.12%] train loss: 1.5456498658750206e-05 \n",
      "epoch: 37 [411070/888800 46.25%] train loss: 1.5111377251741942e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [412181/888800 46.38%] train loss: 1.4763078979740385e-05 \n",
      "epoch: 37 [413292/888800 46.50%] train loss: 1.5413810615427792e-05 \n",
      "epoch: 37 [414403/888800 46.62%] train loss: 1.5518000509473495e-05 \n",
      "epoch: 37 [415514/888800 46.75%] train loss: 1.5030725080578122e-05 \n",
      "epoch: 37 [416625/888800 46.88%] train loss: 1.5760224414407276e-05 \n",
      "epoch: 37 [417736/888800 47.00%] train loss: 1.4819999705650844e-05 \n",
      "epoch: 37 [418847/888800 47.12%] train loss: 1.4692401236970909e-05 \n",
      "epoch: 37 [419958/888800 47.25%] train loss: 1.4584518794436008e-05 \n",
      "epoch: 37 [421069/888800 47.38%] train loss: 1.4373561498359777e-05 \n",
      "epoch: 37 [422180/888800 47.50%] train loss: 1.3910980669606943e-05 \n",
      "epoch: 37 [423291/888800 47.62%] train loss: 1.6745600078138523e-05 \n",
      "epoch: 37 [424402/888800 47.75%] train loss: 1.4296303561422974e-05 \n",
      "epoch: 37 [425513/888800 47.88%] train loss: 1.5672783774789423e-05 \n",
      "epoch: 37 [426624/888800 48.00%] train loss: 1.4978118088038173e-05 \n",
      "epoch: 37 [427735/888800 48.12%] train loss: 1.3334058166947216e-05 \n",
      "epoch: 37 [428846/888800 48.25%] train loss: 1.3763831702817697e-05 \n",
      "epoch: 37 [429957/888800 48.38%] train loss: 1.394948958477471e-05 \n",
      "epoch: 37 [431068/888800 48.50%] train loss: 1.4845603800495155e-05 \n",
      "epoch: 37 [432179/888800 48.62%] train loss: 1.356121720164083e-05 \n",
      "epoch: 37 [433290/888800 48.75%] train loss: 1.44930490932893e-05 \n",
      "epoch: 37 [434401/888800 48.88%] train loss: 1.4425601875700522e-05 \n",
      "epoch: 37 [435512/888800 49.00%] train loss: 1.4563157492375467e-05 \n",
      "epoch: 37 [436623/888800 49.12%] train loss: 1.3638826203532517e-05 \n",
      "epoch: 37 [437734/888800 49.25%] train loss: 1.4594123967981432e-05 \n",
      "epoch: 37 [438845/888800 49.38%] train loss: 1.4097778148425277e-05 \n",
      "epoch: 37 [439956/888800 49.50%] train loss: 1.4281975381891243e-05 \n",
      "epoch: 37 [441067/888800 49.62%] train loss: 1.3790666343993507e-05 \n",
      "epoch: 37 [442178/888800 49.75%] train loss: 1.4189349712978583e-05 \n",
      "epoch: 37 [443289/888800 49.88%] train loss: 1.4267251572164241e-05 \n",
      "epoch: 37 [444400/888800 50.00%] train loss: 1.4762575119675603e-05 \n",
      "epoch: 37 [445511/888800 50.12%] train loss: 1.404344402544666e-05 \n",
      "epoch: 37 [446622/888800 50.25%] train loss: 1.5017225450719707e-05 \n",
      "epoch: 37 [447733/888800 50.38%] train loss: 1.4213379472494125e-05 \n",
      "epoch: 37 [448844/888800 50.50%] train loss: 1.4225105587684084e-05 \n",
      "epoch: 37 [449955/888800 50.62%] train loss: 1.3882881830795668e-05 \n",
      "epoch: 37 [451066/888800 50.75%] train loss: 1.4160821592668071e-05 \n",
      "epoch: 37 [452177/888800 50.88%] train loss: 1.4148393347568344e-05 \n",
      "epoch: 37 [453288/888800 51.00%] train loss: 1.402696670993464e-05 \n",
      "epoch: 37 [454399/888800 51.12%] train loss: 1.4564302546204999e-05 \n",
      "epoch: 37 [455510/888800 51.25%] train loss: 1.366906326438766e-05 \n",
      "epoch: 37 [456621/888800 51.38%] train loss: 1.3070566637907177e-05 \n",
      "epoch: 37 [457732/888800 51.50%] train loss: 1.3791520359518472e-05 \n",
      "epoch: 37 [458843/888800 51.62%] train loss: 1.5120682292035781e-05 \n",
      "epoch: 37 [459954/888800 51.75%] train loss: 1.590937790751923e-05 \n",
      "epoch: 37 [461065/888800 51.88%] train loss: 1.4804106285737362e-05 \n",
      "epoch: 37 [462176/888800 52.00%] train loss: 1.5302914107451215e-05 \n",
      "epoch: 37 [463287/888800 52.12%] train loss: 1.4002926036482677e-05 \n",
      "epoch: 37 [464398/888800 52.25%] train loss: 1.4933720194676425e-05 \n",
      "epoch: 37 [465509/888800 52.38%] train loss: 1.4225076483853627e-05 \n",
      "epoch: 37 [466620/888800 52.50%] train loss: 1.513699498900678e-05 \n",
      "epoch: 37 [467731/888800 52.62%] train loss: 1.3964249774289783e-05 \n",
      "epoch: 37 [468842/888800 52.75%] train loss: 1.5313187759602442e-05 \n",
      "epoch: 37 [469953/888800 52.88%] train loss: 1.4768365872441791e-05 \n",
      "epoch: 37 [471064/888800 53.00%] train loss: 1.566553328302689e-05 \n",
      "epoch: 37 [472175/888800 53.12%] train loss: 1.4062894479138777e-05 \n",
      "epoch: 37 [473286/888800 53.25%] train loss: 1.4817615920037497e-05 \n",
      "epoch: 37 [474397/888800 53.38%] train loss: 1.3450743608700577e-05 \n",
      "epoch: 37 [475508/888800 53.50%] train loss: 1.4769340850762092e-05 \n",
      "epoch: 37 [476619/888800 53.62%] train loss: 1.4483454833680298e-05 \n",
      "epoch: 37 [477730/888800 53.75%] train loss: 1.5356350559159182e-05 \n",
      "epoch: 37 [478841/888800 53.88%] train loss: 1.4346329407999292e-05 \n",
      "epoch: 37 [479952/888800 54.00%] train loss: 1.386768781230785e-05 \n",
      "epoch: 37 [481063/888800 54.12%] train loss: 1.3444585420074873e-05 \n",
      "epoch: 37 [482174/888800 54.25%] train loss: 1.5124261153687257e-05 \n",
      "epoch: 37 [483285/888800 54.38%] train loss: 1.4947672752896324e-05 \n",
      "epoch: 37 [484396/888800 54.50%] train loss: 1.4264945093600545e-05 \n",
      "epoch: 37 [485507/888800 54.62%] train loss: 1.3567025234806351e-05 \n",
      "epoch: 37 [486618/888800 54.75%] train loss: 1.4271791769715492e-05 \n",
      "epoch: 37 [487729/888800 54.88%] train loss: 1.3665987353306264e-05 \n",
      "epoch: 37 [488840/888800 55.00%] train loss: 1.3346494597499259e-05 \n",
      "epoch: 37 [489951/888800 55.12%] train loss: 1.45776921272045e-05 \n",
      "epoch: 37 [491062/888800 55.25%] train loss: 1.4864344848319888e-05 \n",
      "epoch: 37 [492173/888800 55.38%] train loss: 1.424206311639864e-05 \n",
      "epoch: 37 [493284/888800 55.50%] train loss: 1.4040049791219644e-05 \n",
      "epoch: 37 [494395/888800 55.62%] train loss: 1.397079904563725e-05 \n",
      "epoch: 37 [495506/888800 55.75%] train loss: 1.3772624697594438e-05 \n",
      "epoch: 37 [496617/888800 55.88%] train loss: 1.4579358321498148e-05 \n",
      "epoch: 37 [497728/888800 56.00%] train loss: 1.4330300473375246e-05 \n",
      "epoch: 37 [498839/888800 56.12%] train loss: 1.4344146620715037e-05 \n",
      "epoch: 37 [499950/888800 56.25%] train loss: 1.4660769920737948e-05 \n",
      "epoch: 37 [501061/888800 56.38%] train loss: 1.422724290023325e-05 \n",
      "epoch: 37 [502172/888800 56.50%] train loss: 1.5043057828734163e-05 \n",
      "epoch: 37 [503283/888800 56.62%] train loss: 1.4388770068762824e-05 \n",
      "epoch: 37 [504394/888800 56.75%] train loss: 1.3665173355548177e-05 \n",
      "epoch: 37 [505505/888800 56.88%] train loss: 1.4497485608444549e-05 \n",
      "epoch: 37 [506616/888800 57.00%] train loss: 1.4502617887046654e-05 \n",
      "epoch: 37 [507727/888800 57.12%] train loss: 1.6124327885336243e-05 \n",
      "epoch: 37 [508838/888800 57.25%] train loss: 1.4609725440095644e-05 \n",
      "epoch: 37 [509949/888800 57.38%] train loss: 1.4427307178266346e-05 \n",
      "epoch: 37 [511060/888800 57.50%] train loss: 1.4521006050927099e-05 \n",
      "epoch: 37 [512171/888800 57.62%] train loss: 1.4538165487465449e-05 \n",
      "epoch: 37 [513282/888800 57.75%] train loss: 1.4939670109015424e-05 \n",
      "epoch: 37 [514393/888800 57.88%] train loss: 1.3948918422101997e-05 \n",
      "epoch: 37 [515504/888800 58.00%] train loss: 1.4654128790425602e-05 \n",
      "epoch: 37 [516615/888800 58.12%] train loss: 1.4030235433892813e-05 \n",
      "epoch: 37 [517726/888800 58.25%] train loss: 1.5004035958554596e-05 \n",
      "epoch: 37 [518837/888800 58.38%] train loss: 1.5276249541784637e-05 \n",
      "epoch: 37 [519948/888800 58.50%] train loss: 1.4033430488780141e-05 \n",
      "epoch: 37 [521059/888800 58.62%] train loss: 1.4512869711325038e-05 \n",
      "epoch: 37 [522170/888800 58.75%] train loss: 1.5165807781158946e-05 \n",
      "epoch: 37 [523281/888800 58.88%] train loss: 1.3330338333616965e-05 \n",
      "epoch: 37 [524392/888800 59.00%] train loss: 1.7380529243382625e-05 \n",
      "epoch: 37 [525503/888800 59.12%] train loss: 1.4214613656804431e-05 \n",
      "epoch: 37 [526614/888800 59.25%] train loss: 1.6066336684161797e-05 \n",
      "epoch: 37 [527725/888800 59.38%] train loss: 1.4292793821368832e-05 \n",
      "epoch: 37 [528836/888800 59.50%] train loss: 1.4009115147928242e-05 \n",
      "epoch: 37 [529947/888800 59.62%] train loss: 1.5671954315621406e-05 \n",
      "epoch: 37 [531058/888800 59.75%] train loss: 1.4679601918032859e-05 \n",
      "epoch: 37 [532169/888800 59.88%] train loss: 1.5682171579101123e-05 \n",
      "epoch: 37 [533280/888800 60.00%] train loss: 1.4597012523154262e-05 \n",
      "epoch: 37 [534391/888800 60.12%] train loss: 1.5278208593372256e-05 \n",
      "epoch: 37 [535502/888800 60.25%] train loss: 1.3611785107059404e-05 \n",
      "epoch: 37 [536613/888800 60.38%] train loss: 1.6515641618752852e-05 \n",
      "epoch: 37 [537724/888800 60.50%] train loss: 1.4761271813767962e-05 \n",
      "epoch: 37 [538835/888800 60.62%] train loss: 1.5372092093457468e-05 \n",
      "epoch: 37 [539946/888800 60.75%] train loss: 1.5175850421655923e-05 \n",
      "epoch: 37 [541057/888800 60.88%] train loss: 1.5142650227062404e-05 \n",
      "epoch: 37 [542168/888800 61.00%] train loss: 1.5709623767179437e-05 \n",
      "epoch: 37 [543279/888800 61.12%] train loss: 1.5214935956464615e-05 \n",
      "epoch: 37 [544390/888800 61.25%] train loss: 1.4661157365480904e-05 \n",
      "epoch: 37 [545501/888800 61.38%] train loss: 1.558953954372555e-05 \n",
      "epoch: 37 [546612/888800 61.50%] train loss: 1.342059658782091e-05 \n",
      "epoch: 37 [547723/888800 61.62%] train loss: 1.4159750207909383e-05 \n",
      "epoch: 37 [548834/888800 61.75%] train loss: 1.4276590263762046e-05 \n",
      "epoch: 37 [549945/888800 61.88%] train loss: 1.4564520824933425e-05 \n",
      "epoch: 37 [551056/888800 62.00%] train loss: 1.3391070751822554e-05 \n",
      "epoch: 37 [552167/888800 62.12%] train loss: 1.4682599612569902e-05 \n",
      "epoch: 37 [553278/888800 62.25%] train loss: 1.3046568710706197e-05 \n",
      "epoch: 37 [554389/888800 62.38%] train loss: 1.4432251191465184e-05 \n",
      "epoch: 37 [555500/888800 62.50%] train loss: 1.2979678103874903e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [556611/888800 62.62%] train loss: 1.6467331079184078e-05 \n",
      "epoch: 37 [557722/888800 62.75%] train loss: 1.4251143511501141e-05 \n",
      "epoch: 37 [558833/888800 62.88%] train loss: 1.4612510312872473e-05 \n",
      "epoch: 37 [559944/888800 63.00%] train loss: 1.4034933883522172e-05 \n",
      "epoch: 37 [561055/888800 63.12%] train loss: 1.2496766430558637e-05 \n",
      "epoch: 37 [562166/888800 63.25%] train loss: 1.4321367416414432e-05 \n",
      "epoch: 37 [563277/888800 63.38%] train loss: 1.309584786213236e-05 \n",
      "epoch: 37 [564388/888800 63.50%] train loss: 1.471206996939145e-05 \n",
      "epoch: 37 [565499/888800 63.62%] train loss: 1.3381660210143309e-05 \n",
      "epoch: 37 [566610/888800 63.75%] train loss: 1.3831765500071924e-05 \n",
      "epoch: 37 [567721/888800 63.88%] train loss: 1.3423385098576546e-05 \n",
      "epoch: 37 [568832/888800 64.00%] train loss: 1.5051226000650786e-05 \n",
      "epoch: 37 [569943/888800 64.12%] train loss: 1.4103074136073701e-05 \n",
      "epoch: 37 [571054/888800 64.25%] train loss: 1.4523878235195298e-05 \n",
      "epoch: 37 [572165/888800 64.38%] train loss: 1.4143026419333182e-05 \n",
      "epoch: 37 [573276/888800 64.50%] train loss: 1.4308143363450654e-05 \n",
      "epoch: 37 [574387/888800 64.62%] train loss: 1.3918615877628326e-05 \n",
      "epoch: 37 [575498/888800 64.75%] train loss: 1.4072547855903395e-05 \n",
      "epoch: 37 [576609/888800 64.88%] train loss: 1.3641589248436503e-05 \n",
      "epoch: 37 [577720/888800 65.00%] train loss: 1.3208002201281488e-05 \n",
      "epoch: 37 [578831/888800 65.12%] train loss: 1.355795484414557e-05 \n",
      "epoch: 37 [579942/888800 65.25%] train loss: 1.438656181562692e-05 \n",
      "epoch: 37 [581053/888800 65.38%] train loss: 1.544444967294112e-05 \n",
      "epoch: 37 [582164/888800 65.50%] train loss: 1.3673758985532913e-05 \n",
      "epoch: 37 [583275/888800 65.62%] train loss: 1.3806064089294523e-05 \n",
      "epoch: 37 [584386/888800 65.75%] train loss: 1.4400588042917661e-05 \n",
      "epoch: 37 [585497/888800 65.88%] train loss: 1.4731906048837118e-05 \n",
      "epoch: 37 [586608/888800 66.00%] train loss: 1.4083207133808173e-05 \n",
      "epoch: 37 [587719/888800 66.12%] train loss: 1.4103413377597462e-05 \n",
      "epoch: 37 [588830/888800 66.25%] train loss: 1.50870400830172e-05 \n",
      "epoch: 37 [589941/888800 66.38%] train loss: 1.5401705240947194e-05 \n",
      "epoch: 37 [591052/888800 66.50%] train loss: 1.3694776498596184e-05 \n",
      "epoch: 37 [592163/888800 66.62%] train loss: 1.4537994502461515e-05 \n",
      "epoch: 37 [593274/888800 66.75%] train loss: 1.4342180293169804e-05 \n",
      "epoch: 37 [594385/888800 66.88%] train loss: 1.4320492482511327e-05 \n",
      "epoch: 37 [595496/888800 67.00%] train loss: 1.3762444723397493e-05 \n",
      "epoch: 37 [596607/888800 67.12%] train loss: 1.3217069863458164e-05 \n",
      "epoch: 37 [597718/888800 67.25%] train loss: 1.610241633898113e-05 \n",
      "epoch: 37 [598829/888800 67.38%] train loss: 1.3439086615107954e-05 \n",
      "epoch: 37 [599940/888800 67.50%] train loss: 1.2479717042879201e-05 \n",
      "epoch: 37 [601051/888800 67.62%] train loss: 1.4554977497027721e-05 \n",
      "epoch: 37 [602162/888800 67.75%] train loss: 1.4512455891235732e-05 \n",
      "epoch: 37 [603273/888800 67.88%] train loss: 1.3365986887947656e-05 \n",
      "epoch: 37 [604384/888800 68.00%] train loss: 1.5154941138462164e-05 \n",
      "epoch: 37 [605495/888800 68.12%] train loss: 1.3562909771280829e-05 \n",
      "epoch: 37 [606606/888800 68.25%] train loss: 1.4222622667148244e-05 \n",
      "epoch: 37 [607717/888800 68.38%] train loss: 1.3586403838417027e-05 \n",
      "epoch: 37 [608828/888800 68.50%] train loss: 1.469306880608201e-05 \n",
      "epoch: 37 [609939/888800 68.62%] train loss: 1.3769374163530301e-05 \n",
      "epoch: 37 [611050/888800 68.75%] train loss: 1.2559285096358508e-05 \n",
      "epoch: 37 [612161/888800 68.88%] train loss: 1.4068963537283707e-05 \n",
      "epoch: 37 [613272/888800 69.00%] train loss: 1.4034741070645396e-05 \n",
      "epoch: 37 [614383/888800 69.12%] train loss: 1.4365718925546389e-05 \n",
      "epoch: 37 [615494/888800 69.25%] train loss: 1.3971398402645718e-05 \n",
      "epoch: 37 [616605/888800 69.38%] train loss: 1.4371727957041003e-05 \n",
      "epoch: 37 [617716/888800 69.50%] train loss: 1.421400793333305e-05 \n",
      "epoch: 37 [618827/888800 69.62%] train loss: 1.4613013263442554e-05 \n",
      "epoch: 37 [619938/888800 69.75%] train loss: 1.518896078778198e-05 \n",
      "epoch: 37 [621049/888800 69.88%] train loss: 1.4041496797290165e-05 \n",
      "epoch: 37 [622160/888800 70.00%] train loss: 1.3233695426606573e-05 \n",
      "epoch: 37 [623271/888800 70.12%] train loss: 1.368705397908343e-05 \n",
      "epoch: 37 [624382/888800 70.25%] train loss: 1.447105660190573e-05 \n",
      "epoch: 37 [625493/888800 70.38%] train loss: 1.2758256161760073e-05 \n",
      "epoch: 37 [626604/888800 70.50%] train loss: 1.4629847100877669e-05 \n",
      "epoch: 37 [627715/888800 70.62%] train loss: 1.3688378203369211e-05 \n",
      "epoch: 37 [628826/888800 70.75%] train loss: 1.3348992069950327e-05 \n",
      "epoch: 37 [629937/888800 70.88%] train loss: 1.4144002307148185e-05 \n",
      "epoch: 37 [631048/888800 71.00%] train loss: 1.3805237358610611e-05 \n",
      "epoch: 37 [632159/888800 71.12%] train loss: 1.441996846551774e-05 \n",
      "epoch: 37 [633270/888800 71.25%] train loss: 1.467092806706205e-05 \n",
      "epoch: 37 [634381/888800 71.38%] train loss: 1.3881009181204718e-05 \n",
      "epoch: 37 [635492/888800 71.50%] train loss: 1.224758307216689e-05 \n",
      "epoch: 37 [636603/888800 71.62%] train loss: 1.3710193343285937e-05 \n",
      "epoch: 37 [637714/888800 71.75%] train loss: 1.464096931158565e-05 \n",
      "epoch: 37 [638825/888800 71.88%] train loss: 1.4348789591167588e-05 \n",
      "epoch: 37 [639936/888800 72.00%] train loss: 1.5077159332577139e-05 \n",
      "epoch: 37 [641047/888800 72.12%] train loss: 1.4054464372748043e-05 \n",
      "epoch: 37 [642158/888800 72.25%] train loss: 1.4820375326962676e-05 \n",
      "epoch: 37 [643269/888800 72.38%] train loss: 1.4678454135719221e-05 \n",
      "epoch: 37 [644380/888800 72.50%] train loss: 1.3578975085692946e-05 \n",
      "epoch: 37 [645491/888800 72.62%] train loss: 1.4052499864192214e-05 \n",
      "epoch: 37 [646602/888800 72.75%] train loss: 1.3545963156502694e-05 \n",
      "epoch: 37 [647713/888800 72.88%] train loss: 1.4323662981041707e-05 \n",
      "epoch: 37 [648824/888800 73.00%] train loss: 1.5075032933964394e-05 \n",
      "epoch: 37 [649935/888800 73.12%] train loss: 1.2731852621072903e-05 \n",
      "epoch: 37 [651046/888800 73.25%] train loss: 1.4040640053281095e-05 \n",
      "epoch: 37 [652157/888800 73.38%] train loss: 1.4323583855002653e-05 \n",
      "epoch: 37 [653268/888800 73.50%] train loss: 1.4767942957405467e-05 \n",
      "epoch: 37 [654379/888800 73.62%] train loss: 1.4965747141104657e-05 \n",
      "epoch: 37 [655490/888800 73.75%] train loss: 1.3967924132884946e-05 \n",
      "epoch: 37 [656601/888800 73.88%] train loss: 1.3983111784909852e-05 \n",
      "epoch: 37 [657712/888800 74.00%] train loss: 1.4801734323555138e-05 \n",
      "epoch: 37 [658823/888800 74.12%] train loss: 1.4259196177590638e-05 \n",
      "epoch: 37 [659934/888800 74.25%] train loss: 1.3754556675849017e-05 \n",
      "epoch: 37 [661045/888800 74.38%] train loss: 1.360528858640464e-05 \n",
      "epoch: 37 [662156/888800 74.50%] train loss: 1.4807405932515394e-05 \n",
      "epoch: 37 [663267/888800 74.62%] train loss: 1.4110216397966724e-05 \n",
      "epoch: 37 [664378/888800 74.75%] train loss: 1.3490490346157458e-05 \n",
      "epoch: 37 [665489/888800 74.88%] train loss: 1.4093930076342076e-05 \n",
      "epoch: 37 [666600/888800 75.00%] train loss: 1.3968646271678153e-05 \n",
      "epoch: 37 [667711/888800 75.12%] train loss: 1.383674407406943e-05 \n",
      "epoch: 37 [668822/888800 75.25%] train loss: 1.4106365597399417e-05 \n",
      "epoch: 37 [669933/888800 75.38%] train loss: 1.5045039617689326e-05 \n",
      "epoch: 37 [671044/888800 75.50%] train loss: 1.4912595361238346e-05 \n",
      "epoch: 37 [672155/888800 75.62%] train loss: 1.4437644495046698e-05 \n",
      "epoch: 37 [673266/888800 75.75%] train loss: 1.3353605936572421e-05 \n",
      "epoch: 37 [674377/888800 75.88%] train loss: 1.3936452887719497e-05 \n",
      "epoch: 37 [675488/888800 76.00%] train loss: 1.425469326932216e-05 \n",
      "epoch: 37 [676599/888800 76.12%] train loss: 1.4757230019313283e-05 \n",
      "epoch: 37 [677710/888800 76.25%] train loss: 1.4931959412933793e-05 \n",
      "epoch: 37 [678821/888800 76.38%] train loss: 1.3838061022397596e-05 \n",
      "epoch: 37 [679932/888800 76.50%] train loss: 1.4158225894789211e-05 \n",
      "epoch: 37 [681043/888800 76.62%] train loss: 1.3490202036336996e-05 \n",
      "epoch: 37 [682154/888800 76.75%] train loss: 1.42419912663172e-05 \n",
      "epoch: 37 [683265/888800 76.88%] train loss: 1.3325772670214064e-05 \n",
      "epoch: 37 [684376/888800 77.00%] train loss: 1.439021980331745e-05 \n",
      "epoch: 37 [685487/888800 77.12%] train loss: 1.2874413187091704e-05 \n",
      "epoch: 37 [686598/888800 77.25%] train loss: 1.634037289477419e-05 \n",
      "epoch: 37 [687709/888800 77.38%] train loss: 1.3659546311828308e-05 \n",
      "epoch: 37 [688820/888800 77.50%] train loss: 1.5271107258740813e-05 \n",
      "epoch: 37 [689931/888800 77.62%] train loss: 1.4748939065611921e-05 \n",
      "epoch: 37 [691042/888800 77.75%] train loss: 1.4299826943897642e-05 \n",
      "epoch: 37 [692153/888800 77.88%] train loss: 1.4445219676417764e-05 \n",
      "epoch: 37 [693264/888800 78.00%] train loss: 1.539110962767154e-05 \n",
      "epoch: 37 [694375/888800 78.12%] train loss: 1.4128624570730608e-05 \n",
      "epoch: 37 [695486/888800 78.25%] train loss: 1.5390491171274334e-05 \n",
      "epoch: 37 [696597/888800 78.38%] train loss: 1.4192578419169877e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [697708/888800 78.50%] train loss: 1.4979469597165007e-05 \n",
      "epoch: 37 [698819/888800 78.62%] train loss: 1.3918754120822996e-05 \n",
      "epoch: 37 [699930/888800 78.75%] train loss: 1.3950188986200374e-05 \n",
      "epoch: 37 [701041/888800 78.88%] train loss: 1.4706107322126627e-05 \n",
      "epoch: 37 [702152/888800 79.00%] train loss: 1.3243458852230106e-05 \n",
      "epoch: 37 [703263/888800 79.12%] train loss: 1.4688191185996402e-05 \n",
      "epoch: 37 [704374/888800 79.25%] train loss: 1.402907491865335e-05 \n",
      "epoch: 37 [705485/888800 79.38%] train loss: 1.5992654880392365e-05 \n",
      "epoch: 37 [706596/888800 79.50%] train loss: 1.4266911421145778e-05 \n",
      "epoch: 37 [707707/888800 79.62%] train loss: 1.5478208297281526e-05 \n",
      "epoch: 37 [708818/888800 79.75%] train loss: 1.4725097571499646e-05 \n",
      "epoch: 37 [709929/888800 79.88%] train loss: 1.4969415133236907e-05 \n",
      "epoch: 37 [711040/888800 80.00%] train loss: 1.4523572644975502e-05 \n",
      "epoch: 37 [712151/888800 80.12%] train loss: 1.551629975438118e-05 \n",
      "epoch: 37 [713262/888800 80.25%] train loss: 1.464699198550079e-05 \n",
      "epoch: 37 [714373/888800 80.38%] train loss: 1.369092206005007e-05 \n",
      "epoch: 37 [715484/888800 80.50%] train loss: 1.3369351108849514e-05 \n",
      "epoch: 37 [716595/888800 80.62%] train loss: 1.462586715206271e-05 \n",
      "epoch: 37 [717706/888800 80.75%] train loss: 1.30487760543474e-05 \n",
      "epoch: 37 [718817/888800 80.88%] train loss: 1.361133126920322e-05 \n",
      "epoch: 37 [719928/888800 81.00%] train loss: 1.305341902479995e-05 \n",
      "epoch: 37 [721039/888800 81.12%] train loss: 1.4778639524593018e-05 \n",
      "epoch: 37 [722150/888800 81.25%] train loss: 1.3693441360373981e-05 \n",
      "epoch: 37 [723261/888800 81.38%] train loss: 1.4336640560941305e-05 \n",
      "epoch: 37 [724372/888800 81.50%] train loss: 1.4593058949685656e-05 \n",
      "epoch: 37 [725483/888800 81.62%] train loss: 1.3457321074383799e-05 \n",
      "epoch: 37 [726594/888800 81.75%] train loss: 1.4510786968457978e-05 \n",
      "epoch: 37 [727705/888800 81.88%] train loss: 1.3779837900074199e-05 \n",
      "epoch: 37 [728816/888800 82.00%] train loss: 1.4676834325655364e-05 \n",
      "epoch: 37 [729927/888800 82.12%] train loss: 1.4872706742607988e-05 \n",
      "epoch: 37 [731038/888800 82.25%] train loss: 1.370919471810339e-05 \n",
      "epoch: 37 [732149/888800 82.38%] train loss: 1.4305064723885152e-05 \n",
      "epoch: 37 [733260/888800 82.50%] train loss: 1.4806168110226281e-05 \n",
      "epoch: 37 [734371/888800 82.62%] train loss: 1.3024971849517897e-05 \n",
      "epoch: 37 [735482/888800 82.75%] train loss: 1.3262320862850174e-05 \n",
      "epoch: 37 [736593/888800 82.88%] train loss: 1.4315777661977336e-05 \n",
      "epoch: 37 [737704/888800 83.00%] train loss: 1.4538815776177216e-05 \n",
      "epoch: 37 [738815/888800 83.12%] train loss: 1.4090399417909794e-05 \n",
      "epoch: 37 [739926/888800 83.25%] train loss: 1.4126737369224429e-05 \n",
      "epoch: 37 [741037/888800 83.38%] train loss: 1.4783740880375262e-05 \n",
      "epoch: 37 [742148/888800 83.50%] train loss: 1.4551094864145853e-05 \n",
      "epoch: 37 [743259/888800 83.62%] train loss: 1.4528196516039316e-05 \n",
      "epoch: 37 [744370/888800 83.75%] train loss: 1.4189020475896541e-05 \n",
      "epoch: 37 [745481/888800 83.88%] train loss: 1.4373561498359777e-05 \n",
      "epoch: 37 [746592/888800 84.00%] train loss: 1.4131181160337292e-05 \n",
      "epoch: 37 [747703/888800 84.12%] train loss: 1.4366205505211838e-05 \n",
      "epoch: 37 [748814/888800 84.25%] train loss: 1.451621574233286e-05 \n",
      "epoch: 37 [749925/888800 84.38%] train loss: 1.4934328646631911e-05 \n",
      "epoch: 37 [751036/888800 84.50%] train loss: 1.4330920748761855e-05 \n",
      "epoch: 37 [752147/888800 84.62%] train loss: 1.3628431588585954e-05 \n",
      "epoch: 37 [753258/888800 84.75%] train loss: 1.2880352187494282e-05 \n",
      "epoch: 37 [754369/888800 84.88%] train loss: 1.452423293812899e-05 \n",
      "epoch: 37 [755480/888800 85.00%] train loss: 1.3442836461763363e-05 \n",
      "epoch: 37 [756591/888800 85.12%] train loss: 1.5228272786771413e-05 \n",
      "epoch: 37 [757702/888800 85.25%] train loss: 1.4483949598798063e-05 \n",
      "epoch: 37 [758813/888800 85.38%] train loss: 1.4039330380910542e-05 \n",
      "epoch: 37 [759924/888800 85.50%] train loss: 1.4591955732612405e-05 \n",
      "epoch: 37 [761035/888800 85.62%] train loss: 1.568781226524152e-05 \n",
      "epoch: 37 [762146/888800 85.75%] train loss: 1.4906077012710739e-05 \n",
      "epoch: 37 [763257/888800 85.88%] train loss: 1.3420129107544199e-05 \n",
      "epoch: 37 [764368/888800 86.00%] train loss: 1.5990242900443263e-05 \n",
      "epoch: 37 [765479/888800 86.12%] train loss: 1.2863739357271697e-05 \n",
      "epoch: 37 [766590/888800 86.25%] train loss: 1.4105648006079718e-05 \n",
      "epoch: 37 [767701/888800 86.38%] train loss: 1.4039147572475486e-05 \n",
      "epoch: 37 [768812/888800 86.50%] train loss: 1.3941892575530801e-05 \n",
      "epoch: 37 [769923/888800 86.62%] train loss: 1.365057050861651e-05 \n",
      "epoch: 37 [771034/888800 86.75%] train loss: 1.4483221093541943e-05 \n",
      "epoch: 37 [772145/888800 86.88%] train loss: 1.5320536476792768e-05 \n",
      "epoch: 37 [773256/888800 87.00%] train loss: 1.4249817468225956e-05 \n",
      "epoch: 37 [774367/888800 87.12%] train loss: 1.3126483281666879e-05 \n",
      "epoch: 37 [775478/888800 87.25%] train loss: 1.4239136362448335e-05 \n",
      "epoch: 37 [776589/888800 87.38%] train loss: 1.3442510862660129e-05 \n",
      "epoch: 37 [777700/888800 87.50%] train loss: 1.3442460840451531e-05 \n",
      "epoch: 37 [778811/888800 87.62%] train loss: 1.3675230547960382e-05 \n",
      "epoch: 37 [779922/888800 87.75%] train loss: 1.4588969861506484e-05 \n",
      "epoch: 37 [781033/888800 87.88%] train loss: 1.3935627066530287e-05 \n",
      "epoch: 37 [782144/888800 88.00%] train loss: 1.4242951692722272e-05 \n",
      "epoch: 37 [783255/888800 88.12%] train loss: 1.4474952877208125e-05 \n",
      "epoch: 37 [784366/888800 88.25%] train loss: 1.3129739272699226e-05 \n",
      "epoch: 37 [785477/888800 88.38%] train loss: 1.3765683434030507e-05 \n",
      "epoch: 37 [786588/888800 88.50%] train loss: 1.426472681487212e-05 \n",
      "epoch: 37 [787699/888800 88.62%] train loss: 1.4171182556310669e-05 \n",
      "epoch: 37 [788810/888800 88.75%] train loss: 1.4475762327492703e-05 \n",
      "epoch: 37 [789921/888800 88.88%] train loss: 1.3138552276359405e-05 \n",
      "epoch: 37 [791032/888800 89.00%] train loss: 1.4292739251686726e-05 \n",
      "epoch: 37 [792143/888800 89.12%] train loss: 1.4268301129050087e-05 \n",
      "epoch: 37 [793254/888800 89.25%] train loss: 1.5077458556334022e-05 \n",
      "epoch: 37 [794365/888800 89.38%] train loss: 1.3819383639201988e-05 \n",
      "epoch: 37 [795476/888800 89.50%] train loss: 1.4505904800898861e-05 \n",
      "epoch: 37 [796587/888800 89.62%] train loss: 1.272112422157079e-05 \n",
      "epoch: 37 [797698/888800 89.75%] train loss: 1.3382827091845684e-05 \n",
      "epoch: 37 [798809/888800 89.88%] train loss: 1.3250368283479474e-05 \n",
      "epoch: 37 [799920/888800 90.00%] train loss: 1.3384469639277086e-05 \n",
      "epoch: 37 [801031/888800 90.12%] train loss: 1.3583621694124304e-05 \n",
      "epoch: 37 [802142/888800 90.25%] train loss: 1.4787116015213542e-05 \n",
      "epoch: 37 [803253/888800 90.38%] train loss: 1.3676751223101746e-05 \n",
      "epoch: 37 [804364/888800 90.50%] train loss: 1.4281678886618465e-05 \n",
      "epoch: 37 [805475/888800 90.62%] train loss: 1.3675140507984906e-05 \n",
      "epoch: 37 [806586/888800 90.75%] train loss: 1.3329982721188571e-05 \n",
      "epoch: 37 [807697/888800 90.88%] train loss: 1.319120838161325e-05 \n",
      "epoch: 37 [808808/888800 91.00%] train loss: 1.4656816347269341e-05 \n",
      "epoch: 37 [809919/888800 91.12%] train loss: 1.45694330058177e-05 \n",
      "epoch: 37 [811030/888800 91.25%] train loss: 1.3943784324510489e-05 \n",
      "epoch: 37 [812141/888800 91.38%] train loss: 1.4577812180505134e-05 \n",
      "epoch: 37 [813252/888800 91.50%] train loss: 1.3511905308405403e-05 \n",
      "epoch: 37 [814363/888800 91.62%] train loss: 1.3656314877152909e-05 \n",
      "epoch: 37 [815474/888800 91.75%] train loss: 1.412111032550456e-05 \n",
      "epoch: 37 [816585/888800 91.88%] train loss: 1.3255852536531165e-05 \n",
      "epoch: 37 [817696/888800 92.00%] train loss: 1.3609385860036127e-05 \n",
      "epoch: 37 [818807/888800 92.12%] train loss: 1.4246561477193609e-05 \n",
      "epoch: 37 [819918/888800 92.25%] train loss: 1.3547488379117567e-05 \n",
      "epoch: 37 [821029/888800 92.38%] train loss: 1.403905753250001e-05 \n",
      "epoch: 37 [822140/888800 92.50%] train loss: 1.386325584462611e-05 \n",
      "epoch: 37 [823251/888800 92.62%] train loss: 1.5186560631264001e-05 \n",
      "epoch: 37 [824362/888800 92.75%] train loss: 1.3671995475306176e-05 \n",
      "epoch: 37 [825473/888800 92.88%] train loss: 1.5370855180663057e-05 \n",
      "epoch: 37 [826584/888800 93.00%] train loss: 1.4211737834557425e-05 \n",
      "epoch: 37 [827695/888800 93.12%] train loss: 1.5595420336467214e-05 \n",
      "epoch: 37 [828806/888800 93.25%] train loss: 1.4822719094809145e-05 \n",
      "epoch: 37 [829917/888800 93.38%] train loss: 1.5231178622343577e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 [831028/888800 93.50%] train loss: 1.6228974345722236e-05 \n",
      "epoch: 37 [832139/888800 93.62%] train loss: 1.4116945749265142e-05 \n",
      "epoch: 37 [833250/888800 93.75%] train loss: 1.5008498849056195e-05 \n",
      "epoch: 37 [834361/888800 93.88%] train loss: 1.574839188833721e-05 \n",
      "epoch: 37 [835472/888800 94.00%] train loss: 1.4443353393289726e-05 \n",
      "epoch: 37 [836583/888800 94.12%] train loss: 1.4810181710345205e-05 \n",
      "epoch: 37 [837694/888800 94.25%] train loss: 1.4847825696051586e-05 \n",
      "epoch: 37 [838805/888800 94.38%] train loss: 1.3669563486473635e-05 \n",
      "epoch: 37 [839916/888800 94.50%] train loss: 1.4969506082707085e-05 \n",
      "epoch: 37 [841027/888800 94.62%] train loss: 1.4788785847485997e-05 \n",
      "epoch: 37 [842138/888800 94.75%] train loss: 1.3599285011878237e-05 \n",
      "epoch: 37 [843249/888800 94.88%] train loss: 1.512307244411204e-05 \n",
      "epoch: 37 [844360/888800 95.00%] train loss: 1.5449393686139956e-05 \n",
      "epoch: 37 [845471/888800 95.12%] train loss: 1.4403734894585796e-05 \n",
      "epoch: 37 [846582/888800 95.25%] train loss: 1.477573187003145e-05 \n",
      "epoch: 37 [847693/888800 95.38%] train loss: 1.3265973393572494e-05 \n",
      "epoch: 37 [848804/888800 95.50%] train loss: 1.3741181646764744e-05 \n",
      "epoch: 37 [849915/888800 95.62%] train loss: 1.5373589121736586e-05 \n",
      "epoch: 37 [851026/888800 95.75%] train loss: 1.4227209248929285e-05 \n",
      "epoch: 37 [852137/888800 95.88%] train loss: 1.4065417417441495e-05 \n",
      "epoch: 37 [853248/888800 96.00%] train loss: 1.318607792200055e-05 \n",
      "epoch: 37 [854359/888800 96.12%] train loss: 1.4422393178392667e-05 \n",
      "epoch: 37 [855470/888800 96.25%] train loss: 1.554613481857814e-05 \n",
      "epoch: 37 [856581/888800 96.38%] train loss: 1.4701759937452152e-05 \n",
      "epoch: 37 [857692/888800 96.50%] train loss: 1.5121604519663379e-05 \n",
      "epoch: 37 [858803/888800 96.62%] train loss: 1.440086907678051e-05 \n",
      "epoch: 37 [859914/888800 96.75%] train loss: 1.379898822051473e-05 \n",
      "epoch: 37 [861025/888800 96.88%] train loss: 1.481954677728936e-05 \n",
      "epoch: 37 [862136/888800 97.00%] train loss: 1.3611698705062736e-05 \n",
      "epoch: 37 [863247/888800 97.12%] train loss: 1.4856489542580675e-05 \n",
      "epoch: 37 [864358/888800 97.25%] train loss: 1.3432163541438058e-05 \n",
      "epoch: 37 [865469/888800 97.38%] train loss: 1.353901006950764e-05 \n",
      "epoch: 37 [866580/888800 97.50%] train loss: 1.3717846741201356e-05 \n",
      "epoch: 37 [867691/888800 97.62%] train loss: 1.4580350580217782e-05 \n",
      "epoch: 37 [868802/888800 97.75%] train loss: 1.4403414752450772e-05 \n",
      "epoch: 37 [869913/888800 97.88%] train loss: 1.4409027244255412e-05 \n",
      "epoch: 37 [871024/888800 98.00%] train loss: 1.4174729585647583e-05 \n",
      "epoch: 37 [872135/888800 98.12%] train loss: 1.5260382497217506e-05 \n",
      "epoch: 37 [873246/888800 98.25%] train loss: 1.4909970559529029e-05 \n",
      "epoch: 37 [874357/888800 98.38%] train loss: 1.3755766303802375e-05 \n",
      "epoch: 37 [875468/888800 98.50%] train loss: 1.3330392903299071e-05 \n",
      "epoch: 37 [876579/888800 98.62%] train loss: 1.429834355803905e-05 \n",
      "epoch: 37 [877690/888800 98.75%] train loss: 1.5999827155610546e-05 \n",
      "epoch: 37 [878801/888800 98.88%] train loss: 1.3018502613704186e-05 \n",
      "epoch: 37 [879912/888800 99.00%] train loss: 1.488604539190419e-05 \n",
      "epoch: 37 [881023/888800 99.12%] train loss: 1.3925585335528012e-05 \n",
      "epoch: 37 [882134/888800 99.25%] train loss: 1.4512615052808542e-05 \n",
      "epoch: 37 [883245/888800 99.38%] train loss: 1.3180128917156253e-05 \n",
      "epoch: 37 [884356/888800 99.50%] train loss: 1.6065987438196316e-05 \n",
      "epoch: 37 [885467/888800 99.62%] train loss: 1.4644971997768153e-05 \n",
      "epoch: 37 [886578/888800 99.75%] train loss: 1.3575941011367831e-05 \n",
      "epoch: 37 [887689/888800 99.88%] train loss: 1.4972929420764558e-05 \n",
      "epoch: 38 [0/888800 0.00%] train loss: 1.349573904008139e-05 \n",
      "epoch: 38 [1111/888800 0.12%] train loss: 1.4126606401987374e-05 \n",
      "epoch: 38 [2222/888800 0.25%] train loss: 1.3655285329150502e-05 \n",
      "epoch: 38 [3333/888800 0.38%] train loss: 1.3359151125769131e-05 \n",
      "epoch: 38 [4444/888800 0.50%] train loss: 1.4870457562210504e-05 \n",
      "epoch: 38 [5555/888800 0.62%] train loss: 1.4860253941151313e-05 \n",
      "epoch: 38 [6666/888800 0.75%] train loss: 1.4097632629272994e-05 \n",
      "epoch: 38 [7777/888800 0.88%] train loss: 1.3704167940886691e-05 \n",
      "epoch: 38 [8888/888800 1.00%] train loss: 1.4719048522238154e-05 \n",
      "epoch: 38 [9999/888800 1.12%] train loss: 1.4718229977006558e-05 \n",
      "epoch: 38 [11110/888800 1.25%] train loss: 1.3976476111565717e-05 \n",
      "epoch: 38 [12221/888800 1.38%] train loss: 1.4060847206565086e-05 \n",
      "epoch: 38 [13332/888800 1.50%] train loss: 1.4316968190541957e-05 \n",
      "epoch: 38 [14443/888800 1.62%] train loss: 1.3466552445606794e-05 \n",
      "epoch: 38 [15554/888800 1.75%] train loss: 1.3842281987308525e-05 \n",
      "epoch: 38 [16665/888800 1.88%] train loss: 1.4523364370688796e-05 \n",
      "epoch: 38 [17776/888800 2.00%] train loss: 1.4360481145558879e-05 \n",
      "epoch: 38 [18887/888800 2.12%] train loss: 1.350008915323997e-05 \n",
      "epoch: 38 [19998/888800 2.25%] train loss: 1.5644380255253054e-05 \n",
      "epoch: 38 [21109/888800 2.38%] train loss: 1.5129045095818583e-05 \n",
      "epoch: 38 [22220/888800 2.50%] train loss: 1.4621558875660412e-05 \n",
      "epoch: 38 [23331/888800 2.62%] train loss: 1.3945994396635797e-05 \n",
      "epoch: 38 [24442/888800 2.75%] train loss: 1.4655862287327182e-05 \n",
      "epoch: 38 [25553/888800 2.88%] train loss: 1.3284734450280666e-05 \n",
      "epoch: 38 [26664/888800 3.00%] train loss: 1.5289329894585535e-05 \n",
      "epoch: 38 [27775/888800 3.12%] train loss: 1.3196108739066403e-05 \n",
      "epoch: 38 [28886/888800 3.25%] train loss: 1.486984547227621e-05 \n",
      "epoch: 38 [29997/888800 3.38%] train loss: 1.399519715050701e-05 \n",
      "epoch: 38 [31108/888800 3.50%] train loss: 1.409529158991063e-05 \n",
      "epoch: 38 [32219/888800 3.62%] train loss: 1.46687480082619e-05 \n",
      "epoch: 38 [33330/888800 3.75%] train loss: 1.4327010831038933e-05 \n",
      "epoch: 38 [34441/888800 3.88%] train loss: 1.3398647752183024e-05 \n",
      "epoch: 38 [35552/888800 4.00%] train loss: 1.3257385035103653e-05 \n",
      "epoch: 38 [36663/888800 4.12%] train loss: 1.3256470083433669e-05 \n",
      "epoch: 38 [37774/888800 4.25%] train loss: 1.2717660865746439e-05 \n",
      "epoch: 38 [38885/888800 4.38%] train loss: 1.4140159692033194e-05 \n",
      "epoch: 38 [39996/888800 4.50%] train loss: 1.3077878975309432e-05 \n",
      "epoch: 38 [41107/888800 4.62%] train loss: 1.4891776118020061e-05 \n",
      "epoch: 38 [42218/888800 4.75%] train loss: 1.4063954040466342e-05 \n",
      "epoch: 38 [43329/888800 4.88%] train loss: 1.4572658983524889e-05 \n",
      "epoch: 38 [44440/888800 5.00%] train loss: 1.5007385627541225e-05 \n",
      "epoch: 38 [45551/888800 5.12%] train loss: 1.5051665286591742e-05 \n",
      "epoch: 38 [46662/888800 5.25%] train loss: 1.5573250493616797e-05 \n",
      "epoch: 38 [47773/888800 5.38%] train loss: 1.3783288522972725e-05 \n",
      "epoch: 38 [48884/888800 5.50%] train loss: 1.662629256315995e-05 \n",
      "epoch: 38 [49995/888800 5.62%] train loss: 1.4268360246205702e-05 \n",
      "epoch: 38 [51106/888800 5.75%] train loss: 1.4728308997291606e-05 \n",
      "epoch: 38 [52217/888800 5.88%] train loss: 1.4303933312476147e-05 \n",
      "epoch: 38 [53328/888800 6.00%] train loss: 1.3658723219123203e-05 \n",
      "epoch: 38 [54439/888800 6.12%] train loss: 1.5864770830376074e-05 \n",
      "epoch: 38 [55550/888800 6.25%] train loss: 1.3873526768293232e-05 \n",
      "epoch: 38 [56661/888800 6.38%] train loss: 1.4655409358965699e-05 \n",
      "epoch: 38 [57772/888800 6.50%] train loss: 1.4059391105547547e-05 \n",
      "epoch: 38 [58883/888800 6.62%] train loss: 1.4225318409444299e-05 \n",
      "epoch: 38 [59994/888800 6.75%] train loss: 1.2783391866832972e-05 \n",
      "epoch: 38 [61105/888800 6.88%] train loss: 1.380768844683189e-05 \n",
      "epoch: 38 [62216/888800 7.00%] train loss: 1.406656429026043e-05 \n",
      "epoch: 38 [63327/888800 7.12%] train loss: 1.409069500368787e-05 \n",
      "epoch: 38 [64438/888800 7.25%] train loss: 1.4715802535647526e-05 \n",
      "epoch: 38 [65549/888800 7.38%] train loss: 1.4328432371257804e-05 \n",
      "epoch: 38 [66660/888800 7.50%] train loss: 1.5323457773774862e-05 \n",
      "epoch: 38 [67771/888800 7.62%] train loss: 1.333601994701894e-05 \n",
      "epoch: 38 [68882/888800 7.75%] train loss: 1.4300591828941833e-05 \n",
      "epoch: 38 [69993/888800 7.88%] train loss: 1.4850598745397292e-05 \n",
      "epoch: 38 [71104/888800 8.00%] train loss: 1.423238791176118e-05 \n",
      "epoch: 38 [72215/888800 8.12%] train loss: 1.412166420777794e-05 \n",
      "epoch: 38 [73326/888800 8.25%] train loss: 1.477668592997361e-05 \n",
      "epoch: 38 [74437/888800 8.38%] train loss: 1.4334491424961016e-05 \n",
      "epoch: 38 [75548/888800 8.50%] train loss: 1.4544463738275226e-05 \n",
      "epoch: 38 [76659/888800 8.62%] train loss: 1.3984402357891668e-05 \n",
      "epoch: 38 [77770/888800 8.75%] train loss: 1.3807513823849149e-05 \n",
      "epoch: 38 [78881/888800 8.88%] train loss: 1.3392816072155256e-05 \n",
      "epoch: 38 [79992/888800 9.00%] train loss: 1.4536803973896895e-05 \n",
      "epoch: 38 [81103/888800 9.12%] train loss: 1.3918127478973474e-05 \n",
      "epoch: 38 [82214/888800 9.25%] train loss: 1.3609624147647992e-05 \n",
      "epoch: 38 [83325/888800 9.38%] train loss: 1.4332618775370065e-05 \n",
      "epoch: 38 [84436/888800 9.50%] train loss: 1.4538875802827533e-05 \n",
      "epoch: 38 [85547/888800 9.62%] train loss: 1.3761846275883727e-05 \n",
      "epoch: 38 [86658/888800 9.75%] train loss: 1.5400966731249355e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [87769/888800 9.88%] train loss: 1.4997762264101766e-05 \n",
      "epoch: 38 [88880/888800 10.00%] train loss: 1.528440225229133e-05 \n",
      "epoch: 38 [89991/888800 10.12%] train loss: 1.4750054106116295e-05 \n",
      "epoch: 38 [91102/888800 10.25%] train loss: 1.3385550118982792e-05 \n",
      "epoch: 38 [92213/888800 10.38%] train loss: 1.5144592907745391e-05 \n",
      "epoch: 38 [93324/888800 10.50%] train loss: 1.291368516831426e-05 \n",
      "epoch: 38 [94435/888800 10.62%] train loss: 1.509041067038197e-05 \n",
      "epoch: 38 [95546/888800 10.75%] train loss: 1.3014184332860168e-05 \n",
      "epoch: 38 [96657/888800 10.88%] train loss: 1.3497885447577573e-05 \n",
      "epoch: 38 [97768/888800 11.00%] train loss: 1.4404615285457112e-05 \n",
      "epoch: 38 [98879/888800 11.12%] train loss: 1.3960687283542939e-05 \n",
      "epoch: 38 [99990/888800 11.25%] train loss: 1.4311774066300131e-05 \n",
      "epoch: 38 [101101/888800 11.38%] train loss: 1.2674402569246013e-05 \n",
      "epoch: 38 [102212/888800 11.50%] train loss: 1.3443962416204158e-05 \n",
      "epoch: 38 [103323/888800 11.62%] train loss: 1.3919113371230196e-05 \n",
      "epoch: 38 [104434/888800 11.75%] train loss: 1.3119456525600981e-05 \n",
      "epoch: 38 [105545/888800 11.88%] train loss: 1.3130114894011058e-05 \n",
      "epoch: 38 [106656/888800 12.00%] train loss: 1.5025963875814341e-05 \n",
      "epoch: 38 [107767/888800 12.12%] train loss: 1.473429801990278e-05 \n",
      "epoch: 38 [108878/888800 12.25%] train loss: 1.3406021025730297e-05 \n",
      "epoch: 38 [109989/888800 12.38%] train loss: 1.4073097190703265e-05 \n",
      "epoch: 38 [111100/888800 12.50%] train loss: 1.3854674762114882e-05 \n",
      "epoch: 38 [112211/888800 12.62%] train loss: 1.5481311493203975e-05 \n",
      "epoch: 38 [113322/888800 12.75%] train loss: 1.5581072148052044e-05 \n",
      "epoch: 38 [114433/888800 12.88%] train loss: 1.458360657125013e-05 \n",
      "epoch: 38 [115544/888800 13.00%] train loss: 1.4323875802801922e-05 \n",
      "epoch: 38 [116655/888800 13.12%] train loss: 1.5292474927264266e-05 \n",
      "epoch: 38 [117766/888800 13.25%] train loss: 1.4550140804203693e-05 \n",
      "epoch: 38 [118877/888800 13.38%] train loss: 1.2537874681584071e-05 \n",
      "epoch: 38 [119988/888800 13.50%] train loss: 1.5212039215839468e-05 \n",
      "epoch: 38 [121099/888800 13.62%] train loss: 1.398070980940247e-05 \n",
      "epoch: 38 [122210/888800 13.75%] train loss: 1.3241466149338521e-05 \n",
      "epoch: 38 [123321/888800 13.88%] train loss: 1.3421467883745208e-05 \n",
      "epoch: 38 [124432/888800 14.00%] train loss: 1.5133695342228748e-05 \n",
      "epoch: 38 [125543/888800 14.12%] train loss: 1.5194202205748297e-05 \n",
      "epoch: 38 [126654/888800 14.25%] train loss: 1.4861779163766187e-05 \n",
      "epoch: 38 [127765/888800 14.38%] train loss: 1.5111313587112818e-05 \n",
      "epoch: 38 [128876/888800 14.50%] train loss: 1.4866327546769753e-05 \n",
      "epoch: 38 [129987/888800 14.62%] train loss: 1.3527701412385795e-05 \n",
      "epoch: 38 [131098/888800 14.75%] train loss: 1.561318276799284e-05 \n",
      "epoch: 38 [132209/888800 14.88%] train loss: 1.636380511627067e-05 \n",
      "epoch: 38 [133320/888800 15.00%] train loss: 1.3996698726259638e-05 \n",
      "epoch: 38 [134431/888800 15.12%] train loss: 1.6358451830456033e-05 \n",
      "epoch: 38 [135542/888800 15.25%] train loss: 1.3616278920380864e-05 \n",
      "epoch: 38 [136653/888800 15.38%] train loss: 1.5329183952417225e-05 \n",
      "epoch: 38 [137764/888800 15.50%] train loss: 1.4193413335306104e-05 \n",
      "epoch: 38 [138875/888800 15.62%] train loss: 1.5636967873433605e-05 \n",
      "epoch: 38 [139986/888800 15.75%] train loss: 1.401592180627631e-05 \n",
      "epoch: 38 [141097/888800 15.88%] train loss: 1.521936064818874e-05 \n",
      "epoch: 38 [142208/888800 16.00%] train loss: 1.7124988517025486e-05 \n",
      "epoch: 38 [143319/888800 16.12%] train loss: 1.4526447557727806e-05 \n",
      "epoch: 38 [144430/888800 16.25%] train loss: 1.502638951933477e-05 \n",
      "epoch: 38 [145541/888800 16.38%] train loss: 1.4433263459068257e-05 \n",
      "epoch: 38 [146652/888800 16.50%] train loss: 1.4742335224582348e-05 \n",
      "epoch: 38 [147763/888800 16.62%] train loss: 1.405996226822026e-05 \n",
      "epoch: 38 [148874/888800 16.75%] train loss: 1.5318779333028942e-05 \n",
      "epoch: 38 [149985/888800 16.88%] train loss: 1.3790320736006834e-05 \n",
      "epoch: 38 [151096/888800 17.00%] train loss: 1.4334626030176878e-05 \n",
      "epoch: 38 [152207/888800 17.12%] train loss: 1.55390353029361e-05 \n",
      "epoch: 38 [153318/888800 17.25%] train loss: 1.4505571925838012e-05 \n",
      "epoch: 38 [154429/888800 17.38%] train loss: 1.501572387496708e-05 \n",
      "epoch: 38 [155540/888800 17.50%] train loss: 1.603549753781408e-05 \n",
      "epoch: 38 [156651/888800 17.62%] train loss: 1.5222396541503258e-05 \n",
      "epoch: 38 [157762/888800 17.75%] train loss: 1.55782799993176e-05 \n",
      "epoch: 38 [158873/888800 17.88%] train loss: 1.6122579836519435e-05 \n",
      "epoch: 38 [159984/888800 18.00%] train loss: 1.392312697134912e-05 \n",
      "epoch: 38 [161095/888800 18.12%] train loss: 1.6461703125969507e-05 \n",
      "epoch: 38 [162206/888800 18.25%] train loss: 1.2855503882747144e-05 \n",
      "epoch: 38 [163317/888800 18.38%] train loss: 1.7405494872946292e-05 \n",
      "epoch: 38 [164428/888800 18.50%] train loss: 1.3699168448511045e-05 \n",
      "epoch: 38 [165539/888800 18.62%] train loss: 1.6174883057828993e-05 \n",
      "epoch: 38 [166650/888800 18.75%] train loss: 1.4406967238755897e-05 \n",
      "epoch: 38 [167761/888800 18.88%] train loss: 1.6063770090113394e-05 \n",
      "epoch: 38 [168872/888800 19.00%] train loss: 1.4909684978192672e-05 \n",
      "epoch: 38 [169983/888800 19.12%] train loss: 1.5183953109954018e-05 \n",
      "epoch: 38 [171094/888800 19.25%] train loss: 1.5302246538340114e-05 \n",
      "epoch: 38 [172205/888800 19.38%] train loss: 1.399592565576313e-05 \n",
      "epoch: 38 [173316/888800 19.50%] train loss: 1.4214534530765377e-05 \n",
      "epoch: 38 [174427/888800 19.62%] train loss: 1.4458536497841123e-05 \n",
      "epoch: 38 [175538/888800 19.75%] train loss: 1.5850433555897325e-05 \n",
      "epoch: 38 [176649/888800 19.88%] train loss: 1.3207393749326002e-05 \n",
      "epoch: 38 [177760/888800 20.00%] train loss: 1.4637064850830939e-05 \n",
      "epoch: 38 [178871/888800 20.12%] train loss: 1.3819546438753605e-05 \n",
      "epoch: 38 [179982/888800 20.25%] train loss: 1.4803685189690441e-05 \n",
      "epoch: 38 [181093/888800 20.38%] train loss: 1.4616674889111891e-05 \n",
      "epoch: 38 [182204/888800 20.50%] train loss: 1.4455818018177524e-05 \n",
      "epoch: 38 [183315/888800 20.62%] train loss: 1.271990822715452e-05 \n",
      "epoch: 38 [184426/888800 20.75%] train loss: 1.4559366718458477e-05 \n",
      "epoch: 38 [185537/888800 20.88%] train loss: 1.2933608559251297e-05 \n",
      "epoch: 38 [186648/888800 21.00%] train loss: 1.4024353731656447e-05 \n",
      "epoch: 38 [187759/888800 21.12%] train loss: 1.4591427316190675e-05 \n",
      "epoch: 38 [188870/888800 21.25%] train loss: 1.4872252904751804e-05 \n",
      "epoch: 38 [189981/888800 21.38%] train loss: 1.4021501556271687e-05 \n",
      "epoch: 38 [191092/888800 21.50%] train loss: 1.5041062397358473e-05 \n",
      "epoch: 38 [192203/888800 21.62%] train loss: 1.3400073839875404e-05 \n",
      "epoch: 38 [193314/888800 21.75%] train loss: 1.4637859749200288e-05 \n",
      "epoch: 38 [194425/888800 21.88%] train loss: 1.5089371117937844e-05 \n",
      "epoch: 38 [195536/888800 22.00%] train loss: 1.3585043234343175e-05 \n",
      "epoch: 38 [196647/888800 22.12%] train loss: 1.3016039702051785e-05 \n",
      "epoch: 38 [197758/888800 22.25%] train loss: 1.4383902453118935e-05 \n",
      "epoch: 38 [198869/888800 22.38%] train loss: 1.358535882900469e-05 \n",
      "epoch: 38 [199980/888800 22.50%] train loss: 1.4435262528422754e-05 \n",
      "epoch: 38 [201091/888800 22.62%] train loss: 1.3240945918369107e-05 \n",
      "epoch: 38 [202202/888800 22.75%] train loss: 1.5105562852113508e-05 \n",
      "epoch: 38 [203313/888800 22.88%] train loss: 1.4461656064668205e-05 \n",
      "epoch: 38 [204424/888800 23.00%] train loss: 1.4555814232153352e-05 \n",
      "epoch: 38 [205535/888800 23.12%] train loss: 1.462958061893005e-05 \n",
      "epoch: 38 [206646/888800 23.25%] train loss: 1.4754483345313929e-05 \n",
      "epoch: 38 [207757/888800 23.38%] train loss: 1.3645674698636867e-05 \n",
      "epoch: 38 [208868/888800 23.50%] train loss: 1.4808046216785442e-05 \n",
      "epoch: 38 [209979/888800 23.62%] train loss: 1.523273931525182e-05 \n",
      "epoch: 38 [211090/888800 23.75%] train loss: 1.4955598999222275e-05 \n",
      "epoch: 38 [212201/888800 23.88%] train loss: 1.2723533473035786e-05 \n",
      "epoch: 38 [213312/888800 24.00%] train loss: 1.514171435701428e-05 \n",
      "epoch: 38 [214423/888800 24.12%] train loss: 1.4609894606110174e-05 \n",
      "epoch: 38 [215534/888800 24.25%] train loss: 1.5020616956462618e-05 \n",
      "epoch: 38 [216645/888800 24.38%] train loss: 1.4506805200653616e-05 \n",
      "epoch: 38 [217756/888800 24.50%] train loss: 1.3861515071766917e-05 \n",
      "epoch: 38 [218867/888800 24.62%] train loss: 1.580660136824008e-05 \n",
      "epoch: 38 [219978/888800 24.75%] train loss: 1.551963941892609e-05 \n",
      "epoch: 38 [221089/888800 24.88%] train loss: 1.3455372936732601e-05 \n",
      "epoch: 38 [222200/888800 25.00%] train loss: 1.5434845408890396e-05 \n",
      "epoch: 38 [223311/888800 25.12%] train loss: 1.4057468433748e-05 \n",
      "epoch: 38 [224422/888800 25.25%] train loss: 1.3533814126276411e-05 \n",
      "epoch: 38 [225533/888800 25.38%] train loss: 1.4728481801284943e-05 \n",
      "epoch: 38 [226644/888800 25.50%] train loss: 1.5805680959601887e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [227755/888800 25.62%] train loss: 1.3831584510626271e-05 \n",
      "epoch: 38 [228866/888800 25.75%] train loss: 1.505792261013994e-05 \n",
      "epoch: 38 [229977/888800 25.88%] train loss: 1.2607932148966938e-05 \n",
      "epoch: 38 [231088/888800 26.00%] train loss: 1.499903646617895e-05 \n",
      "epoch: 38 [232199/888800 26.12%] train loss: 1.5301742678275332e-05 \n",
      "epoch: 38 [233310/888800 26.25%] train loss: 1.4952480341889895e-05 \n",
      "epoch: 38 [234421/888800 26.38%] train loss: 1.5381607227027416e-05 \n",
      "epoch: 38 [235532/888800 26.50%] train loss: 1.3670180123881437e-05 \n",
      "epoch: 38 [236643/888800 26.62%] train loss: 1.4988511793490034e-05 \n",
      "epoch: 38 [237754/888800 26.75%] train loss: 1.42757971843821e-05 \n",
      "epoch: 38 [238865/888800 26.88%] train loss: 1.405411421728786e-05 \n",
      "epoch: 38 [239976/888800 27.00%] train loss: 1.3771084013569634e-05 \n",
      "epoch: 38 [241087/888800 27.12%] train loss: 1.4772511349292472e-05 \n",
      "epoch: 38 [242198/888800 27.25%] train loss: 1.530606641608756e-05 \n",
      "epoch: 38 [243309/888800 27.38%] train loss: 1.3835235222359188e-05 \n",
      "epoch: 38 [244420/888800 27.50%] train loss: 1.3805110938847065e-05 \n",
      "epoch: 38 [245531/888800 27.62%] train loss: 1.3939620657765772e-05 \n",
      "epoch: 38 [246642/888800 27.75%] train loss: 1.551628520246595e-05 \n",
      "epoch: 38 [247753/888800 27.88%] train loss: 1.4676666978630237e-05 \n",
      "epoch: 38 [248864/888800 28.00%] train loss: 1.3040616977377795e-05 \n",
      "epoch: 38 [249975/888800 28.12%] train loss: 1.5169880498433486e-05 \n",
      "epoch: 38 [251086/888800 28.25%] train loss: 1.4175970136420801e-05 \n",
      "epoch: 38 [252197/888800 28.38%] train loss: 1.3509889868146274e-05 \n",
      "epoch: 38 [253308/888800 28.50%] train loss: 1.4501048099191394e-05 \n",
      "epoch: 38 [254419/888800 28.62%] train loss: 1.4273235137807205e-05 \n",
      "epoch: 38 [255530/888800 28.75%] train loss: 1.3879111065762118e-05 \n",
      "epoch: 38 [256641/888800 28.88%] train loss: 1.4198955796018708e-05 \n",
      "epoch: 38 [257752/888800 29.00%] train loss: 1.3539330211642664e-05 \n",
      "epoch: 38 [258863/888800 29.12%] train loss: 1.4603580893890467e-05 \n",
      "epoch: 38 [259974/888800 29.25%] train loss: 1.528707616671454e-05 \n",
      "epoch: 38 [261085/888800 29.38%] train loss: 1.4293884305516258e-05 \n",
      "epoch: 38 [262196/888800 29.50%] train loss: 1.382046229991829e-05 \n",
      "epoch: 38 [263307/888800 29.62%] train loss: 1.4108868526818696e-05 \n",
      "epoch: 38 [264418/888800 29.75%] train loss: 1.4119963452685624e-05 \n",
      "epoch: 38 [265529/888800 29.88%] train loss: 1.4148087757348549e-05 \n",
      "epoch: 38 [266640/888800 30.00%] train loss: 1.529732980998233e-05 \n",
      "epoch: 38 [267751/888800 30.12%] train loss: 1.4402945453184657e-05 \n",
      "epoch: 38 [268862/888800 30.25%] train loss: 1.3984770703245886e-05 \n",
      "epoch: 38 [269973/888800 30.38%] train loss: 1.4504993487207685e-05 \n",
      "epoch: 38 [271084/888800 30.50%] train loss: 1.2600883565028198e-05 \n",
      "epoch: 38 [272195/888800 30.62%] train loss: 1.3548083188652527e-05 \n",
      "epoch: 38 [273306/888800 30.75%] train loss: 1.5281939340638928e-05 \n",
      "epoch: 38 [274417/888800 30.88%] train loss: 1.3781032976112328e-05 \n",
      "epoch: 38 [275528/888800 31.00%] train loss: 1.4491825822915416e-05 \n",
      "epoch: 38 [276639/888800 31.12%] train loss: 1.3390110325417481e-05 \n",
      "epoch: 38 [277750/888800 31.25%] train loss: 1.3748875062447041e-05 \n",
      "epoch: 38 [278861/888800 31.38%] train loss: 1.4103513422014657e-05 \n",
      "epoch: 38 [279972/888800 31.50%] train loss: 1.4305138392955996e-05 \n",
      "epoch: 38 [281083/888800 31.62%] train loss: 1.4466211723629385e-05 \n",
      "epoch: 38 [282194/888800 31.75%] train loss: 1.4818206182098947e-05 \n",
      "epoch: 38 [283305/888800 31.88%] train loss: 1.3397341717791278e-05 \n",
      "epoch: 38 [284416/888800 32.00%] train loss: 1.3350050721783191e-05 \n",
      "epoch: 38 [285527/888800 32.12%] train loss: 1.3016558114031795e-05 \n",
      "epoch: 38 [286638/888800 32.25%] train loss: 1.4470768292085268e-05 \n",
      "epoch: 38 [287749/888800 32.38%] train loss: 1.4188377463142388e-05 \n",
      "epoch: 38 [288860/888800 32.50%] train loss: 1.4201044905348681e-05 \n",
      "epoch: 38 [289971/888800 32.62%] train loss: 1.3106628102832474e-05 \n",
      "epoch: 38 [291082/888800 32.75%] train loss: 1.4162732441036496e-05 \n",
      "epoch: 38 [292193/888800 32.88%] train loss: 1.3770735677098855e-05 \n",
      "epoch: 38 [293304/888800 33.00%] train loss: 1.2926825547765475e-05 \n",
      "epoch: 38 [294415/888800 33.12%] train loss: 1.564702506584581e-05 \n",
      "epoch: 38 [295526/888800 33.25%] train loss: 1.2772880836564582e-05 \n",
      "epoch: 38 [296637/888800 33.38%] train loss: 1.4972079952713102e-05 \n",
      "epoch: 38 [297748/888800 33.50%] train loss: 1.4679984815302305e-05 \n",
      "epoch: 38 [298859/888800 33.62%] train loss: 1.4249155356083065e-05 \n",
      "epoch: 38 [299970/888800 33.75%] train loss: 1.3997723726788536e-05 \n",
      "epoch: 38 [301081/888800 33.88%] train loss: 1.4752225069969427e-05 \n",
      "epoch: 38 [302192/888800 34.00%] train loss: 1.3641906662087422e-05 \n",
      "epoch: 38 [303303/888800 34.12%] train loss: 1.420313765265746e-05 \n",
      "epoch: 38 [304414/888800 34.25%] train loss: 1.3478617802320514e-05 \n",
      "epoch: 38 [305525/888800 34.38%] train loss: 1.4852405911369715e-05 \n",
      "epoch: 38 [306636/888800 34.50%] train loss: 1.3884017789678182e-05 \n",
      "epoch: 38 [307747/888800 34.62%] train loss: 1.420526677975431e-05 \n",
      "epoch: 38 [308858/888800 34.75%] train loss: 1.4384231690200977e-05 \n",
      "epoch: 38 [309969/888800 34.88%] train loss: 1.4088736861594953e-05 \n",
      "epoch: 38 [311080/888800 35.00%] train loss: 1.275074919249164e-05 \n",
      "epoch: 38 [312191/888800 35.12%] train loss: 1.3104028766974807e-05 \n",
      "epoch: 38 [313302/888800 35.25%] train loss: 1.4952450328564737e-05 \n",
      "epoch: 38 [314413/888800 35.38%] train loss: 1.3970905456517357e-05 \n",
      "epoch: 38 [315524/888800 35.50%] train loss: 1.456576501368545e-05 \n",
      "epoch: 38 [316635/888800 35.62%] train loss: 1.5794808859936893e-05 \n",
      "epoch: 38 [317746/888800 35.75%] train loss: 1.5027365407149773e-05 \n",
      "epoch: 38 [318857/888800 35.88%] train loss: 1.5168437130341772e-05 \n",
      "epoch: 38 [319968/888800 36.00%] train loss: 1.3073332411295269e-05 \n",
      "epoch: 38 [321079/888800 36.12%] train loss: 1.4987152098910883e-05 \n",
      "epoch: 38 [322190/888800 36.25%] train loss: 1.328230973740574e-05 \n",
      "epoch: 38 [323301/888800 36.38%] train loss: 1.445225552743068e-05 \n",
      "epoch: 38 [324412/888800 36.50%] train loss: 1.4375831597135402e-05 \n",
      "epoch: 38 [325523/888800 36.62%] train loss: 1.4518705938826315e-05 \n",
      "epoch: 38 [326634/888800 36.75%] train loss: 1.4924207789590582e-05 \n",
      "epoch: 38 [327745/888800 36.88%] train loss: 1.3773679711448494e-05 \n",
      "epoch: 38 [328856/888800 37.00%] train loss: 1.4278904018283356e-05 \n",
      "epoch: 38 [329967/888800 37.12%] train loss: 1.3504216440196615e-05 \n",
      "epoch: 38 [331078/888800 37.25%] train loss: 1.2334499842836522e-05 \n",
      "epoch: 38 [332189/888800 37.38%] train loss: 1.4650985576736275e-05 \n",
      "epoch: 38 [333300/888800 37.50%] train loss: 1.4535929039993789e-05 \n",
      "epoch: 38 [334411/888800 37.62%] train loss: 1.3877892342861742e-05 \n",
      "epoch: 38 [335522/888800 37.75%] train loss: 1.409237756888615e-05 \n",
      "epoch: 38 [336633/888800 37.88%] train loss: 1.4729553186043631e-05 \n",
      "epoch: 38 [337744/888800 38.00%] train loss: 1.4539700714522041e-05 \n",
      "epoch: 38 [338855/888800 38.12%] train loss: 1.3244550245872233e-05 \n",
      "epoch: 38 [339966/888800 38.25%] train loss: 1.5131995496631134e-05 \n",
      "epoch: 38 [341077/888800 38.38%] train loss: 1.363831961498363e-05 \n",
      "epoch: 38 [342188/888800 38.50%] train loss: 1.4269731764215976e-05 \n",
      "epoch: 38 [343299/888800 38.62%] train loss: 1.4573450243915431e-05 \n",
      "epoch: 38 [344410/888800 38.75%] train loss: 1.2662401786656119e-05 \n",
      "epoch: 38 [345521/888800 38.88%] train loss: 1.3173636034480296e-05 \n",
      "epoch: 38 [346632/888800 39.00%] train loss: 1.3787308489554562e-05 \n",
      "epoch: 38 [347743/888800 39.12%] train loss: 1.4483617633231916e-05 \n",
      "epoch: 38 [348854/888800 39.25%] train loss: 1.5380641343654133e-05 \n",
      "epoch: 38 [349965/888800 39.38%] train loss: 1.4784275663259905e-05 \n",
      "epoch: 38 [351076/888800 39.50%] train loss: 1.548089312564116e-05 \n",
      "epoch: 38 [352187/888800 39.62%] train loss: 1.3978868992126081e-05 \n",
      "epoch: 38 [353298/888800 39.75%] train loss: 1.4792432011745404e-05 \n",
      "epoch: 38 [354409/888800 39.88%] train loss: 1.407805029884912e-05 \n",
      "epoch: 38 [355520/888800 40.00%] train loss: 1.4758645193069242e-05 \n",
      "epoch: 38 [356631/888800 40.12%] train loss: 1.4821572221990209e-05 \n",
      "epoch: 38 [357742/888800 40.25%] train loss: 1.524995059298817e-05 \n",
      "epoch: 38 [358853/888800 40.38%] train loss: 1.5114488633116707e-05 \n",
      "epoch: 38 [359964/888800 40.50%] train loss: 1.3740572285314556e-05 \n",
      "epoch: 38 [361075/888800 40.62%] train loss: 1.489676196797518e-05 \n",
      "epoch: 38 [362186/888800 40.75%] train loss: 1.4276521142164711e-05 \n",
      "epoch: 38 [363297/888800 40.88%] train loss: 1.4046197065908927e-05 \n",
      "epoch: 38 [364408/888800 41.00%] train loss: 1.533528666186612e-05 \n",
      "epoch: 38 [365519/888800 41.12%] train loss: 1.444341705791885e-05 \n",
      "epoch: 38 [366630/888800 41.25%] train loss: 1.4663199181086384e-05 \n",
      "epoch: 38 [367741/888800 41.38%] train loss: 1.390275610901881e-05 \n",
      "epoch: 38 [368852/888800 41.50%] train loss: 1.4627587006543763e-05 \n",
      "epoch: 38 [369963/888800 41.62%] train loss: 1.5945450286380947e-05 \n",
      "epoch: 38 [371074/888800 41.75%] train loss: 1.3925134226155933e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [372185/888800 41.88%] train loss: 1.5393432477139868e-05 \n",
      "epoch: 38 [373296/888800 42.00%] train loss: 1.5357691154349595e-05 \n",
      "epoch: 38 [374407/888800 42.12%] train loss: 1.4675285456178244e-05 \n",
      "epoch: 38 [375518/888800 42.25%] train loss: 1.3834717719873879e-05 \n",
      "epoch: 38 [376629/888800 42.38%] train loss: 1.63434560818132e-05 \n",
      "epoch: 38 [377740/888800 42.50%] train loss: 1.4828094208496623e-05 \n",
      "epoch: 38 [378851/888800 42.62%] train loss: 1.5915378753561527e-05 \n",
      "epoch: 38 [379962/888800 42.75%] train loss: 1.4419977560464758e-05 \n",
      "epoch: 38 [381073/888800 42.88%] train loss: 1.3052132999291644e-05 \n",
      "epoch: 38 [382184/888800 43.00%] train loss: 1.539494769531302e-05 \n",
      "epoch: 38 [383295/888800 43.12%] train loss: 1.338086531177396e-05 \n",
      "epoch: 38 [384406/888800 43.25%] train loss: 1.3664925063494593e-05 \n",
      "epoch: 38 [385517/888800 43.38%] train loss: 1.4506220395560376e-05 \n",
      "epoch: 38 [386628/888800 43.50%] train loss: 1.3806253264192492e-05 \n",
      "epoch: 38 [387739/888800 43.62%] train loss: 1.373772738588741e-05 \n",
      "epoch: 38 [388850/888800 43.75%] train loss: 1.4361985449795611e-05 \n",
      "epoch: 38 [389961/888800 43.88%] train loss: 1.3432712876237929e-05 \n",
      "epoch: 38 [391072/888800 44.00%] train loss: 1.4933778402337339e-05 \n",
      "epoch: 38 [392183/888800 44.12%] train loss: 1.441167296434287e-05 \n",
      "epoch: 38 [393294/888800 44.25%] train loss: 1.4300659131549764e-05 \n",
      "epoch: 38 [394405/888800 44.38%] train loss: 1.3029104593442753e-05 \n",
      "epoch: 38 [395516/888800 44.50%] train loss: 1.3218806088843849e-05 \n",
      "epoch: 38 [396627/888800 44.62%] train loss: 1.362339207844343e-05 \n",
      "epoch: 38 [397738/888800 44.75%] train loss: 1.5472216546186246e-05 \n",
      "epoch: 38 [398849/888800 44.88%] train loss: 1.494260777690215e-05 \n",
      "epoch: 38 [399960/888800 45.00%] train loss: 1.4726793779118452e-05 \n",
      "epoch: 38 [401071/888800 45.12%] train loss: 1.4272839507611934e-05 \n",
      "epoch: 38 [402182/888800 45.25%] train loss: 1.3648376807395834e-05 \n",
      "epoch: 38 [403293/888800 45.38%] train loss: 1.4151031791698188e-05 \n",
      "epoch: 38 [404404/888800 45.50%] train loss: 1.224787592946086e-05 \n",
      "epoch: 38 [405515/888800 45.62%] train loss: 1.448515922675142e-05 \n",
      "epoch: 38 [406626/888800 45.75%] train loss: 1.4031776117917616e-05 \n",
      "epoch: 38 [407737/888800 45.88%] train loss: 1.4821540389675647e-05 \n",
      "epoch: 38 [408848/888800 46.00%] train loss: 1.4844869838270824e-05 \n",
      "epoch: 38 [409959/888800 46.12%] train loss: 1.421118668076815e-05 \n",
      "epoch: 38 [411070/888800 46.25%] train loss: 1.4216029740055092e-05 \n",
      "epoch: 38 [412181/888800 46.38%] train loss: 1.3392330401984509e-05 \n",
      "epoch: 38 [413292/888800 46.50%] train loss: 1.44692457979545e-05 \n",
      "epoch: 38 [414403/888800 46.62%] train loss: 1.4682596884085797e-05 \n",
      "epoch: 38 [415514/888800 46.75%] train loss: 1.3377540199144278e-05 \n",
      "epoch: 38 [416625/888800 46.88%] train loss: 1.4619094145018607e-05 \n",
      "epoch: 38 [417736/888800 47.00%] train loss: 1.5241897926898673e-05 \n",
      "epoch: 38 [418847/888800 47.12%] train loss: 1.3372241483011749e-05 \n",
      "epoch: 38 [419958/888800 47.25%] train loss: 1.4152178664517123e-05 \n",
      "epoch: 38 [421069/888800 47.38%] train loss: 1.3739822861680295e-05 \n",
      "epoch: 38 [422180/888800 47.50%] train loss: 1.4443804502661806e-05 \n",
      "epoch: 38 [423291/888800 47.62%] train loss: 1.4495815776172094e-05 \n",
      "epoch: 38 [424402/888800 47.75%] train loss: 1.458103179174941e-05 \n",
      "epoch: 38 [425513/888800 47.88%] train loss: 1.548916770843789e-05 \n",
      "epoch: 38 [426624/888800 48.00%] train loss: 1.4889616977598052e-05 \n",
      "epoch: 38 [427735/888800 48.12%] train loss: 1.5263824025169015e-05 \n",
      "epoch: 38 [428846/888800 48.25%] train loss: 1.5252606317517348e-05 \n",
      "epoch: 38 [429957/888800 48.38%] train loss: 1.3872609088139143e-05 \n",
      "epoch: 38 [431068/888800 48.50%] train loss: 1.4146644389256835e-05 \n",
      "epoch: 38 [432179/888800 48.62%] train loss: 1.465846253267955e-05 \n",
      "epoch: 38 [433290/888800 48.75%] train loss: 1.3727307305089198e-05 \n",
      "epoch: 38 [434401/888800 48.88%] train loss: 1.4234277841751464e-05 \n",
      "epoch: 38 [435512/888800 49.00%] train loss: 1.4882260074955411e-05 \n",
      "epoch: 38 [436623/888800 49.12%] train loss: 1.2998147212783806e-05 \n",
      "epoch: 38 [437734/888800 49.25%] train loss: 1.40490556077566e-05 \n",
      "epoch: 38 [438845/888800 49.38%] train loss: 1.4738053323526401e-05 \n",
      "epoch: 38 [439956/888800 49.50%] train loss: 1.3351921552384738e-05 \n",
      "epoch: 38 [441067/888800 49.62%] train loss: 1.5041280676086899e-05 \n",
      "epoch: 38 [442178/888800 49.75%] train loss: 1.4374581041920464e-05 \n",
      "epoch: 38 [443289/888800 49.88%] train loss: 1.4463163097389042e-05 \n",
      "epoch: 38 [444400/888800 50.00%] train loss: 1.4027496035851073e-05 \n",
      "epoch: 38 [445511/888800 50.12%] train loss: 1.3675018635694869e-05 \n",
      "epoch: 38 [446622/888800 50.25%] train loss: 1.4215664123184979e-05 \n",
      "epoch: 38 [447733/888800 50.38%] train loss: 1.4440357517742086e-05 \n",
      "epoch: 38 [448844/888800 50.50%] train loss: 1.4171210750646424e-05 \n",
      "epoch: 38 [449955/888800 50.62%] train loss: 1.3483321708918083e-05 \n",
      "epoch: 38 [451066/888800 50.75%] train loss: 1.371664802718442e-05 \n",
      "epoch: 38 [452177/888800 50.88%] train loss: 1.4203130376699846e-05 \n",
      "epoch: 38 [453288/888800 51.00%] train loss: 1.3877989658794831e-05 \n",
      "epoch: 38 [454399/888800 51.12%] train loss: 1.4318206922325771e-05 \n",
      "epoch: 38 [455510/888800 51.25%] train loss: 1.340026665275218e-05 \n",
      "epoch: 38 [456621/888800 51.38%] train loss: 1.4047946933715139e-05 \n",
      "epoch: 38 [457732/888800 51.50%] train loss: 1.3900728845328558e-05 \n",
      "epoch: 38 [458843/888800 51.62%] train loss: 1.3667338862433098e-05 \n",
      "epoch: 38 [459954/888800 51.75%] train loss: 1.298594543186482e-05 \n",
      "epoch: 38 [461065/888800 51.88%] train loss: 1.3727641089644749e-05 \n",
      "epoch: 38 [462176/888800 52.00%] train loss: 1.4923543858458288e-05 \n",
      "epoch: 38 [463287/888800 52.12%] train loss: 1.448470720788464e-05 \n",
      "epoch: 38 [464398/888800 52.25%] train loss: 1.4203716091287788e-05 \n",
      "epoch: 38 [465509/888800 52.38%] train loss: 1.598775270394981e-05 \n",
      "epoch: 38 [466620/888800 52.50%] train loss: 1.3057730939181056e-05 \n",
      "epoch: 38 [467731/888800 52.62%] train loss: 1.3644023056258447e-05 \n",
      "epoch: 38 [468842/888800 52.75%] train loss: 1.4893449588271324e-05 \n",
      "epoch: 38 [469953/888800 52.88%] train loss: 1.503327348473249e-05 \n",
      "epoch: 38 [471064/888800 53.00%] train loss: 1.422250807081582e-05 \n",
      "epoch: 38 [472175/888800 53.12%] train loss: 1.3640519682667218e-05 \n",
      "epoch: 38 [473286/888800 53.25%] train loss: 1.3875317563361023e-05 \n",
      "epoch: 38 [474397/888800 53.38%] train loss: 1.4343531802296638e-05 \n",
      "epoch: 38 [475508/888800 53.50%] train loss: 1.4293188542069402e-05 \n",
      "epoch: 38 [476619/888800 53.62%] train loss: 1.2903757124149706e-05 \n",
      "epoch: 38 [477730/888800 53.75%] train loss: 1.5168970094237011e-05 \n",
      "epoch: 38 [478841/888800 53.88%] train loss: 1.3962929187982809e-05 \n",
      "epoch: 38 [479952/888800 54.00%] train loss: 1.4468580047832802e-05 \n",
      "epoch: 38 [481063/888800 54.12%] train loss: 1.3292648873175494e-05 \n",
      "epoch: 38 [482174/888800 54.25%] train loss: 1.4258369446906727e-05 \n",
      "epoch: 38 [483285/888800 54.38%] train loss: 1.4710185496369377e-05 \n",
      "epoch: 38 [484396/888800 54.50%] train loss: 1.3573589967563748e-05 \n",
      "epoch: 38 [485507/888800 54.62%] train loss: 1.3902968021284323e-05 \n",
      "epoch: 38 [486618/888800 54.75%] train loss: 1.4370963071996812e-05 \n",
      "epoch: 38 [487729/888800 54.88%] train loss: 1.5259798601618968e-05 \n",
      "epoch: 38 [488840/888800 55.00%] train loss: 1.4543637917086016e-05 \n",
      "epoch: 38 [489951/888800 55.12%] train loss: 1.4905061107128859e-05 \n",
      "epoch: 38 [491062/888800 55.25%] train loss: 1.527600943518337e-05 \n",
      "epoch: 38 [492173/888800 55.38%] train loss: 1.3780327208223753e-05 \n",
      "epoch: 38 [493284/888800 55.50%] train loss: 1.4394119716598652e-05 \n",
      "epoch: 38 [494395/888800 55.62%] train loss: 1.4735695003764704e-05 \n",
      "epoch: 38 [495506/888800 55.75%] train loss: 1.4932269550627097e-05 \n",
      "epoch: 38 [496617/888800 55.88%] train loss: 1.3154062799003441e-05 \n",
      "epoch: 38 [497728/888800 56.00%] train loss: 1.4847080819890834e-05 \n",
      "epoch: 38 [498839/888800 56.12%] train loss: 1.3556945305026602e-05 \n",
      "epoch: 38 [499950/888800 56.25%] train loss: 1.4323205505206715e-05 \n",
      "epoch: 38 [501061/888800 56.38%] train loss: 1.403044461767422e-05 \n",
      "epoch: 38 [502172/888800 56.50%] train loss: 1.3413180568022653e-05 \n",
      "epoch: 38 [503283/888800 56.62%] train loss: 1.555452217871789e-05 \n",
      "epoch: 38 [504394/888800 56.75%] train loss: 1.4557400390913244e-05 \n",
      "epoch: 38 [505505/888800 56.88%] train loss: 1.4063730304769706e-05 \n",
      "epoch: 38 [506616/888800 57.00%] train loss: 1.5022178558865562e-05 \n",
      "epoch: 38 [507727/888800 57.12%] train loss: 1.391164096276043e-05 \n",
      "epoch: 38 [508838/888800 57.25%] train loss: 1.5610072296112776e-05 \n",
      "epoch: 38 [509949/888800 57.38%] train loss: 1.4164417734718882e-05 \n",
      "epoch: 38 [511060/888800 57.50%] train loss: 1.668784534558654e-05 \n",
      "epoch: 38 [512171/888800 57.62%] train loss: 1.4326088603411335e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [513282/888800 57.75%] train loss: 1.4979315892560408e-05 \n",
      "epoch: 38 [514393/888800 57.88%] train loss: 1.4432549505727366e-05 \n",
      "epoch: 38 [515504/888800 58.00%] train loss: 1.3251727978058625e-05 \n",
      "epoch: 38 [516615/888800 58.12%] train loss: 1.5451039871550165e-05 \n",
      "epoch: 38 [517726/888800 58.25%] train loss: 1.4795552488067187e-05 \n",
      "epoch: 38 [518837/888800 58.38%] train loss: 1.4671413737232797e-05 \n",
      "epoch: 38 [519948/888800 58.50%] train loss: 1.392986268911045e-05 \n",
      "epoch: 38 [521059/888800 58.62%] train loss: 1.4280418326961808e-05 \n",
      "epoch: 38 [522170/888800 58.75%] train loss: 1.2740697457047645e-05 \n",
      "epoch: 38 [523281/888800 58.88%] train loss: 1.6021429473767057e-05 \n",
      "epoch: 38 [524392/888800 59.00%] train loss: 1.592628723301459e-05 \n",
      "epoch: 38 [525503/888800 59.12%] train loss: 1.3870213479094673e-05 \n",
      "epoch: 38 [526614/888800 59.25%] train loss: 1.5500558220082894e-05 \n",
      "epoch: 38 [527725/888800 59.38%] train loss: 1.3495880011760164e-05 \n",
      "epoch: 38 [528836/888800 59.50%] train loss: 1.3591818969871383e-05 \n",
      "epoch: 38 [529947/888800 59.62%] train loss: 1.3301508261065464e-05 \n",
      "epoch: 38 [531058/888800 59.75%] train loss: 1.3353203030419536e-05 \n",
      "epoch: 38 [532169/888800 59.88%] train loss: 1.3101459444442298e-05 \n",
      "epoch: 38 [533280/888800 60.00%] train loss: 1.592706576047931e-05 \n",
      "epoch: 38 [534391/888800 60.12%] train loss: 1.3961485819891095e-05 \n",
      "epoch: 38 [535502/888800 60.25%] train loss: 1.479828824813012e-05 \n",
      "epoch: 38 [536613/888800 60.38%] train loss: 1.4536428352585062e-05 \n",
      "epoch: 38 [537724/888800 60.50%] train loss: 1.5232484656735323e-05 \n",
      "epoch: 38 [538835/888800 60.62%] train loss: 1.4542571079800837e-05 \n",
      "epoch: 38 [539946/888800 60.75%] train loss: 1.4196277334121987e-05 \n",
      "epoch: 38 [541057/888800 60.88%] train loss: 1.4579078197130002e-05 \n",
      "epoch: 38 [542168/888800 61.00%] train loss: 1.4614132851420436e-05 \n",
      "epoch: 38 [543279/888800 61.12%] train loss: 1.3306183063832577e-05 \n",
      "epoch: 38 [544390/888800 61.25%] train loss: 1.517534110462293e-05 \n",
      "epoch: 38 [545501/888800 61.38%] train loss: 1.4434515833272599e-05 \n",
      "epoch: 38 [546612/888800 61.50%] train loss: 1.3964921890874393e-05 \n",
      "epoch: 38 [547723/888800 61.62%] train loss: 1.3913156180933584e-05 \n",
      "epoch: 38 [548834/888800 61.75%] train loss: 1.4031170394446235e-05 \n",
      "epoch: 38 [549945/888800 61.88%] train loss: 1.4145644854579587e-05 \n",
      "epoch: 38 [551056/888800 62.00%] train loss: 1.3550182302424219e-05 \n",
      "epoch: 38 [552167/888800 62.12%] train loss: 1.4386620932782535e-05 \n",
      "epoch: 38 [553278/888800 62.25%] train loss: 1.4141483916318975e-05 \n",
      "epoch: 38 [554389/888800 62.38%] train loss: 1.3973693057778291e-05 \n",
      "epoch: 38 [555500/888800 62.50%] train loss: 1.3425720680970699e-05 \n",
      "epoch: 38 [556611/888800 62.62%] train loss: 1.4182529412209988e-05 \n",
      "epoch: 38 [557722/888800 62.75%] train loss: 1.4777677279198542e-05 \n",
      "epoch: 38 [558833/888800 62.88%] train loss: 1.4125531379249878e-05 \n",
      "epoch: 38 [559944/888800 63.00%] train loss: 1.4563634067599196e-05 \n",
      "epoch: 38 [561055/888800 63.12%] train loss: 1.4044750969333109e-05 \n",
      "epoch: 38 [562166/888800 63.25%] train loss: 1.3832888726028614e-05 \n",
      "epoch: 38 [563277/888800 63.38%] train loss: 1.24287762446329e-05 \n",
      "epoch: 38 [564388/888800 63.50%] train loss: 1.4261128853831906e-05 \n",
      "epoch: 38 [565499/888800 63.62%] train loss: 1.4635969819210004e-05 \n",
      "epoch: 38 [566610/888800 63.75%] train loss: 1.3793507605441846e-05 \n",
      "epoch: 38 [567721/888800 63.88%] train loss: 1.559636257297825e-05 \n",
      "epoch: 38 [568832/888800 64.00%] train loss: 1.54080171341775e-05 \n",
      "epoch: 38 [569943/888800 64.12%] train loss: 1.3233964637038298e-05 \n",
      "epoch: 38 [571054/888800 64.25%] train loss: 1.745693043631036e-05 \n",
      "epoch: 38 [572165/888800 64.38%] train loss: 1.4486331565422006e-05 \n",
      "epoch: 38 [573276/888800 64.50%] train loss: 1.4496748008241411e-05 \n",
      "epoch: 38 [574387/888800 64.62%] train loss: 1.4806493709329516e-05 \n",
      "epoch: 38 [575498/888800 64.75%] train loss: 1.4265191566664726e-05 \n",
      "epoch: 38 [576609/888800 64.88%] train loss: 1.5385705410153605e-05 \n",
      "epoch: 38 [577720/888800 65.00%] train loss: 1.5429350241902284e-05 \n",
      "epoch: 38 [578831/888800 65.12%] train loss: 1.369116853311425e-05 \n",
      "epoch: 38 [579942/888800 65.25%] train loss: 1.3948762898507994e-05 \n",
      "epoch: 38 [581053/888800 65.38%] train loss: 1.396186780766584e-05 \n",
      "epoch: 38 [582164/888800 65.50%] train loss: 1.527978020021692e-05 \n",
      "epoch: 38 [583275/888800 65.62%] train loss: 1.563736077514477e-05 \n",
      "epoch: 38 [584386/888800 65.75%] train loss: 1.5109244486666285e-05 \n",
      "epoch: 38 [585497/888800 65.88%] train loss: 1.4038297194929328e-05 \n",
      "epoch: 38 [586608/888800 66.00%] train loss: 1.2646019968087785e-05 \n",
      "epoch: 38 [587719/888800 66.12%] train loss: 1.3016066986892838e-05 \n",
      "epoch: 38 [588830/888800 66.25%] train loss: 1.4247636499931104e-05 \n",
      "epoch: 38 [589941/888800 66.38%] train loss: 1.3514312740880996e-05 \n",
      "epoch: 38 [591052/888800 66.50%] train loss: 1.4793727132200729e-05 \n",
      "epoch: 38 [592163/888800 66.62%] train loss: 1.4099891814112198e-05 \n",
      "epoch: 38 [593274/888800 66.75%] train loss: 1.4118891158432234e-05 \n",
      "epoch: 38 [594385/888800 66.88%] train loss: 1.5124217497941572e-05 \n",
      "epoch: 38 [595496/888800 67.00%] train loss: 1.3532437151297927e-05 \n",
      "epoch: 38 [596607/888800 67.12%] train loss: 1.3887656677979976e-05 \n",
      "epoch: 38 [597718/888800 67.25%] train loss: 1.4596372238884214e-05 \n",
      "epoch: 38 [598829/888800 67.38%] train loss: 1.4499350072583184e-05 \n",
      "epoch: 38 [599940/888800 67.50%] train loss: 1.5052768503664993e-05 \n",
      "epoch: 38 [601051/888800 67.62%] train loss: 1.3824383131577633e-05 \n",
      "epoch: 38 [602162/888800 67.75%] train loss: 1.4440620361710899e-05 \n",
      "epoch: 38 [603273/888800 67.88%] train loss: 1.4435976481763646e-05 \n",
      "epoch: 38 [604384/888800 68.00%] train loss: 1.394986429659184e-05 \n",
      "epoch: 38 [605495/888800 68.12%] train loss: 1.5174224245129153e-05 \n",
      "epoch: 38 [606606/888800 68.25%] train loss: 1.327237805526238e-05 \n",
      "epoch: 38 [607717/888800 68.38%] train loss: 1.4528104657074437e-05 \n",
      "epoch: 38 [608828/888800 68.50%] train loss: 1.4659933185612317e-05 \n",
      "epoch: 38 [609939/888800 68.62%] train loss: 1.4741324775968678e-05 \n",
      "epoch: 38 [611050/888800 68.75%] train loss: 1.4687105249322485e-05 \n",
      "epoch: 38 [612161/888800 68.88%] train loss: 1.4870125596644357e-05 \n",
      "epoch: 38 [613272/888800 69.00%] train loss: 1.3334481991478242e-05 \n",
      "epoch: 38 [614383/888800 69.12%] train loss: 1.2994011740374845e-05 \n",
      "epoch: 38 [615494/888800 69.25%] train loss: 1.4452362847805489e-05 \n",
      "epoch: 38 [616605/888800 69.38%] train loss: 1.3767154086963274e-05 \n",
      "epoch: 38 [617716/888800 69.50%] train loss: 1.5046013686514925e-05 \n",
      "epoch: 38 [618827/888800 69.62%] train loss: 1.4906577234796714e-05 \n",
      "epoch: 38 [619938/888800 69.75%] train loss: 1.3770760233455803e-05 \n",
      "epoch: 38 [621049/888800 69.88%] train loss: 1.4890433703840245e-05 \n",
      "epoch: 38 [622160/888800 70.00%] train loss: 1.3558351383835543e-05 \n",
      "epoch: 38 [623271/888800 70.12%] train loss: 1.4605237083742395e-05 \n",
      "epoch: 38 [624382/888800 70.25%] train loss: 1.4239009033190086e-05 \n",
      "epoch: 38 [625493/888800 70.38%] train loss: 1.4229179214453325e-05 \n",
      "epoch: 38 [626604/888800 70.50%] train loss: 1.4610823200200684e-05 \n",
      "epoch: 38 [627715/888800 70.62%] train loss: 1.623948810447473e-05 \n",
      "epoch: 38 [628826/888800 70.75%] train loss: 1.4456059943768196e-05 \n",
      "epoch: 38 [629937/888800 70.88%] train loss: 1.4738231584487949e-05 \n",
      "epoch: 38 [631048/888800 71.00%] train loss: 1.5047086890263017e-05 \n",
      "epoch: 38 [632159/888800 71.12%] train loss: 1.369341498502763e-05 \n",
      "epoch: 38 [633270/888800 71.25%] train loss: 1.519952365924837e-05 \n",
      "epoch: 38 [634381/888800 71.38%] train loss: 1.441873155272333e-05 \n",
      "epoch: 38 [635492/888800 71.50%] train loss: 1.4667859431938268e-05 \n",
      "epoch: 38 [636603/888800 71.62%] train loss: 1.2975050594832283e-05 \n",
      "epoch: 38 [637714/888800 71.75%] train loss: 1.527502536191605e-05 \n",
      "epoch: 38 [638825/888800 71.88%] train loss: 1.457092548662331e-05 \n",
      "epoch: 38 [639936/888800 72.00%] train loss: 1.639423135202378e-05 \n",
      "epoch: 38 [641047/888800 72.12%] train loss: 1.4239793017623015e-05 \n",
      "epoch: 38 [642158/888800 72.25%] train loss: 1.528149914520327e-05 \n",
      "epoch: 38 [643269/888800 72.38%] train loss: 1.4506986190099269e-05 \n",
      "epoch: 38 [644380/888800 72.50%] train loss: 1.552671346871648e-05 \n",
      "epoch: 38 [645491/888800 72.62%] train loss: 1.5568248272757046e-05 \n",
      "epoch: 38 [646602/888800 72.75%] train loss: 1.3573107935371809e-05 \n",
      "epoch: 38 [647713/888800 72.88%] train loss: 1.4847173588350415e-05 \n",
      "epoch: 38 [648824/888800 73.00%] train loss: 1.440225423721131e-05 \n",
      "epoch: 38 [649935/888800 73.12%] train loss: 1.3446633602143265e-05 \n",
      "epoch: 38 [651046/888800 73.25%] train loss: 1.4517475392494816e-05 \n",
      "epoch: 38 [652157/888800 73.38%] train loss: 1.467273887101328e-05 \n",
      "epoch: 38 [653268/888800 73.50%] train loss: 1.528368920844514e-05 \n",
      "epoch: 38 [654379/888800 73.62%] train loss: 1.4689311683468986e-05 \n",
      "epoch: 38 [655490/888800 73.75%] train loss: 1.388719192618737e-05 \n",
      "epoch: 38 [656601/888800 73.88%] train loss: 1.4175176147546154e-05 \n",
      "epoch: 38 [657712/888800 74.00%] train loss: 1.4506800653180107e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [658823/888800 74.12%] train loss: 1.3949123967904598e-05 \n",
      "epoch: 38 [659934/888800 74.25%] train loss: 1.4232839021133259e-05 \n",
      "epoch: 38 [661045/888800 74.38%] train loss: 1.4670717064291239e-05 \n",
      "epoch: 38 [662156/888800 74.50%] train loss: 1.3362293429963756e-05 \n",
      "epoch: 38 [663267/888800 74.62%] train loss: 1.4736351658939384e-05 \n",
      "epoch: 38 [664378/888800 74.75%] train loss: 1.404689101036638e-05 \n",
      "epoch: 38 [665489/888800 74.88%] train loss: 1.3659136129717808e-05 \n",
      "epoch: 38 [666600/888800 75.00%] train loss: 1.4093380741542205e-05 \n",
      "epoch: 38 [667711/888800 75.12%] train loss: 1.4714702956553083e-05 \n",
      "epoch: 38 [668822/888800 75.25%] train loss: 1.3038407814747188e-05 \n",
      "epoch: 38 [669933/888800 75.38%] train loss: 1.3955848771729507e-05 \n",
      "epoch: 38 [671044/888800 75.50%] train loss: 1.4129637747828383e-05 \n",
      "epoch: 38 [672155/888800 75.62%] train loss: 1.3976849913888145e-05 \n",
      "epoch: 38 [673266/888800 75.75%] train loss: 1.4922316040610895e-05 \n",
      "epoch: 38 [674377/888800 75.88%] train loss: 1.4801856195845176e-05 \n",
      "epoch: 38 [675488/888800 76.00%] train loss: 1.4330414160212968e-05 \n",
      "epoch: 38 [676599/888800 76.12%] train loss: 1.3874956493964419e-05 \n",
      "epoch: 38 [677710/888800 76.25%] train loss: 1.4116808415565174e-05 \n",
      "epoch: 38 [678821/888800 76.38%] train loss: 1.3801603017782327e-05 \n",
      "epoch: 38 [679932/888800 76.50%] train loss: 1.410862387274392e-05 \n",
      "epoch: 38 [681043/888800 76.62%] train loss: 1.426468043064233e-05 \n",
      "epoch: 38 [682154/888800 76.75%] train loss: 1.5355593859567307e-05 \n",
      "epoch: 38 [683265/888800 76.88%] train loss: 1.4034883861313574e-05 \n",
      "epoch: 38 [684376/888800 77.00%] train loss: 1.4022302821103949e-05 \n",
      "epoch: 38 [685487/888800 77.12%] train loss: 1.3543933164328337e-05 \n",
      "epoch: 38 [686598/888800 77.25%] train loss: 1.4720932995260227e-05 \n",
      "epoch: 38 [687709/888800 77.38%] train loss: 1.341450752079254e-05 \n",
      "epoch: 38 [688820/888800 77.50%] train loss: 1.5061612430145033e-05 \n",
      "epoch: 38 [689931/888800 77.62%] train loss: 1.64465145644499e-05 \n",
      "epoch: 38 [691042/888800 77.75%] train loss: 1.40490556077566e-05 \n",
      "epoch: 38 [692153/888800 77.88%] train loss: 1.5390020053018816e-05 \n",
      "epoch: 38 [693264/888800 78.00%] train loss: 1.3385053534875624e-05 \n",
      "epoch: 38 [694375/888800 78.12%] train loss: 1.3728756130149122e-05 \n",
      "epoch: 38 [695486/888800 78.25%] train loss: 1.4509685570374131e-05 \n",
      "epoch: 38 [696597/888800 78.38%] train loss: 1.449779392714845e-05 \n",
      "epoch: 38 [697708/888800 78.50%] train loss: 1.4376670151250437e-05 \n",
      "epoch: 38 [698819/888800 78.62%] train loss: 1.4362973161041737e-05 \n",
      "epoch: 38 [699930/888800 78.75%] train loss: 1.5236739272950217e-05 \n",
      "epoch: 38 [701041/888800 78.88%] train loss: 1.3000956641917583e-05 \n",
      "epoch: 38 [702152/888800 79.00%] train loss: 1.465582590753911e-05 \n",
      "epoch: 38 [703263/888800 79.12%] train loss: 1.3483655493473634e-05 \n",
      "epoch: 38 [704374/888800 79.25%] train loss: 1.329236965830205e-05 \n",
      "epoch: 38 [705485/888800 79.38%] train loss: 1.5628053006366827e-05 \n",
      "epoch: 38 [706596/888800 79.50%] train loss: 1.4574700799130369e-05 \n",
      "epoch: 38 [707707/888800 79.62%] train loss: 1.3266761925478932e-05 \n",
      "epoch: 38 [708818/888800 79.75%] train loss: 1.4122092579782475e-05 \n",
      "epoch: 38 [709929/888800 79.88%] train loss: 1.3359703189053107e-05 \n",
      "epoch: 38 [711040/888800 80.00%] train loss: 1.3761830814473797e-05 \n",
      "epoch: 38 [712151/888800 80.12%] train loss: 1.415456790709868e-05 \n",
      "epoch: 38 [713262/888800 80.25%] train loss: 1.556653660372831e-05 \n",
      "epoch: 38 [714373/888800 80.38%] train loss: 1.3838220183970407e-05 \n",
      "epoch: 38 [715484/888800 80.50%] train loss: 1.4779742741666269e-05 \n",
      "epoch: 38 [716595/888800 80.62%] train loss: 1.379895729769487e-05 \n",
      "epoch: 38 [717706/888800 80.75%] train loss: 1.4438624020840507e-05 \n",
      "epoch: 38 [718817/888800 80.88%] train loss: 1.4343908333103172e-05 \n",
      "epoch: 38 [719928/888800 81.00%] train loss: 1.3857268641004339e-05 \n",
      "epoch: 38 [721039/888800 81.12%] train loss: 1.4467307664745022e-05 \n",
      "epoch: 38 [722150/888800 81.25%] train loss: 1.4685567293781787e-05 \n",
      "epoch: 38 [723261/888800 81.38%] train loss: 1.399525808665203e-05 \n",
      "epoch: 38 [724372/888800 81.50%] train loss: 1.575582064106129e-05 \n",
      "epoch: 38 [725483/888800 81.62%] train loss: 1.5271538359229453e-05 \n",
      "epoch: 38 [726594/888800 81.75%] train loss: 1.4904468116583303e-05 \n",
      "epoch: 38 [727705/888800 81.88%] train loss: 1.5609062756993808e-05 \n",
      "epoch: 38 [728816/888800 82.00%] train loss: 1.655237065278925e-05 \n",
      "epoch: 38 [729927/888800 82.12%] train loss: 1.3754141946265008e-05 \n",
      "epoch: 38 [731038/888800 82.25%] train loss: 1.4839015420875512e-05 \n",
      "epoch: 38 [732149/888800 82.38%] train loss: 1.3608693734568078e-05 \n",
      "epoch: 38 [733260/888800 82.50%] train loss: 1.3858081729267724e-05 \n",
      "epoch: 38 [734371/888800 82.62%] train loss: 1.4909354831615929e-05 \n",
      "epoch: 38 [735482/888800 82.75%] train loss: 1.3738657798967324e-05 \n",
      "epoch: 38 [736593/888800 82.88%] train loss: 1.5005944078438915e-05 \n",
      "epoch: 38 [737704/888800 83.00%] train loss: 1.3223891983216163e-05 \n",
      "epoch: 38 [738815/888800 83.12%] train loss: 1.4584111340809613e-05 \n",
      "epoch: 38 [739926/888800 83.25%] train loss: 1.489443820901215e-05 \n",
      "epoch: 38 [741037/888800 83.38%] train loss: 1.4925716641300824e-05 \n",
      "epoch: 38 [742148/888800 83.50%] train loss: 1.3963011042505968e-05 \n",
      "epoch: 38 [743259/888800 83.62%] train loss: 1.2602937204064801e-05 \n",
      "epoch: 38 [744370/888800 83.75%] train loss: 1.3382896213443018e-05 \n",
      "epoch: 38 [745481/888800 83.88%] train loss: 1.4743553947482724e-05 \n",
      "epoch: 38 [746592/888800 84.00%] train loss: 1.4773093425901607e-05 \n",
      "epoch: 38 [747703/888800 84.12%] train loss: 1.4459093108598609e-05 \n",
      "epoch: 38 [748814/888800 84.25%] train loss: 1.3475772902893368e-05 \n",
      "epoch: 38 [749925/888800 84.38%] train loss: 1.322014031757135e-05 \n",
      "epoch: 38 [751036/888800 84.50%] train loss: 1.4277106856752653e-05 \n",
      "epoch: 38 [752147/888800 84.62%] train loss: 1.2850523489760235e-05 \n",
      "epoch: 38 [753258/888800 84.75%] train loss: 1.537003663543146e-05 \n",
      "epoch: 38 [754369/888800 84.88%] train loss: 1.4649662261945195e-05 \n",
      "epoch: 38 [755480/888800 85.00%] train loss: 1.5000047824287321e-05 \n",
      "epoch: 38 [756591/888800 85.12%] train loss: 1.4280037248681765e-05 \n",
      "epoch: 38 [757702/888800 85.25%] train loss: 1.4577543879568111e-05 \n",
      "epoch: 38 [758813/888800 85.38%] train loss: 1.4491583897324745e-05 \n",
      "epoch: 38 [759924/888800 85.50%] train loss: 1.4504255887004547e-05 \n",
      "epoch: 38 [761035/888800 85.62%] train loss: 1.4747160093975253e-05 \n",
      "epoch: 38 [762146/888800 85.75%] train loss: 1.4396897313417867e-05 \n",
      "epoch: 38 [763257/888800 85.88%] train loss: 1.3812408724334091e-05 \n",
      "epoch: 38 [764368/888800 86.00%] train loss: 1.4698166523885448e-05 \n",
      "epoch: 38 [765479/888800 86.12%] train loss: 1.5378003809018992e-05 \n",
      "epoch: 38 [766590/888800 86.25%] train loss: 1.5379493561340496e-05 \n",
      "epoch: 38 [767701/888800 86.38%] train loss: 1.5323075786000118e-05 \n",
      "epoch: 38 [768812/888800 86.50%] train loss: 1.4365261449711397e-05 \n",
      "epoch: 38 [769923/888800 86.62%] train loss: 1.5326722859754227e-05 \n",
      "epoch: 38 [771034/888800 86.75%] train loss: 1.4519477190333419e-05 \n",
      "epoch: 38 [772145/888800 86.88%] train loss: 1.4002678653923795e-05 \n",
      "epoch: 38 [773256/888800 87.00%] train loss: 1.5038410310808104e-05 \n",
      "epoch: 38 [774367/888800 87.12%] train loss: 1.4145544810162392e-05 \n",
      "epoch: 38 [775478/888800 87.25%] train loss: 1.3615408533951268e-05 \n",
      "epoch: 38 [776589/888800 87.38%] train loss: 1.3816277714795433e-05 \n",
      "epoch: 38 [777700/888800 87.50%] train loss: 1.538309697934892e-05 \n",
      "epoch: 38 [778811/888800 87.62%] train loss: 1.346075350738829e-05 \n",
      "epoch: 38 [779922/888800 87.75%] train loss: 1.5452105799340643e-05 \n",
      "epoch: 38 [781033/888800 87.88%] train loss: 1.4824328900431283e-05 \n",
      "epoch: 38 [782144/888800 88.00%] train loss: 1.5075510418682825e-05 \n",
      "epoch: 38 [783255/888800 88.12%] train loss: 1.5519761291216128e-05 \n",
      "epoch: 38 [784366/888800 88.25%] train loss: 1.599964343768079e-05 \n",
      "epoch: 38 [785477/888800 88.38%] train loss: 1.5917907148832455e-05 \n",
      "epoch: 38 [786588/888800 88.50%] train loss: 1.4898405424901284e-05 \n",
      "epoch: 38 [787699/888800 88.62%] train loss: 1.3522289918910246e-05 \n",
      "epoch: 38 [788810/888800 88.75%] train loss: 1.4684167581435759e-05 \n",
      "epoch: 38 [789921/888800 88.88%] train loss: 1.5462839655810967e-05 \n",
      "epoch: 38 [791032/888800 89.00%] train loss: 1.3571391718869563e-05 \n",
      "epoch: 38 [792143/888800 89.12%] train loss: 1.3764260984316934e-05 \n",
      "epoch: 38 [793254/888800 89.25%] train loss: 1.4313222891360056e-05 \n",
      "epoch: 38 [794365/888800 89.38%] train loss: 1.6580936062382534e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 [795476/888800 89.50%] train loss: 1.5121050637389999e-05 \n",
      "epoch: 38 [796587/888800 89.62%] train loss: 1.4096434824750759e-05 \n",
      "epoch: 38 [797698/888800 89.75%] train loss: 1.4156190445646644e-05 \n",
      "epoch: 38 [798809/888800 89.88%] train loss: 1.4028644727659412e-05 \n",
      "epoch: 38 [799920/888800 90.00%] train loss: 1.4302269846666604e-05 \n",
      "epoch: 38 [801031/888800 90.12%] train loss: 1.4043908777239267e-05 \n",
      "epoch: 38 [802142/888800 90.25%] train loss: 1.3452186067297589e-05 \n",
      "epoch: 38 [803253/888800 90.38%] train loss: 1.3629950444737915e-05 \n",
      "epoch: 38 [804364/888800 90.50%] train loss: 1.5662730220356025e-05 \n",
      "epoch: 38 [805475/888800 90.62%] train loss: 1.4676958016934805e-05 \n",
      "epoch: 38 [806586/888800 90.75%] train loss: 1.4582127732865047e-05 \n",
      "epoch: 38 [807697/888800 90.88%] train loss: 1.4641632333223242e-05 \n",
      "epoch: 38 [808808/888800 91.00%] train loss: 1.4021960851096082e-05 \n",
      "epoch: 38 [809919/888800 91.12%] train loss: 1.3405280697043054e-05 \n",
      "epoch: 38 [811030/888800 91.25%] train loss: 1.3481043424690142e-05 \n",
      "epoch: 38 [812141/888800 91.38%] train loss: 1.4167041626933496e-05 \n",
      "epoch: 38 [813252/888800 91.50%] train loss: 1.3053142538410611e-05 \n",
      "epoch: 38 [814363/888800 91.62%] train loss: 1.2855063687311485e-05 \n",
      "epoch: 38 [815474/888800 91.75%] train loss: 1.3898810721002519e-05 \n",
      "epoch: 38 [816585/888800 91.88%] train loss: 1.4316073247755412e-05 \n",
      "epoch: 38 [817696/888800 92.00%] train loss: 1.5157623238337692e-05 \n",
      "epoch: 38 [818807/888800 92.12%] train loss: 1.5545267160632648e-05 \n",
      "epoch: 38 [819918/888800 92.25%] train loss: 1.4210366316547152e-05 \n",
      "epoch: 38 [821029/888800 92.38%] train loss: 1.4515027032757644e-05 \n",
      "epoch: 38 [822140/888800 92.50%] train loss: 1.3755074178334326e-05 \n",
      "epoch: 38 [823251/888800 92.62%] train loss: 1.3833451703249011e-05 \n",
      "epoch: 38 [824362/888800 92.75%] train loss: 1.4185718100634404e-05 \n",
      "epoch: 38 [825473/888800 92.88%] train loss: 1.4957377970858943e-05 \n",
      "epoch: 38 [826584/888800 93.00%] train loss: 1.4315387488750275e-05 \n",
      "epoch: 38 [827695/888800 93.12%] train loss: 1.4468031622527633e-05 \n",
      "epoch: 38 [828806/888800 93.25%] train loss: 1.4526771337841637e-05 \n",
      "epoch: 38 [829917/888800 93.38%] train loss: 1.5195935702649876e-05 \n",
      "epoch: 38 [831028/888800 93.50%] train loss: 1.6476436940138228e-05 \n",
      "epoch: 38 [832139/888800 93.62%] train loss: 1.4105628906690981e-05 \n",
      "epoch: 38 [833250/888800 93.75%] train loss: 1.5120623174880166e-05 \n",
      "epoch: 38 [834361/888800 93.88%] train loss: 1.584273013577331e-05 \n",
      "epoch: 38 [835472/888800 94.00%] train loss: 1.370179234072566e-05 \n",
      "epoch: 38 [836583/888800 94.12%] train loss: 1.3141806448402349e-05 \n",
      "epoch: 38 [837694/888800 94.25%] train loss: 1.291430635319557e-05 \n",
      "epoch: 38 [838805/888800 94.38%] train loss: 1.409808191965567e-05 \n",
      "epoch: 38 [839916/888800 94.50%] train loss: 1.4122894754109439e-05 \n",
      "epoch: 38 [841027/888800 94.62%] train loss: 1.4051706784812268e-05 \n",
      "epoch: 38 [842138/888800 94.75%] train loss: 1.3785406736133154e-05 \n",
      "epoch: 38 [843249/888800 94.88%] train loss: 1.5949281078064814e-05 \n",
      "epoch: 38 [844360/888800 95.00%] train loss: 1.3839640814694576e-05 \n",
      "epoch: 38 [845471/888800 95.12%] train loss: 1.3717727597395424e-05 \n",
      "epoch: 38 [846582/888800 95.25%] train loss: 1.4142565305519383e-05 \n",
      "epoch: 38 [847693/888800 95.38%] train loss: 1.3648274943989236e-05 \n",
      "epoch: 38 [848804/888800 95.50%] train loss: 1.4760076737729833e-05 \n",
      "epoch: 38 [849915/888800 95.62%] train loss: 1.4013240615895484e-05 \n",
      "epoch: 38 [851026/888800 95.75%] train loss: 1.5402958524646237e-05 \n",
      "epoch: 38 [852137/888800 95.88%] train loss: 1.3959875104774255e-05 \n",
      "epoch: 38 [853248/888800 96.00%] train loss: 1.476505622122204e-05 \n",
      "epoch: 38 [854359/888800 96.12%] train loss: 1.4968579307605978e-05 \n",
      "epoch: 38 [855470/888800 96.25%] train loss: 1.4673429177491926e-05 \n",
      "epoch: 38 [856581/888800 96.38%] train loss: 1.4738979189132806e-05 \n",
      "epoch: 38 [857692/888800 96.50%] train loss: 1.4471251233771909e-05 \n",
      "epoch: 38 [858803/888800 96.62%] train loss: 1.3709091035707388e-05 \n",
      "epoch: 38 [859914/888800 96.75%] train loss: 1.4531673514284194e-05 \n",
      "epoch: 38 [861025/888800 96.88%] train loss: 1.4461972568824422e-05 \n",
      "epoch: 38 [862136/888800 97.00%] train loss: 1.3697315807803534e-05 \n",
      "epoch: 38 [863247/888800 97.12%] train loss: 1.290035288548097e-05 \n",
      "epoch: 38 [864358/888800 97.25%] train loss: 1.2520764357759617e-05 \n",
      "epoch: 38 [865469/888800 97.38%] train loss: 1.4921011825208552e-05 \n",
      "epoch: 38 [866580/888800 97.50%] train loss: 1.4631777048634831e-05 \n",
      "epoch: 38 [867691/888800 97.62%] train loss: 1.4410567018785514e-05 \n",
      "epoch: 38 [868802/888800 97.75%] train loss: 1.3909130757383537e-05 \n",
      "epoch: 38 [869913/888800 97.88%] train loss: 1.4788257431064267e-05 \n",
      "epoch: 38 [871024/888800 98.00%] train loss: 1.3203969501773827e-05 \n",
      "epoch: 38 [872135/888800 98.12%] train loss: 1.3034941730438732e-05 \n",
      "epoch: 38 [873246/888800 98.25%] train loss: 1.4423999346035998e-05 \n",
      "epoch: 38 [874357/888800 98.38%] train loss: 1.4484460734820459e-05 \n",
      "epoch: 38 [875468/888800 98.50%] train loss: 1.4426812413148582e-05 \n",
      "epoch: 38 [876579/888800 98.62%] train loss: 1.4328623365145177e-05 \n",
      "epoch: 38 [877690/888800 98.75%] train loss: 1.4715212273586076e-05 \n",
      "epoch: 38 [878801/888800 98.88%] train loss: 1.3413497981673572e-05 \n",
      "epoch: 38 [879912/888800 99.00%] train loss: 1.3450470760290045e-05 \n",
      "epoch: 38 [881023/888800 99.12%] train loss: 1.3393731933319941e-05 \n",
      "epoch: 38 [882134/888800 99.25%] train loss: 1.3816125829180237e-05 \n",
      "epoch: 38 [883245/888800 99.38%] train loss: 1.4800158169236965e-05 \n",
      "epoch: 38 [884356/888800 99.50%] train loss: 1.4180088328430429e-05 \n",
      "epoch: 38 [885467/888800 99.62%] train loss: 1.362868624710245e-05 \n",
      "epoch: 38 [886578/888800 99.75%] train loss: 1.4167034350975882e-05 \n",
      "epoch: 38 [887689/888800 99.88%] train loss: 1.4230688066163566e-05 \n",
      "epoch: 39 [0/888800 0.00%] train loss: 1.4197160453477409e-05 \n",
      "epoch: 39 [1111/888800 0.12%] train loss: 1.496121876698453e-05 \n",
      "epoch: 39 [2222/888800 0.25%] train loss: 1.3841693544236477e-05 \n",
      "epoch: 39 [3333/888800 0.38%] train loss: 1.366625747323269e-05 \n",
      "epoch: 39 [4444/888800 0.50%] train loss: 1.4466895663645118e-05 \n",
      "epoch: 39 [5555/888800 0.62%] train loss: 1.564605554449372e-05 \n",
      "epoch: 39 [6666/888800 0.75%] train loss: 1.4696307516715024e-05 \n",
      "epoch: 39 [7777/888800 0.88%] train loss: 1.4960970474930946e-05 \n",
      "epoch: 39 [8888/888800 1.00%] train loss: 1.4029046724317595e-05 \n",
      "epoch: 39 [9999/888800 1.12%] train loss: 1.3042684258834925e-05 \n",
      "epoch: 39 [11110/888800 1.25%] train loss: 1.4262923286878504e-05 \n",
      "epoch: 39 [12221/888800 1.38%] train loss: 1.4459968042501714e-05 \n",
      "epoch: 39 [13332/888800 1.50%] train loss: 1.3332100024854299e-05 \n",
      "epoch: 39 [14443/888800 1.62%] train loss: 1.4598205780202989e-05 \n",
      "epoch: 39 [15554/888800 1.75%] train loss: 1.4747120076208375e-05 \n",
      "epoch: 39 [16665/888800 1.88%] train loss: 1.3698074326384813e-05 \n",
      "epoch: 39 [17776/888800 2.00%] train loss: 1.3037376447755378e-05 \n",
      "epoch: 39 [18887/888800 2.12%] train loss: 1.485659413447138e-05 \n",
      "epoch: 39 [19998/888800 2.25%] train loss: 1.3089423191559035e-05 \n",
      "epoch: 39 [21109/888800 2.38%] train loss: 1.4557076610799413e-05 \n",
      "epoch: 39 [22220/888800 2.50%] train loss: 1.4023132280271966e-05 \n",
      "epoch: 39 [23331/888800 2.62%] train loss: 1.4720911167387385e-05 \n",
      "epoch: 39 [24442/888800 2.75%] train loss: 1.5228246411425062e-05 \n",
      "epoch: 39 [25553/888800 2.88%] train loss: 1.434277328371536e-05 \n",
      "epoch: 39 [26664/888800 3.00%] train loss: 1.468587106501218e-05 \n",
      "epoch: 39 [27775/888800 3.12%] train loss: 1.4706578440382145e-05 \n",
      "epoch: 39 [28886/888800 3.25%] train loss: 1.4779749108129181e-05 \n",
      "epoch: 39 [29997/888800 3.38%] train loss: 1.3743268937105313e-05 \n",
      "epoch: 39 [31108/888800 3.50%] train loss: 1.47034261317458e-05 \n",
      "epoch: 39 [32219/888800 3.62%] train loss: 1.5268378774635494e-05 \n",
      "epoch: 39 [33330/888800 3.75%] train loss: 1.4941214431019034e-05 \n",
      "epoch: 39 [34441/888800 3.88%] train loss: 1.43846536957426e-05 \n",
      "epoch: 39 [35552/888800 4.00%] train loss: 1.401783993060235e-05 \n",
      "epoch: 39 [36663/888800 4.12%] train loss: 1.2692783457168844e-05 \n",
      "epoch: 39 [37774/888800 4.25%] train loss: 1.3303087143867742e-05 \n",
      "epoch: 39 [38885/888800 4.38%] train loss: 1.3186266187403817e-05 \n",
      "epoch: 39 [39996/888800 4.50%] train loss: 1.3638652490044478e-05 \n",
      "epoch: 39 [41107/888800 4.62%] train loss: 1.37693223223323e-05 \n",
      "epoch: 39 [42218/888800 4.75%] train loss: 1.4858832400932442e-05 \n",
      "epoch: 39 [43329/888800 4.88%] train loss: 1.4090476724959444e-05 \n",
      "epoch: 39 [44440/888800 5.00%] train loss: 1.484953099861741e-05 \n",
      "epoch: 39 [45551/888800 5.12%] train loss: 1.3832480362907518e-05 \n",
      "epoch: 39 [46662/888800 5.25%] train loss: 1.4606590411858633e-05 \n",
      "epoch: 39 [47773/888800 5.38%] train loss: 1.5435074601555243e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [48884/888800 5.50%] train loss: 1.472572057537036e-05 \n",
      "epoch: 39 [49995/888800 5.62%] train loss: 1.3993773791298736e-05 \n",
      "epoch: 39 [51106/888800 5.75%] train loss: 1.4733888747286983e-05 \n",
      "epoch: 39 [52217/888800 5.88%] train loss: 1.3830921488988679e-05 \n",
      "epoch: 39 [53328/888800 6.00%] train loss: 1.5460571376024745e-05 \n",
      "epoch: 39 [54439/888800 6.12%] train loss: 1.4342494978336617e-05 \n",
      "epoch: 39 [55550/888800 6.25%] train loss: 1.3304798812896479e-05 \n",
      "epoch: 39 [56661/888800 6.38%] train loss: 1.4764023035240825e-05 \n",
      "epoch: 39 [57772/888800 6.50%] train loss: 1.4550224477716256e-05 \n",
      "epoch: 39 [58883/888800 6.62%] train loss: 1.477456225984497e-05 \n",
      "epoch: 39 [59994/888800 6.75%] train loss: 1.3785062947135884e-05 \n",
      "epoch: 39 [61105/888800 6.88%] train loss: 1.4930353245290462e-05 \n",
      "epoch: 39 [62216/888800 7.00%] train loss: 1.5043715393403545e-05 \n",
      "epoch: 39 [63327/888800 7.12%] train loss: 1.4488130545942113e-05 \n",
      "epoch: 39 [64438/888800 7.25%] train loss: 1.4663672118331306e-05 \n",
      "epoch: 39 [65549/888800 7.38%] train loss: 1.3296520592120942e-05 \n",
      "epoch: 39 [66660/888800 7.50%] train loss: 1.4250441381591372e-05 \n",
      "epoch: 39 [67771/888800 7.62%] train loss: 1.5015904864412732e-05 \n",
      "epoch: 39 [68882/888800 7.75%] train loss: 1.6489670088049024e-05 \n",
      "epoch: 39 [69993/888800 7.88%] train loss: 1.4894202649884392e-05 \n",
      "epoch: 39 [71104/888800 8.00%] train loss: 1.4893308616592549e-05 \n",
      "epoch: 39 [72215/888800 8.12%] train loss: 1.4991285752330441e-05 \n",
      "epoch: 39 [73326/888800 8.25%] train loss: 1.4328950783237815e-05 \n",
      "epoch: 39 [74437/888800 8.38%] train loss: 1.4372386431205086e-05 \n",
      "epoch: 39 [75548/888800 8.50%] train loss: 1.3822567780152895e-05 \n",
      "epoch: 39 [76659/888800 8.62%] train loss: 1.4039101188245695e-05 \n",
      "epoch: 39 [77770/888800 8.75%] train loss: 1.398644508299185e-05 \n",
      "epoch: 39 [78881/888800 8.88%] train loss: 1.557327777845785e-05 \n",
      "epoch: 39 [79992/888800 9.00%] train loss: 1.3712517102248967e-05 \n",
      "epoch: 39 [81103/888800 9.12%] train loss: 1.3554405995819252e-05 \n",
      "epoch: 39 [82214/888800 9.25%] train loss: 1.4471616850642022e-05 \n",
      "epoch: 39 [83325/888800 9.38%] train loss: 1.628544669074472e-05 \n",
      "epoch: 39 [84436/888800 9.50%] train loss: 1.528317625343334e-05 \n",
      "epoch: 39 [85547/888800 9.62%] train loss: 1.5158116184466053e-05 \n",
      "epoch: 39 [86658/888800 9.75%] train loss: 1.4314202417153865e-05 \n",
      "epoch: 39 [87769/888800 9.88%] train loss: 1.3419087736110669e-05 \n",
      "epoch: 39 [88880/888800 10.00%] train loss: 1.3382557881413959e-05 \n",
      "epoch: 39 [89991/888800 10.12%] train loss: 1.4142092368274461e-05 \n",
      "epoch: 39 [91102/888800 10.25%] train loss: 1.4253898370952811e-05 \n",
      "epoch: 39 [92213/888800 10.38%] train loss: 1.4003758224134799e-05 \n",
      "epoch: 39 [93324/888800 10.50%] train loss: 1.3170150850783102e-05 \n",
      "epoch: 39 [94435/888800 10.62%] train loss: 1.4197973541740794e-05 \n",
      "epoch: 39 [95546/888800 10.75%] train loss: 1.4075847502681427e-05 \n",
      "epoch: 39 [96657/888800 10.88%] train loss: 1.2560339200717863e-05 \n",
      "epoch: 39 [97768/888800 11.00%] train loss: 1.4589380953111686e-05 \n",
      "epoch: 39 [98879/888800 11.12%] train loss: 1.4326148630061653e-05 \n",
      "epoch: 39 [99990/888800 11.25%] train loss: 1.3170910278859083e-05 \n",
      "epoch: 39 [101101/888800 11.38%] train loss: 1.5004954548203386e-05 \n",
      "epoch: 39 [102212/888800 11.50%] train loss: 1.436517595720943e-05 \n",
      "epoch: 39 [103323/888800 11.62%] train loss: 1.522296679468127e-05 \n",
      "epoch: 39 [104434/888800 11.75%] train loss: 1.3910438610764686e-05 \n",
      "epoch: 39 [105545/888800 11.88%] train loss: 1.4094317521085031e-05 \n",
      "epoch: 39 [106656/888800 12.00%] train loss: 1.4621104128309526e-05 \n",
      "epoch: 39 [107767/888800 12.12%] train loss: 1.4726103472639807e-05 \n",
      "epoch: 39 [108878/888800 12.25%] train loss: 1.4586733414034825e-05 \n",
      "epoch: 39 [109989/888800 12.38%] train loss: 1.4090267541178036e-05 \n",
      "epoch: 39 [111100/888800 12.50%] train loss: 1.3737248991674278e-05 \n",
      "epoch: 39 [112211/888800 12.62%] train loss: 1.3934336493548471e-05 \n",
      "epoch: 39 [113322/888800 12.75%] train loss: 1.3594204574474134e-05 \n",
      "epoch: 39 [114433/888800 12.88%] train loss: 1.3757494343735743e-05 \n",
      "epoch: 39 [115544/888800 13.00%] train loss: 1.4294385437096935e-05 \n",
      "epoch: 39 [116655/888800 13.12%] train loss: 1.375236752210185e-05 \n",
      "epoch: 39 [117766/888800 13.25%] train loss: 1.4766879758099094e-05 \n",
      "epoch: 39 [118877/888800 13.38%] train loss: 1.4454592928814236e-05 \n",
      "epoch: 39 [119988/888800 13.50%] train loss: 1.3884377040085383e-05 \n",
      "epoch: 39 [121099/888800 13.62%] train loss: 1.457546568417456e-05 \n",
      "epoch: 39 [122210/888800 13.75%] train loss: 1.4963923604227602e-05 \n",
      "epoch: 39 [123321/888800 13.88%] train loss: 1.43921952258097e-05 \n",
      "epoch: 39 [124432/888800 14.00%] train loss: 1.5654934031772427e-05 \n",
      "epoch: 39 [125543/888800 14.12%] train loss: 1.4092206583882216e-05 \n",
      "epoch: 39 [126654/888800 14.25%] train loss: 1.4025836208020337e-05 \n",
      "epoch: 39 [127765/888800 14.38%] train loss: 1.348027308267774e-05 \n",
      "epoch: 39 [128876/888800 14.50%] train loss: 1.4878910405968782e-05 \n",
      "epoch: 39 [129987/888800 14.62%] train loss: 1.4438335711020045e-05 \n",
      "epoch: 39 [131098/888800 14.75%] train loss: 1.4260072930483148e-05 \n",
      "epoch: 39 [132209/888800 14.88%] train loss: 1.4776552234252449e-05 \n",
      "epoch: 39 [133320/888800 15.00%] train loss: 1.3560442312154919e-05 \n",
      "epoch: 39 [134431/888800 15.12%] train loss: 1.3655974726134446e-05 \n",
      "epoch: 39 [135542/888800 15.25%] train loss: 1.4341560017783195e-05 \n",
      "epoch: 39 [136653/888800 15.38%] train loss: 1.3973961358715314e-05 \n",
      "epoch: 39 [137764/888800 15.50%] train loss: 1.3459928595693782e-05 \n",
      "epoch: 39 [138875/888800 15.62%] train loss: 1.3781832421955187e-05 \n",
      "epoch: 39 [139986/888800 15.75%] train loss: 1.4009206097398419e-05 \n",
      "epoch: 39 [141097/888800 15.88%] train loss: 1.2665995200222824e-05 \n",
      "epoch: 39 [142208/888800 16.00%] train loss: 1.379519744659774e-05 \n",
      "epoch: 39 [143319/888800 16.12%] train loss: 1.3703696822631173e-05 \n",
      "epoch: 39 [144430/888800 16.25%] train loss: 1.5541863831458613e-05 \n",
      "epoch: 39 [145541/888800 16.38%] train loss: 1.548803447803948e-05 \n",
      "epoch: 39 [146652/888800 16.50%] train loss: 1.4087477211432997e-05 \n",
      "epoch: 39 [147763/888800 16.62%] train loss: 1.3662936908076517e-05 \n",
      "epoch: 39 [148874/888800 16.75%] train loss: 1.5166659977694508e-05 \n",
      "epoch: 39 [149985/888800 16.88%] train loss: 1.2673545825236943e-05 \n",
      "epoch: 39 [151096/888800 17.00%] train loss: 1.3668577594216913e-05 \n",
      "epoch: 39 [152207/888800 17.12%] train loss: 1.3764905816060491e-05 \n",
      "epoch: 39 [153318/888800 17.25%] train loss: 1.472164694860112e-05 \n",
      "epoch: 39 [154429/888800 17.38%] train loss: 1.3871157534595113e-05 \n",
      "epoch: 39 [155540/888800 17.50%] train loss: 1.3851705261913594e-05 \n",
      "epoch: 39 [156651/888800 17.62%] train loss: 1.430256543244468e-05 \n",
      "epoch: 39 [157762/888800 17.75%] train loss: 1.4189228750183247e-05 \n",
      "epoch: 39 [158873/888800 17.88%] train loss: 1.3034744370088447e-05 \n",
      "epoch: 39 [159984/888800 18.00%] train loss: 1.4158007616060786e-05 \n",
      "epoch: 39 [161095/888800 18.12%] train loss: 1.3894888070353772e-05 \n",
      "epoch: 39 [162206/888800 18.25%] train loss: 1.3161243259673938e-05 \n",
      "epoch: 39 [163317/888800 18.38%] train loss: 1.542733662063256e-05 \n",
      "epoch: 39 [164428/888800 18.50%] train loss: 1.4031981663720217e-05 \n",
      "epoch: 39 [165539/888800 18.62%] train loss: 1.534251350676641e-05 \n",
      "epoch: 39 [166650/888800 18.75%] train loss: 1.303609042224707e-05 \n",
      "epoch: 39 [167761/888800 18.88%] train loss: 1.3978414244775195e-05 \n",
      "epoch: 39 [168872/888800 19.00%] train loss: 1.3712767213291954e-05 \n",
      "epoch: 39 [169983/888800 19.12%] train loss: 1.4229378393793013e-05 \n",
      "epoch: 39 [171094/888800 19.25%] train loss: 1.684753988229204e-05 \n",
      "epoch: 39 [172205/888800 19.38%] train loss: 1.3748856872553006e-05 \n",
      "epoch: 39 [173316/888800 19.50%] train loss: 1.5861622159718536e-05 \n",
      "epoch: 39 [174427/888800 19.62%] train loss: 1.4833211025688797e-05 \n",
      "epoch: 39 [175538/888800 19.75%] train loss: 1.4447838111664169e-05 \n",
      "epoch: 39 [176649/888800 19.88%] train loss: 1.5946925486787222e-05 \n",
      "epoch: 39 [177760/888800 20.00%] train loss: 1.2794465874321759e-05 \n",
      "epoch: 39 [178871/888800 20.12%] train loss: 1.782838262442965e-05 \n",
      "epoch: 39 [179982/888800 20.25%] train loss: 1.4330645171867218e-05 \n",
      "epoch: 39 [181093/888800 20.38%] train loss: 1.6576772395637818e-05 \n",
      "epoch: 39 [182204/888800 20.50%] train loss: 1.4785358871449716e-05 \n",
      "epoch: 39 [183315/888800 20.62%] train loss: 1.766863715602085e-05 \n",
      "epoch: 39 [184426/888800 20.75%] train loss: 1.4371990801009815e-05 \n",
      "epoch: 39 [185537/888800 20.88%] train loss: 1.5045156942505855e-05 \n",
      "epoch: 39 [186648/888800 21.00%] train loss: 1.6069208868429996e-05 \n",
      "epoch: 39 [187759/888800 21.12%] train loss: 1.4232473404263146e-05 \n",
      "epoch: 39 [188870/888800 21.25%] train loss: 1.4296057997853495e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [189981/888800 21.38%] train loss: 1.4982127140683588e-05 \n",
      "epoch: 39 [191092/888800 21.50%] train loss: 1.4367120456881821e-05 \n",
      "epoch: 39 [192203/888800 21.62%] train loss: 1.4457004908763338e-05 \n",
      "epoch: 39 [193314/888800 21.75%] train loss: 1.4008609468874056e-05 \n",
      "epoch: 39 [194425/888800 21.88%] train loss: 1.4483644008578267e-05 \n",
      "epoch: 39 [195536/888800 22.00%] train loss: 1.392247577314265e-05 \n",
      "epoch: 39 [196647/888800 22.12%] train loss: 1.3865190339856781e-05 \n",
      "epoch: 39 [197758/888800 22.25%] train loss: 1.3519605090550613e-05 \n",
      "epoch: 39 [198869/888800 22.38%] train loss: 1.4721623301738873e-05 \n",
      "epoch: 39 [199980/888800 22.50%] train loss: 1.352224080619635e-05 \n",
      "epoch: 39 [201091/888800 22.62%] train loss: 1.3532186130760238e-05 \n",
      "epoch: 39 [202202/888800 22.75%] train loss: 1.3394766028795857e-05 \n",
      "epoch: 39 [203313/888800 22.88%] train loss: 1.329594033450121e-05 \n",
      "epoch: 39 [204424/888800 23.00%] train loss: 1.4603941053792369e-05 \n",
      "epoch: 39 [205535/888800 23.12%] train loss: 1.3780759218207095e-05 \n",
      "epoch: 39 [206646/888800 23.25%] train loss: 1.3646383195009548e-05 \n",
      "epoch: 39 [207757/888800 23.38%] train loss: 1.3629386558022816e-05 \n",
      "epoch: 39 [208868/888800 23.50%] train loss: 1.507558499724837e-05 \n",
      "epoch: 39 [209979/888800 23.62%] train loss: 1.5014032214821782e-05 \n",
      "epoch: 39 [211090/888800 23.75%] train loss: 1.4465441381616984e-05 \n",
      "epoch: 39 [212201/888800 23.88%] train loss: 1.5153814274526667e-05 \n",
      "epoch: 39 [213312/888800 24.00%] train loss: 1.304434408666566e-05 \n",
      "epoch: 39 [214423/888800 24.12%] train loss: 1.3388477782427799e-05 \n",
      "epoch: 39 [215534/888800 24.25%] train loss: 1.3551803021982778e-05 \n",
      "epoch: 39 [216645/888800 24.38%] train loss: 1.455920937587507e-05 \n",
      "epoch: 39 [217756/888800 24.50%] train loss: 1.3241992746770848e-05 \n",
      "epoch: 39 [218867/888800 24.62%] train loss: 1.3257438695291057e-05 \n",
      "epoch: 39 [219978/888800 24.75%] train loss: 1.3781389498035423e-05 \n",
      "epoch: 39 [221089/888800 24.88%] train loss: 1.4091918274061754e-05 \n",
      "epoch: 39 [222200/888800 25.00%] train loss: 1.3788517208013218e-05 \n",
      "epoch: 39 [223311/888800 25.12%] train loss: 1.3822759683534969e-05 \n",
      "epoch: 39 [224422/888800 25.25%] train loss: 1.669005723670125e-05 \n",
      "epoch: 39 [225533/888800 25.38%] train loss: 1.3722094081458636e-05 \n",
      "epoch: 39 [226644/888800 25.50%] train loss: 1.5109063497220632e-05 \n",
      "epoch: 39 [227755/888800 25.62%] train loss: 1.3977712114865426e-05 \n",
      "epoch: 39 [228866/888800 25.75%] train loss: 1.5000403436715715e-05 \n",
      "epoch: 39 [229977/888800 25.88%] train loss: 1.5226690265990328e-05 \n",
      "epoch: 39 [231088/888800 26.00%] train loss: 1.4602806004404556e-05 \n",
      "epoch: 39 [232199/888800 26.12%] train loss: 1.5666895706090145e-05 \n",
      "epoch: 39 [233310/888800 26.25%] train loss: 1.4791354260523804e-05 \n",
      "epoch: 39 [234421/888800 26.38%] train loss: 1.628860081837047e-05 \n",
      "epoch: 39 [235532/888800 26.50%] train loss: 1.530338886368554e-05 \n",
      "epoch: 39 [236643/888800 26.62%] train loss: 1.575702117406763e-05 \n",
      "epoch: 39 [237754/888800 26.75%] train loss: 1.4633738828706555e-05 \n",
      "epoch: 39 [238865/888800 26.88%] train loss: 1.4391849617823027e-05 \n",
      "epoch: 39 [239976/888800 27.00%] train loss: 1.4944128452043515e-05 \n",
      "epoch: 39 [241087/888800 27.12%] train loss: 1.4990488125476986e-05 \n",
      "epoch: 39 [242198/888800 27.25%] train loss: 1.4468942026724108e-05 \n",
      "epoch: 39 [243309/888800 27.38%] train loss: 1.5421903299284168e-05 \n",
      "epoch: 39 [244420/888800 27.50%] train loss: 1.3764261893811636e-05 \n",
      "epoch: 39 [245531/888800 27.62%] train loss: 1.548985528643243e-05 \n",
      "epoch: 39 [246642/888800 27.75%] train loss: 1.3593451512861066e-05 \n",
      "epoch: 39 [247753/888800 27.88%] train loss: 1.4939480934117455e-05 \n",
      "epoch: 39 [248864/888800 28.00%] train loss: 1.3468579709297046e-05 \n",
      "epoch: 39 [249975/888800 28.12%] train loss: 1.4590313185181003e-05 \n",
      "epoch: 39 [251086/888800 28.25%] train loss: 1.3956504517409485e-05 \n",
      "epoch: 39 [252197/888800 28.38%] train loss: 1.5234566490107682e-05 \n",
      "epoch: 39 [253308/888800 28.50%] train loss: 1.38302139021107e-05 \n",
      "epoch: 39 [254419/888800 28.62%] train loss: 1.4648599972133525e-05 \n",
      "epoch: 39 [255530/888800 28.75%] train loss: 1.5993788110790774e-05 \n",
      "epoch: 39 [256641/888800 28.88%] train loss: 1.2613338185474277e-05 \n",
      "epoch: 39 [257752/888800 29.00%] train loss: 1.6662686903146096e-05 \n",
      "epoch: 39 [258863/888800 29.12%] train loss: 1.4037213077244814e-05 \n",
      "epoch: 39 [259974/888800 29.25%] train loss: 1.6106758266687393e-05 \n",
      "epoch: 39 [261085/888800 29.38%] train loss: 1.4069214557821397e-05 \n",
      "epoch: 39 [262196/888800 29.50%] train loss: 1.4973179531807546e-05 \n",
      "epoch: 39 [263307/888800 29.62%] train loss: 1.4684213056170847e-05 \n",
      "epoch: 39 [264418/888800 29.75%] train loss: 1.5389587133540772e-05 \n",
      "epoch: 39 [265529/888800 29.88%] train loss: 1.708224408503156e-05 \n",
      "epoch: 39 [266640/888800 30.00%] train loss: 1.5067124877532478e-05 \n",
      "epoch: 39 [267751/888800 30.12%] train loss: 1.7036496501532383e-05 \n",
      "epoch: 39 [268862/888800 30.25%] train loss: 1.4547134924214333e-05 \n",
      "epoch: 39 [269973/888800 30.38%] train loss: 1.5255047401296906e-05 \n",
      "epoch: 39 [271084/888800 30.50%] train loss: 1.3847548871126492e-05 \n",
      "epoch: 39 [272195/888800 30.62%] train loss: 1.4322229617391713e-05 \n",
      "epoch: 39 [273306/888800 30.75%] train loss: 1.372059796267422e-05 \n",
      "epoch: 39 [274417/888800 30.88%] train loss: 1.4703761735290755e-05 \n",
      "epoch: 39 [275528/888800 31.00%] train loss: 1.5038205674500205e-05 \n",
      "epoch: 39 [276639/888800 31.12%] train loss: 1.5231654288072605e-05 \n",
      "epoch: 39 [277750/888800 31.25%] train loss: 1.3138957001501694e-05 \n",
      "epoch: 39 [278861/888800 31.38%] train loss: 1.4909051060385536e-05 \n",
      "epoch: 39 [279972/888800 31.50%] train loss: 1.3411581676336937e-05 \n",
      "epoch: 39 [281083/888800 31.62%] train loss: 1.5908997738733888e-05 \n",
      "epoch: 39 [282194/888800 31.75%] train loss: 1.3646857041749172e-05 \n",
      "epoch: 39 [283305/888800 31.88%] train loss: 1.571116445120424e-05 \n",
      "epoch: 39 [284416/888800 32.00%] train loss: 1.4525417100230698e-05 \n",
      "epoch: 39 [285527/888800 32.12%] train loss: 1.5087894098542165e-05 \n",
      "epoch: 39 [286638/888800 32.25%] train loss: 1.3208359632699285e-05 \n",
      "epoch: 39 [287749/888800 32.38%] train loss: 1.432543467672076e-05 \n",
      "epoch: 39 [288860/888800 32.50%] train loss: 1.5606881788698956e-05 \n",
      "epoch: 39 [289971/888800 32.62%] train loss: 1.4952941455703694e-05 \n",
      "epoch: 39 [291082/888800 32.75%] train loss: 1.3191411198931746e-05 \n",
      "epoch: 39 [292193/888800 32.88%] train loss: 1.5524181435466744e-05 \n",
      "epoch: 39 [293304/888800 33.00%] train loss: 1.490455360908527e-05 \n",
      "epoch: 39 [294415/888800 33.12%] train loss: 1.3355360351852141e-05 \n",
      "epoch: 39 [295526/888800 33.25%] train loss: 1.4752491551917046e-05 \n",
      "epoch: 39 [296637/888800 33.38%] train loss: 1.372169117530575e-05 \n",
      "epoch: 39 [297748/888800 33.50%] train loss: 1.3451983249979094e-05 \n",
      "epoch: 39 [298859/888800 33.62%] train loss: 1.5430598068633117e-05 \n",
      "epoch: 39 [299970/888800 33.75%] train loss: 1.3174937521398533e-05 \n",
      "epoch: 39 [301081/888800 33.88%] train loss: 1.626510675123427e-05 \n",
      "epoch: 39 [302192/888800 34.00%] train loss: 1.4494263268716168e-05 \n",
      "epoch: 39 [303303/888800 34.12%] train loss: 1.3538135135604534e-05 \n",
      "epoch: 39 [304414/888800 34.25%] train loss: 1.4450934941123705e-05 \n",
      "epoch: 39 [305525/888800 34.38%] train loss: 1.3443997886497527e-05 \n",
      "epoch: 39 [306636/888800 34.50%] train loss: 1.372964197798865e-05 \n",
      "epoch: 39 [307747/888800 34.62%] train loss: 1.3775703337159939e-05 \n",
      "epoch: 39 [308858/888800 34.75%] train loss: 1.4553187611454632e-05 \n",
      "epoch: 39 [309969/888800 34.88%] train loss: 1.491712191636907e-05 \n",
      "epoch: 39 [311080/888800 35.00%] train loss: 1.3447049241221976e-05 \n",
      "epoch: 39 [312191/888800 35.12%] train loss: 1.366562082694145e-05 \n",
      "epoch: 39 [313302/888800 35.25%] train loss: 1.3741432667302433e-05 \n",
      "epoch: 39 [314413/888800 35.38%] train loss: 1.4148356058285572e-05 \n",
      "epoch: 39 [315524/888800 35.50%] train loss: 1.514212999609299e-05 \n",
      "epoch: 39 [316635/888800 35.62%] train loss: 1.4848011232970748e-05 \n",
      "epoch: 39 [317746/888800 35.75%] train loss: 1.4352901416714303e-05 \n",
      "epoch: 39 [318857/888800 35.88%] train loss: 1.5591349438182078e-05 \n",
      "epoch: 39 [319968/888800 36.00%] train loss: 1.3789324839308392e-05 \n",
      "epoch: 39 [321079/888800 36.12%] train loss: 1.4400140571524389e-05 \n",
      "epoch: 39 [322190/888800 36.25%] train loss: 1.3769717952527571e-05 \n",
      "epoch: 39 [323301/888800 36.38%] train loss: 1.4291914339992218e-05 \n",
      "epoch: 39 [324412/888800 36.50%] train loss: 1.4738808204128873e-05 \n",
      "epoch: 39 [325523/888800 36.62%] train loss: 1.4183769962983206e-05 \n",
      "epoch: 39 [326634/888800 36.75%] train loss: 1.4768318578717299e-05 \n",
      "epoch: 39 [327745/888800 36.88%] train loss: 1.3938011761638336e-05 \n",
      "epoch: 39 [328856/888800 37.00%] train loss: 1.4019104128237814e-05 \n",
      "epoch: 39 [329967/888800 37.12%] train loss: 1.4280736650107428e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [331078/888800 37.25%] train loss: 1.4843297321931459e-05 \n",
      "epoch: 39 [332189/888800 37.38%] train loss: 1.4071595614950638e-05 \n",
      "epoch: 39 [333300/888800 37.50%] train loss: 1.6322153896908276e-05 \n",
      "epoch: 39 [334411/888800 37.62%] train loss: 1.3263567780086305e-05 \n",
      "epoch: 39 [335522/888800 37.75%] train loss: 1.3941466932010371e-05 \n",
      "epoch: 39 [336633/888800 37.88%] train loss: 1.4959548934712075e-05 \n",
      "epoch: 39 [337744/888800 38.00%] train loss: 1.4427577298192773e-05 \n",
      "epoch: 39 [338855/888800 38.12%] train loss: 1.4905334865034092e-05 \n",
      "epoch: 39 [339966/888800 38.25%] train loss: 1.5033161616884172e-05 \n",
      "epoch: 39 [341077/888800 38.38%] train loss: 1.3873786883777939e-05 \n",
      "epoch: 39 [342188/888800 38.50%] train loss: 1.5716921552666463e-05 \n",
      "epoch: 39 [343299/888800 38.62%] train loss: 1.4260398529586382e-05 \n",
      "epoch: 39 [344410/888800 38.75%] train loss: 1.464729484723648e-05 \n",
      "epoch: 39 [345521/888800 38.88%] train loss: 1.4205390471033752e-05 \n",
      "epoch: 39 [346632/888800 39.00%] train loss: 1.5569688912364654e-05 \n",
      "epoch: 39 [347743/888800 39.12%] train loss: 1.5067471395013854e-05 \n",
      "epoch: 39 [348854/888800 39.25%] train loss: 1.3764719369646627e-05 \n",
      "epoch: 39 [349965/888800 39.38%] train loss: 1.6083464288385585e-05 \n",
      "epoch: 39 [351076/888800 39.50%] train loss: 1.457092548662331e-05 \n",
      "epoch: 39 [352187/888800 39.62%] train loss: 1.513528150098864e-05 \n",
      "epoch: 39 [353298/888800 39.75%] train loss: 1.39283492899267e-05 \n",
      "epoch: 39 [354409/888800 39.88%] train loss: 1.7292935808654875e-05 \n",
      "epoch: 39 [355520/888800 40.00%] train loss: 1.4670156815554947e-05 \n",
      "epoch: 39 [356631/888800 40.12%] train loss: 1.7349391782772727e-05 \n",
      "epoch: 39 [357742/888800 40.25%] train loss: 1.5317236830014735e-05 \n",
      "epoch: 39 [358853/888800 40.38%] train loss: 1.714641257422045e-05 \n",
      "epoch: 39 [359964/888800 40.50%] train loss: 1.57408976519946e-05 \n",
      "epoch: 39 [361075/888800 40.62%] train loss: 1.5646468455088325e-05 \n",
      "epoch: 39 [362186/888800 40.75%] train loss: 1.4732316230947617e-05 \n",
      "epoch: 39 [363297/888800 40.88%] train loss: 1.4797206858929712e-05 \n",
      "epoch: 39 [364408/888800 41.00%] train loss: 1.5791911209817044e-05 \n",
      "epoch: 39 [365519/888800 41.12%] train loss: 1.4609037862101104e-05 \n",
      "epoch: 39 [366630/888800 41.25%] train loss: 1.457303915231023e-05 \n",
      "epoch: 39 [367741/888800 41.38%] train loss: 1.3516554645320866e-05 \n",
      "epoch: 39 [368852/888800 41.50%] train loss: 1.5725672710686922e-05 \n",
      "epoch: 39 [369963/888800 41.62%] train loss: 1.321437957813032e-05 \n",
      "epoch: 39 [371074/888800 41.75%] train loss: 1.6128264178405516e-05 \n",
      "epoch: 39 [372185/888800 41.88%] train loss: 1.3544056855607778e-05 \n",
      "epoch: 39 [373296/888800 42.00%] train loss: 1.561821045470424e-05 \n",
      "epoch: 39 [374407/888800 42.12%] train loss: 1.391681689710822e-05 \n",
      "epoch: 39 [375518/888800 42.25%] train loss: 1.664784394961316e-05 \n",
      "epoch: 39 [376629/888800 42.38%] train loss: 1.55447814904619e-05 \n",
      "epoch: 39 [377740/888800 42.50%] train loss: 1.4835367437626701e-05 \n",
      "epoch: 39 [378851/888800 42.62%] train loss: 1.4623067727370653e-05 \n",
      "epoch: 39 [379962/888800 42.75%] train loss: 1.4651359379058704e-05 \n",
      "epoch: 39 [381073/888800 42.88%] train loss: 1.573558802192565e-05 \n",
      "epoch: 39 [382184/888800 43.00%] train loss: 1.3501763532985933e-05 \n",
      "epoch: 39 [383295/888800 43.12%] train loss: 1.5066249943629373e-05 \n",
      "epoch: 39 [384406/888800 43.25%] train loss: 1.386754411214497e-05 \n",
      "epoch: 39 [385517/888800 43.38%] train loss: 1.5385428923764266e-05 \n",
      "epoch: 39 [386628/888800 43.50%] train loss: 1.4489860404864885e-05 \n",
      "epoch: 39 [387739/888800 43.62%] train loss: 1.3964755453343969e-05 \n",
      "epoch: 39 [388850/888800 43.75%] train loss: 1.2568661986733787e-05 \n",
      "epoch: 39 [389961/888800 43.88%] train loss: 1.446839451091364e-05 \n",
      "epoch: 39 [391072/888800 44.00%] train loss: 1.3625868632516358e-05 \n",
      "epoch: 39 [392183/888800 44.12%] train loss: 1.3284255146572832e-05 \n",
      "epoch: 39 [393294/888800 44.25%] train loss: 1.3418831258604769e-05 \n",
      "epoch: 39 [394405/888800 44.38%] train loss: 1.3910197594668716e-05 \n",
      "epoch: 39 [395516/888800 44.50%] train loss: 1.5472422091988847e-05 \n",
      "epoch: 39 [396627/888800 44.62%] train loss: 1.3938612028141506e-05 \n",
      "epoch: 39 [397738/888800 44.75%] train loss: 1.3944194506620988e-05 \n",
      "epoch: 39 [398849/888800 44.88%] train loss: 1.4403920431504957e-05 \n",
      "epoch: 39 [399960/888800 45.00%] train loss: 1.369212714052992e-05 \n",
      "epoch: 39 [401071/888800 45.12%] train loss: 1.4384028872882482e-05 \n",
      "epoch: 39 [402182/888800 45.25%] train loss: 1.4345919225888792e-05 \n",
      "epoch: 39 [403293/888800 45.38%] train loss: 1.530010558781214e-05 \n",
      "epoch: 39 [404404/888800 45.50%] train loss: 1.2927990610478446e-05 \n",
      "epoch: 39 [405515/888800 45.62%] train loss: 1.4182414815877564e-05 \n",
      "epoch: 39 [406626/888800 45.75%] train loss: 1.3104388017382007e-05 \n",
      "epoch: 39 [407737/888800 45.88%] train loss: 1.430677184544038e-05 \n",
      "epoch: 39 [408848/888800 46.00%] train loss: 1.2807323400920723e-05 \n",
      "epoch: 39 [409959/888800 46.12%] train loss: 1.2574209904414602e-05 \n",
      "epoch: 39 [411070/888800 46.25%] train loss: 1.3288243280840106e-05 \n",
      "epoch: 39 [412181/888800 46.38%] train loss: 1.3901718375564087e-05 \n",
      "epoch: 39 [413292/888800 46.50%] train loss: 1.3176211723475717e-05 \n",
      "epoch: 39 [414403/888800 46.62%] train loss: 1.4818733689025976e-05 \n",
      "epoch: 39 [415514/888800 46.75%] train loss: 1.482147490605712e-05 \n",
      "epoch: 39 [416625/888800 46.88%] train loss: 1.3783196664007846e-05 \n",
      "epoch: 39 [417736/888800 47.00%] train loss: 1.4980111700424459e-05 \n",
      "epoch: 39 [418847/888800 47.12%] train loss: 1.4508396816381719e-05 \n",
      "epoch: 39 [419958/888800 47.25%] train loss: 1.4365778952196706e-05 \n",
      "epoch: 39 [421069/888800 47.38%] train loss: 1.430167776561575e-05 \n",
      "epoch: 39 [422180/888800 47.50%] train loss: 1.3434952961688396e-05 \n",
      "epoch: 39 [423291/888800 47.62%] train loss: 1.457072085031541e-05 \n",
      "epoch: 39 [424402/888800 47.75%] train loss: 1.2725525266432669e-05 \n",
      "epoch: 39 [425513/888800 47.88%] train loss: 1.3842000043950975e-05 \n",
      "epoch: 39 [426624/888800 48.00%] train loss: 1.4542964891006704e-05 \n",
      "epoch: 39 [427735/888800 48.12%] train loss: 1.2990257346245926e-05 \n",
      "epoch: 39 [428846/888800 48.25%] train loss: 1.447681734134676e-05 \n",
      "epoch: 39 [429957/888800 48.38%] train loss: 1.522678394394461e-05 \n",
      "epoch: 39 [431068/888800 48.50%] train loss: 1.5988418454071507e-05 \n",
      "epoch: 39 [432179/888800 48.62%] train loss: 1.3857052181265317e-05 \n",
      "epoch: 39 [433290/888800 48.75%] train loss: 1.4100362022873014e-05 \n",
      "epoch: 39 [434401/888800 48.88%] train loss: 1.3695012057723943e-05 \n",
      "epoch: 39 [435512/888800 49.00%] train loss: 1.5725685443612747e-05 \n",
      "epoch: 39 [436623/888800 49.12%] train loss: 1.41193868330447e-05 \n",
      "epoch: 39 [437734/888800 49.25%] train loss: 1.4277532500273082e-05 \n",
      "epoch: 39 [438845/888800 49.38%] train loss: 1.42582020998816e-05 \n",
      "epoch: 39 [439956/888800 49.50%] train loss: 1.3592323739430867e-05 \n",
      "epoch: 39 [441067/888800 49.62%] train loss: 1.3865110304323025e-05 \n",
      "epoch: 39 [442178/888800 49.75%] train loss: 1.4220833691069856e-05 \n",
      "epoch: 39 [443289/888800 49.88%] train loss: 1.3793297512165736e-05 \n",
      "epoch: 39 [444400/888800 50.00%] train loss: 1.4549458683177363e-05 \n",
      "epoch: 39 [445511/888800 50.12%] train loss: 1.409879041602835e-05 \n",
      "epoch: 39 [446622/888800 50.25%] train loss: 1.4265853678807616e-05 \n",
      "epoch: 39 [447733/888800 50.38%] train loss: 1.3362974641495384e-05 \n",
      "epoch: 39 [448844/888800 50.50%] train loss: 1.4085598195379134e-05 \n",
      "epoch: 39 [449955/888800 50.62%] train loss: 1.4092488527239766e-05 \n",
      "epoch: 39 [451066/888800 50.75%] train loss: 1.499438894825289e-05 \n",
      "epoch: 39 [452177/888800 50.88%] train loss: 1.4733222087670583e-05 \n",
      "epoch: 39 [453288/888800 51.00%] train loss: 1.405974126100773e-05 \n",
      "epoch: 39 [454399/888800 51.12%] train loss: 1.3870235306967515e-05 \n",
      "epoch: 39 [455510/888800 51.25%] train loss: 1.5530220480286516e-05 \n",
      "epoch: 39 [456621/888800 51.38%] train loss: 1.4561288480763324e-05 \n",
      "epoch: 39 [457732/888800 51.50%] train loss: 1.3714506167161744e-05 \n",
      "epoch: 39 [458843/888800 51.62%] train loss: 1.312507356487913e-05 \n",
      "epoch: 39 [459954/888800 51.75%] train loss: 1.2855433851655107e-05 \n",
      "epoch: 39 [461065/888800 51.88%] train loss: 1.3148504876880907e-05 \n",
      "epoch: 39 [462176/888800 52.00%] train loss: 1.3689026673091576e-05 \n",
      "epoch: 39 [463287/888800 52.12%] train loss: 1.551588502479717e-05 \n",
      "epoch: 39 [464398/888800 52.25%] train loss: 1.4138768165139481e-05 \n",
      "epoch: 39 [465509/888800 52.38%] train loss: 1.4313849533209577e-05 \n",
      "epoch: 39 [466620/888800 52.50%] train loss: 1.4480518984782975e-05 \n",
      "epoch: 39 [467731/888800 52.62%] train loss: 1.5091530258359853e-05 \n",
      "epoch: 39 [468842/888800 52.75%] train loss: 1.301129759667674e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [469953/888800 52.88%] train loss: 1.4808126252319198e-05 \n",
      "epoch: 39 [471064/888800 53.00%] train loss: 1.3264181689010002e-05 \n",
      "epoch: 39 [472175/888800 53.12%] train loss: 1.3441723240248393e-05 \n",
      "epoch: 39 [473286/888800 53.25%] train loss: 1.4512564121105243e-05 \n",
      "epoch: 39 [474397/888800 53.38%] train loss: 1.369127039652085e-05 \n",
      "epoch: 39 [475508/888800 53.50%] train loss: 1.3141671843186487e-05 \n",
      "epoch: 39 [476619/888800 53.62%] train loss: 1.4051520338398404e-05 \n",
      "epoch: 39 [477730/888800 53.75%] train loss: 1.492937281000195e-05 \n",
      "epoch: 39 [478841/888800 53.88%] train loss: 1.4322215974971186e-05 \n",
      "epoch: 39 [479952/888800 54.00%] train loss: 1.6034222426242195e-05 \n",
      "epoch: 39 [481063/888800 54.12%] train loss: 1.4553336768585723e-05 \n",
      "epoch: 39 [482174/888800 54.25%] train loss: 1.4117968930804636e-05 \n",
      "epoch: 39 [483285/888800 54.38%] train loss: 1.3958529962110333e-05 \n",
      "epoch: 39 [484396/888800 54.50%] train loss: 1.5206219359242823e-05 \n",
      "epoch: 39 [485507/888800 54.62%] train loss: 1.4903196642990224e-05 \n",
      "epoch: 39 [486618/888800 54.75%] train loss: 1.4667984032712411e-05 \n",
      "epoch: 39 [487729/888800 54.88%] train loss: 1.3792223398922943e-05 \n",
      "epoch: 39 [488840/888800 55.00%] train loss: 1.3847541595168877e-05 \n",
      "epoch: 39 [489951/888800 55.12%] train loss: 1.4297657799033914e-05 \n",
      "epoch: 39 [491062/888800 55.25%] train loss: 1.2993710697628558e-05 \n",
      "epoch: 39 [492173/888800 55.38%] train loss: 1.393162165186368e-05 \n",
      "epoch: 39 [493284/888800 55.50%] train loss: 1.3614667295769323e-05 \n",
      "epoch: 39 [494395/888800 55.62%] train loss: 1.405540115229087e-05 \n",
      "epoch: 39 [495506/888800 55.75%] train loss: 1.434398382116342e-05 \n",
      "epoch: 39 [496617/888800 55.88%] train loss: 1.467488800699357e-05 \n",
      "epoch: 39 [497728/888800 56.00%] train loss: 1.4002628631715197e-05 \n",
      "epoch: 39 [498839/888800 56.12%] train loss: 1.4361516150529496e-05 \n",
      "epoch: 39 [499950/888800 56.25%] train loss: 1.54057615873171e-05 \n",
      "epoch: 39 [501061/888800 56.38%] train loss: 1.3878027857572306e-05 \n",
      "epoch: 39 [502172/888800 56.50%] train loss: 1.2764161510858685e-05 \n",
      "epoch: 39 [503283/888800 56.62%] train loss: 1.3996319466968998e-05 \n",
      "epoch: 39 [504394/888800 56.75%] train loss: 1.4979664229031187e-05 \n",
      "epoch: 39 [505505/888800 56.88%] train loss: 1.4223223843146116e-05 \n",
      "epoch: 39 [506616/888800 57.00%] train loss: 1.4456620192504488e-05 \n",
      "epoch: 39 [507727/888800 57.12%] train loss: 1.5215293387882411e-05 \n",
      "epoch: 39 [508838/888800 57.25%] train loss: 1.457484995626146e-05 \n",
      "epoch: 39 [509949/888800 57.38%] train loss: 1.5182203242147807e-05 \n",
      "epoch: 39 [511060/888800 57.50%] train loss: 1.3278411643113941e-05 \n",
      "epoch: 39 [512171/888800 57.62%] train loss: 1.4020242815604433e-05 \n",
      "epoch: 39 [513282/888800 57.75%] train loss: 1.3928540283814073e-05 \n",
      "epoch: 39 [514393/888800 57.88%] train loss: 1.3758006389252841e-05 \n",
      "epoch: 39 [515504/888800 58.00%] train loss: 1.2996376426599454e-05 \n",
      "epoch: 39 [516615/888800 58.12%] train loss: 1.4688725968881045e-05 \n",
      "epoch: 39 [517726/888800 58.25%] train loss: 1.3326295629667584e-05 \n",
      "epoch: 39 [518837/888800 58.38%] train loss: 1.3831864634994417e-05 \n",
      "epoch: 39 [519948/888800 58.50%] train loss: 1.426015660399571e-05 \n",
      "epoch: 39 [521059/888800 58.62%] train loss: 1.4211151210474782e-05 \n",
      "epoch: 39 [522170/888800 58.75%] train loss: 1.565435013617389e-05 \n",
      "epoch: 39 [523281/888800 58.88%] train loss: 1.4352950529428199e-05 \n",
      "epoch: 39 [524392/888800 59.00%] train loss: 1.395991876051994e-05 \n",
      "epoch: 39 [525503/888800 59.12%] train loss: 1.4224875485524535e-05 \n",
      "epoch: 39 [526614/888800 59.25%] train loss: 1.4708220987813547e-05 \n",
      "epoch: 39 [527725/888800 59.38%] train loss: 1.4986963833507616e-05 \n",
      "epoch: 39 [528836/888800 59.50%] train loss: 1.3863289495930076e-05 \n",
      "epoch: 39 [529947/888800 59.62%] train loss: 1.3574923286796547e-05 \n",
      "epoch: 39 [531058/888800 59.75%] train loss: 1.4620221008954104e-05 \n",
      "epoch: 39 [532169/888800 59.88%] train loss: 1.453616005164804e-05 \n",
      "epoch: 39 [533280/888800 60.00%] train loss: 1.3670847692992538e-05 \n",
      "epoch: 39 [534391/888800 60.12%] train loss: 1.3328680324775632e-05 \n",
      "epoch: 39 [535502/888800 60.25%] train loss: 1.3954238966107368e-05 \n",
      "epoch: 39 [536613/888800 60.38%] train loss: 1.5324034393415786e-05 \n",
      "epoch: 39 [537724/888800 60.50%] train loss: 1.4599692804040387e-05 \n",
      "epoch: 39 [538835/888800 60.62%] train loss: 1.4877085050102323e-05 \n",
      "epoch: 39 [539946/888800 60.75%] train loss: 1.4180049220158253e-05 \n",
      "epoch: 39 [541057/888800 60.88%] train loss: 1.4762676983082201e-05 \n",
      "epoch: 39 [542168/888800 61.00%] train loss: 1.4267314327298664e-05 \n",
      "epoch: 39 [543279/888800 61.12%] train loss: 1.3973926797916647e-05 \n",
      "epoch: 39 [544390/888800 61.25%] train loss: 1.3798637155559845e-05 \n",
      "epoch: 39 [545501/888800 61.38%] train loss: 1.4142620784696192e-05 \n",
      "epoch: 39 [546612/888800 61.50%] train loss: 1.518657518317923e-05 \n",
      "epoch: 39 [547723/888800 61.62%] train loss: 1.5105661987036001e-05 \n",
      "epoch: 39 [548834/888800 61.75%] train loss: 1.4909116544004064e-05 \n",
      "epoch: 39 [549945/888800 61.88%] train loss: 1.5067721506056841e-05 \n",
      "epoch: 39 [551056/888800 62.00%] train loss: 1.4062448826734908e-05 \n",
      "epoch: 39 [552167/888800 62.12%] train loss: 1.5043735402286984e-05 \n",
      "epoch: 39 [553278/888800 62.25%] train loss: 1.34193605845212e-05 \n",
      "epoch: 39 [554389/888800 62.38%] train loss: 1.5586121662636288e-05 \n",
      "epoch: 39 [555500/888800 62.50%] train loss: 1.6722608052077703e-05 \n",
      "epoch: 39 [556611/888800 62.62%] train loss: 1.3475168998411391e-05 \n",
      "epoch: 39 [557722/888800 62.75%] train loss: 1.4330157682707068e-05 \n",
      "epoch: 39 [558833/888800 62.88%] train loss: 1.4073855709284544e-05 \n",
      "epoch: 39 [559944/888800 63.00%] train loss: 1.4968211871746462e-05 \n",
      "epoch: 39 [561055/888800 63.12%] train loss: 1.3547582966566551e-05 \n",
      "epoch: 39 [562166/888800 63.25%] train loss: 1.4552218090102542e-05 \n",
      "epoch: 39 [563277/888800 63.38%] train loss: 1.2858938134741038e-05 \n",
      "epoch: 39 [564388/888800 63.50%] train loss: 1.4513712812913582e-05 \n",
      "epoch: 39 [565499/888800 63.62%] train loss: 1.5126208381843753e-05 \n",
      "epoch: 39 [566610/888800 63.75%] train loss: 1.3723329175263643e-05 \n",
      "epoch: 39 [567721/888800 63.88%] train loss: 1.4482785445579793e-05 \n",
      "epoch: 39 [568832/888800 64.00%] train loss: 1.4987614122219384e-05 \n",
      "epoch: 39 [569943/888800 64.12%] train loss: 1.4552416359947529e-05 \n",
      "epoch: 39 [571054/888800 64.25%] train loss: 1.349113790638512e-05 \n",
      "epoch: 39 [572165/888800 64.38%] train loss: 1.4714637472934555e-05 \n",
      "epoch: 39 [573276/888800 64.50%] train loss: 1.631896520848386e-05 \n",
      "epoch: 39 [574387/888800 64.62%] train loss: 1.434400928701507e-05 \n",
      "epoch: 39 [575498/888800 64.75%] train loss: 1.4965691661927849e-05 \n",
      "epoch: 39 [576609/888800 64.88%] train loss: 1.4334479601529893e-05 \n",
      "epoch: 39 [577720/888800 65.00%] train loss: 1.4927623851690441e-05 \n",
      "epoch: 39 [578831/888800 65.12%] train loss: 1.471150062570814e-05 \n",
      "epoch: 39 [579942/888800 65.25%] train loss: 1.4519961041514762e-05 \n",
      "epoch: 39 [581053/888800 65.38%] train loss: 1.269305357709527e-05 \n",
      "epoch: 39 [582164/888800 65.50%] train loss: 1.5114130292204209e-05 \n",
      "epoch: 39 [583275/888800 65.62%] train loss: 1.4285140423453413e-05 \n",
      "epoch: 39 [584386/888800 65.75%] train loss: 1.556122697365936e-05 \n",
      "epoch: 39 [585497/888800 65.88%] train loss: 1.3223491805547383e-05 \n",
      "epoch: 39 [586608/888800 66.00%] train loss: 1.3724858035857324e-05 \n",
      "epoch: 39 [587719/888800 66.12%] train loss: 1.4102362001722213e-05 \n",
      "epoch: 39 [588830/888800 66.25%] train loss: 1.3620312529383227e-05 \n",
      "epoch: 39 [589941/888800 66.38%] train loss: 1.438642902940046e-05 \n",
      "epoch: 39 [591052/888800 66.50%] train loss: 1.4334867046272848e-05 \n",
      "epoch: 39 [592163/888800 66.62%] train loss: 1.48917442857055e-05 \n",
      "epoch: 39 [593274/888800 66.75%] train loss: 1.3894841686123982e-05 \n",
      "epoch: 39 [594385/888800 66.88%] train loss: 1.408263051416725e-05 \n",
      "epoch: 39 [595496/888800 67.00%] train loss: 1.570274616824463e-05 \n",
      "epoch: 39 [596607/888800 67.12%] train loss: 1.391841215081513e-05 \n",
      "epoch: 39 [597718/888800 67.25%] train loss: 1.8149859897675924e-05 \n",
      "epoch: 39 [598829/888800 67.38%] train loss: 1.4674116755486466e-05 \n",
      "epoch: 39 [599940/888800 67.50%] train loss: 1.5826697563170455e-05 \n",
      "epoch: 39 [601051/888800 67.62%] train loss: 1.3404742276179604e-05 \n",
      "epoch: 39 [602162/888800 67.75%] train loss: 1.5235323189699557e-05 \n",
      "epoch: 39 [603273/888800 67.88%] train loss: 1.44568311952753e-05 \n",
      "epoch: 39 [604384/888800 68.00%] train loss: 1.6227415471803397e-05 \n",
      "epoch: 39 [605495/888800 68.12%] train loss: 1.366757078358205e-05 \n",
      "epoch: 39 [606606/888800 68.25%] train loss: 1.7724800272844732e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [607717/888800 68.38%] train loss: 1.6035601220210083e-05 \n",
      "epoch: 39 [608828/888800 68.50%] train loss: 1.869388870545663e-05 \n",
      "epoch: 39 [609939/888800 68.62%] train loss: 1.562323814141564e-05 \n",
      "epoch: 39 [611050/888800 68.75%] train loss: 1.6367856005672365e-05 \n",
      "epoch: 39 [612161/888800 68.88%] train loss: 1.559341762913391e-05 \n",
      "epoch: 39 [613272/888800 69.00%] train loss: 1.5698489733040333e-05 \n",
      "epoch: 39 [614383/888800 69.12%] train loss: 1.3997159840073436e-05 \n",
      "epoch: 39 [615494/888800 69.25%] train loss: 1.5636245734640397e-05 \n",
      "epoch: 39 [616605/888800 69.38%] train loss: 1.5450439605046995e-05 \n",
      "epoch: 39 [617716/888800 69.50%] train loss: 1.5303092368412763e-05 \n",
      "epoch: 39 [618827/888800 69.62%] train loss: 1.2739636076730676e-05 \n",
      "epoch: 39 [619938/888800 69.75%] train loss: 1.5091536624822766e-05 \n",
      "epoch: 39 [621049/888800 69.88%] train loss: 1.3952688277640846e-05 \n",
      "epoch: 39 [622160/888800 70.00%] train loss: 1.4394669960893225e-05 \n",
      "epoch: 39 [623271/888800 70.12%] train loss: 1.392743070027791e-05 \n",
      "epoch: 39 [624382/888800 70.25%] train loss: 1.54217668750789e-05 \n",
      "epoch: 39 [625493/888800 70.38%] train loss: 1.4488502529275138e-05 \n",
      "epoch: 39 [626604/888800 70.50%] train loss: 1.382577192998724e-05 \n",
      "epoch: 39 [627715/888800 70.62%] train loss: 1.5514189726673067e-05 \n",
      "epoch: 39 [628826/888800 70.75%] train loss: 1.5284696928574704e-05 \n",
      "epoch: 39 [629937/888800 70.88%] train loss: 1.4536448361468501e-05 \n",
      "epoch: 39 [631048/888800 71.00%] train loss: 1.4464679225056898e-05 \n",
      "epoch: 39 [632159/888800 71.12%] train loss: 1.4533048670273274e-05 \n",
      "epoch: 39 [633270/888800 71.25%] train loss: 1.445054203941254e-05 \n",
      "epoch: 39 [634381/888800 71.38%] train loss: 1.3789284821541514e-05 \n",
      "epoch: 39 [635492/888800 71.50%] train loss: 1.4205387742549647e-05 \n",
      "epoch: 39 [636603/888800 71.62%] train loss: 1.4349146113090683e-05 \n",
      "epoch: 39 [637714/888800 71.75%] train loss: 1.5613411960657686e-05 \n",
      "epoch: 39 [638825/888800 71.88%] train loss: 1.600297400727868e-05 \n",
      "epoch: 39 [639936/888800 72.00%] train loss: 1.3095941540086642e-05 \n",
      "epoch: 39 [641047/888800 72.12%] train loss: 1.4843269127595704e-05 \n",
      "epoch: 39 [642158/888800 72.25%] train loss: 1.5413321307278238e-05 \n",
      "epoch: 39 [643269/888800 72.38%] train loss: 1.4649836884927936e-05 \n",
      "epoch: 39 [644380/888800 72.50%] train loss: 1.5178951798588969e-05 \n",
      "epoch: 39 [645491/888800 72.62%] train loss: 1.4957175153540447e-05 \n",
      "epoch: 39 [646602/888800 72.75%] train loss: 1.4015980923431925e-05 \n",
      "epoch: 39 [647713/888800 72.88%] train loss: 1.4778806871618144e-05 \n",
      "epoch: 39 [648824/888800 73.00%] train loss: 1.5621824786649086e-05 \n",
      "epoch: 39 [649935/888800 73.12%] train loss: 1.4927396478014998e-05 \n",
      "epoch: 39 [651046/888800 73.25%] train loss: 1.4430544069909956e-05 \n",
      "epoch: 39 [652157/888800 73.38%] train loss: 1.4520717741106637e-05 \n",
      "epoch: 39 [653268/888800 73.50%] train loss: 1.5035358956083655e-05 \n",
      "epoch: 39 [654379/888800 73.62%] train loss: 1.4054855455469806e-05 \n",
      "epoch: 39 [655490/888800 73.75%] train loss: 1.4615609870816115e-05 \n",
      "epoch: 39 [656601/888800 73.88%] train loss: 1.4002407624502666e-05 \n",
      "epoch: 39 [657712/888800 74.00%] train loss: 1.4206185369403102e-05 \n",
      "epoch: 39 [658823/888800 74.12%] train loss: 1.4196045412973035e-05 \n",
      "epoch: 39 [659934/888800 74.25%] train loss: 1.4715567886014469e-05 \n",
      "epoch: 39 [661045/888800 74.38%] train loss: 1.5223451555357315e-05 \n",
      "epoch: 39 [662156/888800 74.50%] train loss: 1.345287364529213e-05 \n",
      "epoch: 39 [663267/888800 74.62%] train loss: 1.4464558262261562e-05 \n",
      "epoch: 39 [664378/888800 74.75%] train loss: 1.4644874681835063e-05 \n",
      "epoch: 39 [665489/888800 74.88%] train loss: 1.3974100511404686e-05 \n",
      "epoch: 39 [666600/888800 75.00%] train loss: 1.4976532838772982e-05 \n",
      "epoch: 39 [667711/888800 75.12%] train loss: 1.4519864635076374e-05 \n",
      "epoch: 39 [668822/888800 75.25%] train loss: 1.3924725863034837e-05 \n",
      "epoch: 39 [669933/888800 75.38%] train loss: 1.4352201105793938e-05 \n",
      "epoch: 39 [671044/888800 75.50%] train loss: 1.4497674783342518e-05 \n",
      "epoch: 39 [672155/888800 75.62%] train loss: 1.3253280485514551e-05 \n",
      "epoch: 39 [673266/888800 75.75%] train loss: 1.4326938980957493e-05 \n",
      "epoch: 39 [674377/888800 75.88%] train loss: 1.4705342437082436e-05 \n",
      "epoch: 39 [675488/888800 76.00%] train loss: 1.410815730196191e-05 \n",
      "epoch: 39 [676599/888800 76.12%] train loss: 1.3880033293389715e-05 \n",
      "epoch: 39 [677710/888800 76.25%] train loss: 1.4256414942792617e-05 \n",
      "epoch: 39 [678821/888800 76.38%] train loss: 1.4817204828432295e-05 \n",
      "epoch: 39 [679932/888800 76.50%] train loss: 1.5690522559452802e-05 \n",
      "epoch: 39 [681043/888800 76.62%] train loss: 1.4856714187772013e-05 \n",
      "epoch: 39 [682154/888800 76.75%] train loss: 1.3146242963557597e-05 \n",
      "epoch: 39 [683265/888800 76.88%] train loss: 1.534810508019291e-05 \n",
      "epoch: 39 [684376/888800 77.00%] train loss: 1.3463342838804238e-05 \n",
      "epoch: 39 [685487/888800 77.12%] train loss: 1.4885145901644137e-05 \n",
      "epoch: 39 [686598/888800 77.25%] train loss: 1.3084144484309945e-05 \n",
      "epoch: 39 [687709/888800 77.38%] train loss: 1.5373572750831954e-05 \n",
      "epoch: 39 [688820/888800 77.50%] train loss: 1.408104071742855e-05 \n",
      "epoch: 39 [689931/888800 77.62%] train loss: 1.3555380974139553e-05 \n",
      "epoch: 39 [691042/888800 77.75%] train loss: 1.540863922855351e-05 \n",
      "epoch: 39 [692153/888800 77.88%] train loss: 1.3379665688262321e-05 \n",
      "epoch: 39 [693264/888800 78.00%] train loss: 1.4663121874036733e-05 \n",
      "epoch: 39 [694375/888800 78.12%] train loss: 1.3700193449039944e-05 \n",
      "epoch: 39 [695486/888800 78.25%] train loss: 1.4929441931599285e-05 \n",
      "epoch: 39 [696597/888800 78.38%] train loss: 1.4719263162987772e-05 \n",
      "epoch: 39 [697708/888800 78.50%] train loss: 1.4450074559135828e-05 \n",
      "epoch: 39 [698819/888800 78.62%] train loss: 1.5212952348520048e-05 \n",
      "epoch: 39 [699930/888800 78.75%] train loss: 1.5384908692794852e-05 \n",
      "epoch: 39 [701041/888800 78.88%] train loss: 1.4506176739814691e-05 \n",
      "epoch: 39 [702152/888800 79.00%] train loss: 1.3932059118815232e-05 \n",
      "epoch: 39 [703263/888800 79.12%] train loss: 1.2972691365575884e-05 \n",
      "epoch: 39 [704374/888800 79.25%] train loss: 1.489419173594797e-05 \n",
      "epoch: 39 [705485/888800 79.38%] train loss: 1.3386428690864705e-05 \n",
      "epoch: 39 [706596/888800 79.50%] train loss: 1.2939958651259076e-05 \n",
      "epoch: 39 [707707/888800 79.62%] train loss: 1.493575382482959e-05 \n",
      "epoch: 39 [708818/888800 79.75%] train loss: 1.3809490155836102e-05 \n",
      "epoch: 39 [709929/888800 79.88%] train loss: 1.5574138160445727e-05 \n",
      "epoch: 39 [711040/888800 80.00%] train loss: 1.3828907867718954e-05 \n",
      "epoch: 39 [712151/888800 80.12%] train loss: 1.4138820006337482e-05 \n",
      "epoch: 39 [713262/888800 80.25%] train loss: 1.2695648365479428e-05 \n",
      "epoch: 39 [714373/888800 80.38%] train loss: 1.459251234336989e-05 \n",
      "epoch: 39 [715484/888800 80.50%] train loss: 1.619926842977293e-05 \n",
      "epoch: 39 [716595/888800 80.62%] train loss: 1.4609946447308175e-05 \n",
      "epoch: 39 [717706/888800 80.75%] train loss: 1.4873624422762077e-05 \n",
      "epoch: 39 [718817/888800 80.88%] train loss: 1.2864682503277436e-05 \n",
      "epoch: 39 [719928/888800 81.00%] train loss: 1.4218898286344483e-05 \n",
      "epoch: 39 [721039/888800 81.12%] train loss: 1.3537524864659645e-05 \n",
      "epoch: 39 [722150/888800 81.25%] train loss: 1.4027918041392695e-05 \n",
      "epoch: 39 [723261/888800 81.38%] train loss: 1.3949415915703867e-05 \n",
      "epoch: 39 [724372/888800 81.50%] train loss: 1.4435312550631352e-05 \n",
      "epoch: 39 [725483/888800 81.62%] train loss: 1.529875589767471e-05 \n",
      "epoch: 39 [726594/888800 81.75%] train loss: 1.4362181900651194e-05 \n",
      "epoch: 39 [727705/888800 81.88%] train loss: 1.4447306966758333e-05 \n",
      "epoch: 39 [728816/888800 82.00%] train loss: 1.4957598978071474e-05 \n",
      "epoch: 39 [729927/888800 82.12%] train loss: 1.3839620805811137e-05 \n",
      "epoch: 39 [731038/888800 82.25%] train loss: 1.4875027773086913e-05 \n",
      "epoch: 39 [732149/888800 82.38%] train loss: 1.4061187357583549e-05 \n",
      "epoch: 39 [733260/888800 82.50%] train loss: 1.511518257757416e-05 \n",
      "epoch: 39 [734371/888800 82.62%] train loss: 1.3483450857165735e-05 \n",
      "epoch: 39 [735482/888800 82.75%] train loss: 1.4706843103340361e-05 \n",
      "epoch: 39 [736593/888800 82.88%] train loss: 1.4501401892630383e-05 \n",
      "epoch: 39 [737704/888800 83.00%] train loss: 1.394867922499543e-05 \n",
      "epoch: 39 [738815/888800 83.12%] train loss: 1.4502407793770544e-05 \n",
      "epoch: 39 [739926/888800 83.25%] train loss: 1.6204654457396828e-05 \n",
      "epoch: 39 [741037/888800 83.38%] train loss: 1.3823880181007553e-05 \n",
      "epoch: 39 [742148/888800 83.50%] train loss: 1.367720960843144e-05 \n",
      "epoch: 39 [743259/888800 83.62%] train loss: 1.4887376892147586e-05 \n",
      "epoch: 39 [744370/888800 83.75%] train loss: 1.4166526852932293e-05 \n",
      "epoch: 39 [745481/888800 83.88%] train loss: 1.546799103380181e-05 \n",
      "epoch: 39 [746592/888800 84.00%] train loss: 1.3978583410789724e-05 \n",
      "epoch: 39 [747703/888800 84.12%] train loss: 1.344939573755255e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [748814/888800 84.25%] train loss: 1.3905917512602173e-05 \n",
      "epoch: 39 [749925/888800 84.38%] train loss: 1.4469894267676864e-05 \n",
      "epoch: 39 [751036/888800 84.50%] train loss: 1.3803967704006936e-05 \n",
      "epoch: 39 [752147/888800 84.62%] train loss: 1.3720175047637895e-05 \n",
      "epoch: 39 [753258/888800 84.75%] train loss: 1.3382931683736388e-05 \n",
      "epoch: 39 [754369/888800 84.88%] train loss: 1.5681463992223144e-05 \n",
      "epoch: 39 [755480/888800 85.00%] train loss: 1.3078941265121102e-05 \n",
      "epoch: 39 [756591/888800 85.12%] train loss: 1.3191245670896024e-05 \n",
      "epoch: 39 [757702/888800 85.25%] train loss: 1.3484318515111227e-05 \n",
      "epoch: 39 [758813/888800 85.38%] train loss: 1.4236765309760813e-05 \n",
      "epoch: 39 [759924/888800 85.50%] train loss: 1.4104777619650122e-05 \n",
      "epoch: 39 [761035/888800 85.62%] train loss: 1.4710994037159253e-05 \n",
      "epoch: 39 [762146/888800 85.75%] train loss: 1.3907199900131673e-05 \n",
      "epoch: 39 [763257/888800 85.88%] train loss: 1.5886240362306125e-05 \n",
      "epoch: 39 [764368/888800 86.00%] train loss: 1.4559231203747913e-05 \n",
      "epoch: 39 [765479/888800 86.12%] train loss: 1.3717055480810814e-05 \n",
      "epoch: 39 [766590/888800 86.25%] train loss: 1.436903858120786e-05 \n",
      "epoch: 39 [767701/888800 86.38%] train loss: 1.4671501048724167e-05 \n",
      "epoch: 39 [768812/888800 86.50%] train loss: 1.567475192132406e-05 \n",
      "epoch: 39 [769923/888800 86.62%] train loss: 1.3606356333184522e-05 \n",
      "epoch: 39 [771034/888800 86.75%] train loss: 1.5759993402753025e-05 \n",
      "epoch: 39 [772145/888800 86.88%] train loss: 1.4337271750264335e-05 \n",
      "epoch: 39 [773256/888800 87.00%] train loss: 1.5414241715916432e-05 \n",
      "epoch: 39 [774367/888800 87.12%] train loss: 1.3172184480936266e-05 \n",
      "epoch: 39 [775478/888800 87.25%] train loss: 1.4284396456787363e-05 \n",
      "epoch: 39 [776589/888800 87.38%] train loss: 1.4297500456450507e-05 \n",
      "epoch: 39 [777700/888800 87.50%] train loss: 1.3864257198292762e-05 \n",
      "epoch: 39 [778811/888800 87.62%] train loss: 1.4083163478062488e-05 \n",
      "epoch: 39 [779922/888800 87.75%] train loss: 1.4582075891667046e-05 \n",
      "epoch: 39 [781033/888800 87.88%] train loss: 1.5461431758012623e-05 \n",
      "epoch: 39 [782144/888800 88.00%] train loss: 1.4758450561203063e-05 \n",
      "epoch: 39 [783255/888800 88.12%] train loss: 1.508540390204871e-05 \n",
      "epoch: 39 [784366/888800 88.25%] train loss: 1.4757930330233648e-05 \n",
      "epoch: 39 [785477/888800 88.38%] train loss: 1.4223748621589039e-05 \n",
      "epoch: 39 [786588/888800 88.50%] train loss: 1.4408843526325654e-05 \n",
      "epoch: 39 [787699/888800 88.62%] train loss: 1.4633420505560935e-05 \n",
      "epoch: 39 [788810/888800 88.75%] train loss: 1.4442202882491983e-05 \n",
      "epoch: 39 [789921/888800 88.88%] train loss: 1.412167421221966e-05 \n",
      "epoch: 39 [791032/888800 89.00%] train loss: 1.4300028851721436e-05 \n",
      "epoch: 39 [792143/888800 89.12%] train loss: 1.3338809367269278e-05 \n",
      "epoch: 39 [793254/888800 89.25%] train loss: 1.4656746316177305e-05 \n",
      "epoch: 39 [794365/888800 89.38%] train loss: 1.3063626283837948e-05 \n",
      "epoch: 39 [795476/888800 89.50%] train loss: 1.484515451011248e-05 \n",
      "epoch: 39 [796587/888800 89.62%] train loss: 1.4926896255929023e-05 \n",
      "epoch: 39 [797698/888800 89.75%] train loss: 1.550786691950634e-05 \n",
      "epoch: 39 [798809/888800 89.88%] train loss: 1.4657901374448556e-05 \n",
      "epoch: 39 [799920/888800 90.00%] train loss: 1.5993697161320597e-05 \n",
      "epoch: 39 [801031/888800 90.12%] train loss: 1.4191725313139614e-05 \n",
      "epoch: 39 [802142/888800 90.25%] train loss: 1.7320333427051082e-05 \n",
      "epoch: 39 [803253/888800 90.38%] train loss: 1.3468341421685182e-05 \n",
      "epoch: 39 [804364/888800 90.50%] train loss: 1.6686828530509956e-05 \n",
      "epoch: 39 [805475/888800 90.62%] train loss: 1.4058723536436446e-05 \n",
      "epoch: 39 [806586/888800 90.75%] train loss: 1.4723675121786073e-05 \n",
      "epoch: 39 [807697/888800 90.88%] train loss: 1.4244497833715286e-05 \n",
      "epoch: 39 [808808/888800 91.00%] train loss: 1.4645558621850796e-05 \n",
      "epoch: 39 [809919/888800 91.12%] train loss: 1.507541037426563e-05 \n",
      "epoch: 39 [811030/888800 91.25%] train loss: 1.4858218492008746e-05 \n",
      "epoch: 39 [812141/888800 91.38%] train loss: 1.3523273082682863e-05 \n",
      "epoch: 39 [813252/888800 91.50%] train loss: 1.3731665603700094e-05 \n",
      "epoch: 39 [814363/888800 91.62%] train loss: 1.3488697732100263e-05 \n",
      "epoch: 39 [815474/888800 91.75%] train loss: 1.3240502084954642e-05 \n",
      "epoch: 39 [816585/888800 91.88%] train loss: 1.3014302567171399e-05 \n",
      "epoch: 39 [817696/888800 92.00%] train loss: 1.368759239994688e-05 \n",
      "epoch: 39 [818807/888800 92.12%] train loss: 1.3799283806292806e-05 \n",
      "epoch: 39 [819918/888800 92.25%] train loss: 1.3554664292314555e-05 \n",
      "epoch: 39 [821029/888800 92.38%] train loss: 1.4074297723709606e-05 \n",
      "epoch: 39 [822140/888800 92.50%] train loss: 1.4859250768495258e-05 \n",
      "epoch: 39 [823251/888800 92.62%] train loss: 1.3043889339314774e-05 \n",
      "epoch: 39 [824362/888800 92.75%] train loss: 1.4121799722488504e-05 \n",
      "epoch: 39 [825473/888800 92.88%] train loss: 1.2952696124557406e-05 \n",
      "epoch: 39 [826584/888800 93.00%] train loss: 1.345227883575717e-05 \n",
      "epoch: 39 [827695/888800 93.12%] train loss: 1.3659380783792585e-05 \n",
      "epoch: 39 [828806/888800 93.25%] train loss: 1.481000435887836e-05 \n",
      "epoch: 39 [829917/888800 93.38%] train loss: 1.3562512322096154e-05 \n",
      "epoch: 39 [831028/888800 93.50%] train loss: 1.3491919162333943e-05 \n",
      "epoch: 39 [832139/888800 93.62%] train loss: 1.3756660337094218e-05 \n",
      "epoch: 39 [833250/888800 93.75%] train loss: 1.2818903996958397e-05 \n",
      "epoch: 39 [834361/888800 93.88%] train loss: 1.46197062349529e-05 \n",
      "epoch: 39 [835472/888800 94.00%] train loss: 1.3672846762347035e-05 \n",
      "epoch: 39 [836583/888800 94.12%] train loss: 1.3427613339445088e-05 \n",
      "epoch: 39 [837694/888800 94.25%] train loss: 1.5090216038515791e-05 \n",
      "epoch: 39 [838805/888800 94.38%] train loss: 1.5085166523931548e-05 \n",
      "epoch: 39 [839916/888800 94.50%] train loss: 1.3681210475624539e-05 \n",
      "epoch: 39 [841027/888800 94.62%] train loss: 1.370877907902468e-05 \n",
      "epoch: 39 [842138/888800 94.75%] train loss: 1.3886813576391432e-05 \n",
      "epoch: 39 [843249/888800 94.88%] train loss: 1.3691043932340108e-05 \n",
      "epoch: 39 [844360/888800 95.00%] train loss: 1.425254868081538e-05 \n",
      "epoch: 39 [845471/888800 95.12%] train loss: 1.3754012798017357e-05 \n",
      "epoch: 39 [846582/888800 95.25%] train loss: 1.3996122106618714e-05 \n",
      "epoch: 39 [847693/888800 95.38%] train loss: 1.4791981811868027e-05 \n",
      "epoch: 39 [848804/888800 95.50%] train loss: 1.4611643564421684e-05 \n",
      "epoch: 39 [849915/888800 95.62%] train loss: 1.4008486687089317e-05 \n",
      "epoch: 39 [851026/888800 95.75%] train loss: 1.3973576642456464e-05 \n",
      "epoch: 39 [852137/888800 95.88%] train loss: 1.470943789172452e-05 \n",
      "epoch: 39 [853248/888800 96.00%] train loss: 1.5113446352188475e-05 \n",
      "epoch: 39 [854359/888800 96.12%] train loss: 1.382241134706419e-05 \n",
      "epoch: 39 [855470/888800 96.25%] train loss: 1.429451094736578e-05 \n",
      "epoch: 39 [856581/888800 96.38%] train loss: 1.3736696928390302e-05 \n",
      "epoch: 39 [857692/888800 96.50%] train loss: 1.4072685189603362e-05 \n",
      "epoch: 39 [858803/888800 96.62%] train loss: 1.4066407857171725e-05 \n",
      "epoch: 39 [859914/888800 96.75%] train loss: 1.5671857909183018e-05 \n",
      "epoch: 39 [861025/888800 96.88%] train loss: 1.398027870891383e-05 \n",
      "epoch: 39 [862136/888800 97.00%] train loss: 1.4336184904095717e-05 \n",
      "epoch: 39 [863247/888800 97.12%] train loss: 1.3842373846273404e-05 \n",
      "epoch: 39 [864358/888800 97.25%] train loss: 1.4921713045623619e-05 \n",
      "epoch: 39 [865469/888800 97.38%] train loss: 1.3812035831506364e-05 \n",
      "epoch: 39 [866580/888800 97.50%] train loss: 1.3900947124056984e-05 \n",
      "epoch: 39 [867691/888800 97.62%] train loss: 1.3493700862454716e-05 \n",
      "epoch: 39 [868802/888800 97.75%] train loss: 1.330814939137781e-05 \n",
      "epoch: 39 [869913/888800 97.88%] train loss: 1.3765909898211248e-05 \n",
      "epoch: 39 [871024/888800 98.00%] train loss: 1.4996320714999456e-05 \n",
      "epoch: 39 [872135/888800 98.12%] train loss: 1.4342582289827988e-05 \n",
      "epoch: 39 [873246/888800 98.25%] train loss: 1.3633645721711218e-05 \n",
      "epoch: 39 [874357/888800 98.38%] train loss: 1.3190560821385588e-05 \n",
      "epoch: 39 [875468/888800 98.50%] train loss: 1.3950902030046564e-05 \n",
      "epoch: 39 [876579/888800 98.62%] train loss: 1.5337185686803423e-05 \n",
      "epoch: 39 [877690/888800 98.75%] train loss: 1.629514190426562e-05 \n",
      "epoch: 39 [878801/888800 98.88%] train loss: 1.4454290976573247e-05 \n",
      "epoch: 39 [879912/888800 99.00%] train loss: 1.5016487850516569e-05 \n",
      "epoch: 39 [881023/888800 99.12%] train loss: 1.3982470591145102e-05 \n",
      "epoch: 39 [882134/888800 99.25%] train loss: 1.4148737136565614e-05 \n",
      "epoch: 39 [883245/888800 99.38%] train loss: 1.4294004358816892e-05 \n",
      "epoch: 39 [884356/888800 99.50%] train loss: 1.4015132364875171e-05 \n",
      "epoch: 39 [885467/888800 99.62%] train loss: 1.3482305803336203e-05 \n",
      "epoch: 39 [886578/888800 99.75%] train loss: 1.3799589396512602e-05 \n",
      "epoch: 39 [887689/888800 99.88%] train loss: 1.5631285350536928e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [0/888800 0.00%] train loss: 1.504806277807802e-05 \n",
      "epoch: 40 [1111/888800 0.12%] train loss: 1.4058656233828515e-05 \n",
      "epoch: 40 [2222/888800 0.25%] train loss: 1.344392785540549e-05 \n",
      "epoch: 40 [3333/888800 0.38%] train loss: 1.3847939044353552e-05 \n",
      "epoch: 40 [4444/888800 0.50%] train loss: 1.3858401871402748e-05 \n",
      "epoch: 40 [5555/888800 0.62%] train loss: 1.3981039955979213e-05 \n",
      "epoch: 40 [6666/888800 0.75%] train loss: 1.4648901014879812e-05 \n",
      "epoch: 40 [7777/888800 0.88%] train loss: 1.4774578630749602e-05 \n",
      "epoch: 40 [8888/888800 1.00%] train loss: 1.3998398571857251e-05 \n",
      "epoch: 40 [9999/888800 1.12%] train loss: 1.504890951764537e-05 \n",
      "epoch: 40 [11110/888800 1.25%] train loss: 1.4235405615181662e-05 \n",
      "epoch: 40 [12221/888800 1.38%] train loss: 1.4651156561740208e-05 \n",
      "epoch: 40 [13332/888800 1.50%] train loss: 1.3623151971842162e-05 \n",
      "epoch: 40 [14443/888800 1.62%] train loss: 1.3475654668582138e-05 \n",
      "epoch: 40 [15554/888800 1.75%] train loss: 1.4462903891399037e-05 \n",
      "epoch: 40 [16665/888800 1.88%] train loss: 1.4421920241147745e-05 \n",
      "epoch: 40 [17776/888800 2.00%] train loss: 1.373621853417717e-05 \n",
      "epoch: 40 [18887/888800 2.12%] train loss: 1.5157869711401872e-05 \n",
      "epoch: 40 [19998/888800 2.25%] train loss: 1.4006214769324288e-05 \n",
      "epoch: 40 [21109/888800 2.38%] train loss: 1.4486649888567626e-05 \n",
      "epoch: 40 [22220/888800 2.50%] train loss: 1.3721412869927008e-05 \n",
      "epoch: 40 [23331/888800 2.62%] train loss: 1.4762152204639278e-05 \n",
      "epoch: 40 [24442/888800 2.75%] train loss: 1.5233176782203373e-05 \n",
      "epoch: 40 [25553/888800 2.88%] train loss: 1.2921940651722252e-05 \n",
      "epoch: 40 [26664/888800 3.00%] train loss: 1.3281103747431189e-05 \n",
      "epoch: 40 [27775/888800 3.12%] train loss: 1.3759784451394808e-05 \n",
      "epoch: 40 [28886/888800 3.25%] train loss: 1.261216038983548e-05 \n",
      "epoch: 40 [29997/888800 3.38%] train loss: 1.4384341739059892e-05 \n",
      "epoch: 40 [31108/888800 3.50%] train loss: 1.5089049156813417e-05 \n",
      "epoch: 40 [32219/888800 3.62%] train loss: 1.3715072782360949e-05 \n",
      "epoch: 40 [33330/888800 3.75%] train loss: 1.3630420653498732e-05 \n",
      "epoch: 40 [34441/888800 3.88%] train loss: 1.2925219380122144e-05 \n",
      "epoch: 40 [35552/888800 4.00%] train loss: 1.4268432096287142e-05 \n",
      "epoch: 40 [36663/888800 4.12%] train loss: 1.3955382200947497e-05 \n",
      "epoch: 40 [37774/888800 4.25%] train loss: 1.4500894394586794e-05 \n",
      "epoch: 40 [38885/888800 4.38%] train loss: 1.3516376384359319e-05 \n",
      "epoch: 40 [39996/888800 4.50%] train loss: 1.4080370419833343e-05 \n",
      "epoch: 40 [41107/888800 4.62%] train loss: 1.385188807034865e-05 \n",
      "epoch: 40 [42218/888800 4.75%] train loss: 1.534062175778672e-05 \n",
      "epoch: 40 [43329/888800 4.88%] train loss: 1.3754353858530521e-05 \n",
      "epoch: 40 [44440/888800 5.00%] train loss: 1.4723514141223859e-05 \n",
      "epoch: 40 [45551/888800 5.12%] train loss: 1.2862524272350129e-05 \n",
      "epoch: 40 [46662/888800 5.25%] train loss: 1.4534899491991382e-05 \n",
      "epoch: 40 [47773/888800 5.38%] train loss: 1.669821358518675e-05 \n",
      "epoch: 40 [48884/888800 5.50%] train loss: 1.2562577467178926e-05 \n",
      "epoch: 40 [49995/888800 5.62%] train loss: 1.4703819942951668e-05 \n",
      "epoch: 40 [51106/888800 5.75%] train loss: 1.4349392586154863e-05 \n",
      "epoch: 40 [52217/888800 5.88%] train loss: 1.531589987280313e-05 \n",
      "epoch: 40 [53328/888800 6.00%] train loss: 1.4910805475665256e-05 \n",
      "epoch: 40 [54439/888800 6.12%] train loss: 1.3729930287809111e-05 \n",
      "epoch: 40 [55550/888800 6.25%] train loss: 1.4668356016045436e-05 \n",
      "epoch: 40 [56661/888800 6.38%] train loss: 1.4665247363154776e-05 \n",
      "epoch: 40 [57772/888800 6.50%] train loss: 1.2998736565350555e-05 \n",
      "epoch: 40 [58883/888800 6.62%] train loss: 1.3984607903694268e-05 \n",
      "epoch: 40 [59994/888800 6.75%] train loss: 1.3771988051303197e-05 \n",
      "epoch: 40 [61105/888800 6.88%] train loss: 1.4929190001566894e-05 \n",
      "epoch: 40 [62216/888800 7.00%] train loss: 1.3776761079498101e-05 \n",
      "epoch: 40 [63327/888800 7.12%] train loss: 1.3845305147697218e-05 \n",
      "epoch: 40 [64438/888800 7.25%] train loss: 1.435130434401799e-05 \n",
      "epoch: 40 [65549/888800 7.38%] train loss: 1.4605839169234969e-05 \n",
      "epoch: 40 [66660/888800 7.50%] train loss: 1.456590871384833e-05 \n",
      "epoch: 40 [67771/888800 7.62%] train loss: 1.456816062272992e-05 \n",
      "epoch: 40 [68882/888800 7.75%] train loss: 1.552670801174827e-05 \n",
      "epoch: 40 [69993/888800 7.88%] train loss: 1.640389564272482e-05 \n",
      "epoch: 40 [71104/888800 8.00%] train loss: 1.4763131730433088e-05 \n",
      "epoch: 40 [72215/888800 8.12%] train loss: 1.5304196494980715e-05 \n",
      "epoch: 40 [73326/888800 8.25%] train loss: 1.3408569429884665e-05 \n",
      "epoch: 40 [74437/888800 8.38%] train loss: 1.3743044291913975e-05 \n",
      "epoch: 40 [75548/888800 8.50%] train loss: 1.6350453734048642e-05 \n",
      "epoch: 40 [76659/888800 8.62%] train loss: 1.5268600691342726e-05 \n",
      "epoch: 40 [77770/888800 8.75%] train loss: 1.4355052371683996e-05 \n",
      "epoch: 40 [78881/888800 8.88%] train loss: 1.4396286132978275e-05 \n",
      "epoch: 40 [79992/888800 9.00%] train loss: 1.3613683222502004e-05 \n",
      "epoch: 40 [81103/888800 9.12%] train loss: 1.5746783901704475e-05 \n",
      "epoch: 40 [82214/888800 9.25%] train loss: 1.3991550986247603e-05 \n",
      "epoch: 40 [83325/888800 9.38%] train loss: 1.540547418699134e-05 \n",
      "epoch: 40 [84436/888800 9.50%] train loss: 1.360171791020548e-05 \n",
      "epoch: 40 [85547/888800 9.62%] train loss: 1.409020296705421e-05 \n",
      "epoch: 40 [86658/888800 9.75%] train loss: 1.4724731954629533e-05 \n",
      "epoch: 40 [87769/888800 9.88%] train loss: 1.4333881154016126e-05 \n",
      "epoch: 40 [88880/888800 10.00%] train loss: 1.5037668163131457e-05 \n",
      "epoch: 40 [89991/888800 10.12%] train loss: 1.4113249562797137e-05 \n",
      "epoch: 40 [91102/888800 10.25%] train loss: 1.3796415260003414e-05 \n",
      "epoch: 40 [92213/888800 10.38%] train loss: 1.449608589609852e-05 \n",
      "epoch: 40 [93324/888800 10.50%] train loss: 1.3701276657229755e-05 \n",
      "epoch: 40 [94435/888800 10.62%] train loss: 1.516806150902994e-05 \n",
      "epoch: 40 [95546/888800 10.75%] train loss: 1.3528512681659777e-05 \n",
      "epoch: 40 [96657/888800 10.88%] train loss: 1.3444120668282267e-05 \n",
      "epoch: 40 [97768/888800 11.00%] train loss: 1.5257184713846073e-05 \n",
      "epoch: 40 [98879/888800 11.12%] train loss: 1.3827556358592119e-05 \n",
      "epoch: 40 [99990/888800 11.25%] train loss: 1.4708954950037878e-05 \n",
      "epoch: 40 [101101/888800 11.38%] train loss: 1.4076927072892431e-05 \n",
      "epoch: 40 [102212/888800 11.50%] train loss: 1.3901047168474179e-05 \n",
      "epoch: 40 [103323/888800 11.62%] train loss: 1.3988763384986669e-05 \n",
      "epoch: 40 [104434/888800 11.75%] train loss: 1.3185193893150426e-05 \n",
      "epoch: 40 [105545/888800 11.88%] train loss: 1.3250578376755584e-05 \n",
      "epoch: 40 [106656/888800 12.00%] train loss: 1.4466610082308762e-05 \n",
      "epoch: 40 [107767/888800 12.12%] train loss: 1.325673201790778e-05 \n",
      "epoch: 40 [108878/888800 12.25%] train loss: 1.3728583326155785e-05 \n",
      "epoch: 40 [109989/888800 12.38%] train loss: 1.5012524272606242e-05 \n",
      "epoch: 40 [111100/888800 12.50%] train loss: 1.4005752746015787e-05 \n",
      "epoch: 40 [112211/888800 12.62%] train loss: 1.3831423530064058e-05 \n",
      "epoch: 40 [113322/888800 12.75%] train loss: 1.4982638276705984e-05 \n",
      "epoch: 40 [114433/888800 12.88%] train loss: 1.3657150702783838e-05 \n",
      "epoch: 40 [115544/888800 13.00%] train loss: 1.3781029338133521e-05 \n",
      "epoch: 40 [116655/888800 13.12%] train loss: 1.3682752069144044e-05 \n",
      "epoch: 40 [117766/888800 13.25%] train loss: 1.3985605619382113e-05 \n",
      "epoch: 40 [118877/888800 13.38%] train loss: 1.3862082596460823e-05 \n",
      "epoch: 40 [119988/888800 13.50%] train loss: 1.4723746062372811e-05 \n",
      "epoch: 40 [121099/888800 13.62%] train loss: 1.4197247764968779e-05 \n",
      "epoch: 40 [122210/888800 13.75%] train loss: 1.4275547073339112e-05 \n",
      "epoch: 40 [123321/888800 13.88%] train loss: 1.5143008567974903e-05 \n",
      "epoch: 40 [124432/888800 14.00%] train loss: 1.3417572517937515e-05 \n",
      "epoch: 40 [125543/888800 14.12%] train loss: 1.3662289347848855e-05 \n",
      "epoch: 40 [126654/888800 14.25%] train loss: 1.537589923827909e-05 \n",
      "epoch: 40 [127765/888800 14.38%] train loss: 1.3834535820933525e-05 \n",
      "epoch: 40 [128876/888800 14.50%] train loss: 1.5050025467644446e-05 \n",
      "epoch: 40 [129987/888800 14.62%] train loss: 1.3054963346803561e-05 \n",
      "epoch: 40 [131098/888800 14.75%] train loss: 1.6004780263756402e-05 \n",
      "epoch: 40 [132209/888800 14.88%] train loss: 1.3085530554235447e-05 \n",
      "epoch: 40 [133320/888800 15.00%] train loss: 1.4469156667473726e-05 \n",
      "epoch: 40 [134431/888800 15.12%] train loss: 1.4703783563163597e-05 \n",
      "epoch: 40 [135542/888800 15.25%] train loss: 1.5104467820492573e-05 \n",
      "epoch: 40 [136653/888800 15.38%] train loss: 1.413099562341813e-05 \n",
      "epoch: 40 [137764/888800 15.50%] train loss: 1.5266297850757837e-05 \n",
      "epoch: 40 [138875/888800 15.62%] train loss: 1.439813513570698e-05 \n",
      "epoch: 40 [139986/888800 15.75%] train loss: 1.3969641258881893e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [141097/888800 15.88%] train loss: 1.3811250028084032e-05 \n",
      "epoch: 40 [142208/888800 16.00%] train loss: 1.398678887198912e-05 \n",
      "epoch: 40 [143319/888800 16.12%] train loss: 1.4077905689191539e-05 \n",
      "epoch: 40 [144430/888800 16.25%] train loss: 1.3468188626575284e-05 \n",
      "epoch: 40 [145541/888800 16.38%] train loss: 1.3690503692487255e-05 \n",
      "epoch: 40 [146652/888800 16.50%] train loss: 1.4981575986894313e-05 \n",
      "epoch: 40 [147763/888800 16.62%] train loss: 1.571177017467562e-05 \n",
      "epoch: 40 [148874/888800 16.75%] train loss: 1.3857066733180545e-05 \n",
      "epoch: 40 [149985/888800 16.88%] train loss: 1.433465240552323e-05 \n",
      "epoch: 40 [151096/888800 17.00%] train loss: 1.4276047295425087e-05 \n",
      "epoch: 40 [152207/888800 17.12%] train loss: 1.4157877558318432e-05 \n",
      "epoch: 40 [153318/888800 17.25%] train loss: 1.3733005289395805e-05 \n",
      "epoch: 40 [154429/888800 17.38%] train loss: 1.3257856153359171e-05 \n",
      "epoch: 40 [155540/888800 17.50%] train loss: 1.3638753443956375e-05 \n",
      "epoch: 40 [156651/888800 17.62%] train loss: 1.3958479939901736e-05 \n",
      "epoch: 40 [157762/888800 17.75%] train loss: 1.4828533494437579e-05 \n",
      "epoch: 40 [158873/888800 17.88%] train loss: 1.309376057179179e-05 \n",
      "epoch: 40 [159984/888800 18.00%] train loss: 1.6238889656960964e-05 \n",
      "epoch: 40 [161095/888800 18.12%] train loss: 1.4747499335499015e-05 \n",
      "epoch: 40 [162206/888800 18.25%] train loss: 1.4052199730940629e-05 \n",
      "epoch: 40 [163317/888800 18.38%] train loss: 1.5466526747331955e-05 \n",
      "epoch: 40 [164428/888800 18.50%] train loss: 1.5093317415448837e-05 \n",
      "epoch: 40 [165539/888800 18.62%] train loss: 1.6323227100656368e-05 \n",
      "epoch: 40 [166650/888800 18.75%] train loss: 1.3952036169939674e-05 \n",
      "epoch: 40 [167761/888800 18.88%] train loss: 1.5947327483445406e-05 \n",
      "epoch: 40 [168872/888800 19.00%] train loss: 1.4453483345278073e-05 \n",
      "epoch: 40 [169983/888800 19.12%] train loss: 1.3700693671125919e-05 \n",
      "epoch: 40 [171094/888800 19.25%] train loss: 1.4569924132956658e-05 \n",
      "epoch: 40 [172205/888800 19.38%] train loss: 1.3758494787907694e-05 \n",
      "epoch: 40 [173316/888800 19.50%] train loss: 1.4709377865074202e-05 \n",
      "epoch: 40 [174427/888800 19.62%] train loss: 1.3521816072170623e-05 \n",
      "epoch: 40 [175538/888800 19.75%] train loss: 1.3978064089315012e-05 \n",
      "epoch: 40 [176649/888800 19.88%] train loss: 1.5590669136145152e-05 \n",
      "epoch: 40 [177760/888800 20.00%] train loss: 1.4598823327105492e-05 \n",
      "epoch: 40 [178871/888800 20.12%] train loss: 1.3564081200456712e-05 \n",
      "epoch: 40 [179982/888800 20.25%] train loss: 1.4367492440214846e-05 \n",
      "epoch: 40 [181093/888800 20.38%] train loss: 1.4052004189579748e-05 \n",
      "epoch: 40 [182204/888800 20.50%] train loss: 1.3720835340791382e-05 \n",
      "epoch: 40 [183315/888800 20.62%] train loss: 1.4421248124563135e-05 \n",
      "epoch: 40 [184426/888800 20.75%] train loss: 1.3976474292576313e-05 \n",
      "epoch: 40 [185537/888800 20.88%] train loss: 1.3251015843707137e-05 \n",
      "epoch: 40 [186648/888800 21.00%] train loss: 1.4846070371277165e-05 \n",
      "epoch: 40 [187759/888800 21.12%] train loss: 1.4545908015861642e-05 \n",
      "epoch: 40 [188870/888800 21.25%] train loss: 1.3686235433851834e-05 \n",
      "epoch: 40 [189981/888800 21.38%] train loss: 1.435975354979746e-05 \n",
      "epoch: 40 [191092/888800 21.50%] train loss: 1.453785353078274e-05 \n",
      "epoch: 40 [192203/888800 21.62%] train loss: 1.4585777535103261e-05 \n",
      "epoch: 40 [193314/888800 21.75%] train loss: 1.3753728126175702e-05 \n",
      "epoch: 40 [194425/888800 21.88%] train loss: 1.501870428910479e-05 \n",
      "epoch: 40 [195536/888800 22.00%] train loss: 1.5016962606750894e-05 \n",
      "epoch: 40 [196647/888800 22.12%] train loss: 1.467975653213216e-05 \n",
      "epoch: 40 [197758/888800 22.25%] train loss: 1.3604602827399503e-05 \n",
      "epoch: 40 [198869/888800 22.38%] train loss: 1.4031995306140743e-05 \n",
      "epoch: 40 [199980/888800 22.50%] train loss: 1.4248868865252007e-05 \n",
      "epoch: 40 [201091/888800 22.62%] train loss: 1.5465258911717683e-05 \n",
      "epoch: 40 [202202/888800 22.75%] train loss: 1.3837926417181734e-05 \n",
      "epoch: 40 [203313/888800 22.88%] train loss: 1.3901666534366086e-05 \n",
      "epoch: 40 [204424/888800 23.00%] train loss: 1.445577981940005e-05 \n",
      "epoch: 40 [205535/888800 23.12%] train loss: 1.3920409401180223e-05 \n",
      "epoch: 40 [206646/888800 23.25%] train loss: 1.37805054691853e-05 \n",
      "epoch: 40 [207757/888800 23.38%] train loss: 1.4220583580026869e-05 \n",
      "epoch: 40 [208868/888800 23.50%] train loss: 1.4288863894762471e-05 \n",
      "epoch: 40 [209979/888800 23.62%] train loss: 1.4434827789955307e-05 \n",
      "epoch: 40 [211090/888800 23.75%] train loss: 1.4549936167895794e-05 \n",
      "epoch: 40 [212201/888800 23.88%] train loss: 1.373110990243731e-05 \n",
      "epoch: 40 [213312/888800 24.00%] train loss: 1.5346657164627686e-05 \n",
      "epoch: 40 [214423/888800 24.12%] train loss: 1.2019911991956178e-05 \n",
      "epoch: 40 [215534/888800 24.25%] train loss: 1.4124017980066128e-05 \n",
      "epoch: 40 [216645/888800 24.38%] train loss: 1.2696944395429455e-05 \n",
      "epoch: 40 [217756/888800 24.50%] train loss: 1.3527434930438176e-05 \n",
      "epoch: 40 [218867/888800 24.62%] train loss: 1.3848541129846126e-05 \n",
      "epoch: 40 [219978/888800 24.75%] train loss: 1.5498999346164055e-05 \n",
      "epoch: 40 [221089/888800 24.88%] train loss: 1.3487564501701854e-05 \n",
      "epoch: 40 [222200/888800 25.00%] train loss: 1.3904969819122925e-05 \n",
      "epoch: 40 [223311/888800 25.12%] train loss: 1.4420483239518944e-05 \n",
      "epoch: 40 [224422/888800 25.25%] train loss: 1.3972239685244858e-05 \n",
      "epoch: 40 [225533/888800 25.38%] train loss: 1.3845450666849501e-05 \n",
      "epoch: 40 [226644/888800 25.50%] train loss: 1.4556010683008935e-05 \n",
      "epoch: 40 [227755/888800 25.62%] train loss: 1.3253199540486094e-05 \n",
      "epoch: 40 [228866/888800 25.75%] train loss: 1.3792296158499084e-05 \n",
      "epoch: 40 [229977/888800 25.88%] train loss: 1.3265891539049335e-05 \n",
      "epoch: 40 [231088/888800 26.00%] train loss: 1.479326056141872e-05 \n",
      "epoch: 40 [232199/888800 26.12%] train loss: 1.3598540135717485e-05 \n",
      "epoch: 40 [233310/888800 26.25%] train loss: 1.3365461200010031e-05 \n",
      "epoch: 40 [234421/888800 26.38%] train loss: 1.3952176232123747e-05 \n",
      "epoch: 40 [235532/888800 26.50%] train loss: 1.3275367564347107e-05 \n",
      "epoch: 40 [236643/888800 26.62%] train loss: 1.3720545211981516e-05 \n",
      "epoch: 40 [237754/888800 26.75%] train loss: 1.4477026525128167e-05 \n",
      "epoch: 40 [238865/888800 26.88%] train loss: 1.6523741578566842e-05 \n",
      "epoch: 40 [239976/888800 27.00%] train loss: 1.3564211258199066e-05 \n",
      "epoch: 40 [241087/888800 27.12%] train loss: 1.3887157365388703e-05 \n",
      "epoch: 40 [242198/888800 27.25%] train loss: 1.4282756637840066e-05 \n",
      "epoch: 40 [243309/888800 27.38%] train loss: 1.4136108802631497e-05 \n",
      "epoch: 40 [244420/888800 27.50%] train loss: 1.3771011253993493e-05 \n",
      "epoch: 40 [245531/888800 27.62%] train loss: 1.4374187230714597e-05 \n",
      "epoch: 40 [246642/888800 27.75%] train loss: 1.417130624759011e-05 \n",
      "epoch: 40 [247753/888800 27.88%] train loss: 1.5056114534672815e-05 \n",
      "epoch: 40 [248864/888800 28.00%] train loss: 1.271935980184935e-05 \n",
      "epoch: 40 [249975/888800 28.12%] train loss: 1.424584934284212e-05 \n",
      "epoch: 40 [251086/888800 28.25%] train loss: 1.3330954971024767e-05 \n",
      "epoch: 40 [252197/888800 28.38%] train loss: 1.4417286365642212e-05 \n",
      "epoch: 40 [253308/888800 28.50%] train loss: 1.487297413405031e-05 \n",
      "epoch: 40 [254419/888800 28.62%] train loss: 1.3981264601170551e-05 \n",
      "epoch: 40 [255530/888800 28.75%] train loss: 1.3354431757761631e-05 \n",
      "epoch: 40 [256641/888800 28.88%] train loss: 1.4314280633698218e-05 \n",
      "epoch: 40 [257752/888800 29.00%] train loss: 1.4216281670087483e-05 \n",
      "epoch: 40 [258863/888800 29.12%] train loss: 1.3639372809848282e-05 \n",
      "epoch: 40 [259974/888800 29.25%] train loss: 1.449007868359331e-05 \n",
      "epoch: 40 [261085/888800 29.38%] train loss: 1.3006405424675904e-05 \n",
      "epoch: 40 [262196/888800 29.50%] train loss: 1.3839759049005806e-05 \n",
      "epoch: 40 [263307/888800 29.62%] train loss: 1.4632192687713541e-05 \n",
      "epoch: 40 [264418/888800 29.75%] train loss: 1.4528361134580337e-05 \n",
      "epoch: 40 [265529/888800 29.88%] train loss: 1.3810760719934478e-05 \n",
      "epoch: 40 [266640/888800 30.00%] train loss: 1.3078951269562822e-05 \n",
      "epoch: 40 [267751/888800 30.12%] train loss: 1.3961453078081831e-05 \n",
      "epoch: 40 [268862/888800 30.25%] train loss: 1.5029293535917532e-05 \n",
      "epoch: 40 [269973/888800 30.38%] train loss: 1.5007170077296905e-05 \n",
      "epoch: 40 [271084/888800 30.50%] train loss: 1.4453330550168175e-05 \n",
      "epoch: 40 [272195/888800 30.62%] train loss: 1.3634663446282502e-05 \n",
      "epoch: 40 [273306/888800 30.75%] train loss: 1.4064993592910469e-05 \n",
      "epoch: 40 [274417/888800 30.88%] train loss: 1.3004157153773122e-05 \n",
      "epoch: 40 [275528/888800 31.00%] train loss: 1.5882116713328287e-05 \n",
      "epoch: 40 [276639/888800 31.12%] train loss: 1.540218545414973e-05 \n",
      "epoch: 40 [277750/888800 31.25%] train loss: 1.738075661705807e-05 \n",
      "epoch: 40 [278861/888800 31.38%] train loss: 1.399852135364199e-05 \n",
      "epoch: 40 [279972/888800 31.50%] train loss: 1.5795267245266587e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [281083/888800 31.62%] train loss: 1.461384272261057e-05 \n",
      "epoch: 40 [282194/888800 31.75%] train loss: 1.458024689782178e-05 \n",
      "epoch: 40 [283305/888800 31.88%] train loss: 1.6269637853838503e-05 \n",
      "epoch: 40 [284416/888800 32.00%] train loss: 1.3809567462885752e-05 \n",
      "epoch: 40 [285527/888800 32.12%] train loss: 1.3940318240202032e-05 \n",
      "epoch: 40 [286638/888800 32.25%] train loss: 1.4692522199766245e-05 \n",
      "epoch: 40 [287749/888800 32.38%] train loss: 1.5485144103877246e-05 \n",
      "epoch: 40 [288860/888800 32.50%] train loss: 1.509539652033709e-05 \n",
      "epoch: 40 [289971/888800 32.62%] train loss: 1.4021524293639231e-05 \n",
      "epoch: 40 [291082/888800 32.75%] train loss: 1.3998270333104301e-05 \n",
      "epoch: 40 [292193/888800 32.88%] train loss: 1.4829750398348551e-05 \n",
      "epoch: 40 [293304/888800 33.00%] train loss: 1.3215500075602904e-05 \n",
      "epoch: 40 [294415/888800 33.12%] train loss: 1.3288909030961804e-05 \n",
      "epoch: 40 [295526/888800 33.25%] train loss: 1.3318361197889317e-05 \n",
      "epoch: 40 [296637/888800 33.38%] train loss: 1.4886682947690133e-05 \n",
      "epoch: 40 [297748/888800 33.50%] train loss: 1.4174832358548883e-05 \n",
      "epoch: 40 [298859/888800 33.62%] train loss: 1.585355494171381e-05 \n",
      "epoch: 40 [299970/888800 33.75%] train loss: 1.4655698578280862e-05 \n",
      "epoch: 40 [301081/888800 33.88%] train loss: 1.5105864804354496e-05 \n",
      "epoch: 40 [302192/888800 34.00%] train loss: 1.5572999473079108e-05 \n",
      "epoch: 40 [303303/888800 34.12%] train loss: 1.5178814464889001e-05 \n",
      "epoch: 40 [304414/888800 34.25%] train loss: 1.3495291568688117e-05 \n",
      "epoch: 40 [305525/888800 34.38%] train loss: 1.4525924598274287e-05 \n",
      "epoch: 40 [306636/888800 34.50%] train loss: 1.310378411290003e-05 \n",
      "epoch: 40 [307747/888800 34.62%] train loss: 1.5041634469525889e-05 \n",
      "epoch: 40 [308858/888800 34.75%] train loss: 1.2836714631703217e-05 \n",
      "epoch: 40 [309969/888800 34.88%] train loss: 1.7236958228750154e-05 \n",
      "epoch: 40 [311080/888800 35.00%] train loss: 1.4043642295291647e-05 \n",
      "epoch: 40 [312191/888800 35.12%] train loss: 1.4881929928378668e-05 \n",
      "epoch: 40 [313302/888800 35.25%] train loss: 1.4245272723201197e-05 \n",
      "epoch: 40 [314413/888800 35.38%] train loss: 1.4908456250850577e-05 \n",
      "epoch: 40 [315524/888800 35.50%] train loss: 1.5012428775662556e-05 \n",
      "epoch: 40 [316635/888800 35.62%] train loss: 1.3737591871176846e-05 \n",
      "epoch: 40 [317746/888800 35.75%] train loss: 1.43117576953955e-05 \n",
      "epoch: 40 [318857/888800 35.88%] train loss: 1.3123006283422e-05 \n",
      "epoch: 40 [319968/888800 36.00%] train loss: 1.661963324295357e-05 \n",
      "epoch: 40 [321079/888800 36.12%] train loss: 1.4309028301795479e-05 \n",
      "epoch: 40 [322190/888800 36.25%] train loss: 1.445085035811644e-05 \n",
      "epoch: 40 [323301/888800 36.38%] train loss: 1.4040944734006189e-05 \n",
      "epoch: 40 [324412/888800 36.50%] train loss: 1.423228059138637e-05 \n",
      "epoch: 40 [325523/888800 36.62%] train loss: 1.3788094292976893e-05 \n",
      "epoch: 40 [326634/888800 36.75%] train loss: 1.294690628128592e-05 \n",
      "epoch: 40 [327745/888800 36.88%] train loss: 1.471485029469477e-05 \n",
      "epoch: 40 [328856/888800 37.00%] train loss: 1.4961852684791666e-05 \n",
      "epoch: 40 [329967/888800 37.12%] train loss: 1.4734546311956365e-05 \n",
      "epoch: 40 [331078/888800 37.25%] train loss: 1.4175048818287905e-05 \n",
      "epoch: 40 [332189/888800 37.38%] train loss: 1.3976459740661085e-05 \n",
      "epoch: 40 [333300/888800 37.50%] train loss: 1.3283991393109318e-05 \n",
      "epoch: 40 [334411/888800 37.62%] train loss: 1.4225905033526942e-05 \n",
      "epoch: 40 [335522/888800 37.75%] train loss: 1.347120814898517e-05 \n",
      "epoch: 40 [336633/888800 37.88%] train loss: 1.279127536690794e-05 \n",
      "epoch: 40 [337744/888800 38.00%] train loss: 1.441188305761898e-05 \n",
      "epoch: 40 [338855/888800 38.12%] train loss: 1.5095666640263516e-05 \n",
      "epoch: 40 [339966/888800 38.25%] train loss: 1.5407866158057004e-05 \n",
      "epoch: 40 [341077/888800 38.38%] train loss: 1.3872198906028643e-05 \n",
      "epoch: 40 [342188/888800 38.50%] train loss: 1.4302094314189162e-05 \n",
      "epoch: 40 [343299/888800 38.62%] train loss: 1.4084151189308614e-05 \n",
      "epoch: 40 [344410/888800 38.75%] train loss: 1.4032524632057175e-05 \n",
      "epoch: 40 [345521/888800 38.88%] train loss: 1.4251098036766052e-05 \n",
      "epoch: 40 [346632/888800 39.00%] train loss: 1.3958266208646819e-05 \n",
      "epoch: 40 [347743/888800 39.12%] train loss: 1.4095821825321764e-05 \n",
      "epoch: 40 [348854/888800 39.25%] train loss: 1.344944212178234e-05 \n",
      "epoch: 40 [349965/888800 39.38%] train loss: 1.3356660019780975e-05 \n",
      "epoch: 40 [351076/888800 39.50%] train loss: 1.4156335055304226e-05 \n",
      "epoch: 40 [352187/888800 39.62%] train loss: 1.3945235878054518e-05 \n",
      "epoch: 40 [353298/888800 39.75%] train loss: 1.4970691154303495e-05 \n",
      "epoch: 40 [354409/888800 39.88%] train loss: 1.3982020391267724e-05 \n",
      "epoch: 40 [355520/888800 40.00%] train loss: 1.2791907465725671e-05 \n",
      "epoch: 40 [356631/888800 40.12%] train loss: 1.3716125977225602e-05 \n",
      "epoch: 40 [357742/888800 40.25%] train loss: 1.4236017705115955e-05 \n",
      "epoch: 40 [358853/888800 40.38%] train loss: 1.4120225387159735e-05 \n",
      "epoch: 40 [359964/888800 40.50%] train loss: 1.3686039892490953e-05 \n",
      "epoch: 40 [361075/888800 40.62%] train loss: 1.3889109141018707e-05 \n",
      "epoch: 40 [362186/888800 40.75%] train loss: 1.3013659554417245e-05 \n",
      "epoch: 40 [363297/888800 40.88%] train loss: 1.4120416381047107e-05 \n",
      "epoch: 40 [364408/888800 41.00%] train loss: 1.448080911359284e-05 \n",
      "epoch: 40 [365519/888800 41.12%] train loss: 1.3349169421417173e-05 \n",
      "epoch: 40 [366630/888800 41.25%] train loss: 1.4967512470320798e-05 \n",
      "epoch: 40 [367741/888800 41.38%] train loss: 1.3978507013234776e-05 \n",
      "epoch: 40 [368852/888800 41.50%] train loss: 1.5156863810261711e-05 \n",
      "epoch: 40 [369963/888800 41.62%] train loss: 1.363334376947023e-05 \n",
      "epoch: 40 [371074/888800 41.75%] train loss: 1.3192006008466706e-05 \n",
      "epoch: 40 [372185/888800 41.88%] train loss: 1.39035719257663e-05 \n",
      "epoch: 40 [373296/888800 42.00%] train loss: 1.462124964746181e-05 \n",
      "epoch: 40 [374407/888800 42.12%] train loss: 1.3683757970284205e-05 \n",
      "epoch: 40 [375518/888800 42.25%] train loss: 1.3433585991151631e-05 \n",
      "epoch: 40 [376629/888800 42.38%] train loss: 1.3154100997780915e-05 \n",
      "epoch: 40 [377740/888800 42.50%] train loss: 1.5710960724391043e-05 \n",
      "epoch: 40 [378851/888800 42.62%] train loss: 1.4290823855844792e-05 \n",
      "epoch: 40 [379962/888800 42.75%] train loss: 1.5175476619333494e-05 \n",
      "epoch: 40 [381073/888800 42.88%] train loss: 1.588750455994159e-05 \n",
      "epoch: 40 [382184/888800 43.00%] train loss: 1.5255381185852457e-05 \n",
      "epoch: 40 [383295/888800 43.12%] train loss: 1.5111621905816719e-05 \n",
      "epoch: 40 [384406/888800 43.25%] train loss: 1.4167600966175087e-05 \n",
      "epoch: 40 [385517/888800 43.38%] train loss: 1.4460031707130838e-05 \n",
      "epoch: 40 [386628/888800 43.50%] train loss: 1.232383419846883e-05 \n",
      "epoch: 40 [387739/888800 43.62%] train loss: 1.3798687177768443e-05 \n",
      "epoch: 40 [388850/888800 43.75%] train loss: 1.5499732398893684e-05 \n",
      "epoch: 40 [389961/888800 43.88%] train loss: 1.3698669135919772e-05 \n",
      "epoch: 40 [391072/888800 44.00%] train loss: 1.3620763638755307e-05 \n",
      "epoch: 40 [392183/888800 44.12%] train loss: 1.3176043466955889e-05 \n",
      "epoch: 40 [393294/888800 44.25%] train loss: 1.5109417290659621e-05 \n",
      "epoch: 40 [394405/888800 44.38%] train loss: 1.4191373338690028e-05 \n",
      "epoch: 40 [395516/888800 44.50%] train loss: 1.346012231806526e-05 \n",
      "epoch: 40 [396627/888800 44.62%] train loss: 1.4059320164960809e-05 \n",
      "epoch: 40 [397738/888800 44.75%] train loss: 1.340049220743822e-05 \n",
      "epoch: 40 [398849/888800 44.88%] train loss: 1.3078017218504101e-05 \n",
      "epoch: 40 [399960/888800 45.00%] train loss: 1.5122767763386946e-05 \n",
      "epoch: 40 [401071/888800 45.12%] train loss: 1.2704696018772665e-05 \n",
      "epoch: 40 [402182/888800 45.25%] train loss: 1.540997800475452e-05 \n",
      "epoch: 40 [403293/888800 45.38%] train loss: 1.5264628018485382e-05 \n",
      "epoch: 40 [404404/888800 45.50%] train loss: 1.5074996554176323e-05 \n",
      "epoch: 40 [405515/888800 45.62%] train loss: 1.4016522982274182e-05 \n",
      "epoch: 40 [406626/888800 45.75%] train loss: 1.4901775102771353e-05 \n",
      "epoch: 40 [407737/888800 45.88%] train loss: 1.4251389984565321e-05 \n",
      "epoch: 40 [408848/888800 46.00%] train loss: 1.4952340279705822e-05 \n",
      "epoch: 40 [409959/888800 46.12%] train loss: 1.3539895007852465e-05 \n",
      "epoch: 40 [411070/888800 46.25%] train loss: 1.4634802028012928e-05 \n",
      "epoch: 40 [412181/888800 46.38%] train loss: 1.2673896890191827e-05 \n",
      "epoch: 40 [413292/888800 46.50%] train loss: 1.485510711063398e-05 \n",
      "epoch: 40 [414403/888800 46.62%] train loss: 1.3052966096438468e-05 \n",
      "epoch: 40 [415514/888800 46.75%] train loss: 1.3148194739187602e-05 \n",
      "epoch: 40 [416625/888800 46.88%] train loss: 1.3514237252820749e-05 \n",
      "epoch: 40 [417736/888800 47.00%] train loss: 1.4674931662739255e-05 \n",
      "epoch: 40 [418847/888800 47.12%] train loss: 1.3595824384537991e-05 \n",
      "epoch: 40 [419958/888800 47.25%] train loss: 1.3019460311625153e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [421069/888800 47.38%] train loss: 1.3771043995802756e-05 \n",
      "epoch: 40 [422180/888800 47.50%] train loss: 1.3674452929990366e-05 \n",
      "epoch: 40 [423291/888800 47.62%] train loss: 1.3603224942926317e-05 \n",
      "epoch: 40 [424402/888800 47.75%] train loss: 1.2952430552104488e-05 \n",
      "epoch: 40 [425513/888800 47.88%] train loss: 1.388978216709802e-05 \n",
      "epoch: 40 [426624/888800 48.00%] train loss: 1.477540354244411e-05 \n",
      "epoch: 40 [427735/888800 48.12%] train loss: 1.4438330254051834e-05 \n",
      "epoch: 40 [428846/888800 48.25%] train loss: 1.2397192222124431e-05 \n",
      "epoch: 40 [429957/888800 48.38%] train loss: 1.4780061064811889e-05 \n",
      "epoch: 40 [431068/888800 48.50%] train loss: 1.3830049283569679e-05 \n",
      "epoch: 40 [432179/888800 48.62%] train loss: 1.331017574557336e-05 \n",
      "epoch: 40 [433290/888800 48.75%] train loss: 1.6112468074425124e-05 \n",
      "epoch: 40 [434401/888800 48.88%] train loss: 1.5187308235908858e-05 \n",
      "epoch: 40 [435512/888800 49.00%] train loss: 1.5836483726161532e-05 \n",
      "epoch: 40 [436623/888800 49.12%] train loss: 1.4277576156018768e-05 \n",
      "epoch: 40 [437734/888800 49.25%] train loss: 1.5107417311810423e-05 \n",
      "epoch: 40 [438845/888800 49.38%] train loss: 1.4293820640887134e-05 \n",
      "epoch: 40 [439956/888800 49.50%] train loss: 1.4083274436416104e-05 \n",
      "epoch: 40 [441067/888800 49.62%] train loss: 1.553937363496516e-05 \n",
      "epoch: 40 [442178/888800 49.75%] train loss: 1.4835796719125938e-05 \n",
      "epoch: 40 [443289/888800 49.88%] train loss: 1.343535041087307e-05 \n",
      "epoch: 40 [444400/888800 50.00%] train loss: 1.3305706488608848e-05 \n",
      "epoch: 40 [445511/888800 50.12%] train loss: 1.3514615602616686e-05 \n",
      "epoch: 40 [446622/888800 50.25%] train loss: 1.39587691592169e-05 \n",
      "epoch: 40 [447733/888800 50.38%] train loss: 1.4508796994050499e-05 \n",
      "epoch: 40 [448844/888800 50.50%] train loss: 1.3726996257901192e-05 \n",
      "epoch: 40 [449955/888800 50.62%] train loss: 1.4553146684193052e-05 \n",
      "epoch: 40 [451066/888800 50.75%] train loss: 1.4882834875606932e-05 \n",
      "epoch: 40 [452177/888800 50.88%] train loss: 1.5139583410928026e-05 \n",
      "epoch: 40 [453288/888800 51.00%] train loss: 1.2999797945667524e-05 \n",
      "epoch: 40 [454399/888800 51.12%] train loss: 1.440179312339751e-05 \n",
      "epoch: 40 [455510/888800 51.25%] train loss: 1.4507189916912466e-05 \n",
      "epoch: 40 [456621/888800 51.38%] train loss: 1.3597103134088684e-05 \n",
      "epoch: 40 [457732/888800 51.50%] train loss: 1.4283977179729845e-05 \n",
      "epoch: 40 [458843/888800 51.62%] train loss: 1.5164413525781129e-05 \n",
      "epoch: 40 [459954/888800 51.75%] train loss: 1.4674196791020222e-05 \n",
      "epoch: 40 [461065/888800 51.88%] train loss: 1.435969716112595e-05 \n",
      "epoch: 40 [462176/888800 52.00%] train loss: 1.3974527973914519e-05 \n",
      "epoch: 40 [463287/888800 52.12%] train loss: 1.4642414498666767e-05 \n",
      "epoch: 40 [464398/888800 52.25%] train loss: 1.398702534061158e-05 \n",
      "epoch: 40 [465509/888800 52.38%] train loss: 1.3283006410347298e-05 \n",
      "epoch: 40 [466620/888800 52.50%] train loss: 1.4994786397437565e-05 \n",
      "epoch: 40 [467731/888800 52.62%] train loss: 1.6095018509076908e-05 \n",
      "epoch: 40 [468842/888800 52.75%] train loss: 1.4000713235873263e-05 \n",
      "epoch: 40 [469953/888800 52.88%] train loss: 1.4633881619374733e-05 \n",
      "epoch: 40 [471064/888800 53.00%] train loss: 1.3507100447895937e-05 \n",
      "epoch: 40 [472175/888800 53.12%] train loss: 1.5296020137611777e-05 \n",
      "epoch: 40 [473286/888800 53.25%] train loss: 1.2975538083992433e-05 \n",
      "epoch: 40 [474397/888800 53.38%] train loss: 1.4412875316338614e-05 \n",
      "epoch: 40 [475508/888800 53.50%] train loss: 1.470193274144549e-05 \n",
      "epoch: 40 [476619/888800 53.62%] train loss: 1.4950794138712808e-05 \n",
      "epoch: 40 [477730/888800 53.75%] train loss: 1.4849017134110909e-05 \n",
      "epoch: 40 [478841/888800 53.88%] train loss: 1.4072339581616689e-05 \n",
      "epoch: 40 [479952/888800 54.00%] train loss: 1.3972867236589082e-05 \n",
      "epoch: 40 [481063/888800 54.12%] train loss: 1.4348084732773714e-05 \n",
      "epoch: 40 [482174/888800 54.25%] train loss: 1.6553418390685692e-05 \n",
      "epoch: 40 [483285/888800 54.38%] train loss: 1.620795410417486e-05 \n",
      "epoch: 40 [484396/888800 54.50%] train loss: 1.4904630006640218e-05 \n",
      "epoch: 40 [485507/888800 54.62%] train loss: 1.6160094673978165e-05 \n",
      "epoch: 40 [486618/888800 54.75%] train loss: 1.3863659660273697e-05 \n",
      "epoch: 40 [487729/888800 54.88%] train loss: 1.665467061684467e-05 \n",
      "epoch: 40 [488840/888800 55.00%] train loss: 1.4232778994482942e-05 \n",
      "epoch: 40 [489951/888800 55.12%] train loss: 1.5836963939364068e-05 \n",
      "epoch: 40 [491062/888800 55.25%] train loss: 1.5253031961037777e-05 \n",
      "epoch: 40 [492173/888800 55.38%] train loss: 1.563713522045873e-05 \n",
      "epoch: 40 [493284/888800 55.50%] train loss: 1.591703221492935e-05 \n",
      "epoch: 40 [494395/888800 55.62%] train loss: 1.3817644685332198e-05 \n",
      "epoch: 40 [495506/888800 55.75%] train loss: 1.4199210454535205e-05 \n",
      "epoch: 40 [496617/888800 55.88%] train loss: 1.459223040001234e-05 \n",
      "epoch: 40 [497728/888800 56.00%] train loss: 1.5737748981337063e-05 \n",
      "epoch: 40 [498839/888800 56.12%] train loss: 1.4071250006963965e-05 \n",
      "epoch: 40 [499950/888800 56.25%] train loss: 1.5030552276584785e-05 \n",
      "epoch: 40 [501061/888800 56.38%] train loss: 1.4232252397050615e-05 \n",
      "epoch: 40 [502172/888800 56.50%] train loss: 1.4747563000128139e-05 \n",
      "epoch: 40 [503283/888800 56.62%] train loss: 1.4498193195322528e-05 \n",
      "epoch: 40 [504394/888800 56.75%] train loss: 1.4765541891392786e-05 \n",
      "epoch: 40 [505505/888800 56.88%] train loss: 1.491892271587858e-05 \n",
      "epoch: 40 [506616/888800 57.00%] train loss: 1.3827352631778922e-05 \n",
      "epoch: 40 [507727/888800 57.12%] train loss: 1.4479485798801761e-05 \n",
      "epoch: 40 [508838/888800 57.25%] train loss: 1.432349017704837e-05 \n",
      "epoch: 40 [509949/888800 57.38%] train loss: 1.4412944437935948e-05 \n",
      "epoch: 40 [511060/888800 57.50%] train loss: 1.2723618965537753e-05 \n",
      "epoch: 40 [512171/888800 57.62%] train loss: 1.4301705050456803e-05 \n",
      "epoch: 40 [513282/888800 57.75%] train loss: 1.5548641385976225e-05 \n",
      "epoch: 40 [514393/888800 57.88%] train loss: 1.315054851147579e-05 \n",
      "epoch: 40 [515504/888800 58.00%] train loss: 1.3081255019642413e-05 \n",
      "epoch: 40 [516615/888800 58.12%] train loss: 1.335077831754461e-05 \n",
      "epoch: 40 [517726/888800 58.25%] train loss: 1.432302360626636e-05 \n",
      "epoch: 40 [518837/888800 58.38%] train loss: 1.5580528270220384e-05 \n",
      "epoch: 40 [519948/888800 58.50%] train loss: 1.4602497685700655e-05 \n",
      "epoch: 40 [521059/888800 58.62%] train loss: 1.4423472748603672e-05 \n",
      "epoch: 40 [522170/888800 58.75%] train loss: 1.4273117812990677e-05 \n",
      "epoch: 40 [523281/888800 58.88%] train loss: 1.3522641893359832e-05 \n",
      "epoch: 40 [524392/888800 59.00%] train loss: 1.4743563042429741e-05 \n",
      "epoch: 40 [525503/888800 59.12%] train loss: 1.4195777112036012e-05 \n",
      "epoch: 40 [526614/888800 59.25%] train loss: 1.5345764040830545e-05 \n",
      "epoch: 40 [527725/888800 59.38%] train loss: 1.3527022019843571e-05 \n",
      "epoch: 40 [528836/888800 59.50%] train loss: 1.5138158232730348e-05 \n",
      "epoch: 40 [529947/888800 59.62%] train loss: 1.5086371604411397e-05 \n",
      "epoch: 40 [531058/888800 59.75%] train loss: 1.576011345605366e-05 \n",
      "epoch: 40 [532169/888800 59.88%] train loss: 1.3993199900141917e-05 \n",
      "epoch: 40 [533280/888800 60.00%] train loss: 1.556413553771563e-05 \n",
      "epoch: 40 [534391/888800 60.12%] train loss: 1.3881870472687297e-05 \n",
      "epoch: 40 [535502/888800 60.25%] train loss: 1.3932054571341723e-05 \n",
      "epoch: 40 [536613/888800 60.38%] train loss: 1.4940918845240958e-05 \n",
      "epoch: 40 [537724/888800 60.50%] train loss: 1.472421718062833e-05 \n",
      "epoch: 40 [538835/888800 60.62%] train loss: 1.3602950275526382e-05 \n",
      "epoch: 40 [539946/888800 60.75%] train loss: 1.3191465768613853e-05 \n",
      "epoch: 40 [541057/888800 60.88%] train loss: 1.4735255717823748e-05 \n",
      "epoch: 40 [542168/888800 61.00%] train loss: 1.3573160686064512e-05 \n",
      "epoch: 40 [543279/888800 61.12%] train loss: 1.4173415365803521e-05 \n",
      "epoch: 40 [544390/888800 61.25%] train loss: 1.3714790839003399e-05 \n",
      "epoch: 40 [545501/888800 61.38%] train loss: 1.3523521374736447e-05 \n",
      "epoch: 40 [546612/888800 61.50%] train loss: 1.324861113971565e-05 \n",
      "epoch: 40 [547723/888800 61.62%] train loss: 1.3193359336582944e-05 \n",
      "epoch: 40 [548834/888800 61.75%] train loss: 1.510179390606936e-05 \n",
      "epoch: 40 [549945/888800 61.88%] train loss: 1.4504222235700581e-05 \n",
      "epoch: 40 [551056/888800 62.00%] train loss: 1.3580574886873364e-05 \n",
      "epoch: 40 [552167/888800 62.12%] train loss: 1.3620003301184624e-05 \n",
      "epoch: 40 [553278/888800 62.25%] train loss: 1.4893972547724843e-05 \n",
      "epoch: 40 [554389/888800 62.38%] train loss: 1.5040574908198323e-05 \n",
      "epoch: 40 [555500/888800 62.50%] train loss: 1.4168167581374291e-05 \n",
      "epoch: 40 [556611/888800 62.62%] train loss: 1.3994567780173384e-05 \n",
      "epoch: 40 [557722/888800 62.75%] train loss: 1.4865042430756148e-05 \n",
      "epoch: 40 [558833/888800 62.88%] train loss: 1.3650713299284689e-05 \n",
      "epoch: 40 [559944/888800 63.00%] train loss: 1.4065785762795713e-05 \n",
      "epoch: 40 [561055/888800 63.12%] train loss: 1.4179877325659618e-05 \n",
      "epoch: 40 [562166/888800 63.25%] train loss: 1.4389103853318375e-05 \n",
      "epoch: 40 [563277/888800 63.38%] train loss: 1.5179247384367045e-05 \n",
      "epoch: 40 [564388/888800 63.50%] train loss: 1.4325897609523963e-05 \n",
      "epoch: 40 [565499/888800 63.62%] train loss: 1.5026844266685657e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [566610/888800 63.75%] train loss: 1.4061542970011942e-05 \n",
      "epoch: 40 [567721/888800 63.88%] train loss: 1.582737786520738e-05 \n",
      "epoch: 40 [568832/888800 64.00%] train loss: 1.448303009965457e-05 \n",
      "epoch: 40 [569943/888800 64.12%] train loss: 1.3082324585411698e-05 \n",
      "epoch: 40 [571054/888800 64.25%] train loss: 1.470810911996523e-05 \n",
      "epoch: 40 [572165/888800 64.38%] train loss: 1.531564339529723e-05 \n",
      "epoch: 40 [573276/888800 64.50%] train loss: 1.45974936458515e-05 \n",
      "epoch: 40 [574387/888800 64.62%] train loss: 1.4882429240969941e-05 \n",
      "epoch: 40 [575498/888800 64.75%] train loss: 1.3730125829169992e-05 \n",
      "epoch: 40 [576609/888800 64.88%] train loss: 1.5420009731315076e-05 \n",
      "epoch: 40 [577720/888800 65.00%] train loss: 1.5089691260072868e-05 \n",
      "epoch: 40 [578831/888800 65.12%] train loss: 1.4493760318146087e-05 \n",
      "epoch: 40 [579942/888800 65.25%] train loss: 1.3519223102775868e-05 \n",
      "epoch: 40 [581053/888800 65.38%] train loss: 1.3592999493994284e-05 \n",
      "epoch: 40 [582164/888800 65.50%] train loss: 1.493354284320958e-05 \n",
      "epoch: 40 [583275/888800 65.62%] train loss: 1.4259697309171315e-05 \n",
      "epoch: 40 [584386/888800 65.75%] train loss: 1.413664358551614e-05 \n",
      "epoch: 40 [585497/888800 65.88%] train loss: 1.3197339285397902e-05 \n",
      "epoch: 40 [586608/888800 66.00%] train loss: 1.535781666461844e-05 \n",
      "epoch: 40 [587719/888800 66.12%] train loss: 1.549309672554955e-05 \n",
      "epoch: 40 [588830/888800 66.25%] train loss: 1.5450013961526565e-05 \n",
      "epoch: 40 [589941/888800 66.38%] train loss: 1.6205342035391368e-05 \n",
      "epoch: 40 [591052/888800 66.50%] train loss: 1.3962880075268913e-05 \n",
      "epoch: 40 [592163/888800 66.62%] train loss: 1.49105198943289e-05 \n",
      "epoch: 40 [593274/888800 66.75%] train loss: 1.4579334674635902e-05 \n",
      "epoch: 40 [594385/888800 66.88%] train loss: 1.505163891124539e-05 \n",
      "epoch: 40 [595496/888800 67.00%] train loss: 1.3714246961171739e-05 \n",
      "epoch: 40 [596607/888800 67.12%] train loss: 1.6433363271062262e-05 \n",
      "epoch: 40 [597718/888800 67.25%] train loss: 1.4264269339037128e-05 \n",
      "epoch: 40 [598829/888800 67.38%] train loss: 1.478706872148905e-05 \n",
      "epoch: 40 [599940/888800 67.50%] train loss: 1.502882059867261e-05 \n",
      "epoch: 40 [601051/888800 67.62%] train loss: 1.5952025933074765e-05 \n",
      "epoch: 40 [602162/888800 67.75%] train loss: 1.4720402759849094e-05 \n",
      "epoch: 40 [603273/888800 67.88%] train loss: 1.3472451428242493e-05 \n",
      "epoch: 40 [604384/888800 68.00%] train loss: 1.3150198356015608e-05 \n",
      "epoch: 40 [605495/888800 68.12%] train loss: 1.366007109027123e-05 \n",
      "epoch: 40 [606606/888800 68.25%] train loss: 1.3278892765811179e-05 \n",
      "epoch: 40 [607717/888800 68.38%] train loss: 1.4981305866967887e-05 \n",
      "epoch: 40 [608828/888800 68.50%] train loss: 1.5394070942420512e-05 \n",
      "epoch: 40 [609939/888800 68.62%] train loss: 1.4351692698255647e-05 \n",
      "epoch: 40 [611050/888800 68.75%] train loss: 1.4394535355677363e-05 \n",
      "epoch: 40 [612161/888800 68.88%] train loss: 1.3937578842160292e-05 \n",
      "epoch: 40 [613272/888800 69.00%] train loss: 1.397759115207009e-05 \n",
      "epoch: 40 [614383/888800 69.12%] train loss: 1.448940111004049e-05 \n",
      "epoch: 40 [615494/888800 69.25%] train loss: 1.493159925303189e-05 \n",
      "epoch: 40 [616605/888800 69.38%] train loss: 1.345668533758726e-05 \n",
      "epoch: 40 [617716/888800 69.50%] train loss: 1.3508180927601643e-05 \n",
      "epoch: 40 [618827/888800 69.62%] train loss: 1.4158313206280582e-05 \n",
      "epoch: 40 [619938/888800 69.75%] train loss: 1.4520153854391538e-05 \n",
      "epoch: 40 [621049/888800 69.88%] train loss: 1.3142881471139845e-05 \n",
      "epoch: 40 [622160/888800 70.00%] train loss: 1.4557422218786087e-05 \n",
      "epoch: 40 [623271/888800 70.12%] train loss: 1.3999524526298046e-05 \n",
      "epoch: 40 [624382/888800 70.25%] train loss: 1.4242851648305077e-05 \n",
      "epoch: 40 [625493/888800 70.38%] train loss: 1.4072527847019956e-05 \n",
      "epoch: 40 [626604/888800 70.50%] train loss: 1.3653876521857455e-05 \n",
      "epoch: 40 [627715/888800 70.62%] train loss: 1.4400286090676673e-05 \n",
      "epoch: 40 [628826/888800 70.75%] train loss: 1.5548303053947166e-05 \n",
      "epoch: 40 [629937/888800 70.88%] train loss: 1.4930853467376437e-05 \n",
      "epoch: 40 [631048/888800 71.00%] train loss: 1.5554542187601328e-05 \n",
      "epoch: 40 [632159/888800 71.12%] train loss: 1.4822915545664728e-05 \n",
      "epoch: 40 [633270/888800 71.25%] train loss: 1.4478255252470262e-05 \n",
      "epoch: 40 [634381/888800 71.38%] train loss: 1.3343280443223193e-05 \n",
      "epoch: 40 [635492/888800 71.50%] train loss: 1.3745310752710793e-05 \n",
      "epoch: 40 [636603/888800 71.62%] train loss: 1.4823207493463997e-05 \n",
      "epoch: 40 [637714/888800 71.75%] train loss: 1.317775240750052e-05 \n",
      "epoch: 40 [638825/888800 71.88%] train loss: 1.3724233212997206e-05 \n",
      "epoch: 40 [639936/888800 72.00%] train loss: 1.4443056898016948e-05 \n",
      "epoch: 40 [641047/888800 72.12%] train loss: 1.3795865015708841e-05 \n",
      "epoch: 40 [642158/888800 72.25%] train loss: 1.4105518857832067e-05 \n",
      "epoch: 40 [643269/888800 72.38%] train loss: 1.590226929693017e-05 \n",
      "epoch: 40 [644380/888800 72.50%] train loss: 1.3851949006493669e-05 \n",
      "epoch: 40 [645491/888800 72.62%] train loss: 1.4949181604606565e-05 \n",
      "epoch: 40 [646602/888800 72.75%] train loss: 1.388067721563857e-05 \n",
      "epoch: 40 [647713/888800 72.88%] train loss: 1.4410090443561785e-05 \n",
      "epoch: 40 [648824/888800 73.00%] train loss: 1.4277559785114136e-05 \n",
      "epoch: 40 [649935/888800 73.12%] train loss: 1.4237632058211602e-05 \n",
      "epoch: 40 [651046/888800 73.25%] train loss: 1.4977499631640967e-05 \n",
      "epoch: 40 [652157/888800 73.38%] train loss: 1.391433397657238e-05 \n",
      "epoch: 40 [653268/888800 73.50%] train loss: 1.4875961824145634e-05 \n",
      "epoch: 40 [654379/888800 73.62%] train loss: 1.543050166219473e-05 \n",
      "epoch: 40 [655490/888800 73.75%] train loss: 1.4091227967583109e-05 \n",
      "epoch: 40 [656601/888800 73.88%] train loss: 1.3086046237731352e-05 \n",
      "epoch: 40 [657712/888800 74.00%] train loss: 1.4286018995335326e-05 \n",
      "epoch: 40 [658823/888800 74.12%] train loss: 1.3962559023639187e-05 \n",
      "epoch: 40 [659934/888800 74.25%] train loss: 1.4264653145801276e-05 \n",
      "epoch: 40 [661045/888800 74.38%] train loss: 1.4377230399986729e-05 \n",
      "epoch: 40 [662156/888800 74.50%] train loss: 1.4367640687851235e-05 \n",
      "epoch: 40 [663267/888800 74.62%] train loss: 1.4495493815047666e-05 \n",
      "epoch: 40 [664378/888800 74.75%] train loss: 1.4893110346747562e-05 \n",
      "epoch: 40 [665489/888800 74.88%] train loss: 1.3723576557822526e-05 \n",
      "epoch: 40 [666600/888800 75.00%] train loss: 1.3618302546092309e-05 \n",
      "epoch: 40 [667711/888800 75.12%] train loss: 1.4983280379965436e-05 \n",
      "epoch: 40 [668822/888800 75.25%] train loss: 1.5818082829355262e-05 \n",
      "epoch: 40 [669933/888800 75.38%] train loss: 1.4915420251782052e-05 \n",
      "epoch: 40 [671044/888800 75.50%] train loss: 1.4262584045354743e-05 \n",
      "epoch: 40 [672155/888800 75.62%] train loss: 1.3878490790375508e-05 \n",
      "epoch: 40 [673266/888800 75.75%] train loss: 1.4581946743419394e-05 \n",
      "epoch: 40 [674377/888800 75.88%] train loss: 1.5278301361831836e-05 \n",
      "epoch: 40 [675488/888800 76.00%] train loss: 1.3863029380445369e-05 \n",
      "epoch: 40 [676599/888800 76.12%] train loss: 1.353110474155983e-05 \n",
      "epoch: 40 [677710/888800 76.25%] train loss: 1.5255194739438593e-05 \n",
      "epoch: 40 [678821/888800 76.38%] train loss: 1.3834664969181176e-05 \n",
      "epoch: 40 [679932/888800 76.50%] train loss: 1.4866768651700113e-05 \n",
      "epoch: 40 [681043/888800 76.62%] train loss: 1.4158573321765289e-05 \n",
      "epoch: 40 [682154/888800 76.75%] train loss: 1.4745812222827226e-05 \n",
      "epoch: 40 [683265/888800 76.88%] train loss: 1.4793317859584931e-05 \n",
      "epoch: 40 [684376/888800 77.00%] train loss: 1.386315852869302e-05 \n",
      "epoch: 40 [685487/888800 77.12%] train loss: 1.4541617019858677e-05 \n",
      "epoch: 40 [686598/888800 77.25%] train loss: 1.3797588508168701e-05 \n",
      "epoch: 40 [687709/888800 77.38%] train loss: 1.5243593225022778e-05 \n",
      "epoch: 40 [688820/888800 77.50%] train loss: 1.4071451005293056e-05 \n",
      "epoch: 40 [689931/888800 77.62%] train loss: 1.3641579243994784e-05 \n",
      "epoch: 40 [691042/888800 77.75%] train loss: 1.3959608622826636e-05 \n",
      "epoch: 40 [692153/888800 77.88%] train loss: 1.4542051758326124e-05 \n",
      "epoch: 40 [693264/888800 78.00%] train loss: 1.3966904589324258e-05 \n",
      "epoch: 40 [694375/888800 78.12%] train loss: 1.4857228961773217e-05 \n",
      "epoch: 40 [695486/888800 78.25%] train loss: 1.4412972632271703e-05 \n",
      "epoch: 40 [696597/888800 78.38%] train loss: 1.5176026863628067e-05 \n",
      "epoch: 40 [697708/888800 78.50%] train loss: 1.497624452895252e-05 \n",
      "epoch: 40 [698819/888800 78.62%] train loss: 1.391386740579037e-05 \n",
      "epoch: 40 [699930/888800 78.75%] train loss: 1.4035567801329307e-05 \n",
      "epoch: 40 [701041/888800 78.88%] train loss: 1.4484385246760212e-05 \n",
      "epoch: 40 [702152/888800 79.00%] train loss: 1.4646445379185025e-05 \n",
      "epoch: 40 [703263/888800 79.12%] train loss: 1.430367319699144e-05 \n",
      "epoch: 40 [704374/888800 79.25%] train loss: 1.5009441085567232e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [705485/888800 79.38%] train loss: 1.4281093172030523e-05 \n",
      "epoch: 40 [706596/888800 79.50%] train loss: 1.377307216898771e-05 \n",
      "epoch: 40 [707707/888800 79.62%] train loss: 1.365690513921436e-05 \n",
      "epoch: 40 [708818/888800 79.75%] train loss: 1.4804813872615341e-05 \n",
      "epoch: 40 [709929/888800 79.88%] train loss: 1.5034112038847525e-05 \n",
      "epoch: 40 [711040/888800 80.00%] train loss: 1.3652482266479637e-05 \n",
      "epoch: 40 [712151/888800 80.12%] train loss: 1.4553597793565132e-05 \n",
      "epoch: 40 [713262/888800 80.25%] train loss: 1.4279969946073834e-05 \n",
      "epoch: 40 [714373/888800 80.38%] train loss: 1.4332650607684627e-05 \n",
      "epoch: 40 [715484/888800 80.50%] train loss: 1.3692770153284073e-05 \n",
      "epoch: 40 [716595/888800 80.62%] train loss: 1.3643983947986271e-05 \n",
      "epoch: 40 [717706/888800 80.75%] train loss: 1.4803116755501833e-05 \n",
      "epoch: 40 [718817/888800 80.88%] train loss: 1.479855473007774e-05 \n",
      "epoch: 40 [719928/888800 81.00%] train loss: 1.5692587112425826e-05 \n",
      "epoch: 40 [721039/888800 81.12%] train loss: 1.4350353012559935e-05 \n",
      "epoch: 40 [722150/888800 81.25%] train loss: 1.234667706739856e-05 \n",
      "epoch: 40 [723261/888800 81.38%] train loss: 1.3105644939059857e-05 \n",
      "epoch: 40 [724372/888800 81.50%] train loss: 1.3202055924921297e-05 \n",
      "epoch: 40 [725483/888800 81.62%] train loss: 1.2847413017880172e-05 \n",
      "epoch: 40 [726594/888800 81.75%] train loss: 1.4196917618392035e-05 \n",
      "epoch: 40 [727705/888800 81.88%] train loss: 1.3980763469589874e-05 \n",
      "epoch: 40 [728816/888800 82.00%] train loss: 1.438816798327025e-05 \n",
      "epoch: 40 [729927/888800 82.12%] train loss: 1.5216440260701347e-05 \n",
      "epoch: 40 [731038/888800 82.25%] train loss: 1.4147149158816319e-05 \n",
      "epoch: 40 [732149/888800 82.38%] train loss: 1.485913890064694e-05 \n",
      "epoch: 40 [733260/888800 82.50%] train loss: 1.5463834643014707e-05 \n",
      "epoch: 40 [734371/888800 82.62%] train loss: 1.409179822076112e-05 \n",
      "epoch: 40 [735482/888800 82.75%] train loss: 1.4818013369222172e-05 \n",
      "epoch: 40 [736593/888800 82.88%] train loss: 1.3179905181459617e-05 \n",
      "epoch: 40 [737704/888800 83.00%] train loss: 1.6863774362718686e-05 \n",
      "epoch: 40 [738815/888800 83.12%] train loss: 1.4791360626986716e-05 \n",
      "epoch: 40 [739926/888800 83.25%] train loss: 1.534293915028684e-05 \n",
      "epoch: 40 [741037/888800 83.38%] train loss: 1.4130049748928286e-05 \n",
      "epoch: 40 [742148/888800 83.50%] train loss: 1.610257641004864e-05 \n",
      "epoch: 40 [743259/888800 83.62%] train loss: 1.3772525562671944e-05 \n",
      "epoch: 40 [744370/888800 83.75%] train loss: 1.461318061046768e-05 \n",
      "epoch: 40 [745481/888800 83.88%] train loss: 1.4293015738076065e-05 \n",
      "epoch: 40 [746592/888800 84.00%] train loss: 1.3733739251620136e-05 \n",
      "epoch: 40 [747703/888800 84.12%] train loss: 1.5463623640243895e-05 \n",
      "epoch: 40 [748814/888800 84.25%] train loss: 1.4194325558491983e-05 \n",
      "epoch: 40 [749925/888800 84.38%] train loss: 1.5131210602703504e-05 \n",
      "epoch: 40 [751036/888800 84.50%] train loss: 1.6265697922790423e-05 \n",
      "epoch: 40 [752147/888800 84.62%] train loss: 1.415587576047983e-05 \n",
      "epoch: 40 [753258/888800 84.75%] train loss: 1.5688092389609665e-05 \n",
      "epoch: 40 [754369/888800 84.88%] train loss: 1.3188029697630554e-05 \n",
      "epoch: 40 [755480/888800 85.00%] train loss: 1.3219327229307964e-05 \n",
      "epoch: 40 [756591/888800 85.12%] train loss: 1.3940208191343118e-05 \n",
      "epoch: 40 [757702/888800 85.25%] train loss: 1.4589615602744743e-05 \n",
      "epoch: 40 [758813/888800 85.38%] train loss: 1.3711583960684948e-05 \n",
      "epoch: 40 [759924/888800 85.50%] train loss: 1.4469876077782828e-05 \n",
      "epoch: 40 [761035/888800 85.62%] train loss: 1.4409775758394971e-05 \n",
      "epoch: 40 [762146/888800 85.75%] train loss: 1.5068027096276637e-05 \n",
      "epoch: 40 [763257/888800 85.88%] train loss: 1.4142676263873e-05 \n",
      "epoch: 40 [764368/888800 86.00%] train loss: 1.375625106447842e-05 \n",
      "epoch: 40 [765479/888800 86.12%] train loss: 1.563185105624143e-05 \n",
      "epoch: 40 [766590/888800 86.25%] train loss: 1.3513200428860728e-05 \n",
      "epoch: 40 [767701/888800 86.38%] train loss: 1.287057875742903e-05 \n",
      "epoch: 40 [768812/888800 86.50%] train loss: 1.4423100765270647e-05 \n",
      "epoch: 40 [769923/888800 86.62%] train loss: 1.535730916657485e-05 \n",
      "epoch: 40 [771034/888800 86.75%] train loss: 1.4080917026149109e-05 \n",
      "epoch: 40 [772145/888800 86.88%] train loss: 1.411107132298639e-05 \n",
      "epoch: 40 [773256/888800 87.00%] train loss: 1.4110273696132936e-05 \n",
      "epoch: 40 [774367/888800 87.12%] train loss: 1.5184235053311568e-05 \n",
      "epoch: 40 [775478/888800 87.25%] train loss: 1.3561239029513672e-05 \n",
      "epoch: 40 [776589/888800 87.38%] train loss: 1.5748975783935748e-05 \n",
      "epoch: 40 [777700/888800 87.50%] train loss: 1.5616134987794794e-05 \n",
      "epoch: 40 [778811/888800 87.62%] train loss: 1.4539469702867791e-05 \n",
      "epoch: 40 [779922/888800 87.75%] train loss: 1.4481503058050293e-05 \n",
      "epoch: 40 [781033/888800 87.88%] train loss: 1.3021685845160391e-05 \n",
      "epoch: 40 [782144/888800 88.00%] train loss: 1.5616211385349743e-05 \n",
      "epoch: 40 [783255/888800 88.12%] train loss: 1.3400583156908397e-05 \n",
      "epoch: 40 [784366/888800 88.25%] train loss: 1.5985749996616505e-05 \n",
      "epoch: 40 [785477/888800 88.38%] train loss: 1.4315711268864106e-05 \n",
      "epoch: 40 [786588/888800 88.50%] train loss: 1.48883591464255e-05 \n",
      "epoch: 40 [787699/888800 88.62%] train loss: 1.4183046914695296e-05 \n",
      "epoch: 40 [788810/888800 88.75%] train loss: 1.514760879217647e-05 \n",
      "epoch: 40 [789921/888800 88.88%] train loss: 1.4609093341277912e-05 \n",
      "epoch: 40 [791032/888800 89.00%] train loss: 1.3343629689188674e-05 \n",
      "epoch: 40 [792143/888800 89.12%] train loss: 1.3308455891092308e-05 \n",
      "epoch: 40 [793254/888800 89.25%] train loss: 1.38732539198827e-05 \n",
      "epoch: 40 [794365/888800 89.38%] train loss: 1.4570321582141332e-05 \n",
      "epoch: 40 [795476/888800 89.50%] train loss: 1.4524596736009698e-05 \n",
      "epoch: 40 [796587/888800 89.62%] train loss: 1.3422547453956213e-05 \n",
      "epoch: 40 [797698/888800 89.75%] train loss: 1.3788942851533648e-05 \n",
      "epoch: 40 [798809/888800 89.88%] train loss: 1.442223583580926e-05 \n",
      "epoch: 40 [799920/888800 90.00%] train loss: 1.3931311514170375e-05 \n",
      "epoch: 40 [801031/888800 90.12%] train loss: 1.465361947339261e-05 \n",
      "epoch: 40 [802142/888800 90.25%] train loss: 1.4358112821355462e-05 \n",
      "epoch: 40 [803253/888800 90.38%] train loss: 1.3829214367433451e-05 \n",
      "epoch: 40 [804364/888800 90.50%] train loss: 1.4714826647832524e-05 \n",
      "epoch: 40 [805475/888800 90.62%] train loss: 1.4778257536818273e-05 \n",
      "epoch: 40 [806586/888800 90.75%] train loss: 1.4132850992609747e-05 \n",
      "epoch: 40 [807697/888800 90.88%] train loss: 1.475259068683954e-05 \n",
      "epoch: 40 [808808/888800 91.00%] train loss: 1.4440023733186536e-05 \n",
      "epoch: 40 [809919/888800 91.12%] train loss: 1.4678885236207861e-05 \n",
      "epoch: 40 [811030/888800 91.25%] train loss: 1.342834275419591e-05 \n",
      "epoch: 40 [812141/888800 91.38%] train loss: 1.3852635674993508e-05 \n",
      "epoch: 40 [813252/888800 91.50%] train loss: 1.5106558748811949e-05 \n",
      "epoch: 40 [814363/888800 91.62%] train loss: 1.328805501543684e-05 \n",
      "epoch: 40 [815474/888800 91.75%] train loss: 1.4546862985298503e-05 \n",
      "epoch: 40 [816585/888800 91.88%] train loss: 1.4235243725124747e-05 \n",
      "epoch: 40 [817696/888800 92.00%] train loss: 1.4748872672498692e-05 \n",
      "epoch: 40 [818807/888800 92.12%] train loss: 1.5557719962089323e-05 \n",
      "epoch: 40 [819918/888800 92.25%] train loss: 1.5973340850905515e-05 \n",
      "epoch: 40 [821029/888800 92.38%] train loss: 1.4213713257049676e-05 \n",
      "epoch: 40 [822140/888800 92.50%] train loss: 1.251471258001402e-05 \n",
      "epoch: 40 [823251/888800 92.62%] train loss: 1.3627211956190877e-05 \n",
      "epoch: 40 [824362/888800 92.75%] train loss: 1.3974091416457668e-05 \n",
      "epoch: 40 [825473/888800 92.88%] train loss: 1.4477866898232605e-05 \n",
      "epoch: 40 [826584/888800 93.00%] train loss: 1.3115227375237737e-05 \n",
      "epoch: 40 [827695/888800 93.12%] train loss: 1.46186803249293e-05 \n",
      "epoch: 40 [828806/888800 93.25%] train loss: 1.4644330804003403e-05 \n",
      "epoch: 40 [829917/888800 93.38%] train loss: 1.3752576705883257e-05 \n",
      "epoch: 40 [831028/888800 93.50%] train loss: 1.5427382095367648e-05 \n",
      "epoch: 40 [832139/888800 93.62%] train loss: 1.3910316738474648e-05 \n",
      "epoch: 40 [833250/888800 93.75%] train loss: 1.5932460883050226e-05 \n",
      "epoch: 40 [834361/888800 93.88%] train loss: 1.3907969332649373e-05 \n",
      "epoch: 40 [835472/888800 94.00%] train loss: 1.3693277651327662e-05 \n",
      "epoch: 40 [836583/888800 94.12%] train loss: 1.4904001545801293e-05 \n",
      "epoch: 40 [837694/888800 94.25%] train loss: 1.3222422239778098e-05 \n",
      "epoch: 40 [838805/888800 94.38%] train loss: 1.3431859770207666e-05 \n",
      "epoch: 40 [839916/888800 94.50%] train loss: 1.3615814168588258e-05 \n",
      "epoch: 40 [841027/888800 94.62%] train loss: 1.3370684428082313e-05 \n",
      "epoch: 40 [842138/888800 94.75%] train loss: 1.3379708434513304e-05 \n",
      "epoch: 40 [843249/888800 94.88%] train loss: 1.3175927051634062e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 [844360/888800 95.00%] train loss: 1.431071632396197e-05 \n",
      "epoch: 40 [845471/888800 95.12%] train loss: 1.2904601135232951e-05 \n",
      "epoch: 40 [846582/888800 95.25%] train loss: 1.3161266906536184e-05 \n",
      "epoch: 40 [847693/888800 95.38%] train loss: 1.394653463648865e-05 \n",
      "epoch: 40 [848804/888800 95.50%] train loss: 1.3922061953053344e-05 \n",
      "epoch: 40 [849915/888800 95.62%] train loss: 1.568644256622065e-05 \n",
      "epoch: 40 [851026/888800 95.75%] train loss: 1.4428241229325067e-05 \n",
      "epoch: 40 [852137/888800 95.88%] train loss: 1.4674484191345982e-05 \n",
      "epoch: 40 [853248/888800 96.00%] train loss: 1.5411640561069362e-05 \n",
      "epoch: 40 [854359/888800 96.12%] train loss: 1.305462956224801e-05 \n",
      "epoch: 40 [855470/888800 96.25%] train loss: 1.5031738257675897e-05 \n",
      "epoch: 40 [856581/888800 96.38%] train loss: 1.4514660506392829e-05 \n",
      "epoch: 40 [857692/888800 96.50%] train loss: 1.663489092607051e-05 \n",
      "epoch: 40 [858803/888800 96.62%] train loss: 1.4543206816597376e-05 \n",
      "epoch: 40 [859914/888800 96.75%] train loss: 1.4339540939545259e-05 \n",
      "epoch: 40 [861025/888800 96.88%] train loss: 1.4354747690958902e-05 \n",
      "epoch: 40 [862136/888800 97.00%] train loss: 1.4068558812141418e-05 \n",
      "epoch: 40 [863247/888800 97.12%] train loss: 1.3073693480691873e-05 \n",
      "epoch: 40 [864358/888800 97.25%] train loss: 1.5431442079716362e-05 \n",
      "epoch: 40 [865469/888800 97.38%] train loss: 1.4462341823673341e-05 \n",
      "epoch: 40 [866580/888800 97.50%] train loss: 1.495613014412811e-05 \n",
      "epoch: 40 [867691/888800 97.62%] train loss: 1.5632576833013445e-05 \n",
      "epoch: 40 [868802/888800 97.75%] train loss: 1.4292109881353099e-05 \n",
      "epoch: 40 [869913/888800 97.88%] train loss: 1.4284064491221216e-05 \n",
      "epoch: 40 [871024/888800 98.00%] train loss: 1.5638548575225286e-05 \n",
      "epoch: 40 [872135/888800 98.12%] train loss: 1.4525373444485012e-05 \n",
      "epoch: 40 [873246/888800 98.25%] train loss: 1.3372850844461937e-05 \n",
      "epoch: 40 [874357/888800 98.38%] train loss: 1.3083380508760456e-05 \n",
      "epoch: 40 [875468/888800 98.50%] train loss: 1.500779853813583e-05 \n",
      "epoch: 40 [876579/888800 98.62%] train loss: 1.4788363841944374e-05 \n",
      "epoch: 40 [877690/888800 98.75%] train loss: 1.4160907085170038e-05 \n",
      "epoch: 40 [878801/888800 98.88%] train loss: 1.5758454537717625e-05 \n",
      "epoch: 40 [879912/888800 99.00%] train loss: 1.36219405248994e-05 \n",
      "epoch: 40 [881023/888800 99.12%] train loss: 1.3896084965381306e-05 \n",
      "epoch: 40 [882134/888800 99.25%] train loss: 1.4933002603356726e-05 \n",
      "epoch: 40 [883245/888800 99.38%] train loss: 1.418764986738097e-05 \n",
      "epoch: 40 [884356/888800 99.50%] train loss: 1.3698508155357558e-05 \n",
      "epoch: 40 [885467/888800 99.62%] train loss: 1.4332628779811785e-05 \n",
      "epoch: 40 [886578/888800 99.75%] train loss: 1.4318282410386018e-05 \n",
      "epoch: 40 [887689/888800 99.88%] train loss: 1.4816013390372973e-05 \n",
      "epoch: 41 [0/888800 0.00%] train loss: 1.4021014067111537e-05 \n",
      "epoch: 41 [1111/888800 0.12%] train loss: 1.4508929780276958e-05 \n",
      "epoch: 41 [2222/888800 0.25%] train loss: 1.5430012354045175e-05 \n",
      "epoch: 41 [3333/888800 0.38%] train loss: 1.3006328117626254e-05 \n",
      "epoch: 41 [4444/888800 0.50%] train loss: 1.317098576691933e-05 \n",
      "epoch: 41 [5555/888800 0.62%] train loss: 1.4192532944434788e-05 \n",
      "epoch: 41 [6666/888800 0.75%] train loss: 1.4704362001793925e-05 \n",
      "epoch: 41 [7777/888800 0.88%] train loss: 1.3979043615108822e-05 \n",
      "epoch: 41 [8888/888800 1.00%] train loss: 1.4868539437884465e-05 \n",
      "epoch: 41 [9999/888800 1.12%] train loss: 1.4349048797157593e-05 \n",
      "epoch: 41 [11110/888800 1.25%] train loss: 1.3433344975055661e-05 \n",
      "epoch: 41 [12221/888800 1.38%] train loss: 1.4144608940114267e-05 \n",
      "epoch: 41 [13332/888800 1.50%] train loss: 1.350741513306275e-05 \n",
      "epoch: 41 [14443/888800 1.62%] train loss: 1.531036468804814e-05 \n",
      "epoch: 41 [15554/888800 1.75%] train loss: 1.3791590390610509e-05 \n",
      "epoch: 41 [16665/888800 1.88%] train loss: 1.3815420061291661e-05 \n",
      "epoch: 41 [17776/888800 2.00%] train loss: 1.4076201296120416e-05 \n",
      "epoch: 41 [18887/888800 2.12%] train loss: 1.5818608517292887e-05 \n",
      "epoch: 41 [19998/888800 2.25%] train loss: 1.5055746189318597e-05 \n",
      "epoch: 41 [21109/888800 2.38%] train loss: 1.3398519513430074e-05 \n",
      "epoch: 41 [22220/888800 2.50%] train loss: 1.320671526627848e-05 \n",
      "epoch: 41 [23331/888800 2.62%] train loss: 1.4297969755716622e-05 \n",
      "epoch: 41 [24442/888800 2.75%] train loss: 1.4993609511293471e-05 \n",
      "epoch: 41 [25553/888800 2.88%] train loss: 1.230921861861134e-05 \n",
      "epoch: 41 [26664/888800 3.00%] train loss: 1.3580277482105885e-05 \n",
      "epoch: 41 [27775/888800 3.12%] train loss: 1.3512240002455655e-05 \n",
      "epoch: 41 [28886/888800 3.25%] train loss: 1.4238180483516771e-05 \n",
      "epoch: 41 [29997/888800 3.38%] train loss: 1.3732985280512366e-05 \n",
      "epoch: 41 [31108/888800 3.50%] train loss: 1.4061315596336499e-05 \n",
      "epoch: 41 [32219/888800 3.62%] train loss: 1.566281025588978e-05 \n",
      "epoch: 41 [33330/888800 3.75%] train loss: 1.4184899555402808e-05 \n",
      "epoch: 41 [34441/888800 3.88%] train loss: 1.3373943147598766e-05 \n",
      "epoch: 41 [35552/888800 4.00%] train loss: 1.2756719115714077e-05 \n",
      "epoch: 41 [36663/888800 4.12%] train loss: 1.3916763236920815e-05 \n",
      "epoch: 41 [37774/888800 4.25%] train loss: 1.4453298717853613e-05 \n",
      "epoch: 41 [38885/888800 4.38%] train loss: 1.4316021406557411e-05 \n",
      "epoch: 41 [39996/888800 4.50%] train loss: 1.493632862548111e-05 \n",
      "epoch: 41 [41107/888800 4.62%] train loss: 1.5278181308531202e-05 \n",
      "epoch: 41 [42218/888800 4.75%] train loss: 1.4084018403082155e-05 \n",
      "epoch: 41 [43329/888800 4.88%] train loss: 1.3058243894192856e-05 \n",
      "epoch: 41 [44440/888800 5.00%] train loss: 1.5621579223079607e-05 \n",
      "epoch: 41 [45551/888800 5.12%] train loss: 1.42518410939374e-05 \n",
      "epoch: 41 [46662/888800 5.25%] train loss: 1.5506304407608695e-05 \n",
      "epoch: 41 [47773/888800 5.38%] train loss: 1.3352495443541557e-05 \n",
      "epoch: 41 [48884/888800 5.50%] train loss: 1.4285694305726793e-05 \n",
      "epoch: 41 [49995/888800 5.62%] train loss: 1.4219313015928492e-05 \n",
      "epoch: 41 [51106/888800 5.75%] train loss: 1.4006755009177141e-05 \n",
      "epoch: 41 [52217/888800 5.88%] train loss: 1.6296602552756667e-05 \n",
      "epoch: 41 [53328/888800 6.00%] train loss: 1.3399689123616554e-05 \n",
      "epoch: 41 [54439/888800 6.12%] train loss: 1.4245936654333491e-05 \n",
      "epoch: 41 [55550/888800 6.25%] train loss: 1.3493947335518897e-05 \n",
      "epoch: 41 [56661/888800 6.38%] train loss: 1.3885558473702986e-05 \n",
      "epoch: 41 [57772/888800 6.50%] train loss: 1.4799894415773451e-05 \n",
      "epoch: 41 [58883/888800 6.62%] train loss: 1.3279731319926213e-05 \n",
      "epoch: 41 [59994/888800 6.75%] train loss: 1.4006142919242848e-05 \n",
      "epoch: 41 [61105/888800 6.88%] train loss: 1.296594382438343e-05 \n",
      "epoch: 41 [62216/888800 7.00%] train loss: 1.3777914318779949e-05 \n",
      "epoch: 41 [63327/888800 7.12%] train loss: 1.4506731531582773e-05 \n",
      "epoch: 41 [64438/888800 7.25%] train loss: 1.3800017768517137e-05 \n",
      "epoch: 41 [65549/888800 7.38%] train loss: 1.535732371849008e-05 \n",
      "epoch: 41 [66660/888800 7.50%] train loss: 1.3955176655144896e-05 \n",
      "epoch: 41 [67771/888800 7.62%] train loss: 1.4279379684012383e-05 \n",
      "epoch: 41 [68882/888800 7.75%] train loss: 1.5188020370260347e-05 \n",
      "epoch: 41 [69993/888800 7.88%] train loss: 1.4382341760210693e-05 \n",
      "epoch: 41 [71104/888800 8.00%] train loss: 1.4656365237897262e-05 \n",
      "epoch: 41 [72215/888800 8.12%] train loss: 1.4519379874400329e-05 \n",
      "epoch: 41 [73326/888800 8.25%] train loss: 1.564761441841256e-05 \n",
      "epoch: 41 [74437/888800 8.38%] train loss: 1.3717140063818078e-05 \n",
      "epoch: 41 [75548/888800 8.50%] train loss: 1.575242458784487e-05 \n",
      "epoch: 41 [76659/888800 8.62%] train loss: 1.4091445336816832e-05 \n",
      "epoch: 41 [77770/888800 8.75%] train loss: 1.4618203749705572e-05 \n",
      "epoch: 41 [78881/888800 8.88%] train loss: 1.582876211614348e-05 \n",
      "epoch: 41 [79992/888800 9.00%] train loss: 1.4702032785862684e-05 \n",
      "epoch: 41 [81103/888800 9.12%] train loss: 1.770261769706849e-05 \n",
      "epoch: 41 [82214/888800 9.25%] train loss: 1.3047612810623832e-05 \n",
      "epoch: 41 [83325/888800 9.38%] train loss: 1.5399813491967507e-05 \n",
      "epoch: 41 [84436/888800 9.50%] train loss: 1.4019003174325917e-05 \n",
      "epoch: 41 [85547/888800 9.62%] train loss: 1.484063523093937e-05 \n",
      "epoch: 41 [86658/888800 9.75%] train loss: 1.4502383237413596e-05 \n",
      "epoch: 41 [87769/888800 9.88%] train loss: 1.4141262909106445e-05 \n",
      "epoch: 41 [88880/888800 10.00%] train loss: 1.3172631952329539e-05 \n",
      "epoch: 41 [89991/888800 10.12%] train loss: 1.422259538230719e-05 \n",
      "epoch: 41 [91102/888800 10.25%] train loss: 1.3057629985269159e-05 \n",
      "epoch: 41 [92213/888800 10.38%] train loss: 1.5237834304571152e-05 \n",
      "epoch: 41 [93324/888800 10.50%] train loss: 1.3756137377640698e-05 \n",
      "epoch: 41 [94435/888800 10.62%] train loss: 1.4067262782191392e-05 \n",
      "epoch: 41 [95546/888800 10.75%] train loss: 1.3967724044050556e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [96657/888800 10.88%] train loss: 1.4453410585701931e-05 \n",
      "epoch: 41 [97768/888800 11.00%] train loss: 1.540380071674008e-05 \n",
      "epoch: 41 [98879/888800 11.12%] train loss: 1.537417665531393e-05 \n",
      "epoch: 41 [99990/888800 11.25%] train loss: 1.544729275337886e-05 \n",
      "epoch: 41 [101101/888800 11.38%] train loss: 1.438996878277976e-05 \n",
      "epoch: 41 [102212/888800 11.50%] train loss: 1.3718259651795961e-05 \n",
      "epoch: 41 [103323/888800 11.62%] train loss: 1.4341452697408386e-05 \n",
      "epoch: 41 [104434/888800 11.75%] train loss: 1.537630487291608e-05 \n",
      "epoch: 41 [105545/888800 11.88%] train loss: 1.3952239896752872e-05 \n",
      "epoch: 41 [106656/888800 12.00%] train loss: 1.3562839740188792e-05 \n",
      "epoch: 41 [107767/888800 12.12%] train loss: 1.4166481378197204e-05 \n",
      "epoch: 41 [108878/888800 12.25%] train loss: 1.4366322830028366e-05 \n",
      "epoch: 41 [109989/888800 12.38%] train loss: 1.4439278857025784e-05 \n",
      "epoch: 41 [111100/888800 12.50%] train loss: 1.4100577573117334e-05 \n",
      "epoch: 41 [112211/888800 12.62%] train loss: 1.4068594282434788e-05 \n",
      "epoch: 41 [113322/888800 12.75%] train loss: 1.600138784851879e-05 \n",
      "epoch: 41 [114433/888800 12.88%] train loss: 1.3119522009219509e-05 \n",
      "epoch: 41 [115544/888800 13.00%] train loss: 1.4404349713004194e-05 \n",
      "epoch: 41 [116655/888800 13.12%] train loss: 1.4099042346060742e-05 \n",
      "epoch: 41 [117766/888800 13.25%] train loss: 1.3931240573583636e-05 \n",
      "epoch: 41 [118877/888800 13.38%] train loss: 1.4732631825609133e-05 \n",
      "epoch: 41 [119988/888800 13.50%] train loss: 1.4552895663655363e-05 \n",
      "epoch: 41 [121099/888800 13.62%] train loss: 1.5247233022819273e-05 \n",
      "epoch: 41 [122210/888800 13.75%] train loss: 1.5519432054134086e-05 \n",
      "epoch: 41 [123321/888800 13.88%] train loss: 1.5519324733759277e-05 \n",
      "epoch: 41 [124432/888800 14.00%] train loss: 1.376085310766939e-05 \n",
      "epoch: 41 [125543/888800 14.12%] train loss: 1.37028382596327e-05 \n",
      "epoch: 41 [126654/888800 14.25%] train loss: 1.3717333786189556e-05 \n",
      "epoch: 41 [127765/888800 14.38%] train loss: 1.390071975038154e-05 \n",
      "epoch: 41 [128876/888800 14.50%] train loss: 1.4868104699417017e-05 \n",
      "epoch: 41 [129987/888800 14.62%] train loss: 1.3432325431494974e-05 \n",
      "epoch: 41 [131098/888800 14.75%] train loss: 1.4361397006723564e-05 \n",
      "epoch: 41 [132209/888800 14.88%] train loss: 1.3916147509007715e-05 \n",
      "epoch: 41 [133320/888800 15.00%] train loss: 1.5075603187142406e-05 \n",
      "epoch: 41 [134431/888800 15.12%] train loss: 1.4046858268557116e-05 \n",
      "epoch: 41 [135542/888800 15.25%] train loss: 1.4227247447706759e-05 \n",
      "epoch: 41 [136653/888800 15.38%] train loss: 1.2839099326811265e-05 \n",
      "epoch: 41 [137764/888800 15.50%] train loss: 1.3871052033209708e-05 \n",
      "epoch: 41 [138875/888800 15.62%] train loss: 1.4090222066442948e-05 \n",
      "epoch: 41 [139986/888800 15.75%] train loss: 1.3792103345622309e-05 \n",
      "epoch: 41 [141097/888800 15.88%] train loss: 1.3720011338591576e-05 \n",
      "epoch: 41 [142208/888800 16.00%] train loss: 1.3767735254077706e-05 \n",
      "epoch: 41 [143319/888800 16.12%] train loss: 1.61577008839231e-05 \n",
      "epoch: 41 [144430/888800 16.25%] train loss: 1.3538157872972079e-05 \n",
      "epoch: 41 [145541/888800 16.38%] train loss: 1.301360589422984e-05 \n",
      "epoch: 41 [146652/888800 16.50%] train loss: 1.3075011338514742e-05 \n",
      "epoch: 41 [147763/888800 16.62%] train loss: 1.4536561138811521e-05 \n",
      "epoch: 41 [148874/888800 16.75%] train loss: 1.3190220670367125e-05 \n",
      "epoch: 41 [149985/888800 16.88%] train loss: 1.441924450773513e-05 \n",
      "epoch: 41 [151096/888800 17.00%] train loss: 1.3693429536942858e-05 \n",
      "epoch: 41 [152207/888800 17.12%] train loss: 1.5147755220823456e-05 \n",
      "epoch: 41 [153318/888800 17.25%] train loss: 1.3368101463129278e-05 \n",
      "epoch: 41 [154429/888800 17.38%] train loss: 1.491908187745139e-05 \n",
      "epoch: 41 [155540/888800 17.50%] train loss: 1.4251515494834166e-05 \n",
      "epoch: 41 [156651/888800 17.62%] train loss: 1.4344180272019003e-05 \n",
      "epoch: 41 [157762/888800 17.75%] train loss: 1.5831612472538836e-05 \n",
      "epoch: 41 [158873/888800 17.88%] train loss: 1.3773213140666485e-05 \n",
      "epoch: 41 [159984/888800 18.00%] train loss: 1.5841644199099392e-05 \n",
      "epoch: 41 [161095/888800 18.12%] train loss: 1.4449995433096774e-05 \n",
      "epoch: 41 [162206/888800 18.25%] train loss: 1.591533873579465e-05 \n",
      "epoch: 41 [163317/888800 18.38%] train loss: 1.4183024177327752e-05 \n",
      "epoch: 41 [164428/888800 18.50%] train loss: 1.571543180034496e-05 \n",
      "epoch: 41 [165539/888800 18.62%] train loss: 1.459137365600327e-05 \n",
      "epoch: 41 [166650/888800 18.75%] train loss: 1.5954849004629068e-05 \n",
      "epoch: 41 [167761/888800 18.88%] train loss: 1.531064663140569e-05 \n",
      "epoch: 41 [168872/888800 19.00%] train loss: 1.5086247913131956e-05 \n",
      "epoch: 41 [169983/888800 19.12%] train loss: 1.3177856089896522e-05 \n",
      "epoch: 41 [171094/888800 19.25%] train loss: 1.3404395758698229e-05 \n",
      "epoch: 41 [172205/888800 19.38%] train loss: 1.294143839913886e-05 \n",
      "epoch: 41 [173316/888800 19.50%] train loss: 1.3713766747969203e-05 \n",
      "epoch: 41 [174427/888800 19.62%] train loss: 1.42012595460983e-05 \n",
      "epoch: 41 [175538/888800 19.75%] train loss: 1.3308433153724764e-05 \n",
      "epoch: 41 [176649/888800 19.88%] train loss: 1.528867142042145e-05 \n",
      "epoch: 41 [177760/888800 20.00%] train loss: 1.4521664525091182e-05 \n",
      "epoch: 41 [178871/888800 20.12%] train loss: 1.3183021110307891e-05 \n",
      "epoch: 41 [179982/888800 20.25%] train loss: 1.3544409739552066e-05 \n",
      "epoch: 41 [181093/888800 20.38%] train loss: 1.4825874131929595e-05 \n",
      "epoch: 41 [182204/888800 20.50%] train loss: 1.4106940398050938e-05 \n",
      "epoch: 41 [183315/888800 20.62%] train loss: 1.5232876648951788e-05 \n",
      "epoch: 41 [184426/888800 20.75%] train loss: 1.3819938430970069e-05 \n",
      "epoch: 41 [185537/888800 20.88%] train loss: 1.365059051749995e-05 \n",
      "epoch: 41 [186648/888800 21.00%] train loss: 1.4664970876765437e-05 \n",
      "epoch: 41 [187759/888800 21.12%] train loss: 1.223959043272771e-05 \n",
      "epoch: 41 [188870/888800 21.25%] train loss: 1.3788750038656872e-05 \n",
      "epoch: 41 [189981/888800 21.38%] train loss: 1.4504446880891919e-05 \n",
      "epoch: 41 [191092/888800 21.50%] train loss: 1.5790110410307534e-05 \n",
      "epoch: 41 [192203/888800 21.62%] train loss: 1.4473008377535734e-05 \n",
      "epoch: 41 [193314/888800 21.75%] train loss: 1.6348420103895478e-05 \n",
      "epoch: 41 [194425/888800 21.88%] train loss: 1.5157172128965613e-05 \n",
      "epoch: 41 [195536/888800 22.00%] train loss: 1.4005076081957668e-05 \n",
      "epoch: 41 [196647/888800 22.12%] train loss: 1.5011015420896001e-05 \n",
      "epoch: 41 [197758/888800 22.25%] train loss: 1.4156878023641184e-05 \n",
      "epoch: 41 [198869/888800 22.38%] train loss: 1.4344879673444666e-05 \n",
      "epoch: 41 [199980/888800 22.50%] train loss: 1.494558819103986e-05 \n",
      "epoch: 41 [201091/888800 22.62%] train loss: 1.4306569028121885e-05 \n",
      "epoch: 41 [202202/888800 22.75%] train loss: 1.4731767805642448e-05 \n",
      "epoch: 41 [203313/888800 22.88%] train loss: 1.3904780644224957e-05 \n",
      "epoch: 41 [204424/888800 23.00%] train loss: 1.4241023563954514e-05 \n",
      "epoch: 41 [205535/888800 23.12%] train loss: 1.4482262486126274e-05 \n",
      "epoch: 41 [206646/888800 23.25%] train loss: 1.4166441360430326e-05 \n",
      "epoch: 41 [207757/888800 23.38%] train loss: 1.5566143702017143e-05 \n",
      "epoch: 41 [208868/888800 23.50%] train loss: 1.533715840196237e-05 \n",
      "epoch: 41 [209979/888800 23.62%] train loss: 1.6408508599852212e-05 \n",
      "epoch: 41 [211090/888800 23.75%] train loss: 1.2919412256451324e-05 \n",
      "epoch: 41 [212201/888800 23.88%] train loss: 1.6490686903125606e-05 \n",
      "epoch: 41 [213312/888800 24.00%] train loss: 1.3969573956273962e-05 \n",
      "epoch: 41 [214423/888800 24.12%] train loss: 1.557970063004177e-05 \n",
      "epoch: 41 [215534/888800 24.25%] train loss: 1.501376482337946e-05 \n",
      "epoch: 41 [216645/888800 24.38%] train loss: 1.5365081708296202e-05 \n",
      "epoch: 41 [217756/888800 24.50%] train loss: 1.3285276509122923e-05 \n",
      "epoch: 41 [218867/888800 24.62%] train loss: 1.3954205314803403e-05 \n",
      "epoch: 41 [219978/888800 24.75%] train loss: 1.3783172107650898e-05 \n",
      "epoch: 41 [221089/888800 24.88%] train loss: 1.3107181075611152e-05 \n",
      "epoch: 41 [222200/888800 25.00%] train loss: 1.4439139704336412e-05 \n",
      "epoch: 41 [223311/888800 25.12%] train loss: 1.318193335464457e-05 \n",
      "epoch: 41 [224422/888800 25.25%] train loss: 1.4583686606783886e-05 \n",
      "epoch: 41 [225533/888800 25.38%] train loss: 1.3685696103493683e-05 \n",
      "epoch: 41 [226644/888800 25.50%] train loss: 1.355577478534542e-05 \n",
      "epoch: 41 [227755/888800 25.62%] train loss: 1.4726911103934981e-05 \n",
      "epoch: 41 [228866/888800 25.75%] train loss: 1.4250519598135725e-05 \n",
      "epoch: 41 [229977/888800 25.88%] train loss: 1.4223331163520925e-05 \n",
      "epoch: 41 [231088/888800 26.00%] train loss: 1.4331581041915342e-05 \n",
      "epoch: 41 [232199/888800 26.12%] train loss: 1.5339332094299607e-05 \n",
      "epoch: 41 [233310/888800 26.25%] train loss: 1.389945282426197e-05 \n",
      "epoch: 41 [234421/888800 26.38%] train loss: 1.5008792615844868e-05 \n",
      "epoch: 41 [235532/888800 26.50%] train loss: 1.4707614354847465e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [236643/888800 26.62%] train loss: 1.4115283192950301e-05 \n",
      "epoch: 41 [237754/888800 26.75%] train loss: 1.4382067092810757e-05 \n",
      "epoch: 41 [238865/888800 26.88%] train loss: 1.4807358638790902e-05 \n",
      "epoch: 41 [239976/888800 27.00%] train loss: 1.4464427295024507e-05 \n",
      "epoch: 41 [241087/888800 27.12%] train loss: 1.5091550267243292e-05 \n",
      "epoch: 41 [242198/888800 27.25%] train loss: 1.2551629879453685e-05 \n",
      "epoch: 41 [243309/888800 27.38%] train loss: 1.4044350791664328e-05 \n",
      "epoch: 41 [244420/888800 27.50%] train loss: 1.306229842157336e-05 \n",
      "epoch: 41 [245531/888800 27.62%] train loss: 1.5239301319525111e-05 \n",
      "epoch: 41 [246642/888800 27.75%] train loss: 1.2821409654861782e-05 \n",
      "epoch: 41 [247753/888800 27.88%] train loss: 1.4378259947989136e-05 \n",
      "epoch: 41 [248864/888800 28.00%] train loss: 1.3776818377664313e-05 \n",
      "epoch: 41 [249975/888800 28.12%] train loss: 1.535668889118824e-05 \n",
      "epoch: 41 [251086/888800 28.25%] train loss: 1.4880385606375057e-05 \n",
      "epoch: 41 [252197/888800 28.38%] train loss: 1.4137178368400782e-05 \n",
      "epoch: 41 [253308/888800 28.50%] train loss: 1.532395435788203e-05 \n",
      "epoch: 41 [254419/888800 28.62%] train loss: 1.4418656064663082e-05 \n",
      "epoch: 41 [255530/888800 28.75%] train loss: 1.4483664017461706e-05 \n",
      "epoch: 41 [256641/888800 28.88%] train loss: 1.3089588719594758e-05 \n",
      "epoch: 41 [257752/888800 29.00%] train loss: 1.4533424291585106e-05 \n",
      "epoch: 41 [258863/888800 29.12%] train loss: 1.4677409126306884e-05 \n",
      "epoch: 41 [259974/888800 29.25%] train loss: 1.451217849535169e-05 \n",
      "epoch: 41 [261085/888800 29.38%] train loss: 1.4442705833062064e-05 \n",
      "epoch: 41 [262196/888800 29.50%] train loss: 1.505018190073315e-05 \n",
      "epoch: 41 [263307/888800 29.62%] train loss: 1.4010341146786232e-05 \n",
      "epoch: 41 [264418/888800 29.75%] train loss: 1.4863778233120684e-05 \n",
      "epoch: 41 [265529/888800 29.88%] train loss: 1.3657559975399636e-05 \n",
      "epoch: 41 [266640/888800 30.00%] train loss: 1.494267962698359e-05 \n",
      "epoch: 41 [267751/888800 30.12%] train loss: 1.4770816960663069e-05 \n",
      "epoch: 41 [268862/888800 30.25%] train loss: 1.4947685485822149e-05 \n",
      "epoch: 41 [269973/888800 30.38%] train loss: 1.4483493032457773e-05 \n",
      "epoch: 41 [271084/888800 30.50%] train loss: 1.3210118595452514e-05 \n",
      "epoch: 41 [272195/888800 30.62%] train loss: 1.3637726624438073e-05 \n",
      "epoch: 41 [273306/888800 30.75%] train loss: 1.2907420568808448e-05 \n",
      "epoch: 41 [274417/888800 30.88%] train loss: 1.4993155673437286e-05 \n",
      "epoch: 41 [275528/888800 31.00%] train loss: 1.3587276043836027e-05 \n",
      "epoch: 41 [276639/888800 31.12%] train loss: 1.3387301805778407e-05 \n",
      "epoch: 41 [277750/888800 31.25%] train loss: 1.4461922546615824e-05 \n",
      "epoch: 41 [278861/888800 31.38%] train loss: 1.4535613445332274e-05 \n",
      "epoch: 41 [279972/888800 31.50%] train loss: 1.4461554201261606e-05 \n",
      "epoch: 41 [281083/888800 31.62%] train loss: 1.590795727679506e-05 \n",
      "epoch: 41 [282194/888800 31.75%] train loss: 1.507172692072345e-05 \n",
      "epoch: 41 [283305/888800 31.88%] train loss: 1.4651242054242175e-05 \n",
      "epoch: 41 [284416/888800 32.00%] train loss: 1.333457839791663e-05 \n",
      "epoch: 41 [285527/888800 32.12%] train loss: 1.380071171297459e-05 \n",
      "epoch: 41 [286638/888800 32.25%] train loss: 1.5142933079914656e-05 \n",
      "epoch: 41 [287749/888800 32.38%] train loss: 1.3771547855867539e-05 \n",
      "epoch: 41 [288860/888800 32.50%] train loss: 1.4954010111978278e-05 \n",
      "epoch: 41 [289971/888800 32.62%] train loss: 1.45164922287222e-05 \n",
      "epoch: 41 [291082/888800 32.75%] train loss: 1.5554951460217126e-05 \n",
      "epoch: 41 [292193/888800 32.88%] train loss: 1.4775200725125615e-05 \n",
      "epoch: 41 [293304/888800 33.00%] train loss: 1.4943942005629651e-05 \n",
      "epoch: 41 [294415/888800 33.12%] train loss: 1.3231180673756171e-05 \n",
      "epoch: 41 [295526/888800 33.25%] train loss: 1.5012311450846028e-05 \n",
      "epoch: 41 [296637/888800 33.38%] train loss: 1.560580676596146e-05 \n",
      "epoch: 41 [297748/888800 33.50%] train loss: 1.607778722245712e-05 \n",
      "epoch: 41 [298859/888800 33.62%] train loss: 1.549265107314568e-05 \n",
      "epoch: 41 [299970/888800 33.75%] train loss: 1.4598024790757336e-05 \n",
      "epoch: 41 [301081/888800 33.88%] train loss: 1.601767507963814e-05 \n",
      "epoch: 41 [302192/888800 34.00%] train loss: 1.4374242709891405e-05 \n",
      "epoch: 41 [303303/888800 34.12%] train loss: 1.503851126472e-05 \n",
      "epoch: 41 [304414/888800 34.25%] train loss: 1.3792105164611712e-05 \n",
      "epoch: 41 [305525/888800 34.38%] train loss: 1.4017038665770087e-05 \n",
      "epoch: 41 [306636/888800 34.50%] train loss: 1.3850009054294787e-05 \n",
      "epoch: 41 [307747/888800 34.62%] train loss: 1.35797727125464e-05 \n",
      "epoch: 41 [308858/888800 34.75%] train loss: 1.399583834427176e-05 \n",
      "epoch: 41 [309969/888800 34.88%] train loss: 1.4350106539495755e-05 \n",
      "epoch: 41 [311080/888800 35.00%] train loss: 1.5010003153292928e-05 \n",
      "epoch: 41 [312191/888800 35.12%] train loss: 1.4479863239102997e-05 \n",
      "epoch: 41 [313302/888800 35.25%] train loss: 1.4585568351321854e-05 \n",
      "epoch: 41 [314413/888800 35.38%] train loss: 1.4429716429731343e-05 \n",
      "epoch: 41 [315524/888800 35.50%] train loss: 1.4963206922402605e-05 \n",
      "epoch: 41 [316635/888800 35.62%] train loss: 1.4001766430737916e-05 \n",
      "epoch: 41 [317746/888800 35.75%] train loss: 1.4074718819756526e-05 \n",
      "epoch: 41 [318857/888800 35.88%] train loss: 1.4146069588605314e-05 \n",
      "epoch: 41 [319968/888800 36.00%] train loss: 1.4055728570383508e-05 \n",
      "epoch: 41 [321079/888800 36.12%] train loss: 1.3889292858948465e-05 \n",
      "epoch: 41 [322190/888800 36.25%] train loss: 1.529273322375957e-05 \n",
      "epoch: 41 [323301/888800 36.38%] train loss: 1.5329804227803834e-05 \n",
      "epoch: 41 [324412/888800 36.50%] train loss: 1.5230180906655733e-05 \n",
      "epoch: 41 [325523/888800 36.62%] train loss: 1.5010145943961106e-05 \n",
      "epoch: 41 [326634/888800 36.75%] train loss: 1.3628761735162698e-05 \n",
      "epoch: 41 [327745/888800 36.88%] train loss: 1.2927492207381874e-05 \n",
      "epoch: 41 [328856/888800 37.00%] train loss: 1.3935578863311093e-05 \n",
      "epoch: 41 [329967/888800 37.12%] train loss: 1.5291181625798345e-05 \n",
      "epoch: 41 [331078/888800 37.25%] train loss: 1.31693286675727e-05 \n",
      "epoch: 41 [332189/888800 37.38%] train loss: 1.4366921277542133e-05 \n",
      "epoch: 41 [333300/888800 37.50%] train loss: 1.4313065548776649e-05 \n",
      "epoch: 41 [334411/888800 37.62%] train loss: 1.5843897926970385e-05 \n",
      "epoch: 41 [335522/888800 37.75%] train loss: 1.4657281099061947e-05 \n",
      "epoch: 41 [336633/888800 37.88%] train loss: 1.4480276149697602e-05 \n",
      "epoch: 41 [337744/888800 38.00%] train loss: 1.4877810826874338e-05 \n",
      "epoch: 41 [338855/888800 38.12%] train loss: 1.2563023119582795e-05 \n",
      "epoch: 41 [339966/888800 38.25%] train loss: 1.4485063729807734e-05 \n",
      "epoch: 41 [341077/888800 38.38%] train loss: 1.4726118024555035e-05 \n",
      "epoch: 41 [342188/888800 38.50%] train loss: 1.4731320334249176e-05 \n",
      "epoch: 41 [343299/888800 38.62%] train loss: 1.3618551747640595e-05 \n",
      "epoch: 41 [344410/888800 38.75%] train loss: 1.4657581232313532e-05 \n",
      "epoch: 41 [345521/888800 38.88%] train loss: 1.4434043805522379e-05 \n",
      "epoch: 41 [346632/888800 39.00%] train loss: 1.3642636076838244e-05 \n",
      "epoch: 41 [347743/888800 39.12%] train loss: 1.4487490261672065e-05 \n",
      "epoch: 41 [348854/888800 39.25%] train loss: 1.3833147932018619e-05 \n",
      "epoch: 41 [349965/888800 39.38%] train loss: 1.4850591469439678e-05 \n",
      "epoch: 41 [351076/888800 39.50%] train loss: 1.432178669347195e-05 \n",
      "epoch: 41 [352187/888800 39.62%] train loss: 1.4678232219011988e-05 \n",
      "epoch: 41 [353298/888800 39.75%] train loss: 1.3263533219287638e-05 \n",
      "epoch: 41 [354409/888800 39.88%] train loss: 1.3954389942227863e-05 \n",
      "epoch: 41 [355520/888800 40.00%] train loss: 1.3095882422931027e-05 \n",
      "epoch: 41 [356631/888800 40.12%] train loss: 1.2885309843113646e-05 \n",
      "epoch: 41 [357742/888800 40.25%] train loss: 1.3946727449365426e-05 \n",
      "epoch: 41 [358853/888800 40.38%] train loss: 1.5231017641781364e-05 \n",
      "epoch: 41 [359964/888800 40.50%] train loss: 1.3082728401059285e-05 \n",
      "epoch: 41 [361075/888800 40.62%] train loss: 1.3853894415660761e-05 \n",
      "epoch: 41 [362186/888800 40.75%] train loss: 1.427144707122352e-05 \n",
      "epoch: 41 [363297/888800 40.88%] train loss: 1.452508968213806e-05 \n",
      "epoch: 41 [364408/888800 41.00%] train loss: 1.474203872930957e-05 \n",
      "epoch: 41 [365519/888800 41.12%] train loss: 1.528916254756041e-05 \n",
      "epoch: 41 [366630/888800 41.25%] train loss: 1.3801569366478361e-05 \n",
      "epoch: 41 [367741/888800 41.38%] train loss: 1.548167892906349e-05 \n",
      "epoch: 41 [368852/888800 41.50%] train loss: 1.4901218492013868e-05 \n",
      "epoch: 41 [369963/888800 41.62%] train loss: 1.4371161341841798e-05 \n",
      "epoch: 41 [371074/888800 41.75%] train loss: 1.2771644833264872e-05 \n",
      "epoch: 41 [372185/888800 41.88%] train loss: 1.4394471691048238e-05 \n",
      "epoch: 41 [373296/888800 42.00%] train loss: 1.4693631783302408e-05 \n",
      "epoch: 41 [374407/888800 42.12%] train loss: 1.4883235962770414e-05 \n",
      "epoch: 41 [375518/888800 42.25%] train loss: 1.592173066455871e-05 \n",
      "epoch: 41 [376629/888800 42.38%] train loss: 1.3097921510052402e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [377740/888800 42.50%] train loss: 1.5258016901498195e-05 \n",
      "epoch: 41 [378851/888800 42.62%] train loss: 1.3729906640946865e-05 \n",
      "epoch: 41 [379962/888800 42.75%] train loss: 1.4477234799414873e-05 \n",
      "epoch: 41 [381073/888800 42.88%] train loss: 1.4005782759340946e-05 \n",
      "epoch: 41 [382184/888800 43.00%] train loss: 1.3691572348761838e-05 \n",
      "epoch: 41 [383295/888800 43.12%] train loss: 1.3531443073588889e-05 \n",
      "epoch: 41 [384406/888800 43.25%] train loss: 1.3340915756998584e-05 \n",
      "epoch: 41 [385517/888800 43.38%] train loss: 1.534375041956082e-05 \n",
      "epoch: 41 [386628/888800 43.50%] train loss: 1.4900631867931224e-05 \n",
      "epoch: 41 [387739/888800 43.62%] train loss: 1.4032941180630587e-05 \n",
      "epoch: 41 [388850/888800 43.75%] train loss: 1.3746736840403173e-05 \n",
      "epoch: 41 [389961/888800 43.88%] train loss: 1.5227189578581601e-05 \n",
      "epoch: 41 [391072/888800 44.00%] train loss: 1.4653313883172814e-05 \n",
      "epoch: 41 [392183/888800 44.12%] train loss: 1.4333220860862639e-05 \n",
      "epoch: 41 [393294/888800 44.25%] train loss: 1.5718287613708526e-05 \n",
      "epoch: 41 [394405/888800 44.38%] train loss: 1.4442659448832273e-05 \n",
      "epoch: 41 [395516/888800 44.50%] train loss: 1.582220102136489e-05 \n",
      "epoch: 41 [396627/888800 44.62%] train loss: 1.5390707631013356e-05 \n",
      "epoch: 41 [397738/888800 44.75%] train loss: 1.4732333511346951e-05 \n",
      "epoch: 41 [398849/888800 44.88%] train loss: 1.5499927030759864e-05 \n",
      "epoch: 41 [399960/888800 45.00%] train loss: 1.297292510571424e-05 \n",
      "epoch: 41 [401071/888800 45.12%] train loss: 1.5007384718046524e-05 \n",
      "epoch: 41 [402182/888800 45.25%] train loss: 1.4550156265613623e-05 \n",
      "epoch: 41 [403293/888800 45.38%] train loss: 1.523555602034321e-05 \n",
      "epoch: 41 [404404/888800 45.50%] train loss: 1.2890782272734214e-05 \n",
      "epoch: 41 [405515/888800 45.62%] train loss: 1.5462459487025626e-05 \n",
      "epoch: 41 [406626/888800 45.75%] train loss: 1.3056156603852287e-05 \n",
      "epoch: 41 [407737/888800 45.88%] train loss: 1.508783498138655e-05 \n",
      "epoch: 41 [408848/888800 46.00%] train loss: 1.412813344359165e-05 \n",
      "epoch: 41 [409959/888800 46.12%] train loss: 1.5537179933744483e-05 \n",
      "epoch: 41 [411070/888800 46.25%] train loss: 1.5582580090267584e-05 \n",
      "epoch: 41 [412181/888800 46.38%] train loss: 1.3099949683237355e-05 \n",
      "epoch: 41 [413292/888800 46.50%] train loss: 1.4616381122323219e-05 \n",
      "epoch: 41 [414403/888800 46.62%] train loss: 1.323485321336193e-05 \n",
      "epoch: 41 [415514/888800 46.75%] train loss: 1.4779317098145839e-05 \n",
      "epoch: 41 [416625/888800 46.88%] train loss: 1.442590382794151e-05 \n",
      "epoch: 41 [417736/888800 47.00%] train loss: 1.35513009809074e-05 \n",
      "epoch: 41 [418847/888800 47.12%] train loss: 1.3512136320059653e-05 \n",
      "epoch: 41 [419958/888800 47.25%] train loss: 1.3875255717721302e-05 \n",
      "epoch: 41 [421069/888800 47.38%] train loss: 1.5116702343220823e-05 \n",
      "epoch: 41 [422180/888800 47.50%] train loss: 1.4247340004658327e-05 \n",
      "epoch: 41 [423291/888800 47.62%] train loss: 1.4077064406592399e-05 \n",
      "epoch: 41 [424402/888800 47.75%] train loss: 1.3462706192512996e-05 \n",
      "epoch: 41 [425513/888800 47.88%] train loss: 1.5421957868966274e-05 \n",
      "epoch: 41 [426624/888800 48.00%] train loss: 1.4128960174275562e-05 \n",
      "epoch: 41 [427735/888800 48.12%] train loss: 1.4521825505653396e-05 \n",
      "epoch: 41 [428846/888800 48.25%] train loss: 1.298840743402252e-05 \n",
      "epoch: 41 [429957/888800 48.38%] train loss: 1.2921875168103725e-05 \n",
      "epoch: 41 [431068/888800 48.50%] train loss: 1.4531083252222743e-05 \n",
      "epoch: 41 [432179/888800 48.62%] train loss: 1.5252248886099551e-05 \n",
      "epoch: 41 [433290/888800 48.75%] train loss: 1.3199264685681555e-05 \n",
      "epoch: 41 [434401/888800 48.88%] train loss: 1.3452226085064467e-05 \n",
      "epoch: 41 [435512/888800 49.00%] train loss: 1.388322652928764e-05 \n",
      "epoch: 41 [436623/888800 49.12%] train loss: 1.3926863175584003e-05 \n",
      "epoch: 41 [437734/888800 49.25%] train loss: 1.3865635082765948e-05 \n",
      "epoch: 41 [438845/888800 49.38%] train loss: 1.4462175386142917e-05 \n",
      "epoch: 41 [439956/888800 49.50%] train loss: 1.4652830941486172e-05 \n",
      "epoch: 41 [441067/888800 49.62%] train loss: 1.4511682820739225e-05 \n",
      "epoch: 41 [442178/888800 49.75%] train loss: 1.3540337931772228e-05 \n",
      "epoch: 41 [443289/888800 49.88%] train loss: 1.5611698472639546e-05 \n",
      "epoch: 41 [444400/888800 50.00%] train loss: 1.3627846783492714e-05 \n",
      "epoch: 41 [445511/888800 50.12%] train loss: 1.4168385860102717e-05 \n",
      "epoch: 41 [446622/888800 50.25%] train loss: 1.4802211808273569e-05 \n",
      "epoch: 41 [447733/888800 50.38%] train loss: 1.4650894627266098e-05 \n",
      "epoch: 41 [448844/888800 50.50%] train loss: 1.4720005310664419e-05 \n",
      "epoch: 41 [449955/888800 50.62%] train loss: 1.3077135918138083e-05 \n",
      "epoch: 41 [451066/888800 50.75%] train loss: 1.4480091522273142e-05 \n",
      "epoch: 41 [452177/888800 50.88%] train loss: 1.4851636478852015e-05 \n",
      "epoch: 41 [453288/888800 51.00%] train loss: 1.3191352081776131e-05 \n",
      "epoch: 41 [454399/888800 51.12%] train loss: 1.5450625141966157e-05 \n",
      "epoch: 41 [455510/888800 51.25%] train loss: 1.3703161130251829e-05 \n",
      "epoch: 41 [456621/888800 51.38%] train loss: 1.3882854545954615e-05 \n",
      "epoch: 41 [457732/888800 51.50%] train loss: 1.3696942914975807e-05 \n",
      "epoch: 41 [458843/888800 51.62%] train loss: 1.313346092501888e-05 \n",
      "epoch: 41 [459954/888800 51.75%] train loss: 1.546007661090698e-05 \n",
      "epoch: 41 [461065/888800 51.88%] train loss: 1.732478449412156e-05 \n",
      "epoch: 41 [462176/888800 52.00%] train loss: 1.4551200365531258e-05 \n",
      "epoch: 41 [463287/888800 52.12%] train loss: 1.4996069694461767e-05 \n",
      "epoch: 41 [464398/888800 52.25%] train loss: 1.3516682884073816e-05 \n",
      "epoch: 41 [465509/888800 52.38%] train loss: 1.4474157978838775e-05 \n",
      "epoch: 41 [466620/888800 52.50%] train loss: 1.3699667761102319e-05 \n",
      "epoch: 41 [467731/888800 52.62%] train loss: 1.4462122635450214e-05 \n",
      "epoch: 41 [468842/888800 52.75%] train loss: 1.4184026440489106e-05 \n",
      "epoch: 41 [469953/888800 52.88%] train loss: 1.4048550838197116e-05 \n",
      "epoch: 41 [471064/888800 53.00%] train loss: 1.3729604688705876e-05 \n",
      "epoch: 41 [472175/888800 53.12%] train loss: 1.525014522485435e-05 \n",
      "epoch: 41 [473286/888800 53.25%] train loss: 1.5187461940513458e-05 \n",
      "epoch: 41 [474397/888800 53.38%] train loss: 1.498257461207686e-05 \n",
      "epoch: 41 [475508/888800 53.50%] train loss: 1.3572669558925554e-05 \n",
      "epoch: 41 [476619/888800 53.62%] train loss: 1.2975919162272476e-05 \n",
      "epoch: 41 [477730/888800 53.75%] train loss: 1.56979604071239e-05 \n",
      "epoch: 41 [478841/888800 53.88%] train loss: 1.4525314327329397e-05 \n",
      "epoch: 41 [479952/888800 54.00%] train loss: 1.6164951375685632e-05 \n",
      "epoch: 41 [481063/888800 54.12%] train loss: 1.55185680341674e-05 \n",
      "epoch: 41 [482174/888800 54.25%] train loss: 1.4807457773713395e-05 \n",
      "epoch: 41 [483285/888800 54.38%] train loss: 1.4566381651093252e-05 \n",
      "epoch: 41 [484396/888800 54.50%] train loss: 1.4472545444732532e-05 \n",
      "epoch: 41 [485507/888800 54.62%] train loss: 1.5164716387516819e-05 \n",
      "epoch: 41 [486618/888800 54.75%] train loss: 1.2904808500024956e-05 \n",
      "epoch: 41 [487729/888800 54.88%] train loss: 1.4108934010437224e-05 \n",
      "epoch: 41 [488840/888800 55.00%] train loss: 1.3736504115513526e-05 \n",
      "epoch: 41 [489951/888800 55.12%] train loss: 1.5104463273019064e-05 \n",
      "epoch: 41 [491062/888800 55.25%] train loss: 1.474768669140758e-05 \n",
      "epoch: 41 [492173/888800 55.38%] train loss: 1.3052476788288914e-05 \n",
      "epoch: 41 [493284/888800 55.50%] train loss: 1.322787102253642e-05 \n",
      "epoch: 41 [494395/888800 55.62%] train loss: 1.4514163922285661e-05 \n",
      "epoch: 41 [495506/888800 55.75%] train loss: 1.4362235560838599e-05 \n",
      "epoch: 41 [496617/888800 55.88%] train loss: 1.3683043107448611e-05 \n",
      "epoch: 41 [497728/888800 56.00%] train loss: 1.3111993212078232e-05 \n",
      "epoch: 41 [498839/888800 56.12%] train loss: 1.3138233953213785e-05 \n",
      "epoch: 41 [499950/888800 56.25%] train loss: 1.4574549823009875e-05 \n",
      "epoch: 41 [501061/888800 56.38%] train loss: 1.5229614291456528e-05 \n",
      "epoch: 41 [502172/888800 56.50%] train loss: 1.516778957011411e-05 \n",
      "epoch: 41 [503283/888800 56.62%] train loss: 1.377593434881419e-05 \n",
      "epoch: 41 [504394/888800 56.75%] train loss: 1.2835913366870955e-05 \n",
      "epoch: 41 [505505/888800 56.88%] train loss: 1.4978423678257968e-05 \n",
      "epoch: 41 [506616/888800 57.00%] train loss: 1.3973094610264525e-05 \n",
      "epoch: 41 [507727/888800 57.12%] train loss: 1.4036551874596626e-05 \n",
      "epoch: 41 [508838/888800 57.25%] train loss: 1.3091582331981044e-05 \n",
      "epoch: 41 [509949/888800 57.38%] train loss: 1.4922665286576375e-05 \n",
      "epoch: 41 [511060/888800 57.50%] train loss: 1.4434886907110922e-05 \n",
      "epoch: 41 [512171/888800 57.62%] train loss: 1.3752964150626212e-05 \n",
      "epoch: 41 [513282/888800 57.75%] train loss: 1.4106229173194151e-05 \n",
      "epoch: 41 [514393/888800 57.88%] train loss: 1.4171836483001243e-05 \n",
      "epoch: 41 [515504/888800 58.00%] train loss: 1.4634882063546684e-05 \n",
      "epoch: 41 [516615/888800 58.12%] train loss: 1.5190837075351737e-05 \n",
      "epoch: 41 [517726/888800 58.25%] train loss: 1.4879661648592446e-05 \n",
      "epoch: 41 [518837/888800 58.38%] train loss: 1.4369831660587806e-05 \n",
      "epoch: 41 [519948/888800 58.50%] train loss: 1.4850390471110586e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [521059/888800 58.62%] train loss: 1.4458710211329162e-05 \n",
      "epoch: 41 [522170/888800 58.75%] train loss: 1.3569641851063352e-05 \n",
      "epoch: 41 [523281/888800 58.88%] train loss: 1.4288851161836646e-05 \n",
      "epoch: 41 [524392/888800 59.00%] train loss: 1.4864824152027722e-05 \n",
      "epoch: 41 [525503/888800 59.12%] train loss: 1.5564193745376542e-05 \n",
      "epoch: 41 [526614/888800 59.25%] train loss: 1.322078696830431e-05 \n",
      "epoch: 41 [527725/888800 59.38%] train loss: 1.4011116036272142e-05 \n",
      "epoch: 41 [528836/888800 59.50%] train loss: 1.3968678103992715e-05 \n",
      "epoch: 41 [529947/888800 59.62%] train loss: 1.536367562948726e-05 \n",
      "epoch: 41 [531058/888800 59.75%] train loss: 1.4651996025349945e-05 \n",
      "epoch: 41 [532169/888800 59.88%] train loss: 1.3933705304225441e-05 \n",
      "epoch: 41 [533280/888800 60.00%] train loss: 1.3698188013222534e-05 \n",
      "epoch: 41 [534391/888800 60.12%] train loss: 1.489463284087833e-05 \n",
      "epoch: 41 [535502/888800 60.25%] train loss: 1.4885995369695593e-05 \n",
      "epoch: 41 [536613/888800 60.38%] train loss: 1.5968338630045764e-05 \n",
      "epoch: 41 [537724/888800 60.50%] train loss: 1.302322380070109e-05 \n",
      "epoch: 41 [538835/888800 60.62%] train loss: 1.4814034329901915e-05 \n",
      "epoch: 41 [539946/888800 60.75%] train loss: 1.3030500667809974e-05 \n",
      "epoch: 41 [541057/888800 60.88%] train loss: 1.5013042684586253e-05 \n",
      "epoch: 41 [542168/888800 61.00%] train loss: 1.5061863450682722e-05 \n",
      "epoch: 41 [543279/888800 61.12%] train loss: 1.3065749953966588e-05 \n",
      "epoch: 41 [544390/888800 61.25%] train loss: 1.4718168131366838e-05 \n",
      "epoch: 41 [545501/888800 61.38%] train loss: 1.5217434338410385e-05 \n",
      "epoch: 41 [546612/888800 61.50%] train loss: 1.4279797142080497e-05 \n",
      "epoch: 41 [547723/888800 61.62%] train loss: 1.4229777661967091e-05 \n",
      "epoch: 41 [548834/888800 61.75%] train loss: 1.3968289749755058e-05 \n",
      "epoch: 41 [549945/888800 61.88%] train loss: 1.4478457160294056e-05 \n",
      "epoch: 41 [551056/888800 62.00%] train loss: 1.503632029198343e-05 \n",
      "epoch: 41 [552167/888800 62.12%] train loss: 1.4353855476656463e-05 \n",
      "epoch: 41 [553278/888800 62.25%] train loss: 1.4876318346068729e-05 \n",
      "epoch: 41 [554389/888800 62.38%] train loss: 1.4367553376359865e-05 \n",
      "epoch: 41 [555500/888800 62.50%] train loss: 1.4660969100077637e-05 \n",
      "epoch: 41 [556611/888800 62.62%] train loss: 1.3655823750013951e-05 \n",
      "epoch: 41 [557722/888800 62.75%] train loss: 1.4307191122497898e-05 \n",
      "epoch: 41 [558833/888800 62.88%] train loss: 1.3233300705906004e-05 \n",
      "epoch: 41 [559944/888800 63.00%] train loss: 1.513435290689813e-05 \n",
      "epoch: 41 [561055/888800 63.12%] train loss: 1.407831132382853e-05 \n",
      "epoch: 41 [562166/888800 63.25%] train loss: 1.4054823623155244e-05 \n",
      "epoch: 41 [563277/888800 63.38%] train loss: 1.3366437087825034e-05 \n",
      "epoch: 41 [564388/888800 63.50%] train loss: 1.273295856663026e-05 \n",
      "epoch: 41 [565499/888800 63.62%] train loss: 1.4062642549106386e-05 \n",
      "epoch: 41 [566610/888800 63.75%] train loss: 1.4154607924865559e-05 \n",
      "epoch: 41 [567721/888800 63.88%] train loss: 1.4924743481969927e-05 \n",
      "epoch: 41 [568832/888800 64.00%] train loss: 1.3914923329139128e-05 \n",
      "epoch: 41 [569943/888800 64.12%] train loss: 1.3825367204844952e-05 \n",
      "epoch: 41 [571054/888800 64.25%] train loss: 1.4757285498490091e-05 \n",
      "epoch: 41 [572165/888800 64.38%] train loss: 1.3915335330239031e-05 \n",
      "epoch: 41 [573276/888800 64.50%] train loss: 1.548501313664019e-05 \n",
      "epoch: 41 [574387/888800 64.62%] train loss: 1.3861005754733924e-05 \n",
      "epoch: 41 [575498/888800 64.75%] train loss: 1.5073832400958054e-05 \n",
      "epoch: 41 [576609/888800 64.88%] train loss: 1.4250033927964978e-05 \n",
      "epoch: 41 [577720/888800 65.00%] train loss: 1.401669669576222e-05 \n",
      "epoch: 41 [578831/888800 65.12%] train loss: 1.3193518498155754e-05 \n",
      "epoch: 41 [579942/888800 65.25%] train loss: 1.4753518371435348e-05 \n",
      "epoch: 41 [581053/888800 65.38%] train loss: 1.4454408301389776e-05 \n",
      "epoch: 41 [582164/888800 65.50%] train loss: 1.3724316886509769e-05 \n",
      "epoch: 41 [583275/888800 65.62%] train loss: 1.5599393009324558e-05 \n",
      "epoch: 41 [584386/888800 65.75%] train loss: 1.2948146832059138e-05 \n",
      "epoch: 41 [585497/888800 65.88%] train loss: 1.4723786080139689e-05 \n",
      "epoch: 41 [586608/888800 66.00%] train loss: 1.3408553058980033e-05 \n",
      "epoch: 41 [587719/888800 66.12%] train loss: 1.524894469184801e-05 \n",
      "epoch: 41 [588830/888800 66.25%] train loss: 1.4328836186905392e-05 \n",
      "epoch: 41 [589941/888800 66.38%] train loss: 1.3334380128071643e-05 \n",
      "epoch: 41 [591052/888800 66.50%] train loss: 1.4165711945679504e-05 \n",
      "epoch: 41 [592163/888800 66.62%] train loss: 1.3782449059362989e-05 \n",
      "epoch: 41 [593274/888800 66.75%] train loss: 1.304303623328451e-05 \n",
      "epoch: 41 [594385/888800 66.88%] train loss: 1.3057761862000916e-05 \n",
      "epoch: 41 [595496/888800 67.00%] train loss: 1.4861484487482812e-05 \n",
      "epoch: 41 [596607/888800 67.12%] train loss: 1.474478358431952e-05 \n",
      "epoch: 41 [597718/888800 67.25%] train loss: 1.3835180652677082e-05 \n",
      "epoch: 41 [598829/888800 67.38%] train loss: 1.4642499081674032e-05 \n",
      "epoch: 41 [599940/888800 67.50%] train loss: 1.5388937754323706e-05 \n",
      "epoch: 41 [601051/888800 67.62%] train loss: 1.4041751455806661e-05 \n",
      "epoch: 41 [602162/888800 67.75%] train loss: 1.4085429938859306e-05 \n",
      "epoch: 41 [603273/888800 67.88%] train loss: 1.3698432667297311e-05 \n",
      "epoch: 41 [604384/888800 68.00%] train loss: 1.43998386192834e-05 \n",
      "epoch: 41 [605495/888800 68.12%] train loss: 1.3298425074026454e-05 \n",
      "epoch: 41 [606606/888800 68.25%] train loss: 1.4059763998375274e-05 \n",
      "epoch: 41 [607717/888800 68.38%] train loss: 1.5044924111862201e-05 \n",
      "epoch: 41 [608828/888800 68.50%] train loss: 1.4731244846188929e-05 \n",
      "epoch: 41 [609939/888800 68.62%] train loss: 1.4895809727022424e-05 \n",
      "epoch: 41 [611050/888800 68.75%] train loss: 1.527368658571504e-05 \n",
      "epoch: 41 [612161/888800 68.88%] train loss: 1.4227435713110026e-05 \n",
      "epoch: 41 [613272/888800 69.00%] train loss: 1.4222372556105256e-05 \n",
      "epoch: 41 [614383/888800 69.12%] train loss: 1.385334508086089e-05 \n",
      "epoch: 41 [615494/888800 69.25%] train loss: 1.3850129107595421e-05 \n",
      "epoch: 41 [616605/888800 69.38%] train loss: 1.4271819054556545e-05 \n",
      "epoch: 41 [617716/888800 69.50%] train loss: 1.4908229786669835e-05 \n",
      "epoch: 41 [618827/888800 69.62%] train loss: 1.3024136023886967e-05 \n",
      "epoch: 41 [619938/888800 69.75%] train loss: 1.3570591363532003e-05 \n",
      "epoch: 41 [621049/888800 69.88%] train loss: 1.388616055919556e-05 \n",
      "epoch: 41 [622160/888800 70.00%] train loss: 1.3896209566155449e-05 \n",
      "epoch: 41 [623271/888800 70.12%] train loss: 1.371405232930556e-05 \n",
      "epoch: 41 [624382/888800 70.25%] train loss: 1.4082903362577781e-05 \n",
      "epoch: 41 [625493/888800 70.38%] train loss: 1.3354250768315978e-05 \n",
      "epoch: 41 [626604/888800 70.50%] train loss: 1.4944879694667179e-05 \n",
      "epoch: 41 [627715/888800 70.62%] train loss: 1.4909116544004064e-05 \n",
      "epoch: 41 [628826/888800 70.75%] train loss: 1.5147926205827389e-05 \n",
      "epoch: 41 [629937/888800 70.88%] train loss: 1.3401506294030696e-05 \n",
      "epoch: 41 [631048/888800 71.00%] train loss: 1.3785207556793466e-05 \n",
      "epoch: 41 [632159/888800 71.12%] train loss: 1.3852453776053153e-05 \n",
      "epoch: 41 [633270/888800 71.25%] train loss: 1.4182432096276898e-05 \n",
      "epoch: 41 [634381/888800 71.38%] train loss: 1.2874989806732628e-05 \n",
      "epoch: 41 [635492/888800 71.50%] train loss: 1.429392614227254e-05 \n",
      "epoch: 41 [636603/888800 71.62%] train loss: 1.4365768947754987e-05 \n",
      "epoch: 41 [637714/888800 71.75%] train loss: 1.5381441698991694e-05 \n",
      "epoch: 41 [638825/888800 71.88%] train loss: 1.3426686564343981e-05 \n",
      "epoch: 41 [639936/888800 72.00%] train loss: 1.3754487554251682e-05 \n",
      "epoch: 41 [641047/888800 72.12%] train loss: 1.4334092156786937e-05 \n",
      "epoch: 41 [642158/888800 72.25%] train loss: 1.5136134607018903e-05 \n",
      "epoch: 41 [643269/888800 72.38%] train loss: 1.4628471035393886e-05 \n",
      "epoch: 41 [644380/888800 72.50%] train loss: 1.590199644851964e-05 \n",
      "epoch: 41 [645491/888800 72.62%] train loss: 1.4028129044163506e-05 \n",
      "epoch: 41 [646602/888800 72.75%] train loss: 1.338710899290163e-05 \n",
      "epoch: 41 [647713/888800 72.88%] train loss: 1.3786715499009006e-05 \n",
      "epoch: 41 [648824/888800 73.00%] train loss: 1.3793682228424586e-05 \n",
      "epoch: 41 [649935/888800 73.12%] train loss: 1.4398505300050601e-05 \n",
      "epoch: 41 [651046/888800 73.25%] train loss: 1.4091480807110202e-05 \n",
      "epoch: 41 [652157/888800 73.38%] train loss: 1.4515340808429755e-05 \n",
      "epoch: 41 [653268/888800 73.50%] train loss: 1.4159963029669598e-05 \n",
      "epoch: 41 [654379/888800 73.62%] train loss: 1.4748880857951008e-05 \n",
      "epoch: 41 [655490/888800 73.75%] train loss: 1.3666283848579042e-05 \n",
      "epoch: 41 [656601/888800 73.88%] train loss: 1.530968256702181e-05 \n",
      "epoch: 41 [657712/888800 74.00%] train loss: 1.3521089385903906e-05 \n",
      "epoch: 41 [658823/888800 74.12%] train loss: 1.3936453797214199e-05 \n",
      "epoch: 41 [659934/888800 74.25%] train loss: 1.4037640539754648e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [661045/888800 74.38%] train loss: 1.3796599887427874e-05 \n",
      "epoch: 41 [662156/888800 74.50%] train loss: 1.5209503544610925e-05 \n",
      "epoch: 41 [663267/888800 74.62%] train loss: 1.4218355318007525e-05 \n",
      "epoch: 41 [664378/888800 74.75%] train loss: 1.389215776725905e-05 \n",
      "epoch: 41 [665489/888800 74.88%] train loss: 1.3734441381529905e-05 \n",
      "epoch: 41 [666600/888800 75.00%] train loss: 1.4255710993893445e-05 \n",
      "epoch: 41 [667711/888800 75.12%] train loss: 1.5513343896600418e-05 \n",
      "epoch: 41 [668822/888800 75.25%] train loss: 1.4925518371455837e-05 \n",
      "epoch: 41 [669933/888800 75.38%] train loss: 1.4930728866602294e-05 \n",
      "epoch: 41 [671044/888800 75.50%] train loss: 1.4687465409224387e-05 \n",
      "epoch: 41 [672155/888800 75.62%] train loss: 1.4928511518519372e-05 \n",
      "epoch: 41 [673266/888800 75.75%] train loss: 1.4548762919730507e-05 \n",
      "epoch: 41 [674377/888800 75.88%] train loss: 1.4401610314962454e-05 \n",
      "epoch: 41 [675488/888800 76.00%] train loss: 1.3242109162092675e-05 \n",
      "epoch: 41 [676599/888800 76.12%] train loss: 1.532629357825499e-05 \n",
      "epoch: 41 [677710/888800 76.25%] train loss: 1.4395676771528088e-05 \n",
      "epoch: 41 [678821/888800 76.38%] train loss: 1.4319908586912788e-05 \n",
      "epoch: 41 [679932/888800 76.50%] train loss: 1.3956165275885724e-05 \n",
      "epoch: 41 [681043/888800 76.62%] train loss: 1.493580566602759e-05 \n",
      "epoch: 41 [682154/888800 76.75%] train loss: 1.4400195141206495e-05 \n",
      "epoch: 41 [683265/888800 76.88%] train loss: 1.571199027239345e-05 \n",
      "epoch: 41 [684376/888800 77.00%] train loss: 1.3784464499622118e-05 \n",
      "epoch: 41 [685487/888800 77.12%] train loss: 1.4494635252049193e-05 \n",
      "epoch: 41 [686598/888800 77.25%] train loss: 1.357873134111287e-05 \n",
      "epoch: 41 [687709/888800 77.38%] train loss: 1.5198371329461224e-05 \n",
      "epoch: 41 [688820/888800 77.50%] train loss: 1.4377833394974004e-05 \n",
      "epoch: 41 [689931/888800 77.62%] train loss: 1.3881955055694561e-05 \n",
      "epoch: 41 [691042/888800 77.75%] train loss: 1.3231952834757976e-05 \n",
      "epoch: 41 [692153/888800 77.88%] train loss: 1.5385639926535077e-05 \n",
      "epoch: 41 [693264/888800 78.00%] train loss: 1.5108235857042018e-05 \n",
      "epoch: 41 [694375/888800 78.12%] train loss: 1.3991874766361434e-05 \n",
      "epoch: 41 [695486/888800 78.25%] train loss: 1.611129664524924e-05 \n",
      "epoch: 41 [696597/888800 78.38%] train loss: 1.3969914107292425e-05 \n",
      "epoch: 41 [697708/888800 78.50%] train loss: 1.5685875041526742e-05 \n",
      "epoch: 41 [698819/888800 78.62%] train loss: 1.54458757606335e-05 \n",
      "epoch: 41 [699930/888800 78.75%] train loss: 1.6420815882156603e-05 \n",
      "epoch: 41 [701041/888800 78.88%] train loss: 1.4013224244990852e-05 \n",
      "epoch: 41 [702152/888800 79.00%] train loss: 1.3806376045977231e-05 \n",
      "epoch: 41 [703263/888800 79.12%] train loss: 1.6147479982464574e-05 \n",
      "epoch: 41 [704374/888800 79.25%] train loss: 1.3810400560032576e-05 \n",
      "epoch: 41 [705485/888800 79.38%] train loss: 1.7121490600402467e-05 \n",
      "epoch: 41 [706596/888800 79.50%] train loss: 1.4471193935605697e-05 \n",
      "epoch: 41 [707707/888800 79.62%] train loss: 1.4962248314986937e-05 \n",
      "epoch: 41 [708818/888800 79.75%] train loss: 1.4811429537076037e-05 \n",
      "epoch: 41 [709929/888800 79.88%] train loss: 1.4872388419462368e-05 \n",
      "epoch: 41 [711040/888800 80.00%] train loss: 1.5076981071615592e-05 \n",
      "epoch: 41 [712151/888800 80.12%] train loss: 1.4410386029339861e-05 \n",
      "epoch: 41 [713262/888800 80.25%] train loss: 1.4684120287711266e-05 \n",
      "epoch: 41 [714373/888800 80.38%] train loss: 1.320669525739504e-05 \n",
      "epoch: 41 [715484/888800 80.50%] train loss: 1.3721704817726277e-05 \n",
      "epoch: 41 [716595/888800 80.62%] train loss: 1.5899737263680436e-05 \n",
      "epoch: 41 [717706/888800 80.75%] train loss: 1.3829250747221522e-05 \n",
      "epoch: 41 [718817/888800 80.88%] train loss: 1.3496815881808288e-05 \n",
      "epoch: 41 [719928/888800 81.00%] train loss: 1.4457461475103628e-05 \n",
      "epoch: 41 [721039/888800 81.12%] train loss: 1.4130841009318829e-05 \n",
      "epoch: 41 [722150/888800 81.25%] train loss: 1.3729107195104007e-05 \n",
      "epoch: 41 [723261/888800 81.38%] train loss: 1.504274314356735e-05 \n",
      "epoch: 41 [724372/888800 81.50%] train loss: 1.4349537195812445e-05 \n",
      "epoch: 41 [725483/888800 81.62%] train loss: 1.4334777006297372e-05 \n",
      "epoch: 41 [726594/888800 81.75%] train loss: 1.4286700206866954e-05 \n",
      "epoch: 41 [727705/888800 81.88%] train loss: 1.4414090401260182e-05 \n",
      "epoch: 41 [728816/888800 82.00%] train loss: 1.3520447282644454e-05 \n",
      "epoch: 41 [729927/888800 82.12%] train loss: 1.4407581147679593e-05 \n",
      "epoch: 41 [731038/888800 82.25%] train loss: 1.3966055121272802e-05 \n",
      "epoch: 41 [732149/888800 82.38%] train loss: 1.486762903368799e-05 \n",
      "epoch: 41 [733260/888800 82.50%] train loss: 1.4868905054754578e-05 \n",
      "epoch: 41 [734371/888800 82.62%] train loss: 1.446003807359375e-05 \n",
      "epoch: 41 [735482/888800 82.75%] train loss: 1.375291685690172e-05 \n",
      "epoch: 41 [736593/888800 82.88%] train loss: 1.4980016203480773e-05 \n",
      "epoch: 41 [737704/888800 83.00%] train loss: 1.4829177416686434e-05 \n",
      "epoch: 41 [738815/888800 83.12%] train loss: 1.2902890375698917e-05 \n",
      "epoch: 41 [739926/888800 83.25%] train loss: 1.3939606105850544e-05 \n",
      "epoch: 41 [741037/888800 83.38%] train loss: 1.4218358955986332e-05 \n",
      "epoch: 41 [742148/888800 83.50%] train loss: 1.4100331100053154e-05 \n",
      "epoch: 41 [743259/888800 83.62%] train loss: 1.3930110981164034e-05 \n",
      "epoch: 41 [744370/888800 83.75%] train loss: 1.4269475286710076e-05 \n",
      "epoch: 41 [745481/888800 83.88%] train loss: 1.3496437532012351e-05 \n",
      "epoch: 41 [746592/888800 84.00%] train loss: 1.4036778338777367e-05 \n",
      "epoch: 41 [747703/888800 84.12%] train loss: 1.2891518053947948e-05 \n",
      "epoch: 41 [748814/888800 84.25%] train loss: 1.445361522200983e-05 \n",
      "epoch: 41 [749925/888800 84.38%] train loss: 1.3848382877768017e-05 \n",
      "epoch: 41 [751036/888800 84.50%] train loss: 1.4493299204332288e-05 \n",
      "epoch: 41 [752147/888800 84.62%] train loss: 1.4261206160881557e-05 \n",
      "epoch: 41 [753258/888800 84.75%] train loss: 1.365370462735882e-05 \n",
      "epoch: 41 [754369/888800 84.88%] train loss: 1.4911177458998282e-05 \n",
      "epoch: 41 [755480/888800 85.00%] train loss: 1.4211342204362154e-05 \n",
      "epoch: 41 [756591/888800 85.12%] train loss: 1.3913362636230886e-05 \n",
      "epoch: 41 [757702/888800 85.25%] train loss: 1.328748567175353e-05 \n",
      "epoch: 41 [758813/888800 85.38%] train loss: 1.3897752978664357e-05 \n",
      "epoch: 41 [759924/888800 85.50%] train loss: 1.4326227756100707e-05 \n",
      "epoch: 41 [761035/888800 85.62%] train loss: 1.321931449638214e-05 \n",
      "epoch: 41 [762146/888800 85.75%] train loss: 1.444280678697396e-05 \n",
      "epoch: 41 [763257/888800 85.88%] train loss: 1.2697702004516032e-05 \n",
      "epoch: 41 [764368/888800 86.00%] train loss: 1.330622035311535e-05 \n",
      "epoch: 41 [765479/888800 86.12%] train loss: 1.3381502867559902e-05 \n",
      "epoch: 41 [766590/888800 86.25%] train loss: 1.365490970783867e-05 \n",
      "epoch: 41 [767701/888800 86.38%] train loss: 1.4370121789397672e-05 \n",
      "epoch: 41 [768812/888800 86.50%] train loss: 1.398987205902813e-05 \n",
      "epoch: 41 [769923/888800 86.62%] train loss: 1.3762498383584898e-05 \n",
      "epoch: 41 [771034/888800 86.75%] train loss: 1.2618124856089707e-05 \n",
      "epoch: 41 [772145/888800 86.88%] train loss: 1.59477349370718e-05 \n",
      "epoch: 41 [773256/888800 87.00%] train loss: 1.3453808605845552e-05 \n",
      "epoch: 41 [774367/888800 87.12%] train loss: 1.3267396752780769e-05 \n",
      "epoch: 41 [775478/888800 87.25%] train loss: 1.5360768884420395e-05 \n",
      "epoch: 41 [776589/888800 87.38%] train loss: 1.4450183698500041e-05 \n",
      "epoch: 41 [777700/888800 87.50%] train loss: 1.4283122254710179e-05 \n",
      "epoch: 41 [778811/888800 87.62%] train loss: 1.3517089428205509e-05 \n",
      "epoch: 41 [779922/888800 87.75%] train loss: 1.5392950444947928e-05 \n",
      "epoch: 41 [781033/888800 87.88%] train loss: 1.4708251001138706e-05 \n",
      "epoch: 41 [782144/888800 88.00%] train loss: 1.4936757906980347e-05 \n",
      "epoch: 41 [783255/888800 88.12%] train loss: 1.4153917618386913e-05 \n",
      "epoch: 41 [784366/888800 88.25%] train loss: 1.421215074515203e-05 \n",
      "epoch: 41 [785477/888800 88.38%] train loss: 1.3434169886750169e-05 \n",
      "epoch: 41 [786588/888800 88.50%] train loss: 1.3801975001115352e-05 \n",
      "epoch: 41 [787699/888800 88.62%] train loss: 1.4632501006417442e-05 \n",
      "epoch: 41 [788810/888800 88.75%] train loss: 1.3522471817850601e-05 \n",
      "epoch: 41 [789921/888800 88.88%] train loss: 1.3300295904628001e-05 \n",
      "epoch: 41 [791032/888800 89.00%] train loss: 1.4275073226599488e-05 \n",
      "epoch: 41 [792143/888800 89.12%] train loss: 1.4973152246966492e-05 \n",
      "epoch: 41 [793254/888800 89.25%] train loss: 1.4128195289231371e-05 \n",
      "epoch: 41 [794365/888800 89.38%] train loss: 1.323272954323329e-05 \n",
      "epoch: 41 [795476/888800 89.50%] train loss: 1.2861554750998039e-05 \n",
      "epoch: 41 [796587/888800 89.62%] train loss: 1.3048838809481822e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 [797698/888800 89.75%] train loss: 1.4287666999734938e-05 \n",
      "epoch: 41 [798809/888800 89.88%] train loss: 1.3963373021397274e-05 \n",
      "epoch: 41 [799920/888800 90.00%] train loss: 1.3103343917464372e-05 \n",
      "epoch: 41 [801031/888800 90.12%] train loss: 1.526471351098735e-05 \n",
      "epoch: 41 [802142/888800 90.25%] train loss: 1.5130516658246052e-05 \n",
      "epoch: 41 [803253/888800 90.38%] train loss: 1.4390436263056472e-05 \n",
      "epoch: 41 [804364/888800 90.50%] train loss: 1.3546214177040383e-05 \n",
      "epoch: 41 [805475/888800 90.62%] train loss: 1.3736776963924058e-05 \n",
      "epoch: 41 [806586/888800 90.75%] train loss: 1.4282124539022334e-05 \n",
      "epoch: 41 [807697/888800 90.88%] train loss: 1.3909108929510694e-05 \n",
      "epoch: 41 [808808/888800 91.00%] train loss: 1.3873604984837584e-05 \n",
      "epoch: 41 [809919/888800 91.12%] train loss: 1.4135059245745651e-05 \n",
      "epoch: 41 [811030/888800 91.25%] train loss: 1.4772563190490473e-05 \n",
      "epoch: 41 [812141/888800 91.38%] train loss: 1.406590217811754e-05 \n",
      "epoch: 41 [813252/888800 91.50%] train loss: 1.3506381037586834e-05 \n",
      "epoch: 41 [814363/888800 91.62%] train loss: 1.4537957213178743e-05 \n",
      "epoch: 41 [815474/888800 91.75%] train loss: 1.372636415908346e-05 \n",
      "epoch: 41 [816585/888800 91.88%] train loss: 1.3967359336675145e-05 \n",
      "epoch: 41 [817696/888800 92.00%] train loss: 1.3508700249076355e-05 \n",
      "epoch: 41 [818807/888800 92.12%] train loss: 1.3841337022313382e-05 \n",
      "epoch: 41 [819918/888800 92.25%] train loss: 1.3834393030265346e-05 \n",
      "epoch: 41 [821029/888800 92.38%] train loss: 1.430633528798353e-05 \n",
      "epoch: 41 [822140/888800 92.50%] train loss: 1.2467852684494574e-05 \n",
      "epoch: 41 [823251/888800 92.62%] train loss: 1.4121606909611728e-05 \n",
      "epoch: 41 [824362/888800 92.75%] train loss: 1.4266244761529379e-05 \n",
      "epoch: 41 [825473/888800 92.88%] train loss: 1.52861830429174e-05 \n",
      "epoch: 41 [826584/888800 93.00%] train loss: 1.4150862625683658e-05 \n",
      "epoch: 41 [827695/888800 93.12%] train loss: 1.5200623238342814e-05 \n",
      "epoch: 41 [828806/888800 93.25%] train loss: 1.4252977962314617e-05 \n",
      "epoch: 41 [829917/888800 93.38%] train loss: 1.4298130736278836e-05 \n",
      "epoch: 41 [831028/888800 93.50%] train loss: 1.4481464859272819e-05 \n",
      "epoch: 41 [832139/888800 93.62%] train loss: 1.3522550034394953e-05 \n",
      "epoch: 41 [833250/888800 93.75%] train loss: 1.4244424164644442e-05 \n",
      "epoch: 41 [834361/888800 93.88%] train loss: 1.4735808690602425e-05 \n",
      "epoch: 41 [835472/888800 94.00%] train loss: 1.552468711452093e-05 \n",
      "epoch: 41 [836583/888800 94.12%] train loss: 1.4913835912011564e-05 \n",
      "epoch: 41 [837694/888800 94.25%] train loss: 1.4489718523691408e-05 \n",
      "epoch: 41 [838805/888800 94.38%] train loss: 1.4468951121671125e-05 \n",
      "epoch: 41 [839916/888800 94.50%] train loss: 1.4107111383054871e-05 \n",
      "epoch: 41 [841027/888800 94.62%] train loss: 1.4080115761316847e-05 \n",
      "epoch: 41 [842138/888800 94.75%] train loss: 1.3901472811994608e-05 \n",
      "epoch: 41 [843249/888800 94.88%] train loss: 1.4554444533132482e-05 \n",
      "epoch: 41 [844360/888800 95.00%] train loss: 1.650784361117985e-05 \n",
      "epoch: 41 [845471/888800 95.12%] train loss: 1.4670361451862846e-05 \n",
      "epoch: 41 [846582/888800 95.25%] train loss: 1.4984085282776505e-05 \n",
      "epoch: 41 [847693/888800 95.38%] train loss: 1.3632443369715475e-05 \n",
      "epoch: 41 [848804/888800 95.50%] train loss: 1.5030104805191513e-05 \n",
      "epoch: 41 [849915/888800 95.62%] train loss: 1.3255315025162417e-05 \n",
      "epoch: 41 [851026/888800 95.75%] train loss: 1.4712113625137135e-05 \n",
      "epoch: 41 [852137/888800 95.88%] train loss: 1.3638252312375698e-05 \n",
      "epoch: 41 [853248/888800 96.00%] train loss: 1.3930140084994491e-05 \n",
      "epoch: 41 [854359/888800 96.12%] train loss: 1.421063188900007e-05 \n",
      "epoch: 41 [855470/888800 96.25%] train loss: 1.5490730220335536e-05 \n",
      "epoch: 41 [856581/888800 96.38%] train loss: 1.4051985999685712e-05 \n",
      "epoch: 41 [857692/888800 96.50%] train loss: 1.5758232621010393e-05 \n",
      "epoch: 41 [858803/888800 96.62%] train loss: 1.5576972145936452e-05 \n",
      "epoch: 41 [859914/888800 96.75%] train loss: 1.3970180589240044e-05 \n",
      "epoch: 41 [861025/888800 96.88%] train loss: 1.7500757166999392e-05 \n",
      "epoch: 41 [862136/888800 97.00%] train loss: 1.4270372048486024e-05 \n",
      "epoch: 41 [863247/888800 97.12%] train loss: 1.6321204384439625e-05 \n",
      "epoch: 41 [864358/888800 97.25%] train loss: 1.4194834875524975e-05 \n",
      "epoch: 41 [865469/888800 97.38%] train loss: 1.4483823179034516e-05 \n",
      "epoch: 41 [866580/888800 97.50%] train loss: 1.4186435691954102e-05 \n",
      "epoch: 41 [867691/888800 97.62%] train loss: 1.5403033103211783e-05 \n",
      "epoch: 41 [868802/888800 97.75%] train loss: 1.556631650601048e-05 \n",
      "epoch: 41 [869913/888800 97.88%] train loss: 1.4219432159734424e-05 \n",
      "epoch: 41 [871024/888800 98.00%] train loss: 1.67217858688673e-05 \n",
      "epoch: 41 [872135/888800 98.12%] train loss: 1.4007639947521966e-05 \n",
      "epoch: 41 [873246/888800 98.25%] train loss: 1.5546364011242986e-05 \n",
      "epoch: 41 [874357/888800 98.38%] train loss: 1.48467042890843e-05 \n",
      "epoch: 41 [875468/888800 98.50%] train loss: 1.4328392353490926e-05 \n",
      "epoch: 41 [876579/888800 98.62%] train loss: 1.3953343113826122e-05 \n",
      "epoch: 41 [877690/888800 98.75%] train loss: 1.427435563527979e-05 \n",
      "epoch: 41 [878801/888800 98.88%] train loss: 1.4873863619868644e-05 \n",
      "epoch: 41 [879912/888800 99.00%] train loss: 1.4588771591661498e-05 \n",
      "epoch: 41 [881023/888800 99.12%] train loss: 1.3411266081675421e-05 \n",
      "epoch: 41 [882134/888800 99.25%] train loss: 1.416599661752116e-05 \n",
      "epoch: 41 [883245/888800 99.38%] train loss: 1.4270896826928947e-05 \n",
      "epoch: 41 [884356/888800 99.50%] train loss: 1.4120852029009257e-05 \n",
      "epoch: 41 [885467/888800 99.62%] train loss: 1.3333892638911493e-05 \n",
      "epoch: 41 [886578/888800 99.75%] train loss: 1.3999684597365558e-05 \n",
      "epoch: 41 [887689/888800 99.88%] train loss: 1.289978808927117e-05 \n",
      "epoch: 42 [0/888800 0.00%] train loss: 1.4854475011816248e-05 \n",
      "epoch: 42 [1111/888800 0.12%] train loss: 1.3346922060009092e-05 \n",
      "epoch: 42 [2222/888800 0.25%] train loss: 1.4212651876732707e-05 \n",
      "epoch: 42 [3333/888800 0.38%] train loss: 1.4209568689693697e-05 \n",
      "epoch: 42 [4444/888800 0.50%] train loss: 1.322871230513556e-05 \n",
      "epoch: 42 [5555/888800 0.62%] train loss: 1.5090212400536984e-05 \n",
      "epoch: 42 [6666/888800 0.75%] train loss: 1.3637082702189218e-05 \n",
      "epoch: 42 [7777/888800 0.88%] train loss: 1.4574454326066189e-05 \n",
      "epoch: 42 [8888/888800 1.00%] train loss: 1.2509296539064962e-05 \n",
      "epoch: 42 [9999/888800 1.12%] train loss: 1.4245601050788537e-05 \n",
      "epoch: 42 [11110/888800 1.25%] train loss: 1.3694043445866555e-05 \n",
      "epoch: 42 [12221/888800 1.38%] train loss: 1.3756927728536539e-05 \n",
      "epoch: 42 [13332/888800 1.50%] train loss: 1.3662149285664782e-05 \n",
      "epoch: 42 [14443/888800 1.62%] train loss: 1.5979947420419194e-05 \n",
      "epoch: 42 [15554/888800 1.75%] train loss: 1.414227153873071e-05 \n",
      "epoch: 42 [16665/888800 1.88%] train loss: 1.4431159797823057e-05 \n",
      "epoch: 42 [17776/888800 2.00%] train loss: 1.3461694834404625e-05 \n",
      "epoch: 42 [18887/888800 2.12%] train loss: 1.4721961633767933e-05 \n",
      "epoch: 42 [19998/888800 2.25%] train loss: 1.6434025383205153e-05 \n",
      "epoch: 42 [21109/888800 2.38%] train loss: 1.6146152120199986e-05 \n",
      "epoch: 42 [22220/888800 2.50%] train loss: 1.5670328139094636e-05 \n",
      "epoch: 42 [23331/888800 2.62%] train loss: 1.4158847989165224e-05 \n",
      "epoch: 42 [24442/888800 2.75%] train loss: 1.652344326430466e-05 \n",
      "epoch: 42 [25553/888800 2.88%] train loss: 1.3543380191549659e-05 \n",
      "epoch: 42 [26664/888800 3.00%] train loss: 1.636450360820163e-05 \n",
      "epoch: 42 [27775/888800 3.12%] train loss: 1.4279115021054167e-05 \n",
      "epoch: 42 [28886/888800 3.25%] train loss: 1.5099992197065149e-05 \n",
      "epoch: 42 [29997/888800 3.38%] train loss: 1.3950763786851894e-05 \n",
      "epoch: 42 [31108/888800 3.50%] train loss: 1.5225809875119012e-05 \n",
      "epoch: 42 [32219/888800 3.62%] train loss: 1.4610136531700846e-05 \n",
      "epoch: 42 [33330/888800 3.75%] train loss: 1.3424593817035202e-05 \n",
      "epoch: 42 [34441/888800 3.88%] train loss: 1.398995391355129e-05 \n",
      "epoch: 42 [35552/888800 4.00%] train loss: 1.4945243492547888e-05 \n",
      "epoch: 42 [36663/888800 4.12%] train loss: 1.3924883205618244e-05 \n",
      "epoch: 42 [37774/888800 4.25%] train loss: 1.473068641644204e-05 \n",
      "epoch: 42 [38885/888800 4.38%] train loss: 1.4688095689052716e-05 \n",
      "epoch: 42 [39996/888800 4.50%] train loss: 1.4104864931141492e-05 \n",
      "epoch: 42 [41107/888800 4.62%] train loss: 1.4541360542352777e-05 \n",
      "epoch: 42 [42218/888800 4.75%] train loss: 1.3857496014679782e-05 \n",
      "epoch: 42 [43329/888800 4.88%] train loss: 1.3605966159957461e-05 \n",
      "epoch: 42 [44440/888800 5.00%] train loss: 1.5755371350678615e-05 \n",
      "epoch: 42 [45551/888800 5.12%] train loss: 1.4753159121028148e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [46662/888800 5.25%] train loss: 1.3941951692686416e-05 \n",
      "epoch: 42 [47773/888800 5.38%] train loss: 1.5530882592429407e-05 \n",
      "epoch: 42 [48884/888800 5.50%] train loss: 1.4646067938883789e-05 \n",
      "epoch: 42 [49995/888800 5.62%] train loss: 1.4610448488383554e-05 \n",
      "epoch: 42 [51106/888800 5.75%] train loss: 1.3777768799627665e-05 \n",
      "epoch: 42 [52217/888800 5.88%] train loss: 1.4272143744165078e-05 \n",
      "epoch: 42 [53328/888800 6.00%] train loss: 1.5107675608305726e-05 \n",
      "epoch: 42 [54439/888800 6.12%] train loss: 1.4649112927145325e-05 \n",
      "epoch: 42 [55550/888800 6.25%] train loss: 1.5155163964664098e-05 \n",
      "epoch: 42 [56661/888800 6.38%] train loss: 1.5133891793084331e-05 \n",
      "epoch: 42 [57772/888800 6.50%] train loss: 1.4198441022017505e-05 \n",
      "epoch: 42 [58883/888800 6.62%] train loss: 1.3066636711300816e-05 \n",
      "epoch: 42 [59994/888800 6.75%] train loss: 1.4224519873096142e-05 \n",
      "epoch: 42 [61105/888800 6.88%] train loss: 1.363590399705572e-05 \n",
      "epoch: 42 [62216/888800 7.00%] train loss: 1.3097640476189554e-05 \n",
      "epoch: 42 [63327/888800 7.12%] train loss: 1.387672182318056e-05 \n",
      "epoch: 42 [64438/888800 7.25%] train loss: 1.4634620129072573e-05 \n",
      "epoch: 42 [65549/888800 7.38%] train loss: 1.5270317817339674e-05 \n",
      "epoch: 42 [66660/888800 7.50%] train loss: 1.3599652447737753e-05 \n",
      "epoch: 42 [67771/888800 7.62%] train loss: 1.3766584743279964e-05 \n",
      "epoch: 42 [68882/888800 7.75%] train loss: 1.4189447938406374e-05 \n",
      "epoch: 42 [69993/888800 7.88%] train loss: 1.3417745321930852e-05 \n",
      "epoch: 42 [71104/888800 8.00%] train loss: 1.3859646969649475e-05 \n",
      "epoch: 42 [72215/888800 8.12%] train loss: 1.2196069292258471e-05 \n",
      "epoch: 42 [73326/888800 8.25%] train loss: 1.369568781228736e-05 \n",
      "epoch: 42 [74437/888800 8.38%] train loss: 1.3221263543528039e-05 \n",
      "epoch: 42 [75548/888800 8.50%] train loss: 1.4656720850325655e-05 \n",
      "epoch: 42 [76659/888800 8.62%] train loss: 1.3428553756966721e-05 \n",
      "epoch: 42 [77770/888800 8.75%] train loss: 1.298670940741431e-05 \n",
      "epoch: 42 [78881/888800 8.88%] train loss: 1.4495050891127903e-05 \n",
      "epoch: 42 [79992/888800 9.00%] train loss: 1.4404947251023259e-05 \n",
      "epoch: 42 [81103/888800 9.12%] train loss: 1.5237725165206939e-05 \n",
      "epoch: 42 [82214/888800 9.25%] train loss: 1.4440305676544085e-05 \n",
      "epoch: 42 [83325/888800 9.38%] train loss: 1.3813400073559023e-05 \n",
      "epoch: 42 [84436/888800 9.50%] train loss: 1.4035511412657797e-05 \n",
      "epoch: 42 [85547/888800 9.62%] train loss: 1.4136957361188252e-05 \n",
      "epoch: 42 [86658/888800 9.75%] train loss: 1.4265159734350163e-05 \n",
      "epoch: 42 [87769/888800 9.88%] train loss: 1.3190227036830038e-05 \n",
      "epoch: 42 [88880/888800 10.00%] train loss: 1.3807510185870342e-05 \n",
      "epoch: 42 [89991/888800 10.12%] train loss: 1.3564642358687706e-05 \n",
      "epoch: 42 [91102/888800 10.25%] train loss: 1.3449041034618858e-05 \n",
      "epoch: 42 [92213/888800 10.38%] train loss: 1.39627709359047e-05 \n",
      "epoch: 42 [93324/888800 10.50%] train loss: 1.432805038348306e-05 \n",
      "epoch: 42 [94435/888800 10.62%] train loss: 1.4208069842425175e-05 \n",
      "epoch: 42 [95546/888800 10.75%] train loss: 1.5028838788566645e-05 \n",
      "epoch: 42 [96657/888800 10.88%] train loss: 1.4730918337590992e-05 \n",
      "epoch: 42 [97768/888800 11.00%] train loss: 1.4407506569114048e-05 \n",
      "epoch: 42 [98879/888800 11.12%] train loss: 1.4175029718899168e-05 \n",
      "epoch: 42 [99990/888800 11.25%] train loss: 1.552798494230956e-05 \n",
      "epoch: 42 [101101/888800 11.38%] train loss: 1.4466992979578208e-05 \n",
      "epoch: 42 [102212/888800 11.50%] train loss: 1.524269646324683e-05 \n",
      "epoch: 42 [103323/888800 11.62%] train loss: 1.4506641491607297e-05 \n",
      "epoch: 42 [104434/888800 11.75%] train loss: 1.5219925444398541e-05 \n",
      "epoch: 42 [105545/888800 11.88%] train loss: 1.3522469998861197e-05 \n",
      "epoch: 42 [106656/888800 12.00%] train loss: 1.352415893052239e-05 \n",
      "epoch: 42 [107767/888800 12.12%] train loss: 1.4581966752302833e-05 \n",
      "epoch: 42 [108878/888800 12.25%] train loss: 1.4783692677156068e-05 \n",
      "epoch: 42 [109989/888800 12.38%] train loss: 1.4001483577885665e-05 \n",
      "epoch: 42 [111100/888800 12.50%] train loss: 1.3371476597967558e-05 \n",
      "epoch: 42 [112211/888800 12.62%] train loss: 1.4226268831407651e-05 \n",
      "epoch: 42 [113322/888800 12.75%] train loss: 1.5238476407830603e-05 \n",
      "epoch: 42 [114433/888800 12.88%] train loss: 1.4142668987915386e-05 \n",
      "epoch: 42 [115544/888800 13.00%] train loss: 1.4251439097279217e-05 \n",
      "epoch: 42 [116655/888800 13.12%] train loss: 1.5778825400047936e-05 \n",
      "epoch: 42 [117766/888800 13.25%] train loss: 1.4433179785555694e-05 \n",
      "epoch: 42 [118877/888800 13.38%] train loss: 1.550359775137622e-05 \n",
      "epoch: 42 [119988/888800 13.50%] train loss: 1.48101280501578e-05 \n",
      "epoch: 42 [121099/888800 13.62%] train loss: 1.4395588550542016e-05 \n",
      "epoch: 42 [122210/888800 13.75%] train loss: 1.479820639360696e-05 \n",
      "epoch: 42 [123321/888800 13.88%] train loss: 1.5403367797262035e-05 \n",
      "epoch: 42 [124432/888800 14.00%] train loss: 1.4874803127895575e-05 \n",
      "epoch: 42 [125543/888800 14.12%] train loss: 1.336703007837059e-05 \n",
      "epoch: 42 [126654/888800 14.25%] train loss: 1.3651717381435446e-05 \n",
      "epoch: 42 [127765/888800 14.38%] train loss: 1.397011692461092e-05 \n",
      "epoch: 42 [128876/888800 14.50%] train loss: 1.4728330825164448e-05 \n",
      "epoch: 42 [129987/888800 14.62%] train loss: 1.261871602764586e-05 \n",
      "epoch: 42 [131098/888800 14.75%] train loss: 1.3815872989653144e-05 \n",
      "epoch: 42 [132209/888800 14.88%] train loss: 1.4028491023054812e-05 \n",
      "epoch: 42 [133320/888800 15.00%] train loss: 1.4900829228281509e-05 \n",
      "epoch: 42 [134431/888800 15.12%] train loss: 1.3300908904056996e-05 \n",
      "epoch: 42 [135542/888800 15.25%] train loss: 1.4264344827097375e-05 \n",
      "epoch: 42 [136653/888800 15.38%] train loss: 1.3585183296527248e-05 \n",
      "epoch: 42 [137764/888800 15.50%] train loss: 1.3955514987173956e-05 \n",
      "epoch: 42 [138875/888800 15.62%] train loss: 1.511229947936954e-05 \n",
      "epoch: 42 [139986/888800 15.75%] train loss: 1.3967292034067214e-05 \n",
      "epoch: 42 [141097/888800 15.88%] train loss: 1.4158187696011737e-05 \n",
      "epoch: 42 [142208/888800 16.00%] train loss: 1.4918810848030262e-05 \n",
      "epoch: 42 [143319/888800 16.12%] train loss: 1.57409995154012e-05 \n",
      "epoch: 42 [144430/888800 16.25%] train loss: 1.6267844330286607e-05 \n",
      "epoch: 42 [145541/888800 16.38%] train loss: 1.4169701898936182e-05 \n",
      "epoch: 42 [146652/888800 16.50%] train loss: 1.4194613868312445e-05 \n",
      "epoch: 42 [147763/888800 16.62%] train loss: 1.5338191587943584e-05 \n",
      "epoch: 42 [148874/888800 16.75%] train loss: 1.2639811757253483e-05 \n",
      "epoch: 42 [149985/888800 16.88%] train loss: 1.561191675136797e-05 \n",
      "epoch: 42 [151096/888800 17.00%] train loss: 1.4670880773337558e-05 \n",
      "epoch: 42 [152207/888800 17.12%] train loss: 1.2931162018503528e-05 \n",
      "epoch: 42 [153318/888800 17.25%] train loss: 1.4984459085098933e-05 \n",
      "epoch: 42 [154429/888800 17.38%] train loss: 1.4391254808288068e-05 \n",
      "epoch: 42 [155540/888800 17.50%] train loss: 1.5044389328977559e-05 \n",
      "epoch: 42 [156651/888800 17.62%] train loss: 1.3760767615167424e-05 \n",
      "epoch: 42 [157762/888800 17.75%] train loss: 1.3390490494202822e-05 \n",
      "epoch: 42 [158873/888800 17.88%] train loss: 1.3834236597176641e-05 \n",
      "epoch: 42 [159984/888800 18.00%] train loss: 1.4119948900770396e-05 \n",
      "epoch: 42 [161095/888800 18.12%] train loss: 1.3266210771689657e-05 \n",
      "epoch: 42 [162206/888800 18.25%] train loss: 1.4249310879677068e-05 \n",
      "epoch: 42 [163317/888800 18.38%] train loss: 1.3933127775089815e-05 \n",
      "epoch: 42 [164428/888800 18.50%] train loss: 1.3851030416844878e-05 \n",
      "epoch: 42 [165539/888800 18.62%] train loss: 1.4015086890140083e-05 \n",
      "epoch: 42 [166650/888800 18.75%] train loss: 1.4177571756590623e-05 \n",
      "epoch: 42 [167761/888800 18.88%] train loss: 1.5136565707507543e-05 \n",
      "epoch: 42 [168872/888800 19.00%] train loss: 1.475608951295726e-05 \n",
      "epoch: 42 [169983/888800 19.12%] train loss: 1.470361075917026e-05 \n",
      "epoch: 42 [171094/888800 19.25%] train loss: 1.372717997583095e-05 \n",
      "epoch: 42 [172205/888800 19.38%] train loss: 1.4786372958042193e-05 \n",
      "epoch: 42 [173316/888800 19.50%] train loss: 1.3789064723823685e-05 \n",
      "epoch: 42 [174427/888800 19.62%] train loss: 1.4615377040172461e-05 \n",
      "epoch: 42 [175538/888800 19.75%] train loss: 1.4592001207347494e-05 \n",
      "epoch: 42 [176649/888800 19.88%] train loss: 1.2961688298673835e-05 \n",
      "epoch: 42 [177760/888800 20.00%] train loss: 1.4265869140217546e-05 \n",
      "epoch: 42 [178871/888800 20.12%] train loss: 1.3989756553201005e-05 \n",
      "epoch: 42 [179982/888800 20.25%] train loss: 1.465135210310109e-05 \n",
      "epoch: 42 [181093/888800 20.38%] train loss: 1.3914261216996238e-05 \n",
      "epoch: 42 [182204/888800 20.50%] train loss: 1.551588502479717e-05 \n",
      "epoch: 42 [183315/888800 20.62%] train loss: 1.4277066838985775e-05 \n",
      "epoch: 42 [184426/888800 20.75%] train loss: 1.3559853869082872e-05 \n",
      "epoch: 42 [185537/888800 20.88%] train loss: 1.4461191312875599e-05 \n",
      "epoch: 42 [186648/888800 21.00%] train loss: 1.3477653737936635e-05 \n",
      "epoch: 42 [187759/888800 21.12%] train loss: 1.4013504369358998e-05 \n",
      "epoch: 42 [188870/888800 21.25%] train loss: 1.541983692732174e-05 \n",
      "epoch: 42 [189981/888800 21.38%] train loss: 1.3920754099672195e-05 \n",
      "epoch: 42 [191092/888800 21.50%] train loss: 1.3772634702036157e-05 \n",
      "epoch: 42 [192203/888800 21.62%] train loss: 1.5766852811793797e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [193314/888800 21.75%] train loss: 1.409216201864183e-05 \n",
      "epoch: 42 [194425/888800 21.88%] train loss: 1.408733987773303e-05 \n",
      "epoch: 42 [195536/888800 22.00%] train loss: 1.3805239177600015e-05 \n",
      "epoch: 42 [196647/888800 22.12%] train loss: 1.4067598385736346e-05 \n",
      "epoch: 42 [197758/888800 22.25%] train loss: 1.3984502402308863e-05 \n",
      "epoch: 42 [198869/888800 22.38%] train loss: 1.3296461474965326e-05 \n",
      "epoch: 42 [199980/888800 22.50%] train loss: 1.4196491974871606e-05 \n",
      "epoch: 42 [201091/888800 22.62%] train loss: 1.361204431304941e-05 \n",
      "epoch: 42 [202202/888800 22.75%] train loss: 1.372829319734592e-05 \n",
      "epoch: 42 [203313/888800 22.88%] train loss: 1.553432593937032e-05 \n",
      "epoch: 42 [204424/888800 23.00%] train loss: 1.3839989151165355e-05 \n",
      "epoch: 42 [205535/888800 23.12%] train loss: 1.3793795915262308e-05 \n",
      "epoch: 42 [206646/888800 23.25%] train loss: 1.4689202544104774e-05 \n",
      "epoch: 42 [207757/888800 23.38%] train loss: 1.3922554899181705e-05 \n",
      "epoch: 42 [208868/888800 23.50%] train loss: 1.4416739759326447e-05 \n",
      "epoch: 42 [209979/888800 23.62%] train loss: 1.4826323422312271e-05 \n",
      "epoch: 42 [211090/888800 23.75%] train loss: 1.4882134564686567e-05 \n",
      "epoch: 42 [212201/888800 23.88%] train loss: 1.4454079973802436e-05 \n",
      "epoch: 42 [213312/888800 24.00%] train loss: 1.5182024071691558e-05 \n",
      "epoch: 42 [214423/888800 24.12%] train loss: 1.3544905414164532e-05 \n",
      "epoch: 42 [215534/888800 24.25%] train loss: 1.5738127331133e-05 \n",
      "epoch: 42 [216645/888800 24.38%] train loss: 1.3636911717185285e-05 \n",
      "epoch: 42 [217756/888800 24.50%] train loss: 1.485013581259409e-05 \n",
      "epoch: 42 [218867/888800 24.62%] train loss: 1.413280097040115e-05 \n",
      "epoch: 42 [219978/888800 24.75%] train loss: 1.4291439583757892e-05 \n",
      "epoch: 42 [221089/888800 24.88%] train loss: 1.3917753676651046e-05 \n",
      "epoch: 42 [222200/888800 25.00%] train loss: 1.4016748536960222e-05 \n",
      "epoch: 42 [223311/888800 25.12%] train loss: 1.375381452817237e-05 \n",
      "epoch: 42 [224422/888800 25.25%] train loss: 1.4514557733491529e-05 \n",
      "epoch: 42 [225533/888800 25.38%] train loss: 1.4456421922659501e-05 \n",
      "epoch: 42 [226644/888800 25.50%] train loss: 1.519253601145465e-05 \n",
      "epoch: 42 [227755/888800 25.62%] train loss: 1.5233172234729864e-05 \n",
      "epoch: 42 [228866/888800 25.75%] train loss: 1.4728288078913465e-05 \n",
      "epoch: 42 [229977/888800 25.88%] train loss: 1.476546185585903e-05 \n",
      "epoch: 42 [231088/888800 26.00%] train loss: 1.4292086234490853e-05 \n",
      "epoch: 42 [232199/888800 26.12%] train loss: 1.435577723896131e-05 \n",
      "epoch: 42 [233310/888800 26.25%] train loss: 1.5656283721909858e-05 \n",
      "epoch: 42 [234421/888800 26.38%] train loss: 1.4210789231583476e-05 \n",
      "epoch: 42 [235532/888800 26.50%] train loss: 1.4307201126939617e-05 \n",
      "epoch: 42 [236643/888800 26.62%] train loss: 1.4933253623894416e-05 \n",
      "epoch: 42 [237754/888800 26.75%] train loss: 1.530314148112666e-05 \n",
      "epoch: 42 [238865/888800 26.88%] train loss: 1.5606368833687156e-05 \n",
      "epoch: 42 [239976/888800 27.00%] train loss: 1.2873032574134413e-05 \n",
      "epoch: 42 [241087/888800 27.12%] train loss: 1.4120901141723152e-05 \n",
      "epoch: 42 [242198/888800 27.25%] train loss: 1.4366925825015642e-05 \n",
      "epoch: 42 [243309/888800 27.38%] train loss: 1.3729201782552991e-05 \n",
      "epoch: 42 [244420/888800 27.50%] train loss: 1.575139322085306e-05 \n",
      "epoch: 42 [245531/888800 27.62%] train loss: 1.4852827007416636e-05 \n",
      "epoch: 42 [246642/888800 27.75%] train loss: 1.6190406313398853e-05 \n",
      "epoch: 42 [247753/888800 27.88%] train loss: 1.4048863704374526e-05 \n",
      "epoch: 42 [248864/888800 28.00%] train loss: 1.4261504475143738e-05 \n",
      "epoch: 42 [249975/888800 28.12%] train loss: 1.4401127373275813e-05 \n",
      "epoch: 42 [251086/888800 28.25%] train loss: 1.4498079508484807e-05 \n",
      "epoch: 42 [252197/888800 28.38%] train loss: 1.4041057511349209e-05 \n",
      "epoch: 42 [253308/888800 28.50%] train loss: 1.4906295291439164e-05 \n",
      "epoch: 42 [254419/888800 28.62%] train loss: 1.4235618436941877e-05 \n",
      "epoch: 42 [255530/888800 28.75%] train loss: 1.4927152733434923e-05 \n",
      "epoch: 42 [256641/888800 28.88%] train loss: 1.5110792446648702e-05 \n",
      "epoch: 42 [257752/888800 29.00%] train loss: 1.3605838830699213e-05 \n",
      "epoch: 42 [258863/888800 29.12%] train loss: 1.579264790052548e-05 \n",
      "epoch: 42 [259974/888800 29.25%] train loss: 1.3676611160917673e-05 \n",
      "epoch: 42 [261085/888800 29.38%] train loss: 1.4742657185706776e-05 \n",
      "epoch: 42 [262196/888800 29.50%] train loss: 1.5175106454989873e-05 \n",
      "epoch: 42 [263307/888800 29.62%] train loss: 1.4959203326725401e-05 \n",
      "epoch: 42 [264418/888800 29.75%] train loss: 1.5131876352825202e-05 \n",
      "epoch: 42 [265529/888800 29.88%] train loss: 1.3055956515017897e-05 \n",
      "epoch: 42 [266640/888800 30.00%] train loss: 1.4470096175500657e-05 \n",
      "epoch: 42 [267751/888800 30.12%] train loss: 1.448784678359516e-05 \n",
      "epoch: 42 [268862/888800 30.25%] train loss: 1.479849288443802e-05 \n",
      "epoch: 42 [269973/888800 30.38%] train loss: 1.4334220395539887e-05 \n",
      "epoch: 42 [271084/888800 30.50%] train loss: 1.375809824821772e-05 \n",
      "epoch: 42 [272195/888800 30.62%] train loss: 1.4093639038037509e-05 \n",
      "epoch: 42 [273306/888800 30.75%] train loss: 1.4799800737819169e-05 \n",
      "epoch: 42 [274417/888800 30.88%] train loss: 1.3462315109791234e-05 \n",
      "epoch: 42 [275528/888800 31.00%] train loss: 1.4291374100139365e-05 \n",
      "epoch: 42 [276639/888800 31.12%] train loss: 1.3510071767086629e-05 \n",
      "epoch: 42 [277750/888800 31.25%] train loss: 1.4942156667530071e-05 \n",
      "epoch: 42 [278861/888800 31.38%] train loss: 1.3540228792408016e-05 \n",
      "epoch: 42 [279972/888800 31.50%] train loss: 1.30645248646033e-05 \n",
      "epoch: 42 [281083/888800 31.62%] train loss: 1.4471452232101e-05 \n",
      "epoch: 42 [282194/888800 31.75%] train loss: 1.3949500498711132e-05 \n",
      "epoch: 42 [283305/888800 31.88%] train loss: 1.4812272638664581e-05 \n",
      "epoch: 42 [284416/888800 32.00%] train loss: 1.4863333490211517e-05 \n",
      "epoch: 42 [285527/888800 32.12%] train loss: 1.3111700354784261e-05 \n",
      "epoch: 42 [286638/888800 32.25%] train loss: 1.4419522813113872e-05 \n",
      "epoch: 42 [287749/888800 32.38%] train loss: 1.5007096408226062e-05 \n",
      "epoch: 42 [288860/888800 32.50%] train loss: 1.5314255506382324e-05 \n",
      "epoch: 42 [289971/888800 32.62%] train loss: 1.4347058822750114e-05 \n",
      "epoch: 42 [291082/888800 32.75%] train loss: 1.4055646715860348e-05 \n",
      "epoch: 42 [292193/888800 32.88%] train loss: 1.4300937436928507e-05 \n",
      "epoch: 42 [293304/888800 33.00%] train loss: 1.3418499293038622e-05 \n",
      "epoch: 42 [294415/888800 33.12%] train loss: 1.4836876289336942e-05 \n",
      "epoch: 42 [295526/888800 33.25%] train loss: 1.4340582310978789e-05 \n",
      "epoch: 42 [296637/888800 33.38%] train loss: 1.4323850336950272e-05 \n",
      "epoch: 42 [297748/888800 33.50%] train loss: 1.4417471902561374e-05 \n",
      "epoch: 42 [298859/888800 33.62%] train loss: 1.333824093308067e-05 \n",
      "epoch: 42 [299970/888800 33.75%] train loss: 1.2928475371154491e-05 \n",
      "epoch: 42 [301081/888800 33.88%] train loss: 1.3678888535650913e-05 \n",
      "epoch: 42 [302192/888800 34.00%] train loss: 1.3925878192821983e-05 \n",
      "epoch: 42 [303303/888800 34.12%] train loss: 1.445202451577643e-05 \n",
      "epoch: 42 [304414/888800 34.25%] train loss: 1.4205213119566906e-05 \n",
      "epoch: 42 [305525/888800 34.38%] train loss: 1.4798089068790432e-05 \n",
      "epoch: 42 [306636/888800 34.50%] train loss: 1.5373127098428085e-05 \n",
      "epoch: 42 [307747/888800 34.62%] train loss: 1.4277478840085678e-05 \n",
      "epoch: 42 [308858/888800 34.75%] train loss: 1.3393466360867023e-05 \n",
      "epoch: 42 [309969/888800 34.88%] train loss: 1.3569154361903202e-05 \n",
      "epoch: 42 [311080/888800 35.00%] train loss: 1.4225294762582052e-05 \n",
      "epoch: 42 [312191/888800 35.12%] train loss: 1.363215869787382e-05 \n",
      "epoch: 42 [313302/888800 35.25%] train loss: 1.4314191503217444e-05 \n",
      "epoch: 42 [314413/888800 35.38%] train loss: 1.3968064195069019e-05 \n",
      "epoch: 42 [315524/888800 35.50%] train loss: 1.5178566172835417e-05 \n",
      "epoch: 42 [316635/888800 35.62%] train loss: 1.4525663573294878e-05 \n",
      "epoch: 42 [317746/888800 35.75%] train loss: 1.2536408576124813e-05 \n",
      "epoch: 42 [318857/888800 35.88%] train loss: 1.365874686598545e-05 \n",
      "epoch: 42 [319968/888800 36.00%] train loss: 1.409803098795237e-05 \n",
      "epoch: 42 [321079/888800 36.12%] train loss: 1.48339304359979e-05 \n",
      "epoch: 42 [322190/888800 36.25%] train loss: 1.3518527339329012e-05 \n",
      "epoch: 42 [323301/888800 36.38%] train loss: 1.4361116882355418e-05 \n",
      "epoch: 42 [324412/888800 36.50%] train loss: 1.5098169569682796e-05 \n",
      "epoch: 42 [325523/888800 36.62%] train loss: 1.50088089867495e-05 \n",
      "epoch: 42 [326634/888800 36.75%] train loss: 1.3435971595754381e-05 \n",
      "epoch: 42 [327745/888800 36.88%] train loss: 1.4585831195290666e-05 \n",
      "epoch: 42 [328856/888800 37.00%] train loss: 1.4665906746813562e-05 \n",
      "epoch: 42 [329967/888800 37.12%] train loss: 1.4332558748719748e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [331078/888800 37.25%] train loss: 1.4335029845824465e-05 \n",
      "epoch: 42 [332189/888800 37.38%] train loss: 1.4258860574045684e-05 \n",
      "epoch: 42 [333300/888800 37.50%] train loss: 1.5671348592150025e-05 \n",
      "epoch: 42 [334411/888800 37.62%] train loss: 1.5135307876334991e-05 \n",
      "epoch: 42 [335522/888800 37.75%] train loss: 1.4527261555485893e-05 \n",
      "epoch: 42 [336633/888800 37.88%] train loss: 1.3875856893719174e-05 \n",
      "epoch: 42 [337744/888800 38.00%] train loss: 1.575438363943249e-05 \n",
      "epoch: 42 [338855/888800 38.12%] train loss: 1.4867344361846335e-05 \n",
      "epoch: 42 [339966/888800 38.25%] train loss: 1.477660407545045e-05 \n",
      "epoch: 42 [341077/888800 38.38%] train loss: 1.413649988535326e-05 \n",
      "epoch: 42 [342188/888800 38.50%] train loss: 1.4353704500535969e-05 \n",
      "epoch: 42 [343299/888800 38.62%] train loss: 1.4376787476066966e-05 \n",
      "epoch: 42 [344410/888800 38.75%] train loss: 1.3410847714112606e-05 \n",
      "epoch: 42 [345521/888800 38.88%] train loss: 1.4770221241633408e-05 \n",
      "epoch: 42 [346632/888800 39.00%] train loss: 1.639602123759687e-05 \n",
      "epoch: 42 [347743/888800 39.12%] train loss: 1.5577497833874077e-05 \n",
      "epoch: 42 [348854/888800 39.25%] train loss: 1.6127942217281088e-05 \n",
      "epoch: 42 [349965/888800 39.38%] train loss: 1.4073047168494668e-05 \n",
      "epoch: 42 [351076/888800 39.50%] train loss: 1.5544957932434045e-05 \n",
      "epoch: 42 [352187/888800 39.62%] train loss: 1.3777439562545624e-05 \n",
      "epoch: 42 [353298/888800 39.75%] train loss: 1.4150728929962497e-05 \n",
      "epoch: 42 [354409/888800 39.88%] train loss: 1.3732569641433656e-05 \n",
      "epoch: 42 [355520/888800 40.00%] train loss: 1.4099658983468544e-05 \n",
      "epoch: 42 [356631/888800 40.12%] train loss: 1.4763782019144855e-05 \n",
      "epoch: 42 [357742/888800 40.25%] train loss: 1.3197608495829627e-05 \n",
      "epoch: 42 [358853/888800 40.38%] train loss: 1.421420802216744e-05 \n",
      "epoch: 42 [359964/888800 40.50%] train loss: 1.3929253327660263e-05 \n",
      "epoch: 42 [361075/888800 40.62%] train loss: 1.4045681382413022e-05 \n",
      "epoch: 42 [362186/888800 40.75%] train loss: 1.3235582628112752e-05 \n",
      "epoch: 42 [363297/888800 40.88%] train loss: 1.4388992894964758e-05 \n",
      "epoch: 42 [364408/888800 41.00%] train loss: 1.3205092727730516e-05 \n",
      "epoch: 42 [365519/888800 41.12%] train loss: 1.556859388074372e-05 \n",
      "epoch: 42 [366630/888800 41.25%] train loss: 1.3240333828434814e-05 \n",
      "epoch: 42 [367741/888800 41.38%] train loss: 1.4075762919674162e-05 \n",
      "epoch: 42 [368852/888800 41.50%] train loss: 1.5440919014508836e-05 \n",
      "epoch: 42 [369963/888800 41.62%] train loss: 1.4829643077973742e-05 \n",
      "epoch: 42 [371074/888800 41.75%] train loss: 1.4871843632136006e-05 \n",
      "epoch: 42 [372185/888800 41.88%] train loss: 1.4208862921805121e-05 \n",
      "epoch: 42 [373296/888800 42.00%] train loss: 1.4975022168073338e-05 \n",
      "epoch: 42 [374407/888800 42.12%] train loss: 1.3059167940809857e-05 \n",
      "epoch: 42 [375518/888800 42.25%] train loss: 1.4912229744368233e-05 \n",
      "epoch: 42 [376629/888800 42.38%] train loss: 1.5036986951599829e-05 \n",
      "epoch: 42 [377740/888800 42.50%] train loss: 1.4892728358972818e-05 \n",
      "epoch: 42 [378851/888800 42.62%] train loss: 1.4881067727401387e-05 \n",
      "epoch: 42 [379962/888800 42.75%] train loss: 1.4481723155768123e-05 \n",
      "epoch: 42 [381073/888800 42.88%] train loss: 1.4011682651471347e-05 \n",
      "epoch: 42 [382184/888800 43.00%] train loss: 1.325631183135556e-05 \n",
      "epoch: 42 [383295/888800 43.12%] train loss: 1.49652560139657e-05 \n",
      "epoch: 42 [384406/888800 43.25%] train loss: 1.4615737200074363e-05 \n",
      "epoch: 42 [385517/888800 43.38%] train loss: 1.5175723092397675e-05 \n",
      "epoch: 42 [386628/888800 43.50%] train loss: 1.444547888240777e-05 \n",
      "epoch: 42 [387739/888800 43.62%] train loss: 1.3642215890286025e-05 \n",
      "epoch: 42 [388850/888800 43.75%] train loss: 1.3311799193616025e-05 \n",
      "epoch: 42 [389961/888800 43.88%] train loss: 1.4162797924655024e-05 \n",
      "epoch: 42 [391072/888800 44.00%] train loss: 1.3090882021060679e-05 \n",
      "epoch: 42 [392183/888800 44.12%] train loss: 1.4596764231100678e-05 \n",
      "epoch: 42 [393294/888800 44.25%] train loss: 1.4426609595830087e-05 \n",
      "epoch: 42 [394405/888800 44.38%] train loss: 1.4022817595105153e-05 \n",
      "epoch: 42 [395516/888800 44.50%] train loss: 1.3703385775443166e-05 \n",
      "epoch: 42 [396627/888800 44.62%] train loss: 1.4636810192314442e-05 \n",
      "epoch: 42 [397738/888800 44.75%] train loss: 1.4677697436127346e-05 \n",
      "epoch: 42 [398849/888800 44.88%] train loss: 1.4323691175377462e-05 \n",
      "epoch: 42 [399960/888800 45.00%] train loss: 1.3967217455501668e-05 \n",
      "epoch: 42 [401071/888800 45.12%] train loss: 1.349825288343709e-05 \n",
      "epoch: 42 [402182/888800 45.25%] train loss: 1.4231389286578633e-05 \n",
      "epoch: 42 [403293/888800 45.38%] train loss: 1.4170672329782974e-05 \n",
      "epoch: 42 [404404/888800 45.50%] train loss: 1.5228483789542224e-05 \n",
      "epoch: 42 [405515/888800 45.62%] train loss: 1.3373578440223355e-05 \n",
      "epoch: 42 [406626/888800 45.75%] train loss: 1.4399584870261606e-05 \n",
      "epoch: 42 [407737/888800 45.88%] train loss: 1.4376761100720614e-05 \n",
      "epoch: 42 [408848/888800 46.00%] train loss: 1.3907961147197057e-05 \n",
      "epoch: 42 [409959/888800 46.12%] train loss: 1.4308221579995006e-05 \n",
      "epoch: 42 [411070/888800 46.25%] train loss: 1.3038227734796237e-05 \n",
      "epoch: 42 [412181/888800 46.38%] train loss: 1.4054793609830085e-05 \n",
      "epoch: 42 [413292/888800 46.50%] train loss: 1.5321180399041623e-05 \n",
      "epoch: 42 [414403/888800 46.62%] train loss: 1.4413943063118495e-05 \n",
      "epoch: 42 [415514/888800 46.75%] train loss: 1.3958170711703133e-05 \n",
      "epoch: 42 [416625/888800 46.88%] train loss: 1.3057931028015446e-05 \n",
      "epoch: 42 [417736/888800 47.00%] train loss: 1.4791421563131735e-05 \n",
      "epoch: 42 [418847/888800 47.12%] train loss: 1.3574404874816537e-05 \n",
      "epoch: 42 [419958/888800 47.25%] train loss: 1.5375269867945462e-05 \n",
      "epoch: 42 [421069/888800 47.38%] train loss: 1.433282159268856e-05 \n",
      "epoch: 42 [422180/888800 47.50%] train loss: 1.297041671932675e-05 \n",
      "epoch: 42 [423291/888800 47.62%] train loss: 1.5123572666198015e-05 \n",
      "epoch: 42 [424402/888800 47.75%] train loss: 1.3624310668092221e-05 \n",
      "epoch: 42 [425513/888800 47.88%] train loss: 1.4281063158705365e-05 \n",
      "epoch: 42 [426624/888800 48.00%] train loss: 1.5259027350111865e-05 \n",
      "epoch: 42 [427735/888800 48.12%] train loss: 1.2996943041798659e-05 \n",
      "epoch: 42 [428846/888800 48.25%] train loss: 1.4260728676163126e-05 \n",
      "epoch: 42 [429957/888800 48.38%] train loss: 1.3832114746037405e-05 \n",
      "epoch: 42 [431068/888800 48.50%] train loss: 1.525297648186097e-05 \n",
      "epoch: 42 [432179/888800 48.62%] train loss: 1.3814950762025546e-05 \n",
      "epoch: 42 [433290/888800 48.75%] train loss: 1.4306728189694695e-05 \n",
      "epoch: 42 [434401/888800 48.88%] train loss: 1.3115011824993417e-05 \n",
      "epoch: 42 [435512/888800 49.00%] train loss: 1.3599187695945147e-05 \n",
      "epoch: 42 [436623/888800 49.12%] train loss: 1.3892312381358352e-05 \n",
      "epoch: 42 [437734/888800 49.25%] train loss: 1.4372555597219616e-05 \n",
      "epoch: 42 [438845/888800 49.38%] train loss: 1.4180336620484013e-05 \n",
      "epoch: 42 [439956/888800 49.50%] train loss: 1.4666397873952519e-05 \n",
      "epoch: 42 [441067/888800 49.62%] train loss: 1.4314588042907417e-05 \n",
      "epoch: 42 [442178/888800 49.75%] train loss: 1.4358989574247971e-05 \n",
      "epoch: 42 [443289/888800 49.88%] train loss: 1.3782231690129265e-05 \n",
      "epoch: 42 [444400/888800 50.00%] train loss: 1.3080137250653934e-05 \n",
      "epoch: 42 [445511/888800 50.12%] train loss: 1.3466213204083033e-05 \n",
      "epoch: 42 [446622/888800 50.25%] train loss: 1.4717403246322647e-05 \n",
      "epoch: 42 [447733/888800 50.38%] train loss: 1.2928904652653728e-05 \n",
      "epoch: 42 [448844/888800 50.50%] train loss: 1.3431829756882507e-05 \n",
      "epoch: 42 [449955/888800 50.62%] train loss: 1.4424715118366294e-05 \n",
      "epoch: 42 [451066/888800 50.75%] train loss: 1.3815672900818754e-05 \n",
      "epoch: 42 [452177/888800 50.88%] train loss: 1.4117144019110128e-05 \n",
      "epoch: 42 [453288/888800 51.00%] train loss: 1.4631867998105008e-05 \n",
      "epoch: 42 [454399/888800 51.12%] train loss: 1.412522487953538e-05 \n",
      "epoch: 42 [455510/888800 51.25%] train loss: 1.3508696611097548e-05 \n",
      "epoch: 42 [456621/888800 51.38%] train loss: 1.4290249055193271e-05 \n",
      "epoch: 42 [457732/888800 51.50%] train loss: 1.4463995285041165e-05 \n",
      "epoch: 42 [458843/888800 51.62%] train loss: 1.3049113476881757e-05 \n",
      "epoch: 42 [459954/888800 51.75%] train loss: 1.3351350389712024e-05 \n",
      "epoch: 42 [461065/888800 51.88%] train loss: 1.4154313248582184e-05 \n",
      "epoch: 42 [462176/888800 52.00%] train loss: 1.3514056263375096e-05 \n",
      "epoch: 42 [463287/888800 52.12%] train loss: 1.5573943528579548e-05 \n",
      "epoch: 42 [464398/888800 52.25%] train loss: 1.3144219337846152e-05 \n",
      "epoch: 42 [465509/888800 52.38%] train loss: 1.4689292584080249e-05 \n",
      "epoch: 42 [466620/888800 52.50%] train loss: 1.3324382052815054e-05 \n",
      "epoch: 42 [467731/888800 52.62%] train loss: 1.360110763926059e-05 \n",
      "epoch: 42 [468842/888800 52.75%] train loss: 1.3695667803403921e-05 \n",
      "epoch: 42 [469953/888800 52.88%] train loss: 1.492106184741715e-05 \n",
      "epoch: 42 [471064/888800 53.00%] train loss: 1.4196613847161643e-05 \n",
      "epoch: 42 [472175/888800 53.12%] train loss: 1.397163487126818e-05 \n",
      "epoch: 42 [473286/888800 53.25%] train loss: 1.472744952479843e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [474397/888800 53.38%] train loss: 1.5445739336428232e-05 \n",
      "epoch: 42 [475508/888800 53.50%] train loss: 1.538895048724953e-05 \n",
      "epoch: 42 [476619/888800 53.62%] train loss: 1.4662114153907169e-05 \n",
      "epoch: 42 [477730/888800 53.75%] train loss: 1.5816827726666816e-05 \n",
      "epoch: 42 [478841/888800 53.88%] train loss: 1.329901806457201e-05 \n",
      "epoch: 42 [479952/888800 54.00%] train loss: 1.5309165974031202e-05 \n",
      "epoch: 42 [481063/888800 54.12%] train loss: 1.4828654457232915e-05 \n",
      "epoch: 42 [482174/888800 54.25%] train loss: 1.4261913747759536e-05 \n",
      "epoch: 42 [483285/888800 54.38%] train loss: 1.544186488899868e-05 \n",
      "epoch: 42 [484396/888800 54.50%] train loss: 1.4142590771371033e-05 \n",
      "epoch: 42 [485507/888800 54.62%] train loss: 1.4436197488976177e-05 \n",
      "epoch: 42 [486618/888800 54.75%] train loss: 1.4189200555847492e-05 \n",
      "epoch: 42 [487729/888800 54.88%] train loss: 1.4363735317601822e-05 \n",
      "epoch: 42 [488840/888800 55.00%] train loss: 1.4207121239451226e-05 \n",
      "epoch: 42 [489951/888800 55.12%] train loss: 1.4098885003477335e-05 \n",
      "epoch: 42 [491062/888800 55.25%] train loss: 1.3942089935881086e-05 \n",
      "epoch: 42 [492173/888800 55.38%] train loss: 1.548457657918334e-05 \n",
      "epoch: 42 [493284/888800 55.50%] train loss: 1.4876824934617616e-05 \n",
      "epoch: 42 [494395/888800 55.62%] train loss: 1.4405738511413801e-05 \n",
      "epoch: 42 [495506/888800 55.75%] train loss: 1.5522051398875192e-05 \n",
      "epoch: 42 [496617/888800 55.88%] train loss: 1.542482823424507e-05 \n",
      "epoch: 42 [497728/888800 56.00%] train loss: 1.5636172975064255e-05 \n",
      "epoch: 42 [498839/888800 56.12%] train loss: 1.4149482922221068e-05 \n",
      "epoch: 42 [499950/888800 56.25%] train loss: 1.538915057608392e-05 \n",
      "epoch: 42 [501061/888800 56.38%] train loss: 1.2878216693934519e-05 \n",
      "epoch: 42 [502172/888800 56.50%] train loss: 1.44148179970216e-05 \n",
      "epoch: 42 [503283/888800 56.62%] train loss: 1.5196153981378302e-05 \n",
      "epoch: 42 [504394/888800 56.75%] train loss: 1.5102739780559205e-05 \n",
      "epoch: 42 [505505/888800 56.88%] train loss: 1.4298679161584005e-05 \n",
      "epoch: 42 [506616/888800 57.00%] train loss: 1.4527207895298488e-05 \n",
      "epoch: 42 [507727/888800 57.12%] train loss: 1.4537982679030392e-05 \n",
      "epoch: 42 [508838/888800 57.25%] train loss: 1.476427678426262e-05 \n",
      "epoch: 42 [509949/888800 57.38%] train loss: 1.3507403309631627e-05 \n",
      "epoch: 42 [511060/888800 57.50%] train loss: 1.3656884220836218e-05 \n",
      "epoch: 42 [512171/888800 57.62%] train loss: 1.3917062460677698e-05 \n",
      "epoch: 42 [513282/888800 57.75%] train loss: 1.343598614766961e-05 \n",
      "epoch: 42 [514393/888800 57.88%] train loss: 1.5416575479321182e-05 \n",
      "epoch: 42 [515504/888800 58.00%] train loss: 1.2747422260872554e-05 \n",
      "epoch: 42 [516615/888800 58.12%] train loss: 1.5078461728990078e-05 \n",
      "epoch: 42 [517726/888800 58.25%] train loss: 1.3605087588075548e-05 \n",
      "epoch: 42 [518837/888800 58.38%] train loss: 1.4800353710597847e-05 \n",
      "epoch: 42 [519948/888800 58.50%] train loss: 1.4858614122204017e-05 \n",
      "epoch: 42 [521059/888800 58.62%] train loss: 1.4476790056505706e-05 \n",
      "epoch: 42 [522170/888800 58.75%] train loss: 1.3566463167080656e-05 \n",
      "epoch: 42 [523281/888800 58.88%] train loss: 1.4075313629291486e-05 \n",
      "epoch: 42 [524392/888800 59.00%] train loss: 1.531002635601908e-05 \n",
      "epoch: 42 [525503/888800 59.12%] train loss: 1.3740849681198597e-05 \n",
      "epoch: 42 [526614/888800 59.25%] train loss: 1.3040615158388391e-05 \n",
      "epoch: 42 [527725/888800 59.38%] train loss: 1.4739158359589055e-05 \n",
      "epoch: 42 [528836/888800 59.50%] train loss: 1.3692736501980107e-05 \n",
      "epoch: 42 [529947/888800 59.62%] train loss: 1.288481416850118e-05 \n",
      "epoch: 42 [531058/888800 59.75%] train loss: 1.5173047358985059e-05 \n",
      "epoch: 42 [532169/888800 59.88%] train loss: 1.407778836437501e-05 \n",
      "epoch: 42 [533280/888800 60.00%] train loss: 1.491245438955957e-05 \n",
      "epoch: 42 [534391/888800 60.12%] train loss: 1.365829575661337e-05 \n",
      "epoch: 42 [535502/888800 60.25%] train loss: 1.3298757039592601e-05 \n",
      "epoch: 42 [536613/888800 60.38%] train loss: 1.4717254089191556e-05 \n",
      "epoch: 42 [537724/888800 60.50%] train loss: 1.4567927792086266e-05 \n",
      "epoch: 42 [538835/888800 60.62%] train loss: 1.4651600395154674e-05 \n",
      "epoch: 42 [539946/888800 60.75%] train loss: 1.4497056326945312e-05 \n",
      "epoch: 42 [541057/888800 60.88%] train loss: 1.4078133972361684e-05 \n",
      "epoch: 42 [542168/888800 61.00%] train loss: 1.456714471714804e-05 \n",
      "epoch: 42 [543279/888800 61.12%] train loss: 1.386461008223705e-05 \n",
      "epoch: 42 [544390/888800 61.25%] train loss: 1.667995093157515e-05 \n",
      "epoch: 42 [545501/888800 61.38%] train loss: 1.5158013411564752e-05 \n",
      "epoch: 42 [546612/888800 61.50%] train loss: 1.477781461289851e-05 \n",
      "epoch: 42 [547723/888800 61.62%] train loss: 1.5013101801741868e-05 \n",
      "epoch: 42 [548834/888800 61.75%] train loss: 1.4866420315229334e-05 \n",
      "epoch: 42 [549945/888800 61.88%] train loss: 1.5964824342518114e-05 \n",
      "epoch: 42 [551056/888800 62.00%] train loss: 1.4697786355100106e-05 \n",
      "epoch: 42 [552167/888800 62.12%] train loss: 1.5887615518295206e-05 \n",
      "epoch: 42 [553278/888800 62.25%] train loss: 1.327937570749782e-05 \n",
      "epoch: 42 [554389/888800 62.38%] train loss: 1.4540717529598624e-05 \n",
      "epoch: 42 [555500/888800 62.50%] train loss: 1.3431587831291836e-05 \n",
      "epoch: 42 [556611/888800 62.62%] train loss: 1.3047228094364982e-05 \n",
      "epoch: 42 [557722/888800 62.75%] train loss: 1.4342160284286365e-05 \n",
      "epoch: 42 [558833/888800 62.88%] train loss: 1.5673333109589294e-05 \n",
      "epoch: 42 [559944/888800 63.00%] train loss: 1.4451276911131572e-05 \n",
      "epoch: 42 [561055/888800 63.12%] train loss: 1.4903681403666269e-05 \n",
      "epoch: 42 [562166/888800 63.25%] train loss: 1.3719134585699067e-05 \n",
      "epoch: 42 [563277/888800 63.38%] train loss: 1.3963855963083915e-05 \n",
      "epoch: 42 [564388/888800 63.50%] train loss: 1.436802267562598e-05 \n",
      "epoch: 42 [565499/888800 63.62%] train loss: 1.5953632100718096e-05 \n",
      "epoch: 42 [566610/888800 63.75%] train loss: 1.582749973749742e-05 \n",
      "epoch: 42 [567721/888800 63.88%] train loss: 1.4942460438760463e-05 \n",
      "epoch: 42 [568832/888800 64.00%] train loss: 1.493400486651808e-05 \n",
      "epoch: 42 [569943/888800 64.12%] train loss: 1.4969896255934145e-05 \n",
      "epoch: 42 [571054/888800 64.25%] train loss: 1.3316041986399796e-05 \n",
      "epoch: 42 [572165/888800 64.38%] train loss: 1.3162291907065082e-05 \n",
      "epoch: 42 [573276/888800 64.50%] train loss: 1.2656021681323182e-05 \n",
      "epoch: 42 [574387/888800 64.62%] train loss: 1.3534156096284278e-05 \n",
      "epoch: 42 [575498/888800 64.75%] train loss: 1.3634705283038784e-05 \n",
      "epoch: 42 [576609/888800 64.88%] train loss: 1.4976410056988243e-05 \n",
      "epoch: 42 [577720/888800 65.00%] train loss: 1.458264796383446e-05 \n",
      "epoch: 42 [578831/888800 65.12%] train loss: 1.3596033568319399e-05 \n",
      "epoch: 42 [579942/888800 65.25%] train loss: 1.400153723807307e-05 \n",
      "epoch: 42 [581053/888800 65.38%] train loss: 1.4131476746115368e-05 \n",
      "epoch: 42 [582164/888800 65.50%] train loss: 1.596692527527921e-05 \n",
      "epoch: 42 [583275/888800 65.62%] train loss: 1.3470373232848942e-05 \n",
      "epoch: 42 [584386/888800 65.75%] train loss: 1.62472188094398e-05 \n",
      "epoch: 42 [585497/888800 65.88%] train loss: 1.393276579619851e-05 \n",
      "epoch: 42 [586608/888800 66.00%] train loss: 1.5910160072962753e-05 \n",
      "epoch: 42 [587719/888800 66.12%] train loss: 1.4403719433175866e-05 \n",
      "epoch: 42 [588830/888800 66.25%] train loss: 1.453944332752144e-05 \n",
      "epoch: 42 [589941/888800 66.38%] train loss: 1.543655525892973e-05 \n",
      "epoch: 42 [591052/888800 66.50%] train loss: 1.5263824025169015e-05 \n",
      "epoch: 42 [592163/888800 66.62%] train loss: 1.6373422113247216e-05 \n",
      "epoch: 42 [593274/888800 66.75%] train loss: 1.4714846656715963e-05 \n",
      "epoch: 42 [594385/888800 66.88%] train loss: 1.5351479305536486e-05 \n",
      "epoch: 42 [595496/888800 67.00%] train loss: 1.2890042853541672e-05 \n",
      "epoch: 42 [596607/888800 67.12%] train loss: 1.774875636328943e-05 \n",
      "epoch: 42 [597718/888800 67.25%] train loss: 1.4439544429478701e-05 \n",
      "epoch: 42 [598829/888800 67.38%] train loss: 1.5358395103248768e-05 \n",
      "epoch: 42 [599940/888800 67.50%] train loss: 1.4570095117960591e-05 \n",
      "epoch: 42 [601051/888800 67.62%] train loss: 1.4976616512285545e-05 \n",
      "epoch: 42 [602162/888800 67.75%] train loss: 1.5276926205842756e-05 \n",
      "epoch: 42 [603273/888800 67.88%] train loss: 1.4396362530533224e-05 \n",
      "epoch: 42 [604384/888800 68.00%] train loss: 1.657606117078103e-05 \n",
      "epoch: 42 [605495/888800 68.12%] train loss: 1.4998004189692438e-05 \n",
      "epoch: 42 [606606/888800 68.25%] train loss: 1.6335461623384617e-05 \n",
      "epoch: 42 [607717/888800 68.38%] train loss: 1.557288305775728e-05 \n",
      "epoch: 42 [608828/888800 68.50%] train loss: 1.3909040717408061e-05 \n",
      "epoch: 42 [609939/888800 68.62%] train loss: 1.3612975635624025e-05 \n",
      "epoch: 42 [611050/888800 68.75%] train loss: 1.4112812095845584e-05 \n",
      "epoch: 42 [612161/888800 68.88%] train loss: 1.444750068912981e-05 \n",
      "epoch: 42 [613272/888800 69.00%] train loss: 1.4153082702250686e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [614383/888800 69.12%] train loss: 1.4238351468520705e-05 \n",
      "epoch: 42 [615494/888800 69.25%] train loss: 1.4221110177459195e-05 \n",
      "epoch: 42 [616605/888800 69.38%] train loss: 1.2868104931840207e-05 \n",
      "epoch: 42 [617716/888800 69.50%] train loss: 1.5049180547066499e-05 \n",
      "epoch: 42 [618827/888800 69.62%] train loss: 1.4696371181344148e-05 \n",
      "epoch: 42 [619938/888800 69.75%] train loss: 1.4264827768784016e-05 \n",
      "epoch: 42 [621049/888800 69.88%] train loss: 1.3066564861219376e-05 \n",
      "epoch: 42 [622160/888800 70.00%] train loss: 1.3589247828349471e-05 \n",
      "epoch: 42 [623271/888800 70.12%] train loss: 1.5539644664386287e-05 \n",
      "epoch: 42 [624382/888800 70.25%] train loss: 1.6205904103117064e-05 \n",
      "epoch: 42 [625493/888800 70.38%] train loss: 1.3255375961307436e-05 \n",
      "epoch: 42 [626604/888800 70.50%] train loss: 1.5228140910039656e-05 \n",
      "epoch: 42 [627715/888800 70.62%] train loss: 1.4480317986453883e-05 \n",
      "epoch: 42 [628826/888800 70.75%] train loss: 1.5134677596506663e-05 \n",
      "epoch: 42 [629937/888800 70.88%] train loss: 1.4039583220437635e-05 \n",
      "epoch: 42 [631048/888800 71.00%] train loss: 1.4467713299382012e-05 \n",
      "epoch: 42 [632159/888800 71.12%] train loss: 1.4428156646317802e-05 \n",
      "epoch: 42 [633270/888800 71.25%] train loss: 1.4526932318403851e-05 \n",
      "epoch: 42 [634381/888800 71.38%] train loss: 1.4503675629384816e-05 \n",
      "epoch: 42 [635492/888800 71.50%] train loss: 1.4136647223494947e-05 \n",
      "epoch: 42 [636603/888800 71.62%] train loss: 1.4142437976261135e-05 \n",
      "epoch: 42 [637714/888800 71.75%] train loss: 1.3797906831314322e-05 \n",
      "epoch: 42 [638825/888800 71.88%] train loss: 1.2786370461981278e-05 \n",
      "epoch: 42 [639936/888800 72.00%] train loss: 1.457305461372016e-05 \n",
      "epoch: 42 [641047/888800 72.12%] train loss: 1.302130021940684e-05 \n",
      "epoch: 42 [642158/888800 72.25%] train loss: 1.558950316393748e-05 \n",
      "epoch: 42 [643269/888800 72.38%] train loss: 1.4720679246238433e-05 \n",
      "epoch: 42 [644380/888800 72.50%] train loss: 1.4682271284982562e-05 \n",
      "epoch: 42 [645491/888800 72.62%] train loss: 1.48731232911814e-05 \n",
      "epoch: 42 [646602/888800 72.75%] train loss: 1.3993836546433158e-05 \n",
      "epoch: 42 [647713/888800 72.88%] train loss: 1.357440669380594e-05 \n",
      "epoch: 42 [648824/888800 73.00%] train loss: 1.3619561286759563e-05 \n",
      "epoch: 42 [649935/888800 73.12%] train loss: 1.3619348464999348e-05 \n",
      "epoch: 42 [651046/888800 73.25%] train loss: 1.4656881830887869e-05 \n",
      "epoch: 42 [652157/888800 73.38%] train loss: 1.4418727914744522e-05 \n",
      "epoch: 42 [653268/888800 73.50%] train loss: 1.4963938156142831e-05 \n",
      "epoch: 42 [654379/888800 73.62%] train loss: 1.3700502677238546e-05 \n",
      "epoch: 42 [655490/888800 73.75%] train loss: 1.5137088666961063e-05 \n",
      "epoch: 42 [656601/888800 73.88%] train loss: 1.4739362995896954e-05 \n",
      "epoch: 42 [657712/888800 74.00%] train loss: 1.3115560250298586e-05 \n",
      "epoch: 42 [658823/888800 74.12%] train loss: 1.4403496606973931e-05 \n",
      "epoch: 42 [659934/888800 74.25%] train loss: 1.3738242159888614e-05 \n",
      "epoch: 42 [661045/888800 74.38%] train loss: 1.4519543583446648e-05 \n",
      "epoch: 42 [662156/888800 74.50%] train loss: 1.3248255527287256e-05 \n",
      "epoch: 42 [663267/888800 74.62%] train loss: 1.454001267120475e-05 \n",
      "epoch: 42 [664378/888800 74.75%] train loss: 1.310950392507948e-05 \n",
      "epoch: 42 [665489/888800 74.88%] train loss: 1.5063928003655747e-05 \n",
      "epoch: 42 [666600/888800 75.00%] train loss: 1.4701867257826962e-05 \n",
      "epoch: 42 [667711/888800 75.12%] train loss: 1.3624868188344408e-05 \n",
      "epoch: 42 [668822/888800 75.25%] train loss: 1.3932717592979316e-05 \n",
      "epoch: 42 [669933/888800 75.38%] train loss: 1.4471799659077078e-05 \n",
      "epoch: 42 [671044/888800 75.50%] train loss: 1.3989527360536158e-05 \n",
      "epoch: 42 [672155/888800 75.62%] train loss: 1.4362003639689647e-05 \n",
      "epoch: 42 [673266/888800 75.75%] train loss: 1.4338683286041487e-05 \n",
      "epoch: 42 [674377/888800 75.88%] train loss: 1.400014207320055e-05 \n",
      "epoch: 42 [675488/888800 76.00%] train loss: 1.3702419892069884e-05 \n",
      "epoch: 42 [676599/888800 76.12%] train loss: 1.4332288628793322e-05 \n",
      "epoch: 42 [677710/888800 76.25%] train loss: 1.4654534425062593e-05 \n",
      "epoch: 42 [678821/888800 76.38%] train loss: 1.46988086271449e-05 \n",
      "epoch: 42 [679932/888800 76.50%] train loss: 1.3833101547788829e-05 \n",
      "epoch: 42 [681043/888800 76.62%] train loss: 1.453720142308157e-05 \n",
      "epoch: 42 [682154/888800 76.75%] train loss: 1.2806394806830212e-05 \n",
      "epoch: 42 [683265/888800 76.88%] train loss: 1.2370811418804806e-05 \n",
      "epoch: 42 [684376/888800 77.00%] train loss: 1.4208048014552332e-05 \n",
      "epoch: 42 [685487/888800 77.12%] train loss: 1.4410281437449157e-05 \n",
      "epoch: 42 [686598/888800 77.25%] train loss: 1.4511535482597537e-05 \n",
      "epoch: 42 [687709/888800 77.38%] train loss: 1.4562006072083022e-05 \n",
      "epoch: 42 [688820/888800 77.50%] train loss: 1.4861120689602103e-05 \n",
      "epoch: 42 [689931/888800 77.62%] train loss: 1.4515592738462146e-05 \n",
      "epoch: 42 [691042/888800 77.75%] train loss: 1.5401337805087678e-05 \n",
      "epoch: 42 [692153/888800 77.88%] train loss: 1.3689498700841796e-05 \n",
      "epoch: 42 [693264/888800 78.00%] train loss: 1.4734755495737772e-05 \n",
      "epoch: 42 [694375/888800 78.12%] train loss: 1.4822035154793411e-05 \n",
      "epoch: 42 [695486/888800 78.25%] train loss: 1.482901643612422e-05 \n",
      "epoch: 42 [696597/888800 78.38%] train loss: 1.3707683137909044e-05 \n",
      "epoch: 42 [697708/888800 78.50%] train loss: 1.3451521226670593e-05 \n",
      "epoch: 42 [698819/888800 78.62%] train loss: 1.4185330655891448e-05 \n",
      "epoch: 42 [699930/888800 78.75%] train loss: 1.4150473361951299e-05 \n",
      "epoch: 42 [701041/888800 78.88%] train loss: 1.4474245290330146e-05 \n",
      "epoch: 42 [702152/888800 79.00%] train loss: 1.378623528580647e-05 \n",
      "epoch: 42 [703263/888800 79.12%] train loss: 1.5884656022535637e-05 \n",
      "epoch: 42 [704374/888800 79.25%] train loss: 1.3860380931873806e-05 \n",
      "epoch: 42 [705485/888800 79.38%] train loss: 1.421694196324097e-05 \n",
      "epoch: 42 [706596/888800 79.50%] train loss: 1.5050392903503962e-05 \n",
      "epoch: 42 [707707/888800 79.62%] train loss: 1.4600354006688576e-05 \n",
      "epoch: 42 [708818/888800 79.75%] train loss: 1.3544636203732807e-05 \n",
      "epoch: 42 [709929/888800 79.88%] train loss: 1.3150988706911448e-05 \n",
      "epoch: 42 [711040/888800 80.00%] train loss: 1.5864539818721823e-05 \n",
      "epoch: 42 [712151/888800 80.12%] train loss: 1.5508721844526008e-05 \n",
      "epoch: 42 [713262/888800 80.25%] train loss: 1.4945583643566351e-05 \n",
      "epoch: 42 [714373/888800 80.38%] train loss: 1.450811032555066e-05 \n",
      "epoch: 42 [715484/888800 80.50%] train loss: 1.6022766430978663e-05 \n",
      "epoch: 42 [716595/888800 80.62%] train loss: 1.7829241187428124e-05 \n",
      "epoch: 42 [717706/888800 80.75%] train loss: 1.4041439499123953e-05 \n",
      "epoch: 42 [718817/888800 80.88%] train loss: 1.645807242312003e-05 \n",
      "epoch: 42 [719928/888800 81.00%] train loss: 1.3921538993599825e-05 \n",
      "epoch: 42 [721039/888800 81.12%] train loss: 1.5338664525188506e-05 \n",
      "epoch: 42 [722150/888800 81.25%] train loss: 1.3795395716442727e-05 \n",
      "epoch: 42 [723261/888800 81.38%] train loss: 1.6407157090725377e-05 \n",
      "epoch: 42 [724372/888800 81.50%] train loss: 1.3387714716373011e-05 \n",
      "epoch: 42 [725483/888800 81.62%] train loss: 1.4885881682857871e-05 \n",
      "epoch: 42 [726594/888800 81.75%] train loss: 1.4940290384402033e-05 \n",
      "epoch: 42 [727705/888800 81.88%] train loss: 1.4921735782991163e-05 \n",
      "epoch: 42 [728816/888800 82.00%] train loss: 1.5293466276489198e-05 \n",
      "epoch: 42 [729927/888800 82.12%] train loss: 1.4027547877049074e-05 \n",
      "epoch: 42 [731038/888800 82.25%] train loss: 1.3225929251348134e-05 \n",
      "epoch: 42 [732149/888800 82.38%] train loss: 1.3159072295820806e-05 \n",
      "epoch: 42 [733260/888800 82.50%] train loss: 1.4536181879520882e-05 \n",
      "epoch: 42 [734371/888800 82.62%] train loss: 1.411838093190454e-05 \n",
      "epoch: 42 [735482/888800 82.75%] train loss: 1.3240792213764507e-05 \n",
      "epoch: 42 [736593/888800 82.88%] train loss: 1.3232246601546649e-05 \n",
      "epoch: 42 [737704/888800 83.00%] train loss: 1.4653321159130428e-05 \n",
      "epoch: 42 [738815/888800 83.12%] train loss: 1.436400089005474e-05 \n",
      "epoch: 42 [739926/888800 83.25%] train loss: 1.357443215965759e-05 \n",
      "epoch: 42 [741037/888800 83.38%] train loss: 1.357294422632549e-05 \n",
      "epoch: 42 [742148/888800 83.50%] train loss: 1.5962859833962284e-05 \n",
      "epoch: 42 [743259/888800 83.62%] train loss: 1.3453513020067476e-05 \n",
      "epoch: 42 [744370/888800 83.75%] train loss: 1.3254677469376475e-05 \n",
      "epoch: 42 [745481/888800 83.88%] train loss: 1.3912974281993229e-05 \n",
      "epoch: 42 [746592/888800 84.00%] train loss: 1.4045128409634344e-05 \n",
      "epoch: 42 [747703/888800 84.12%] train loss: 1.347913894278463e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 [748814/888800 84.25%] train loss: 1.447942395316204e-05 \n",
      "epoch: 42 [749925/888800 84.38%] train loss: 1.288031580770621e-05 \n",
      "epoch: 42 [751036/888800 84.50%] train loss: 1.3289850357978139e-05 \n",
      "epoch: 42 [752147/888800 84.62%] train loss: 1.4801021279708948e-05 \n",
      "epoch: 42 [753258/888800 84.75%] train loss: 1.3830139323545154e-05 \n",
      "epoch: 42 [754369/888800 84.88%] train loss: 1.4582177755073644e-05 \n",
      "epoch: 42 [755480/888800 85.00%] train loss: 1.5019302736618556e-05 \n",
      "epoch: 42 [756591/888800 85.12%] train loss: 1.370454174320912e-05 \n",
      "epoch: 42 [757702/888800 85.25%] train loss: 1.4462239960266743e-05 \n",
      "epoch: 42 [758813/888800 85.38%] train loss: 1.5291414456442e-05 \n",
      "epoch: 42 [759924/888800 85.50%] train loss: 1.4276640285970643e-05 \n",
      "epoch: 42 [761035/888800 85.62%] train loss: 1.3482841495715547e-05 \n",
      "epoch: 42 [762146/888800 85.75%] train loss: 1.4200376426742878e-05 \n",
      "epoch: 42 [763257/888800 85.88%] train loss: 1.3143619071342982e-05 \n",
      "epoch: 42 [764368/888800 86.00%] train loss: 1.3455903172143735e-05 \n",
      "epoch: 42 [765479/888800 86.12%] train loss: 1.4315910448203795e-05 \n",
      "epoch: 42 [766590/888800 86.25%] train loss: 1.405780221830355e-05 \n",
      "epoch: 42 [767701/888800 86.38%] train loss: 1.5161342162173241e-05 \n",
      "epoch: 42 [768812/888800 86.50%] train loss: 1.4395613106898963e-05 \n",
      "epoch: 42 [769923/888800 86.62%] train loss: 1.5557563529000618e-05 \n",
      "epoch: 42 [771034/888800 86.75%] train loss: 1.372960650769528e-05 \n",
      "epoch: 42 [772145/888800 86.88%] train loss: 1.5464533134945668e-05 \n",
      "epoch: 42 [773256/888800 87.00%] train loss: 1.4999372069723904e-05 \n",
      "epoch: 42 [774367/888800 87.12%] train loss: 1.5450379578396678e-05 \n",
      "epoch: 42 [775478/888800 87.25%] train loss: 1.4879808986734133e-05 \n",
      "epoch: 42 [776589/888800 87.38%] train loss: 1.4690584066556767e-05 \n",
      "epoch: 42 [777700/888800 87.50%] train loss: 1.3928927728557028e-05 \n",
      "epoch: 42 [778811/888800 87.62%] train loss: 1.3630861758429091e-05 \n",
      "epoch: 42 [779922/888800 87.75%] train loss: 1.3588756701210514e-05 \n",
      "epoch: 42 [781033/888800 87.88%] train loss: 1.39616422529798e-05 \n",
      "epoch: 42 [782144/888800 88.00%] train loss: 1.3906272215535864e-05 \n",
      "epoch: 42 [783255/888800 88.12%] train loss: 1.3421320545603521e-05 \n",
      "epoch: 42 [784366/888800 88.25%] train loss: 1.364764648315031e-05 \n",
      "epoch: 42 [785477/888800 88.38%] train loss: 1.3441304872685578e-05 \n",
      "epoch: 42 [786588/888800 88.50%] train loss: 1.394730952597456e-05 \n",
      "epoch: 42 [787699/888800 88.62%] train loss: 1.5167685887718108e-05 \n",
      "epoch: 42 [788810/888800 88.75%] train loss: 1.4900033420417458e-05 \n",
      "epoch: 42 [789921/888800 88.88%] train loss: 1.3349695109354798e-05 \n",
      "epoch: 42 [791032/888800 89.00%] train loss: 1.395580420648912e-05 \n",
      "epoch: 42 [792143/888800 89.12%] train loss: 1.495415017416235e-05 \n",
      "epoch: 42 [793254/888800 89.25%] train loss: 1.50569785546395e-05 \n",
      "epoch: 42 [794365/888800 89.38%] train loss: 1.5814999642316252e-05 \n",
      "epoch: 42 [795476/888800 89.50%] train loss: 1.4034524610906374e-05 \n",
      "epoch: 42 [796587/888800 89.62%] train loss: 1.4967512470320798e-05 \n",
      "epoch: 42 [797698/888800 89.75%] train loss: 1.3851778021489736e-05 \n",
      "epoch: 42 [798809/888800 89.88%] train loss: 1.4211188499757554e-05 \n",
      "epoch: 42 [799920/888800 90.00%] train loss: 1.418141255271621e-05 \n",
      "epoch: 42 [801031/888800 90.12%] train loss: 1.4207213098416105e-05 \n",
      "epoch: 42 [802142/888800 90.25%] train loss: 1.4063642083783634e-05 \n",
      "epoch: 42 [803253/888800 90.38%] train loss: 1.4421997548197396e-05 \n",
      "epoch: 42 [804364/888800 90.50%] train loss: 1.4716043551743496e-05 \n",
      "epoch: 42 [805475/888800 90.62%] train loss: 1.4238643416319974e-05 \n",
      "epoch: 42 [806586/888800 90.75%] train loss: 1.3351701454666909e-05 \n",
      "epoch: 42 [807697/888800 90.88%] train loss: 1.4794157323194668e-05 \n",
      "epoch: 42 [808808/888800 91.00%] train loss: 1.3130311344866641e-05 \n",
      "epoch: 42 [809919/888800 91.12%] train loss: 1.4523518984788097e-05 \n",
      "epoch: 42 [811030/888800 91.25%] train loss: 1.4243746591091622e-05 \n",
      "epoch: 42 [812141/888800 91.38%] train loss: 1.4251147149479948e-05 \n",
      "epoch: 42 [813252/888800 91.50%] train loss: 1.4919965906301513e-05 \n",
      "epoch: 42 [814363/888800 91.62%] train loss: 1.4800973985984456e-05 \n",
      "epoch: 42 [815474/888800 91.75%] train loss: 1.4433674550673459e-05 \n",
      "epoch: 42 [816585/888800 91.88%] train loss: 1.373160193907097e-05 \n",
      "epoch: 42 [817696/888800 92.00%] train loss: 1.4272306543716695e-05 \n",
      "epoch: 42 [818807/888800 92.12%] train loss: 1.43051402119454e-05 \n",
      "epoch: 42 [819918/888800 92.25%] train loss: 1.3930122804595158e-05 \n",
      "epoch: 42 [821029/888800 92.38%] train loss: 1.5235377759381663e-05 \n",
      "epoch: 42 [822140/888800 92.50%] train loss: 1.3656863302458078e-05 \n",
      "epoch: 42 [823251/888800 92.62%] train loss: 1.4077599189477041e-05 \n",
      "epoch: 42 [824362/888800 92.75%] train loss: 1.5847181202843785e-05 \n",
      "epoch: 42 [825473/888800 92.88%] train loss: 1.3891745766159147e-05 \n",
      "epoch: 42 [826584/888800 93.00%] train loss: 1.369933488604147e-05 \n",
      "epoch: 42 [827695/888800 93.12%] train loss: 1.4555348570866045e-05 \n",
      "epoch: 42 [828806/888800 93.25%] train loss: 1.4762319551664405e-05 \n",
      "epoch: 42 [829917/888800 93.38%] train loss: 1.3830057469021995e-05 \n",
      "epoch: 42 [831028/888800 93.50%] train loss: 1.5238265405059792e-05 \n",
      "epoch: 42 [832139/888800 93.62%] train loss: 1.390190936945146e-05 \n",
      "epoch: 42 [833250/888800 93.75%] train loss: 1.3736723303736653e-05 \n",
      "epoch: 42 [834361/888800 93.88%] train loss: 1.3359065633267164e-05 \n",
      "epoch: 42 [835472/888800 94.00%] train loss: 1.4371395991474856e-05 \n",
      "epoch: 42 [836583/888800 94.12%] train loss: 1.630989572731778e-05 \n",
      "epoch: 42 [837694/888800 94.25%] train loss: 1.4116684724285733e-05 \n",
      "epoch: 42 [838805/888800 94.38%] train loss: 1.416655140928924e-05 \n",
      "epoch: 42 [839916/888800 94.50%] train loss: 1.402799716743175e-05 \n",
      "epoch: 42 [841027/888800 94.62%] train loss: 1.4053550330572762e-05 \n",
      "epoch: 42 [842138/888800 94.75%] train loss: 1.5043785424495582e-05 \n",
      "epoch: 42 [843249/888800 94.88%] train loss: 1.3790669981972314e-05 \n",
      "epoch: 42 [844360/888800 95.00%] train loss: 1.4267047845351044e-05 \n",
      "epoch: 42 [845471/888800 95.12%] train loss: 1.4361939975060523e-05 \n",
      "epoch: 42 [846582/888800 95.25%] train loss: 1.3896870768803637e-05 \n",
      "epoch: 42 [847693/888800 95.38%] train loss: 1.4597915651393123e-05 \n",
      "epoch: 42 [848804/888800 95.50%] train loss: 1.5107108993106522e-05 \n",
      "epoch: 42 [849915/888800 95.62%] train loss: 1.4312002349470276e-05 \n",
      "epoch: 42 [851026/888800 95.75%] train loss: 1.4541753444063943e-05 \n",
      "epoch: 42 [852137/888800 95.88%] train loss: 1.5329731468227692e-05 \n",
      "epoch: 42 [853248/888800 96.00%] train loss: 1.5351519323303364e-05 \n",
      "epoch: 42 [854359/888800 96.12%] train loss: 1.4207471394911408e-05 \n",
      "epoch: 42 [855470/888800 96.25%] train loss: 1.3084428246656898e-05 \n",
      "epoch: 42 [856581/888800 96.38%] train loss: 1.374979819956934e-05 \n",
      "epoch: 42 [857692/888800 96.50%] train loss: 1.4243738405639306e-05 \n",
      "epoch: 42 [858803/888800 96.62%] train loss: 1.5450834325747564e-05 \n",
      "epoch: 42 [859914/888800 96.75%] train loss: 1.520741352578625e-05 \n",
      "epoch: 42 [861025/888800 96.88%] train loss: 1.4803599697188474e-05 \n",
      "epoch: 42 [862136/888800 97.00%] train loss: 1.3159282389096916e-05 \n",
      "epoch: 42 [863247/888800 97.12%] train loss: 1.4528283827530686e-05 \n",
      "epoch: 42 [864358/888800 97.25%] train loss: 1.42240369314095e-05 \n",
      "epoch: 42 [865469/888800 97.38%] train loss: 1.3340571968001314e-05 \n",
      "epoch: 42 [866580/888800 97.50%] train loss: 1.351547416561516e-05 \n",
      "epoch: 42 [867691/888800 97.62%] train loss: 1.4591800209018402e-05 \n",
      "epoch: 42 [868802/888800 97.75%] train loss: 1.4215985174814705e-05 \n",
      "epoch: 42 [869913/888800 97.88%] train loss: 1.3658098396263085e-05 \n",
      "epoch: 42 [871024/888800 98.00%] train loss: 1.3384193152887747e-05 \n",
      "epoch: 42 [872135/888800 98.12%] train loss: 1.490646263846429e-05 \n",
      "epoch: 42 [873246/888800 98.25%] train loss: 1.4630801160819829e-05 \n",
      "epoch: 42 [874357/888800 98.38%] train loss: 1.4354948689287994e-05 \n",
      "epoch: 42 [875468/888800 98.50%] train loss: 1.5312194591388106e-05 \n",
      "epoch: 42 [876579/888800 98.62%] train loss: 1.486351993662538e-05 \n",
      "epoch: 42 [877690/888800 98.75%] train loss: 1.4251123502617702e-05 \n",
      "epoch: 42 [878801/888800 98.88%] train loss: 1.218916349898791e-05 \n",
      "epoch: 42 [879912/888800 99.00%] train loss: 1.360067653877195e-05 \n",
      "epoch: 42 [881023/888800 99.12%] train loss: 1.4367873518494889e-05 \n",
      "epoch: 42 [882134/888800 99.25%] train loss: 1.6511979993083514e-05 \n",
      "epoch: 42 [883245/888800 99.38%] train loss: 1.365905518468935e-05 \n",
      "epoch: 42 [884356/888800 99.50%] train loss: 1.533452632429544e-05 \n",
      "epoch: 42 [885467/888800 99.62%] train loss: 1.4136568097455893e-05 \n",
      "epoch: 42 [886578/888800 99.75%] train loss: 1.5110629647097085e-05 \n",
      "epoch: 42 [887689/888800 99.88%] train loss: 1.4872231076878961e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [0/888800 0.00%] train loss: 1.432572116755182e-05 \n",
      "epoch: 43 [1111/888800 0.12%] train loss: 1.4012272913532797e-05 \n",
      "epoch: 43 [2222/888800 0.25%] train loss: 1.2898944987682626e-05 \n",
      "epoch: 43 [3333/888800 0.38%] train loss: 1.470983352191979e-05 \n",
      "epoch: 43 [4444/888800 0.50%] train loss: 1.465747209294932e-05 \n",
      "epoch: 43 [5555/888800 0.62%] train loss: 1.5348125089076348e-05 \n",
      "epoch: 43 [6666/888800 0.75%] train loss: 1.4544462828780524e-05 \n",
      "epoch: 43 [7777/888800 0.88%] train loss: 1.4445606211666018e-05 \n",
      "epoch: 43 [8888/888800 1.00%] train loss: 1.419698128302116e-05 \n",
      "epoch: 43 [9999/888800 1.12%] train loss: 1.3507652511179913e-05 \n",
      "epoch: 43 [11110/888800 1.25%] train loss: 1.4410722542379517e-05 \n",
      "epoch: 43 [12221/888800 1.38%] train loss: 1.3997263522469439e-05 \n",
      "epoch: 43 [13332/888800 1.50%] train loss: 1.319552757195197e-05 \n",
      "epoch: 43 [14443/888800 1.62%] train loss: 1.5256926417350769e-05 \n",
      "epoch: 43 [15554/888800 1.75%] train loss: 1.4977283171901945e-05 \n",
      "epoch: 43 [16665/888800 1.88%] train loss: 1.4460785678238608e-05 \n",
      "epoch: 43 [17776/888800 2.00%] train loss: 1.22377387015149e-05 \n",
      "epoch: 43 [18887/888800 2.12%] train loss: 1.3734908861806616e-05 \n",
      "epoch: 43 [19998/888800 2.25%] train loss: 1.3546178706747014e-05 \n",
      "epoch: 43 [21109/888800 2.38%] train loss: 1.4462752915278543e-05 \n",
      "epoch: 43 [22220/888800 2.50%] train loss: 1.4207382264430635e-05 \n",
      "epoch: 43 [23331/888800 2.62%] train loss: 1.3364949154492933e-05 \n",
      "epoch: 43 [24442/888800 2.75%] train loss: 1.4307473975350149e-05 \n",
      "epoch: 43 [25553/888800 2.88%] train loss: 1.4034362720849458e-05 \n",
      "epoch: 43 [26664/888800 3.00%] train loss: 1.4289767932496034e-05 \n",
      "epoch: 43 [27775/888800 3.12%] train loss: 1.4108677532931324e-05 \n",
      "epoch: 43 [28886/888800 3.25%] train loss: 1.5063143109728117e-05 \n",
      "epoch: 43 [29997/888800 3.38%] train loss: 1.3279348422656767e-05 \n",
      "epoch: 43 [31108/888800 3.50%] train loss: 1.453499044146156e-05 \n",
      "epoch: 43 [32219/888800 3.62%] train loss: 1.4881635252095293e-05 \n",
      "epoch: 43 [33330/888800 3.75%] train loss: 1.4007071513333358e-05 \n",
      "epoch: 43 [34441/888800 3.88%] train loss: 1.3641719306178857e-05 \n",
      "epoch: 43 [35552/888800 4.00%] train loss: 1.4271988220571075e-05 \n",
      "epoch: 43 [36663/888800 4.12%] train loss: 1.2894054634671193e-05 \n",
      "epoch: 43 [37774/888800 4.25%] train loss: 1.3397490874922369e-05 \n",
      "epoch: 43 [38885/888800 4.38%] train loss: 1.4316936358227395e-05 \n",
      "epoch: 43 [39996/888800 4.50%] train loss: 1.5259232895914465e-05 \n",
      "epoch: 43 [41107/888800 4.62%] train loss: 1.4031559658178594e-05 \n",
      "epoch: 43 [42218/888800 4.75%] train loss: 1.4546715647156816e-05 \n",
      "epoch: 43 [43329/888800 4.88%] train loss: 1.4541789823852014e-05 \n",
      "epoch: 43 [44440/888800 5.00%] train loss: 1.3704607226827648e-05 \n",
      "epoch: 43 [45551/888800 5.12%] train loss: 1.3540722648031078e-05 \n",
      "epoch: 43 [46662/888800 5.25%] train loss: 1.3018497156735975e-05 \n",
      "epoch: 43 [47773/888800 5.38%] train loss: 1.4103004104981665e-05 \n",
      "epoch: 43 [48884/888800 5.50%] train loss: 1.3345800653041806e-05 \n",
      "epoch: 43 [49995/888800 5.62%] train loss: 1.4187488886818755e-05 \n",
      "epoch: 43 [51106/888800 5.75%] train loss: 1.2434569725883193e-05 \n",
      "epoch: 43 [52217/888800 5.88%] train loss: 1.366502601740649e-05 \n",
      "epoch: 43 [53328/888800 6.00%] train loss: 1.4169089809001889e-05 \n",
      "epoch: 43 [54439/888800 6.12%] train loss: 1.467441143176984e-05 \n",
      "epoch: 43 [55550/888800 6.25%] train loss: 1.4887718862155452e-05 \n",
      "epoch: 43 [56661/888800 6.38%] train loss: 1.523974697192898e-05 \n",
      "epoch: 43 [57772/888800 6.50%] train loss: 1.3083614248898812e-05 \n",
      "epoch: 43 [58883/888800 6.62%] train loss: 1.334504850092344e-05 \n",
      "epoch: 43 [59994/888800 6.75%] train loss: 1.4181674487190321e-05 \n",
      "epoch: 43 [61105/888800 6.88%] train loss: 1.4108425602898933e-05 \n",
      "epoch: 43 [62216/888800 7.00%] train loss: 1.4429348993871827e-05 \n",
      "epoch: 43 [63327/888800 7.12%] train loss: 1.447644353902433e-05 \n",
      "epoch: 43 [64438/888800 7.25%] train loss: 1.3206825315137394e-05 \n",
      "epoch: 43 [65549/888800 7.38%] train loss: 1.4820991964370478e-05 \n",
      "epoch: 43 [66660/888800 7.50%] train loss: 1.499339850852266e-05 \n",
      "epoch: 43 [67771/888800 7.62%] train loss: 1.3594487427326385e-05 \n",
      "epoch: 43 [68882/888800 7.75%] train loss: 1.5054956747917458e-05 \n",
      "epoch: 43 [69993/888800 7.88%] train loss: 1.4184452084009536e-05 \n",
      "epoch: 43 [71104/888800 8.00%] train loss: 1.4154004020383582e-05 \n",
      "epoch: 43 [72215/888800 8.12%] train loss: 1.4493691196548752e-05 \n",
      "epoch: 43 [73326/888800 8.25%] train loss: 1.4064902643440291e-05 \n",
      "epoch: 43 [74437/888800 8.38%] train loss: 1.370720383420121e-05 \n",
      "epoch: 43 [75548/888800 8.50%] train loss: 1.4975312296883203e-05 \n",
      "epoch: 43 [76659/888800 8.62%] train loss: 1.4449325135501567e-05 \n",
      "epoch: 43 [77770/888800 8.75%] train loss: 1.4931903024262283e-05 \n",
      "epoch: 43 [78881/888800 8.88%] train loss: 1.536071067675948e-05 \n",
      "epoch: 43 [79992/888800 9.00%] train loss: 1.3792489880870562e-05 \n",
      "epoch: 43 [81103/888800 9.12%] train loss: 1.4431034287554212e-05 \n",
      "epoch: 43 [82214/888800 9.25%] train loss: 1.4024474694451783e-05 \n",
      "epoch: 43 [83325/888800 9.38%] train loss: 1.54470053530531e-05 \n",
      "epoch: 43 [84436/888800 9.50%] train loss: 1.491615785198519e-05 \n",
      "epoch: 43 [85547/888800 9.62%] train loss: 1.524404069641605e-05 \n",
      "epoch: 43 [86658/888800 9.75%] train loss: 1.3734763342654333e-05 \n",
      "epoch: 43 [87769/888800 9.88%] train loss: 1.3899635632697027e-05 \n",
      "epoch: 43 [88880/888800 10.00%] train loss: 1.5777983207954094e-05 \n",
      "epoch: 43 [89991/888800 10.12%] train loss: 1.4181117876432836e-05 \n",
      "epoch: 43 [91102/888800 10.25%] train loss: 1.5645264284103177e-05 \n",
      "epoch: 43 [92213/888800 10.38%] train loss: 1.4656999155704398e-05 \n",
      "epoch: 43 [93324/888800 10.50%] train loss: 1.5480733054573648e-05 \n",
      "epoch: 43 [94435/888800 10.62%] train loss: 1.531889029138256e-05 \n",
      "epoch: 43 [95546/888800 10.75%] train loss: 1.446187434339663e-05 \n",
      "epoch: 43 [96657/888800 10.88%] train loss: 1.3206806215748657e-05 \n",
      "epoch: 43 [97768/888800 11.00%] train loss: 1.5297282516257837e-05 \n",
      "epoch: 43 [98879/888800 11.12%] train loss: 1.5520325177931227e-05 \n",
      "epoch: 43 [99990/888800 11.25%] train loss: 1.4614766769227572e-05 \n",
      "epoch: 43 [101101/888800 11.38%] train loss: 1.4779502635065e-05 \n",
      "epoch: 43 [102212/888800 11.50%] train loss: 1.425142545485869e-05 \n",
      "epoch: 43 [103323/888800 11.62%] train loss: 1.3050084817223251e-05 \n",
      "epoch: 43 [104434/888800 11.75%] train loss: 1.3827303519065026e-05 \n",
      "epoch: 43 [105545/888800 11.88%] train loss: 1.297804010391701e-05 \n",
      "epoch: 43 [106656/888800 12.00%] train loss: 1.4000382179801818e-05 \n",
      "epoch: 43 [107767/888800 12.12%] train loss: 1.3977679373056162e-05 \n",
      "epoch: 43 [108878/888800 12.25%] train loss: 1.5806203009560704e-05 \n",
      "epoch: 43 [109989/888800 12.38%] train loss: 1.3423902601061855e-05 \n",
      "epoch: 43 [111100/888800 12.50%] train loss: 1.4200396435626317e-05 \n",
      "epoch: 43 [112211/888800 12.62%] train loss: 1.4651020137534942e-05 \n",
      "epoch: 43 [113322/888800 12.75%] train loss: 1.3785140254185535e-05 \n",
      "epoch: 43 [114433/888800 12.88%] train loss: 1.5231998077069875e-05 \n",
      "epoch: 43 [115544/888800 13.00%] train loss: 1.6360083463951014e-05 \n",
      "epoch: 43 [116655/888800 13.12%] train loss: 1.4690638636238873e-05 \n",
      "epoch: 43 [117766/888800 13.25%] train loss: 1.4081088011153042e-05 \n",
      "epoch: 43 [118877/888800 13.38%] train loss: 1.4760867998120375e-05 \n",
      "epoch: 43 [119988/888800 13.50%] train loss: 1.391317982779583e-05 \n",
      "epoch: 43 [121099/888800 13.62%] train loss: 1.374823295918759e-05 \n",
      "epoch: 43 [122210/888800 13.75%] train loss: 1.3981580195832066e-05 \n",
      "epoch: 43 [123321/888800 13.88%] train loss: 1.3797600331599824e-05 \n",
      "epoch: 43 [124432/888800 14.00%] train loss: 1.4447178728005383e-05 \n",
      "epoch: 43 [125543/888800 14.12%] train loss: 1.4224875485524535e-05 \n",
      "epoch: 43 [126654/888800 14.25%] train loss: 1.4317969544208609e-05 \n",
      "epoch: 43 [127765/888800 14.38%] train loss: 1.5006468856881838e-05 \n",
      "epoch: 43 [128876/888800 14.50%] train loss: 1.4830978216195945e-05 \n",
      "epoch: 43 [129987/888800 14.62%] train loss: 1.4276542970037553e-05 \n",
      "epoch: 43 [131098/888800 14.75%] train loss: 1.4834726243861951e-05 \n",
      "epoch: 43 [132209/888800 14.88%] train loss: 1.4309813195723109e-05 \n",
      "epoch: 43 [133320/888800 15.00%] train loss: 1.576915747136809e-05 \n",
      "epoch: 43 [134431/888800 15.12%] train loss: 1.4504319551633671e-05 \n",
      "epoch: 43 [135542/888800 15.25%] train loss: 1.5955218259477988e-05 \n",
      "epoch: 43 [136653/888800 15.38%] train loss: 1.432566477888031e-05 \n",
      "epoch: 43 [137764/888800 15.50%] train loss: 1.3926375686423853e-05 \n",
      "epoch: 43 [138875/888800 15.62%] train loss: 1.313874963670969e-05 \n",
      "epoch: 43 [139986/888800 15.75%] train loss: 1.4184678548190277e-05 \n",
      "epoch: 43 [141097/888800 15.88%] train loss: 1.3587687135441229e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [142208/888800 16.00%] train loss: 1.5146179066505283e-05 \n",
      "epoch: 43 [143319/888800 16.12%] train loss: 1.366360538668232e-05 \n",
      "epoch: 43 [144430/888800 16.25%] train loss: 1.3246219168649986e-05 \n",
      "epoch: 43 [145541/888800 16.38%] train loss: 1.4208576430974063e-05 \n",
      "epoch: 43 [146652/888800 16.50%] train loss: 1.4385540453076828e-05 \n",
      "epoch: 43 [147763/888800 16.62%] train loss: 1.4058726264920551e-05 \n",
      "epoch: 43 [148874/888800 16.75%] train loss: 1.5866562534938566e-05 \n",
      "epoch: 43 [149985/888800 16.88%] train loss: 1.4705397916259244e-05 \n",
      "epoch: 43 [151096/888800 17.00%] train loss: 1.3516471881303005e-05 \n",
      "epoch: 43 [152207/888800 17.12%] train loss: 1.5688112398493104e-05 \n",
      "epoch: 43 [153318/888800 17.25%] train loss: 1.5543322660960257e-05 \n",
      "epoch: 43 [154429/888800 17.38%] train loss: 1.588404666108545e-05 \n",
      "epoch: 43 [155540/888800 17.50%] train loss: 1.506075932411477e-05 \n",
      "epoch: 43 [156651/888800 17.62%] train loss: 1.506818261987064e-05 \n",
      "epoch: 43 [157762/888800 17.75%] train loss: 1.557951509312261e-05 \n",
      "epoch: 43 [158873/888800 17.88%] train loss: 1.468068512622267e-05 \n",
      "epoch: 43 [159984/888800 18.00%] train loss: 1.5214039194688667e-05 \n",
      "epoch: 43 [161095/888800 18.12%] train loss: 1.4333246326714288e-05 \n",
      "epoch: 43 [162206/888800 18.25%] train loss: 1.727708149701357e-05 \n",
      "epoch: 43 [163317/888800 18.38%] train loss: 1.5393821740872227e-05 \n",
      "epoch: 43 [164428/888800 18.50%] train loss: 1.533643990114797e-05 \n",
      "epoch: 43 [165539/888800 18.62%] train loss: 1.3690636478713714e-05 \n",
      "epoch: 43 [166650/888800 18.75%] train loss: 1.4996069694461767e-05 \n",
      "epoch: 43 [167761/888800 18.88%] train loss: 1.4484482562693302e-05 \n",
      "epoch: 43 [168872/888800 19.00%] train loss: 1.3419660717772786e-05 \n",
      "epoch: 43 [169983/888800 19.12%] train loss: 1.598980452399701e-05 \n",
      "epoch: 43 [171094/888800 19.25%] train loss: 1.2762859114445746e-05 \n",
      "epoch: 43 [172205/888800 19.38%] train loss: 1.4944067515898496e-05 \n",
      "epoch: 43 [173316/888800 19.50%] train loss: 1.4621731679653749e-05 \n",
      "epoch: 43 [174427/888800 19.62%] train loss: 1.58571401698282e-05 \n",
      "epoch: 43 [175538/888800 19.75%] train loss: 1.4467941582552157e-05 \n",
      "epoch: 43 [176649/888800 19.88%] train loss: 1.5715695553808473e-05 \n",
      "epoch: 43 [177760/888800 20.00%] train loss: 1.473844258725876e-05 \n",
      "epoch: 43 [178871/888800 20.12%] train loss: 1.586272264830768e-05 \n",
      "epoch: 43 [179982/888800 20.25%] train loss: 1.3379933989199344e-05 \n",
      "epoch: 43 [181093/888800 20.38%] train loss: 1.5001172869233415e-05 \n",
      "epoch: 43 [182204/888800 20.50%] train loss: 1.4540076335833874e-05 \n",
      "epoch: 43 [183315/888800 20.62%] train loss: 1.538157812319696e-05 \n",
      "epoch: 43 [184426/888800 20.75%] train loss: 1.4950376680644695e-05 \n",
      "epoch: 43 [185537/888800 20.88%] train loss: 1.3613288501801435e-05 \n",
      "epoch: 43 [186648/888800 21.00%] train loss: 1.3856064470019192e-05 \n",
      "epoch: 43 [187759/888800 21.12%] train loss: 1.3799808584735729e-05 \n",
      "epoch: 43 [188870/888800 21.25%] train loss: 1.6492436770931818e-05 \n",
      "epoch: 43 [189981/888800 21.38%] train loss: 1.4387104783963878e-05 \n",
      "epoch: 43 [191092/888800 21.50%] train loss: 1.487635017838329e-05 \n",
      "epoch: 43 [192203/888800 21.62%] train loss: 1.5655072274967097e-05 \n",
      "epoch: 43 [193314/888800 21.75%] train loss: 1.4284583812695928e-05 \n",
      "epoch: 43 [194425/888800 21.88%] train loss: 1.4687534530821722e-05 \n",
      "epoch: 43 [195536/888800 22.00%] train loss: 1.3973909517517313e-05 \n",
      "epoch: 43 [196647/888800 22.12%] train loss: 1.4292407286120579e-05 \n",
      "epoch: 43 [197758/888800 22.25%] train loss: 1.4143449334369507e-05 \n",
      "epoch: 43 [198869/888800 22.38%] train loss: 1.4095672668190673e-05 \n",
      "epoch: 43 [199980/888800 22.50%] train loss: 1.4163584637572058e-05 \n",
      "epoch: 43 [201091/888800 22.62%] train loss: 1.3942202713224106e-05 \n",
      "epoch: 43 [202202/888800 22.75%] train loss: 1.49087245517876e-05 \n",
      "epoch: 43 [203313/888800 22.88%] train loss: 1.4050031495571602e-05 \n",
      "epoch: 43 [204424/888800 23.00%] train loss: 1.3999749171489384e-05 \n",
      "epoch: 43 [205535/888800 23.12%] train loss: 1.3990081242809538e-05 \n",
      "epoch: 43 [206646/888800 23.25%] train loss: 1.4900057976774406e-05 \n",
      "epoch: 43 [207757/888800 23.38%] train loss: 1.4227070096239913e-05 \n",
      "epoch: 43 [208868/888800 23.50%] train loss: 1.4386863767867908e-05 \n",
      "epoch: 43 [209979/888800 23.62%] train loss: 1.4843392818875145e-05 \n",
      "epoch: 43 [211090/888800 23.75%] train loss: 1.4209625987859908e-05 \n",
      "epoch: 43 [212201/888800 23.88%] train loss: 1.5317888028221205e-05 \n",
      "epoch: 43 [213312/888800 24.00%] train loss: 1.4269018720369786e-05 \n",
      "epoch: 43 [214423/888800 24.12%] train loss: 1.4475482203124557e-05 \n",
      "epoch: 43 [215534/888800 24.25%] train loss: 1.4093289792072028e-05 \n",
      "epoch: 43 [216645/888800 24.38%] train loss: 1.4696109246870037e-05 \n",
      "epoch: 43 [217756/888800 24.50%] train loss: 1.5390218322863802e-05 \n",
      "epoch: 43 [218867/888800 24.62%] train loss: 1.4209404071152676e-05 \n",
      "epoch: 43 [219978/888800 24.75%] train loss: 1.3683266843145248e-05 \n",
      "epoch: 43 [221089/888800 24.88%] train loss: 1.5208769582386594e-05 \n",
      "epoch: 43 [222200/888800 25.00%] train loss: 1.5027494555397425e-05 \n",
      "epoch: 43 [223311/888800 25.12%] train loss: 1.505796899436973e-05 \n",
      "epoch: 43 [224422/888800 25.25%] train loss: 1.2791837434633635e-05 \n",
      "epoch: 43 [225533/888800 25.38%] train loss: 1.4974068108131178e-05 \n",
      "epoch: 43 [226644/888800 25.50%] train loss: 1.4375860700965859e-05 \n",
      "epoch: 43 [227755/888800 25.62%] train loss: 1.4132329852145631e-05 \n",
      "epoch: 43 [228866/888800 25.75%] train loss: 1.4475824173132423e-05 \n",
      "epoch: 43 [229977/888800 25.88%] train loss: 1.4787126019655261e-05 \n",
      "epoch: 43 [231088/888800 26.00%] train loss: 1.4107564311416354e-05 \n",
      "epoch: 43 [232199/888800 26.12%] train loss: 1.4149236449156888e-05 \n",
      "epoch: 43 [233310/888800 26.25%] train loss: 1.5088802683749236e-05 \n",
      "epoch: 43 [234421/888800 26.38%] train loss: 1.4558165275957435e-05 \n",
      "epoch: 43 [235532/888800 26.50%] train loss: 1.5486555639654398e-05 \n",
      "epoch: 43 [236643/888800 26.62%] train loss: 1.3960680917080026e-05 \n",
      "epoch: 43 [237754/888800 26.75%] train loss: 1.5611989510944113e-05 \n",
      "epoch: 43 [238865/888800 26.88%] train loss: 1.4327058124763425e-05 \n",
      "epoch: 43 [239976/888800 27.00%] train loss: 1.458039059798466e-05 \n",
      "epoch: 43 [241087/888800 27.12%] train loss: 1.5109506421140395e-05 \n",
      "epoch: 43 [242198/888800 27.25%] train loss: 1.3825230780639686e-05 \n",
      "epoch: 43 [243309/888800 27.38%] train loss: 1.5383935533463955e-05 \n",
      "epoch: 43 [244420/888800 27.50%] train loss: 1.4222177924239077e-05 \n",
      "epoch: 43 [245531/888800 27.62%] train loss: 1.505250020272797e-05 \n",
      "epoch: 43 [246642/888800 27.75%] train loss: 1.3428751117317006e-05 \n",
      "epoch: 43 [247753/888800 27.88%] train loss: 1.3957205737824552e-05 \n",
      "epoch: 43 [248864/888800 28.00%] train loss: 1.5144441931624897e-05 \n",
      "epoch: 43 [249975/888800 28.12%] train loss: 1.4653198377345689e-05 \n",
      "epoch: 43 [251086/888800 28.25%] train loss: 1.4506173101835884e-05 \n",
      "epoch: 43 [252197/888800 28.38%] train loss: 1.4886642929923255e-05 \n",
      "epoch: 43 [253308/888800 28.50%] train loss: 1.263890226255171e-05 \n",
      "epoch: 43 [254419/888800 28.62%] train loss: 1.4188201021170244e-05 \n",
      "epoch: 43 [255530/888800 28.75%] train loss: 1.465293189539807e-05 \n",
      "epoch: 43 [256641/888800 28.88%] train loss: 1.4466942047874909e-05 \n",
      "epoch: 43 [257752/888800 29.00%] train loss: 1.3973949535284191e-05 \n",
      "epoch: 43 [258863/888800 29.12%] train loss: 1.474059172323905e-05 \n",
      "epoch: 43 [259974/888800 29.25%] train loss: 1.3308218512975145e-05 \n",
      "epoch: 43 [261085/888800 29.38%] train loss: 1.3610478163172957e-05 \n",
      "epoch: 43 [262196/888800 29.50%] train loss: 1.5328583685914055e-05 \n",
      "epoch: 43 [263307/888800 29.62%] train loss: 1.3269143892102875e-05 \n",
      "epoch: 43 [264418/888800 29.75%] train loss: 1.493154741183389e-05 \n",
      "epoch: 43 [265529/888800 29.88%] train loss: 1.4641696907347068e-05 \n",
      "epoch: 43 [266640/888800 30.00%] train loss: 1.393110869685188e-05 \n",
      "epoch: 43 [267751/888800 30.12%] train loss: 1.3466357813740615e-05 \n",
      "epoch: 43 [268862/888800 30.25%] train loss: 1.3804513400828e-05 \n",
      "epoch: 43 [269973/888800 30.38%] train loss: 1.4268804079620168e-05 \n",
      "epoch: 43 [271084/888800 30.50%] train loss: 1.4027832548890729e-05 \n",
      "epoch: 43 [272195/888800 30.62%] train loss: 1.3924962331657298e-05 \n",
      "epoch: 43 [273306/888800 30.75%] train loss: 1.484180484112585e-05 \n",
      "epoch: 43 [274417/888800 30.88%] train loss: 1.495056949352147e-05 \n",
      "epoch: 43 [275528/888800 31.00%] train loss: 1.3236523045634385e-05 \n",
      "epoch: 43 [276639/888800 31.12%] train loss: 1.4291600564320106e-05 \n",
      "epoch: 43 [277750/888800 31.25%] train loss: 1.4492157788481563e-05 \n",
      "epoch: 43 [278861/888800 31.38%] train loss: 1.4283778000390157e-05 \n",
      "epoch: 43 [279972/888800 31.50%] train loss: 1.4479204764938913e-05 \n",
      "epoch: 43 [281083/888800 31.62%] train loss: 1.2946956303494517e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [282194/888800 31.75%] train loss: 1.4554803783539683e-05 \n",
      "epoch: 43 [283305/888800 31.88%] train loss: 1.287169743591221e-05 \n",
      "epoch: 43 [284416/888800 32.00%] train loss: 1.2753658666042611e-05 \n",
      "epoch: 43 [285527/888800 32.12%] train loss: 1.4343330803967547e-05 \n",
      "epoch: 43 [286638/888800 32.25%] train loss: 1.549340595374815e-05 \n",
      "epoch: 43 [287749/888800 32.38%] train loss: 1.4664449736301322e-05 \n",
      "epoch: 43 [288860/888800 32.50%] train loss: 1.4261732758313883e-05 \n",
      "epoch: 43 [289971/888800 32.62%] train loss: 1.4044677300262265e-05 \n",
      "epoch: 43 [291082/888800 32.75%] train loss: 1.4442917745327577e-05 \n",
      "epoch: 43 [292193/888800 32.88%] train loss: 1.549706757941749e-05 \n",
      "epoch: 43 [293304/888800 33.00%] train loss: 1.470197457820177e-05 \n",
      "epoch: 43 [294415/888800 33.12%] train loss: 1.2729165064229164e-05 \n",
      "epoch: 43 [295526/888800 33.25%] train loss: 1.4148918126011267e-05 \n",
      "epoch: 43 [296637/888800 33.38%] train loss: 1.4239431038731709e-05 \n",
      "epoch: 43 [297748/888800 33.50%] train loss: 1.4529615327774081e-05 \n",
      "epoch: 43 [298859/888800 33.62%] train loss: 1.2746521861117799e-05 \n",
      "epoch: 43 [299970/888800 33.75%] train loss: 1.4903077499184292e-05 \n",
      "epoch: 43 [301081/888800 33.88%] train loss: 1.4573830412700772e-05 \n",
      "epoch: 43 [302192/888800 34.00%] train loss: 1.4757675671717152e-05 \n",
      "epoch: 43 [303303/888800 34.12%] train loss: 1.3562169442593586e-05 \n",
      "epoch: 43 [304414/888800 34.25%] train loss: 1.4091293451201636e-05 \n",
      "epoch: 43 [305525/888800 34.38%] train loss: 1.338197398581542e-05 \n",
      "epoch: 43 [306636/888800 34.50%] train loss: 1.607191916264128e-05 \n",
      "epoch: 43 [307747/888800 34.62%] train loss: 1.4081688277656212e-05 \n",
      "epoch: 43 [308858/888800 34.75%] train loss: 1.4323784853331745e-05 \n",
      "epoch: 43 [309969/888800 34.88%] train loss: 1.4044195268070325e-05 \n",
      "epoch: 43 [311080/888800 35.00%] train loss: 1.5187311873887666e-05 \n",
      "epoch: 43 [312191/888800 35.12%] train loss: 1.527743552287575e-05 \n",
      "epoch: 43 [313302/888800 35.25%] train loss: 1.2869041711383034e-05 \n",
      "epoch: 43 [314413/888800 35.38%] train loss: 1.5550622265436687e-05 \n",
      "epoch: 43 [315524/888800 35.50%] train loss: 1.412784058629768e-05 \n",
      "epoch: 43 [316635/888800 35.62%] train loss: 1.4558489965565968e-05 \n",
      "epoch: 43 [317746/888800 35.75%] train loss: 1.3665731785295065e-05 \n",
      "epoch: 43 [318857/888800 35.88%] train loss: 1.4627556993218604e-05 \n",
      "epoch: 43 [319968/888800 36.00%] train loss: 1.378976958221756e-05 \n",
      "epoch: 43 [321079/888800 36.12%] train loss: 1.587245424161665e-05 \n",
      "epoch: 43 [322190/888800 36.25%] train loss: 1.4861749150441028e-05 \n",
      "epoch: 43 [323301/888800 36.38%] train loss: 1.3429755199467763e-05 \n",
      "epoch: 43 [324412/888800 36.50%] train loss: 1.3718789887207095e-05 \n",
      "epoch: 43 [325523/888800 36.62%] train loss: 1.3954392670711968e-05 \n",
      "epoch: 43 [326634/888800 36.75%] train loss: 1.4909132005413994e-05 \n",
      "epoch: 43 [327745/888800 36.88%] train loss: 1.4491281945083756e-05 \n",
      "epoch: 43 [328856/888800 37.00%] train loss: 1.5870087736402638e-05 \n",
      "epoch: 43 [329967/888800 37.12%] train loss: 1.3536987353290897e-05 \n",
      "epoch: 43 [331078/888800 37.25%] train loss: 1.5119746421987657e-05 \n",
      "epoch: 43 [332189/888800 37.38%] train loss: 1.5263651221175678e-05 \n",
      "epoch: 43 [333300/888800 37.50%] train loss: 1.376645468553761e-05 \n",
      "epoch: 43 [334411/888800 37.62%] train loss: 1.6476506061735563e-05 \n",
      "epoch: 43 [335522/888800 37.75%] train loss: 1.397611868014792e-05 \n",
      "epoch: 43 [336633/888800 37.88%] train loss: 1.5531681128777564e-05 \n",
      "epoch: 43 [337744/888800 38.00%] train loss: 1.3436354493023828e-05 \n",
      "epoch: 43 [338855/888800 38.12%] train loss: 1.5406758393510245e-05 \n",
      "epoch: 43 [339966/888800 38.25%] train loss: 1.28393739942112e-05 \n",
      "epoch: 43 [341077/888800 38.38%] train loss: 1.5432198779308237e-05 \n",
      "epoch: 43 [342188/888800 38.50%] train loss: 1.4907273907738272e-05 \n",
      "epoch: 43 [343299/888800 38.62%] train loss: 1.5259742212947458e-05 \n",
      "epoch: 43 [344410/888800 38.75%] train loss: 1.384971801599022e-05 \n",
      "epoch: 43 [345521/888800 38.88%] train loss: 1.410893219144782e-05 \n",
      "epoch: 43 [346632/888800 39.00%] train loss: 1.3682133612746838e-05 \n",
      "epoch: 43 [347743/888800 39.12%] train loss: 1.4513426322082523e-05 \n",
      "epoch: 43 [348854/888800 39.25%] train loss: 1.4428480426431634e-05 \n",
      "epoch: 43 [349965/888800 39.38%] train loss: 1.4102634850132745e-05 \n",
      "epoch: 43 [351076/888800 39.50%] train loss: 1.4600177564716432e-05 \n",
      "epoch: 43 [352187/888800 39.62%] train loss: 1.4205157640390098e-05 \n",
      "epoch: 43 [353298/888800 39.75%] train loss: 1.5027403605927248e-05 \n",
      "epoch: 43 [354409/888800 39.88%] train loss: 1.4287197700468823e-05 \n",
      "epoch: 43 [355520/888800 40.00%] train loss: 1.3963900528324302e-05 \n",
      "epoch: 43 [356631/888800 40.12%] train loss: 1.4705084140587132e-05 \n",
      "epoch: 43 [357742/888800 40.25%] train loss: 1.4245604688767344e-05 \n",
      "epoch: 43 [358853/888800 40.38%] train loss: 1.3535721336666029e-05 \n",
      "epoch: 43 [359964/888800 40.50%] train loss: 1.4115738849795889e-05 \n",
      "epoch: 43 [361075/888800 40.62%] train loss: 1.4483942322840448e-05 \n",
      "epoch: 43 [362186/888800 40.75%] train loss: 1.5197840184555389e-05 \n",
      "epoch: 43 [363297/888800 40.88%] train loss: 1.3499157830665354e-05 \n",
      "epoch: 43 [364408/888800 41.00%] train loss: 1.3471821148414165e-05 \n",
      "epoch: 43 [365519/888800 41.12%] train loss: 1.3535955986299086e-05 \n",
      "epoch: 43 [366630/888800 41.25%] train loss: 1.526912637928035e-05 \n",
      "epoch: 43 [367741/888800 41.38%] train loss: 1.4132430806057528e-05 \n",
      "epoch: 43 [368852/888800 41.50%] train loss: 1.3349597793421708e-05 \n",
      "epoch: 43 [369963/888800 41.62%] train loss: 1.482934476371156e-05 \n",
      "epoch: 43 [371074/888800 41.75%] train loss: 1.4178384844854008e-05 \n",
      "epoch: 43 [372185/888800 41.88%] train loss: 1.3390394997259136e-05 \n",
      "epoch: 43 [373296/888800 42.00%] train loss: 1.5493757018703036e-05 \n",
      "epoch: 43 [374407/888800 42.12%] train loss: 1.3884486179449596e-05 \n",
      "epoch: 43 [375518/888800 42.25%] train loss: 1.3821469110553153e-05 \n",
      "epoch: 43 [376629/888800 42.38%] train loss: 1.5247162991727237e-05 \n",
      "epoch: 43 [377740/888800 42.50%] train loss: 1.4459552403423004e-05 \n",
      "epoch: 43 [378851/888800 42.62%] train loss: 1.4962969544285443e-05 \n",
      "epoch: 43 [379962/888800 42.75%] train loss: 1.4082409506954718e-05 \n",
      "epoch: 43 [381073/888800 42.88%] train loss: 1.3621603102365043e-05 \n",
      "epoch: 43 [382184/888800 43.00%] train loss: 1.3472887985699344e-05 \n",
      "epoch: 43 [383295/888800 43.12%] train loss: 1.3839137864124496e-05 \n",
      "epoch: 43 [384406/888800 43.25%] train loss: 1.5572244592476636e-05 \n",
      "epoch: 43 [385517/888800 43.38%] train loss: 1.5085984159668442e-05 \n",
      "epoch: 43 [386628/888800 43.50%] train loss: 1.356640859739855e-05 \n",
      "epoch: 43 [387739/888800 43.62%] train loss: 1.502118266216712e-05 \n",
      "epoch: 43 [388850/888800 43.75%] train loss: 1.5357030861196108e-05 \n",
      "epoch: 43 [389961/888800 43.88%] train loss: 1.4518968782795127e-05 \n",
      "epoch: 43 [391072/888800 44.00%] train loss: 1.5878616977715865e-05 \n",
      "epoch: 43 [392183/888800 44.12%] train loss: 1.530733788968064e-05 \n",
      "epoch: 43 [393294/888800 44.25%] train loss: 1.7369342458550818e-05 \n",
      "epoch: 43 [394405/888800 44.38%] train loss: 1.595475805515889e-05 \n",
      "epoch: 43 [395516/888800 44.50%] train loss: 1.515124586148886e-05 \n",
      "epoch: 43 [396627/888800 44.62%] train loss: 1.2567707017296925e-05 \n",
      "epoch: 43 [397738/888800 44.75%] train loss: 1.6057882021414116e-05 \n",
      "epoch: 43 [398849/888800 44.88%] train loss: 1.3318800483830273e-05 \n",
      "epoch: 43 [399960/888800 45.00%] train loss: 1.4776721400266979e-05 \n",
      "epoch: 43 [401071/888800 45.12%] train loss: 1.4448852198256645e-05 \n",
      "epoch: 43 [402182/888800 45.25%] train loss: 1.51655785884941e-05 \n",
      "epoch: 43 [403293/888800 45.38%] train loss: 1.4648723663412966e-05 \n",
      "epoch: 43 [404404/888800 45.50%] train loss: 1.314283781539416e-05 \n",
      "epoch: 43 [405515/888800 45.62%] train loss: 1.514729592599906e-05 \n",
      "epoch: 43 [406626/888800 45.75%] train loss: 1.4511140761896968e-05 \n",
      "epoch: 43 [407737/888800 45.88%] train loss: 1.420458920620149e-05 \n",
      "epoch: 43 [408848/888800 46.00%] train loss: 1.3354914699448273e-05 \n",
      "epoch: 43 [409959/888800 46.12%] train loss: 1.5470681319129653e-05 \n",
      "epoch: 43 [411070/888800 46.25%] train loss: 1.462845284549985e-05 \n",
      "epoch: 43 [412181/888800 46.38%] train loss: 1.413664358551614e-05 \n",
      "epoch: 43 [413292/888800 46.50%] train loss: 1.4977461432863493e-05 \n",
      "epoch: 43 [414403/888800 46.62%] train loss: 1.5474122847081162e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [415514/888800 46.75%] train loss: 1.3825542737322394e-05 \n",
      "epoch: 43 [416625/888800 46.88%] train loss: 1.4221150195226073e-05 \n",
      "epoch: 43 [417736/888800 47.00%] train loss: 1.4942260349926073e-05 \n",
      "epoch: 43 [418847/888800 47.12%] train loss: 1.3667741768585984e-05 \n",
      "epoch: 43 [419958/888800 47.25%] train loss: 1.3676981325261295e-05 \n",
      "epoch: 43 [421069/888800 47.38%] train loss: 1.2859281923738308e-05 \n",
      "epoch: 43 [422180/888800 47.50%] train loss: 1.414859616488684e-05 \n",
      "epoch: 43 [423291/888800 47.62%] train loss: 1.5503897884627804e-05 \n",
      "epoch: 43 [424402/888800 47.75%] train loss: 1.4263642697187606e-05 \n",
      "epoch: 43 [425513/888800 47.88%] train loss: 1.4942711459298152e-05 \n",
      "epoch: 43 [426624/888800 48.00%] train loss: 1.4100559383223299e-05 \n",
      "epoch: 43 [427735/888800 48.12%] train loss: 1.501567294326378e-05 \n",
      "epoch: 43 [428846/888800 48.25%] train loss: 1.5573783457512036e-05 \n",
      "epoch: 43 [429957/888800 48.38%] train loss: 1.3495136954588816e-05 \n",
      "epoch: 43 [431068/888800 48.50%] train loss: 1.464614524593344e-05 \n",
      "epoch: 43 [432179/888800 48.62%] train loss: 1.5885172615526244e-05 \n",
      "epoch: 43 [433290/888800 48.75%] train loss: 1.4662716239399742e-05 \n",
      "epoch: 43 [434401/888800 48.88%] train loss: 1.4148874470265582e-05 \n",
      "epoch: 43 [435512/888800 49.00%] train loss: 1.3598320947494358e-05 \n",
      "epoch: 43 [436623/888800 49.12%] train loss: 1.561981662234757e-05 \n",
      "epoch: 43 [437734/888800 49.25%] train loss: 1.3009917893214151e-05 \n",
      "epoch: 43 [438845/888800 49.38%] train loss: 1.3443233910948038e-05 \n",
      "epoch: 43 [439956/888800 49.50%] train loss: 1.4531516171700787e-05 \n",
      "epoch: 43 [441067/888800 49.62%] train loss: 1.4767135326110292e-05 \n",
      "epoch: 43 [442178/888800 49.75%] train loss: 1.3528112503990997e-05 \n",
      "epoch: 43 [443289/888800 49.88%] train loss: 1.4123588698566891e-05 \n",
      "epoch: 43 [444400/888800 50.00%] train loss: 1.3484467672242317e-05 \n",
      "epoch: 43 [445511/888800 50.12%] train loss: 1.4707255104440264e-05 \n",
      "epoch: 43 [446622/888800 50.25%] train loss: 1.4152948097034823e-05 \n",
      "epoch: 43 [447733/888800 50.38%] train loss: 1.4500811630568933e-05 \n",
      "epoch: 43 [448844/888800 50.50%] train loss: 1.3996682355355006e-05 \n",
      "epoch: 43 [449955/888800 50.62%] train loss: 1.2917007552459836e-05 \n",
      "epoch: 43 [451066/888800 50.75%] train loss: 1.3126045814715326e-05 \n",
      "epoch: 43 [452177/888800 50.88%] train loss: 1.4490125977317803e-05 \n",
      "epoch: 43 [453288/888800 51.00%] train loss: 1.4544502846547402e-05 \n",
      "epoch: 43 [454399/888800 51.12%] train loss: 1.4029088561073877e-05 \n",
      "epoch: 43 [455510/888800 51.25%] train loss: 1.4569758604920935e-05 \n",
      "epoch: 43 [456621/888800 51.38%] train loss: 1.4249654668674339e-05 \n",
      "epoch: 43 [457732/888800 51.50%] train loss: 1.4309883226815145e-05 \n",
      "epoch: 43 [458843/888800 51.62%] train loss: 1.3714269698539283e-05 \n",
      "epoch: 43 [459954/888800 51.75%] train loss: 1.4873606232868042e-05 \n",
      "epoch: 43 [461065/888800 51.88%] train loss: 1.534643342893105e-05 \n",
      "epoch: 43 [462176/888800 52.00%] train loss: 1.3684435543837026e-05 \n",
      "epoch: 43 [463287/888800 52.12%] train loss: 1.4563045624527149e-05 \n",
      "epoch: 43 [464398/888800 52.25%] train loss: 1.2863278243457898e-05 \n",
      "epoch: 43 [465509/888800 52.38%] train loss: 1.3808692528982647e-05 \n",
      "epoch: 43 [466620/888800 52.50%] train loss: 1.4281351468525827e-05 \n",
      "epoch: 43 [467731/888800 52.62%] train loss: 1.3529410352930427e-05 \n",
      "epoch: 43 [468842/888800 52.75%] train loss: 1.4300136172096245e-05 \n",
      "epoch: 43 [469953/888800 52.88%] train loss: 1.3903173567086924e-05 \n",
      "epoch: 43 [471064/888800 53.00%] train loss: 1.4575144632544834e-05 \n",
      "epoch: 43 [472175/888800 53.12%] train loss: 1.3868195310351439e-05 \n",
      "epoch: 43 [473286/888800 53.25%] train loss: 1.455184246879071e-05 \n",
      "epoch: 43 [474397/888800 53.38%] train loss: 1.5049351532070432e-05 \n",
      "epoch: 43 [475508/888800 53.50%] train loss: 1.440891355741769e-05 \n",
      "epoch: 43 [476619/888800 53.62%] train loss: 1.616320150787942e-05 \n",
      "epoch: 43 [477730/888800 53.75%] train loss: 1.444365807401482e-05 \n",
      "epoch: 43 [478841/888800 53.88%] train loss: 1.4726358131156303e-05 \n",
      "epoch: 43 [479952/888800 54.00%] train loss: 1.4094071048020851e-05 \n",
      "epoch: 43 [481063/888800 54.12%] train loss: 1.3452221537590958e-05 \n",
      "epoch: 43 [482174/888800 54.25%] train loss: 1.4538815776177216e-05 \n",
      "epoch: 43 [483285/888800 54.38%] train loss: 1.3854031749360729e-05 \n",
      "epoch: 43 [484396/888800 54.50%] train loss: 1.3428052625386044e-05 \n",
      "epoch: 43 [485507/888800 54.62%] train loss: 1.326841265836265e-05 \n",
      "epoch: 43 [486618/888800 54.75%] train loss: 1.3952496374258772e-05 \n",
      "epoch: 43 [487729/888800 54.88%] train loss: 1.5363173588411883e-05 \n",
      "epoch: 43 [488840/888800 55.00%] train loss: 1.2498574506025761e-05 \n",
      "epoch: 43 [489951/888800 55.12%] train loss: 1.4570442544936668e-05 \n",
      "epoch: 43 [491062/888800 55.25%] train loss: 1.4253540939535014e-05 \n",
      "epoch: 43 [492173/888800 55.38%] train loss: 1.2858832633355632e-05 \n",
      "epoch: 43 [493284/888800 55.50%] train loss: 1.4563793229172006e-05 \n",
      "epoch: 43 [494395/888800 55.62%] train loss: 1.388125110679539e-05 \n",
      "epoch: 43 [495506/888800 55.75%] train loss: 1.4741386621608399e-05 \n",
      "epoch: 43 [496617/888800 55.88%] train loss: 1.5242474546539597e-05 \n",
      "epoch: 43 [497728/888800 56.00%] train loss: 1.5823450667085126e-05 \n",
      "epoch: 43 [498839/888800 56.12%] train loss: 1.3702583601116203e-05 \n",
      "epoch: 43 [499950/888800 56.25%] train loss: 1.4122066204436123e-05 \n",
      "epoch: 43 [501061/888800 56.38%] train loss: 1.4024044503457844e-05 \n",
      "epoch: 43 [502172/888800 56.50%] train loss: 1.5491688827751204e-05 \n",
      "epoch: 43 [503283/888800 56.62%] train loss: 1.5183747564151417e-05 \n",
      "epoch: 43 [504394/888800 56.75%] train loss: 1.3199501154304016e-05 \n",
      "epoch: 43 [505505/888800 56.88%] train loss: 1.5171000086411368e-05 \n",
      "epoch: 43 [506616/888800 57.00%] train loss: 1.4574553460988682e-05 \n",
      "epoch: 43 [507727/888800 57.12%] train loss: 1.4932516023691278e-05 \n",
      "epoch: 43 [508838/888800 57.25%] train loss: 1.4124029803497251e-05 \n",
      "epoch: 43 [509949/888800 57.38%] train loss: 1.4324036783364136e-05 \n",
      "epoch: 43 [511060/888800 57.50%] train loss: 1.3552979908126872e-05 \n",
      "epoch: 43 [512171/888800 57.62%] train loss: 1.403684655088e-05 \n",
      "epoch: 43 [513282/888800 57.75%] train loss: 1.5161760529736057e-05 \n",
      "epoch: 43 [514393/888800 57.88%] train loss: 1.3063403457636014e-05 \n",
      "epoch: 43 [515504/888800 58.00%] train loss: 1.3675269656232558e-05 \n",
      "epoch: 43 [516615/888800 58.12%] train loss: 1.4011065104568843e-05 \n",
      "epoch: 43 [517726/888800 58.25%] train loss: 1.3740209396928549e-05 \n",
      "epoch: 43 [518837/888800 58.38%] train loss: 1.3234987818577792e-05 \n",
      "epoch: 43 [519948/888800 58.50%] train loss: 1.4421631931327283e-05 \n",
      "epoch: 43 [521059/888800 58.62%] train loss: 1.3837715414410923e-05 \n",
      "epoch: 43 [522170/888800 58.75%] train loss: 1.37976903715753e-05 \n",
      "epoch: 43 [523281/888800 58.88%] train loss: 1.4146419744065497e-05 \n",
      "epoch: 43 [524392/888800 59.00%] train loss: 1.4551061212841887e-05 \n",
      "epoch: 43 [525503/888800 59.12%] train loss: 1.401477220497327e-05 \n",
      "epoch: 43 [526614/888800 59.25%] train loss: 1.4127534996077884e-05 \n",
      "epoch: 43 [527725/888800 59.38%] train loss: 1.5019306374597363e-05 \n",
      "epoch: 43 [528836/888800 59.50%] train loss: 1.3750811376667116e-05 \n",
      "epoch: 43 [529947/888800 59.62%] train loss: 1.3784926522930618e-05 \n",
      "epoch: 43 [531058/888800 59.75%] train loss: 1.5043059647723567e-05 \n",
      "epoch: 43 [532169/888800 59.88%] train loss: 1.3823594599671196e-05 \n",
      "epoch: 43 [533280/888800 60.00%] train loss: 1.5006035937403794e-05 \n",
      "epoch: 43 [534391/888800 60.12%] train loss: 1.4394612662727013e-05 \n",
      "epoch: 43 [535502/888800 60.25%] train loss: 1.3816820683132391e-05 \n",
      "epoch: 43 [536613/888800 60.38%] train loss: 1.3679387848242186e-05 \n",
      "epoch: 43 [537724/888800 60.50%] train loss: 1.5398492905660532e-05 \n",
      "epoch: 43 [538835/888800 60.62%] train loss: 1.4401878615899477e-05 \n",
      "epoch: 43 [539946/888800 60.75%] train loss: 1.4660243323305622e-05 \n",
      "epoch: 43 [541057/888800 60.88%] train loss: 1.5042576706036925e-05 \n",
      "epoch: 43 [542168/888800 61.00%] train loss: 1.3903021681471728e-05 \n",
      "epoch: 43 [543279/888800 61.12%] train loss: 1.5762307157274336e-05 \n",
      "epoch: 43 [544390/888800 61.25%] train loss: 1.2827861610276159e-05 \n",
      "epoch: 43 [545501/888800 61.38%] train loss: 1.4378856576513499e-05 \n",
      "epoch: 43 [546612/888800 61.50%] train loss: 1.4669729353045113e-05 \n",
      "epoch: 43 [547723/888800 61.62%] train loss: 1.472896292398218e-05 \n",
      "epoch: 43 [548834/888800 61.75%] train loss: 1.4947870113246609e-05 \n",
      "epoch: 43 [549945/888800 61.88%] train loss: 1.5577425074297935e-05 \n",
      "epoch: 43 [551056/888800 62.00%] train loss: 1.4444162843574304e-05 \n",
      "epoch: 43 [552167/888800 62.12%] train loss: 1.4047274817130528e-05 \n",
      "epoch: 43 [553278/888800 62.25%] train loss: 1.4566582649422344e-05 \n",
      "epoch: 43 [554389/888800 62.38%] train loss: 1.4502627891488373e-05 \n",
      "epoch: 43 [555500/888800 62.50%] train loss: 1.5199052540992852e-05 \n",
      "epoch: 43 [556611/888800 62.62%] train loss: 1.2769321074301843e-05 \n",
      "epoch: 43 [557722/888800 62.75%] train loss: 1.5130320207390469e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [558833/888800 62.88%] train loss: 1.4705708053952549e-05 \n",
      "epoch: 43 [559944/888800 63.00%] train loss: 1.4857975656923372e-05 \n",
      "epoch: 43 [561055/888800 63.12%] train loss: 1.405292368872324e-05 \n",
      "epoch: 43 [562166/888800 63.25%] train loss: 1.401124336553039e-05 \n",
      "epoch: 43 [563277/888800 63.38%] train loss: 1.4687525435874704e-05 \n",
      "epoch: 43 [564388/888800 63.50%] train loss: 1.5010770766821224e-05 \n",
      "epoch: 43 [565499/888800 63.62%] train loss: 1.4043189366930164e-05 \n",
      "epoch: 43 [566610/888800 63.75%] train loss: 1.7010584997478873e-05 \n",
      "epoch: 43 [567721/888800 63.88%] train loss: 1.3317252523847856e-05 \n",
      "epoch: 43 [568832/888800 64.00%] train loss: 1.5182044080574997e-05 \n",
      "epoch: 43 [569943/888800 64.12%] train loss: 1.4040982023288961e-05 \n",
      "epoch: 43 [571054/888800 64.25%] train loss: 1.5001176507212222e-05 \n",
      "epoch: 43 [572165/888800 64.38%] train loss: 1.5026664186734706e-05 \n",
      "epoch: 43 [573276/888800 64.50%] train loss: 1.4362895853992086e-05 \n",
      "epoch: 43 [574387/888800 64.62%] train loss: 1.5127131518966053e-05 \n",
      "epoch: 43 [575498/888800 64.75%] train loss: 1.486031396780163e-05 \n",
      "epoch: 43 [576609/888800 64.88%] train loss: 1.3013052921451163e-05 \n",
      "epoch: 43 [577720/888800 65.00%] train loss: 1.4172456758387852e-05 \n",
      "epoch: 43 [578831/888800 65.12%] train loss: 1.4216019735613372e-05 \n",
      "epoch: 43 [579942/888800 65.25%] train loss: 1.3792153367830906e-05 \n",
      "epoch: 43 [581053/888800 65.38%] train loss: 1.5118656847334933e-05 \n",
      "epoch: 43 [582164/888800 65.50%] train loss: 1.5097026334842667e-05 \n",
      "epoch: 43 [583275/888800 65.62%] train loss: 1.5479279682040215e-05 \n",
      "epoch: 43 [584386/888800 65.75%] train loss: 1.4190968613547739e-05 \n",
      "epoch: 43 [585497/888800 65.88%] train loss: 1.3568266695074271e-05 \n",
      "epoch: 43 [586608/888800 66.00%] train loss: 1.341728238912765e-05 \n",
      "epoch: 43 [587719/888800 66.12%] train loss: 1.4328787983686198e-05 \n",
      "epoch: 43 [588830/888800 66.25%] train loss: 1.3609964298666455e-05 \n",
      "epoch: 43 [589941/888800 66.38%] train loss: 1.3880484402761795e-05 \n",
      "epoch: 43 [591052/888800 66.50%] train loss: 1.3625280189444311e-05 \n",
      "epoch: 43 [592163/888800 66.62%] train loss: 1.296685695706401e-05 \n",
      "epoch: 43 [593274/888800 66.75%] train loss: 1.3795594895782415e-05 \n",
      "epoch: 43 [594385/888800 66.88%] train loss: 1.4287303201854229e-05 \n",
      "epoch: 43 [595496/888800 67.00%] train loss: 1.368416087643709e-05 \n",
      "epoch: 43 [596607/888800 67.12%] train loss: 1.3615406714961864e-05 \n",
      "epoch: 43 [597718/888800 67.25%] train loss: 1.497251014370704e-05 \n",
      "epoch: 43 [598829/888800 67.38%] train loss: 1.2933475773024838e-05 \n",
      "epoch: 43 [599940/888800 67.50%] train loss: 1.3874221622245386e-05 \n",
      "epoch: 43 [601051/888800 67.62%] train loss: 1.3630990906676743e-05 \n",
      "epoch: 43 [602162/888800 67.75%] train loss: 1.344326028629439e-05 \n",
      "epoch: 43 [603273/888800 67.88%] train loss: 1.429191524948692e-05 \n",
      "epoch: 43 [604384/888800 68.00%] train loss: 1.4749356523680035e-05 \n",
      "epoch: 43 [605495/888800 68.12%] train loss: 1.3183192095311824e-05 \n",
      "epoch: 43 [606606/888800 68.25%] train loss: 1.4165716493153013e-05 \n",
      "epoch: 43 [607717/888800 68.38%] train loss: 1.5143811651796568e-05 \n",
      "epoch: 43 [608828/888800 68.50%] train loss: 1.2454525858629495e-05 \n",
      "epoch: 43 [609939/888800 68.62%] train loss: 1.564690137456637e-05 \n",
      "epoch: 43 [611050/888800 68.75%] train loss: 1.436643287888728e-05 \n",
      "epoch: 43 [612161/888800 68.88%] train loss: 1.4827511222392786e-05 \n",
      "epoch: 43 [613272/888800 69.00%] train loss: 1.5025085303932428e-05 \n",
      "epoch: 43 [614383/888800 69.12%] train loss: 1.4617040505982004e-05 \n",
      "epoch: 43 [615494/888800 69.25%] train loss: 1.439674997527618e-05 \n",
      "epoch: 43 [616605/888800 69.38%] train loss: 1.4181120604916941e-05 \n",
      "epoch: 43 [617716/888800 69.50%] train loss: 1.394007085764315e-05 \n",
      "epoch: 43 [618827/888800 69.62%] train loss: 1.4406808077183086e-05 \n",
      "epoch: 43 [619938/888800 69.75%] train loss: 1.4012882274982985e-05 \n",
      "epoch: 43 [621049/888800 69.88%] train loss: 1.4493733942799736e-05 \n",
      "epoch: 43 [622160/888800 70.00%] train loss: 1.4712371921632439e-05 \n",
      "epoch: 43 [623271/888800 70.12%] train loss: 1.3959933312435169e-05 \n",
      "epoch: 43 [624382/888800 70.25%] train loss: 1.365091338811908e-05 \n",
      "epoch: 43 [625493/888800 70.38%] train loss: 1.360354963253485e-05 \n",
      "epoch: 43 [626604/888800 70.50%] train loss: 1.3721915820497088e-05 \n",
      "epoch: 43 [627715/888800 70.62%] train loss: 1.3791136552754324e-05 \n",
      "epoch: 43 [628826/888800 70.75%] train loss: 1.3518435480364133e-05 \n",
      "epoch: 43 [629937/888800 70.88%] train loss: 1.3239612599136308e-05 \n",
      "epoch: 43 [631048/888800 71.00%] train loss: 1.3195769497542642e-05 \n",
      "epoch: 43 [632159/888800 71.12%] train loss: 1.4900429050612729e-05 \n",
      "epoch: 43 [633270/888800 71.25%] train loss: 1.450755644327728e-05 \n",
      "epoch: 43 [634381/888800 71.38%] train loss: 1.3580673112301156e-05 \n",
      "epoch: 43 [635492/888800 71.50%] train loss: 1.4471353097178508e-05 \n",
      "epoch: 43 [636603/888800 71.62%] train loss: 1.442852953914553e-05 \n",
      "epoch: 43 [637714/888800 71.75%] train loss: 1.3930887689639349e-05 \n",
      "epoch: 43 [638825/888800 71.88%] train loss: 1.4224129699869081e-05 \n",
      "epoch: 43 [639936/888800 72.00%] train loss: 1.423744652129244e-05 \n",
      "epoch: 43 [641047/888800 72.12%] train loss: 1.4437265235756058e-05 \n",
      "epoch: 43 [642158/888800 72.25%] train loss: 1.3742163901042659e-05 \n",
      "epoch: 43 [643269/888800 72.38%] train loss: 1.4747211025678553e-05 \n",
      "epoch: 43 [644380/888800 72.50%] train loss: 1.2876655091531575e-05 \n",
      "epoch: 43 [645491/888800 72.62%] train loss: 1.3647557352669537e-05 \n",
      "epoch: 43 [646602/888800 72.75%] train loss: 1.4610162907047197e-05 \n",
      "epoch: 43 [647713/888800 72.88%] train loss: 1.5103182704478968e-05 \n",
      "epoch: 43 [648824/888800 73.00%] train loss: 1.4854518667561933e-05 \n",
      "epoch: 43 [649935/888800 73.12%] train loss: 1.479787806601962e-05 \n",
      "epoch: 43 [651046/888800 73.25%] train loss: 1.5110192180145532e-05 \n",
      "epoch: 43 [652157/888800 73.38%] train loss: 1.3656611372425687e-05 \n",
      "epoch: 43 [653268/888800 73.50%] train loss: 1.4290018043539021e-05 \n",
      "epoch: 43 [654379/888800 73.62%] train loss: 1.4853684660920408e-05 \n",
      "epoch: 43 [655490/888800 73.75%] train loss: 1.4007532627147157e-05 \n",
      "epoch: 43 [656601/888800 73.88%] train loss: 1.3767394193564542e-05 \n",
      "epoch: 43 [657712/888800 74.00%] train loss: 1.4235900380299427e-05 \n",
      "epoch: 43 [658823/888800 74.12%] train loss: 1.3717385627387557e-05 \n",
      "epoch: 43 [659934/888800 74.25%] train loss: 1.3722366929869168e-05 \n",
      "epoch: 43 [661045/888800 74.38%] train loss: 1.333490672550397e-05 \n",
      "epoch: 43 [662156/888800 74.50%] train loss: 1.3580051927419845e-05 \n",
      "epoch: 43 [663267/888800 74.62%] train loss: 1.388574492011685e-05 \n",
      "epoch: 43 [664378/888800 74.75%] train loss: 1.5454917956958525e-05 \n",
      "epoch: 43 [665489/888800 74.88%] train loss: 1.582826917001512e-05 \n",
      "epoch: 43 [666600/888800 75.00%] train loss: 1.2963978406332899e-05 \n",
      "epoch: 43 [667711/888800 75.12%] train loss: 1.4375193131854758e-05 \n",
      "epoch: 43 [668822/888800 75.25%] train loss: 1.4171228940540459e-05 \n",
      "epoch: 43 [669933/888800 75.38%] train loss: 1.5038886886031833e-05 \n",
      "epoch: 43 [671044/888800 75.50%] train loss: 1.5906734915915877e-05 \n",
      "epoch: 43 [672155/888800 75.62%] train loss: 1.5637233445886523e-05 \n",
      "epoch: 43 [673266/888800 75.75%] train loss: 1.5059555153129622e-05 \n",
      "epoch: 43 [674377/888800 75.88%] train loss: 1.3240653061075136e-05 \n",
      "epoch: 43 [675488/888800 76.00%] train loss: 1.429201802238822e-05 \n",
      "epoch: 43 [676599/888800 76.12%] train loss: 1.474550117563922e-05 \n",
      "epoch: 43 [677710/888800 76.25%] train loss: 1.587475162523333e-05 \n",
      "epoch: 43 [678821/888800 76.38%] train loss: 1.4757021745026577e-05 \n",
      "epoch: 43 [679932/888800 76.50%] train loss: 1.4031110367795918e-05 \n",
      "epoch: 43 [681043/888800 76.62%] train loss: 1.4531363376590889e-05 \n",
      "epoch: 43 [682154/888800 76.75%] train loss: 1.3800045962852892e-05 \n",
      "epoch: 43 [683265/888800 76.88%] train loss: 1.579463241796475e-05 \n",
      "epoch: 43 [684376/888800 77.00%] train loss: 1.421289471181808e-05 \n",
      "epoch: 43 [685487/888800 77.12%] train loss: 1.5575964425806887e-05 \n",
      "epoch: 43 [686598/888800 77.25%] train loss: 1.444928511773469e-05 \n",
      "epoch: 43 [687709/888800 77.38%] train loss: 1.360745318379486e-05 \n",
      "epoch: 43 [688820/888800 77.50%] train loss: 1.4190187357598916e-05 \n",
      "epoch: 43 [689931/888800 77.62%] train loss: 1.3632562513521407e-05 \n",
      "epoch: 43 [691042/888800 77.75%] train loss: 1.4672721590613946e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [692153/888800 77.88%] train loss: 1.3838075574312825e-05 \n",
      "epoch: 43 [693264/888800 78.00%] train loss: 1.4624930372519884e-05 \n",
      "epoch: 43 [694375/888800 78.12%] train loss: 1.3485293493431527e-05 \n",
      "epoch: 43 [695486/888800 78.25%] train loss: 1.3660061085829511e-05 \n",
      "epoch: 43 [696597/888800 78.38%] train loss: 1.4484452549368143e-05 \n",
      "epoch: 43 [697708/888800 78.50%] train loss: 1.4632099009759258e-05 \n",
      "epoch: 43 [698819/888800 78.62%] train loss: 1.5028966117824893e-05 \n",
      "epoch: 43 [699930/888800 78.75%] train loss: 1.5314639313146472e-05 \n",
      "epoch: 43 [701041/888800 78.88%] train loss: 1.3796894563711248e-05 \n",
      "epoch: 43 [702152/888800 79.00%] train loss: 1.614004941075109e-05 \n",
      "epoch: 43 [703263/888800 79.12%] train loss: 1.4196632037055679e-05 \n",
      "epoch: 43 [704374/888800 79.25%] train loss: 1.517868076916784e-05 \n",
      "epoch: 43 [705485/888800 79.38%] train loss: 1.4470720998360775e-05 \n",
      "epoch: 43 [706596/888800 79.50%] train loss: 1.5083254766068421e-05 \n",
      "epoch: 43 [707707/888800 79.62%] train loss: 1.5493003957089968e-05 \n",
      "epoch: 43 [708818/888800 79.75%] train loss: 1.358763165626442e-05 \n",
      "epoch: 43 [709929/888800 79.88%] train loss: 1.4249180821934715e-05 \n",
      "epoch: 43 [711040/888800 80.00%] train loss: 1.4318013199954294e-05 \n",
      "epoch: 43 [712151/888800 80.12%] train loss: 1.4123632354312576e-05 \n",
      "epoch: 43 [713262/888800 80.25%] train loss: 1.4642322639701888e-05 \n",
      "epoch: 43 [714373/888800 80.38%] train loss: 1.4134347111394163e-05 \n",
      "epoch: 43 [715484/888800 80.50%] train loss: 1.4599680980609264e-05 \n",
      "epoch: 43 [716595/888800 80.62%] train loss: 1.4329187251860276e-05 \n",
      "epoch: 43 [717706/888800 80.75%] train loss: 1.5434306988026947e-05 \n",
      "epoch: 43 [718817/888800 80.88%] train loss: 1.4759530131414067e-05 \n",
      "epoch: 43 [719928/888800 81.00%] train loss: 1.3501410649041645e-05 \n",
      "epoch: 43 [721039/888800 81.12%] train loss: 1.456461632187711e-05 \n",
      "epoch: 43 [722150/888800 81.25%] train loss: 1.4905343050486408e-05 \n",
      "epoch: 43 [723261/888800 81.38%] train loss: 1.3113635759509634e-05 \n",
      "epoch: 43 [724372/888800 81.50%] train loss: 1.4735458535142243e-05 \n",
      "epoch: 43 [725483/888800 81.62%] train loss: 1.3848674825567286e-05 \n",
      "epoch: 43 [726594/888800 81.75%] train loss: 1.49000034070923e-05 \n",
      "epoch: 43 [727705/888800 81.88%] train loss: 1.488001726102084e-05 \n",
      "epoch: 43 [728816/888800 82.00%] train loss: 1.5707950296928175e-05 \n",
      "epoch: 43 [729927/888800 82.12%] train loss: 1.4097310668148566e-05 \n",
      "epoch: 43 [731038/888800 82.25%] train loss: 1.3325792679097503e-05 \n",
      "epoch: 43 [732149/888800 82.38%] train loss: 1.3183736882638186e-05 \n",
      "epoch: 43 [733260/888800 82.50%] train loss: 1.4393990568351e-05 \n",
      "epoch: 43 [734371/888800 82.62%] train loss: 1.4456748431257438e-05 \n",
      "epoch: 43 [735482/888800 82.75%] train loss: 1.3292467883729842e-05 \n",
      "epoch: 43 [736593/888800 82.88%] train loss: 1.41117943712743e-05 \n",
      "epoch: 43 [737704/888800 83.00%] train loss: 1.5168017853284255e-05 \n",
      "epoch: 43 [738815/888800 83.12%] train loss: 1.3708366168430075e-05 \n",
      "epoch: 43 [739926/888800 83.25%] train loss: 1.4722860214533284e-05 \n",
      "epoch: 43 [741037/888800 83.38%] train loss: 1.4244923477235716e-05 \n",
      "epoch: 43 [742148/888800 83.50%] train loss: 1.353233074041782e-05 \n",
      "epoch: 43 [743259/888800 83.62%] train loss: 1.3941196812083945e-05 \n",
      "epoch: 43 [744370/888800 83.75%] train loss: 1.476879606343573e-05 \n",
      "epoch: 43 [745481/888800 83.88%] train loss: 1.4060183275432792e-05 \n",
      "epoch: 43 [746592/888800 84.00%] train loss: 1.3702776413992979e-05 \n",
      "epoch: 43 [747703/888800 84.12%] train loss: 1.3102661796438042e-05 \n",
      "epoch: 43 [748814/888800 84.25%] train loss: 1.340481230727164e-05 \n",
      "epoch: 43 [749925/888800 84.38%] train loss: 1.562577199365478e-05 \n",
      "epoch: 43 [751036/888800 84.50%] train loss: 1.2965719179192092e-05 \n",
      "epoch: 43 [752147/888800 84.62%] train loss: 1.3713576663576532e-05 \n",
      "epoch: 43 [753258/888800 84.75%] train loss: 1.3943572412244976e-05 \n",
      "epoch: 43 [754369/888800 84.88%] train loss: 1.4029560588824097e-05 \n",
      "epoch: 43 [755480/888800 85.00%] train loss: 1.5411020285682753e-05 \n",
      "epoch: 43 [756591/888800 85.12%] train loss: 1.4450173694058321e-05 \n",
      "epoch: 43 [757702/888800 85.25%] train loss: 1.2681760381383356e-05 \n",
      "epoch: 43 [758813/888800 85.38%] train loss: 1.3483270777214784e-05 \n",
      "epoch: 43 [759924/888800 85.50%] train loss: 1.5901357983238995e-05 \n",
      "epoch: 43 [761035/888800 85.62%] train loss: 1.4745346561539918e-05 \n",
      "epoch: 43 [762146/888800 85.75%] train loss: 1.3911047062720172e-05 \n",
      "epoch: 43 [763257/888800 85.88%] train loss: 1.5320374586735852e-05 \n",
      "epoch: 43 [764368/888800 86.00%] train loss: 1.4092079254623968e-05 \n",
      "epoch: 43 [765479/888800 86.12%] train loss: 1.4007239769853186e-05 \n",
      "epoch: 43 [766590/888800 86.25%] train loss: 1.3555263649323024e-05 \n",
      "epoch: 43 [767701/888800 86.38%] train loss: 1.4920931789674796e-05 \n",
      "epoch: 43 [768812/888800 86.50%] train loss: 1.385522773489356e-05 \n",
      "epoch: 43 [769923/888800 86.62%] train loss: 1.479765160183888e-05 \n",
      "epoch: 43 [771034/888800 86.75%] train loss: 1.4398025996342767e-05 \n",
      "epoch: 43 [772145/888800 86.88%] train loss: 1.3517482329916675e-05 \n",
      "epoch: 43 [773256/888800 87.00%] train loss: 1.3514449165086262e-05 \n",
      "epoch: 43 [774367/888800 87.12%] train loss: 1.4016989553056192e-05 \n",
      "epoch: 43 [775478/888800 87.25%] train loss: 1.4114870282355696e-05 \n",
      "epoch: 43 [776589/888800 87.38%] train loss: 1.4799713426327799e-05 \n",
      "epoch: 43 [777700/888800 87.50%] train loss: 1.549132321088109e-05 \n",
      "epoch: 43 [778811/888800 87.62%] train loss: 1.500540747656487e-05 \n",
      "epoch: 43 [779922/888800 87.75%] train loss: 1.346400586044183e-05 \n",
      "epoch: 43 [781033/888800 87.88%] train loss: 1.4633349564974196e-05 \n",
      "epoch: 43 [782144/888800 88.00%] train loss: 1.3817554645356722e-05 \n",
      "epoch: 43 [783255/888800 88.12%] train loss: 1.3801751265418716e-05 \n",
      "epoch: 43 [784366/888800 88.25%] train loss: 1.374658131680917e-05 \n",
      "epoch: 43 [785477/888800 88.38%] train loss: 1.4417910279007629e-05 \n",
      "epoch: 43 [786588/888800 88.50%] train loss: 1.3230709555500653e-05 \n",
      "epoch: 43 [787699/888800 88.62%] train loss: 1.5584679204039276e-05 \n",
      "epoch: 43 [788810/888800 88.75%] train loss: 1.4267300684878137e-05 \n",
      "epoch: 43 [789921/888800 88.88%] train loss: 1.433644320059102e-05 \n",
      "epoch: 43 [791032/888800 89.00%] train loss: 1.2954958037880715e-05 \n",
      "epoch: 43 [792143/888800 89.12%] train loss: 1.408210755471373e-05 \n",
      "epoch: 43 [793254/888800 89.25%] train loss: 1.5071943380462471e-05 \n",
      "epoch: 43 [794365/888800 89.38%] train loss: 1.4494545212073717e-05 \n",
      "epoch: 43 [795476/888800 89.50%] train loss: 1.597439040779136e-05 \n",
      "epoch: 43 [796587/888800 89.62%] train loss: 1.4045810530660674e-05 \n",
      "epoch: 43 [797698/888800 89.75%] train loss: 1.5324649211834185e-05 \n",
      "epoch: 43 [798809/888800 89.88%] train loss: 1.5280229490599595e-05 \n",
      "epoch: 43 [799920/888800 90.00%] train loss: 1.393460206600139e-05 \n",
      "epoch: 43 [801031/888800 90.12%] train loss: 1.34524480017717e-05 \n",
      "epoch: 43 [802142/888800 90.25%] train loss: 1.398787662765244e-05 \n",
      "epoch: 43 [803253/888800 90.38%] train loss: 1.4005341654410586e-05 \n",
      "epoch: 43 [804364/888800 90.50%] train loss: 1.329745828115847e-05 \n",
      "epoch: 43 [805475/888800 90.62%] train loss: 1.5973684639902785e-05 \n",
      "epoch: 43 [806586/888800 90.75%] train loss: 1.2854939086537343e-05 \n",
      "epoch: 43 [807697/888800 90.88%] train loss: 1.669108314672485e-05 \n",
      "epoch: 43 [808808/888800 91.00%] train loss: 1.4353757251228672e-05 \n",
      "epoch: 43 [809919/888800 91.12%] train loss: 1.2210149179736618e-05 \n",
      "epoch: 43 [811030/888800 91.25%] train loss: 1.5352930859080516e-05 \n",
      "epoch: 43 [812141/888800 91.38%] train loss: 1.4173467207001522e-05 \n",
      "epoch: 43 [813252/888800 91.50%] train loss: 1.4680036656500306e-05 \n",
      "epoch: 43 [814363/888800 91.62%] train loss: 1.3845209650753532e-05 \n",
      "epoch: 43 [815474/888800 91.75%] train loss: 1.548960426589474e-05 \n",
      "epoch: 43 [816585/888800 91.88%] train loss: 1.3713940461457241e-05 \n",
      "epoch: 43 [817696/888800 92.00%] train loss: 1.3795252016279846e-05 \n",
      "epoch: 43 [818807/888800 92.12%] train loss: 1.3855252291250508e-05 \n",
      "epoch: 43 [819918/888800 92.25%] train loss: 1.3921046047471464e-05 \n",
      "epoch: 43 [821029/888800 92.38%] train loss: 1.4183607163431589e-05 \n",
      "epoch: 43 [822140/888800 92.50%] train loss: 1.4431879208132159e-05 \n",
      "epoch: 43 [823251/888800 92.62%] train loss: 1.3609103007183876e-05 \n",
      "epoch: 43 [824362/888800 92.75%] train loss: 1.357426754111657e-05 \n",
      "epoch: 43 [825473/888800 92.88%] train loss: 1.3795477570965886e-05 \n",
      "epoch: 43 [826584/888800 93.00%] train loss: 1.4777687283640262e-05 \n",
      "epoch: 43 [827695/888800 93.12%] train loss: 1.5174506188486703e-05 \n",
      "epoch: 43 [828806/888800 93.25%] train loss: 1.313663597102277e-05 \n",
      "epoch: 43 [829917/888800 93.38%] train loss: 1.5479177818633616e-05 \n",
      "epoch: 43 [831028/888800 93.50%] train loss: 1.4193049537425395e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 [832139/888800 93.62%] train loss: 1.3808133189741056e-05 \n",
      "epoch: 43 [833250/888800 93.75%] train loss: 1.3518030755221844e-05 \n",
      "epoch: 43 [834361/888800 93.88%] train loss: 1.4693194316350855e-05 \n",
      "epoch: 43 [835472/888800 94.00%] train loss: 1.4998981896496844e-05 \n",
      "epoch: 43 [836583/888800 94.12%] train loss: 1.3806841707264539e-05 \n",
      "epoch: 43 [837694/888800 94.25%] train loss: 1.4710745745105669e-05 \n",
      "epoch: 43 [838805/888800 94.38%] train loss: 1.3993316315463744e-05 \n",
      "epoch: 43 [839916/888800 94.50%] train loss: 1.4160685168462805e-05 \n",
      "epoch: 43 [841027/888800 94.62%] train loss: 1.5410876585519873e-05 \n",
      "epoch: 43 [842138/888800 94.75%] train loss: 1.4356893188960385e-05 \n",
      "epoch: 43 [843249/888800 94.88%] train loss: 1.4556704627466388e-05 \n",
      "epoch: 43 [844360/888800 95.00%] train loss: 1.3626950021716766e-05 \n",
      "epoch: 43 [845471/888800 95.12%] train loss: 1.731083648337517e-05 \n",
      "epoch: 43 [846582/888800 95.25%] train loss: 1.4719537830387708e-05 \n",
      "epoch: 43 [847693/888800 95.38%] train loss: 1.6300684364978224e-05 \n",
      "epoch: 43 [848804/888800 95.50%] train loss: 1.5526449715252966e-05 \n",
      "epoch: 43 [849915/888800 95.62%] train loss: 1.4404058674699627e-05 \n",
      "epoch: 43 [851026/888800 95.75%] train loss: 1.5022234947537072e-05 \n",
      "epoch: 43 [852137/888800 95.88%] train loss: 1.5466444892808795e-05 \n",
      "epoch: 43 [853248/888800 96.00%] train loss: 1.4864631339150947e-05 \n",
      "epoch: 43 [854359/888800 96.12%] train loss: 1.3991222658660263e-05 \n",
      "epoch: 43 [855470/888800 96.25%] train loss: 1.485076154494891e-05 \n",
      "epoch: 43 [856581/888800 96.38%] train loss: 1.5584975699312054e-05 \n",
      "epoch: 43 [857692/888800 96.50%] train loss: 1.5195288142422214e-05 \n",
      "epoch: 43 [858803/888800 96.62%] train loss: 1.3733985724684317e-05 \n",
      "epoch: 43 [859914/888800 96.75%] train loss: 1.4731459486938547e-05 \n",
      "epoch: 43 [861025/888800 96.88%] train loss: 1.5168621757766232e-05 \n",
      "epoch: 43 [862136/888800 97.00%] train loss: 1.39070089062443e-05 \n",
      "epoch: 43 [863247/888800 97.12%] train loss: 1.4200672922015656e-05 \n",
      "epoch: 43 [864358/888800 97.25%] train loss: 1.4117003047431353e-05 \n",
      "epoch: 43 [865469/888800 97.38%] train loss: 1.3578348443843424e-05 \n",
      "epoch: 43 [866580/888800 97.50%] train loss: 1.4787551663175691e-05 \n",
      "epoch: 43 [867691/888800 97.62%] train loss: 1.4919675777491648e-05 \n",
      "epoch: 43 [868802/888800 97.75%] train loss: 1.3776571904600132e-05 \n",
      "epoch: 43 [869913/888800 97.88%] train loss: 1.3841634427080862e-05 \n",
      "epoch: 43 [871024/888800 98.00%] train loss: 1.427819279342657e-05 \n",
      "epoch: 43 [872135/888800 98.12%] train loss: 1.3533707715396304e-05 \n",
      "epoch: 43 [873246/888800 98.25%] train loss: 1.4352034668263514e-05 \n",
      "epoch: 43 [874357/888800 98.38%] train loss: 1.4698500308440998e-05 \n",
      "epoch: 43 [875468/888800 98.50%] train loss: 1.3634319657285232e-05 \n",
      "epoch: 43 [876579/888800 98.62%] train loss: 1.3337864402274136e-05 \n",
      "epoch: 43 [877690/888800 98.75%] train loss: 1.4897704204486217e-05 \n",
      "epoch: 43 [878801/888800 98.88%] train loss: 1.3222150300862268e-05 \n",
      "epoch: 43 [879912/888800 99.00%] train loss: 1.4786036445002537e-05 \n",
      "epoch: 43 [881023/888800 99.12%] train loss: 1.4000656847201753e-05 \n",
      "epoch: 43 [882134/888800 99.25%] train loss: 1.3793156540486962e-05 \n",
      "epoch: 43 [883245/888800 99.38%] train loss: 1.4354312042996753e-05 \n",
      "epoch: 43 [884356/888800 99.50%] train loss: 1.4045250281924382e-05 \n",
      "epoch: 43 [885467/888800 99.62%] train loss: 1.4217404896044172e-05 \n",
      "epoch: 43 [886578/888800 99.75%] train loss: 1.3781673260382377e-05 \n",
      "epoch: 43 [887689/888800 99.88%] train loss: 1.3346283594728447e-05 \n",
      "epoch: 44 [0/888800 0.00%] train loss: 1.5149413229664788e-05 \n",
      "epoch: 44 [1111/888800 0.12%] train loss: 1.5504168914048932e-05 \n",
      "epoch: 44 [2222/888800 0.25%] train loss: 1.2819919902540278e-05 \n",
      "epoch: 44 [3333/888800 0.38%] train loss: 1.4614141946367454e-05 \n",
      "epoch: 44 [4444/888800 0.50%] train loss: 1.4089936485106591e-05 \n",
      "epoch: 44 [5555/888800 0.62%] train loss: 1.2880569556728005e-05 \n",
      "epoch: 44 [6666/888800 0.75%] train loss: 1.3825451787852217e-05 \n",
      "epoch: 44 [7777/888800 0.88%] train loss: 1.2567867997859139e-05 \n",
      "epoch: 44 [8888/888800 1.00%] train loss: 1.5236182662192732e-05 \n",
      "epoch: 44 [9999/888800 1.12%] train loss: 1.4831650332780555e-05 \n",
      "epoch: 44 [11110/888800 1.25%] train loss: 1.5477929991902784e-05 \n",
      "epoch: 44 [12221/888800 1.38%] train loss: 1.4456792087003123e-05 \n",
      "epoch: 44 [13332/888800 1.50%] train loss: 1.4506586012430489e-05 \n",
      "epoch: 44 [14443/888800 1.62%] train loss: 1.4431883755605668e-05 \n",
      "epoch: 44 [15554/888800 1.75%] train loss: 1.5079851436894387e-05 \n",
      "epoch: 44 [16665/888800 1.88%] train loss: 1.295407309953589e-05 \n",
      "epoch: 44 [17776/888800 2.00%] train loss: 1.412404981238069e-05 \n",
      "epoch: 44 [18887/888800 2.12%] train loss: 1.3398523151408881e-05 \n",
      "epoch: 44 [19998/888800 2.25%] train loss: 1.3783162103209179e-05 \n",
      "epoch: 44 [21109/888800 2.38%] train loss: 1.319796410825802e-05 \n",
      "epoch: 44 [22220/888800 2.50%] train loss: 1.4967209608585108e-05 \n",
      "epoch: 44 [23331/888800 2.62%] train loss: 1.4113465113041457e-05 \n",
      "epoch: 44 [24442/888800 2.75%] train loss: 1.4548506442224607e-05 \n",
      "epoch: 44 [25553/888800 2.88%] train loss: 1.3974537978356238e-05 \n",
      "epoch: 44 [26664/888800 3.00%] train loss: 1.4545374142471701e-05 \n",
      "epoch: 44 [27775/888800 3.12%] train loss: 1.5190097656159196e-05 \n",
      "epoch: 44 [28886/888800 3.25%] train loss: 1.500421240052674e-05 \n",
      "epoch: 44 [29997/888800 3.38%] train loss: 1.3838166523783002e-05 \n",
      "epoch: 44 [31108/888800 3.50%] train loss: 1.5217943655443378e-05 \n",
      "epoch: 44 [32219/888800 3.62%] train loss: 1.3056901480013039e-05 \n",
      "epoch: 44 [33330/888800 3.75%] train loss: 1.6604897609795444e-05 \n",
      "epoch: 44 [34441/888800 3.88%] train loss: 1.447430895495927e-05 \n",
      "epoch: 44 [35552/888800 4.00%] train loss: 1.3709159247810021e-05 \n",
      "epoch: 44 [36663/888800 4.12%] train loss: 1.6294630768243223e-05 \n",
      "epoch: 44 [37774/888800 4.25%] train loss: 1.3600424608739559e-05 \n",
      "epoch: 44 [38885/888800 4.38%] train loss: 1.4250947060645558e-05 \n",
      "epoch: 44 [39996/888800 4.50%] train loss: 1.5330018868553452e-05 \n",
      "epoch: 44 [41107/888800 4.62%] train loss: 1.379337118123658e-05 \n",
      "epoch: 44 [42218/888800 4.75%] train loss: 1.562223224027548e-05 \n",
      "epoch: 44 [43329/888800 4.88%] train loss: 1.5434619854204357e-05 \n",
      "epoch: 44 [44440/888800 5.00%] train loss: 1.3538048733607866e-05 \n",
      "epoch: 44 [45551/888800 5.12%] train loss: 1.3939550626673736e-05 \n",
      "epoch: 44 [46662/888800 5.25%] train loss: 1.5355104551417753e-05 \n",
      "epoch: 44 [47773/888800 5.38%] train loss: 1.3840315659763291e-05 \n",
      "epoch: 44 [48884/888800 5.50%] train loss: 1.4683966583106667e-05 \n",
      "epoch: 44 [49995/888800 5.62%] train loss: 1.2846305253333412e-05 \n",
      "epoch: 44 [51106/888800 5.75%] train loss: 1.4421884770854376e-05 \n",
      "epoch: 44 [52217/888800 5.88%] train loss: 1.3755197869613767e-05 \n",
      "epoch: 44 [53328/888800 6.00%] train loss: 1.4684100278827827e-05 \n",
      "epoch: 44 [54439/888800 6.12%] train loss: 1.3746244803769514e-05 \n",
      "epoch: 44 [55550/888800 6.25%] train loss: 1.4588210433430504e-05 \n",
      "epoch: 44 [56661/888800 6.38%] train loss: 1.4950287550163921e-05 \n",
      "epoch: 44 [57772/888800 6.50%] train loss: 1.456813515687827e-05 \n",
      "epoch: 44 [58883/888800 6.62%] train loss: 1.3724728887609672e-05 \n",
      "epoch: 44 [59994/888800 6.75%] train loss: 1.3289894923218526e-05 \n",
      "epoch: 44 [61105/888800 6.88%] train loss: 1.3966820006316993e-05 \n",
      "epoch: 44 [62216/888800 7.00%] train loss: 1.2986662113689817e-05 \n",
      "epoch: 44 [63327/888800 7.12%] train loss: 1.3749801837548148e-05 \n",
      "epoch: 44 [64438/888800 7.25%] train loss: 1.4237878531275783e-05 \n",
      "epoch: 44 [65549/888800 7.38%] train loss: 1.4152735275274608e-05 \n",
      "epoch: 44 [66660/888800 7.50%] train loss: 1.4018787624081597e-05 \n",
      "epoch: 44 [67771/888800 7.62%] train loss: 1.4607611774408724e-05 \n",
      "epoch: 44 [68882/888800 7.75%] train loss: 1.4341799214889761e-05 \n",
      "epoch: 44 [69993/888800 7.88%] train loss: 1.5161103874561377e-05 \n",
      "epoch: 44 [71104/888800 8.00%] train loss: 1.5654404705855995e-05 \n",
      "epoch: 44 [72215/888800 8.12%] train loss: 1.4146196917863563e-05 \n",
      "epoch: 44 [73326/888800 8.25%] train loss: 1.4131544048723299e-05 \n",
      "epoch: 44 [74437/888800 8.38%] train loss: 1.5060916666698176e-05 \n",
      "epoch: 44 [75548/888800 8.50%] train loss: 1.424072434019763e-05 \n",
      "epoch: 44 [76659/888800 8.62%] train loss: 1.4095526239543688e-05 \n",
      "epoch: 44 [77770/888800 8.75%] train loss: 1.374704788759118e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [78881/888800 8.88%] train loss: 1.4911150174157228e-05 \n",
      "epoch: 44 [79992/888800 9.00%] train loss: 1.3538434359361418e-05 \n",
      "epoch: 44 [81103/888800 9.12%] train loss: 1.4772272152185906e-05 \n",
      "epoch: 44 [82214/888800 9.25%] train loss: 1.3682634744327515e-05 \n",
      "epoch: 44 [83325/888800 9.38%] train loss: 1.3794777260045521e-05 \n",
      "epoch: 44 [84436/888800 9.50%] train loss: 1.3574815966421738e-05 \n",
      "epoch: 44 [85547/888800 9.62%] train loss: 1.4423432730836794e-05 \n",
      "epoch: 44 [86658/888800 9.75%] train loss: 1.4829754036327358e-05 \n",
      "epoch: 44 [87769/888800 9.88%] train loss: 1.5034497664601076e-05 \n",
      "epoch: 44 [88880/888800 10.00%] train loss: 1.4447534340433776e-05 \n",
      "epoch: 44 [89991/888800 10.12%] train loss: 1.4264482160797343e-05 \n",
      "epoch: 44 [91102/888800 10.25%] train loss: 1.4263157936511561e-05 \n",
      "epoch: 44 [92213/888800 10.38%] train loss: 1.4458894838753622e-05 \n",
      "epoch: 44 [93324/888800 10.50%] train loss: 1.3627797670778818e-05 \n",
      "epoch: 44 [94435/888800 10.62%] train loss: 1.552263529447373e-05 \n",
      "epoch: 44 [95546/888800 10.75%] train loss: 1.3508717529475689e-05 \n",
      "epoch: 44 [96657/888800 10.88%] train loss: 1.512261042080354e-05 \n",
      "epoch: 44 [97768/888800 11.00%] train loss: 1.4077486412134022e-05 \n",
      "epoch: 44 [98879/888800 11.12%] train loss: 1.4596382243325934e-05 \n",
      "epoch: 44 [99990/888800 11.25%] train loss: 1.5751396858831868e-05 \n",
      "epoch: 44 [101101/888800 11.38%] train loss: 1.5022461411717813e-05 \n",
      "epoch: 44 [102212/888800 11.50%] train loss: 1.4724565517099109e-05 \n",
      "epoch: 44 [103323/888800 11.62%] train loss: 1.4621211448684335e-05 \n",
      "epoch: 44 [104434/888800 11.75%] train loss: 1.3980065887153614e-05 \n",
      "epoch: 44 [105545/888800 11.88%] train loss: 1.63046734087402e-05 \n",
      "epoch: 44 [106656/888800 12.00%] train loss: 1.4348066542879678e-05 \n",
      "epoch: 44 [107767/888800 12.12%] train loss: 1.5039980098663364e-05 \n",
      "epoch: 44 [108878/888800 12.25%] train loss: 1.3675079571839888e-05 \n",
      "epoch: 44 [109989/888800 12.38%] train loss: 1.3885323824069928e-05 \n",
      "epoch: 44 [111100/888800 12.50%] train loss: 1.3805765775032341e-05 \n",
      "epoch: 44 [112211/888800 12.62%] train loss: 1.5512430763919838e-05 \n",
      "epoch: 44 [113322/888800 12.75%] train loss: 1.586381404194981e-05 \n",
      "epoch: 44 [114433/888800 12.88%] train loss: 1.4400108739209827e-05 \n",
      "epoch: 44 [115544/888800 13.00%] train loss: 1.4605710020987317e-05 \n",
      "epoch: 44 [116655/888800 13.12%] train loss: 1.4874863154545892e-05 \n",
      "epoch: 44 [117766/888800 13.25%] train loss: 1.42348608278553e-05 \n",
      "epoch: 44 [118877/888800 13.38%] train loss: 1.3419386959867552e-05 \n",
      "epoch: 44 [119988/888800 13.50%] train loss: 1.3837619917467237e-05 \n",
      "epoch: 44 [121099/888800 13.62%] train loss: 1.3960298929305281e-05 \n",
      "epoch: 44 [122210/888800 13.75%] train loss: 1.372168117086403e-05 \n",
      "epoch: 44 [123321/888800 13.88%] train loss: 1.4822683624515776e-05 \n",
      "epoch: 44 [124432/888800 14.00%] train loss: 1.5079777767823543e-05 \n",
      "epoch: 44 [125543/888800 14.12%] train loss: 1.5022727893665433e-05 \n",
      "epoch: 44 [126654/888800 14.25%] train loss: 1.4544924852089025e-05 \n",
      "epoch: 44 [127765/888800 14.38%] train loss: 1.3834226592734922e-05 \n",
      "epoch: 44 [128876/888800 14.50%] train loss: 1.3226564988144673e-05 \n",
      "epoch: 44 [129987/888800 14.62%] train loss: 1.5289364455384202e-05 \n",
      "epoch: 44 [131098/888800 14.75%] train loss: 1.2968531336809974e-05 \n",
      "epoch: 44 [132209/888800 14.88%] train loss: 1.3999379007145762e-05 \n",
      "epoch: 44 [133320/888800 15.00%] train loss: 1.4114120858721435e-05 \n",
      "epoch: 44 [134431/888800 15.12%] train loss: 1.4765947526029777e-05 \n",
      "epoch: 44 [135542/888800 15.25%] train loss: 1.5057474229251966e-05 \n",
      "epoch: 44 [136653/888800 15.38%] train loss: 1.4348948752740398e-05 \n",
      "epoch: 44 [137764/888800 15.50%] train loss: 1.3003476851736195e-05 \n",
      "epoch: 44 [138875/888800 15.62%] train loss: 1.3968474377179518e-05 \n",
      "epoch: 44 [139986/888800 15.75%] train loss: 1.4432066564040724e-05 \n",
      "epoch: 44 [141097/888800 15.88%] train loss: 1.5258892744896002e-05 \n",
      "epoch: 44 [142208/888800 16.00%] train loss: 1.543468897580169e-05 \n",
      "epoch: 44 [143319/888800 16.12%] train loss: 1.4354326594911981e-05 \n",
      "epoch: 44 [144430/888800 16.25%] train loss: 1.3867396774003282e-05 \n",
      "epoch: 44 [145541/888800 16.38%] train loss: 1.4584978089260403e-05 \n",
      "epoch: 44 [146652/888800 16.50%] train loss: 1.4984308108978439e-05 \n",
      "epoch: 44 [147763/888800 16.62%] train loss: 1.4004246622789651e-05 \n",
      "epoch: 44 [148874/888800 16.75%] train loss: 1.3990255865792278e-05 \n",
      "epoch: 44 [149985/888800 16.88%] train loss: 1.4546962120220996e-05 \n",
      "epoch: 44 [151096/888800 17.00%] train loss: 1.3912823305872735e-05 \n",
      "epoch: 44 [152207/888800 17.12%] train loss: 1.4469500456470996e-05 \n",
      "epoch: 44 [153318/888800 17.25%] train loss: 1.3177734217606485e-05 \n",
      "epoch: 44 [154429/888800 17.38%] train loss: 1.3614508134196512e-05 \n",
      "epoch: 44 [155540/888800 17.50%] train loss: 1.3416075489658397e-05 \n",
      "epoch: 44 [156651/888800 17.62%] train loss: 1.3308940651768353e-05 \n",
      "epoch: 44 [157762/888800 17.75%] train loss: 1.5123183402465656e-05 \n",
      "epoch: 44 [158873/888800 17.88%] train loss: 1.4182147424435243e-05 \n",
      "epoch: 44 [159984/888800 18.00%] train loss: 1.5198581422737334e-05 \n",
      "epoch: 44 [161095/888800 18.12%] train loss: 1.3969848623673897e-05 \n",
      "epoch: 44 [162206/888800 18.25%] train loss: 1.3264091649034526e-05 \n",
      "epoch: 44 [163317/888800 18.38%] train loss: 1.3820667845720891e-05 \n",
      "epoch: 44 [164428/888800 18.50%] train loss: 1.4443546206166502e-05 \n",
      "epoch: 44 [165539/888800 18.62%] train loss: 1.3160488379071467e-05 \n",
      "epoch: 44 [166650/888800 18.75%] train loss: 1.375710780848749e-05 \n",
      "epoch: 44 [167761/888800 18.88%] train loss: 1.3590896742243785e-05 \n",
      "epoch: 44 [168872/888800 19.00%] train loss: 1.3920516721555032e-05 \n",
      "epoch: 44 [169983/888800 19.12%] train loss: 1.4627758901042398e-05 \n",
      "epoch: 44 [171094/888800 19.25%] train loss: 1.4571104657079559e-05 \n",
      "epoch: 44 [172205/888800 19.38%] train loss: 1.4154375094221905e-05 \n",
      "epoch: 44 [173316/888800 19.50%] train loss: 1.4216518138709944e-05 \n",
      "epoch: 44 [174427/888800 19.62%] train loss: 1.4511335393763147e-05 \n",
      "epoch: 44 [175538/888800 19.75%] train loss: 1.434527166566113e-05 \n",
      "epoch: 44 [176649/888800 19.88%] train loss: 1.279902153328294e-05 \n",
      "epoch: 44 [177760/888800 20.00%] train loss: 1.591006548551377e-05 \n",
      "epoch: 44 [178871/888800 20.12%] train loss: 1.49769011841272e-05 \n",
      "epoch: 44 [179982/888800 20.25%] train loss: 1.4926599760656245e-05 \n",
      "epoch: 44 [181093/888800 20.38%] train loss: 1.4453151379711926e-05 \n",
      "epoch: 44 [182204/888800 20.50%] train loss: 1.4235960406949744e-05 \n",
      "epoch: 44 [183315/888800 20.62%] train loss: 1.3456463420880027e-05 \n",
      "epoch: 44 [184426/888800 20.75%] train loss: 1.4369365089805797e-05 \n",
      "epoch: 44 [185537/888800 20.88%] train loss: 1.4572360669262707e-05 \n",
      "epoch: 44 [186648/888800 21.00%] train loss: 1.3799874977848958e-05 \n",
      "epoch: 44 [187759/888800 21.12%] train loss: 1.292805427510757e-05 \n",
      "epoch: 44 [188870/888800 21.25%] train loss: 1.4460252714343369e-05 \n",
      "epoch: 44 [189981/888800 21.38%] train loss: 1.4545039448421448e-05 \n",
      "epoch: 44 [191092/888800 21.50%] train loss: 1.4306981029221788e-05 \n",
      "epoch: 44 [192203/888800 21.62%] train loss: 1.3779180335404817e-05 \n",
      "epoch: 44 [193314/888800 21.75%] train loss: 1.5051673472044058e-05 \n",
      "epoch: 44 [194425/888800 21.88%] train loss: 1.3620698155136779e-05 \n",
      "epoch: 44 [195536/888800 22.00%] train loss: 1.365748539683409e-05 \n",
      "epoch: 44 [196647/888800 22.12%] train loss: 1.3755713553109672e-05 \n",
      "epoch: 44 [197758/888800 22.25%] train loss: 1.4649129298049957e-05 \n",
      "epoch: 44 [198869/888800 22.38%] train loss: 1.5578292732243426e-05 \n",
      "epoch: 44 [199980/888800 22.50%] train loss: 1.3886907254345715e-05 \n",
      "epoch: 44 [201091/888800 22.62%] train loss: 1.5048307432152797e-05 \n",
      "epoch: 44 [202202/888800 22.75%] train loss: 1.488678390160203e-05 \n",
      "epoch: 44 [203313/888800 22.88%] train loss: 1.3737959307036363e-05 \n",
      "epoch: 44 [204424/888800 23.00%] train loss: 1.447321119485423e-05 \n",
      "epoch: 44 [205535/888800 23.12%] train loss: 1.4027585166331846e-05 \n",
      "epoch: 44 [206646/888800 23.25%] train loss: 1.3015915101277642e-05 \n",
      "epoch: 44 [207757/888800 23.38%] train loss: 1.5283005268429406e-05 \n",
      "epoch: 44 [208868/888800 23.50%] train loss: 1.3730152204516344e-05 \n",
      "epoch: 44 [209979/888800 23.62%] train loss: 1.5591809642501175e-05 \n",
      "epoch: 44 [211090/888800 23.75%] train loss: 1.4819578609603923e-05 \n",
      "epoch: 44 [212201/888800 23.88%] train loss: 1.355048607365461e-05 \n",
      "epoch: 44 [213312/888800 24.00%] train loss: 1.4756548807781655e-05 \n",
      "epoch: 44 [214423/888800 24.12%] train loss: 1.3885641237720847e-05 \n",
      "epoch: 44 [215534/888800 24.25%] train loss: 1.3595647033071145e-05 \n",
      "epoch: 44 [216645/888800 24.38%] train loss: 1.4069097233004868e-05 \n",
      "epoch: 44 [217756/888800 24.50%] train loss: 1.498738129157573e-05 \n",
      "epoch: 44 [218867/888800 24.62%] train loss: 1.3868358109903056e-05 \n",
      "epoch: 44 [219978/888800 24.75%] train loss: 1.510342008259613e-05 \n",
      "epoch: 44 [221089/888800 24.88%] train loss: 1.535674891783856e-05 \n",
      "epoch: 44 [222200/888800 25.00%] train loss: 1.5448453268618323e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [223311/888800 25.12%] train loss: 1.4843531971564516e-05 \n",
      "epoch: 44 [224422/888800 25.25%] train loss: 1.4860148439765908e-05 \n",
      "epoch: 44 [225533/888800 25.38%] train loss: 1.538861579319928e-05 \n",
      "epoch: 44 [226644/888800 25.50%] train loss: 1.3406337529886514e-05 \n",
      "epoch: 44 [227755/888800 25.62%] train loss: 1.4024770280229859e-05 \n",
      "epoch: 44 [228866/888800 25.75%] train loss: 1.2957732906215824e-05 \n",
      "epoch: 44 [229977/888800 25.88%] train loss: 1.4332640603242908e-05 \n",
      "epoch: 44 [231088/888800 26.00%] train loss: 1.5287874703062698e-05 \n",
      "epoch: 44 [232199/888800 26.12%] train loss: 1.3956369912193622e-05 \n",
      "epoch: 44 [233310/888800 26.25%] train loss: 1.3825267160427757e-05 \n",
      "epoch: 44 [234421/888800 26.38%] train loss: 1.4082712368690409e-05 \n",
      "epoch: 44 [235532/888800 26.50%] train loss: 1.3109352039464284e-05 \n",
      "epoch: 44 [236643/888800 26.62%] train loss: 1.3601480532088317e-05 \n",
      "epoch: 44 [237754/888800 26.75%] train loss: 1.358621557301376e-05 \n",
      "epoch: 44 [238865/888800 26.88%] train loss: 1.3233848221716471e-05 \n",
      "epoch: 44 [239976/888800 27.00%] train loss: 1.32508939714171e-05 \n",
      "epoch: 44 [241087/888800 27.12%] train loss: 1.3925183338869829e-05 \n",
      "epoch: 44 [242198/888800 27.25%] train loss: 1.3715413842874113e-05 \n",
      "epoch: 44 [243309/888800 27.38%] train loss: 1.52597640408203e-05 \n",
      "epoch: 44 [244420/888800 27.50%] train loss: 1.5034269381430931e-05 \n",
      "epoch: 44 [245531/888800 27.62%] train loss: 1.4376002582139336e-05 \n",
      "epoch: 44 [246642/888800 27.75%] train loss: 1.3812124052492436e-05 \n",
      "epoch: 44 [247753/888800 27.88%] train loss: 1.4278248272603378e-05 \n",
      "epoch: 44 [248864/888800 28.00%] train loss: 1.4651687706646044e-05 \n",
      "epoch: 44 [249975/888800 28.12%] train loss: 1.4494140486931428e-05 \n",
      "epoch: 44 [251086/888800 28.25%] train loss: 1.464107208448695e-05 \n",
      "epoch: 44 [252197/888800 28.38%] train loss: 1.3789654985885136e-05 \n",
      "epoch: 44 [253308/888800 28.50%] train loss: 1.3496179235517047e-05 \n",
      "epoch: 44 [254419/888800 28.62%] train loss: 1.526828418718651e-05 \n",
      "epoch: 44 [255530/888800 28.75%] train loss: 1.4364424714585766e-05 \n",
      "epoch: 44 [256641/888800 28.88%] train loss: 1.4453016774496064e-05 \n",
      "epoch: 44 [257752/888800 29.00%] train loss: 1.4779236153117381e-05 \n",
      "epoch: 44 [258863/888800 29.12%] train loss: 1.48056133184582e-05 \n",
      "epoch: 44 [259974/888800 29.25%] train loss: 1.4122096217761282e-05 \n",
      "epoch: 44 [261085/888800 29.38%] train loss: 1.4604171155951917e-05 \n",
      "epoch: 44 [262196/888800 29.50%] train loss: 1.4101260603638366e-05 \n",
      "epoch: 44 [263307/888800 29.62%] train loss: 1.511271511844825e-05 \n",
      "epoch: 44 [264418/888800 29.75%] train loss: 1.4459028534474783e-05 \n",
      "epoch: 44 [265529/888800 29.88%] train loss: 1.5077489479153883e-05 \n",
      "epoch: 44 [266640/888800 30.00%] train loss: 1.4500808902084827e-05 \n",
      "epoch: 44 [267751/888800 30.12%] train loss: 1.4313249266706407e-05 \n",
      "epoch: 44 [268862/888800 30.25%] train loss: 1.5265284673660062e-05 \n",
      "epoch: 44 [269973/888800 30.38%] train loss: 1.3316729564394336e-05 \n",
      "epoch: 44 [271084/888800 30.50%] train loss: 1.4465011190623045e-05 \n",
      "epoch: 44 [272195/888800 30.62%] train loss: 1.3679552466783207e-05 \n",
      "epoch: 44 [273306/888800 30.75%] train loss: 1.4439709957514424e-05 \n",
      "epoch: 44 [274417/888800 30.88%] train loss: 1.4423254469875246e-05 \n",
      "epoch: 44 [275528/888800 31.00%] train loss: 1.3684400073543657e-05 \n",
      "epoch: 44 [276639/888800 31.12%] train loss: 1.4100896805757657e-05 \n",
      "epoch: 44 [277750/888800 31.25%] train loss: 1.4311534869193565e-05 \n",
      "epoch: 44 [278861/888800 31.38%] train loss: 1.4740317055839114e-05 \n",
      "epoch: 44 [279972/888800 31.50%] train loss: 1.560655982757453e-05 \n",
      "epoch: 44 [281083/888800 31.62%] train loss: 1.432393128197873e-05 \n",
      "epoch: 44 [282194/888800 31.75%] train loss: 1.4350095625559334e-05 \n",
      "epoch: 44 [283305/888800 31.88%] train loss: 1.4471525901171844e-05 \n",
      "epoch: 44 [284416/888800 32.00%] train loss: 1.4641601410403382e-05 \n",
      "epoch: 44 [285527/888800 32.12%] train loss: 1.4771495443710592e-05 \n",
      "epoch: 44 [286638/888800 32.25%] train loss: 1.4592063052987214e-05 \n",
      "epoch: 44 [287749/888800 32.38%] train loss: 1.4313360225060023e-05 \n",
      "epoch: 44 [288860/888800 32.50%] train loss: 1.4524381185765378e-05 \n",
      "epoch: 44 [289971/888800 32.62%] train loss: 1.3877001038054004e-05 \n",
      "epoch: 44 [291082/888800 32.75%] train loss: 1.4266386642702855e-05 \n",
      "epoch: 44 [292193/888800 32.88%] train loss: 1.4560632735083345e-05 \n",
      "epoch: 44 [293304/888800 33.00%] train loss: 1.4467482287727762e-05 \n",
      "epoch: 44 [294415/888800 33.12%] train loss: 1.5337540389737114e-05 \n",
      "epoch: 44 [295526/888800 33.25%] train loss: 1.5297449863282964e-05 \n",
      "epoch: 44 [296637/888800 33.38%] train loss: 1.3599321391666308e-05 \n",
      "epoch: 44 [297748/888800 33.50%] train loss: 1.4521968296321575e-05 \n",
      "epoch: 44 [298859/888800 33.62%] train loss: 1.4398314306163229e-05 \n",
      "epoch: 44 [299970/888800 33.75%] train loss: 1.2702108506346121e-05 \n",
      "epoch: 44 [301081/888800 33.88%] train loss: 1.3279181985126343e-05 \n",
      "epoch: 44 [302192/888800 34.00%] train loss: 1.525761399534531e-05 \n",
      "epoch: 44 [303303/888800 34.12%] train loss: 1.3476195817929693e-05 \n",
      "epoch: 44 [304414/888800 34.25%] train loss: 1.6361844245693646e-05 \n",
      "epoch: 44 [305525/888800 34.38%] train loss: 1.4782921425648965e-05 \n",
      "epoch: 44 [306636/888800 34.50%] train loss: 1.4263569937611464e-05 \n",
      "epoch: 44 [307747/888800 34.62%] train loss: 1.3782794667349663e-05 \n",
      "epoch: 44 [308858/888800 34.75%] train loss: 1.4972317330830265e-05 \n",
      "epoch: 44 [309969/888800 34.88%] train loss: 1.3698605471290648e-05 \n",
      "epoch: 44 [311080/888800 35.00%] train loss: 1.4201184058038052e-05 \n",
      "epoch: 44 [312191/888800 35.12%] train loss: 1.5162133422563784e-05 \n",
      "epoch: 44 [313302/888800 35.25%] train loss: 1.4749180991202593e-05 \n",
      "epoch: 44 [314413/888800 35.38%] train loss: 1.4466355423792265e-05 \n",
      "epoch: 44 [315524/888800 35.50%] train loss: 1.4755308257008437e-05 \n",
      "epoch: 44 [316635/888800 35.62%] train loss: 1.4569300219591241e-05 \n",
      "epoch: 44 [317746/888800 35.75%] train loss: 1.4072031262912787e-05 \n",
      "epoch: 44 [318857/888800 35.88%] train loss: 1.5254834579536691e-05 \n",
      "epoch: 44 [319968/888800 36.00%] train loss: 1.4527186976920348e-05 \n",
      "epoch: 44 [321079/888800 36.12%] train loss: 1.3357379430090077e-05 \n",
      "epoch: 44 [322190/888800 36.25%] train loss: 1.3287772162584588e-05 \n",
      "epoch: 44 [323301/888800 36.38%] train loss: 1.4841724805592094e-05 \n",
      "epoch: 44 [324412/888800 36.50%] train loss: 1.4021846254763659e-05 \n",
      "epoch: 44 [325523/888800 36.62%] train loss: 1.5412237189593725e-05 \n",
      "epoch: 44 [326634/888800 36.75%] train loss: 1.4674176782136783e-05 \n",
      "epoch: 44 [327745/888800 36.88%] train loss: 1.3624498024000786e-05 \n",
      "epoch: 44 [328856/888800 37.00%] train loss: 1.3652768757310696e-05 \n",
      "epoch: 44 [329967/888800 37.12%] train loss: 1.4209503206075169e-05 \n",
      "epoch: 44 [331078/888800 37.25%] train loss: 1.3392839719017502e-05 \n",
      "epoch: 44 [332189/888800 37.38%] train loss: 1.3681053133041132e-05 \n",
      "epoch: 44 [333300/888800 37.50%] train loss: 1.4522690435114782e-05 \n",
      "epoch: 44 [334411/888800 37.62%] train loss: 1.3714723536395468e-05 \n",
      "epoch: 44 [335522/888800 37.75%] train loss: 1.4091398952587042e-05 \n",
      "epoch: 44 [336633/888800 37.88%] train loss: 1.504092688264791e-05 \n",
      "epoch: 44 [337744/888800 38.00%] train loss: 1.3785468581772875e-05 \n",
      "epoch: 44 [338855/888800 38.12%] train loss: 1.4457781617238652e-05 \n",
      "epoch: 44 [339966/888800 38.25%] train loss: 1.360658097837586e-05 \n",
      "epoch: 44 [341077/888800 38.38%] train loss: 1.5755607819301076e-05 \n",
      "epoch: 44 [342188/888800 38.50%] train loss: 1.3251790733193047e-05 \n",
      "epoch: 44 [343299/888800 38.62%] train loss: 1.5216091014735866e-05 \n",
      "epoch: 44 [344410/888800 38.75%] train loss: 1.4301896044344176e-05 \n",
      "epoch: 44 [345521/888800 38.88%] train loss: 1.3944038983026985e-05 \n",
      "epoch: 44 [346632/888800 39.00%] train loss: 1.518409226264339e-05 \n",
      "epoch: 44 [347743/888800 39.12%] train loss: 1.4062638001632877e-05 \n",
      "epoch: 44 [348854/888800 39.25%] train loss: 1.3402146578300744e-05 \n",
      "epoch: 44 [349965/888800 39.38%] train loss: 1.541123492643237e-05 \n",
      "epoch: 44 [351076/888800 39.50%] train loss: 1.3736315850110259e-05 \n",
      "epoch: 44 [352187/888800 39.62%] train loss: 1.4776641364733223e-05 \n",
      "epoch: 44 [353298/888800 39.75%] train loss: 1.4819140233157668e-05 \n",
      "epoch: 44 [354409/888800 39.88%] train loss: 1.412350593454903e-05 \n",
      "epoch: 44 [355520/888800 40.00%] train loss: 1.4947629097150639e-05 \n",
      "epoch: 44 [356631/888800 40.12%] train loss: 1.3658471289090812e-05 \n",
      "epoch: 44 [357742/888800 40.25%] train loss: 1.3959715943201445e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [358853/888800 40.38%] train loss: 1.486298151576193e-05 \n",
      "epoch: 44 [359964/888800 40.50%] train loss: 1.2980125575268175e-05 \n",
      "epoch: 44 [361075/888800 40.62%] train loss: 1.3584272892330773e-05 \n",
      "epoch: 44 [362186/888800 40.75%] train loss: 1.33628291223431e-05 \n",
      "epoch: 44 [363297/888800 40.88%] train loss: 1.3770963960269e-05 \n",
      "epoch: 44 [364408/888800 41.00%] train loss: 1.4532917703036219e-05 \n",
      "epoch: 44 [365519/888800 41.12%] train loss: 1.4676460523332935e-05 \n",
      "epoch: 44 [366630/888800 41.25%] train loss: 1.3893954019295052e-05 \n",
      "epoch: 44 [367741/888800 41.38%] train loss: 1.3720582501264289e-05 \n",
      "epoch: 44 [368852/888800 41.50%] train loss: 1.4318723515316378e-05 \n",
      "epoch: 44 [369963/888800 41.62%] train loss: 1.3197186490288004e-05 \n",
      "epoch: 44 [371074/888800 41.75%] train loss: 1.4354348422784824e-05 \n",
      "epoch: 44 [372185/888800 41.88%] train loss: 1.4055522115086205e-05 \n",
      "epoch: 44 [373296/888800 42.00%] train loss: 1.57289450726239e-05 \n",
      "epoch: 44 [374407/888800 42.12%] train loss: 1.4912786355125718e-05 \n",
      "epoch: 44 [375518/888800 42.25%] train loss: 1.485739994677715e-05 \n",
      "epoch: 44 [376629/888800 42.38%] train loss: 1.5225314200506546e-05 \n",
      "epoch: 44 [377740/888800 42.50%] train loss: 1.4005325283505954e-05 \n",
      "epoch: 44 [378851/888800 42.62%] train loss: 1.5007202819106169e-05 \n",
      "epoch: 44 [379962/888800 42.75%] train loss: 1.4869243386783637e-05 \n",
      "epoch: 44 [381073/888800 42.88%] train loss: 1.5513558537350036e-05 \n",
      "epoch: 44 [382184/888800 43.00%] train loss: 1.3825168025505263e-05 \n",
      "epoch: 44 [383295/888800 43.12%] train loss: 1.3106129699735902e-05 \n",
      "epoch: 44 [384406/888800 43.25%] train loss: 1.4178696801536717e-05 \n",
      "epoch: 44 [385517/888800 43.38%] train loss: 1.6394782505813055e-05 \n",
      "epoch: 44 [386628/888800 43.50%] train loss: 1.584409073984716e-05 \n",
      "epoch: 44 [387739/888800 43.62%] train loss: 1.4323134564619977e-05 \n",
      "epoch: 44 [388850/888800 43.75%] train loss: 1.4902744624123443e-05 \n",
      "epoch: 44 [389961/888800 43.88%] train loss: 1.4488214219454676e-05 \n",
      "epoch: 44 [391072/888800 44.00%] train loss: 1.4583592928829603e-05 \n",
      "epoch: 44 [392183/888800 44.12%] train loss: 1.5046675798657816e-05 \n",
      "epoch: 44 [393294/888800 44.25%] train loss: 1.5732650354038924e-05 \n",
      "epoch: 44 [394405/888800 44.38%] train loss: 1.436655566067202e-05 \n",
      "epoch: 44 [395516/888800 44.50%] train loss: 1.4318302419269457e-05 \n",
      "epoch: 44 [396627/888800 44.62%] train loss: 1.3898640645493288e-05 \n",
      "epoch: 44 [397738/888800 44.75%] train loss: 1.629563485039398e-05 \n",
      "epoch: 44 [398849/888800 44.88%] train loss: 1.4748557077837177e-05 \n",
      "epoch: 44 [399960/888800 45.00%] train loss: 1.596500806044787e-05 \n",
      "epoch: 44 [401071/888800 45.12%] train loss: 1.4199534234649036e-05 \n",
      "epoch: 44 [402182/888800 45.25%] train loss: 1.432717363059055e-05 \n",
      "epoch: 44 [403293/888800 45.38%] train loss: 1.4352353900903836e-05 \n",
      "epoch: 44 [404404/888800 45.50%] train loss: 1.4137101061351132e-05 \n",
      "epoch: 44 [405515/888800 45.62%] train loss: 1.4283690688898787e-05 \n",
      "epoch: 44 [406626/888800 45.75%] train loss: 1.4490480680251494e-05 \n",
      "epoch: 44 [407737/888800 45.88%] train loss: 1.5926078049233183e-05 \n",
      "epoch: 44 [408848/888800 46.00%] train loss: 1.4724378161190543e-05 \n",
      "epoch: 44 [409959/888800 46.12%] train loss: 1.5821560737094842e-05 \n",
      "epoch: 44 [411070/888800 46.25%] train loss: 1.4699506209581159e-05 \n",
      "epoch: 44 [412181/888800 46.38%] train loss: 1.621117007744033e-05 \n",
      "epoch: 44 [413292/888800 46.50%] train loss: 1.4008567632117774e-05 \n",
      "epoch: 44 [414403/888800 46.62%] train loss: 1.4666356037196238e-05 \n",
      "epoch: 44 [415514/888800 46.75%] train loss: 1.39219882839825e-05 \n",
      "epoch: 44 [416625/888800 46.88%] train loss: 1.5205803720164113e-05 \n",
      "epoch: 44 [417736/888800 47.00%] train loss: 1.5362980775535107e-05 \n",
      "epoch: 44 [418847/888800 47.12%] train loss: 1.4518998796120286e-05 \n",
      "epoch: 44 [419958/888800 47.25%] train loss: 1.4451769857259933e-05 \n",
      "epoch: 44 [421069/888800 47.38%] train loss: 1.4224613551050425e-05 \n",
      "epoch: 44 [422180/888800 47.50%] train loss: 1.2906992196803913e-05 \n",
      "epoch: 44 [423291/888800 47.62%] train loss: 1.4997965081420261e-05 \n",
      "epoch: 44 [424402/888800 47.75%] train loss: 1.3527275768865366e-05 \n",
      "epoch: 44 [425513/888800 47.88%] train loss: 1.3976415175420698e-05 \n",
      "epoch: 44 [426624/888800 48.00%] train loss: 1.3005829714529682e-05 \n",
      "epoch: 44 [427735/888800 48.12%] train loss: 1.382762366120005e-05 \n",
      "epoch: 44 [428846/888800 48.25%] train loss: 1.4277381524152588e-05 \n",
      "epoch: 44 [429957/888800 48.38%] train loss: 1.394389801134821e-05 \n",
      "epoch: 44 [431068/888800 48.50%] train loss: 1.5287612768588588e-05 \n",
      "epoch: 44 [432179/888800 48.62%] train loss: 1.4969866242608987e-05 \n",
      "epoch: 44 [433290/888800 48.75%] train loss: 1.488289581175195e-05 \n",
      "epoch: 44 [434401/888800 48.88%] train loss: 1.5564432032988407e-05 \n",
      "epoch: 44 [435512/888800 49.00%] train loss: 1.3646495062857866e-05 \n",
      "epoch: 44 [436623/888800 49.12%] train loss: 1.3629782188218087e-05 \n",
      "epoch: 44 [437734/888800 49.25%] train loss: 1.449645969842095e-05 \n",
      "epoch: 44 [438845/888800 49.38%] train loss: 1.4150131391943432e-05 \n",
      "epoch: 44 [439956/888800 49.50%] train loss: 1.4549746992997825e-05 \n",
      "epoch: 44 [441067/888800 49.62%] train loss: 1.4660764463769738e-05 \n",
      "epoch: 44 [442178/888800 49.75%] train loss: 1.4805694263486657e-05 \n",
      "epoch: 44 [443289/888800 49.88%] train loss: 1.3986383237352129e-05 \n",
      "epoch: 44 [444400/888800 50.00%] train loss: 1.3623994163936004e-05 \n",
      "epoch: 44 [445511/888800 50.12%] train loss: 1.4347622709465213e-05 \n",
      "epoch: 44 [446622/888800 50.25%] train loss: 1.4134190678305458e-05 \n",
      "epoch: 44 [447733/888800 50.38%] train loss: 1.5819639884284697e-05 \n",
      "epoch: 44 [448844/888800 50.50%] train loss: 1.4620575711887795e-05 \n",
      "epoch: 44 [449955/888800 50.62%] train loss: 1.3829938325216062e-05 \n",
      "epoch: 44 [451066/888800 50.75%] train loss: 1.3856610166840255e-05 \n",
      "epoch: 44 [452177/888800 50.88%] train loss: 1.4349961020343471e-05 \n",
      "epoch: 44 [453288/888800 51.00%] train loss: 1.3355914234125521e-05 \n",
      "epoch: 44 [454399/888800 51.12%] train loss: 1.2913915270473808e-05 \n",
      "epoch: 44 [455510/888800 51.25%] train loss: 1.5620502381352708e-05 \n",
      "epoch: 44 [456621/888800 51.38%] train loss: 1.4806030776526313e-05 \n",
      "epoch: 44 [457732/888800 51.50%] train loss: 1.5358617019956e-05 \n",
      "epoch: 44 [458843/888800 51.62%] train loss: 1.5129638086364139e-05 \n",
      "epoch: 44 [459954/888800 51.75%] train loss: 1.4618565728596877e-05 \n",
      "epoch: 44 [461065/888800 51.88%] train loss: 1.3222426787251607e-05 \n",
      "epoch: 44 [462176/888800 52.00%] train loss: 1.4669841220893431e-05 \n",
      "epoch: 44 [463287/888800 52.12%] train loss: 1.4444332009588834e-05 \n",
      "epoch: 44 [464398/888800 52.25%] train loss: 1.4193594324751757e-05 \n",
      "epoch: 44 [465509/888800 52.38%] train loss: 1.2820094525523018e-05 \n",
      "epoch: 44 [466620/888800 52.50%] train loss: 1.4720674698764924e-05 \n",
      "epoch: 44 [467731/888800 52.62%] train loss: 1.4397992345038801e-05 \n",
      "epoch: 44 [468842/888800 52.75%] train loss: 1.445261477783788e-05 \n",
      "epoch: 44 [469953/888800 52.88%] train loss: 1.4755124539078679e-05 \n",
      "epoch: 44 [471064/888800 53.00%] train loss: 1.6208119632210582e-05 \n",
      "epoch: 44 [472175/888800 53.12%] train loss: 1.378561501041986e-05 \n",
      "epoch: 44 [473286/888800 53.25%] train loss: 1.3671671695192344e-05 \n",
      "epoch: 44 [474397/888800 53.38%] train loss: 1.3841683539794758e-05 \n",
      "epoch: 44 [475508/888800 53.50%] train loss: 1.336694822384743e-05 \n",
      "epoch: 44 [476619/888800 53.62%] train loss: 1.4420354091271292e-05 \n",
      "epoch: 44 [477730/888800 53.75%] train loss: 1.4240898053685669e-05 \n",
      "epoch: 44 [478841/888800 53.88%] train loss: 1.4260315765568521e-05 \n",
      "epoch: 44 [479952/888800 54.00%] train loss: 1.4053639461053535e-05 \n",
      "epoch: 44 [481063/888800 54.12%] train loss: 1.4621791706304066e-05 \n",
      "epoch: 44 [482174/888800 54.25%] train loss: 1.4073097190703265e-05 \n",
      "epoch: 44 [483285/888800 54.38%] train loss: 1.4277653463068418e-05 \n",
      "epoch: 44 [484396/888800 54.50%] train loss: 1.4998116057540756e-05 \n",
      "epoch: 44 [485507/888800 54.62%] train loss: 1.4632963939220645e-05 \n",
      "epoch: 44 [486618/888800 54.75%] train loss: 1.5101589269761462e-05 \n",
      "epoch: 44 [487729/888800 54.88%] train loss: 1.3711785868508741e-05 \n",
      "epoch: 44 [488840/888800 55.00%] train loss: 1.5202313079498708e-05 \n",
      "epoch: 44 [489951/888800 55.12%] train loss: 1.5318144505727105e-05 \n",
      "epoch: 44 [491062/888800 55.25%] train loss: 1.4326774362416472e-05 \n",
      "epoch: 44 [492173/888800 55.38%] train loss: 1.3995362678542733e-05 \n",
      "epoch: 44 [493284/888800 55.50%] train loss: 1.4045339412405156e-05 \n",
      "epoch: 44 [494395/888800 55.62%] train loss: 1.3770470104645938e-05 \n",
      "epoch: 44 [495506/888800 55.75%] train loss: 1.4650393495685421e-05 \n",
      "epoch: 44 [496617/888800 55.88%] train loss: 1.351904938928783e-05 \n",
      "epoch: 44 [497728/888800 56.00%] train loss: 1.4640580957347993e-05 \n",
      "epoch: 44 [498839/888800 56.12%] train loss: 1.4994992852734867e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [499950/888800 56.25%] train loss: 1.48413691931637e-05 \n",
      "epoch: 44 [501061/888800 56.38%] train loss: 1.4734331671206746e-05 \n",
      "epoch: 44 [502172/888800 56.50%] train loss: 1.3946392755315173e-05 \n",
      "epoch: 44 [503283/888800 56.62%] train loss: 1.4154852578940336e-05 \n",
      "epoch: 44 [504394/888800 56.75%] train loss: 1.4042851034901105e-05 \n",
      "epoch: 44 [505505/888800 56.88%] train loss: 1.5237738807627466e-05 \n",
      "epoch: 44 [506616/888800 57.00%] train loss: 1.263395188288996e-05 \n",
      "epoch: 44 [507727/888800 57.12%] train loss: 1.5104982594493777e-05 \n",
      "epoch: 44 [508838/888800 57.25%] train loss: 1.4518403986585326e-05 \n",
      "epoch: 44 [509949/888800 57.38%] train loss: 1.3383099940256216e-05 \n",
      "epoch: 44 [511060/888800 57.50%] train loss: 1.4229141925170552e-05 \n",
      "epoch: 44 [512171/888800 57.62%] train loss: 1.4293650565377902e-05 \n",
      "epoch: 44 [513282/888800 57.75%] train loss: 1.5239988897519652e-05 \n",
      "epoch: 44 [514393/888800 57.88%] train loss: 1.3745659089181572e-05 \n",
      "epoch: 44 [515504/888800 58.00%] train loss: 1.4666783499706071e-05 \n",
      "epoch: 44 [516615/888800 58.12%] train loss: 1.530438930785749e-05 \n",
      "epoch: 44 [517726/888800 58.25%] train loss: 1.4618539353250526e-05 \n",
      "epoch: 44 [518837/888800 58.38%] train loss: 1.325276207353454e-05 \n",
      "epoch: 44 [519948/888800 58.50%] train loss: 1.375875945086591e-05 \n",
      "epoch: 44 [521059/888800 58.62%] train loss: 1.2327579497650731e-05 \n",
      "epoch: 44 [522170/888800 58.75%] train loss: 1.3061295248917304e-05 \n",
      "epoch: 44 [523281/888800 58.88%] train loss: 1.4314495274447836e-05 \n",
      "epoch: 44 [524392/888800 59.00%] train loss: 1.419000000169035e-05 \n",
      "epoch: 44 [525503/888800 59.12%] train loss: 1.5244595488184132e-05 \n",
      "epoch: 44 [526614/888800 59.25%] train loss: 1.3456094166031107e-05 \n",
      "epoch: 44 [527725/888800 59.38%] train loss: 1.4540713891619816e-05 \n",
      "epoch: 44 [528836/888800 59.50%] train loss: 1.3700112504011486e-05 \n",
      "epoch: 44 [529947/888800 59.62%] train loss: 1.609285391168669e-05 \n",
      "epoch: 44 [531058/888800 59.75%] train loss: 1.498762776463991e-05 \n",
      "epoch: 44 [532169/888800 59.88%] train loss: 1.5373156202258542e-05 \n",
      "epoch: 44 [533280/888800 60.00%] train loss: 1.632008388696704e-05 \n",
      "epoch: 44 [534391/888800 60.12%] train loss: 1.64983775903238e-05 \n",
      "epoch: 44 [535502/888800 60.25%] train loss: 1.4677365470561199e-05 \n",
      "epoch: 44 [536613/888800 60.38%] train loss: 1.5055525182106066e-05 \n",
      "epoch: 44 [537724/888800 60.50%] train loss: 1.6684592992533e-05 \n",
      "epoch: 44 [538835/888800 60.62%] train loss: 1.3414324712357484e-05 \n",
      "epoch: 44 [539946/888800 60.75%] train loss: 1.7111147826653905e-05 \n",
      "epoch: 44 [541057/888800 60.88%] train loss: 1.4352380276250187e-05 \n",
      "epoch: 44 [542168/888800 61.00%] train loss: 1.6655960280331783e-05 \n",
      "epoch: 44 [543279/888800 61.12%] train loss: 1.4468511835730169e-05 \n",
      "epoch: 44 [544390/888800 61.25%] train loss: 1.711504955892451e-05 \n",
      "epoch: 44 [545501/888800 61.38%] train loss: 1.4037063920113724e-05 \n",
      "epoch: 44 [546612/888800 61.50%] train loss: 1.635534681554418e-05 \n",
      "epoch: 44 [547723/888800 61.62%] train loss: 1.5842819266254082e-05 \n",
      "epoch: 44 [548834/888800 61.75%] train loss: 1.555049129819963e-05 \n",
      "epoch: 44 [549945/888800 61.88%] train loss: 1.5138694834604394e-05 \n",
      "epoch: 44 [551056/888800 62.00%] train loss: 1.5097810319275595e-05 \n",
      "epoch: 44 [552167/888800 62.12%] train loss: 1.630652513995301e-05 \n",
      "epoch: 44 [553278/888800 62.25%] train loss: 1.3117279195284937e-05 \n",
      "epoch: 44 [554389/888800 62.38%] train loss: 1.5329998859670013e-05 \n",
      "epoch: 44 [555500/888800 62.50%] train loss: 1.3206990843173116e-05 \n",
      "epoch: 44 [556611/888800 62.62%] train loss: 1.5458423149539158e-05 \n",
      "epoch: 44 [557722/888800 62.75%] train loss: 1.3335245967027731e-05 \n",
      "epoch: 44 [558833/888800 62.88%] train loss: 1.628965219424572e-05 \n",
      "epoch: 44 [559944/888800 63.00%] train loss: 1.4549270417774096e-05 \n",
      "epoch: 44 [561055/888800 63.12%] train loss: 1.4637591448263265e-05 \n",
      "epoch: 44 [562166/888800 63.25%] train loss: 1.3939515156380367e-05 \n",
      "epoch: 44 [563277/888800 63.38%] train loss: 1.5332272596424446e-05 \n",
      "epoch: 44 [564388/888800 63.50%] train loss: 1.4633267710451037e-05 \n",
      "epoch: 44 [565499/888800 63.62%] train loss: 1.4617838132835459e-05 \n",
      "epoch: 44 [566610/888800 63.75%] train loss: 1.46920892802882e-05 \n",
      "epoch: 44 [567721/888800 63.88%] train loss: 1.4728730093338527e-05 \n",
      "epoch: 44 [568832/888800 64.00%] train loss: 1.4449066839006264e-05 \n",
      "epoch: 44 [569943/888800 64.12%] train loss: 1.4913338418409694e-05 \n",
      "epoch: 44 [571054/888800 64.25%] train loss: 1.4764801562705543e-05 \n",
      "epoch: 44 [572165/888800 64.38%] train loss: 1.2951180906384252e-05 \n",
      "epoch: 44 [573276/888800 64.50%] train loss: 1.3150516679161228e-05 \n",
      "epoch: 44 [574387/888800 64.62%] train loss: 1.4287588783190586e-05 \n",
      "epoch: 44 [575498/888800 64.75%] train loss: 1.4995425772212911e-05 \n",
      "epoch: 44 [576609/888800 64.88%] train loss: 1.2390998563205358e-05 \n",
      "epoch: 44 [577720/888800 65.00%] train loss: 1.6315452739945613e-05 \n",
      "epoch: 44 [578831/888800 65.12%] train loss: 1.461094416299602e-05 \n",
      "epoch: 44 [579942/888800 65.25%] train loss: 1.4728849237144459e-05 \n",
      "epoch: 44 [581053/888800 65.38%] train loss: 1.4608323908760212e-05 \n",
      "epoch: 44 [582164/888800 65.50%] train loss: 1.3833609045832418e-05 \n",
      "epoch: 44 [583275/888800 65.62%] train loss: 1.4124181689112447e-05 \n",
      "epoch: 44 [584386/888800 65.75%] train loss: 1.6581132513238117e-05 \n",
      "epoch: 44 [585497/888800 65.88%] train loss: 1.4174246643960942e-05 \n",
      "epoch: 44 [586608/888800 66.00%] train loss: 1.6168907677638344e-05 \n",
      "epoch: 44 [587719/888800 66.12%] train loss: 1.4342653230414726e-05 \n",
      "epoch: 44 [588830/888800 66.25%] train loss: 1.4968233699619304e-05 \n",
      "epoch: 44 [589941/888800 66.38%] train loss: 1.3854653843736742e-05 \n",
      "epoch: 44 [591052/888800 66.50%] train loss: 1.3211282748670783e-05 \n",
      "epoch: 44 [592163/888800 66.62%] train loss: 1.6068262993940152e-05 \n",
      "epoch: 44 [593274/888800 66.75%] train loss: 1.386450276186224e-05 \n",
      "epoch: 44 [594385/888800 66.88%] train loss: 1.5298599464586005e-05 \n",
      "epoch: 44 [595496/888800 67.00%] train loss: 1.3858995771443006e-05 \n",
      "epoch: 44 [596607/888800 67.12%] train loss: 1.5152068954193965e-05 \n",
      "epoch: 44 [597718/888800 67.25%] train loss: 1.4731157534697559e-05 \n",
      "epoch: 44 [598829/888800 67.38%] train loss: 1.4102378372626845e-05 \n",
      "epoch: 44 [599940/888800 67.50%] train loss: 1.4744654436071869e-05 \n",
      "epoch: 44 [601051/888800 67.62%] train loss: 1.3599357771454379e-05 \n",
      "epoch: 44 [602162/888800 67.75%] train loss: 1.5334220734075643e-05 \n",
      "epoch: 44 [603273/888800 67.88%] train loss: 1.4875993656460196e-05 \n",
      "epoch: 44 [604384/888800 68.00%] train loss: 1.2885440810350701e-05 \n",
      "epoch: 44 [605495/888800 68.12%] train loss: 1.4342663234856445e-05 \n",
      "epoch: 44 [606606/888800 68.25%] train loss: 1.5044967767607886e-05 \n",
      "epoch: 44 [607717/888800 68.38%] train loss: 1.3981611118651927e-05 \n",
      "epoch: 44 [608828/888800 68.50%] train loss: 1.4435648154176306e-05 \n",
      "epoch: 44 [609939/888800 68.62%] train loss: 1.3461082744470332e-05 \n",
      "epoch: 44 [611050/888800 68.75%] train loss: 1.4433508113143034e-05 \n",
      "epoch: 44 [612161/888800 68.88%] train loss: 1.4579090020561125e-05 \n",
      "epoch: 44 [613272/888800 69.00%] train loss: 1.3532529919757508e-05 \n",
      "epoch: 44 [614383/888800 69.12%] train loss: 1.3943391422799323e-05 \n",
      "epoch: 44 [615494/888800 69.25%] train loss: 1.4085289876675233e-05 \n",
      "epoch: 44 [616605/888800 69.38%] train loss: 1.369256824546028e-05 \n",
      "epoch: 44 [617716/888800 69.50%] train loss: 1.4477614968200214e-05 \n",
      "epoch: 44 [618827/888800 69.62%] train loss: 1.3179208508518059e-05 \n",
      "epoch: 44 [619938/888800 69.75%] train loss: 1.3992146705277264e-05 \n",
      "epoch: 44 [621049/888800 69.88%] train loss: 1.3650410437548999e-05 \n",
      "epoch: 44 [622160/888800 70.00%] train loss: 1.4576026842405554e-05 \n",
      "epoch: 44 [623271/888800 70.12%] train loss: 1.4312749954115134e-05 \n",
      "epoch: 44 [624382/888800 70.25%] train loss: 1.4991863281466067e-05 \n",
      "epoch: 44 [625493/888800 70.38%] train loss: 1.5046542102936655e-05 \n",
      "epoch: 44 [626604/888800 70.50%] train loss: 1.5045586224005092e-05 \n",
      "epoch: 44 [627715/888800 70.62%] train loss: 1.390355100738816e-05 \n",
      "epoch: 44 [628826/888800 70.75%] train loss: 1.3627196494780947e-05 \n",
      "epoch: 44 [629937/888800 70.88%] train loss: 1.4280404684541281e-05 \n",
      "epoch: 44 [631048/888800 71.00%] train loss: 1.4189010471454822e-05 \n",
      "epoch: 44 [632159/888800 71.12%] train loss: 1.3778357242699713e-05 \n",
      "epoch: 44 [633270/888800 71.25%] train loss: 1.4281623407441657e-05 \n",
      "epoch: 44 [634381/888800 71.38%] train loss: 1.4302219824458007e-05 \n",
      "epoch: 44 [635492/888800 71.50%] train loss: 1.3958609088149387e-05 \n",
      "epoch: 44 [636603/888800 71.62%] train loss: 1.5952447938616388e-05 \n",
      "epoch: 44 [637714/888800 71.75%] train loss: 1.4021327842783649e-05 \n",
      "epoch: 44 [638825/888800 71.88%] train loss: 1.4154643395158928e-05 \n",
      "epoch: 44 [639936/888800 72.00%] train loss: 1.5045965483295731e-05 \n",
      "epoch: 44 [641047/888800 72.12%] train loss: 1.483991763961967e-05 \n",
      "epoch: 44 [642158/888800 72.25%] train loss: 1.3840464816894382e-05 \n",
      "epoch: 44 [643269/888800 72.38%] train loss: 1.3641753866977524e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [644380/888800 72.50%] train loss: 1.255860388482688e-05 \n",
      "epoch: 44 [645491/888800 72.62%] train loss: 1.4595593711419497e-05 \n",
      "epoch: 44 [646602/888800 72.75%] train loss: 1.4827648556092754e-05 \n",
      "epoch: 44 [647713/888800 72.88%] train loss: 1.3834277524438221e-05 \n",
      "epoch: 44 [648824/888800 73.00%] train loss: 1.5060370060382411e-05 \n",
      "epoch: 44 [649935/888800 73.12%] train loss: 1.4339291737996973e-05 \n",
      "epoch: 44 [651046/888800 73.25%] train loss: 1.4694436686113477e-05 \n",
      "epoch: 44 [652157/888800 73.38%] train loss: 1.231829901371384e-05 \n",
      "epoch: 44 [653268/888800 73.50%] train loss: 1.5461228031199425e-05 \n",
      "epoch: 44 [654379/888800 73.62%] train loss: 1.3857486919732764e-05 \n",
      "epoch: 44 [655490/888800 73.75%] train loss: 1.3919345292379148e-05 \n",
      "epoch: 44 [656601/888800 73.88%] train loss: 1.3469800251186825e-05 \n",
      "epoch: 44 [657712/888800 74.00%] train loss: 1.3701918760489207e-05 \n",
      "epoch: 44 [658823/888800 74.12%] train loss: 1.345726013823878e-05 \n",
      "epoch: 44 [659934/888800 74.25%] train loss: 1.4778387594560627e-05 \n",
      "epoch: 44 [661045/888800 74.38%] train loss: 1.4859075236017816e-05 \n",
      "epoch: 44 [662156/888800 74.50%] train loss: 1.4393740457308013e-05 \n",
      "epoch: 44 [663267/888800 74.62%] train loss: 1.493662057328038e-05 \n",
      "epoch: 44 [664378/888800 74.75%] train loss: 1.4896316315571312e-05 \n",
      "epoch: 44 [665489/888800 74.88%] train loss: 1.4880281923979055e-05 \n",
      "epoch: 44 [666600/888800 75.00%] train loss: 1.3723330084758345e-05 \n",
      "epoch: 44 [667711/888800 75.12%] train loss: 1.3724291420658119e-05 \n",
      "epoch: 44 [668822/888800 75.25%] train loss: 1.4102131899562664e-05 \n",
      "epoch: 44 [669933/888800 75.38%] train loss: 1.3695725101570133e-05 \n",
      "epoch: 44 [671044/888800 75.50%] train loss: 1.4534269212163053e-05 \n",
      "epoch: 44 [672155/888800 75.62%] train loss: 1.5416295354953036e-05 \n",
      "epoch: 44 [673266/888800 75.75%] train loss: 1.663229522819165e-05 \n",
      "epoch: 44 [674377/888800 75.88%] train loss: 1.3362558092921972e-05 \n",
      "epoch: 44 [675488/888800 76.00%] train loss: 1.4997962352936156e-05 \n",
      "epoch: 44 [676599/888800 76.12%] train loss: 1.3888999092159793e-05 \n",
      "epoch: 44 [677710/888800 76.25%] train loss: 1.4993489457992837e-05 \n",
      "epoch: 44 [678821/888800 76.38%] train loss: 1.4864267541270237e-05 \n",
      "epoch: 44 [679932/888800 76.50%] train loss: 1.4093940080783796e-05 \n",
      "epoch: 44 [681043/888800 76.62%] train loss: 1.5010189599706791e-05 \n",
      "epoch: 44 [682154/888800 76.75%] train loss: 1.4466933862422593e-05 \n",
      "epoch: 44 [683265/888800 76.88%] train loss: 1.4337767424876802e-05 \n",
      "epoch: 44 [684376/888800 77.00%] train loss: 1.5438226910191588e-05 \n",
      "epoch: 44 [685487/888800 77.12%] train loss: 1.347344004898332e-05 \n",
      "epoch: 44 [686598/888800 77.25%] train loss: 1.3361317542148754e-05 \n",
      "epoch: 44 [687709/888800 77.38%] train loss: 1.5154800166783389e-05 \n",
      "epoch: 44 [688820/888800 77.50%] train loss: 1.442943266738439e-05 \n",
      "epoch: 44 [689931/888800 77.62%] train loss: 1.3511745237337891e-05 \n",
      "epoch: 44 [691042/888800 77.75%] train loss: 1.4756717064301483e-05 \n",
      "epoch: 44 [692153/888800 77.88%] train loss: 1.3896971722715534e-05 \n",
      "epoch: 44 [693264/888800 78.00%] train loss: 1.372102906316286e-05 \n",
      "epoch: 44 [694375/888800 78.12%] train loss: 1.3751429833064321e-05 \n",
      "epoch: 44 [695486/888800 78.25%] train loss: 1.5059960787766613e-05 \n",
      "epoch: 44 [696597/888800 78.38%] train loss: 1.4141633073450066e-05 \n",
      "epoch: 44 [697708/888800 78.50%] train loss: 1.4485129213426262e-05 \n",
      "epoch: 44 [698819/888800 78.62%] train loss: 1.4600779650209006e-05 \n",
      "epoch: 44 [699930/888800 78.75%] train loss: 1.5270461517502554e-05 \n",
      "epoch: 44 [701041/888800 78.88%] train loss: 1.4033993466000538e-05 \n",
      "epoch: 44 [702152/888800 79.00%] train loss: 1.4301919691206422e-05 \n",
      "epoch: 44 [703263/888800 79.12%] train loss: 1.3736423170485068e-05 \n",
      "epoch: 44 [704374/888800 79.25%] train loss: 1.425552909495309e-05 \n",
      "epoch: 44 [705485/888800 79.38%] train loss: 1.3906491403758992e-05 \n",
      "epoch: 44 [706596/888800 79.50%] train loss: 1.4046599062567111e-05 \n",
      "epoch: 44 [707707/888800 79.62%] train loss: 1.2872491424786858e-05 \n",
      "epoch: 44 [708818/888800 79.75%] train loss: 1.437289120076457e-05 \n",
      "epoch: 44 [709929/888800 79.88%] train loss: 1.5254145182552747e-05 \n",
      "epoch: 44 [711040/888800 80.00%] train loss: 1.4167835615808144e-05 \n",
      "epoch: 44 [712151/888800 80.12%] train loss: 1.366147625958547e-05 \n",
      "epoch: 44 [713262/888800 80.25%] train loss: 1.3900680642109364e-05 \n",
      "epoch: 44 [714373/888800 80.38%] train loss: 1.4924220522516407e-05 \n",
      "epoch: 44 [715484/888800 80.50%] train loss: 1.4315550288301893e-05 \n",
      "epoch: 44 [716595/888800 80.62%] train loss: 1.4444164662563708e-05 \n",
      "epoch: 44 [717706/888800 80.75%] train loss: 1.3949600543128327e-05 \n",
      "epoch: 44 [718817/888800 80.88%] train loss: 1.467699166823877e-05 \n",
      "epoch: 44 [719928/888800 81.00%] train loss: 1.5257253835443407e-05 \n",
      "epoch: 44 [721039/888800 81.12%] train loss: 1.538218930363655e-05 \n",
      "epoch: 44 [722150/888800 81.25%] train loss: 1.4484870916930959e-05 \n",
      "epoch: 44 [723261/888800 81.38%] train loss: 1.2859480193583295e-05 \n",
      "epoch: 44 [724372/888800 81.50%] train loss: 1.497661924076965e-05 \n",
      "epoch: 44 [725483/888800 81.62%] train loss: 1.4460697457252536e-05 \n",
      "epoch: 44 [726594/888800 81.75%] train loss: 1.3881473023502622e-05 \n",
      "epoch: 44 [727705/888800 81.88%] train loss: 1.3015111107961275e-05 \n",
      "epoch: 44 [728816/888800 82.00%] train loss: 1.3798662621411495e-05 \n",
      "epoch: 44 [729927/888800 82.12%] train loss: 1.3320561265572906e-05 \n",
      "epoch: 44 [731038/888800 82.25%] train loss: 1.3864941138308495e-05 \n",
      "epoch: 44 [732149/888800 82.38%] train loss: 1.4101456144999247e-05 \n",
      "epoch: 44 [733260/888800 82.50%] train loss: 1.4451868082687724e-05 \n",
      "epoch: 44 [734371/888800 82.62%] train loss: 1.406859064445598e-05 \n",
      "epoch: 44 [735482/888800 82.75%] train loss: 1.527092172182165e-05 \n",
      "epoch: 44 [736593/888800 82.88%] train loss: 1.4347589058161248e-05 \n",
      "epoch: 44 [737704/888800 83.00%] train loss: 1.3393720109888818e-05 \n",
      "epoch: 44 [738815/888800 83.12%] train loss: 1.3235908227215987e-05 \n",
      "epoch: 44 [739926/888800 83.25%] train loss: 1.4129607734503224e-05 \n",
      "epoch: 44 [741037/888800 83.38%] train loss: 1.390386387356557e-05 \n",
      "epoch: 44 [742148/888800 83.50%] train loss: 1.4318417015601881e-05 \n",
      "epoch: 44 [743259/888800 83.62%] train loss: 1.5040529433463234e-05 \n",
      "epoch: 44 [744370/888800 83.75%] train loss: 1.4510565961245447e-05 \n",
      "epoch: 44 [745481/888800 83.88%] train loss: 1.4006935998622794e-05 \n",
      "epoch: 44 [746592/888800 84.00%] train loss: 1.3848877642885782e-05 \n",
      "epoch: 44 [747703/888800 84.12%] train loss: 1.3770633813692257e-05 \n",
      "epoch: 44 [748814/888800 84.25%] train loss: 1.4630371879320592e-05 \n",
      "epoch: 44 [749925/888800 84.38%] train loss: 1.325974335486535e-05 \n",
      "epoch: 44 [751036/888800 84.50%] train loss: 1.4154635209706612e-05 \n",
      "epoch: 44 [752147/888800 84.62%] train loss: 1.4551495951309334e-05 \n",
      "epoch: 44 [753258/888800 84.75%] train loss: 1.3442045201372821e-05 \n",
      "epoch: 44 [754369/888800 84.88%] train loss: 1.442542634322308e-05 \n",
      "epoch: 44 [755480/888800 85.00%] train loss: 1.4535680747940205e-05 \n",
      "epoch: 44 [756591/888800 85.12%] train loss: 1.4469893358182162e-05 \n",
      "epoch: 44 [757702/888800 85.25%] train loss: 1.4688511328131426e-05 \n",
      "epoch: 44 [758813/888800 85.38%] train loss: 1.4775256204302423e-05 \n",
      "epoch: 44 [759924/888800 85.50%] train loss: 1.3278183359943796e-05 \n",
      "epoch: 44 [761035/888800 85.62%] train loss: 1.3724161362915765e-05 \n",
      "epoch: 44 [762146/888800 85.75%] train loss: 1.4400866348296404e-05 \n",
      "epoch: 44 [763257/888800 85.88%] train loss: 1.4107265997154173e-05 \n",
      "epoch: 44 [764368/888800 86.00%] train loss: 1.3506803043128457e-05 \n",
      "epoch: 44 [765479/888800 86.12%] train loss: 1.4300856491900049e-05 \n",
      "epoch: 44 [766590/888800 86.25%] train loss: 1.3681663403986022e-05 \n",
      "epoch: 44 [767701/888800 86.38%] train loss: 1.3834581295668613e-05 \n",
      "epoch: 44 [768812/888800 86.50%] train loss: 1.5633149814675562e-05 \n",
      "epoch: 44 [769923/888800 86.62%] train loss: 1.3404590390564408e-05 \n",
      "epoch: 44 [771034/888800 86.75%] train loss: 1.415519818692701e-05 \n",
      "epoch: 44 [772145/888800 86.88%] train loss: 1.3317859156813938e-05 \n",
      "epoch: 44 [773256/888800 87.00%] train loss: 1.499692280049203e-05 \n",
      "epoch: 44 [774367/888800 87.12%] train loss: 1.3469076293404214e-05 \n",
      "epoch: 44 [775478/888800 87.25%] train loss: 1.3641842997458298e-05 \n",
      "epoch: 44 [776589/888800 87.38%] train loss: 1.2431975846993737e-05 \n",
      "epoch: 44 [777700/888800 87.50%] train loss: 1.375283500237856e-05 \n",
      "epoch: 44 [778811/888800 87.62%] train loss: 1.4922727132216096e-05 \n",
      "epoch: 44 [779922/888800 87.75%] train loss: 1.4074428690946661e-05 \n",
      "epoch: 44 [781033/888800 87.88%] train loss: 1.3267147551232483e-05 \n",
      "epoch: 44 [782144/888800 88.00%] train loss: 1.4530478438246064e-05 \n",
      "epoch: 44 [783255/888800 88.12%] train loss: 1.4610424841521308e-05 \n",
      "epoch: 44 [784366/888800 88.25%] train loss: 1.4080990695219953e-05 \n",
      "epoch: 44 [785477/888800 88.38%] train loss: 1.501042515883455e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 [786588/888800 88.50%] train loss: 1.3152521205483936e-05 \n",
      "epoch: 44 [787699/888800 88.62%] train loss: 1.4358298358274624e-05 \n",
      "epoch: 44 [788810/888800 88.75%] train loss: 1.4776587704545818e-05 \n",
      "epoch: 44 [789921/888800 88.88%] train loss: 1.3289980415720493e-05 \n",
      "epoch: 44 [791032/888800 89.00%] train loss: 1.440095184079837e-05 \n",
      "epoch: 44 [792143/888800 89.12%] train loss: 1.3678691175300628e-05 \n",
      "epoch: 44 [793254/888800 89.25%] train loss: 1.498775054642465e-05 \n",
      "epoch: 44 [794365/888800 89.38%] train loss: 1.4281874427979346e-05 \n",
      "epoch: 44 [795476/888800 89.50%] train loss: 1.4158905287331436e-05 \n",
      "epoch: 44 [796587/888800 89.62%] train loss: 1.442557004338596e-05 \n",
      "epoch: 44 [797698/888800 89.75%] train loss: 1.4650611774413846e-05 \n",
      "epoch: 44 [798809/888800 89.88%] train loss: 1.2676700862357393e-05 \n",
      "epoch: 44 [799920/888800 90.00%] train loss: 1.3908584151067771e-05 \n",
      "epoch: 44 [801031/888800 90.12%] train loss: 1.4865293451293837e-05 \n",
      "epoch: 44 [802142/888800 90.25%] train loss: 1.3942755686002783e-05 \n",
      "epoch: 44 [803253/888800 90.38%] train loss: 1.3972863598610274e-05 \n",
      "epoch: 44 [804364/888800 90.50%] train loss: 1.368864923279034e-05 \n",
      "epoch: 44 [805475/888800 90.62%] train loss: 1.4015815395396203e-05 \n",
      "epoch: 44 [806586/888800 90.75%] train loss: 1.3334966752154287e-05 \n",
      "epoch: 44 [807697/888800 90.88%] train loss: 1.4445146916841622e-05 \n",
      "epoch: 44 [808808/888800 91.00%] train loss: 1.3387594663072377e-05 \n",
      "epoch: 44 [809919/888800 91.12%] train loss: 1.4003023352415767e-05 \n",
      "epoch: 44 [811030/888800 91.25%] train loss: 1.3813267287332565e-05 \n",
      "epoch: 44 [812141/888800 91.38%] train loss: 1.5006337889644783e-05 \n",
      "epoch: 44 [813252/888800 91.50%] train loss: 1.4894811101839878e-05 \n",
      "epoch: 44 [814363/888800 91.62%] train loss: 1.4693626326334197e-05 \n",
      "epoch: 44 [815474/888800 91.75%] train loss: 1.3479212611855473e-05 \n",
      "epoch: 44 [816585/888800 91.88%] train loss: 1.3425140423350967e-05 \n",
      "epoch: 44 [817696/888800 92.00%] train loss: 1.3608590052172076e-05 \n",
      "epoch: 44 [818807/888800 92.12%] train loss: 1.497025732533075e-05 \n",
      "epoch: 44 [819918/888800 92.25%] train loss: 1.3546800801123027e-05 \n",
      "epoch: 44 [821029/888800 92.38%] train loss: 1.3451329323288519e-05 \n",
      "epoch: 44 [822140/888800 92.50%] train loss: 1.34259262267733e-05 \n",
      "epoch: 44 [823251/888800 92.62%] train loss: 1.4173013369145337e-05 \n",
      "epoch: 44 [824362/888800 92.75%] train loss: 1.5203213479253463e-05 \n",
      "epoch: 44 [825473/888800 92.88%] train loss: 1.4311777704278938e-05 \n",
      "epoch: 44 [826584/888800 93.00%] train loss: 1.4686839676869567e-05 \n",
      "epoch: 44 [827695/888800 93.12%] train loss: 1.4487714906863403e-05 \n",
      "epoch: 44 [828806/888800 93.25%] train loss: 1.5048063687572721e-05 \n",
      "epoch: 44 [829917/888800 93.38%] train loss: 1.4404108696908224e-05 \n",
      "epoch: 44 [831028/888800 93.50%] train loss: 1.4601372640754562e-05 \n",
      "epoch: 44 [832139/888800 93.62%] train loss: 1.4734961951035075e-05 \n",
      "epoch: 44 [833250/888800 93.75%] train loss: 1.3577659956354182e-05 \n",
      "epoch: 44 [834361/888800 93.88%] train loss: 1.3652992493007332e-05 \n",
      "epoch: 44 [835472/888800 94.00%] train loss: 1.4121955246082507e-05 \n",
      "epoch: 44 [836583/888800 94.12%] train loss: 1.5048613931867294e-05 \n",
      "epoch: 44 [837694/888800 94.25%] train loss: 1.4118334547674749e-05 \n",
      "epoch: 44 [838805/888800 94.38%] train loss: 1.4507585547107738e-05 \n",
      "epoch: 44 [839916/888800 94.50%] train loss: 1.4267986443883274e-05 \n",
      "epoch: 44 [841027/888800 94.62%] train loss: 1.3023133760725614e-05 \n",
      "epoch: 44 [842138/888800 94.75%] train loss: 1.434736441296991e-05 \n",
      "epoch: 44 [843249/888800 94.88%] train loss: 1.4718065358465537e-05 \n",
      "epoch: 44 [844360/888800 95.00%] train loss: 1.3894124094804283e-05 \n",
      "epoch: 44 [845471/888800 95.12%] train loss: 1.4237955838325433e-05 \n",
      "epoch: 44 [846582/888800 95.25%] train loss: 1.4218293472367804e-05 \n",
      "epoch: 44 [847693/888800 95.38%] train loss: 1.2863385563832708e-05 \n",
      "epoch: 44 [848804/888800 95.50%] train loss: 1.4406261470867321e-05 \n",
      "epoch: 44 [849915/888800 95.62%] train loss: 1.4620714864577167e-05 \n",
      "epoch: 44 [851026/888800 95.75%] train loss: 1.441672611690592e-05 \n",
      "epoch: 44 [852137/888800 95.88%] train loss: 1.4053538507141639e-05 \n",
      "epoch: 44 [853248/888800 96.00%] train loss: 1.3825831956637558e-05 \n",
      "epoch: 44 [854359/888800 96.12%] train loss: 1.4123229448159691e-05 \n",
      "epoch: 44 [855470/888800 96.25%] train loss: 1.3479986591846682e-05 \n",
      "epoch: 44 [856581/888800 96.38%] train loss: 1.33875037136022e-05 \n",
      "epoch: 44 [857692/888800 96.50%] train loss: 1.4055947758606635e-05 \n",
      "epoch: 44 [858803/888800 96.62%] train loss: 1.5047520719235763e-05 \n",
      "epoch: 44 [859914/888800 96.75%] train loss: 1.3226682312961202e-05 \n",
      "epoch: 44 [861025/888800 96.88%] train loss: 1.3890748050471302e-05 \n",
      "epoch: 44 [862136/888800 97.00%] train loss: 1.2753850569424685e-05 \n",
      "epoch: 44 [863247/888800 97.12%] train loss: 1.3518713785742875e-05 \n",
      "epoch: 44 [864358/888800 97.25%] train loss: 1.3677571587322745e-05 \n",
      "epoch: 44 [865469/888800 97.38%] train loss: 1.426855942554539e-05 \n",
      "epoch: 44 [866580/888800 97.50%] train loss: 1.3899228179070633e-05 \n",
      "epoch: 44 [867691/888800 97.62%] train loss: 1.4148126865620725e-05 \n",
      "epoch: 44 [868802/888800 97.75%] train loss: 1.5011468349257484e-05 \n",
      "epoch: 44 [869913/888800 97.88%] train loss: 1.3415006833383814e-05 \n",
      "epoch: 44 [871024/888800 98.00%] train loss: 1.5312039977288805e-05 \n",
      "epoch: 44 [872135/888800 98.12%] train loss: 1.4289368664321955e-05 \n",
      "epoch: 44 [873246/888800 98.25%] train loss: 1.489301666879328e-05 \n",
      "epoch: 44 [874357/888800 98.38%] train loss: 1.4629091310780495e-05 \n",
      "epoch: 44 [875468/888800 98.50%] train loss: 1.4757266399101354e-05 \n",
      "epoch: 44 [876579/888800 98.62%] train loss: 1.3435244909487665e-05 \n",
      "epoch: 44 [877690/888800 98.75%] train loss: 1.371885900880443e-05 \n",
      "epoch: 44 [878801/888800 98.88%] train loss: 1.3397258953773417e-05 \n",
      "epoch: 44 [879912/888800 99.00%] train loss: 1.61312309501227e-05 \n",
      "epoch: 44 [881023/888800 99.12%] train loss: 1.4225234735931735e-05 \n",
      "epoch: 44 [882134/888800 99.25%] train loss: 1.4878542970109265e-05 \n",
      "epoch: 44 [883245/888800 99.38%] train loss: 1.4284116332419217e-05 \n",
      "epoch: 44 [884356/888800 99.50%] train loss: 1.3557191778090782e-05 \n",
      "epoch: 44 [885467/888800 99.62%] train loss: 1.3780319022771437e-05 \n",
      "epoch: 44 [886578/888800 99.75%] train loss: 1.450457057217136e-05 \n",
      "epoch: 44 [887689/888800 99.88%] train loss: 1.5510760931647383e-05 \n",
      "epoch: 45 [0/888800 0.00%] train loss: 1.4899872439855244e-05 \n",
      "epoch: 45 [1111/888800 0.12%] train loss: 1.4556627320416737e-05 \n",
      "epoch: 45 [2222/888800 0.25%] train loss: 1.4276737601903733e-05 \n",
      "epoch: 45 [3333/888800 0.38%] train loss: 1.398911263095215e-05 \n",
      "epoch: 45 [4444/888800 0.50%] train loss: 1.4121878848527558e-05 \n",
      "epoch: 45 [5555/888800 0.62%] train loss: 1.6139027138706297e-05 \n",
      "epoch: 45 [6666/888800 0.75%] train loss: 1.3505417882697657e-05 \n",
      "epoch: 45 [7777/888800 0.88%] train loss: 1.4605648175347596e-05 \n",
      "epoch: 45 [8888/888800 1.00%] train loss: 1.4329706573334988e-05 \n",
      "epoch: 45 [9999/888800 1.12%] train loss: 1.4031068531039637e-05 \n",
      "epoch: 45 [11110/888800 1.25%] train loss: 1.4248988009057939e-05 \n",
      "epoch: 45 [12221/888800 1.38%] train loss: 1.3716625289816875e-05 \n",
      "epoch: 45 [13332/888800 1.50%] train loss: 1.383978633384686e-05 \n",
      "epoch: 45 [14443/888800 1.62%] train loss: 1.457044891139958e-05 \n",
      "epoch: 45 [15554/888800 1.75%] train loss: 1.3892246897739824e-05 \n",
      "epoch: 45 [16665/888800 1.88%] train loss: 1.3030587979301345e-05 \n",
      "epoch: 45 [17776/888800 2.00%] train loss: 1.380590856570052e-05 \n",
      "epoch: 45 [18887/888800 2.12%] train loss: 1.467813035560539e-05 \n",
      "epoch: 45 [19998/888800 2.25%] train loss: 1.3673507964995224e-05 \n",
      "epoch: 45 [21109/888800 2.38%] train loss: 1.3432579180516768e-05 \n",
      "epoch: 45 [22220/888800 2.50%] train loss: 1.3513357771444134e-05 \n",
      "epoch: 45 [23331/888800 2.62%] train loss: 1.4516093870042823e-05 \n",
      "epoch: 45 [24442/888800 2.75%] train loss: 1.4824066965957172e-05 \n",
      "epoch: 45 [25553/888800 2.88%] train loss: 1.467186666559428e-05 \n",
      "epoch: 45 [26664/888800 3.00%] train loss: 1.3399218914855737e-05 \n",
      "epoch: 45 [27775/888800 3.12%] train loss: 1.4160650607664138e-05 \n",
      "epoch: 45 [28886/888800 3.25%] train loss: 1.4856865163892508e-05 \n",
      "epoch: 45 [29997/888800 3.38%] train loss: 1.4030974853085354e-05 \n",
      "epoch: 45 [31108/888800 3.50%] train loss: 1.4461906175711192e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [32219/888800 3.62%] train loss: 1.3962381672172341e-05 \n",
      "epoch: 45 [33330/888800 3.75%] train loss: 1.3891881280869711e-05 \n",
      "epoch: 45 [34441/888800 3.88%] train loss: 1.4396781807590742e-05 \n",
      "epoch: 45 [35552/888800 4.00%] train loss: 1.4427438145503402e-05 \n",
      "epoch: 45 [36663/888800 4.12%] train loss: 1.2731097740470432e-05 \n",
      "epoch: 45 [37774/888800 4.25%] train loss: 1.4780131095903926e-05 \n",
      "epoch: 45 [38885/888800 4.38%] train loss: 1.3754061910731252e-05 \n",
      "epoch: 45 [39996/888800 4.50%] train loss: 1.4122262655291706e-05 \n",
      "epoch: 45 [41107/888800 4.62%] train loss: 1.2778498785337433e-05 \n",
      "epoch: 45 [42218/888800 4.75%] train loss: 1.422595050826203e-05 \n",
      "epoch: 45 [43329/888800 4.88%] train loss: 1.4669250049337279e-05 \n",
      "epoch: 45 [44440/888800 5.00%] train loss: 1.571028769831173e-05 \n",
      "epoch: 45 [45551/888800 5.12%] train loss: 1.4155023563944269e-05 \n",
      "epoch: 45 [46662/888800 5.25%] train loss: 1.3067652616882697e-05 \n",
      "epoch: 45 [47773/888800 5.38%] train loss: 1.3148425750841852e-05 \n",
      "epoch: 45 [48884/888800 5.50%] train loss: 1.4390344404091593e-05 \n",
      "epoch: 45 [49995/888800 5.62%] train loss: 1.5100558812264353e-05 \n",
      "epoch: 45 [51106/888800 5.75%] train loss: 1.4559574992745183e-05 \n",
      "epoch: 45 [52217/888800 5.88%] train loss: 1.4821484910498839e-05 \n",
      "epoch: 45 [53328/888800 6.00%] train loss: 1.4618944987887517e-05 \n",
      "epoch: 45 [54439/888800 6.12%] train loss: 1.4203599675965961e-05 \n",
      "epoch: 45 [55550/888800 6.25%] train loss: 1.618065834918525e-05 \n",
      "epoch: 45 [56661/888800 6.38%] train loss: 1.4434678632824216e-05 \n",
      "epoch: 45 [57772/888800 6.50%] train loss: 1.445225552743068e-05 \n",
      "epoch: 45 [58883/888800 6.62%] train loss: 1.4714524695591535e-05 \n",
      "epoch: 45 [59994/888800 6.75%] train loss: 1.489185706304852e-05 \n",
      "epoch: 45 [61105/888800 6.88%] train loss: 1.4633363207394723e-05 \n",
      "epoch: 45 [62216/888800 7.00%] train loss: 1.4708556591358501e-05 \n",
      "epoch: 45 [63327/888800 7.12%] train loss: 1.4335809282783885e-05 \n",
      "epoch: 45 [64438/888800 7.25%] train loss: 1.3873534044250846e-05 \n",
      "epoch: 45 [65549/888800 7.38%] train loss: 1.3776191735814791e-05 \n",
      "epoch: 45 [66660/888800 7.50%] train loss: 1.5307403373299167e-05 \n",
      "epoch: 45 [67771/888800 7.62%] train loss: 1.3158778529032134e-05 \n",
      "epoch: 45 [68882/888800 7.75%] train loss: 1.2873403647972737e-05 \n",
      "epoch: 45 [69993/888800 7.88%] train loss: 1.4848323189653456e-05 \n",
      "epoch: 45 [71104/888800 8.00%] train loss: 1.4265324352891184e-05 \n",
      "epoch: 45 [72215/888800 8.12%] train loss: 1.4251911125029437e-05 \n",
      "epoch: 45 [73326/888800 8.25%] train loss: 1.4377870684256777e-05 \n",
      "epoch: 45 [74437/888800 8.38%] train loss: 1.363883256999543e-05 \n",
      "epoch: 45 [75548/888800 8.50%] train loss: 1.2812023669539485e-05 \n",
      "epoch: 45 [76659/888800 8.62%] train loss: 1.3500861314241774e-05 \n",
      "epoch: 45 [77770/888800 8.75%] train loss: 1.488992347731255e-05 \n",
      "epoch: 45 [78881/888800 8.88%] train loss: 1.2950808013556525e-05 \n",
      "epoch: 45 [79992/888800 9.00%] train loss: 1.4564437151420861e-05 \n",
      "epoch: 45 [81103/888800 9.12%] train loss: 1.3025462976656854e-05 \n",
      "epoch: 45 [82214/888800 9.25%] train loss: 1.3748463061347138e-05 \n",
      "epoch: 45 [83325/888800 9.38%] train loss: 1.3821676475345157e-05 \n",
      "epoch: 45 [84436/888800 9.50%] train loss: 1.3474926163326018e-05 \n",
      "epoch: 45 [85547/888800 9.62%] train loss: 1.4367050425789785e-05 \n",
      "epoch: 45 [86658/888800 9.75%] train loss: 1.4721487787028309e-05 \n",
      "epoch: 45 [87769/888800 9.88%] train loss: 1.3953371308161877e-05 \n",
      "epoch: 45 [88880/888800 10.00%] train loss: 1.5194838852039538e-05 \n",
      "epoch: 45 [89991/888800 10.12%] train loss: 1.4055399333301466e-05 \n",
      "epoch: 45 [91102/888800 10.25%] train loss: 1.4771852875128388e-05 \n",
      "epoch: 45 [92213/888800 10.38%] train loss: 1.4593249943573028e-05 \n",
      "epoch: 45 [93324/888800 10.50%] train loss: 1.4254679626901634e-05 \n",
      "epoch: 45 [94435/888800 10.62%] train loss: 1.4154458767734468e-05 \n",
      "epoch: 45 [95546/888800 10.75%] train loss: 1.5261910448316485e-05 \n",
      "epoch: 45 [96657/888800 10.88%] train loss: 1.2996039004065096e-05 \n",
      "epoch: 45 [97768/888800 11.00%] train loss: 1.43331499202759e-05 \n",
      "epoch: 45 [98879/888800 11.12%] train loss: 1.4499588360195048e-05 \n",
      "epoch: 45 [99990/888800 11.25%] train loss: 1.4054902749194298e-05 \n",
      "epoch: 45 [101101/888800 11.38%] train loss: 1.4472106158791576e-05 \n",
      "epoch: 45 [102212/888800 11.50%] train loss: 1.3562219464802183e-05 \n",
      "epoch: 45 [103323/888800 11.62%] train loss: 1.4273168744693976e-05 \n",
      "epoch: 45 [104434/888800 11.75%] train loss: 1.5262326996889897e-05 \n",
      "epoch: 45 [105545/888800 11.88%] train loss: 1.395028448314406e-05 \n",
      "epoch: 45 [106656/888800 12.00%] train loss: 1.399527354806196e-05 \n",
      "epoch: 45 [107767/888800 12.12%] train loss: 1.371971120533999e-05 \n",
      "epoch: 45 [108878/888800 12.25%] train loss: 1.3759266039414797e-05 \n",
      "epoch: 45 [109989/888800 12.38%] train loss: 1.4648344404122327e-05 \n",
      "epoch: 45 [111100/888800 12.50%] train loss: 1.4301538612926379e-05 \n",
      "epoch: 45 [112211/888800 12.62%] train loss: 1.409475316904718e-05 \n",
      "epoch: 45 [113322/888800 12.75%] train loss: 1.421629531250801e-05 \n",
      "epoch: 45 [114433/888800 12.88%] train loss: 1.4713468772242777e-05 \n",
      "epoch: 45 [115544/888800 13.00%] train loss: 1.4118857507128268e-05 \n",
      "epoch: 45 [116655/888800 13.12%] train loss: 1.2281357157917228e-05 \n",
      "epoch: 45 [117766/888800 13.25%] train loss: 1.3804255104332697e-05 \n",
      "epoch: 45 [118877/888800 13.38%] train loss: 1.4005638149683364e-05 \n",
      "epoch: 45 [119988/888800 13.50%] train loss: 1.5053219613037072e-05 \n",
      "epoch: 45 [121099/888800 13.62%] train loss: 1.3644758837472182e-05 \n",
      "epoch: 45 [122210/888800 13.75%] train loss: 1.4722776541020721e-05 \n",
      "epoch: 45 [123321/888800 13.88%] train loss: 1.4360270142788067e-05 \n",
      "epoch: 45 [124432/888800 14.00%] train loss: 1.3606087122752797e-05 \n",
      "epoch: 45 [125543/888800 14.12%] train loss: 1.4197390555636957e-05 \n",
      "epoch: 45 [126654/888800 14.25%] train loss: 1.599692586751189e-05 \n",
      "epoch: 45 [127765/888800 14.38%] train loss: 1.44330797411385e-05 \n",
      "epoch: 45 [128876/888800 14.50%] train loss: 1.3385610145633109e-05 \n",
      "epoch: 45 [129987/888800 14.62%] train loss: 1.51351068780059e-05 \n",
      "epoch: 45 [131098/888800 14.75%] train loss: 1.3538637176679913e-05 \n",
      "epoch: 45 [132209/888800 14.88%] train loss: 1.4726200788572896e-05 \n",
      "epoch: 45 [133320/888800 15.00%] train loss: 1.389501994708553e-05 \n",
      "epoch: 45 [134431/888800 15.12%] train loss: 1.4497767551802099e-05 \n",
      "epoch: 45 [135542/888800 15.25%] train loss: 1.3886742635804694e-05 \n",
      "epoch: 45 [136653/888800 15.38%] train loss: 1.3522622793971095e-05 \n",
      "epoch: 45 [137764/888800 15.50%] train loss: 1.3902989849157166e-05 \n",
      "epoch: 45 [138875/888800 15.62%] train loss: 1.4331266356748529e-05 \n",
      "epoch: 45 [139986/888800 15.75%] train loss: 1.382310438202694e-05 \n",
      "epoch: 45 [141097/888800 15.88%] train loss: 1.4304599062597845e-05 \n",
      "epoch: 45 [142208/888800 16.00%] train loss: 1.2869528291048482e-05 \n",
      "epoch: 45 [143319/888800 16.12%] train loss: 1.3951867913419846e-05 \n",
      "epoch: 45 [144430/888800 16.25%] train loss: 1.4401250155060552e-05 \n",
      "epoch: 45 [145541/888800 16.38%] train loss: 1.4181231563270558e-05 \n",
      "epoch: 45 [146652/888800 16.50%] train loss: 1.2997040357731748e-05 \n",
      "epoch: 45 [147763/888800 16.62%] train loss: 1.3513623343897052e-05 \n",
      "epoch: 45 [148874/888800 16.75%] train loss: 1.41757127494202e-05 \n",
      "epoch: 45 [149985/888800 16.88%] train loss: 1.4573872249457054e-05 \n",
      "epoch: 45 [151096/888800 17.00%] train loss: 1.4220438060874585e-05 \n",
      "epoch: 45 [152207/888800 17.12%] train loss: 1.6793184840935282e-05 \n",
      "epoch: 45 [153318/888800 17.25%] train loss: 1.7018441212712787e-05 \n",
      "epoch: 45 [154429/888800 17.38%] train loss: 1.4544888472300954e-05 \n",
      "epoch: 45 [155540/888800 17.50%] train loss: 1.6983542082016356e-05 \n",
      "epoch: 45 [156651/888800 17.62%] train loss: 1.4714915778313298e-05 \n",
      "epoch: 45 [157762/888800 17.75%] train loss: 1.617886300664395e-05 \n",
      "epoch: 45 [158873/888800 17.88%] train loss: 1.413379686709959e-05 \n",
      "epoch: 45 [159984/888800 18.00%] train loss: 1.4837274648016319e-05 \n",
      "epoch: 45 [161095/888800 18.12%] train loss: 1.4492372429231182e-05 \n",
      "epoch: 45 [162206/888800 18.25%] train loss: 1.4208351785782725e-05 \n",
      "epoch: 45 [163317/888800 18.38%] train loss: 1.5104652447917033e-05 \n",
      "epoch: 45 [164428/888800 18.50%] train loss: 1.4823333003732841e-05 \n",
      "epoch: 45 [165539/888800 18.62%] train loss: 1.5497915228479542e-05 \n",
      "epoch: 45 [166650/888800 18.75%] train loss: 1.3785090231976938e-05 \n",
      "epoch: 45 [167761/888800 18.88%] train loss: 1.4627009477408137e-05 \n",
      "epoch: 45 [168872/888800 19.00%] train loss: 1.3654341273650061e-05 \n",
      "epoch: 45 [169983/888800 19.12%] train loss: 1.6232750567723997e-05 \n",
      "epoch: 45 [171094/888800 19.25%] train loss: 1.338621586910449e-05 \n",
      "epoch: 45 [172205/888800 19.38%] train loss: 1.5814492144272663e-05 \n",
      "epoch: 45 [173316/888800 19.50%] train loss: 1.4578555237676483e-05 \n",
      "epoch: 45 [174427/888800 19.62%] train loss: 1.6433339624200016e-05 \n",
      "epoch: 45 [175538/888800 19.75%] train loss: 1.3834608580509666e-05 \n",
      "epoch: 45 [176649/888800 19.88%] train loss: 1.4209437722456641e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [177760/888800 20.00%] train loss: 1.4082046618568711e-05 \n",
      "epoch: 45 [178871/888800 20.12%] train loss: 1.6012569176382385e-05 \n",
      "epoch: 45 [179982/888800 20.25%] train loss: 1.434235764463665e-05 \n",
      "epoch: 45 [181093/888800 20.38%] train loss: 1.3689092156710103e-05 \n",
      "epoch: 45 [182204/888800 20.50%] train loss: 1.5738422007416375e-05 \n",
      "epoch: 45 [183315/888800 20.62%] train loss: 1.3629397471959237e-05 \n",
      "epoch: 45 [184426/888800 20.75%] train loss: 1.4806026229052804e-05 \n",
      "epoch: 45 [185537/888800 20.88%] train loss: 1.4266103789850604e-05 \n",
      "epoch: 45 [186648/888800 21.00%] train loss: 1.3754262909060344e-05 \n",
      "epoch: 45 [187759/888800 21.12%] train loss: 1.4856944289931562e-05 \n",
      "epoch: 45 [188870/888800 21.25%] train loss: 1.5407107639475726e-05 \n",
      "epoch: 45 [189981/888800 21.38%] train loss: 1.4204018953023478e-05 \n",
      "epoch: 45 [191092/888800 21.50%] train loss: 1.4354473933053669e-05 \n",
      "epoch: 45 [192203/888800 21.62%] train loss: 1.4342361282615457e-05 \n",
      "epoch: 45 [193314/888800 21.75%] train loss: 1.452649030397879e-05 \n",
      "epoch: 45 [194425/888800 21.88%] train loss: 1.4202917554939631e-05 \n",
      "epoch: 45 [195536/888800 22.00%] train loss: 1.478913145547267e-05 \n",
      "epoch: 45 [196647/888800 22.12%] train loss: 1.2642356523429044e-05 \n",
      "epoch: 45 [197758/888800 22.25%] train loss: 1.3692690117750317e-05 \n",
      "epoch: 45 [198869/888800 22.38%] train loss: 1.4583727534045465e-05 \n",
      "epoch: 45 [199980/888800 22.50%] train loss: 1.4121364074526355e-05 \n",
      "epoch: 45 [201091/888800 22.62%] train loss: 1.535137380415108e-05 \n",
      "epoch: 45 [202202/888800 22.75%] train loss: 1.4703543456562329e-05 \n",
      "epoch: 45 [203313/888800 22.88%] train loss: 1.4082211237109732e-05 \n",
      "epoch: 45 [204424/888800 23.00%] train loss: 1.5962788893375546e-05 \n",
      "epoch: 45 [205535/888800 23.12%] train loss: 1.4304994692793116e-05 \n",
      "epoch: 45 [206646/888800 23.25%] train loss: 1.762845022312831e-05 \n",
      "epoch: 45 [207757/888800 23.38%] train loss: 1.3901016245654318e-05 \n",
      "epoch: 45 [208868/888800 23.50%] train loss: 1.6766340195317753e-05 \n",
      "epoch: 45 [209979/888800 23.62%] train loss: 1.4546544662152883e-05 \n",
      "epoch: 45 [211090/888800 23.75%] train loss: 1.4060571629670449e-05 \n",
      "epoch: 45 [212201/888800 23.88%] train loss: 1.4872219253447838e-05 \n",
      "epoch: 45 [213312/888800 24.00%] train loss: 1.3554363249568269e-05 \n",
      "epoch: 45 [214423/888800 24.12%] train loss: 1.4417393686017022e-05 \n",
      "epoch: 45 [215534/888800 24.25%] train loss: 1.3829144336341415e-05 \n",
      "epoch: 45 [216645/888800 24.38%] train loss: 1.5137829905143008e-05 \n",
      "epoch: 45 [217756/888800 24.50%] train loss: 1.456404152122559e-05 \n",
      "epoch: 45 [218867/888800 24.62%] train loss: 1.5005707609816454e-05 \n",
      "epoch: 45 [219978/888800 24.75%] train loss: 1.4599698261008598e-05 \n",
      "epoch: 45 [221089/888800 24.88%] train loss: 1.2731386959785596e-05 \n",
      "epoch: 45 [222200/888800 25.00%] train loss: 1.4756677956029307e-05 \n",
      "epoch: 45 [223311/888800 25.12%] train loss: 1.5349021850852296e-05 \n",
      "epoch: 45 [224422/888800 25.25%] train loss: 1.3498161933966912e-05 \n",
      "epoch: 45 [225533/888800 25.38%] train loss: 1.5304303815355524e-05 \n",
      "epoch: 45 [226644/888800 25.50%] train loss: 1.3577196114056278e-05 \n",
      "epoch: 45 [227755/888800 25.62%] train loss: 1.4314759937406052e-05 \n",
      "epoch: 45 [228866/888800 25.75%] train loss: 1.401790723321028e-05 \n",
      "epoch: 45 [229977/888800 25.88%] train loss: 1.4281705261964817e-05 \n",
      "epoch: 45 [231088/888800 26.00%] train loss: 1.4498721611744259e-05 \n",
      "epoch: 45 [232199/888800 26.12%] train loss: 1.4610880498366896e-05 \n",
      "epoch: 45 [233310/888800 26.25%] train loss: 1.6184501873794943e-05 \n",
      "epoch: 45 [234421/888800 26.38%] train loss: 1.4499976714432705e-05 \n",
      "epoch: 45 [235532/888800 26.50%] train loss: 1.544360929983668e-05 \n",
      "epoch: 45 [236643/888800 26.62%] train loss: 1.388270356983412e-05 \n",
      "epoch: 45 [237754/888800 26.75%] train loss: 1.4698852282890584e-05 \n",
      "epoch: 45 [238865/888800 26.88%] train loss: 1.4313946849142667e-05 \n",
      "epoch: 45 [239976/888800 27.00%] train loss: 1.4356940482684877e-05 \n",
      "epoch: 45 [241087/888800 27.12%] train loss: 1.3457519344228785e-05 \n",
      "epoch: 45 [242198/888800 27.25%] train loss: 1.4015836313774344e-05 \n",
      "epoch: 45 [243309/888800 27.38%] train loss: 1.4360139175551012e-05 \n",
      "epoch: 45 [244420/888800 27.50%] train loss: 1.368704397464171e-05 \n",
      "epoch: 45 [245531/888800 27.62%] train loss: 1.3421302355709486e-05 \n",
      "epoch: 45 [246642/888800 27.75%] train loss: 1.3920704077463597e-05 \n",
      "epoch: 45 [247753/888800 27.88%] train loss: 1.4406289665203076e-05 \n",
      "epoch: 45 [248864/888800 28.00%] train loss: 1.4352799553307705e-05 \n",
      "epoch: 45 [249975/888800 28.12%] train loss: 1.4860575902275741e-05 \n",
      "epoch: 45 [251086/888800 28.25%] train loss: 1.4602688679588027e-05 \n",
      "epoch: 45 [252197/888800 28.38%] train loss: 1.4223074686015025e-05 \n",
      "epoch: 45 [253308/888800 28.50%] train loss: 1.3864761058357544e-05 \n",
      "epoch: 45 [254419/888800 28.62%] train loss: 1.4263877346820664e-05 \n",
      "epoch: 45 [255530/888800 28.75%] train loss: 1.2470743058656808e-05 \n",
      "epoch: 45 [256641/888800 28.88%] train loss: 1.392488684359705e-05 \n",
      "epoch: 45 [257752/888800 29.00%] train loss: 1.44608329719631e-05 \n",
      "epoch: 45 [258863/888800 29.12%] train loss: 1.46677220982383e-05 \n",
      "epoch: 45 [259974/888800 29.25%] train loss: 1.387070915370714e-05 \n",
      "epoch: 45 [261085/888800 29.38%] train loss: 1.3374852642300539e-05 \n",
      "epoch: 45 [262196/888800 29.50%] train loss: 1.411016273777932e-05 \n",
      "epoch: 45 [263307/888800 29.62%] train loss: 1.348116529698018e-05 \n",
      "epoch: 45 [264418/888800 29.75%] train loss: 1.414408234268194e-05 \n",
      "epoch: 45 [265529/888800 29.88%] train loss: 1.4833985915174708e-05 \n",
      "epoch: 45 [266640/888800 30.00%] train loss: 1.390008856105851e-05 \n",
      "epoch: 45 [267751/888800 30.12%] train loss: 1.4439996448345482e-05 \n",
      "epoch: 45 [268862/888800 30.25%] train loss: 1.3372978173720185e-05 \n",
      "epoch: 45 [269973/888800 30.38%] train loss: 1.4016020031704102e-05 \n",
      "epoch: 45 [271084/888800 30.50%] train loss: 1.3420939467323478e-05 \n",
      "epoch: 45 [272195/888800 30.62%] train loss: 1.4662139619758818e-05 \n",
      "epoch: 45 [273306/888800 30.75%] train loss: 1.4462029866990633e-05 \n",
      "epoch: 45 [274417/888800 30.88%] train loss: 1.3373723959375639e-05 \n",
      "epoch: 45 [275528/888800 31.00%] train loss: 1.4570514395018108e-05 \n",
      "epoch: 45 [276639/888800 31.12%] train loss: 1.3912796021031681e-05 \n",
      "epoch: 45 [277750/888800 31.25%] train loss: 1.334858825430274e-05 \n",
      "epoch: 45 [278861/888800 31.38%] train loss: 1.4382253539224621e-05 \n",
      "epoch: 45 [279972/888800 31.50%] train loss: 1.529980181658175e-05 \n",
      "epoch: 45 [281083/888800 31.62%] train loss: 1.3757415217696689e-05 \n",
      "epoch: 45 [282194/888800 31.75%] train loss: 1.548268846818246e-05 \n",
      "epoch: 45 [283305/888800 31.88%] train loss: 1.4362663932843134e-05 \n",
      "epoch: 45 [284416/888800 32.00%] train loss: 1.434108071407536e-05 \n",
      "epoch: 45 [285527/888800 32.12%] train loss: 1.4036671018402558e-05 \n",
      "epoch: 45 [286638/888800 32.25%] train loss: 1.4627532436861657e-05 \n",
      "epoch: 45 [287749/888800 32.38%] train loss: 1.4758584256924223e-05 \n",
      "epoch: 45 [288860/888800 32.50%] train loss: 1.4246044884203002e-05 \n",
      "epoch: 45 [289971/888800 32.62%] train loss: 1.471822542953305e-05 \n",
      "epoch: 45 [291082/888800 32.75%] train loss: 1.439017341908766e-05 \n",
      "epoch: 45 [292193/888800 32.88%] train loss: 1.4390370779437944e-05 \n",
      "epoch: 45 [293304/888800 33.00%] train loss: 1.2781336408806965e-05 \n",
      "epoch: 45 [294415/888800 33.12%] train loss: 1.5195885680441279e-05 \n",
      "epoch: 45 [295526/888800 33.25%] train loss: 1.4321414710138924e-05 \n",
      "epoch: 45 [296637/888800 33.38%] train loss: 1.628298923606053e-05 \n",
      "epoch: 45 [297748/888800 33.50%] train loss: 1.650808371778112e-05 \n",
      "epoch: 45 [298859/888800 33.62%] train loss: 1.5705509213148616e-05 \n",
      "epoch: 45 [299970/888800 33.75%] train loss: 1.4366778486873955e-05 \n",
      "epoch: 45 [301081/888800 33.88%] train loss: 1.5496101696044207e-05 \n",
      "epoch: 45 [302192/888800 34.00%] train loss: 1.3909596418670844e-05 \n",
      "epoch: 45 [303303/888800 34.12%] train loss: 1.4155452845443506e-05 \n",
      "epoch: 45 [304414/888800 34.25%] train loss: 1.431810869689798e-05 \n",
      "epoch: 45 [305525/888800 34.38%] train loss: 1.478811554989079e-05 \n",
      "epoch: 45 [306636/888800 34.50%] train loss: 1.3600634702015668e-05 \n",
      "epoch: 45 [307747/888800 34.62%] train loss: 1.556935785629321e-05 \n",
      "epoch: 45 [308858/888800 34.75%] train loss: 1.4443272448261268e-05 \n",
      "epoch: 45 [309969/888800 34.88%] train loss: 1.4527343410009053e-05 \n",
      "epoch: 45 [311080/888800 35.00%] train loss: 1.3472971659211908e-05 \n",
      "epoch: 45 [312191/888800 35.12%] train loss: 1.4707768059452064e-05 \n",
      "epoch: 45 [313302/888800 35.25%] train loss: 1.4261981050367467e-05 \n",
      "epoch: 45 [314413/888800 35.38%] train loss: 1.4158947124087717e-05 \n",
      "epoch: 45 [315524/888800 35.50%] train loss: 1.5766549040563405e-05 \n",
      "epoch: 45 [316635/888800 35.62%] train loss: 1.5062242709973361e-05 \n",
      "epoch: 45 [317746/888800 35.75%] train loss: 1.6195199350477196e-05 \n",
      "epoch: 45 [318857/888800 35.88%] train loss: 1.493770378147019e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [319968/888800 36.00%] train loss: 1.4391694094229024e-05 \n",
      "epoch: 45 [321079/888800 36.12%] train loss: 1.3862560081179254e-05 \n",
      "epoch: 45 [322190/888800 36.25%] train loss: 1.5519093722105026e-05 \n",
      "epoch: 45 [323301/888800 36.38%] train loss: 1.4572061445505824e-05 \n",
      "epoch: 45 [324412/888800 36.50%] train loss: 1.525812695035711e-05 \n",
      "epoch: 45 [325523/888800 36.62%] train loss: 1.4757240023755003e-05 \n",
      "epoch: 45 [326634/888800 36.75%] train loss: 1.4107691640674602e-05 \n",
      "epoch: 45 [327745/888800 36.88%] train loss: 1.5379868273157626e-05 \n",
      "epoch: 45 [328856/888800 37.00%] train loss: 1.4152810763334855e-05 \n",
      "epoch: 45 [329967/888800 37.12%] train loss: 1.4138108781480696e-05 \n",
      "epoch: 45 [331078/888800 37.25%] train loss: 1.4815767826803494e-05 \n",
      "epoch: 45 [332189/888800 37.38%] train loss: 1.4115170415607281e-05 \n",
      "epoch: 45 [333300/888800 37.50%] train loss: 1.474228520237375e-05 \n",
      "epoch: 45 [334411/888800 37.62%] train loss: 1.548351428937167e-05 \n",
      "epoch: 45 [335522/888800 37.75%] train loss: 1.4238659787224606e-05 \n",
      "epoch: 45 [336633/888800 37.88%] train loss: 1.47464661495178e-05 \n",
      "epoch: 45 [337744/888800 38.00%] train loss: 1.4107407878327649e-05 \n",
      "epoch: 45 [338855/888800 38.12%] train loss: 1.547595820738934e-05 \n",
      "epoch: 45 [339966/888800 38.25%] train loss: 1.3978250535728876e-05 \n",
      "epoch: 45 [341077/888800 38.38%] train loss: 1.3893716641177889e-05 \n",
      "epoch: 45 [342188/888800 38.50%] train loss: 1.4219202057574876e-05 \n",
      "epoch: 45 [343299/888800 38.62%] train loss: 1.4889442354615312e-05 \n",
      "epoch: 45 [344410/888800 38.75%] train loss: 1.4759778423467651e-05 \n",
      "epoch: 45 [345521/888800 38.88%] train loss: 1.3615653188026045e-05 \n",
      "epoch: 45 [346632/888800 39.00%] train loss: 1.4971466043789405e-05 \n",
      "epoch: 45 [347743/888800 39.12%] train loss: 1.3096268048684578e-05 \n",
      "epoch: 45 [348854/888800 39.25%] train loss: 1.4608013771066908e-05 \n",
      "epoch: 45 [349965/888800 39.38%] train loss: 1.324182994721923e-05 \n",
      "epoch: 45 [351076/888800 39.50%] train loss: 1.4451340575760696e-05 \n",
      "epoch: 45 [352187/888800 39.62%] train loss: 1.4286614714364987e-05 \n",
      "epoch: 45 [353298/888800 39.75%] train loss: 1.5312692994484678e-05 \n",
      "epoch: 45 [354409/888800 39.88%] train loss: 1.4204082617652602e-05 \n",
      "epoch: 45 [355520/888800 40.00%] train loss: 1.3729099919146392e-05 \n",
      "epoch: 45 [356631/888800 40.12%] train loss: 1.2813235116482247e-05 \n",
      "epoch: 45 [357742/888800 40.25%] train loss: 1.4709958122693934e-05 \n",
      "epoch: 45 [358853/888800 40.38%] train loss: 1.4401896805793513e-05 \n",
      "epoch: 45 [359964/888800 40.50%] train loss: 1.3614695490105078e-05 \n",
      "epoch: 45 [361075/888800 40.62%] train loss: 1.3264754670672119e-05 \n",
      "epoch: 45 [362186/888800 40.75%] train loss: 1.3993537322676275e-05 \n",
      "epoch: 45 [363297/888800 40.88%] train loss: 1.3996421330375597e-05 \n",
      "epoch: 45 [364408/888800 41.00%] train loss: 1.5031828297651373e-05 \n",
      "epoch: 45 [365519/888800 41.12%] train loss: 1.4753209143236745e-05 \n",
      "epoch: 45 [366630/888800 41.25%] train loss: 1.4375294995261356e-05 \n",
      "epoch: 45 [367741/888800 41.38%] train loss: 1.4523244317388162e-05 \n",
      "epoch: 45 [368852/888800 41.50%] train loss: 1.4515360817313194e-05 \n",
      "epoch: 45 [369963/888800 41.62%] train loss: 1.3719559319724794e-05 \n",
      "epoch: 45 [371074/888800 41.75%] train loss: 1.4419286344491411e-05 \n",
      "epoch: 45 [372185/888800 41.88%] train loss: 1.4371559700521175e-05 \n",
      "epoch: 45 [373296/888800 42.00%] train loss: 1.4098692190600559e-05 \n",
      "epoch: 45 [374407/888800 42.12%] train loss: 1.3932857655163389e-05 \n",
      "epoch: 45 [375518/888800 42.25%] train loss: 1.4842455129837617e-05 \n",
      "epoch: 45 [376629/888800 42.38%] train loss: 1.39571793624782e-05 \n",
      "epoch: 45 [377740/888800 42.50%] train loss: 1.3523637790058274e-05 \n",
      "epoch: 45 [378851/888800 42.62%] train loss: 1.598652670509182e-05 \n",
      "epoch: 45 [379962/888800 42.75%] train loss: 1.6362131646019407e-05 \n",
      "epoch: 45 [381073/888800 42.88%] train loss: 1.4899059351591859e-05 \n",
      "epoch: 45 [382184/888800 43.00%] train loss: 1.356868688162649e-05 \n",
      "epoch: 45 [383295/888800 43.12%] train loss: 1.5569403331028298e-05 \n",
      "epoch: 45 [384406/888800 43.25%] train loss: 1.4251236279960722e-05 \n",
      "epoch: 45 [385517/888800 43.38%] train loss: 1.529730980109889e-05 \n",
      "epoch: 45 [386628/888800 43.50%] train loss: 1.3900374142394867e-05 \n",
      "epoch: 45 [387739/888800 43.62%] train loss: 1.5730183804407716e-05 \n",
      "epoch: 45 [388850/888800 43.75%] train loss: 1.3952845620224252e-05 \n",
      "epoch: 45 [389961/888800 43.88%] train loss: 1.3286115063237958e-05 \n",
      "epoch: 45 [391072/888800 44.00%] train loss: 1.5098893527465407e-05 \n",
      "epoch: 45 [392183/888800 44.12%] train loss: 1.4068936252442654e-05 \n",
      "epoch: 45 [393294/888800 44.25%] train loss: 1.3600438251160085e-05 \n",
      "epoch: 45 [394405/888800 44.38%] train loss: 1.4320103218778968e-05 \n",
      "epoch: 45 [395516/888800 44.50%] train loss: 1.4256800568546169e-05 \n",
      "epoch: 45 [396627/888800 44.62%] train loss: 1.5362065823865123e-05 \n",
      "epoch: 45 [397738/888800 44.75%] train loss: 1.4193589777278248e-05 \n",
      "epoch: 45 [398849/888800 44.88%] train loss: 1.3140829651092645e-05 \n",
      "epoch: 45 [399960/888800 45.00%] train loss: 1.5411487765959464e-05 \n",
      "epoch: 45 [401071/888800 45.12%] train loss: 1.378129582008114e-05 \n",
      "epoch: 45 [402182/888800 45.25%] train loss: 1.513225015514763e-05 \n",
      "epoch: 45 [403293/888800 45.38%] train loss: 1.4417574675462674e-05 \n",
      "epoch: 45 [404404/888800 45.50%] train loss: 1.4596050277759787e-05 \n",
      "epoch: 45 [405515/888800 45.62%] train loss: 1.595889261807315e-05 \n",
      "epoch: 45 [406626/888800 45.75%] train loss: 1.4647037460235879e-05 \n",
      "epoch: 45 [407737/888800 45.88%] train loss: 1.2910074474348221e-05 \n",
      "epoch: 45 [408848/888800 46.00%] train loss: 1.5564086425001733e-05 \n",
      "epoch: 45 [409959/888800 46.12%] train loss: 1.4913664017512929e-05 \n",
      "epoch: 45 [411070/888800 46.25%] train loss: 1.497660832683323e-05 \n",
      "epoch: 45 [412181/888800 46.38%] train loss: 1.582057484483812e-05 \n",
      "epoch: 45 [413292/888800 46.50%] train loss: 1.4734304386365693e-05 \n",
      "epoch: 45 [414403/888800 46.62%] train loss: 1.5205831005005166e-05 \n",
      "epoch: 45 [415514/888800 46.75%] train loss: 1.4121784261078574e-05 \n",
      "epoch: 45 [416625/888800 46.88%] train loss: 1.515303574706195e-05 \n",
      "epoch: 45 [417736/888800 47.00%] train loss: 1.4523388017551042e-05 \n",
      "epoch: 45 [418847/888800 47.12%] train loss: 1.6004136341507547e-05 \n",
      "epoch: 45 [419958/888800 47.25%] train loss: 1.3353545909922104e-05 \n",
      "epoch: 45 [421069/888800 47.38%] train loss: 1.5007160072855186e-05 \n",
      "epoch: 45 [422180/888800 47.50%] train loss: 1.5930727386148646e-05 \n",
      "epoch: 45 [423291/888800 47.62%] train loss: 1.4443729014601558e-05 \n",
      "epoch: 45 [424402/888800 47.75%] train loss: 1.4729888789588585e-05 \n",
      "epoch: 45 [425513/888800 47.88%] train loss: 1.4120000741968397e-05 \n",
      "epoch: 45 [426624/888800 48.00%] train loss: 1.5574814824503846e-05 \n",
      "epoch: 45 [427735/888800 48.12%] train loss: 1.4617875422118232e-05 \n",
      "epoch: 45 [428846/888800 48.25%] train loss: 1.401231565978378e-05 \n",
      "epoch: 45 [429957/888800 48.38%] train loss: 1.363602132187225e-05 \n",
      "epoch: 45 [431068/888800 48.50%] train loss: 1.5953917682054453e-05 \n",
      "epoch: 45 [432179/888800 48.62%] train loss: 1.4432573152589612e-05 \n",
      "epoch: 45 [433290/888800 48.75%] train loss: 1.3820248568663374e-05 \n",
      "epoch: 45 [434401/888800 48.88%] train loss: 1.4681168067909312e-05 \n",
      "epoch: 45 [435512/888800 49.00%] train loss: 1.5204588635242544e-05 \n",
      "epoch: 45 [436623/888800 49.12%] train loss: 1.420032094756607e-05 \n",
      "epoch: 45 [437734/888800 49.25%] train loss: 1.6183204934350215e-05 \n",
      "epoch: 45 [438845/888800 49.38%] train loss: 1.6573749235249124e-05 \n",
      "epoch: 45 [439956/888800 49.50%] train loss: 1.3952148947282694e-05 \n",
      "epoch: 45 [441067/888800 49.62%] train loss: 1.5087741303432267e-05 \n",
      "epoch: 45 [442178/888800 49.75%] train loss: 1.4673244550067466e-05 \n",
      "epoch: 45 [443289/888800 49.88%] train loss: 1.436998718418181e-05 \n",
      "epoch: 45 [444400/888800 50.00%] train loss: 1.4901993381499778e-05 \n",
      "epoch: 45 [445511/888800 50.12%] train loss: 1.5013845768407919e-05 \n",
      "epoch: 45 [446622/888800 50.25%] train loss: 1.4107296010479331e-05 \n",
      "epoch: 45 [447733/888800 50.38%] train loss: 1.5529964002780616e-05 \n",
      "epoch: 45 [448844/888800 50.50%] train loss: 1.5178744433796965e-05 \n",
      "epoch: 45 [449955/888800 50.62%] train loss: 1.5190560588962398e-05 \n",
      "epoch: 45 [451066/888800 50.75%] train loss: 1.333135696768295e-05 \n",
      "epoch: 45 [452177/888800 50.88%] train loss: 1.5864401575527154e-05 \n",
      "epoch: 45 [453288/888800 51.00%] train loss: 1.4321021808427759e-05 \n",
      "epoch: 45 [454399/888800 51.12%] train loss: 1.508913828729419e-05 \n",
      "epoch: 45 [455510/888800 51.25%] train loss: 1.3293119081936311e-05 \n",
      "epoch: 45 [456621/888800 51.38%] train loss: 1.4386271686817054e-05 \n",
      "epoch: 45 [457732/888800 51.50%] train loss: 1.4396185179066379e-05 \n",
      "epoch: 45 [458843/888800 51.62%] train loss: 1.4604312127630692e-05 \n",
      "epoch: 45 [459954/888800 51.75%] train loss: 1.3713059161091223e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [461065/888800 51.88%] train loss: 1.3811573808197863e-05 \n",
      "epoch: 45 [462176/888800 52.00%] train loss: 1.3250502888695337e-05 \n",
      "epoch: 45 [463287/888800 52.12%] train loss: 1.4486435247818008e-05 \n",
      "epoch: 45 [464398/888800 52.25%] train loss: 1.4730093425896484e-05 \n",
      "epoch: 45 [465509/888800 52.38%] train loss: 1.3629288332595024e-05 \n",
      "epoch: 45 [466620/888800 52.50%] train loss: 1.4804089005338028e-05 \n",
      "epoch: 45 [467731/888800 52.62%] train loss: 1.3823482731822878e-05 \n",
      "epoch: 45 [468842/888800 52.75%] train loss: 1.4381880646396894e-05 \n",
      "epoch: 45 [469953/888800 52.88%] train loss: 1.401175086357398e-05 \n",
      "epoch: 45 [471064/888800 53.00%] train loss: 1.368233915854944e-05 \n",
      "epoch: 45 [472175/888800 53.12%] train loss: 1.4172598639561329e-05 \n",
      "epoch: 45 [473286/888800 53.25%] train loss: 1.356824031972792e-05 \n",
      "epoch: 45 [474397/888800 53.38%] train loss: 1.3145308912498876e-05 \n",
      "epoch: 45 [475508/888800 53.50%] train loss: 1.4764746083528735e-05 \n",
      "epoch: 45 [476619/888800 53.62%] train loss: 1.41243626785581e-05 \n",
      "epoch: 45 [477730/888800 53.75%] train loss: 1.387514203088358e-05 \n",
      "epoch: 45 [478841/888800 53.88%] train loss: 1.4297615962277632e-05 \n",
      "epoch: 45 [479952/888800 54.00%] train loss: 1.3685723388334736e-05 \n",
      "epoch: 45 [481063/888800 54.12%] train loss: 1.4028934856469277e-05 \n",
      "epoch: 45 [482174/888800 54.25%] train loss: 1.3768871212960221e-05 \n",
      "epoch: 45 [483285/888800 54.38%] train loss: 1.5194230400084052e-05 \n",
      "epoch: 45 [484396/888800 54.50%] train loss: 1.3884110558137763e-05 \n",
      "epoch: 45 [485507/888800 54.62%] train loss: 1.418703959643608e-05 \n",
      "epoch: 45 [486618/888800 54.75%] train loss: 1.4377149454958271e-05 \n",
      "epoch: 45 [487729/888800 54.88%] train loss: 1.3156733075447846e-05 \n",
      "epoch: 45 [488840/888800 55.00%] train loss: 1.3714296073885635e-05 \n",
      "epoch: 45 [489951/888800 55.12%] train loss: 1.4407422895601485e-05 \n",
      "epoch: 45 [491062/888800 55.25%] train loss: 1.4853148968541063e-05 \n",
      "epoch: 45 [492173/888800 55.38%] train loss: 1.4437652680499014e-05 \n",
      "epoch: 45 [493284/888800 55.50%] train loss: 1.3462386959872674e-05 \n",
      "epoch: 45 [494395/888800 55.62%] train loss: 1.440044343326008e-05 \n",
      "epoch: 45 [495506/888800 55.75%] train loss: 1.4455078598984983e-05 \n",
      "epoch: 45 [496617/888800 55.88%] train loss: 1.498903293395415e-05 \n",
      "epoch: 45 [497728/888800 56.00%] train loss: 1.302186501561664e-05 \n",
      "epoch: 45 [498839/888800 56.12%] train loss: 1.3248232789919712e-05 \n",
      "epoch: 45 [499950/888800 56.25%] train loss: 1.3175232197681908e-05 \n",
      "epoch: 45 [501061/888800 56.38%] train loss: 1.496455843152944e-05 \n",
      "epoch: 45 [502172/888800 56.50%] train loss: 1.3661868251801934e-05 \n",
      "epoch: 45 [503283/888800 56.62%] train loss: 1.3335053154150955e-05 \n",
      "epoch: 45 [504394/888800 56.75%] train loss: 1.3297117220645305e-05 \n",
      "epoch: 45 [505505/888800 56.88%] train loss: 1.3433663298201282e-05 \n",
      "epoch: 45 [506616/888800 57.00%] train loss: 1.3564354048867244e-05 \n",
      "epoch: 45 [507727/888800 57.12%] train loss: 1.3188616321713198e-05 \n",
      "epoch: 45 [508838/888800 57.25%] train loss: 1.41807404361316e-05 \n",
      "epoch: 45 [509949/888800 57.38%] train loss: 1.3962961020297371e-05 \n",
      "epoch: 45 [511060/888800 57.50%] train loss: 1.3760065485257655e-05 \n",
      "epoch: 45 [512171/888800 57.62%] train loss: 1.4719504179083742e-05 \n",
      "epoch: 45 [513282/888800 57.75%] train loss: 1.3810538803227246e-05 \n",
      "epoch: 45 [514393/888800 57.88%] train loss: 1.2795047950930893e-05 \n",
      "epoch: 45 [515504/888800 58.00%] train loss: 1.562259058118798e-05 \n",
      "epoch: 45 [516615/888800 58.12%] train loss: 1.556839379190933e-05 \n",
      "epoch: 45 [517726/888800 58.25%] train loss: 1.503591556684114e-05 \n",
      "epoch: 45 [518837/888800 58.38%] train loss: 1.3286310604598839e-05 \n",
      "epoch: 45 [519948/888800 58.50%] train loss: 1.4139782251731958e-05 \n",
      "epoch: 45 [521059/888800 58.62%] train loss: 1.3807110008201562e-05 \n",
      "epoch: 45 [522170/888800 58.75%] train loss: 1.4235105481930077e-05 \n",
      "epoch: 45 [523281/888800 58.88%] train loss: 1.4598092093365267e-05 \n",
      "epoch: 45 [524392/888800 59.00%] train loss: 1.4890285456203856e-05 \n",
      "epoch: 45 [525503/888800 59.12%] train loss: 1.4345501767820679e-05 \n",
      "epoch: 45 [526614/888800 59.25%] train loss: 1.4300746443041135e-05 \n",
      "epoch: 45 [527725/888800 59.38%] train loss: 1.5468076526303776e-05 \n",
      "epoch: 45 [528836/888800 59.50%] train loss: 1.3232856872491539e-05 \n",
      "epoch: 45 [529947/888800 59.62%] train loss: 1.6469972251798026e-05 \n",
      "epoch: 45 [531058/888800 59.75%] train loss: 1.4361367902893107e-05 \n",
      "epoch: 45 [532169/888800 59.88%] train loss: 1.6308929843944497e-05 \n",
      "epoch: 45 [533280/888800 60.00%] train loss: 1.3655358088726643e-05 \n",
      "epoch: 45 [534391/888800 60.12%] train loss: 1.5446719771716744e-05 \n",
      "epoch: 45 [535502/888800 60.25%] train loss: 1.5034500393085182e-05 \n",
      "epoch: 45 [536613/888800 60.38%] train loss: 1.5920246369205415e-05 \n",
      "epoch: 45 [537724/888800 60.50%] train loss: 1.4870038285152987e-05 \n",
      "epoch: 45 [538835/888800 60.62%] train loss: 1.3897682038077619e-05 \n",
      "epoch: 45 [539946/888800 60.75%] train loss: 1.337063622486312e-05 \n",
      "epoch: 45 [541057/888800 60.88%] train loss: 1.4216898307495285e-05 \n",
      "epoch: 45 [542168/888800 61.00%] train loss: 1.4357460713654291e-05 \n",
      "epoch: 45 [543279/888800 61.12%] train loss: 1.3300629689183552e-05 \n",
      "epoch: 45 [544390/888800 61.25%] train loss: 1.3470504200085998e-05 \n",
      "epoch: 45 [545501/888800 61.38%] train loss: 1.4371751603903249e-05 \n",
      "epoch: 45 [546612/888800 61.50%] train loss: 1.4679460036859382e-05 \n",
      "epoch: 45 [547723/888800 61.62%] train loss: 1.3074474736640695e-05 \n",
      "epoch: 45 [548834/888800 61.75%] train loss: 1.5426956451847218e-05 \n",
      "epoch: 45 [549945/888800 61.88%] train loss: 1.5284522305591963e-05 \n",
      "epoch: 45 [551056/888800 62.00%] train loss: 1.4092210221861023e-05 \n",
      "epoch: 45 [552167/888800 62.12%] train loss: 1.40838874358451e-05 \n",
      "epoch: 45 [553278/888800 62.25%] train loss: 1.5089729458850343e-05 \n",
      "epoch: 45 [554389/888800 62.38%] train loss: 1.5358125892817043e-05 \n",
      "epoch: 45 [555500/888800 62.50%] train loss: 1.5717985661467537e-05 \n",
      "epoch: 45 [556611/888800 62.62%] train loss: 1.3908364962844644e-05 \n",
      "epoch: 45 [557722/888800 62.75%] train loss: 1.4866041055938695e-05 \n",
      "epoch: 45 [558833/888800 62.88%] train loss: 1.532853457320016e-05 \n",
      "epoch: 45 [559944/888800 63.00%] train loss: 1.479965794715099e-05 \n",
      "epoch: 45 [561055/888800 63.12%] train loss: 1.4036514585313853e-05 \n",
      "epoch: 45 [562166/888800 63.25%] train loss: 1.415055612596916e-05 \n",
      "epoch: 45 [563277/888800 63.38%] train loss: 1.478734066040488e-05 \n",
      "epoch: 45 [564388/888800 63.50%] train loss: 1.341298866464058e-05 \n",
      "epoch: 45 [565499/888800 63.62%] train loss: 1.6139487343025394e-05 \n",
      "epoch: 45 [566610/888800 63.75%] train loss: 1.4927142728993203e-05 \n",
      "epoch: 45 [567721/888800 63.88%] train loss: 1.4699878192914184e-05 \n",
      "epoch: 45 [568832/888800 64.00%] train loss: 1.5432418877026066e-05 \n",
      "epoch: 45 [569943/888800 64.12%] train loss: 1.4651850506197661e-05 \n",
      "epoch: 45 [571054/888800 64.25%] train loss: 1.4848845239612274e-05 \n",
      "epoch: 45 [572165/888800 64.38%] train loss: 1.4537742572429124e-05 \n",
      "epoch: 45 [573276/888800 64.50%] train loss: 1.4596619621443097e-05 \n",
      "epoch: 45 [574387/888800 64.62%] train loss: 1.3676095477421768e-05 \n",
      "epoch: 45 [575498/888800 64.75%] train loss: 1.5096256902324967e-05 \n",
      "epoch: 45 [576609/888800 64.88%] train loss: 1.5673322195652872e-05 \n",
      "epoch: 45 [577720/888800 65.00%] train loss: 1.365449406875996e-05 \n",
      "epoch: 45 [578831/888800 65.12%] train loss: 1.4086262126511429e-05 \n",
      "epoch: 45 [579942/888800 65.25%] train loss: 1.3959296666143928e-05 \n",
      "epoch: 45 [581053/888800 65.38%] train loss: 1.3030871741648298e-05 \n",
      "epoch: 45 [582164/888800 65.50%] train loss: 1.434422028978588e-05 \n",
      "epoch: 45 [583275/888800 65.62%] train loss: 1.333196723862784e-05 \n",
      "epoch: 45 [584386/888800 65.75%] train loss: 1.4946281226002611e-05 \n",
      "epoch: 45 [585497/888800 65.88%] train loss: 1.3725814824283589e-05 \n",
      "epoch: 45 [586608/888800 66.00%] train loss: 1.4560946510755457e-05 \n",
      "epoch: 45 [587719/888800 66.12%] train loss: 1.5077103853400331e-05 \n",
      "epoch: 45 [588830/888800 66.25%] train loss: 1.3935565220890567e-05 \n",
      "epoch: 45 [589941/888800 66.38%] train loss: 1.5718958820798434e-05 \n",
      "epoch: 45 [591052/888800 66.50%] train loss: 1.3884256986784749e-05 \n",
      "epoch: 45 [592163/888800 66.62%] train loss: 1.390597753925249e-05 \n",
      "epoch: 45 [593274/888800 66.75%] train loss: 1.4918520719220396e-05 \n",
      "epoch: 45 [594385/888800 66.88%] train loss: 1.3987005331728142e-05 \n",
      "epoch: 45 [595496/888800 67.00%] train loss: 1.368475022900384e-05 \n",
      "epoch: 45 [596607/888800 67.12%] train loss: 1.26387431009789e-05 \n",
      "epoch: 45 [597718/888800 67.25%] train loss: 1.5291632735170424e-05 \n",
      "epoch: 45 [598829/888800 67.38%] train loss: 1.3897103599447291e-05 \n",
      "epoch: 45 [599940/888800 67.50%] train loss: 1.4417328202398494e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [601051/888800 67.62%] train loss: 1.4050365280127153e-05 \n",
      "epoch: 45 [602162/888800 67.75%] train loss: 1.4561652278644033e-05 \n",
      "epoch: 45 [603273/888800 67.88%] train loss: 1.3915208910475485e-05 \n",
      "epoch: 45 [604384/888800 68.00%] train loss: 1.381032507197233e-05 \n",
      "epoch: 45 [605495/888800 68.12%] train loss: 1.5080020602908917e-05 \n",
      "epoch: 45 [606606/888800 68.25%] train loss: 1.3223020687291864e-05 \n",
      "epoch: 45 [607717/888800 68.38%] train loss: 1.3337075870367698e-05 \n",
      "epoch: 45 [608828/888800 68.50%] train loss: 1.416419127053814e-05 \n",
      "epoch: 45 [609939/888800 68.62%] train loss: 1.3168391888029873e-05 \n",
      "epoch: 45 [611050/888800 68.75%] train loss: 1.4112500139162876e-05 \n",
      "epoch: 45 [612161/888800 68.88%] train loss: 1.374159000988584e-05 \n",
      "epoch: 45 [613272/888800 69.00%] train loss: 1.253628397535067e-05 \n",
      "epoch: 45 [614383/888800 69.12%] train loss: 1.3691999811271671e-05 \n",
      "epoch: 45 [615494/888800 69.25%] train loss: 1.554517075419426e-05 \n",
      "epoch: 45 [616605/888800 69.38%] train loss: 1.3535626749217045e-05 \n",
      "epoch: 45 [617716/888800 69.50%] train loss: 1.3475456398737151e-05 \n",
      "epoch: 45 [618827/888800 69.62%] train loss: 1.2789462743967306e-05 \n",
      "epoch: 45 [619938/888800 69.75%] train loss: 1.4591516446671449e-05 \n",
      "epoch: 45 [621049/888800 69.88%] train loss: 1.4765736523258965e-05 \n",
      "epoch: 45 [622160/888800 70.00%] train loss: 1.4233878573577385e-05 \n",
      "epoch: 45 [623271/888800 70.12%] train loss: 1.4812676454312168e-05 \n",
      "epoch: 45 [624382/888800 70.25%] train loss: 1.3331930858839769e-05 \n",
      "epoch: 45 [625493/888800 70.38%] train loss: 1.4872139217914082e-05 \n",
      "epoch: 45 [626604/888800 70.50%] train loss: 1.4015149645274505e-05 \n",
      "epoch: 45 [627715/888800 70.62%] train loss: 1.3980769836052787e-05 \n",
      "epoch: 45 [628826/888800 70.75%] train loss: 1.4799172276980244e-05 \n",
      "epoch: 45 [629937/888800 70.88%] train loss: 1.3761631635134108e-05 \n",
      "epoch: 45 [631048/888800 71.00%] train loss: 1.3824434972775634e-05 \n",
      "epoch: 45 [632159/888800 71.12%] train loss: 1.3986104931973387e-05 \n",
      "epoch: 45 [633270/888800 71.25%] train loss: 1.5178438843577169e-05 \n",
      "epoch: 45 [634381/888800 71.38%] train loss: 1.3968006896902807e-05 \n",
      "epoch: 45 [635492/888800 71.50%] train loss: 1.4033675142854918e-05 \n",
      "epoch: 45 [636603/888800 71.62%] train loss: 1.531922498543281e-05 \n",
      "epoch: 45 [637714/888800 71.75%] train loss: 1.388374494126765e-05 \n",
      "epoch: 45 [638825/888800 71.88%] train loss: 1.396900916006416e-05 \n",
      "epoch: 45 [639936/888800 72.00%] train loss: 1.5098404219315853e-05 \n",
      "epoch: 45 [641047/888800 72.12%] train loss: 1.4342965187097434e-05 \n",
      "epoch: 45 [642158/888800 72.25%] train loss: 1.3878347090212628e-05 \n",
      "epoch: 45 [643269/888800 72.38%] train loss: 1.3949398635304533e-05 \n",
      "epoch: 45 [644380/888800 72.50%] train loss: 1.300004714721581e-05 \n",
      "epoch: 45 [645491/888800 72.62%] train loss: 1.4836707123322412e-05 \n",
      "epoch: 45 [646602/888800 72.75%] train loss: 1.3569218026532326e-05 \n",
      "epoch: 45 [647713/888800 72.88%] train loss: 1.400416385877179e-05 \n",
      "epoch: 45 [648824/888800 73.00%] train loss: 1.4077605555939954e-05 \n",
      "epoch: 45 [649935/888800 73.12%] train loss: 1.3369871339818928e-05 \n",
      "epoch: 45 [651046/888800 73.25%] train loss: 1.4575130080629606e-05 \n",
      "epoch: 45 [652157/888800 73.38%] train loss: 1.3710307030123658e-05 \n",
      "epoch: 45 [653268/888800 73.50%] train loss: 1.4204500075720716e-05 \n",
      "epoch: 45 [654379/888800 73.62%] train loss: 1.52910561155295e-05 \n",
      "epoch: 45 [655490/888800 73.75%] train loss: 1.479136244597612e-05 \n",
      "epoch: 45 [656601/888800 73.88%] train loss: 1.479053662478691e-05 \n",
      "epoch: 45 [657712/888800 74.00%] train loss: 1.6457157471450046e-05 \n",
      "epoch: 45 [658823/888800 74.12%] train loss: 1.3800011402054224e-05 \n",
      "epoch: 45 [659934/888800 74.25%] train loss: 1.3782387213723268e-05 \n",
      "epoch: 45 [661045/888800 74.38%] train loss: 1.4340856068884023e-05 \n",
      "epoch: 45 [662156/888800 74.50%] train loss: 1.3307096196513157e-05 \n",
      "epoch: 45 [663267/888800 74.62%] train loss: 1.436430375179043e-05 \n",
      "epoch: 45 [664378/888800 74.75%] train loss: 1.4966778508096468e-05 \n",
      "epoch: 45 [665489/888800 74.88%] train loss: 1.4527653547702357e-05 \n",
      "epoch: 45 [666600/888800 75.00%] train loss: 1.3339599718165118e-05 \n",
      "epoch: 45 [667711/888800 75.12%] train loss: 1.3959373063698877e-05 \n",
      "epoch: 45 [668822/888800 75.25%] train loss: 1.3966256119601894e-05 \n",
      "epoch: 45 [669933/888800 75.38%] train loss: 1.4665847629657947e-05 \n",
      "epoch: 45 [671044/888800 75.50%] train loss: 1.4294502761913463e-05 \n",
      "epoch: 45 [672155/888800 75.62%] train loss: 1.4196424672263674e-05 \n",
      "epoch: 45 [673266/888800 75.75%] train loss: 1.4358246517076623e-05 \n",
      "epoch: 45 [674377/888800 75.88%] train loss: 1.3799741282127798e-05 \n",
      "epoch: 45 [675488/888800 76.00%] train loss: 1.4635176739830058e-05 \n",
      "epoch: 45 [676599/888800 76.12%] train loss: 1.3222688721725717e-05 \n",
      "epoch: 45 [677710/888800 76.25%] train loss: 1.5165194781729952e-05 \n",
      "epoch: 45 [678821/888800 76.38%] train loss: 1.482133120589424e-05 \n",
      "epoch: 45 [679932/888800 76.50%] train loss: 1.4665698472526856e-05 \n",
      "epoch: 45 [681043/888800 76.62%] train loss: 1.4560849194822367e-05 \n",
      "epoch: 45 [682154/888800 76.75%] train loss: 1.3499502529157326e-05 \n",
      "epoch: 45 [683265/888800 76.88%] train loss: 1.523579703643918e-05 \n",
      "epoch: 45 [684376/888800 77.00%] train loss: 1.4302491763373837e-05 \n",
      "epoch: 45 [685487/888800 77.12%] train loss: 1.4478222510660999e-05 \n",
      "epoch: 45 [686598/888800 77.25%] train loss: 1.4564761841029394e-05 \n",
      "epoch: 45 [687709/888800 77.38%] train loss: 1.4942168490961194e-05 \n",
      "epoch: 45 [688820/888800 77.50%] train loss: 1.482292191212764e-05 \n",
      "epoch: 45 [689931/888800 77.62%] train loss: 1.4823104720562696e-05 \n",
      "epoch: 45 [691042/888800 77.75%] train loss: 1.4252081200538669e-05 \n",
      "epoch: 45 [692153/888800 77.88%] train loss: 1.5538678781013004e-05 \n",
      "epoch: 45 [693264/888800 78.00%] train loss: 1.4560570889443625e-05 \n",
      "epoch: 45 [694375/888800 78.12%] train loss: 1.5035483556857798e-05 \n",
      "epoch: 45 [695486/888800 78.25%] train loss: 1.5702251403126866e-05 \n",
      "epoch: 45 [696597/888800 78.38%] train loss: 1.4143063708615955e-05 \n",
      "epoch: 45 [697708/888800 78.50%] train loss: 1.3999779184814543e-05 \n",
      "epoch: 45 [698819/888800 78.62%] train loss: 1.4265770005295053e-05 \n",
      "epoch: 45 [699930/888800 78.75%] train loss: 1.3595636119134724e-05 \n",
      "epoch: 45 [701041/888800 78.88%] train loss: 1.3540614418161567e-05 \n",
      "epoch: 45 [702152/888800 79.00%] train loss: 1.46010843309341e-05 \n",
      "epoch: 45 [703263/888800 79.12%] train loss: 1.4006290257384535e-05 \n",
      "epoch: 45 [704374/888800 79.25%] train loss: 1.4033317711437121e-05 \n",
      "epoch: 45 [705485/888800 79.38%] train loss: 1.4231709428713657e-05 \n",
      "epoch: 45 [706596/888800 79.50%] train loss: 1.4920814464858267e-05 \n",
      "epoch: 45 [707707/888800 79.62%] train loss: 1.383781182084931e-05 \n",
      "epoch: 45 [708818/888800 79.75%] train loss: 1.6180183592950925e-05 \n",
      "epoch: 45 [709929/888800 79.88%] train loss: 1.4350631317938678e-05 \n",
      "epoch: 45 [711040/888800 80.00%] train loss: 1.649524347158149e-05 \n",
      "epoch: 45 [712151/888800 80.12%] train loss: 1.4983956134528853e-05 \n",
      "epoch: 45 [713262/888800 80.25%] train loss: 1.5261555745382793e-05 \n",
      "epoch: 45 [714373/888800 80.38%] train loss: 1.6101936125778593e-05 \n",
      "epoch: 45 [715484/888800 80.50%] train loss: 1.381922629661858e-05 \n",
      "epoch: 45 [716595/888800 80.62%] train loss: 1.5212818652798887e-05 \n",
      "epoch: 45 [717706/888800 80.75%] train loss: 1.3312480405147653e-05 \n",
      "epoch: 45 [718817/888800 80.88%] train loss: 1.57514641614398e-05 \n",
      "epoch: 45 [719928/888800 81.00%] train loss: 1.3156251952750608e-05 \n",
      "epoch: 45 [721039/888800 81.12%] train loss: 1.4928430573490914e-05 \n",
      "epoch: 45 [722150/888800 81.25%] train loss: 1.4985909729148261e-05 \n",
      "epoch: 45 [723261/888800 81.38%] train loss: 1.3923723599873483e-05 \n",
      "epoch: 45 [724372/888800 81.50%] train loss: 1.4905996977176983e-05 \n",
      "epoch: 45 [725483/888800 81.62%] train loss: 1.4366410141519736e-05 \n",
      "epoch: 45 [726594/888800 81.75%] train loss: 1.4317449313239194e-05 \n",
      "epoch: 45 [727705/888800 81.88%] train loss: 1.4071504665480461e-05 \n",
      "epoch: 45 [728816/888800 82.00%] train loss: 1.4941731024009641e-05 \n",
      "epoch: 45 [729927/888800 82.12%] train loss: 1.5141209587454796e-05 \n",
      "epoch: 45 [731038/888800 82.25%] train loss: 1.4828613529971335e-05 \n",
      "epoch: 45 [732149/888800 82.38%] train loss: 1.434209116268903e-05 \n",
      "epoch: 45 [733260/888800 82.50%] train loss: 1.3676812159246765e-05 \n",
      "epoch: 45 [734371/888800 82.62%] train loss: 1.4260495845519472e-05 \n",
      "epoch: 45 [735482/888800 82.75%] train loss: 1.4812771041761152e-05 \n",
      "epoch: 45 [736593/888800 82.88%] train loss: 1.3098611816531047e-05 \n",
      "epoch: 45 [737704/888800 83.00%] train loss: 1.3103670426062308e-05 \n",
      "epoch: 45 [738815/888800 83.12%] train loss: 1.4311613085737918e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [739926/888800 83.25%] train loss: 1.4606526747229509e-05 \n",
      "epoch: 45 [741037/888800 83.38%] train loss: 1.6067526303231716e-05 \n",
      "epoch: 45 [742148/888800 83.50%] train loss: 1.4108548384683672e-05 \n",
      "epoch: 45 [743259/888800 83.62%] train loss: 1.4916324289515615e-05 \n",
      "epoch: 45 [744370/888800 83.75%] train loss: 1.5094082300493028e-05 \n",
      "epoch: 45 [745481/888800 83.88%] train loss: 1.4990333511377685e-05 \n",
      "epoch: 45 [746592/888800 84.00%] train loss: 1.655638698139228e-05 \n",
      "epoch: 45 [747703/888800 84.12%] train loss: 1.5239398635458201e-05 \n",
      "epoch: 45 [748814/888800 84.25%] train loss: 1.4752787137695123e-05 \n",
      "epoch: 45 [749925/888800 84.38%] train loss: 1.3766981282969937e-05 \n",
      "epoch: 45 [751036/888800 84.50%] train loss: 1.4580248716811184e-05 \n",
      "epoch: 45 [752147/888800 84.62%] train loss: 1.35884420160437e-05 \n",
      "epoch: 45 [753258/888800 84.75%] train loss: 1.465891364205163e-05 \n",
      "epoch: 45 [754369/888800 84.88%] train loss: 1.3356354429561179e-05 \n",
      "epoch: 45 [755480/888800 85.00%] train loss: 1.3346267223823816e-05 \n",
      "epoch: 45 [756591/888800 85.12%] train loss: 1.4046361684449948e-05 \n",
      "epoch: 45 [757702/888800 85.25%] train loss: 1.6403573681600392e-05 \n",
      "epoch: 45 [758813/888800 85.38%] train loss: 1.3627600310428534e-05 \n",
      "epoch: 45 [759924/888800 85.50%] train loss: 1.374891053274041e-05 \n",
      "epoch: 45 [761035/888800 85.62%] train loss: 1.3669159670826048e-05 \n",
      "epoch: 45 [762146/888800 85.75%] train loss: 1.4892654689901974e-05 \n",
      "epoch: 45 [763257/888800 85.88%] train loss: 1.3357166608329862e-05 \n",
      "epoch: 45 [764368/888800 86.00%] train loss: 1.443347991880728e-05 \n",
      "epoch: 45 [765479/888800 86.12%] train loss: 1.378230626869481e-05 \n",
      "epoch: 45 [766590/888800 86.25%] train loss: 1.5242446352203842e-05 \n",
      "epoch: 45 [767701/888800 86.38%] train loss: 1.4433356227527838e-05 \n",
      "epoch: 45 [768812/888800 86.50%] train loss: 1.476093711971771e-05 \n",
      "epoch: 45 [769923/888800 86.62%] train loss: 1.3028190551267471e-05 \n",
      "epoch: 45 [771034/888800 86.75%] train loss: 1.3874437172489706e-05 \n",
      "epoch: 45 [772145/888800 86.88%] train loss: 1.4848685168544762e-05 \n",
      "epoch: 45 [773256/888800 87.00%] train loss: 1.483942469349131e-05 \n",
      "epoch: 45 [774367/888800 87.12%] train loss: 1.3469432815327309e-05 \n",
      "epoch: 45 [775478/888800 87.25%] train loss: 1.3886368833482265e-05 \n",
      "epoch: 45 [776589/888800 87.38%] train loss: 1.3576005585491657e-05 \n",
      "epoch: 45 [777700/888800 87.50%] train loss: 1.3920102901465725e-05 \n",
      "epoch: 45 [778811/888800 87.62%] train loss: 1.3982543350721244e-05 \n",
      "epoch: 45 [779922/888800 87.75%] train loss: 1.3451284758048132e-05 \n",
      "epoch: 45 [781033/888800 87.88%] train loss: 1.490614431531867e-05 \n",
      "epoch: 45 [782144/888800 88.00%] train loss: 1.38723307827604e-05 \n",
      "epoch: 45 [783255/888800 88.12%] train loss: 1.406275805493351e-05 \n",
      "epoch: 45 [784366/888800 88.25%] train loss: 1.4384627320396248e-05 \n",
      "epoch: 45 [785477/888800 88.38%] train loss: 1.3865021173842251e-05 \n",
      "epoch: 45 [786588/888800 88.50%] train loss: 1.3247901733848266e-05 \n",
      "epoch: 45 [787699/888800 88.62%] train loss: 1.3588087313110009e-05 \n",
      "epoch: 45 [788810/888800 88.75%] train loss: 1.351562332274625e-05 \n",
      "epoch: 45 [789921/888800 88.88%] train loss: 1.627240089874249e-05 \n",
      "epoch: 45 [791032/888800 89.00%] train loss: 1.4695667232444976e-05 \n",
      "epoch: 45 [792143/888800 89.12%] train loss: 1.321375930274371e-05 \n",
      "epoch: 45 [793254/888800 89.25%] train loss: 1.3303241757967044e-05 \n",
      "epoch: 45 [794365/888800 89.38%] train loss: 1.491411603637971e-05 \n",
      "epoch: 45 [795476/888800 89.50%] train loss: 1.3329065041034482e-05 \n",
      "epoch: 45 [796587/888800 89.62%] train loss: 1.4500255019811448e-05 \n",
      "epoch: 45 [797698/888800 89.75%] train loss: 1.3398940609476995e-05 \n",
      "epoch: 45 [798809/888800 89.88%] train loss: 1.3444321666611359e-05 \n",
      "epoch: 45 [799920/888800 90.00%] train loss: 1.5019757483969443e-05 \n",
      "epoch: 45 [801031/888800 90.12%] train loss: 1.4807425941398833e-05 \n",
      "epoch: 45 [802142/888800 90.25%] train loss: 1.4674074918730184e-05 \n",
      "epoch: 45 [803253/888800 90.38%] train loss: 1.389132648910163e-05 \n",
      "epoch: 45 [804364/888800 90.50%] train loss: 1.4480423487839289e-05 \n",
      "epoch: 45 [805475/888800 90.62%] train loss: 1.4821225704508834e-05 \n",
      "epoch: 45 [806586/888800 90.75%] train loss: 1.4253822882892564e-05 \n",
      "epoch: 45 [807697/888800 90.88%] train loss: 1.4017165995028336e-05 \n",
      "epoch: 45 [808808/888800 91.00%] train loss: 1.3060634955763817e-05 \n",
      "epoch: 45 [809919/888800 91.12%] train loss: 1.3555633813666645e-05 \n",
      "epoch: 45 [811030/888800 91.25%] train loss: 1.419609907316044e-05 \n",
      "epoch: 45 [812141/888800 91.38%] train loss: 1.3999960174260195e-05 \n",
      "epoch: 45 [813252/888800 91.50%] train loss: 1.502226496086223e-05 \n",
      "epoch: 45 [814363/888800 91.62%] train loss: 1.3672578461410012e-05 \n",
      "epoch: 45 [815474/888800 91.75%] train loss: 1.4011483472131658e-05 \n",
      "epoch: 45 [816585/888800 91.88%] train loss: 1.484693530073855e-05 \n",
      "epoch: 45 [817696/888800 92.00%] train loss: 1.4173987437970936e-05 \n",
      "epoch: 45 [818807/888800 92.12%] train loss: 1.4797248695685994e-05 \n",
      "epoch: 45 [819918/888800 92.25%] train loss: 1.3597252291219775e-05 \n",
      "epoch: 45 [821029/888800 92.38%] train loss: 1.4832890883553773e-05 \n",
      "epoch: 45 [822140/888800 92.50%] train loss: 1.4836190530331805e-05 \n",
      "epoch: 45 [823251/888800 92.62%] train loss: 1.4521886441798415e-05 \n",
      "epoch: 45 [824362/888800 92.75%] train loss: 1.4221438505046535e-05 \n",
      "epoch: 45 [825473/888800 92.88%] train loss: 1.498019446444232e-05 \n",
      "epoch: 45 [826584/888800 93.00%] train loss: 1.3724985365115572e-05 \n",
      "epoch: 45 [827695/888800 93.12%] train loss: 1.3997401765664108e-05 \n",
      "epoch: 45 [828806/888800 93.25%] train loss: 1.4543324141413905e-05 \n",
      "epoch: 45 [829917/888800 93.38%] train loss: 1.4315958651422989e-05 \n",
      "epoch: 45 [831028/888800 93.50%] train loss: 1.4364738490257878e-05 \n",
      "epoch: 45 [832139/888800 93.62%] train loss: 1.526026608189568e-05 \n",
      "epoch: 45 [833250/888800 93.75%] train loss: 1.4794246453675441e-05 \n",
      "epoch: 45 [834361/888800 93.88%] train loss: 1.5499957953579724e-05 \n",
      "epoch: 45 [835472/888800 94.00%] train loss: 1.5003670341684483e-05 \n",
      "epoch: 45 [836583/888800 94.12%] train loss: 1.2417996913427487e-05 \n",
      "epoch: 45 [837694/888800 94.25%] train loss: 1.4103507055551745e-05 \n",
      "epoch: 45 [838805/888800 94.38%] train loss: 1.411427729181014e-05 \n",
      "epoch: 45 [839916/888800 94.50%] train loss: 1.4599044334318023e-05 \n",
      "epoch: 45 [841027/888800 94.62%] train loss: 1.496149070590036e-05 \n",
      "epoch: 45 [842138/888800 94.75%] train loss: 1.4750276022823527e-05 \n",
      "epoch: 45 [843249/888800 94.88%] train loss: 1.553525544295553e-05 \n",
      "epoch: 45 [844360/888800 95.00%] train loss: 1.4385633221536409e-05 \n",
      "epoch: 45 [845471/888800 95.12%] train loss: 1.5511372112086974e-05 \n",
      "epoch: 45 [846582/888800 95.25%] train loss: 1.4043319424672518e-05 \n",
      "epoch: 45 [847693/888800 95.38%] train loss: 1.582535514899064e-05 \n",
      "epoch: 45 [848804/888800 95.50%] train loss: 1.516254178568488e-05 \n",
      "epoch: 45 [849915/888800 95.62%] train loss: 1.3688776562048588e-05 \n",
      "epoch: 45 [851026/888800 95.75%] train loss: 1.5128092854865827e-05 \n",
      "epoch: 45 [852137/888800 95.88%] train loss: 1.5886440451140516e-05 \n",
      "epoch: 45 [853248/888800 96.00%] train loss: 1.3982526979816612e-05 \n",
      "epoch: 45 [854359/888800 96.12%] train loss: 1.628956124477554e-05 \n",
      "epoch: 45 [855470/888800 96.25%] train loss: 1.3760974070464727e-05 \n",
      "epoch: 45 [856581/888800 96.38%] train loss: 1.4953811842133291e-05 \n",
      "epoch: 45 [857692/888800 96.50%] train loss: 1.3523143934435211e-05 \n",
      "epoch: 45 [858803/888800 96.62%] train loss: 1.4243026271287818e-05 \n",
      "epoch: 45 [859914/888800 96.75%] train loss: 1.426196740794694e-05 \n",
      "epoch: 45 [861025/888800 96.88%] train loss: 1.3515824321075343e-05 \n",
      "epoch: 45 [862136/888800 97.00%] train loss: 1.603535929461941e-05 \n",
      "epoch: 45 [863247/888800 97.12%] train loss: 1.3630894500238355e-05 \n",
      "epoch: 45 [864358/888800 97.25%] train loss: 1.4655848644906655e-05 \n",
      "epoch: 45 [865469/888800 97.38%] train loss: 1.3642023077409249e-05 \n",
      "epoch: 45 [866580/888800 97.50%] train loss: 1.4511601875710767e-05 \n",
      "epoch: 45 [867691/888800 97.62%] train loss: 1.355650783807505e-05 \n",
      "epoch: 45 [868802/888800 97.75%] train loss: 1.4703466149512678e-05 \n",
      "epoch: 45 [869913/888800 97.88%] train loss: 1.4182789527694695e-05 \n",
      "epoch: 45 [871024/888800 98.00%] train loss: 1.453813547414029e-05 \n",
      "epoch: 45 [872135/888800 98.12%] train loss: 1.4124348126642872e-05 \n",
      "epoch: 45 [873246/888800 98.25%] train loss: 1.5143902601266745e-05 \n",
      "epoch: 45 [874357/888800 98.38%] train loss: 1.4815865142736584e-05 \n",
      "epoch: 45 [875468/888800 98.50%] train loss: 1.511922982899705e-05 \n",
      "epoch: 45 [876579/888800 98.62%] train loss: 1.4038403605809435e-05 \n",
      "epoch: 45 [877690/888800 98.75%] train loss: 1.4739250218553934e-05 \n",
      "epoch: 45 [878801/888800 98.88%] train loss: 1.4257630027714185e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 [879912/888800 99.00%] train loss: 1.4458274563367013e-05 \n",
      "epoch: 45 [881023/888800 99.12%] train loss: 1.4367959010996856e-05 \n",
      "epoch: 45 [882134/888800 99.25%] train loss: 1.3732072147831786e-05 \n",
      "epoch: 45 [883245/888800 99.38%] train loss: 1.4935175386199262e-05 \n",
      "epoch: 45 [884356/888800 99.50%] train loss: 1.4313262909126934e-05 \n",
      "epoch: 45 [885467/888800 99.62%] train loss: 1.4548778381140437e-05 \n",
      "epoch: 45 [886578/888800 99.75%] train loss: 1.3171143109502736e-05 \n",
      "epoch: 45 [887689/888800 99.88%] train loss: 1.4587037185265217e-05 \n",
      "epoch: 46 [0/888800 0.00%] train loss: 1.460235671402188e-05 \n",
      "epoch: 46 [1111/888800 0.12%] train loss: 1.3119544746587053e-05 \n",
      "epoch: 46 [2222/888800 0.25%] train loss: 1.445013185730204e-05 \n",
      "epoch: 46 [3333/888800 0.38%] train loss: 1.4701086001878139e-05 \n",
      "epoch: 46 [4444/888800 0.50%] train loss: 1.3435186701826751e-05 \n",
      "epoch: 46 [5555/888800 0.62%] train loss: 1.329684255324537e-05 \n",
      "epoch: 46 [6666/888800 0.75%] train loss: 1.4492732589133084e-05 \n",
      "epoch: 46 [7777/888800 0.88%] train loss: 1.3539278370444663e-05 \n",
      "epoch: 46 [8888/888800 1.00%] train loss: 1.3963928722660057e-05 \n",
      "epoch: 46 [9999/888800 1.12%] train loss: 1.4011034181748983e-05 \n",
      "epoch: 46 [11110/888800 1.25%] train loss: 1.3687143109564204e-05 \n",
      "epoch: 46 [12221/888800 1.38%] train loss: 1.4319168258225545e-05 \n",
      "epoch: 46 [13332/888800 1.50%] train loss: 1.4222156096366234e-05 \n",
      "epoch: 46 [14443/888800 1.62%] train loss: 1.4140779967419803e-05 \n",
      "epoch: 46 [15554/888800 1.75%] train loss: 1.355977110506501e-05 \n",
      "epoch: 46 [16665/888800 1.88%] train loss: 1.2870980754087213e-05 \n",
      "epoch: 46 [17776/888800 2.00%] train loss: 1.4873081454425119e-05 \n",
      "epoch: 46 [18887/888800 2.12%] train loss: 1.4103870853432454e-05 \n",
      "epoch: 46 [19998/888800 2.25%] train loss: 1.4625897165387869e-05 \n",
      "epoch: 46 [21109/888800 2.38%] train loss: 1.3979202776681632e-05 \n",
      "epoch: 46 [22220/888800 2.50%] train loss: 1.4462413673754781e-05 \n",
      "epoch: 46 [23331/888800 2.62%] train loss: 1.4417430065805092e-05 \n",
      "epoch: 46 [24442/888800 2.75%] train loss: 1.4328980796562973e-05 \n",
      "epoch: 46 [25553/888800 2.88%] train loss: 1.616663757886272e-05 \n",
      "epoch: 46 [26664/888800 3.00%] train loss: 1.4523770914820489e-05 \n",
      "epoch: 46 [27775/888800 3.12%] train loss: 1.5148197235248517e-05 \n",
      "epoch: 46 [28886/888800 3.25%] train loss: 1.4544955774908885e-05 \n",
      "epoch: 46 [29997/888800 3.38%] train loss: 1.3721590221393853e-05 \n",
      "epoch: 46 [31108/888800 3.50%] train loss: 1.4425058907363564e-05 \n",
      "epoch: 46 [32219/888800 3.62%] train loss: 1.5392994100693613e-05 \n",
      "epoch: 46 [33330/888800 3.75%] train loss: 1.4584307791665196e-05 \n",
      "epoch: 46 [34441/888800 3.88%] train loss: 1.5680403521400876e-05 \n",
      "epoch: 46 [35552/888800 4.00%] train loss: 1.4538301002176013e-05 \n",
      "epoch: 46 [36663/888800 4.12%] train loss: 1.4487196494883392e-05 \n",
      "epoch: 46 [37774/888800 4.25%] train loss: 1.3982376003696118e-05 \n",
      "epoch: 46 [38885/888800 4.38%] train loss: 1.593303750269115e-05 \n",
      "epoch: 46 [39996/888800 4.50%] train loss: 1.5187610188149847e-05 \n",
      "epoch: 46 [41107/888800 4.62%] train loss: 1.3378396943153348e-05 \n",
      "epoch: 46 [42218/888800 4.75%] train loss: 1.4769970221095718e-05 \n",
      "epoch: 46 [43329/888800 4.88%] train loss: 1.346279532299377e-05 \n",
      "epoch: 46 [44440/888800 5.00%] train loss: 1.3496182873495854e-05 \n",
      "epoch: 46 [45551/888800 5.12%] train loss: 1.3133518223185092e-05 \n",
      "epoch: 46 [46662/888800 5.25%] train loss: 1.4378938431036659e-05 \n",
      "epoch: 46 [47773/888800 5.38%] train loss: 1.3511625184037257e-05 \n",
      "epoch: 46 [48884/888800 5.50%] train loss: 1.3280571693030652e-05 \n",
      "epoch: 46 [49995/888800 5.62%] train loss: 1.4050345271243714e-05 \n",
      "epoch: 46 [51106/888800 5.75%] train loss: 1.3726696124649607e-05 \n",
      "epoch: 46 [52217/888800 5.88%] train loss: 1.4583046322513837e-05 \n",
      "epoch: 46 [53328/888800 6.00%] train loss: 1.4655703125754371e-05 \n",
      "epoch: 46 [54439/888800 6.12%] train loss: 1.4638523680332582e-05 \n",
      "epoch: 46 [55550/888800 6.25%] train loss: 1.462628279114142e-05 \n",
      "epoch: 46 [56661/888800 6.38%] train loss: 1.494567550253123e-05 \n",
      "epoch: 46 [57772/888800 6.50%] train loss: 1.3998063877806999e-05 \n",
      "epoch: 46 [58883/888800 6.62%] train loss: 1.3092283552396111e-05 \n",
      "epoch: 46 [59994/888800 6.75%] train loss: 1.4196343727235217e-05 \n",
      "epoch: 46 [61105/888800 6.88%] train loss: 1.4202151760400739e-05 \n",
      "epoch: 46 [62216/888800 7.00%] train loss: 1.3663126082974486e-05 \n",
      "epoch: 46 [63327/888800 7.12%] train loss: 1.3806263268634211e-05 \n",
      "epoch: 46 [64438/888800 7.25%] train loss: 1.476844226999674e-05 \n",
      "epoch: 46 [65549/888800 7.38%] train loss: 1.380716003041016e-05 \n",
      "epoch: 46 [66660/888800 7.50%] train loss: 1.6748037523939274e-05 \n",
      "epoch: 46 [67771/888800 7.62%] train loss: 1.3479027984431013e-05 \n",
      "epoch: 46 [68882/888800 7.75%] train loss: 1.4759971236344427e-05 \n",
      "epoch: 46 [69993/888800 7.88%] train loss: 1.5270179574145004e-05 \n",
      "epoch: 46 [71104/888800 8.00%] train loss: 1.346584758721292e-05 \n",
      "epoch: 46 [72215/888800 8.12%] train loss: 1.503386374679394e-05 \n",
      "epoch: 46 [73326/888800 8.25%] train loss: 1.518760109320283e-05 \n",
      "epoch: 46 [74437/888800 8.38%] train loss: 1.432357203157153e-05 \n",
      "epoch: 46 [75548/888800 8.50%] train loss: 1.3724833479500376e-05 \n",
      "epoch: 46 [76659/888800 8.62%] train loss: 1.6123989553307183e-05 \n",
      "epoch: 46 [77770/888800 8.75%] train loss: 1.4182187442202121e-05 \n",
      "epoch: 46 [78881/888800 8.88%] train loss: 1.4825532161921728e-05 \n",
      "epoch: 46 [79992/888800 9.00%] train loss: 1.3953422239865176e-05 \n",
      "epoch: 46 [81103/888800 9.12%] train loss: 1.5113707377167884e-05 \n",
      "epoch: 46 [82214/888800 9.25%] train loss: 1.4333556464407593e-05 \n",
      "epoch: 46 [83325/888800 9.38%] train loss: 1.4318168723548297e-05 \n",
      "epoch: 46 [84436/888800 9.50%] train loss: 1.4976565580582246e-05 \n",
      "epoch: 46 [85547/888800 9.62%] train loss: 1.4066800758882891e-05 \n",
      "epoch: 46 [86658/888800 9.75%] train loss: 1.4000304872752167e-05 \n",
      "epoch: 46 [87769/888800 9.88%] train loss: 1.4828058738203254e-05 \n",
      "epoch: 46 [88880/888800 10.00%] train loss: 1.512729431851767e-05 \n",
      "epoch: 46 [89991/888800 10.12%] train loss: 1.480149421695387e-05 \n",
      "epoch: 46 [91102/888800 10.25%] train loss: 1.401736335537862e-05 \n",
      "epoch: 46 [92213/888800 10.38%] train loss: 1.4329431905935053e-05 \n",
      "epoch: 46 [93324/888800 10.50%] train loss: 1.4000673218106385e-05 \n",
      "epoch: 46 [94435/888800 10.62%] train loss: 1.2556312867673114e-05 \n",
      "epoch: 46 [95546/888800 10.75%] train loss: 1.3923987353336997e-05 \n",
      "epoch: 46 [96657/888800 10.88%] train loss: 1.4251653738028836e-05 \n",
      "epoch: 46 [97768/888800 11.00%] train loss: 1.4377686056832317e-05 \n",
      "epoch: 46 [98879/888800 11.12%] train loss: 1.5284538676496595e-05 \n",
      "epoch: 46 [99990/888800 11.25%] train loss: 1.3487832802638877e-05 \n",
      "epoch: 46 [101101/888800 11.38%] train loss: 1.4023010407981928e-05 \n",
      "epoch: 46 [102212/888800 11.50%] train loss: 1.4541888958774507e-05 \n",
      "epoch: 46 [103323/888800 11.62%] train loss: 1.3910827874497045e-05 \n",
      "epoch: 46 [104434/888800 11.75%] train loss: 1.5096816241566557e-05 \n",
      "epoch: 46 [105545/888800 11.88%] train loss: 1.4307480341813061e-05 \n",
      "epoch: 46 [106656/888800 12.00%] train loss: 1.4777144315303303e-05 \n",
      "epoch: 46 [107767/888800 12.12%] train loss: 1.4116092643234879e-05 \n",
      "epoch: 46 [108878/888800 12.25%] train loss: 1.4334515071823262e-05 \n",
      "epoch: 46 [109989/888800 12.38%] train loss: 1.3964106074126903e-05 \n",
      "epoch: 46 [111100/888800 12.50%] train loss: 1.3279743143357337e-05 \n",
      "epoch: 46 [112211/888800 12.62%] train loss: 1.324084496445721e-05 \n",
      "epoch: 46 [113322/888800 12.75%] train loss: 1.4677835679322015e-05 \n",
      "epoch: 46 [114433/888800 12.88%] train loss: 1.3268024304124992e-05 \n",
      "epoch: 46 [115544/888800 13.00%] train loss: 1.486943438067101e-05 \n",
      "epoch: 46 [116655/888800 13.12%] train loss: 1.3417096852208488e-05 \n",
      "epoch: 46 [117766/888800 13.25%] train loss: 1.48889230331406e-05 \n",
      "epoch: 46 [118877/888800 13.38%] train loss: 1.3782452697341796e-05 \n",
      "epoch: 46 [119988/888800 13.50%] train loss: 1.3465015399560798e-05 \n",
      "epoch: 46 [121099/888800 13.62%] train loss: 1.5068832908582408e-05 \n",
      "epoch: 46 [122210/888800 13.75%] train loss: 1.3495987332134973e-05 \n",
      "epoch: 46 [123321/888800 13.88%] train loss: 1.4630284567829221e-05 \n",
      "epoch: 46 [124432/888800 14.00%] train loss: 1.4353302503877785e-05 \n",
      "epoch: 46 [125543/888800 14.12%] train loss: 1.2450416761566885e-05 \n",
      "epoch: 46 [126654/888800 14.25%] train loss: 1.417370185663458e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [127765/888800 14.38%] train loss: 1.3635989489557687e-05 \n",
      "epoch: 46 [128876/888800 14.50%] train loss: 1.3636609764944296e-05 \n",
      "epoch: 46 [129987/888800 14.62%] train loss: 1.4410040421353187e-05 \n",
      "epoch: 46 [131098/888800 14.75%] train loss: 1.3286354260344524e-05 \n",
      "epoch: 46 [132209/888800 14.88%] train loss: 1.3657602721650619e-05 \n",
      "epoch: 46 [133320/888800 15.00%] train loss: 1.6430871255579405e-05 \n",
      "epoch: 46 [134431/888800 15.12%] train loss: 1.3941556971985847e-05 \n",
      "epoch: 46 [135542/888800 15.25%] train loss: 1.4046268915990368e-05 \n",
      "epoch: 46 [136653/888800 15.38%] train loss: 1.4972775716159958e-05 \n",
      "epoch: 46 [137764/888800 15.50%] train loss: 1.58244638441829e-05 \n",
      "epoch: 46 [138875/888800 15.62%] train loss: 1.3261758795124479e-05 \n",
      "epoch: 46 [139986/888800 15.75%] train loss: 1.5164238902798388e-05 \n",
      "epoch: 46 [141097/888800 15.88%] train loss: 1.3590110938821454e-05 \n",
      "epoch: 46 [142208/888800 16.00%] train loss: 1.475439694331726e-05 \n",
      "epoch: 46 [143319/888800 16.12%] train loss: 1.3843470696883742e-05 \n",
      "epoch: 46 [144430/888800 16.25%] train loss: 1.3077694347884972e-05 \n",
      "epoch: 46 [145541/888800 16.38%] train loss: 1.4153764823277015e-05 \n",
      "epoch: 46 [146652/888800 16.50%] train loss: 1.4785400708205998e-05 \n",
      "epoch: 46 [147763/888800 16.62%] train loss: 1.5607287423335947e-05 \n",
      "epoch: 46 [148874/888800 16.75%] train loss: 1.3414939530775882e-05 \n",
      "epoch: 46 [149985/888800 16.88%] train loss: 1.3831990145263262e-05 \n",
      "epoch: 46 [151096/888800 17.00%] train loss: 1.3486788702721242e-05 \n",
      "epoch: 46 [152207/888800 17.12%] train loss: 1.4314244253910147e-05 \n",
      "epoch: 46 [153318/888800 17.25%] train loss: 1.4340771485876758e-05 \n",
      "epoch: 46 [154429/888800 17.38%] train loss: 1.3911822861700784e-05 \n",
      "epoch: 46 [155540/888800 17.50%] train loss: 1.4205932529876009e-05 \n",
      "epoch: 46 [156651/888800 17.62%] train loss: 1.4462244507740252e-05 \n",
      "epoch: 46 [157762/888800 17.75%] train loss: 1.5879806596785784e-05 \n",
      "epoch: 46 [158873/888800 17.88%] train loss: 1.4594514141208492e-05 \n",
      "epoch: 46 [159984/888800 18.00%] train loss: 1.372680071654031e-05 \n",
      "epoch: 46 [161095/888800 18.12%] train loss: 1.385584801028017e-05 \n",
      "epoch: 46 [162206/888800 18.25%] train loss: 1.4114538316789549e-05 \n",
      "epoch: 46 [163317/888800 18.38%] train loss: 1.3928066437074449e-05 \n",
      "epoch: 46 [164428/888800 18.50%] train loss: 1.3353950635064393e-05 \n",
      "epoch: 46 [165539/888800 18.62%] train loss: 1.3654773283633403e-05 \n",
      "epoch: 46 [166650/888800 18.75%] train loss: 1.3967702216177713e-05 \n",
      "epoch: 46 [167761/888800 18.88%] train loss: 1.4560575436917134e-05 \n",
      "epoch: 46 [168872/888800 19.00%] train loss: 1.334181160927983e-05 \n",
      "epoch: 46 [169983/888800 19.12%] train loss: 1.3787462194159161e-05 \n",
      "epoch: 46 [171094/888800 19.25%] train loss: 1.4325939446280245e-05 \n",
      "epoch: 46 [172205/888800 19.38%] train loss: 1.4261140677263029e-05 \n",
      "epoch: 46 [173316/888800 19.50%] train loss: 1.4654531696578488e-05 \n",
      "epoch: 46 [174427/888800 19.62%] train loss: 1.3833561752107926e-05 \n",
      "epoch: 46 [175538/888800 19.75%] train loss: 1.3623994163936004e-05 \n",
      "epoch: 46 [176649/888800 19.88%] train loss: 1.4332606951938942e-05 \n",
      "epoch: 46 [177760/888800 20.00%] train loss: 1.4154333257465623e-05 \n",
      "epoch: 46 [178871/888800 20.12%] train loss: 1.3879208381695207e-05 \n",
      "epoch: 46 [179982/888800 20.25%] train loss: 1.46447400766192e-05 \n",
      "epoch: 46 [181093/888800 20.38%] train loss: 1.4511313565890305e-05 \n",
      "epoch: 46 [182204/888800 20.50%] train loss: 1.3980806215840857e-05 \n",
      "epoch: 46 [183315/888800 20.62%] train loss: 1.4509446373267565e-05 \n",
      "epoch: 46 [184426/888800 20.75%] train loss: 1.3129560102242976e-05 \n",
      "epoch: 46 [185537/888800 20.88%] train loss: 1.422809418727411e-05 \n",
      "epoch: 46 [186648/888800 21.00%] train loss: 1.4097601706453133e-05 \n",
      "epoch: 46 [187759/888800 21.12%] train loss: 1.4198533790477086e-05 \n",
      "epoch: 46 [188870/888800 21.25%] train loss: 1.4677321814815514e-05 \n",
      "epoch: 46 [189981/888800 21.38%] train loss: 1.3749277059105225e-05 \n",
      "epoch: 46 [191092/888800 21.50%] train loss: 1.4753516552445944e-05 \n",
      "epoch: 46 [192203/888800 21.62%] train loss: 1.548737236589659e-05 \n",
      "epoch: 46 [193314/888800 21.75%] train loss: 1.3618139746540692e-05 \n",
      "epoch: 46 [194425/888800 21.88%] train loss: 1.4046528121980373e-05 \n",
      "epoch: 46 [195536/888800 22.00%] train loss: 1.5508778233197518e-05 \n",
      "epoch: 46 [196647/888800 22.12%] train loss: 1.3537238373828586e-05 \n",
      "epoch: 46 [197758/888800 22.25%] train loss: 1.4733736861671787e-05 \n",
      "epoch: 46 [198869/888800 22.38%] train loss: 1.4084803297009785e-05 \n",
      "epoch: 46 [199980/888800 22.50%] train loss: 1.4358643966261297e-05 \n",
      "epoch: 46 [201091/888800 22.62%] train loss: 1.4764223124075215e-05 \n",
      "epoch: 46 [202202/888800 22.75%] train loss: 1.3906445929023903e-05 \n",
      "epoch: 46 [203313/888800 22.88%] train loss: 1.488518864789512e-05 \n",
      "epoch: 46 [204424/888800 23.00%] train loss: 1.4267411643231753e-05 \n",
      "epoch: 46 [205535/888800 23.12%] train loss: 1.4285432371252682e-05 \n",
      "epoch: 46 [206646/888800 23.25%] train loss: 1.441583299310878e-05 \n",
      "epoch: 46 [207757/888800 23.38%] train loss: 1.4134542652755044e-05 \n",
      "epoch: 46 [208868/888800 23.50%] train loss: 1.2305704331083689e-05 \n",
      "epoch: 46 [209979/888800 23.62%] train loss: 1.4182837730913889e-05 \n",
      "epoch: 46 [211090/888800 23.75%] train loss: 1.473011707275873e-05 \n",
      "epoch: 46 [212201/888800 23.88%] train loss: 1.4955487131373957e-05 \n",
      "epoch: 46 [213312/888800 24.00%] train loss: 1.3429056707536802e-05 \n",
      "epoch: 46 [214423/888800 24.12%] train loss: 1.4337791071739048e-05 \n",
      "epoch: 46 [215534/888800 24.25%] train loss: 1.3148484867997468e-05 \n",
      "epoch: 46 [216645/888800 24.38%] train loss: 1.4388469935511239e-05 \n",
      "epoch: 46 [217756/888800 24.50%] train loss: 1.4683114386571106e-05 \n",
      "epoch: 46 [218867/888800 24.62%] train loss: 1.3826748727296945e-05 \n",
      "epoch: 46 [219978/888800 24.75%] train loss: 1.4556349015037995e-05 \n",
      "epoch: 46 [221089/888800 24.88%] train loss: 1.3118816241330933e-05 \n",
      "epoch: 46 [222200/888800 25.00%] train loss: 1.3858073543815408e-05 \n",
      "epoch: 46 [223311/888800 25.12%] train loss: 1.3334622963157017e-05 \n",
      "epoch: 46 [224422/888800 25.25%] train loss: 1.4485764950222801e-05 \n",
      "epoch: 46 [225533/888800 25.38%] train loss: 1.475586850574473e-05 \n",
      "epoch: 46 [226644/888800 25.50%] train loss: 1.546039857203141e-05 \n",
      "epoch: 46 [227755/888800 25.62%] train loss: 1.5231888937705662e-05 \n",
      "epoch: 46 [228866/888800 25.75%] train loss: 1.2912651982333045e-05 \n",
      "epoch: 46 [229977/888800 25.88%] train loss: 1.41656582854921e-05 \n",
      "epoch: 46 [231088/888800 26.00%] train loss: 1.483167852711631e-05 \n",
      "epoch: 46 [232199/888800 26.12%] train loss: 1.3740177564613987e-05 \n",
      "epoch: 46 [233310/888800 26.25%] train loss: 1.3517133083951194e-05 \n",
      "epoch: 46 [234421/888800 26.38%] train loss: 1.4315020052890759e-05 \n",
      "epoch: 46 [235532/888800 26.50%] train loss: 1.3940733879280742e-05 \n",
      "epoch: 46 [236643/888800 26.62%] train loss: 1.4805294995312579e-05 \n",
      "epoch: 46 [237754/888800 26.75%] train loss: 1.347365014225943e-05 \n",
      "epoch: 46 [238865/888800 26.88%] train loss: 1.4321671187644824e-05 \n",
      "epoch: 46 [239976/888800 27.00%] train loss: 1.438551589671988e-05 \n",
      "epoch: 46 [241087/888800 27.12%] train loss: 1.4539409676217474e-05 \n",
      "epoch: 46 [242198/888800 27.25%] train loss: 1.3949029380455613e-05 \n",
      "epoch: 46 [243309/888800 27.38%] train loss: 1.1975953384535387e-05 \n",
      "epoch: 46 [244420/888800 27.50%] train loss: 1.3823850167682394e-05 \n",
      "epoch: 46 [245531/888800 27.62%] train loss: 1.4187669876264408e-05 \n",
      "epoch: 46 [246642/888800 27.75%] train loss: 1.470293318561744e-05 \n",
      "epoch: 46 [247753/888800 27.88%] train loss: 1.4610443031415343e-05 \n",
      "epoch: 46 [248864/888800 28.00%] train loss: 1.4926551557437051e-05 \n",
      "epoch: 46 [249975/888800 28.12%] train loss: 1.4403488421521615e-05 \n",
      "epoch: 46 [251086/888800 28.25%] train loss: 1.344623069599038e-05 \n",
      "epoch: 46 [252197/888800 28.38%] train loss: 1.5147446902119555e-05 \n",
      "epoch: 46 [253308/888800 28.50%] train loss: 1.3878688150725793e-05 \n",
      "epoch: 46 [254419/888800 28.62%] train loss: 1.5431791325681843e-05 \n",
      "epoch: 46 [255530/888800 28.75%] train loss: 1.4345828276418615e-05 \n",
      "epoch: 46 [256641/888800 28.88%] train loss: 1.68821970873978e-05 \n",
      "epoch: 46 [257752/888800 29.00%] train loss: 1.398245422024047e-05 \n",
      "epoch: 46 [258863/888800 29.12%] train loss: 1.5475730833713897e-05 \n",
      "epoch: 46 [259974/888800 29.25%] train loss: 1.4879326045047492e-05 \n",
      "epoch: 46 [261085/888800 29.38%] train loss: 1.6447424059151672e-05 \n",
      "epoch: 46 [262196/888800 29.50%] train loss: 1.7719201423460618e-05 \n",
      "epoch: 46 [263307/888800 29.62%] train loss: 1.3719766684516799e-05 \n",
      "epoch: 46 [264418/888800 29.75%] train loss: 1.6871494153747335e-05 \n",
      "epoch: 46 [265529/888800 29.88%] train loss: 1.556532697577495e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [266640/888800 30.00%] train loss: 1.4264297533372883e-05 \n",
      "epoch: 46 [267751/888800 30.12%] train loss: 1.4052727237867657e-05 \n",
      "epoch: 46 [268862/888800 30.25%] train loss: 1.4100663065619301e-05 \n",
      "epoch: 46 [269973/888800 30.38%] train loss: 1.5226556570269167e-05 \n",
      "epoch: 46 [271084/888800 30.50%] train loss: 1.334959870291641e-05 \n",
      "epoch: 46 [272195/888800 30.62%] train loss: 1.4260666830523405e-05 \n",
      "epoch: 46 [273306/888800 30.75%] train loss: 1.5342649930971675e-05 \n",
      "epoch: 46 [274417/888800 30.88%] train loss: 1.500523376307683e-05 \n",
      "epoch: 46 [275528/888800 31.00%] train loss: 1.4602191185986158e-05 \n",
      "epoch: 46 [276639/888800 31.12%] train loss: 1.3880911865271628e-05 \n",
      "epoch: 46 [277750/888800 31.25%] train loss: 1.4961096894694492e-05 \n",
      "epoch: 46 [278861/888800 31.38%] train loss: 1.4150758943287656e-05 \n",
      "epoch: 46 [279972/888800 31.50%] train loss: 1.58587827172596e-05 \n",
      "epoch: 46 [281083/888800 31.62%] train loss: 1.4320180525828619e-05 \n",
      "epoch: 46 [282194/888800 31.75%] train loss: 1.5464258467545733e-05 \n",
      "epoch: 46 [283305/888800 31.88%] train loss: 1.4284613826021086e-05 \n",
      "epoch: 46 [284416/888800 32.00%] train loss: 1.3733316336583812e-05 \n",
      "epoch: 46 [285527/888800 32.12%] train loss: 1.4202622878656257e-05 \n",
      "epoch: 46 [286638/888800 32.25%] train loss: 1.4453756193688605e-05 \n",
      "epoch: 46 [287749/888800 32.38%] train loss: 1.4156617908156477e-05 \n",
      "epoch: 46 [288860/888800 32.50%] train loss: 1.4025485143065453e-05 \n",
      "epoch: 46 [289971/888800 32.62%] train loss: 1.4430072042159736e-05 \n",
      "epoch: 46 [291082/888800 32.75%] train loss: 1.4178919627738651e-05 \n",
      "epoch: 46 [292193/888800 32.88%] train loss: 1.4668433323095087e-05 \n",
      "epoch: 46 [293304/888800 33.00%] train loss: 1.4617040505982004e-05 \n",
      "epoch: 46 [294415/888800 33.12%] train loss: 1.4181362530507613e-05 \n",
      "epoch: 46 [295526/888800 33.25%] train loss: 1.5032143892312888e-05 \n",
      "epoch: 46 [296637/888800 33.38%] train loss: 1.3549180039262865e-05 \n",
      "epoch: 46 [297748/888800 33.50%] train loss: 1.5181656635832042e-05 \n",
      "epoch: 46 [298859/888800 33.62%] train loss: 1.4916522559360601e-05 \n",
      "epoch: 46 [299970/888800 33.75%] train loss: 1.432382850907743e-05 \n",
      "epoch: 46 [301081/888800 33.88%] train loss: 1.3831547221343499e-05 \n",
      "epoch: 46 [302192/888800 34.00%] train loss: 1.4702577573189046e-05 \n",
      "epoch: 46 [303303/888800 34.12%] train loss: 1.4177529919834342e-05 \n",
      "epoch: 46 [304414/888800 34.25%] train loss: 1.4157806617731694e-05 \n",
      "epoch: 46 [305525/888800 34.38%] train loss: 1.4607228877139278e-05 \n",
      "epoch: 46 [306636/888800 34.50%] train loss: 1.3518319065042306e-05 \n",
      "epoch: 46 [307747/888800 34.62%] train loss: 1.3110522559145465e-05 \n",
      "epoch: 46 [308858/888800 34.75%] train loss: 1.3759698049398139e-05 \n",
      "epoch: 46 [309969/888800 34.88%] train loss: 1.4158457815938164e-05 \n",
      "epoch: 46 [311080/888800 35.00%] train loss: 1.4631210433435626e-05 \n",
      "epoch: 46 [312191/888800 35.12%] train loss: 1.586289727129042e-05 \n",
      "epoch: 46 [313302/888800 35.25%] train loss: 1.4472689144895412e-05 \n",
      "epoch: 46 [314413/888800 35.38%] train loss: 1.414335838489933e-05 \n",
      "epoch: 46 [315524/888800 35.50%] train loss: 1.529610926809255e-05 \n",
      "epoch: 46 [316635/888800 35.62%] train loss: 1.520194473414449e-05 \n",
      "epoch: 46 [317746/888800 35.75%] train loss: 1.5609106412739493e-05 \n",
      "epoch: 46 [318857/888800 35.88%] train loss: 1.3010673683311325e-05 \n",
      "epoch: 46 [319968/888800 36.00%] train loss: 1.3542706255975645e-05 \n",
      "epoch: 46 [321079/888800 36.12%] train loss: 1.3051379028183874e-05 \n",
      "epoch: 46 [322190/888800 36.25%] train loss: 1.4553696928487625e-05 \n",
      "epoch: 46 [323301/888800 36.38%] train loss: 1.3677383321919478e-05 \n",
      "epoch: 46 [324412/888800 36.50%] train loss: 1.3256082638690714e-05 \n",
      "epoch: 46 [325523/888800 36.62%] train loss: 1.4967519746278413e-05 \n",
      "epoch: 46 [326634/888800 36.75%] train loss: 1.4856709640298504e-05 \n",
      "epoch: 46 [327745/888800 36.88%] train loss: 1.3942758414486889e-05 \n",
      "epoch: 46 [328856/888800 37.00%] train loss: 1.4668697986053303e-05 \n",
      "epoch: 46 [329967/888800 37.12%] train loss: 1.3796260645904113e-05 \n",
      "epoch: 46 [331078/888800 37.25%] train loss: 1.5413823348353617e-05 \n",
      "epoch: 46 [332189/888800 37.38%] train loss: 1.4507544619846158e-05 \n",
      "epoch: 46 [333300/888800 37.50%] train loss: 1.6020314433262683e-05 \n",
      "epoch: 46 [334411/888800 37.62%] train loss: 1.3879071957489941e-05 \n",
      "epoch: 46 [335522/888800 37.75%] train loss: 1.410874756402336e-05 \n",
      "epoch: 46 [336633/888800 37.88%] train loss: 1.3242784916656092e-05 \n",
      "epoch: 46 [337744/888800 38.00%] train loss: 1.3033999493927695e-05 \n",
      "epoch: 46 [338855/888800 38.12%] train loss: 1.4452481991611421e-05 \n",
      "epoch: 46 [339966/888800 38.25%] train loss: 1.532566784590017e-05 \n",
      "epoch: 46 [341077/888800 38.38%] train loss: 1.4364830349222757e-05 \n",
      "epoch: 46 [342188/888800 38.50%] train loss: 1.536439776828047e-05 \n",
      "epoch: 46 [343299/888800 38.62%] train loss: 1.4529697182297241e-05 \n",
      "epoch: 46 [344410/888800 38.75%] train loss: 1.611653897271026e-05 \n",
      "epoch: 46 [345521/888800 38.88%] train loss: 1.3027125532971695e-05 \n",
      "epoch: 46 [346632/888800 39.00%] train loss: 1.4238691619539168e-05 \n",
      "epoch: 46 [347743/888800 39.12%] train loss: 1.3210882571002003e-05 \n",
      "epoch: 46 [348854/888800 39.25%] train loss: 1.4573865882994141e-05 \n",
      "epoch: 46 [349965/888800 39.38%] train loss: 1.3859073987987358e-05 \n",
      "epoch: 46 [351076/888800 39.50%] train loss: 1.4072289559408091e-05 \n",
      "epoch: 46 [352187/888800 39.62%] train loss: 1.4861663657939062e-05 \n",
      "epoch: 46 [353298/888800 39.75%] train loss: 1.4348517652251758e-05 \n",
      "epoch: 46 [354409/888800 39.88%] train loss: 1.3982851669425145e-05 \n",
      "epoch: 46 [355520/888800 40.00%] train loss: 1.3928551197750494e-05 \n",
      "epoch: 46 [356631/888800 40.12%] train loss: 1.5042306586110499e-05 \n",
      "epoch: 46 [357742/888800 40.25%] train loss: 1.327301470155362e-05 \n",
      "epoch: 46 [358853/888800 40.38%] train loss: 1.5055353287607431e-05 \n",
      "epoch: 46 [359964/888800 40.50%] train loss: 1.3944075362815056e-05 \n",
      "epoch: 46 [361075/888800 40.62%] train loss: 1.4814943824603688e-05 \n",
      "epoch: 46 [362186/888800 40.75%] train loss: 1.5626195818185806e-05 \n",
      "epoch: 46 [363297/888800 40.88%] train loss: 1.405081002303632e-05 \n",
      "epoch: 46 [364408/888800 41.00%] train loss: 1.459904797229683e-05 \n",
      "epoch: 46 [365519/888800 41.12%] train loss: 1.509418598288903e-05 \n",
      "epoch: 46 [366630/888800 41.25%] train loss: 1.3397117982094642e-05 \n",
      "epoch: 46 [367741/888800 41.38%] train loss: 1.3495178791345097e-05 \n",
      "epoch: 46 [368852/888800 41.50%] train loss: 1.3754675819654949e-05 \n",
      "epoch: 46 [369963/888800 41.62%] train loss: 1.3701818716072012e-05 \n",
      "epoch: 46 [371074/888800 41.75%] train loss: 1.4714854842168279e-05 \n",
      "epoch: 46 [372185/888800 41.88%] train loss: 1.4878315596433822e-05 \n",
      "epoch: 46 [373296/888800 42.00%] train loss: 1.371703820041148e-05 \n",
      "epoch: 46 [374407/888800 42.12%] train loss: 1.3750598554906901e-05 \n",
      "epoch: 46 [375518/888800 42.25%] train loss: 1.3926033716415986e-05 \n",
      "epoch: 46 [376629/888800 42.38%] train loss: 1.5501342204515822e-05 \n",
      "epoch: 46 [377740/888800 42.50%] train loss: 1.3537460290535819e-05 \n",
      "epoch: 46 [378851/888800 42.62%] train loss: 1.3521461369236931e-05 \n",
      "epoch: 46 [379962/888800 42.75%] train loss: 1.4512555935652927e-05 \n",
      "epoch: 46 [381073/888800 42.88%] train loss: 1.4237387404136825e-05 \n",
      "epoch: 46 [382184/888800 43.00%] train loss: 1.3271612260723487e-05 \n",
      "epoch: 46 [383295/888800 43.12%] train loss: 1.4927601114322897e-05 \n",
      "epoch: 46 [384406/888800 43.25%] train loss: 1.3824986126564909e-05 \n",
      "epoch: 46 [385517/888800 43.38%] train loss: 1.3713861335418187e-05 \n",
      "epoch: 46 [386628/888800 43.50%] train loss: 1.4711617950524669e-05 \n",
      "epoch: 46 [387739/888800 43.62%] train loss: 1.4272400221670978e-05 \n",
      "epoch: 46 [388850/888800 43.75%] train loss: 1.4172687770042103e-05 \n",
      "epoch: 46 [389961/888800 43.88%] train loss: 1.393898310197983e-05 \n",
      "epoch: 46 [391072/888800 44.00%] train loss: 1.3685431440535467e-05 \n",
      "epoch: 46 [392183/888800 44.12%] train loss: 1.527602034911979e-05 \n",
      "epoch: 46 [393294/888800 44.25%] train loss: 1.3590944035968278e-05 \n",
      "epoch: 46 [394405/888800 44.38%] train loss: 1.4034698324394412e-05 \n",
      "epoch: 46 [395516/888800 44.50%] train loss: 1.46573593156063e-05 \n",
      "epoch: 46 [396627/888800 44.62%] train loss: 1.4299981557996944e-05 \n",
      "epoch: 46 [397738/888800 44.75%] train loss: 1.493514901085291e-05 \n",
      "epoch: 46 [398849/888800 44.88%] train loss: 1.3946966646471992e-05 \n",
      "epoch: 46 [399960/888800 45.00%] train loss: 1.3408964150585234e-05 \n",
      "epoch: 46 [401071/888800 45.12%] train loss: 1.5164869182626717e-05 \n",
      "epoch: 46 [402182/888800 45.25%] train loss: 1.5559333405690268e-05 \n",
      "epoch: 46 [403293/888800 45.38%] train loss: 1.4999229279055726e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [404404/888800 45.50%] train loss: 1.357577639282681e-05 \n",
      "epoch: 46 [405515/888800 45.62%] train loss: 1.3740277609031182e-05 \n",
      "epoch: 46 [406626/888800 45.75%] train loss: 1.5489951692870818e-05 \n",
      "epoch: 46 [407737/888800 45.88%] train loss: 1.44632440424175e-05 \n",
      "epoch: 46 [408848/888800 46.00%] train loss: 1.4233969523047563e-05 \n",
      "epoch: 46 [409959/888800 46.12%] train loss: 1.3441419469018001e-05 \n",
      "epoch: 46 [411070/888800 46.25%] train loss: 1.3199448403611314e-05 \n",
      "epoch: 46 [412181/888800 46.38%] train loss: 1.3294315976963844e-05 \n",
      "epoch: 46 [413292/888800 46.50%] train loss: 1.4745356565981638e-05 \n",
      "epoch: 46 [414403/888800 46.62%] train loss: 1.5633946532034315e-05 \n",
      "epoch: 46 [415514/888800 46.75%] train loss: 1.3633211892738473e-05 \n",
      "epoch: 46 [416625/888800 46.88%] train loss: 1.409967717336258e-05 \n",
      "epoch: 46 [417736/888800 47.00%] train loss: 1.2881099792139139e-05 \n",
      "epoch: 46 [418847/888800 47.12%] train loss: 1.363894534733845e-05 \n",
      "epoch: 46 [419958/888800 47.25%] train loss: 1.3752705854130909e-05 \n",
      "epoch: 46 [421069/888800 47.38%] train loss: 1.3992535969009623e-05 \n",
      "epoch: 46 [422180/888800 47.50%] train loss: 1.4676631508336868e-05 \n",
      "epoch: 46 [423291/888800 47.62%] train loss: 1.4030832062417176e-05 \n",
      "epoch: 46 [424402/888800 47.75%] train loss: 1.3833780030836351e-05 \n",
      "epoch: 46 [425513/888800 47.88%] train loss: 1.4680596905236598e-05 \n",
      "epoch: 46 [426624/888800 48.00%] train loss: 1.3667205166711938e-05 \n",
      "epoch: 46 [427735/888800 48.12%] train loss: 1.5255929611157626e-05 \n",
      "epoch: 46 [428846/888800 48.25%] train loss: 1.4583220945496578e-05 \n",
      "epoch: 46 [429957/888800 48.38%] train loss: 1.3111146472510882e-05 \n",
      "epoch: 46 [431068/888800 48.50%] train loss: 1.4308702702692244e-05 \n",
      "epoch: 46 [432179/888800 48.62%] train loss: 1.4567715879820753e-05 \n",
      "epoch: 46 [433290/888800 48.75%] train loss: 1.3791794117423706e-05 \n",
      "epoch: 46 [434401/888800 48.88%] train loss: 1.466913272452075e-05 \n",
      "epoch: 46 [435512/888800 49.00%] train loss: 1.3827188922732603e-05 \n",
      "epoch: 46 [436623/888800 49.12%] train loss: 1.4115658814262133e-05 \n",
      "epoch: 46 [437734/888800 49.25%] train loss: 1.373722989228554e-05 \n",
      "epoch: 46 [438845/888800 49.38%] train loss: 1.3365857739700004e-05 \n",
      "epoch: 46 [439956/888800 49.50%] train loss: 1.5189491023193114e-05 \n",
      "epoch: 46 [441067/888800 49.62%] train loss: 1.407333547831513e-05 \n",
      "epoch: 46 [442178/888800 49.75%] train loss: 1.4296725566964597e-05 \n",
      "epoch: 46 [443289/888800 49.88%] train loss: 1.5269826690200716e-05 \n",
      "epoch: 46 [444400/888800 50.00%] train loss: 1.4024917618371546e-05 \n",
      "epoch: 46 [445511/888800 50.12%] train loss: 1.4181221558828838e-05 \n",
      "epoch: 46 [446622/888800 50.25%] train loss: 1.4387061128218193e-05 \n",
      "epoch: 46 [447733/888800 50.38%] train loss: 1.482028983446071e-05 \n",
      "epoch: 46 [448844/888800 50.50%] train loss: 1.347474790236447e-05 \n",
      "epoch: 46 [449955/888800 50.62%] train loss: 1.3784357179247309e-05 \n",
      "epoch: 46 [451066/888800 50.75%] train loss: 1.354285723209614e-05 \n",
      "epoch: 46 [452177/888800 50.88%] train loss: 1.2853423868364189e-05 \n",
      "epoch: 46 [453288/888800 51.00%] train loss: 1.4275916328188032e-05 \n",
      "epoch: 46 [454399/888800 51.12%] train loss: 1.387383326800773e-05 \n",
      "epoch: 46 [455510/888800 51.25%] train loss: 1.4160619684844278e-05 \n",
      "epoch: 46 [456621/888800 51.38%] train loss: 1.4004875083628576e-05 \n",
      "epoch: 46 [457732/888800 51.50%] train loss: 1.3681081327376887e-05 \n",
      "epoch: 46 [458843/888800 51.62%] train loss: 1.5009929484222084e-05 \n",
      "epoch: 46 [459954/888800 51.75%] train loss: 1.3268208931549452e-05 \n",
      "epoch: 46 [461065/888800 51.88%] train loss: 1.4100034604780376e-05 \n",
      "epoch: 46 [462176/888800 52.00%] train loss: 1.37254619403393e-05 \n",
      "epoch: 46 [463287/888800 52.12%] train loss: 1.643727046030108e-05 \n",
      "epoch: 46 [464398/888800 52.25%] train loss: 1.353602965536993e-05 \n",
      "epoch: 46 [465509/888800 52.38%] train loss: 1.5510320736211725e-05 \n",
      "epoch: 46 [466620/888800 52.50%] train loss: 1.3971291082270909e-05 \n",
      "epoch: 46 [467731/888800 52.62%] train loss: 1.668701042945031e-05 \n",
      "epoch: 46 [468842/888800 52.75%] train loss: 1.250903369509615e-05 \n",
      "epoch: 46 [469953/888800 52.88%] train loss: 1.5006579815235455e-05 \n",
      "epoch: 46 [471064/888800 53.00%] train loss: 1.4098604879109189e-05 \n",
      "epoch: 46 [472175/888800 53.12%] train loss: 1.532458009023685e-05 \n",
      "epoch: 46 [473286/888800 53.25%] train loss: 1.3769330507784616e-05 \n",
      "epoch: 46 [474397/888800 53.38%] train loss: 1.4201980775396805e-05 \n",
      "epoch: 46 [475508/888800 53.50%] train loss: 1.415526548953494e-05 \n",
      "epoch: 46 [476619/888800 53.62%] train loss: 1.6486539607285522e-05 \n",
      "epoch: 46 [477730/888800 53.75%] train loss: 1.4210946574166883e-05 \n",
      "epoch: 46 [478841/888800 53.88%] train loss: 1.5213516235235147e-05 \n",
      "epoch: 46 [479952/888800 54.00%] train loss: 1.551263267174363e-05 \n",
      "epoch: 46 [481063/888800 54.12%] train loss: 1.3259942534205038e-05 \n",
      "epoch: 46 [482174/888800 54.25%] train loss: 1.594155401107855e-05 \n",
      "epoch: 46 [483285/888800 54.38%] train loss: 1.445809357392136e-05 \n",
      "epoch: 46 [484396/888800 54.50%] train loss: 1.5319268641178496e-05 \n",
      "epoch: 46 [485507/888800 54.62%] train loss: 1.3452528946800157e-05 \n",
      "epoch: 46 [486618/888800 54.75%] train loss: 1.7097214367822744e-05 \n",
      "epoch: 46 [487729/888800 54.88%] train loss: 1.4272139196691569e-05 \n",
      "epoch: 46 [488840/888800 55.00%] train loss: 1.6075462553999387e-05 \n",
      "epoch: 46 [489951/888800 55.12%] train loss: 1.573821464262437e-05 \n",
      "epoch: 46 [491062/888800 55.25%] train loss: 1.4496258700091857e-05 \n",
      "epoch: 46 [492173/888800 55.38%] train loss: 1.541389610792976e-05 \n",
      "epoch: 46 [493284/888800 55.50%] train loss: 1.502933355368441e-05 \n",
      "epoch: 46 [494395/888800 55.62%] train loss: 1.4636166270065587e-05 \n",
      "epoch: 46 [495506/888800 55.75%] train loss: 1.4833960449323058e-05 \n",
      "epoch: 46 [496617/888800 55.88%] train loss: 1.471626637794543e-05 \n",
      "epoch: 46 [497728/888800 56.00%] train loss: 1.6589652659604326e-05 \n",
      "epoch: 46 [498839/888800 56.12%] train loss: 1.4149916751193814e-05 \n",
      "epoch: 46 [499950/888800 56.25%] train loss: 1.4872405699861702e-05 \n",
      "epoch: 46 [501061/888800 56.38%] train loss: 1.39191670314176e-05 \n",
      "epoch: 46 [502172/888800 56.50%] train loss: 1.5152663763728924e-05 \n",
      "epoch: 46 [503283/888800 56.62%] train loss: 1.4573510270565748e-05 \n",
      "epoch: 46 [504394/888800 56.75%] train loss: 1.4721244042448234e-05 \n",
      "epoch: 46 [505505/888800 56.88%] train loss: 1.3723263691645116e-05 \n",
      "epoch: 46 [506616/888800 57.00%] train loss: 1.4604523130401503e-05 \n",
      "epoch: 46 [507727/888800 57.12%] train loss: 1.4448615729634184e-05 \n",
      "epoch: 46 [508838/888800 57.25%] train loss: 1.4943722817406524e-05 \n",
      "epoch: 46 [509949/888800 57.38%] train loss: 1.3976121408632025e-05 \n",
      "epoch: 46 [511060/888800 57.50%] train loss: 1.3917672731622588e-05 \n",
      "epoch: 46 [512171/888800 57.62%] train loss: 1.3387340914050583e-05 \n",
      "epoch: 46 [513282/888800 57.75%] train loss: 1.4995603123679757e-05 \n",
      "epoch: 46 [514393/888800 57.88%] train loss: 1.3361214769247454e-05 \n",
      "epoch: 46 [515504/888800 58.00%] train loss: 1.3195514839026146e-05 \n",
      "epoch: 46 [516615/888800 58.12%] train loss: 1.535083538328763e-05 \n",
      "epoch: 46 [517726/888800 58.25%] train loss: 1.35940335894702e-05 \n",
      "epoch: 46 [518837/888800 58.38%] train loss: 1.4271386135078501e-05 \n",
      "epoch: 46 [519948/888800 58.50%] train loss: 1.385303221468348e-05 \n",
      "epoch: 46 [521059/888800 58.62%] train loss: 1.4487295629805885e-05 \n",
      "epoch: 46 [522170/888800 58.75%] train loss: 1.4183676285028923e-05 \n",
      "epoch: 46 [523281/888800 58.88%] train loss: 1.5074845578055829e-05 \n",
      "epoch: 46 [524392/888800 59.00%] train loss: 1.3927950021752622e-05 \n",
      "epoch: 46 [525503/888800 59.12%] train loss: 1.4667292816739064e-05 \n",
      "epoch: 46 [526614/888800 59.25%] train loss: 1.587813312653452e-05 \n",
      "epoch: 46 [527725/888800 59.38%] train loss: 1.4251427273848094e-05 \n",
      "epoch: 46 [528836/888800 59.50%] train loss: 1.4780156561755575e-05 \n",
      "epoch: 46 [529947/888800 59.62%] train loss: 1.4373030353453942e-05 \n",
      "epoch: 46 [531058/888800 59.75%] train loss: 1.3219626453064848e-05 \n",
      "epoch: 46 [532169/888800 59.88%] train loss: 1.547232204757165e-05 \n",
      "epoch: 46 [533280/888800 60.00%] train loss: 1.5528030417044647e-05 \n",
      "epoch: 46 [534391/888800 60.12%] train loss: 1.3712460713577457e-05 \n",
      "epoch: 46 [535502/888800 60.25%] train loss: 1.517069358669687e-05 \n",
      "epoch: 46 [536613/888800 60.38%] train loss: 1.4572898180631455e-05 \n",
      "epoch: 46 [537724/888800 60.50%] train loss: 1.6071931895567104e-05 \n",
      "epoch: 46 [538835/888800 60.62%] train loss: 1.4706242836837191e-05 \n",
      "epoch: 46 [539946/888800 60.75%] train loss: 1.5112973414943554e-05 \n",
      "epoch: 46 [541057/888800 60.88%] train loss: 1.3891089110984467e-05 \n",
      "epoch: 46 [542168/888800 61.00%] train loss: 1.4335614650917705e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [543279/888800 61.12%] train loss: 1.3826585018250626e-05 \n",
      "epoch: 46 [544390/888800 61.25%] train loss: 1.4116818420006894e-05 \n",
      "epoch: 46 [545501/888800 61.38%] train loss: 1.4510381333820987e-05 \n",
      "epoch: 46 [546612/888800 61.50%] train loss: 1.3695484994968865e-05 \n",
      "epoch: 46 [547723/888800 61.62%] train loss: 1.4035057574801613e-05 \n",
      "epoch: 46 [548834/888800 61.75%] train loss: 1.4162869774736464e-05 \n",
      "epoch: 46 [549945/888800 61.88%] train loss: 1.438509480067296e-05 \n",
      "epoch: 46 [551056/888800 62.00%] train loss: 1.3938556548964698e-05 \n",
      "epoch: 46 [552167/888800 62.12%] train loss: 1.413543850503629e-05 \n",
      "epoch: 46 [553278/888800 62.25%] train loss: 1.4271825421019457e-05 \n",
      "epoch: 46 [554389/888800 62.38%] train loss: 1.4051557627681177e-05 \n",
      "epoch: 46 [555500/888800 62.50%] train loss: 1.457472717447672e-05 \n",
      "epoch: 46 [556611/888800 62.62%] train loss: 1.3935704373579938e-05 \n",
      "epoch: 46 [557722/888800 62.75%] train loss: 1.3872982890461572e-05 \n",
      "epoch: 46 [558833/888800 62.88%] train loss: 1.4161927538225427e-05 \n",
      "epoch: 46 [559944/888800 63.00%] train loss: 1.2878404049843084e-05 \n",
      "epoch: 46 [561055/888800 63.12%] train loss: 1.404016529704677e-05 \n",
      "epoch: 46 [562166/888800 63.25%] train loss: 1.3916192074248102e-05 \n",
      "epoch: 46 [563277/888800 63.38%] train loss: 1.3281307474244386e-05 \n",
      "epoch: 46 [564388/888800 63.50%] train loss: 1.3768787539447658e-05 \n",
      "epoch: 46 [565499/888800 63.62%] train loss: 1.5114185771381017e-05 \n",
      "epoch: 46 [566610/888800 63.75%] train loss: 1.4291350453277119e-05 \n",
      "epoch: 46 [567721/888800 63.88%] train loss: 1.2999035789107438e-05 \n",
      "epoch: 46 [568832/888800 64.00%] train loss: 1.3438383575703483e-05 \n",
      "epoch: 46 [569943/888800 64.12%] train loss: 1.4917324733687565e-05 \n",
      "epoch: 46 [571054/888800 64.25%] train loss: 1.4840993571851868e-05 \n",
      "epoch: 46 [572165/888800 64.38%] train loss: 1.4449853551923297e-05 \n",
      "epoch: 46 [573276/888800 64.50%] train loss: 1.5855101082706824e-05 \n",
      "epoch: 46 [574387/888800 64.62%] train loss: 1.3506608411262278e-05 \n",
      "epoch: 46 [575498/888800 64.75%] train loss: 1.4507715604850091e-05 \n",
      "epoch: 46 [576609/888800 64.88%] train loss: 1.4507142623187974e-05 \n",
      "epoch: 46 [577720/888800 65.00%] train loss: 1.4943701899028383e-05 \n",
      "epoch: 46 [578831/888800 65.12%] train loss: 1.3228293028078042e-05 \n",
      "epoch: 46 [579942/888800 65.25%] train loss: 1.4733823263668455e-05 \n",
      "epoch: 46 [581053/888800 65.38%] train loss: 1.3373490219237283e-05 \n",
      "epoch: 46 [582164/888800 65.50%] train loss: 1.4660825399914756e-05 \n",
      "epoch: 46 [583275/888800 65.62%] train loss: 1.4705129615322221e-05 \n",
      "epoch: 46 [584386/888800 65.75%] train loss: 1.3047435459156986e-05 \n",
      "epoch: 46 [585497/888800 65.88%] train loss: 1.4540706615662202e-05 \n",
      "epoch: 46 [586608/888800 66.00%] train loss: 1.4487238331639674e-05 \n",
      "epoch: 46 [587719/888800 66.12%] train loss: 1.4462562830885872e-05 \n",
      "epoch: 46 [588830/888800 66.25%] train loss: 1.251754929398885e-05 \n",
      "epoch: 46 [589941/888800 66.38%] train loss: 1.5169865037023555e-05 \n",
      "epoch: 46 [591052/888800 66.50%] train loss: 1.4150215065455996e-05 \n",
      "epoch: 46 [592163/888800 66.62%] train loss: 1.5522055036854e-05 \n",
      "epoch: 46 [593274/888800 66.75%] train loss: 1.378792330797296e-05 \n",
      "epoch: 46 [594385/888800 66.88%] train loss: 1.4167386325425468e-05 \n",
      "epoch: 46 [595496/888800 67.00%] train loss: 1.3237046914582606e-05 \n",
      "epoch: 46 [596607/888800 67.12%] train loss: 1.3803647561871912e-05 \n",
      "epoch: 46 [597718/888800 67.25%] train loss: 1.3518981177185196e-05 \n",
      "epoch: 46 [598829/888800 67.38%] train loss: 1.5184887161012739e-05 \n",
      "epoch: 46 [599940/888800 67.50%] train loss: 1.4467884284385946e-05 \n",
      "epoch: 46 [601051/888800 67.62%] train loss: 1.467425772716524e-05 \n",
      "epoch: 46 [602162/888800 67.75%] train loss: 1.4632266356784385e-05 \n",
      "epoch: 46 [603273/888800 67.88%] train loss: 1.3261768799566198e-05 \n",
      "epoch: 46 [604384/888800 68.00%] train loss: 1.4345258023240604e-05 \n",
      "epoch: 46 [605495/888800 68.12%] train loss: 1.450421677873237e-05 \n",
      "epoch: 46 [606606/888800 68.25%] train loss: 1.5264833564287983e-05 \n",
      "epoch: 46 [607717/888800 68.38%] train loss: 1.5521001841989346e-05 \n",
      "epoch: 46 [608828/888800 68.50%] train loss: 1.58107668539742e-05 \n",
      "epoch: 46 [609939/888800 68.62%] train loss: 1.6407704606535845e-05 \n",
      "epoch: 46 [611050/888800 68.75%] train loss: 1.4802814803260844e-05 \n",
      "epoch: 46 [612161/888800 68.88%] train loss: 1.3332865819393191e-05 \n",
      "epoch: 46 [613272/888800 69.00%] train loss: 1.607960984983947e-05 \n",
      "epoch: 46 [614383/888800 69.12%] train loss: 1.4239833944884595e-05 \n",
      "epoch: 46 [615494/888800 69.25%] train loss: 1.5391609849757515e-05 \n",
      "epoch: 46 [616605/888800 69.38%] train loss: 1.370189511362696e-05 \n",
      "epoch: 46 [617716/888800 69.50%] train loss: 1.5789981262059882e-05 \n",
      "epoch: 46 [618827/888800 69.62%] train loss: 1.5530375094385818e-05 \n",
      "epoch: 46 [619938/888800 69.75%] train loss: 1.4486538020719308e-05 \n",
      "epoch: 46 [621049/888800 69.88%] train loss: 1.4984059816924855e-05 \n",
      "epoch: 46 [622160/888800 70.00%] train loss: 1.6039501133491285e-05 \n",
      "epoch: 46 [623271/888800 70.12%] train loss: 1.4452066352532711e-05 \n",
      "epoch: 46 [624382/888800 70.25%] train loss: 1.4394531717698555e-05 \n",
      "epoch: 46 [625493/888800 70.38%] train loss: 1.322094067290891e-05 \n",
      "epoch: 46 [626604/888800 70.50%] train loss: 1.4251759239414241e-05 \n",
      "epoch: 46 [627715/888800 70.62%] train loss: 1.4504449609376024e-05 \n",
      "epoch: 46 [628826/888800 70.75%] train loss: 1.408465232088929e-05 \n",
      "epoch: 46 [629937/888800 70.88%] train loss: 1.4854606888548005e-05 \n",
      "epoch: 46 [631048/888800 71.00%] train loss: 1.3914485862187576e-05 \n",
      "epoch: 46 [632159/888800 71.12%] train loss: 1.306750527874101e-05 \n",
      "epoch: 46 [633270/888800 71.25%] train loss: 1.393091952195391e-05 \n",
      "epoch: 46 [634381/888800 71.38%] train loss: 1.3710510756936856e-05 \n",
      "epoch: 46 [635492/888800 71.50%] train loss: 1.3565235349233262e-05 \n",
      "epoch: 46 [636603/888800 71.62%] train loss: 1.4649154763901606e-05 \n",
      "epoch: 46 [637714/888800 71.75%] train loss: 1.3589166883321013e-05 \n",
      "epoch: 46 [638825/888800 71.88%] train loss: 1.4067316442378797e-05 \n",
      "epoch: 46 [639936/888800 72.00%] train loss: 1.505240834376309e-05 \n",
      "epoch: 46 [641047/888800 72.12%] train loss: 1.5141499716264661e-05 \n",
      "epoch: 46 [642158/888800 72.25%] train loss: 1.3929764463682659e-05 \n",
      "epoch: 46 [643269/888800 72.38%] train loss: 1.411525227013044e-05 \n",
      "epoch: 46 [644380/888800 72.50%] train loss: 1.5085530321812257e-05 \n",
      "epoch: 46 [645491/888800 72.62%] train loss: 1.3889613910578191e-05 \n",
      "epoch: 46 [646602/888800 72.75%] train loss: 1.2993305062991567e-05 \n",
      "epoch: 46 [647713/888800 72.88%] train loss: 1.3600551937997807e-05 \n",
      "epoch: 46 [648824/888800 73.00%] train loss: 1.4950145668990444e-05 \n",
      "epoch: 46 [649935/888800 73.12%] train loss: 1.5013724805612583e-05 \n",
      "epoch: 46 [651046/888800 73.25%] train loss: 1.3238975043350365e-05 \n",
      "epoch: 46 [652157/888800 73.38%] train loss: 1.4009426195116248e-05 \n",
      "epoch: 46 [653268/888800 73.50%] train loss: 1.4777313481317833e-05 \n",
      "epoch: 46 [654379/888800 73.62%] train loss: 1.3366526218305808e-05 \n",
      "epoch: 46 [655490/888800 73.75%] train loss: 1.3637605661642738e-05 \n",
      "epoch: 46 [656601/888800 73.88%] train loss: 1.5213123333523981e-05 \n",
      "epoch: 46 [657712/888800 74.00%] train loss: 1.3858019883628003e-05 \n",
      "epoch: 46 [658823/888800 74.12%] train loss: 1.308546507061692e-05 \n",
      "epoch: 46 [659934/888800 74.25%] train loss: 1.5316369172069244e-05 \n",
      "epoch: 46 [661045/888800 74.38%] train loss: 1.5151822481129784e-05 \n",
      "epoch: 46 [662156/888800 74.50%] train loss: 1.5255353901011404e-05 \n",
      "epoch: 46 [663267/888800 74.62%] train loss: 1.3230650438345037e-05 \n",
      "epoch: 46 [664378/888800 74.75%] train loss: 1.3711232895730063e-05 \n",
      "epoch: 46 [665489/888800 74.88%] train loss: 1.4685382666357327e-05 \n",
      "epoch: 46 [666600/888800 75.00%] train loss: 1.4213840586307924e-05 \n",
      "epoch: 46 [667711/888800 75.12%] train loss: 1.5248004274326377e-05 \n",
      "epoch: 46 [668822/888800 75.25%] train loss: 1.3460111404128838e-05 \n",
      "epoch: 46 [669933/888800 75.38%] train loss: 1.3759594367002137e-05 \n",
      "epoch: 46 [671044/888800 75.50%] train loss: 1.3681218661076855e-05 \n",
      "epoch: 46 [672155/888800 75.62%] train loss: 1.442170196241932e-05 \n",
      "epoch: 46 [673266/888800 75.75%] train loss: 1.3523229426937178e-05 \n",
      "epoch: 46 [674377/888800 75.88%] train loss: 1.4843732969893608e-05 \n",
      "epoch: 46 [675488/888800 76.00%] train loss: 1.3384480553213507e-05 \n",
      "epoch: 46 [676599/888800 76.12%] train loss: 1.4495755749521777e-05 \n",
      "epoch: 46 [677710/888800 76.25%] train loss: 1.44502655530232e-05 \n",
      "epoch: 46 [678821/888800 76.38%] train loss: 1.5051338777993806e-05 \n",
      "epoch: 46 [679932/888800 76.50%] train loss: 1.509821322542848e-05 \n",
      "epoch: 46 [681043/888800 76.62%] train loss: 1.460803559893975e-05 \n",
      "epoch: 46 [682154/888800 76.75%] train loss: 1.4861530871712603e-05 \n",
      "epoch: 46 [683265/888800 76.88%] train loss: 1.4348702279676218e-05 \n",
      "epoch: 46 [684376/888800 77.00%] train loss: 1.5201984751911368e-05 \n",
      "epoch: 46 [685487/888800 77.12%] train loss: 1.46006741488236e-05 \n",
      "epoch: 46 [686598/888800 77.25%] train loss: 1.4333596482174471e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [687709/888800 77.38%] train loss: 1.4773844668525271e-05 \n",
      "epoch: 46 [688820/888800 77.50%] train loss: 1.5252240700647235e-05 \n",
      "epoch: 46 [689931/888800 77.62%] train loss: 1.4108705727267079e-05 \n",
      "epoch: 46 [691042/888800 77.75%] train loss: 1.5196633285086136e-05 \n",
      "epoch: 46 [692153/888800 77.88%] train loss: 1.406324008712545e-05 \n",
      "epoch: 46 [693264/888800 78.00%] train loss: 1.2706000234175008e-05 \n",
      "epoch: 46 [694375/888800 78.12%] train loss: 1.3132445928931702e-05 \n",
      "epoch: 46 [695486/888800 78.25%] train loss: 1.4120257219474297e-05 \n",
      "epoch: 46 [696597/888800 78.38%] train loss: 1.425804293830879e-05 \n",
      "epoch: 46 [697708/888800 78.50%] train loss: 1.3889605725125875e-05 \n",
      "epoch: 46 [698819/888800 78.62%] train loss: 1.4137281141302083e-05 \n",
      "epoch: 46 [699930/888800 78.75%] train loss: 1.547669671708718e-05 \n",
      "epoch: 46 [701041/888800 78.88%] train loss: 1.4303619536804035e-05 \n",
      "epoch: 46 [702152/888800 79.00%] train loss: 1.4700788597110659e-05 \n",
      "epoch: 46 [703263/888800 79.12%] train loss: 1.3560495972342324e-05 \n",
      "epoch: 46 [704374/888800 79.25%] train loss: 1.384143342875177e-05 \n",
      "epoch: 46 [705485/888800 79.38%] train loss: 1.475539738748921e-05 \n",
      "epoch: 46 [706596/888800 79.50%] train loss: 1.470943789172452e-05 \n",
      "epoch: 46 [707707/888800 79.62%] train loss: 1.337265257461695e-05 \n",
      "epoch: 46 [708818/888800 79.75%] train loss: 1.4926597941666842e-05 \n",
      "epoch: 46 [709929/888800 79.88%] train loss: 1.434075693396153e-05 \n",
      "epoch: 46 [711040/888800 80.00%] train loss: 1.335599063168047e-05 \n",
      "epoch: 46 [712151/888800 80.12%] train loss: 1.4904883755662013e-05 \n",
      "epoch: 46 [713262/888800 80.25%] train loss: 1.4962355635361746e-05 \n",
      "epoch: 46 [714373/888800 80.38%] train loss: 1.4284845747170039e-05 \n",
      "epoch: 46 [715484/888800 80.50%] train loss: 1.483111918787472e-05 \n",
      "epoch: 46 [716595/888800 80.62%] train loss: 1.3743127055931836e-05 \n",
      "epoch: 46 [717706/888800 80.75%] train loss: 1.4279110473580658e-05 \n",
      "epoch: 46 [718817/888800 80.88%] train loss: 1.426962626283057e-05 \n",
      "epoch: 46 [719928/888800 81.00%] train loss: 1.2639357919397298e-05 \n",
      "epoch: 46 [721039/888800 81.12%] train loss: 1.3797083738609217e-05 \n",
      "epoch: 46 [722150/888800 81.25%] train loss: 1.4793471564189531e-05 \n",
      "epoch: 46 [723261/888800 81.38%] train loss: 1.6192958355532028e-05 \n",
      "epoch: 46 [724372/888800 81.50%] train loss: 1.4217146599548869e-05 \n",
      "epoch: 46 [725483/888800 81.62%] train loss: 1.449455157853663e-05 \n",
      "epoch: 46 [726594/888800 81.75%] train loss: 1.3656995179189835e-05 \n",
      "epoch: 46 [727705/888800 81.88%] train loss: 1.5391133274533786e-05 \n",
      "epoch: 46 [728816/888800 82.00%] train loss: 1.325391076534288e-05 \n",
      "epoch: 46 [729927/888800 82.12%] train loss: 1.5246547263814136e-05 \n",
      "epoch: 46 [731038/888800 82.25%] train loss: 1.3916658645030111e-05 \n",
      "epoch: 46 [732149/888800 82.38%] train loss: 1.3113039130985271e-05 \n",
      "epoch: 46 [733260/888800 82.50%] train loss: 1.323767992289504e-05 \n",
      "epoch: 46 [734371/888800 82.62%] train loss: 1.3720548849960323e-05 \n",
      "epoch: 46 [735482/888800 82.75%] train loss: 1.457063353882404e-05 \n",
      "epoch: 46 [736593/888800 82.88%] train loss: 1.4469001143879723e-05 \n",
      "epoch: 46 [737704/888800 83.00%] train loss: 1.3984391443955246e-05 \n",
      "epoch: 46 [738815/888800 83.12%] train loss: 1.4226320672605652e-05 \n",
      "epoch: 46 [739926/888800 83.25%] train loss: 1.5528028598055243e-05 \n",
      "epoch: 46 [741037/888800 83.38%] train loss: 1.3755135114479344e-05 \n",
      "epoch: 46 [742148/888800 83.50%] train loss: 1.35190857690759e-05 \n",
      "epoch: 46 [743259/888800 83.62%] train loss: 1.4363296031660866e-05 \n",
      "epoch: 46 [744370/888800 83.75%] train loss: 1.4570031453331467e-05 \n",
      "epoch: 46 [745481/888800 83.88%] train loss: 1.4689993804495316e-05 \n",
      "epoch: 46 [746592/888800 84.00%] train loss: 1.4865961020404939e-05 \n",
      "epoch: 46 [747703/888800 84.12%] train loss: 1.4260381249187049e-05 \n",
      "epoch: 46 [748814/888800 84.25%] train loss: 1.5118364899535663e-05 \n",
      "epoch: 46 [749925/888800 84.38%] train loss: 1.3822338587488048e-05 \n",
      "epoch: 46 [751036/888800 84.50%] train loss: 1.4455075870500877e-05 \n",
      "epoch: 46 [752147/888800 84.62%] train loss: 1.3085084901831578e-05 \n",
      "epoch: 46 [753258/888800 84.75%] train loss: 1.470121515012579e-05 \n",
      "epoch: 46 [754369/888800 84.88%] train loss: 1.3100201613269746e-05 \n",
      "epoch: 46 [755480/888800 85.00%] train loss: 1.4718631973664742e-05 \n",
      "epoch: 46 [756591/888800 85.12%] train loss: 1.4952416677260771e-05 \n",
      "epoch: 46 [757702/888800 85.25%] train loss: 1.3214425052865408e-05 \n",
      "epoch: 46 [758813/888800 85.38%] train loss: 1.3221780136518646e-05 \n",
      "epoch: 46 [759924/888800 85.50%] train loss: 1.4643435861216858e-05 \n",
      "epoch: 46 [761035/888800 85.62%] train loss: 1.4665173694083933e-05 \n",
      "epoch: 46 [762146/888800 85.75%] train loss: 1.6022799172787927e-05 \n",
      "epoch: 46 [763257/888800 85.88%] train loss: 1.3549910363508388e-05 \n",
      "epoch: 46 [764368/888800 86.00%] train loss: 1.6286070604110137e-05 \n",
      "epoch: 46 [765479/888800 86.12%] train loss: 1.5037795492389705e-05 \n",
      "epoch: 46 [766590/888800 86.25%] train loss: 1.4332972568809055e-05 \n",
      "epoch: 46 [767701/888800 86.38%] train loss: 1.6271742424578406e-05 \n",
      "epoch: 46 [768812/888800 86.50%] train loss: 1.5379189790110104e-05 \n",
      "epoch: 46 [769923/888800 86.62%] train loss: 1.5425230230903253e-05 \n",
      "epoch: 46 [771034/888800 86.75%] train loss: 1.3307088920555543e-05 \n",
      "epoch: 46 [772145/888800 86.88%] train loss: 1.488164343754761e-05 \n",
      "epoch: 46 [773256/888800 87.00%] train loss: 1.4211761481419671e-05 \n",
      "epoch: 46 [774367/888800 87.12%] train loss: 1.378897468384821e-05 \n",
      "epoch: 46 [775478/888800 87.25%] train loss: 1.4895937056280673e-05 \n",
      "epoch: 46 [776589/888800 87.38%] train loss: 1.339891787210945e-05 \n",
      "epoch: 46 [777700/888800 87.50%] train loss: 1.4265857316786423e-05 \n",
      "epoch: 46 [778811/888800 87.62%] train loss: 1.363624232908478e-05 \n",
      "epoch: 46 [779922/888800 87.75%] train loss: 1.4391386685019825e-05 \n",
      "epoch: 46 [781033/888800 87.88%] train loss: 1.4505890248983633e-05 \n",
      "epoch: 46 [782144/888800 88.00%] train loss: 1.4977612408983987e-05 \n",
      "epoch: 46 [783255/888800 88.12%] train loss: 1.4805963473918382e-05 \n",
      "epoch: 46 [784366/888800 88.25%] train loss: 1.4170796930557117e-05 \n",
      "epoch: 46 [785477/888800 88.38%] train loss: 1.4883641597407404e-05 \n",
      "epoch: 46 [786588/888800 88.50%] train loss: 1.617770249140449e-05 \n",
      "epoch: 46 [787699/888800 88.62%] train loss: 1.4534283764078282e-05 \n",
      "epoch: 46 [788810/888800 88.75%] train loss: 1.4604506759496871e-05 \n",
      "epoch: 46 [789921/888800 88.88%] train loss: 1.4959357940824702e-05 \n",
      "epoch: 46 [791032/888800 89.00%] train loss: 1.4148616173770279e-05 \n",
      "epoch: 46 [792143/888800 89.12%] train loss: 1.3489627235685475e-05 \n",
      "epoch: 46 [793254/888800 89.25%] train loss: 1.6745780158089474e-05 \n",
      "epoch: 46 [794365/888800 89.38%] train loss: 1.5296956917154603e-05 \n",
      "epoch: 46 [795476/888800 89.50%] train loss: 1.4857377209409606e-05 \n",
      "epoch: 46 [796587/888800 89.62%] train loss: 1.4374980310094543e-05 \n",
      "epoch: 46 [797698/888800 89.75%] train loss: 1.5015817552921362e-05 \n",
      "epoch: 46 [798809/888800 89.88%] train loss: 1.5594774595228955e-05 \n",
      "epoch: 46 [799920/888800 90.00%] train loss: 1.4698421182401944e-05 \n",
      "epoch: 46 [801031/888800 90.12%] train loss: 1.584670098964125e-05 \n",
      "epoch: 46 [802142/888800 90.25%] train loss: 1.3742854207521304e-05 \n",
      "epoch: 46 [803253/888800 90.38%] train loss: 1.5146331861615181e-05 \n",
      "epoch: 46 [804364/888800 90.50%] train loss: 1.4309316611615941e-05 \n",
      "epoch: 46 [805475/888800 90.62%] train loss: 1.4952651326893829e-05 \n",
      "epoch: 46 [806586/888800 90.75%] train loss: 1.4698758604936302e-05 \n",
      "epoch: 46 [807697/888800 90.88%] train loss: 1.3810656128043775e-05 \n",
      "epoch: 46 [808808/888800 91.00%] train loss: 1.5097696632437874e-05 \n",
      "epoch: 46 [809919/888800 91.12%] train loss: 1.3591178685601335e-05 \n",
      "epoch: 46 [811030/888800 91.25%] train loss: 1.3427915291686077e-05 \n",
      "epoch: 46 [812141/888800 91.38%] train loss: 1.2692404197878204e-05 \n",
      "epoch: 46 [813252/888800 91.50%] train loss: 1.49591514855274e-05 \n",
      "epoch: 46 [814363/888800 91.62%] train loss: 1.5976029317243956e-05 \n",
      "epoch: 46 [815474/888800 91.75%] train loss: 1.4294908396550454e-05 \n",
      "epoch: 46 [816585/888800 91.88%] train loss: 1.4797751646256074e-05 \n",
      "epoch: 46 [817696/888800 92.00%] train loss: 1.4209932487574406e-05 \n",
      "epoch: 46 [818807/888800 92.12%] train loss: 1.3454686268232763e-05 \n",
      "epoch: 46 [819918/888800 92.25%] train loss: 1.422232344339136e-05 \n",
      "epoch: 46 [821029/888800 92.38%] train loss: 1.36364578793291e-05 \n",
      "epoch: 46 [822140/888800 92.50%] train loss: 1.4757883946003858e-05 \n",
      "epoch: 46 [823251/888800 92.62%] train loss: 1.4337055290525313e-05 \n",
      "epoch: 46 [824362/888800 92.75%] train loss: 1.3200035027693957e-05 \n",
      "epoch: 46 [825473/888800 92.88%] train loss: 1.4945210750738624e-05 \n",
      "epoch: 46 [826584/888800 93.00%] train loss: 1.4163708328851499e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 [827695/888800 93.12%] train loss: 1.3934223716205452e-05 \n",
      "epoch: 46 [828806/888800 93.25%] train loss: 1.502792838437017e-05 \n",
      "epoch: 46 [829917/888800 93.38%] train loss: 1.40671127155656e-05 \n",
      "epoch: 46 [831028/888800 93.50%] train loss: 1.5370562323369086e-05 \n",
      "epoch: 46 [832139/888800 93.62%] train loss: 1.407094987371238e-05 \n",
      "epoch: 46 [833250/888800 93.75%] train loss: 1.4994508092058823e-05 \n",
      "epoch: 46 [834361/888800 93.88%] train loss: 1.3045314517512452e-05 \n",
      "epoch: 46 [835472/888800 94.00%] train loss: 1.3021578524785582e-05 \n",
      "epoch: 46 [836583/888800 94.12%] train loss: 1.2803881872969214e-05 \n",
      "epoch: 46 [837694/888800 94.25%] train loss: 1.3915164345235098e-05 \n",
      "epoch: 46 [838805/888800 94.38%] train loss: 1.4038710105523933e-05 \n",
      "epoch: 46 [839916/888800 94.50%] train loss: 1.4606171134801116e-05 \n",
      "epoch: 46 [841027/888800 94.62%] train loss: 1.3991966625326313e-05 \n",
      "epoch: 46 [842138/888800 94.75%] train loss: 1.3460847185342573e-05 \n",
      "epoch: 46 [843249/888800 94.88%] train loss: 1.4021135029906873e-05 \n",
      "epoch: 46 [844360/888800 95.00%] train loss: 1.345312011835631e-05 \n",
      "epoch: 46 [845471/888800 95.12%] train loss: 1.2701245395874139e-05 \n",
      "epoch: 46 [846582/888800 95.25%] train loss: 1.4857839232718106e-05 \n",
      "epoch: 46 [847693/888800 95.38%] train loss: 1.5982390323188156e-05 \n",
      "epoch: 46 [848804/888800 95.50%] train loss: 1.3925992789154407e-05 \n",
      "epoch: 46 [849915/888800 95.62%] train loss: 1.5729325241409242e-05 \n",
      "epoch: 46 [851026/888800 95.75%] train loss: 1.473682641517371e-05 \n",
      "epoch: 46 [852137/888800 95.88%] train loss: 1.3535565813072026e-05 \n",
      "epoch: 46 [853248/888800 96.00%] train loss: 1.3426031728158705e-05 \n",
      "epoch: 46 [854359/888800 96.12%] train loss: 1.4278691196523141e-05 \n",
      "epoch: 46 [855470/888800 96.25%] train loss: 1.4324784388008993e-05 \n",
      "epoch: 46 [856581/888800 96.38%] train loss: 1.3935956303612329e-05 \n",
      "epoch: 46 [857692/888800 96.50%] train loss: 1.596263791725505e-05 \n",
      "epoch: 46 [858803/888800 96.62%] train loss: 1.4351758181874175e-05 \n",
      "epoch: 46 [859914/888800 96.75%] train loss: 1.3572567695518956e-05 \n",
      "epoch: 46 [861025/888800 96.88%] train loss: 1.4648210708401166e-05 \n",
      "epoch: 46 [862136/888800 97.00%] train loss: 1.36760090754251e-05 \n",
      "epoch: 46 [863247/888800 97.12%] train loss: 1.362142211291939e-05 \n",
      "epoch: 46 [864358/888800 97.25%] train loss: 1.3960552678327076e-05 \n",
      "epoch: 46 [865469/888800 97.38%] train loss: 1.3288473382999655e-05 \n",
      "epoch: 46 [866580/888800 97.50%] train loss: 1.4433197065955028e-05 \n",
      "epoch: 46 [867691/888800 97.62%] train loss: 1.3930890418123454e-05 \n",
      "epoch: 46 [868802/888800 97.75%] train loss: 1.4293530512077268e-05 \n",
      "epoch: 46 [869913/888800 97.88%] train loss: 1.4490742614725605e-05 \n",
      "epoch: 46 [871024/888800 98.00%] train loss: 1.5029937458166387e-05 \n",
      "epoch: 46 [872135/888800 98.12%] train loss: 1.4429028851736803e-05 \n",
      "epoch: 46 [873246/888800 98.25%] train loss: 1.4663316505902912e-05 \n",
      "epoch: 46 [874357/888800 98.38%] train loss: 1.5933810573187657e-05 \n",
      "epoch: 46 [875468/888800 98.50%] train loss: 1.3787467651127372e-05 \n",
      "epoch: 46 [876579/888800 98.62%] train loss: 1.3024330655753147e-05 \n",
      "epoch: 46 [877690/888800 98.75%] train loss: 1.4787310647079721e-05 \n",
      "epoch: 46 [878801/888800 98.88%] train loss: 1.3704850061913021e-05 \n",
      "epoch: 46 [879912/888800 99.00%] train loss: 1.4377505067386664e-05 \n",
      "epoch: 46 [881023/888800 99.12%] train loss: 1.2717339814116713e-05 \n",
      "epoch: 46 [882134/888800 99.25%] train loss: 1.4419013496080879e-05 \n",
      "epoch: 46 [883245/888800 99.38%] train loss: 1.4155741155263968e-05 \n",
      "epoch: 46 [884356/888800 99.50%] train loss: 1.481161052652169e-05 \n",
      "epoch: 46 [885467/888800 99.62%] train loss: 1.4147036381473299e-05 \n",
      "epoch: 46 [886578/888800 99.75%] train loss: 1.2418556252669077e-05 \n",
      "epoch: 46 [887689/888800 99.88%] train loss: 1.5045131476654205e-05 \n",
      "epoch: 47 [0/888800 0.00%] train loss: 1.3729368220083416e-05 \n",
      "epoch: 47 [1111/888800 0.12%] train loss: 1.3715349268750288e-05 \n",
      "epoch: 47 [2222/888800 0.25%] train loss: 1.419778709532693e-05 \n",
      "epoch: 47 [3333/888800 0.38%] train loss: 1.4241774806578178e-05 \n",
      "epoch: 47 [4444/888800 0.50%] train loss: 1.338446145382477e-05 \n",
      "epoch: 47 [5555/888800 0.62%] train loss: 1.2477805285016075e-05 \n",
      "epoch: 47 [6666/888800 0.75%] train loss: 1.409519427397754e-05 \n",
      "epoch: 47 [7777/888800 0.88%] train loss: 1.4208245374902617e-05 \n",
      "epoch: 47 [8888/888800 1.00%] train loss: 1.451591288059717e-05 \n",
      "epoch: 47 [9999/888800 1.12%] train loss: 1.3488169315678533e-05 \n",
      "epoch: 47 [11110/888800 1.25%] train loss: 1.453342611057451e-05 \n",
      "epoch: 47 [12221/888800 1.38%] train loss: 1.427295046596555e-05 \n",
      "epoch: 47 [13332/888800 1.50%] train loss: 1.4342364920594264e-05 \n",
      "epoch: 47 [14443/888800 1.62%] train loss: 1.547255669720471e-05 \n",
      "epoch: 47 [15554/888800 1.75%] train loss: 1.4207767890184186e-05 \n",
      "epoch: 47 [16665/888800 1.88%] train loss: 1.395693834638223e-05 \n",
      "epoch: 47 [17776/888800 2.00%] train loss: 1.4879949958412908e-05 \n",
      "epoch: 47 [18887/888800 2.12%] train loss: 1.4404755347641185e-05 \n",
      "epoch: 47 [19998/888800 2.25%] train loss: 1.4712615666212514e-05 \n",
      "epoch: 47 [21109/888800 2.38%] train loss: 1.4402103261090815e-05 \n",
      "epoch: 47 [22220/888800 2.50%] train loss: 1.4345704585139174e-05 \n",
      "epoch: 47 [23331/888800 2.62%] train loss: 1.4051103789824992e-05 \n",
      "epoch: 47 [24442/888800 2.75%] train loss: 1.4199738870956935e-05 \n",
      "epoch: 47 [25553/888800 2.88%] train loss: 1.432403860235354e-05 \n",
      "epoch: 47 [26664/888800 3.00%] train loss: 1.6392581528634764e-05 \n",
      "epoch: 47 [27775/888800 3.12%] train loss: 1.3947312254458666e-05 \n",
      "epoch: 47 [28886/888800 3.25%] train loss: 1.2824023542634677e-05 \n",
      "epoch: 47 [29997/888800 3.38%] train loss: 1.4114987607172225e-05 \n",
      "epoch: 47 [31108/888800 3.50%] train loss: 1.524079380033072e-05 \n",
      "epoch: 47 [32219/888800 3.62%] train loss: 1.3924792256148066e-05 \n",
      "epoch: 47 [33330/888800 3.75%] train loss: 1.4875133274472319e-05 \n",
      "epoch: 47 [34441/888800 3.88%] train loss: 1.3468842553265858e-05 \n",
      "epoch: 47 [35552/888800 4.00%] train loss: 1.5098461517482065e-05 \n",
      "epoch: 47 [36663/888800 4.12%] train loss: 1.417324074282078e-05 \n",
      "epoch: 47 [37774/888800 4.25%] train loss: 1.5021640138002113e-05 \n",
      "epoch: 47 [38885/888800 4.38%] train loss: 1.4906697288097348e-05 \n",
      "epoch: 47 [39996/888800 4.50%] train loss: 1.4523707250191364e-05 \n",
      "epoch: 47 [41107/888800 4.62%] train loss: 1.512393919256283e-05 \n",
      "epoch: 47 [42218/888800 4.75%] train loss: 1.4223986909200903e-05 \n",
      "epoch: 47 [43329/888800 4.88%] train loss: 1.4350774108606856e-05 \n",
      "epoch: 47 [44440/888800 5.00%] train loss: 1.3687039427168202e-05 \n",
      "epoch: 47 [45551/888800 5.12%] train loss: 1.4243163604987785e-05 \n",
      "epoch: 47 [46662/888800 5.25%] train loss: 1.3321933693077881e-05 \n",
      "epoch: 47 [47773/888800 5.38%] train loss: 1.492161572969053e-05 \n",
      "epoch: 47 [48884/888800 5.50%] train loss: 1.4484634448308498e-05 \n",
      "epoch: 47 [49995/888800 5.62%] train loss: 1.4433209798880853e-05 \n",
      "epoch: 47 [51106/888800 5.75%] train loss: 1.4704923160024919e-05 \n",
      "epoch: 47 [52217/888800 5.88%] train loss: 1.4582793482986744e-05 \n",
      "epoch: 47 [53328/888800 6.00%] train loss: 1.486425389884971e-05 \n",
      "epoch: 47 [54439/888800 6.12%] train loss: 1.5419536794070154e-05 \n",
      "epoch: 47 [55550/888800 6.25%] train loss: 1.4434688637265936e-05 \n",
      "epoch: 47 [56661/888800 6.38%] train loss: 1.580857133376412e-05 \n",
      "epoch: 47 [57772/888800 6.50%] train loss: 1.330036684521474e-05 \n",
      "epoch: 47 [58883/888800 6.62%] train loss: 1.3449196558212861e-05 \n",
      "epoch: 47 [59994/888800 6.75%] train loss: 1.642824827285949e-05 \n",
      "epoch: 47 [61105/888800 6.88%] train loss: 1.3195972314861137e-05 \n",
      "epoch: 47 [62216/888800 7.00%] train loss: 1.3832563126925379e-05 \n",
      "epoch: 47 [63327/888800 7.12%] train loss: 1.5648083717678674e-05 \n",
      "epoch: 47 [64438/888800 7.25%] train loss: 1.5270514268195257e-05 \n",
      "epoch: 47 [65549/888800 7.38%] train loss: 1.433059514965862e-05 \n",
      "epoch: 47 [66660/888800 7.50%] train loss: 1.3708847291127313e-05 \n",
      "epoch: 47 [67771/888800 7.62%] train loss: 1.5652700312784873e-05 \n",
      "epoch: 47 [68882/888800 7.75%] train loss: 1.3562261301558465e-05 \n",
      "epoch: 47 [69993/888800 7.88%] train loss: 1.552715002617333e-05 \n",
      "epoch: 47 [71104/888800 8.00%] train loss: 1.4327585631690454e-05 \n",
      "epoch: 47 [72215/888800 8.12%] train loss: 1.3383059012994636e-05 \n",
      "epoch: 47 [73326/888800 8.25%] train loss: 1.4605492651753593e-05 \n",
      "epoch: 47 [74437/888800 8.38%] train loss: 1.519257239124272e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [75548/888800 8.50%] train loss: 1.4399873180082068e-05 \n",
      "epoch: 47 [76659/888800 8.62%] train loss: 1.3429048522084486e-05 \n",
      "epoch: 47 [77770/888800 8.75%] train loss: 1.3563765605795197e-05 \n",
      "epoch: 47 [78881/888800 8.88%] train loss: 1.4025864402356092e-05 \n",
      "epoch: 47 [79992/888800 9.00%] train loss: 1.3992150343256071e-05 \n",
      "epoch: 47 [81103/888800 9.12%] train loss: 1.3372388821153436e-05 \n",
      "epoch: 47 [82214/888800 9.25%] train loss: 1.4529438885801937e-05 \n",
      "epoch: 47 [83325/888800 9.38%] train loss: 1.3308984307514038e-05 \n",
      "epoch: 47 [84436/888800 9.50%] train loss: 1.3067550753476098e-05 \n",
      "epoch: 47 [85547/888800 9.62%] train loss: 1.3793700418318622e-05 \n",
      "epoch: 47 [86658/888800 9.75%] train loss: 1.4929424651199952e-05 \n",
      "epoch: 47 [87769/888800 9.88%] train loss: 1.482430707255844e-05 \n",
      "epoch: 47 [88880/888800 10.00%] train loss: 1.254517883353401e-05 \n",
      "epoch: 47 [89991/888800 10.12%] train loss: 1.55700199684361e-05 \n",
      "epoch: 47 [91102/888800 10.25%] train loss: 1.3903993931307923e-05 \n",
      "epoch: 47 [92213/888800 10.38%] train loss: 1.4452742107096128e-05 \n",
      "epoch: 47 [93324/888800 10.50%] train loss: 1.422098466719035e-05 \n",
      "epoch: 47 [94435/888800 10.62%] train loss: 1.462278942199191e-05 \n",
      "epoch: 47 [95546/888800 10.75%] train loss: 1.5476305634365417e-05 \n",
      "epoch: 47 [96657/888800 10.88%] train loss: 1.48333147080848e-05 \n",
      "epoch: 47 [97768/888800 11.00%] train loss: 1.3354348084249068e-05 \n",
      "epoch: 47 [98879/888800 11.12%] train loss: 1.3167017641535494e-05 \n",
      "epoch: 47 [99990/888800 11.25%] train loss: 1.4585973985958844e-05 \n",
      "epoch: 47 [101101/888800 11.38%] train loss: 1.353351581201423e-05 \n",
      "epoch: 47 [102212/888800 11.50%] train loss: 1.5102169527381193e-05 \n",
      "epoch: 47 [103323/888800 11.62%] train loss: 1.4415415535040665e-05 \n",
      "epoch: 47 [104434/888800 11.75%] train loss: 1.5343503037001938e-05 \n",
      "epoch: 47 [105545/888800 11.88%] train loss: 1.4313421161205042e-05 \n",
      "epoch: 47 [106656/888800 12.00%] train loss: 1.4426007510337513e-05 \n",
      "epoch: 47 [107767/888800 12.12%] train loss: 1.4107165043242276e-05 \n",
      "epoch: 47 [108878/888800 12.25%] train loss: 1.5147825251915492e-05 \n",
      "epoch: 47 [109989/888800 12.38%] train loss: 1.3646354091179091e-05 \n",
      "epoch: 47 [111100/888800 12.50%] train loss: 1.3666065569850616e-05 \n",
      "epoch: 47 [112211/888800 12.62%] train loss: 1.4958422070776578e-05 \n",
      "epoch: 47 [113322/888800 12.75%] train loss: 1.4082191228226293e-05 \n",
      "epoch: 47 [114433/888800 12.88%] train loss: 1.2803822755813599e-05 \n",
      "epoch: 47 [115544/888800 13.00%] train loss: 1.4588086742151063e-05 \n",
      "epoch: 47 [116655/888800 13.12%] train loss: 1.3351012967177667e-05 \n",
      "epoch: 47 [117766/888800 13.25%] train loss: 1.3612148904940113e-05 \n",
      "epoch: 47 [118877/888800 13.38%] train loss: 1.4603252566303127e-05 \n",
      "epoch: 47 [119988/888800 13.50%] train loss: 1.453838649467798e-05 \n",
      "epoch: 47 [121099/888800 13.62%] train loss: 1.4841842130408622e-05 \n",
      "epoch: 47 [122210/888800 13.75%] train loss: 1.447739759896649e-05 \n",
      "epoch: 47 [123321/888800 13.88%] train loss: 1.5009402886789758e-05 \n",
      "epoch: 47 [124432/888800 14.00%] train loss: 1.3631061847263481e-05 \n",
      "epoch: 47 [125543/888800 14.12%] train loss: 1.4344175724545494e-05 \n",
      "epoch: 47 [126654/888800 14.25%] train loss: 1.3909672816225793e-05 \n",
      "epoch: 47 [127765/888800 14.38%] train loss: 1.3905888408771716e-05 \n",
      "epoch: 47 [128876/888800 14.50%] train loss: 1.3354447219171561e-05 \n",
      "epoch: 47 [129987/888800 14.62%] train loss: 1.4104495676292572e-05 \n",
      "epoch: 47 [131098/888800 14.75%] train loss: 1.4469951565843076e-05 \n",
      "epoch: 47 [132209/888800 14.88%] train loss: 1.4833642126177438e-05 \n",
      "epoch: 47 [133320/888800 15.00%] train loss: 1.4555435882357415e-05 \n",
      "epoch: 47 [134431/888800 15.12%] train loss: 1.4476982869382482e-05 \n",
      "epoch: 47 [135542/888800 15.25%] train loss: 1.3485747331287712e-05 \n",
      "epoch: 47 [136653/888800 15.38%] train loss: 1.4483093764283694e-05 \n",
      "epoch: 47 [137764/888800 15.50%] train loss: 1.3912770555180032e-05 \n",
      "epoch: 47 [138875/888800 15.62%] train loss: 1.3700992894882802e-05 \n",
      "epoch: 47 [139986/888800 15.75%] train loss: 1.4196605661709327e-05 \n",
      "epoch: 47 [141097/888800 15.88%] train loss: 1.3838526683684904e-05 \n",
      "epoch: 47 [142208/888800 16.00%] train loss: 1.3495259736373555e-05 \n",
      "epoch: 47 [143319/888800 16.12%] train loss: 1.4946273950044997e-05 \n",
      "epoch: 47 [144430/888800 16.25%] train loss: 1.4338790606416296e-05 \n",
      "epoch: 47 [145541/888800 16.38%] train loss: 1.3570780538429972e-05 \n",
      "epoch: 47 [146652/888800 16.50%] train loss: 1.56456353579415e-05 \n",
      "epoch: 47 [147763/888800 16.62%] train loss: 1.562663419463206e-05 \n",
      "epoch: 47 [148874/888800 16.75%] train loss: 1.544605584058445e-05 \n",
      "epoch: 47 [149985/888800 16.88%] train loss: 1.4899826965120155e-05 \n",
      "epoch: 47 [151096/888800 17.00%] train loss: 1.330712348135421e-05 \n",
      "epoch: 47 [152207/888800 17.12%] train loss: 1.4309980542748235e-05 \n",
      "epoch: 47 [153318/888800 17.25%] train loss: 1.483753658249043e-05 \n",
      "epoch: 47 [154429/888800 17.38%] train loss: 1.3604745618067682e-05 \n",
      "epoch: 47 [155540/888800 17.50%] train loss: 1.4470054338744376e-05 \n",
      "epoch: 47 [156651/888800 17.62%] train loss: 1.499240897828713e-05 \n",
      "epoch: 47 [157762/888800 17.75%] train loss: 1.4178995115798898e-05 \n",
      "epoch: 47 [158873/888800 17.88%] train loss: 1.4019049558555707e-05 \n",
      "epoch: 47 [159984/888800 18.00%] train loss: 1.3182935617805924e-05 \n",
      "epoch: 47 [161095/888800 18.12%] train loss: 1.359809630230302e-05 \n",
      "epoch: 47 [162206/888800 18.25%] train loss: 1.2993319614906795e-05 \n",
      "epoch: 47 [163317/888800 18.38%] train loss: 1.3067367945041042e-05 \n",
      "epoch: 47 [164428/888800 18.50%] train loss: 1.5035442629596218e-05 \n",
      "epoch: 47 [165539/888800 18.62%] train loss: 1.4637617823609617e-05 \n",
      "epoch: 47 [166650/888800 18.75%] train loss: 1.363734008918982e-05 \n",
      "epoch: 47 [167761/888800 18.88%] train loss: 1.3743348972639069e-05 \n",
      "epoch: 47 [168872/888800 19.00%] train loss: 1.5947840438457206e-05 \n",
      "epoch: 47 [169983/888800 19.12%] train loss: 1.415082260791678e-05 \n",
      "epoch: 47 [171094/888800 19.25%] train loss: 1.3913901966589037e-05 \n",
      "epoch: 47 [172205/888800 19.38%] train loss: 1.4753075447515585e-05 \n",
      "epoch: 47 [173316/888800 19.50%] train loss: 1.5632404029020108e-05 \n",
      "epoch: 47 [174427/888800 19.62%] train loss: 1.4631387784902472e-05 \n",
      "epoch: 47 [175538/888800 19.75%] train loss: 1.4348603144753724e-05 \n",
      "epoch: 47 [176649/888800 19.88%] train loss: 1.58202055899892e-05 \n",
      "epoch: 47 [177760/888800 20.00%] train loss: 1.4514990652969573e-05 \n",
      "epoch: 47 [178871/888800 20.12%] train loss: 1.534286275273189e-05 \n",
      "epoch: 47 [179982/888800 20.25%] train loss: 1.5246811926772352e-05 \n",
      "epoch: 47 [181093/888800 20.38%] train loss: 1.4868442121951375e-05 \n",
      "epoch: 47 [182204/888800 20.50%] train loss: 1.3637390111398418e-05 \n",
      "epoch: 47 [183315/888800 20.62%] train loss: 1.416995200997917e-05 \n",
      "epoch: 47 [184426/888800 20.75%] train loss: 1.3000976650801022e-05 \n",
      "epoch: 47 [185537/888800 20.88%] train loss: 1.3246527487353887e-05 \n",
      "epoch: 47 [186648/888800 21.00%] train loss: 1.2963941117050126e-05 \n",
      "epoch: 47 [187759/888800 21.12%] train loss: 1.4113011275185272e-05 \n",
      "epoch: 47 [188870/888800 21.25%] train loss: 1.4582503354176879e-05 \n",
      "epoch: 47 [189981/888800 21.38%] train loss: 1.4425390872929711e-05 \n",
      "epoch: 47 [191092/888800 21.50%] train loss: 1.4896811080689076e-05 \n",
      "epoch: 47 [192203/888800 21.62%] train loss: 1.3953179404779803e-05 \n",
      "epoch: 47 [193314/888800 21.75%] train loss: 1.51152034959523e-05 \n",
      "epoch: 47 [194425/888800 21.88%] train loss: 1.4779028788325377e-05 \n",
      "epoch: 47 [195536/888800 22.00%] train loss: 1.3669946383743081e-05 \n",
      "epoch: 47 [196647/888800 22.12%] train loss: 1.4797983567405026e-05 \n",
      "epoch: 47 [197758/888800 22.25%] train loss: 1.4342961549118627e-05 \n",
      "epoch: 47 [198869/888800 22.38%] train loss: 1.49832621900714e-05 \n",
      "epoch: 47 [199980/888800 22.50%] train loss: 1.3503423360816669e-05 \n",
      "epoch: 47 [201091/888800 22.62%] train loss: 1.3950513675808907e-05 \n",
      "epoch: 47 [202202/888800 22.75%] train loss: 1.4827163795416709e-05 \n",
      "epoch: 47 [203313/888800 22.88%] train loss: 1.4167141671350691e-05 \n",
      "epoch: 47 [204424/888800 23.00%] train loss: 1.3383878467720933e-05 \n",
      "epoch: 47 [205535/888800 23.12%] train loss: 1.496008553658612e-05 \n",
      "epoch: 47 [206646/888800 23.25%] train loss: 1.4595917491533328e-05 \n",
      "epoch: 47 [207757/888800 23.38%] train loss: 1.4035940694157034e-05 \n",
      "epoch: 47 [208868/888800 23.50%] train loss: 1.377903299726313e-05 \n",
      "epoch: 47 [209979/888800 23.62%] train loss: 1.3800098713545594e-05 \n",
      "epoch: 47 [211090/888800 23.75%] train loss: 1.454883113183314e-05 \n",
      "epoch: 47 [212201/888800 23.88%] train loss: 1.379855712002609e-05 \n",
      "epoch: 47 [213312/888800 24.00%] train loss: 1.4691306205349974e-05 \n",
      "epoch: 47 [214423/888800 24.12%] train loss: 1.4651053788838908e-05 \n",
      "epoch: 47 [215534/888800 24.25%] train loss: 1.3819996638630982e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [216645/888800 24.38%] train loss: 1.4438133803196251e-05 \n",
      "epoch: 47 [217756/888800 24.50%] train loss: 1.3662142009707168e-05 \n",
      "epoch: 47 [218867/888800 24.62%] train loss: 1.4460933925874997e-05 \n",
      "epoch: 47 [219978/888800 24.75%] train loss: 1.5359348253696226e-05 \n",
      "epoch: 47 [221089/888800 24.88%] train loss: 1.4692743206978776e-05 \n",
      "epoch: 47 [222200/888800 25.00%] train loss: 1.4008084690431133e-05 \n",
      "epoch: 47 [223311/888800 25.12%] train loss: 1.5018707927083597e-05 \n",
      "epoch: 47 [224422/888800 25.25%] train loss: 1.3456211490847636e-05 \n",
      "epoch: 47 [225533/888800 25.38%] train loss: 1.41483196784975e-05 \n",
      "epoch: 47 [226644/888800 25.50%] train loss: 1.4327493772725575e-05 \n",
      "epoch: 47 [227755/888800 25.62%] train loss: 1.3954893802292645e-05 \n",
      "epoch: 47 [228866/888800 25.75%] train loss: 1.6427728041890077e-05 \n",
      "epoch: 47 [229977/888800 25.88%] train loss: 1.355282984150108e-05 \n",
      "epoch: 47 [231088/888800 26.00%] train loss: 1.5836736565688625e-05 \n",
      "epoch: 47 [232199/888800 26.12%] train loss: 1.4616349290008657e-05 \n",
      "epoch: 47 [233310/888800 26.25%] train loss: 1.4227135579858441e-05 \n",
      "epoch: 47 [234421/888800 26.38%] train loss: 1.4147655747365206e-05 \n",
      "epoch: 47 [235532/888800 26.50%] train loss: 1.4609016034228262e-05 \n",
      "epoch: 47 [236643/888800 26.62%] train loss: 1.4537996321450919e-05 \n",
      "epoch: 47 [237754/888800 26.75%] train loss: 1.5045408872538246e-05 \n",
      "epoch: 47 [238865/888800 26.88%] train loss: 1.663248986005783e-05 \n",
      "epoch: 47 [239976/888800 27.00%] train loss: 1.6067875549197197e-05 \n",
      "epoch: 47 [241087/888800 27.12%] train loss: 1.5937868738546968e-05 \n",
      "epoch: 47 [242198/888800 27.25%] train loss: 1.3804628906655125e-05 \n",
      "epoch: 47 [243309/888800 27.38%] train loss: 1.4836708032817114e-05 \n",
      "epoch: 47 [244420/888800 27.50%] train loss: 1.4790707609790843e-05 \n",
      "epoch: 47 [245531/888800 27.62%] train loss: 1.5033239833428524e-05 \n",
      "epoch: 47 [246642/888800 27.75%] train loss: 1.3994702385389246e-05 \n",
      "epoch: 47 [247753/888800 27.88%] train loss: 1.6096735635073856e-05 \n",
      "epoch: 47 [248864/888800 28.00%] train loss: 1.3847873560735025e-05 \n",
      "epoch: 47 [249975/888800 28.12%] train loss: 1.4171522707329132e-05 \n",
      "epoch: 47 [251086/888800 28.25%] train loss: 1.421814249624731e-05 \n",
      "epoch: 47 [252197/888800 28.38%] train loss: 1.3830986972607207e-05 \n",
      "epoch: 47 [253308/888800 28.50%] train loss: 1.4036872926226351e-05 \n",
      "epoch: 47 [254419/888800 28.62%] train loss: 1.4096227459958754e-05 \n",
      "epoch: 47 [255530/888800 28.75%] train loss: 1.6259624317171983e-05 \n",
      "epoch: 47 [256641/888800 28.88%] train loss: 1.4596392247767653e-05 \n",
      "epoch: 47 [257752/888800 29.00%] train loss: 1.5274699762812816e-05 \n",
      "epoch: 47 [258863/888800 29.12%] train loss: 1.3079491509415675e-05 \n",
      "epoch: 47 [259974/888800 29.25%] train loss: 1.5553878256469034e-05 \n",
      "epoch: 47 [261085/888800 29.38%] train loss: 1.3835046047461219e-05 \n",
      "epoch: 47 [262196/888800 29.50%] train loss: 1.5927498679957353e-05 \n",
      "epoch: 47 [263307/888800 29.62%] train loss: 1.4634084436693229e-05 \n",
      "epoch: 47 [264418/888800 29.75%] train loss: 1.4393403944268357e-05 \n",
      "epoch: 47 [265529/888800 29.88%] train loss: 1.385151881549973e-05 \n",
      "epoch: 47 [266640/888800 30.00%] train loss: 1.4810264474363066e-05 \n",
      "epoch: 47 [267751/888800 30.12%] train loss: 1.5156778317759745e-05 \n",
      "epoch: 47 [268862/888800 30.25%] train loss: 1.3646411389345303e-05 \n",
      "epoch: 47 [269973/888800 30.38%] train loss: 1.4040418136573862e-05 \n",
      "epoch: 47 [271084/888800 30.50%] train loss: 1.3555891200667247e-05 \n",
      "epoch: 47 [272195/888800 30.62%] train loss: 1.5827985407668166e-05 \n",
      "epoch: 47 [273306/888800 30.75%] train loss: 1.537966454634443e-05 \n",
      "epoch: 47 [274417/888800 30.88%] train loss: 1.399253415002022e-05 \n",
      "epoch: 47 [275528/888800 31.00%] train loss: 1.4363254194904584e-05 \n",
      "epoch: 47 [276639/888800 31.12%] train loss: 1.4899384041200392e-05 \n",
      "epoch: 47 [277750/888800 31.25%] train loss: 1.4982041648181621e-05 \n",
      "epoch: 47 [278861/888800 31.38%] train loss: 1.4704080058436375e-05 \n",
      "epoch: 47 [279972/888800 31.50%] train loss: 1.5246942894009408e-05 \n",
      "epoch: 47 [281083/888800 31.62%] train loss: 1.3091894288663752e-05 \n",
      "epoch: 47 [282194/888800 31.75%] train loss: 1.2633199730771594e-05 \n",
      "epoch: 47 [283305/888800 31.88%] train loss: 1.5276616977644153e-05 \n",
      "epoch: 47 [284416/888800 32.00%] train loss: 1.4162702427711338e-05 \n",
      "epoch: 47 [285527/888800 32.12%] train loss: 1.3946951185062062e-05 \n",
      "epoch: 47 [286638/888800 32.25%] train loss: 1.340650487691164e-05 \n",
      "epoch: 47 [287749/888800 32.38%] train loss: 1.5374116628663614e-05 \n",
      "epoch: 47 [288860/888800 32.50%] train loss: 1.3877231140213553e-05 \n",
      "epoch: 47 [289971/888800 32.62%] train loss: 1.490235354140168e-05 \n",
      "epoch: 47 [291082/888800 32.75%] train loss: 1.3597694305644836e-05 \n",
      "epoch: 47 [292193/888800 32.88%] train loss: 1.4875135093461722e-05 \n",
      "epoch: 47 [293304/888800 33.00%] train loss: 1.3758870409219526e-05 \n",
      "epoch: 47 [294415/888800 33.12%] train loss: 1.617616362636909e-05 \n",
      "epoch: 47 [295526/888800 33.25%] train loss: 1.3343100363272242e-05 \n",
      "epoch: 47 [296637/888800 33.38%] train loss: 1.4597650988434907e-05 \n",
      "epoch: 47 [297748/888800 33.50%] train loss: 1.4718939382873941e-05 \n",
      "epoch: 47 [298859/888800 33.62%] train loss: 1.3439468602882698e-05 \n",
      "epoch: 47 [299970/888800 33.75%] train loss: 1.4471973372565117e-05 \n",
      "epoch: 47 [301081/888800 33.88%] train loss: 1.3305110769579187e-05 \n",
      "epoch: 47 [302192/888800 34.00%] train loss: 1.4780691344640218e-05 \n",
      "epoch: 47 [303303/888800 34.12%] train loss: 1.4416568774322513e-05 \n",
      "epoch: 47 [304414/888800 34.25%] train loss: 1.4473876035481226e-05 \n",
      "epoch: 47 [305525/888800 34.38%] train loss: 1.3780531844531652e-05 \n",
      "epoch: 47 [306636/888800 34.50%] train loss: 1.3632310583489016e-05 \n",
      "epoch: 47 [307747/888800 34.62%] train loss: 1.3611250324174762e-05 \n",
      "epoch: 47 [308858/888800 34.75%] train loss: 1.3431696970656049e-05 \n",
      "epoch: 47 [309969/888800 34.88%] train loss: 1.4819605894444976e-05 \n",
      "epoch: 47 [311080/888800 35.00%] train loss: 1.4057664884603582e-05 \n",
      "epoch: 47 [312191/888800 35.12%] train loss: 1.4418946193472948e-05 \n",
      "epoch: 47 [313302/888800 35.25%] train loss: 1.5053098650241736e-05 \n",
      "epoch: 47 [314413/888800 35.38%] train loss: 1.4117231330601498e-05 \n",
      "epoch: 47 [315524/888800 35.50%] train loss: 1.2354688806226477e-05 \n",
      "epoch: 47 [316635/888800 35.62%] train loss: 1.433711531717563e-05 \n",
      "epoch: 47 [317746/888800 35.75%] train loss: 1.3038883480476215e-05 \n",
      "epoch: 47 [318857/888800 35.88%] train loss: 1.4164655112836044e-05 \n",
      "epoch: 47 [319968/888800 36.00%] train loss: 1.4764509614906274e-05 \n",
      "epoch: 47 [321079/888800 36.12%] train loss: 1.3818597835779656e-05 \n",
      "epoch: 47 [322190/888800 36.25%] train loss: 1.3497660802386235e-05 \n",
      "epoch: 47 [323301/888800 36.38%] train loss: 1.238258664670866e-05 \n",
      "epoch: 47 [324412/888800 36.50%] train loss: 1.4201494195731357e-05 \n",
      "epoch: 47 [325523/888800 36.62%] train loss: 1.5186711607384495e-05 \n",
      "epoch: 47 [326634/888800 36.75%] train loss: 1.4842187738395296e-05 \n",
      "epoch: 47 [327745/888800 36.88%] train loss: 1.267943389393622e-05 \n",
      "epoch: 47 [328856/888800 37.00%] train loss: 1.5904726751614362e-05 \n",
      "epoch: 47 [329967/888800 37.12%] train loss: 1.4394810023077298e-05 \n",
      "epoch: 47 [331078/888800 37.25%] train loss: 1.3045420018897858e-05 \n",
      "epoch: 47 [332189/888800 37.38%] train loss: 1.4082455891184509e-05 \n",
      "epoch: 47 [333300/888800 37.50%] train loss: 1.3770386431133375e-05 \n",
      "epoch: 47 [334411/888800 37.62%] train loss: 1.4092005585553125e-05 \n",
      "epoch: 47 [335522/888800 37.75%] train loss: 1.3918129297962878e-05 \n",
      "epoch: 47 [336633/888800 37.88%] train loss: 1.5003791304479819e-05 \n",
      "epoch: 47 [337744/888800 38.00%] train loss: 1.549196349515114e-05 \n",
      "epoch: 47 [338855/888800 38.12%] train loss: 1.387467455060687e-05 \n",
      "epoch: 47 [339966/888800 38.25%] train loss: 1.4165374523145147e-05 \n",
      "epoch: 47 [341077/888800 38.38%] train loss: 1.4508661479339935e-05 \n",
      "epoch: 47 [342188/888800 38.50%] train loss: 1.4221649507817347e-05 \n",
      "epoch: 47 [343299/888800 38.62%] train loss: 1.3924191080150194e-05 \n",
      "epoch: 47 [344410/888800 38.75%] train loss: 1.622081981622614e-05 \n",
      "epoch: 47 [345521/888800 38.88%] train loss: 1.4275111425376963e-05 \n",
      "epoch: 47 [346632/888800 39.00%] train loss: 1.3418661183095537e-05 \n",
      "epoch: 47 [347743/888800 39.12%] train loss: 1.4588594240194652e-05 \n",
      "epoch: 47 [348854/888800 39.25%] train loss: 1.3005855180381332e-05 \n",
      "epoch: 47 [349965/888800 39.38%] train loss: 1.437397895642789e-05 \n",
      "epoch: 47 [351076/888800 39.50%] train loss: 1.3863274034520146e-05 \n",
      "epoch: 47 [352187/888800 39.62%] train loss: 1.4936726074665785e-05 \n",
      "epoch: 47 [353298/888800 39.75%] train loss: 1.4682147593703121e-05 \n",
      "epoch: 47 [354409/888800 39.88%] train loss: 1.3914827832195442e-05 \n",
      "epoch: 47 [355520/888800 40.00%] train loss: 1.564280864840839e-05 \n",
      "epoch: 47 [356631/888800 40.12%] train loss: 1.4850117622700054e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [357742/888800 40.25%] train loss: 1.5227853509713896e-05 \n",
      "epoch: 47 [358853/888800 40.38%] train loss: 1.4677548278996255e-05 \n",
      "epoch: 47 [359964/888800 40.50%] train loss: 1.540712037240155e-05 \n",
      "epoch: 47 [361075/888800 40.62%] train loss: 1.3333189599507023e-05 \n",
      "epoch: 47 [362186/888800 40.75%] train loss: 1.5739895388833247e-05 \n",
      "epoch: 47 [363297/888800 40.88%] train loss: 1.3483700058714021e-05 \n",
      "epoch: 47 [364408/888800 41.00%] train loss: 1.439118932466954e-05 \n",
      "epoch: 47 [365519/888800 41.12%] train loss: 1.3484686860465445e-05 \n",
      "epoch: 47 [366630/888800 41.25%] train loss: 1.481512481404934e-05 \n",
      "epoch: 47 [367741/888800 41.38%] train loss: 1.4876219211146235e-05 \n",
      "epoch: 47 [368852/888800 41.50%] train loss: 1.4623851711803582e-05 \n",
      "epoch: 47 [369963/888800 41.62%] train loss: 1.4835548427072354e-05 \n",
      "epoch: 47 [371074/888800 41.75%] train loss: 1.4495617506327108e-05 \n",
      "epoch: 47 [372185/888800 41.88%] train loss: 1.5348019587690942e-05 \n",
      "epoch: 47 [373296/888800 42.00%] train loss: 1.4153496522339992e-05 \n",
      "epoch: 47 [374407/888800 42.12%] train loss: 1.5849280316615477e-05 \n",
      "epoch: 47 [375518/888800 42.25%] train loss: 1.2035729923809413e-05 \n",
      "epoch: 47 [376629/888800 42.38%] train loss: 1.7339150872430764e-05 \n",
      "epoch: 47 [377740/888800 42.50%] train loss: 1.3467874850903172e-05 \n",
      "epoch: 47 [378851/888800 42.62%] train loss: 1.6371524907299317e-05 \n",
      "epoch: 47 [379962/888800 42.75%] train loss: 1.5323896150221117e-05 \n",
      "epoch: 47 [381073/888800 42.88%] train loss: 1.523523769719759e-05 \n",
      "epoch: 47 [382184/888800 43.00%] train loss: 1.4940556866349652e-05 \n",
      "epoch: 47 [383295/888800 43.12%] train loss: 1.4115895282884594e-05 \n",
      "epoch: 47 [384406/888800 43.25%] train loss: 1.4533021385432221e-05 \n",
      "epoch: 47 [385517/888800 43.38%] train loss: 1.3286245120980311e-05 \n",
      "epoch: 47 [386628/888800 43.50%] train loss: 1.3331039554032031e-05 \n",
      "epoch: 47 [387739/888800 43.62%] train loss: 1.3675684385816567e-05 \n",
      "epoch: 47 [388850/888800 43.75%] train loss: 1.5173766769294161e-05 \n",
      "epoch: 47 [389961/888800 43.88%] train loss: 1.4072356862016022e-05 \n",
      "epoch: 47 [391072/888800 44.00%] train loss: 1.4031638784217648e-05 \n",
      "epoch: 47 [392183/888800 44.12%] train loss: 1.5943547623464838e-05 \n",
      "epoch: 47 [393294/888800 44.25%] train loss: 1.4131486750557087e-05 \n",
      "epoch: 47 [394405/888800 44.38%] train loss: 1.4734147043782286e-05 \n",
      "epoch: 47 [395516/888800 44.50%] train loss: 1.4176434888213407e-05 \n",
      "epoch: 47 [396627/888800 44.62%] train loss: 1.4868760445096996e-05 \n",
      "epoch: 47 [397738/888800 44.75%] train loss: 1.419564796378836e-05 \n",
      "epoch: 47 [398849/888800 44.88%] train loss: 1.493005493102828e-05 \n",
      "epoch: 47 [399960/888800 45.00%] train loss: 1.4145817658572923e-05 \n",
      "epoch: 47 [401071/888800 45.12%] train loss: 1.3967279301141389e-05 \n",
      "epoch: 47 [402182/888800 45.25%] train loss: 1.3903432773076929e-05 \n",
      "epoch: 47 [403293/888800 45.38%] train loss: 1.5901228834991343e-05 \n",
      "epoch: 47 [404404/888800 45.50%] train loss: 1.3662710443895776e-05 \n",
      "epoch: 47 [405515/888800 45.62%] train loss: 1.3951001164969057e-05 \n",
      "epoch: 47 [406626/888800 45.75%] train loss: 1.4045168427401222e-05 \n",
      "epoch: 47 [407737/888800 45.88%] train loss: 1.3584236512542702e-05 \n",
      "epoch: 47 [408848/888800 46.00%] train loss: 1.5198275832517538e-05 \n",
      "epoch: 47 [409959/888800 46.12%] train loss: 1.3532955563277937e-05 \n",
      "epoch: 47 [411070/888800 46.25%] train loss: 1.4145453860692214e-05 \n",
      "epoch: 47 [412181/888800 46.38%] train loss: 1.369818073726492e-05 \n",
      "epoch: 47 [413292/888800 46.50%] train loss: 1.4800833923800383e-05 \n",
      "epoch: 47 [414403/888800 46.62%] train loss: 1.3559306353272405e-05 \n",
      "epoch: 47 [415514/888800 46.75%] train loss: 1.4398759049072396e-05 \n",
      "epoch: 47 [416625/888800 46.88%] train loss: 1.4386404473043513e-05 \n",
      "epoch: 47 [417736/888800 47.00%] train loss: 1.4524624020850752e-05 \n",
      "epoch: 47 [418847/888800 47.12%] train loss: 1.4174763236951549e-05 \n",
      "epoch: 47 [419958/888800 47.25%] train loss: 1.3537232916860376e-05 \n",
      "epoch: 47 [421069/888800 47.38%] train loss: 1.4640207155025564e-05 \n",
      "epoch: 47 [422180/888800 47.50%] train loss: 1.2228831110405736e-05 \n",
      "epoch: 47 [423291/888800 47.62%] train loss: 1.4301500414148904e-05 \n",
      "epoch: 47 [424402/888800 47.75%] train loss: 1.4725093933520839e-05 \n",
      "epoch: 47 [425513/888800 47.88%] train loss: 1.3479193512466736e-05 \n",
      "epoch: 47 [426624/888800 48.00%] train loss: 1.3833045159117319e-05 \n",
      "epoch: 47 [427735/888800 48.12%] train loss: 1.3613630471809302e-05 \n",
      "epoch: 47 [428846/888800 48.25%] train loss: 1.4477229342446662e-05 \n",
      "epoch: 47 [429957/888800 48.38%] train loss: 1.3059873708698433e-05 \n",
      "epoch: 47 [431068/888800 48.50%] train loss: 1.419874115526909e-05 \n",
      "epoch: 47 [432179/888800 48.62%] train loss: 1.3110123290971387e-05 \n",
      "epoch: 47 [433290/888800 48.75%] train loss: 1.4566358004231006e-05 \n",
      "epoch: 47 [434401/888800 48.88%] train loss: 1.4651084711658768e-05 \n",
      "epoch: 47 [435512/888800 49.00%] train loss: 1.4703979104524478e-05 \n",
      "epoch: 47 [436623/888800 49.12%] train loss: 1.5778958186274394e-05 \n",
      "epoch: 47 [437734/888800 49.25%] train loss: 1.4176594049786218e-05 \n",
      "epoch: 47 [438845/888800 49.38%] train loss: 1.470376446377486e-05 \n",
      "epoch: 47 [439956/888800 49.50%] train loss: 1.3958016097603831e-05 \n",
      "epoch: 47 [441067/888800 49.62%] train loss: 1.4960328371671494e-05 \n",
      "epoch: 47 [442178/888800 49.75%] train loss: 1.3873423995391931e-05 \n",
      "epoch: 47 [443289/888800 49.88%] train loss: 1.4293969798018225e-05 \n",
      "epoch: 47 [444400/888800 50.00%] train loss: 1.3922431207902264e-05 \n",
      "epoch: 47 [445511/888800 50.12%] train loss: 1.5015421922726091e-05 \n",
      "epoch: 47 [446622/888800 50.25%] train loss: 1.4831479347776622e-05 \n",
      "epoch: 47 [447733/888800 50.38%] train loss: 1.4691938304167707e-05 \n",
      "epoch: 47 [448844/888800 50.50%] train loss: 1.4247529179556295e-05 \n",
      "epoch: 47 [449955/888800 50.62%] train loss: 1.3114637113176286e-05 \n",
      "epoch: 47 [451066/888800 50.75%] train loss: 1.3499218766810372e-05 \n",
      "epoch: 47 [452177/888800 50.88%] train loss: 1.4171363545756321e-05 \n",
      "epoch: 47 [453288/888800 51.00%] train loss: 1.4997630387370009e-05 \n",
      "epoch: 47 [454399/888800 51.12%] train loss: 1.4004298463987652e-05 \n",
      "epoch: 47 [455510/888800 51.25%] train loss: 1.4440664017456584e-05 \n",
      "epoch: 47 [456621/888800 51.38%] train loss: 1.4393916899280157e-05 \n",
      "epoch: 47 [457732/888800 51.50%] train loss: 1.5307772628148086e-05 \n",
      "epoch: 47 [458843/888800 51.62%] train loss: 1.4234648006095085e-05 \n",
      "epoch: 47 [459954/888800 51.75%] train loss: 1.37995375553146e-05 \n",
      "epoch: 47 [461065/888800 51.88%] train loss: 1.4906365322531201e-05 \n",
      "epoch: 47 [462176/888800 52.00%] train loss: 1.3876669072487857e-05 \n",
      "epoch: 47 [463287/888800 52.12%] train loss: 1.432367480447283e-05 \n",
      "epoch: 47 [464398/888800 52.25%] train loss: 1.401778354193084e-05 \n",
      "epoch: 47 [465509/888800 52.38%] train loss: 1.373199211229803e-05 \n",
      "epoch: 47 [466620/888800 52.50%] train loss: 1.3692996617464814e-05 \n",
      "epoch: 47 [467731/888800 52.62%] train loss: 1.3040383237239439e-05 \n",
      "epoch: 47 [468842/888800 52.75%] train loss: 1.398048425471643e-05 \n",
      "epoch: 47 [469953/888800 52.88%] train loss: 1.3367995961743873e-05 \n",
      "epoch: 47 [471064/888800 53.00%] train loss: 1.549719127069693e-05 \n",
      "epoch: 47 [472175/888800 53.12%] train loss: 1.4929129974916577e-05 \n",
      "epoch: 47 [473286/888800 53.25%] train loss: 1.3812773431709502e-05 \n",
      "epoch: 47 [474397/888800 53.38%] train loss: 1.6359466826543212e-05 \n",
      "epoch: 47 [475508/888800 53.50%] train loss: 1.4289435966929886e-05 \n",
      "epoch: 47 [476619/888800 53.62%] train loss: 1.4786233805352822e-05 \n",
      "epoch: 47 [477730/888800 53.75%] train loss: 1.4512232155539095e-05 \n",
      "epoch: 47 [478841/888800 53.88%] train loss: 1.4913247468939517e-05 \n",
      "epoch: 47 [479952/888800 54.00%] train loss: 1.6392796169384383e-05 \n",
      "epoch: 47 [481063/888800 54.12%] train loss: 1.3706177014682908e-05 \n",
      "epoch: 47 [482174/888800 54.25%] train loss: 1.53109594975831e-05 \n",
      "epoch: 47 [483285/888800 54.38%] train loss: 1.2682377018791158e-05 \n",
      "epoch: 47 [484396/888800 54.50%] train loss: 1.6073216102086008e-05 \n",
      "epoch: 47 [485507/888800 54.62%] train loss: 1.4118823855824303e-05 \n",
      "epoch: 47 [486618/888800 54.75%] train loss: 1.444531517336145e-05 \n",
      "epoch: 47 [487729/888800 54.88%] train loss: 1.3770826626569033e-05 \n",
      "epoch: 47 [488840/888800 55.00%] train loss: 1.5263245586538687e-05 \n",
      "epoch: 47 [489951/888800 55.12%] train loss: 1.3332079106476158e-05 \n",
      "epoch: 47 [491062/888800 55.25%] train loss: 1.4993800505180843e-05 \n",
      "epoch: 47 [492173/888800 55.38%] train loss: 1.5940720913931727e-05 \n",
      "epoch: 47 [493284/888800 55.50%] train loss: 1.3381844837567769e-05 \n",
      "epoch: 47 [494395/888800 55.62%] train loss: 1.6550347936572507e-05 \n",
      "epoch: 47 [495506/888800 55.75%] train loss: 1.4899625966791064e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [496617/888800 55.88%] train loss: 1.632799467188306e-05 \n",
      "epoch: 47 [497728/888800 56.00%] train loss: 1.4296226254373323e-05 \n",
      "epoch: 47 [498839/888800 56.12%] train loss: 1.6392716133850627e-05 \n",
      "epoch: 47 [499950/888800 56.25%] train loss: 1.4865142475173343e-05 \n",
      "epoch: 47 [501061/888800 56.38%] train loss: 1.488471116317669e-05 \n",
      "epoch: 47 [502172/888800 56.50%] train loss: 1.5103400073712692e-05 \n",
      "epoch: 47 [503283/888800 56.62%] train loss: 1.55062552948948e-05 \n",
      "epoch: 47 [504394/888800 56.75%] train loss: 1.3043478247709572e-05 \n",
      "epoch: 47 [505505/888800 56.88%] train loss: 1.4791427929594647e-05 \n",
      "epoch: 47 [506616/888800 57.00%] train loss: 1.3913881048210897e-05 \n",
      "epoch: 47 [507727/888800 57.12%] train loss: 1.5457779227290303e-05 \n",
      "epoch: 47 [508838/888800 57.25%] train loss: 1.5222468391584698e-05 \n",
      "epoch: 47 [509949/888800 57.38%] train loss: 1.4724567336088512e-05 \n",
      "epoch: 47 [511060/888800 57.50%] train loss: 1.459587201679824e-05 \n",
      "epoch: 47 [512171/888800 57.62%] train loss: 1.3990360457682982e-05 \n",
      "epoch: 47 [513282/888800 57.75%] train loss: 1.4485898645943962e-05 \n",
      "epoch: 47 [514393/888800 57.88%] train loss: 1.4444041880778968e-05 \n",
      "epoch: 47 [515504/888800 58.00%] train loss: 1.3785688679490704e-05 \n",
      "epoch: 47 [516615/888800 58.12%] train loss: 1.3111288353684358e-05 \n",
      "epoch: 47 [517726/888800 58.25%] train loss: 1.4079179891268723e-05 \n",
      "epoch: 47 [518837/888800 58.38%] train loss: 1.4832409760856535e-05 \n",
      "epoch: 47 [519948/888800 58.50%] train loss: 1.2809549843950663e-05 \n",
      "epoch: 47 [521059/888800 58.62%] train loss: 1.4231506611395162e-05 \n",
      "epoch: 47 [522170/888800 58.75%] train loss: 1.2729117770504672e-05 \n",
      "epoch: 47 [523281/888800 58.88%] train loss: 1.3879615835321601e-05 \n",
      "epoch: 47 [524392/888800 59.00%] train loss: 1.4920240573701449e-05 \n",
      "epoch: 47 [525503/888800 59.12%] train loss: 1.409873402735684e-05 \n",
      "epoch: 47 [526614/888800 59.25%] train loss: 1.3745966498390771e-05 \n",
      "epoch: 47 [527725/888800 59.38%] train loss: 1.3028435205342248e-05 \n",
      "epoch: 47 [528836/888800 59.50%] train loss: 1.4569734958058689e-05 \n",
      "epoch: 47 [529947/888800 59.62%] train loss: 1.416127724951366e-05 \n",
      "epoch: 47 [531058/888800 59.75%] train loss: 1.458219139749417e-05 \n",
      "epoch: 47 [532169/888800 59.88%] train loss: 1.36720591399353e-05 \n",
      "epoch: 47 [533280/888800 60.00%] train loss: 1.5886311302892864e-05 \n",
      "epoch: 47 [534391/888800 60.12%] train loss: 1.4617588931287173e-05 \n",
      "epoch: 47 [535502/888800 60.25%] train loss: 1.427812094334513e-05 \n",
      "epoch: 47 [536613/888800 60.38%] train loss: 1.4276806723501068e-05 \n",
      "epoch: 47 [537724/888800 60.50%] train loss: 1.3946679246146232e-05 \n",
      "epoch: 47 [538835/888800 60.62%] train loss: 1.5454881577170454e-05 \n",
      "epoch: 47 [539946/888800 60.75%] train loss: 1.3924511222285219e-05 \n",
      "epoch: 47 [541057/888800 60.88%] train loss: 1.436087677575415e-05 \n",
      "epoch: 47 [542168/888800 61.00%] train loss: 1.4818482668488286e-05 \n",
      "epoch: 47 [543279/888800 61.12%] train loss: 1.5112476830836385e-05 \n",
      "epoch: 47 [544390/888800 61.25%] train loss: 1.3274525372253265e-05 \n",
      "epoch: 47 [545501/888800 61.38%] train loss: 1.4989190276537556e-05 \n",
      "epoch: 47 [546612/888800 61.50%] train loss: 1.3554046745412052e-05 \n",
      "epoch: 47 [547723/888800 61.62%] train loss: 1.4700766769237816e-05 \n",
      "epoch: 47 [548834/888800 61.75%] train loss: 1.3367249266593717e-05 \n",
      "epoch: 47 [549945/888800 61.88%] train loss: 1.563289697514847e-05 \n",
      "epoch: 47 [551056/888800 62.00%] train loss: 1.5548350347671658e-05 \n",
      "epoch: 47 [552167/888800 62.12%] train loss: 1.5071730558702257e-05 \n",
      "epoch: 47 [553278/888800 62.25%] train loss: 1.532191163278185e-05 \n",
      "epoch: 47 [554389/888800 62.38%] train loss: 1.474530654377304e-05 \n",
      "epoch: 47 [555500/888800 62.50%] train loss: 1.5443638403667137e-05 \n",
      "epoch: 47 [556611/888800 62.62%] train loss: 1.3398779628914781e-05 \n",
      "epoch: 47 [557722/888800 62.75%] train loss: 1.3777811545878649e-05 \n",
      "epoch: 47 [558833/888800 62.88%] train loss: 1.603342934686225e-05 \n",
      "epoch: 47 [559944/888800 63.00%] train loss: 1.4613707207900006e-05 \n",
      "epoch: 47 [561055/888800 63.12%] train loss: 1.251686171599431e-05 \n",
      "epoch: 47 [562166/888800 63.25%] train loss: 1.3857421436114237e-05 \n",
      "epoch: 47 [563277/888800 63.38%] train loss: 1.4850107618258335e-05 \n",
      "epoch: 47 [564388/888800 63.50%] train loss: 1.570987114973832e-05 \n",
      "epoch: 47 [565499/888800 63.62%] train loss: 1.3502841284207534e-05 \n",
      "epoch: 47 [566610/888800 63.75%] train loss: 1.4714119060954545e-05 \n",
      "epoch: 47 [567721/888800 63.88%] train loss: 1.3361275705392472e-05 \n",
      "epoch: 47 [568832/888800 64.00%] train loss: 1.529573455627542e-05 \n",
      "epoch: 47 [569943/888800 64.12%] train loss: 1.49420175148407e-05 \n",
      "epoch: 47 [571054/888800 64.25%] train loss: 1.4538547475240193e-05 \n",
      "epoch: 47 [572165/888800 64.38%] train loss: 1.4088974239712115e-05 \n",
      "epoch: 47 [573276/888800 64.50%] train loss: 1.3642806152347475e-05 \n",
      "epoch: 47 [574387/888800 64.62%] train loss: 1.5351646652561612e-05 \n",
      "epoch: 47 [575498/888800 64.75%] train loss: 1.3755675354332197e-05 \n",
      "epoch: 47 [576609/888800 64.88%] train loss: 1.5431043721036986e-05 \n",
      "epoch: 47 [577720/888800 65.00%] train loss: 1.3266539099276997e-05 \n",
      "epoch: 47 [578831/888800 65.12%] train loss: 1.5454563254024833e-05 \n",
      "epoch: 47 [579942/888800 65.25%] train loss: 1.5012239600764588e-05 \n",
      "epoch: 47 [581053/888800 65.38%] train loss: 1.4170838767313398e-05 \n",
      "epoch: 47 [582164/888800 65.50%] train loss: 1.5693954992457293e-05 \n",
      "epoch: 47 [583275/888800 65.62%] train loss: 1.4070901670493186e-05 \n",
      "epoch: 47 [584386/888800 65.75%] train loss: 1.4925075447536074e-05 \n",
      "epoch: 47 [585497/888800 65.88%] train loss: 1.4037500477570575e-05 \n",
      "epoch: 47 [586608/888800 66.00%] train loss: 1.380984303978039e-05 \n",
      "epoch: 47 [587719/888800 66.12%] train loss: 1.4710421964991838e-05 \n",
      "epoch: 47 [588830/888800 66.25%] train loss: 1.5225986317091156e-05 \n",
      "epoch: 47 [589941/888800 66.38%] train loss: 1.367592176393373e-05 \n",
      "epoch: 47 [591052/888800 66.50%] train loss: 1.292322212975705e-05 \n",
      "epoch: 47 [592163/888800 66.62%] train loss: 1.3956581824459136e-05 \n",
      "epoch: 47 [593274/888800 66.75%] train loss: 1.334449461865006e-05 \n",
      "epoch: 47 [594385/888800 66.88%] train loss: 1.5097042705747299e-05 \n",
      "epoch: 47 [595496/888800 67.00%] train loss: 1.313220855081454e-05 \n",
      "epoch: 47 [596607/888800 67.12%] train loss: 1.3751749065704644e-05 \n",
      "epoch: 47 [597718/888800 67.25%] train loss: 1.4135001038084738e-05 \n",
      "epoch: 47 [598829/888800 67.38%] train loss: 1.3101177501084749e-05 \n",
      "epoch: 47 [599940/888800 67.50%] train loss: 1.3459905858326238e-05 \n",
      "epoch: 47 [601051/888800 67.62%] train loss: 1.3122122254571877e-05 \n",
      "epoch: 47 [602162/888800 67.75%] train loss: 1.397932464897167e-05 \n",
      "epoch: 47 [603273/888800 67.88%] train loss: 1.4764197658223566e-05 \n",
      "epoch: 47 [604384/888800 68.00%] train loss: 1.4379686035681516e-05 \n",
      "epoch: 47 [605495/888800 68.12%] train loss: 1.3495151506504044e-05 \n",
      "epoch: 47 [606606/888800 68.25%] train loss: 1.4118790204520337e-05 \n",
      "epoch: 47 [607717/888800 68.38%] train loss: 1.4026349163032137e-05 \n",
      "epoch: 47 [608828/888800 68.50%] train loss: 1.3573404430644587e-05 \n",
      "epoch: 47 [609939/888800 68.62%] train loss: 1.4738898244104348e-05 \n",
      "epoch: 47 [611050/888800 68.75%] train loss: 1.3730691534874495e-05 \n",
      "epoch: 47 [612161/888800 68.88%] train loss: 1.5424544471898116e-05 \n",
      "epoch: 47 [613272/888800 69.00%] train loss: 1.4518095667881425e-05 \n",
      "epoch: 47 [614383/888800 69.12%] train loss: 1.3594014490081463e-05 \n",
      "epoch: 47 [615494/888800 69.25%] train loss: 1.395484468957875e-05 \n",
      "epoch: 47 [616605/888800 69.38%] train loss: 1.4545357771567069e-05 \n",
      "epoch: 47 [617716/888800 69.50%] train loss: 1.4252250366553199e-05 \n",
      "epoch: 47 [618827/888800 69.62%] train loss: 1.5095867638592608e-05 \n",
      "epoch: 47 [619938/888800 69.75%] train loss: 1.5816582163097337e-05 \n",
      "epoch: 47 [621049/888800 69.88%] train loss: 1.5515952327405103e-05 \n",
      "epoch: 47 [622160/888800 70.00%] train loss: 1.369826259178808e-05 \n",
      "epoch: 47 [623271/888800 70.12%] train loss: 1.3676438356924336e-05 \n",
      "epoch: 47 [624382/888800 70.25%] train loss: 1.4008373000251595e-05 \n",
      "epoch: 47 [625493/888800 70.38%] train loss: 1.4252813343773596e-05 \n",
      "epoch: 47 [626604/888800 70.50%] train loss: 1.4790928617003374e-05 \n",
      "epoch: 47 [627715/888800 70.62%] train loss: 1.3550572475651279e-05 \n",
      "epoch: 47 [628826/888800 70.75%] train loss: 1.5083985999808647e-05 \n",
      "epoch: 47 [629937/888800 70.88%] train loss: 1.4154936252452899e-05 \n",
      "epoch: 47 [631048/888800 71.00%] train loss: 1.3880339793104213e-05 \n",
      "epoch: 47 [632159/888800 71.12%] train loss: 1.4307090168586e-05 \n",
      "epoch: 47 [633270/888800 71.25%] train loss: 1.4089753676671535e-05 \n",
      "epoch: 47 [634381/888800 71.38%] train loss: 1.4298391761258245e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [635492/888800 71.50%] train loss: 1.4107133210927714e-05 \n",
      "epoch: 47 [636603/888800 71.62%] train loss: 1.3290591596160084e-05 \n",
      "epoch: 47 [637714/888800 71.75%] train loss: 1.568108746141661e-05 \n",
      "epoch: 47 [638825/888800 71.88%] train loss: 1.4045333955436945e-05 \n",
      "epoch: 47 [639936/888800 72.00%] train loss: 1.4991122043284122e-05 \n",
      "epoch: 47 [641047/888800 72.12%] train loss: 1.4971593373047654e-05 \n",
      "epoch: 47 [642158/888800 72.25%] train loss: 1.585933205205947e-05 \n",
      "epoch: 47 [643269/888800 72.38%] train loss: 1.4456460121436976e-05 \n",
      "epoch: 47 [644380/888800 72.50%] train loss: 1.394765331497183e-05 \n",
      "epoch: 47 [645491/888800 72.62%] train loss: 1.4571379324479494e-05 \n",
      "epoch: 47 [646602/888800 72.75%] train loss: 1.4821341210335959e-05 \n",
      "epoch: 47 [647713/888800 72.88%] train loss: 1.3763698916591238e-05 \n",
      "epoch: 47 [648824/888800 73.00%] train loss: 1.479573347751284e-05 \n",
      "epoch: 47 [649935/888800 73.12%] train loss: 1.3993634638609365e-05 \n",
      "epoch: 47 [651046/888800 73.25%] train loss: 1.571226675878279e-05 \n",
      "epoch: 47 [652157/888800 73.38%] train loss: 1.3804504305880982e-05 \n",
      "epoch: 47 [653268/888800 73.50%] train loss: 1.4315663975139614e-05 \n",
      "epoch: 47 [654379/888800 73.62%] train loss: 1.3816208593198098e-05 \n",
      "epoch: 47 [655490/888800 73.75%] train loss: 1.4453875337494537e-05 \n",
      "epoch: 47 [656601/888800 73.88%] train loss: 1.3909946574131027e-05 \n",
      "epoch: 47 [657712/888800 74.00%] train loss: 1.4125302186585031e-05 \n",
      "epoch: 47 [658823/888800 74.12%] train loss: 1.4356162864714861e-05 \n",
      "epoch: 47 [659934/888800 74.25%] train loss: 1.4382462723006029e-05 \n",
      "epoch: 47 [661045/888800 74.38%] train loss: 1.4342921531351749e-05 \n",
      "epoch: 47 [662156/888800 74.50%] train loss: 1.5235522369039245e-05 \n",
      "epoch: 47 [663267/888800 74.62%] train loss: 1.5125121535675135e-05 \n",
      "epoch: 47 [664378/888800 74.75%] train loss: 1.5120665011636447e-05 \n",
      "epoch: 47 [665489/888800 74.88%] train loss: 1.4738206118636299e-05 \n",
      "epoch: 47 [666600/888800 75.00%] train loss: 1.475626413594e-05 \n",
      "epoch: 47 [667711/888800 75.12%] train loss: 1.4074345017434098e-05 \n",
      "epoch: 47 [668822/888800 75.25%] train loss: 1.3898374163545668e-05 \n",
      "epoch: 47 [669933/888800 75.38%] train loss: 1.3912428585172165e-05 \n",
      "epoch: 47 [671044/888800 75.50%] train loss: 1.5331112081184983e-05 \n",
      "epoch: 47 [672155/888800 75.62%] train loss: 1.3407343431026675e-05 \n",
      "epoch: 47 [673266/888800 75.75%] train loss: 1.4874471162329428e-05 \n",
      "epoch: 47 [674377/888800 75.88%] train loss: 1.5241596884152386e-05 \n",
      "epoch: 47 [675488/888800 76.00%] train loss: 1.3177212167647667e-05 \n",
      "epoch: 47 [676599/888800 76.12%] train loss: 1.3931392459198833e-05 \n",
      "epoch: 47 [677710/888800 76.25%] train loss: 1.4381975233845878e-05 \n",
      "epoch: 47 [678821/888800 76.38%] train loss: 1.4648461728938855e-05 \n",
      "epoch: 47 [679932/888800 76.50%] train loss: 1.4207314961822703e-05 \n",
      "epoch: 47 [681043/888800 76.62%] train loss: 1.4361556168296374e-05 \n",
      "epoch: 47 [682154/888800 76.75%] train loss: 1.5142229131015483e-05 \n",
      "epoch: 47 [683265/888800 76.88%] train loss: 1.3937795301899314e-05 \n",
      "epoch: 47 [684376/888800 77.00%] train loss: 1.3124927136232145e-05 \n",
      "epoch: 47 [685487/888800 77.12%] train loss: 1.4545397789333947e-05 \n",
      "epoch: 47 [686598/888800 77.25%] train loss: 1.4056213331059553e-05 \n",
      "epoch: 47 [687709/888800 77.38%] train loss: 1.4644535440311301e-05 \n",
      "epoch: 47 [688820/888800 77.50%] train loss: 1.4233813089958858e-05 \n",
      "epoch: 47 [689931/888800 77.62%] train loss: 1.271613291464746e-05 \n",
      "epoch: 47 [691042/888800 77.75%] train loss: 1.2607718417712022e-05 \n",
      "epoch: 47 [692153/888800 77.88%] train loss: 1.4183005077939015e-05 \n",
      "epoch: 47 [693264/888800 78.00%] train loss: 1.4480567188002169e-05 \n",
      "epoch: 47 [694375/888800 78.12%] train loss: 1.4590345017495565e-05 \n",
      "epoch: 47 [695486/888800 78.25%] train loss: 1.3436374501907267e-05 \n",
      "epoch: 47 [696597/888800 78.38%] train loss: 1.4151723917166237e-05 \n",
      "epoch: 47 [697708/888800 78.50%] train loss: 1.3205605682742316e-05 \n",
      "epoch: 47 [698819/888800 78.62%] train loss: 1.3262182619655505e-05 \n",
      "epoch: 47 [699930/888800 78.75%] train loss: 1.3982051314087585e-05 \n",
      "epoch: 47 [701041/888800 78.88%] train loss: 1.3469611985783558e-05 \n",
      "epoch: 47 [702152/888800 79.00%] train loss: 1.4603721865569241e-05 \n",
      "epoch: 47 [703263/888800 79.12%] train loss: 1.5377128875115886e-05 \n",
      "epoch: 47 [704374/888800 79.25%] train loss: 1.3948305422673002e-05 \n",
      "epoch: 47 [705485/888800 79.38%] train loss: 1.3277103789732791e-05 \n",
      "epoch: 47 [706596/888800 79.50%] train loss: 1.539342883916106e-05 \n",
      "epoch: 47 [707707/888800 79.62%] train loss: 1.5196572348941118e-05 \n",
      "epoch: 47 [708818/888800 79.75%] train loss: 1.5227743460854981e-05 \n",
      "epoch: 47 [709929/888800 79.88%] train loss: 1.3570305782195646e-05 \n",
      "epoch: 47 [711040/888800 80.00%] train loss: 1.499358313594712e-05 \n",
      "epoch: 47 [712151/888800 80.12%] train loss: 1.594555033079814e-05 \n",
      "epoch: 47 [713262/888800 80.25%] train loss: 1.3897353710490279e-05 \n",
      "epoch: 47 [714373/888800 80.38%] train loss: 1.5375051589217037e-05 \n",
      "epoch: 47 [715484/888800 80.50%] train loss: 1.536441959615331e-05 \n",
      "epoch: 47 [716595/888800 80.62%] train loss: 1.4889177691657096e-05 \n",
      "epoch: 47 [717706/888800 80.75%] train loss: 1.466081175749423e-05 \n",
      "epoch: 47 [718817/888800 80.88%] train loss: 1.4561046555172652e-05 \n",
      "epoch: 47 [719928/888800 81.00%] train loss: 1.3355594091990497e-05 \n",
      "epoch: 47 [721039/888800 81.12%] train loss: 1.325857374467887e-05 \n",
      "epoch: 47 [722150/888800 81.25%] train loss: 1.5006677131168544e-05 \n",
      "epoch: 47 [723261/888800 81.38%] train loss: 1.418090960214613e-05 \n",
      "epoch: 47 [724372/888800 81.50%] train loss: 1.3722346920985729e-05 \n",
      "epoch: 47 [725483/888800 81.62%] train loss: 1.4689869203721173e-05 \n",
      "epoch: 47 [726594/888800 81.75%] train loss: 1.4796206414757762e-05 \n",
      "epoch: 47 [727705/888800 81.88%] train loss: 1.3792467143503018e-05 \n",
      "epoch: 47 [728816/888800 82.00%] train loss: 1.682558468019124e-05 \n",
      "epoch: 47 [729927/888800 82.12%] train loss: 1.4066741641727276e-05 \n",
      "epoch: 47 [731038/888800 82.25%] train loss: 1.541721576359123e-05 \n",
      "epoch: 47 [732149/888800 82.38%] train loss: 1.3358568139665294e-05 \n",
      "epoch: 47 [733260/888800 82.50%] train loss: 1.4214400835044216e-05 \n",
      "epoch: 47 [734371/888800 82.62%] train loss: 1.4129434930509888e-05 \n",
      "epoch: 47 [735482/888800 82.75%] train loss: 1.536657327960711e-05 \n",
      "epoch: 47 [736593/888800 82.88%] train loss: 1.4049468518351205e-05 \n",
      "epoch: 47 [737704/888800 83.00%] train loss: 1.4244006706576329e-05 \n",
      "epoch: 47 [738815/888800 83.12%] train loss: 1.395134131598752e-05 \n",
      "epoch: 47 [739926/888800 83.25%] train loss: 1.4325052688946016e-05 \n",
      "epoch: 47 [741037/888800 83.38%] train loss: 1.4129377632343676e-05 \n",
      "epoch: 47 [742148/888800 83.50%] train loss: 1.4083520909480285e-05 \n",
      "epoch: 47 [743259/888800 83.62%] train loss: 1.5645602616132237e-05 \n",
      "epoch: 47 [744370/888800 83.75%] train loss: 1.3854626558895689e-05 \n",
      "epoch: 47 [745481/888800 83.88%] train loss: 1.5201871974568348e-05 \n",
      "epoch: 47 [746592/888800 84.00%] train loss: 1.3109316569170915e-05 \n",
      "epoch: 47 [747703/888800 84.12%] train loss: 1.4275758985604625e-05 \n",
      "epoch: 47 [748814/888800 84.25%] train loss: 1.3886730812373571e-05 \n",
      "epoch: 47 [749925/888800 84.38%] train loss: 1.4830706277280115e-05 \n",
      "epoch: 47 [751036/888800 84.50%] train loss: 1.3801910426991526e-05 \n",
      "epoch: 47 [752147/888800 84.62%] train loss: 1.457920552638825e-05 \n",
      "epoch: 47 [753258/888800 84.75%] train loss: 1.4124373592494521e-05 \n",
      "epoch: 47 [754369/888800 84.88%] train loss: 1.3483075235853903e-05 \n",
      "epoch: 47 [755480/888800 85.00%] train loss: 1.4547455066349357e-05 \n",
      "epoch: 47 [756591/888800 85.12%] train loss: 1.4417644706554711e-05 \n",
      "epoch: 47 [757702/888800 85.25%] train loss: 1.3734619642491452e-05 \n",
      "epoch: 47 [758813/888800 85.38%] train loss: 1.3964916433906183e-05 \n",
      "epoch: 47 [759924/888800 85.50%] train loss: 1.4392149751074612e-05 \n",
      "epoch: 47 [761035/888800 85.62%] train loss: 1.274478381674271e-05 \n",
      "epoch: 47 [762146/888800 85.75%] train loss: 1.4602962437493261e-05 \n",
      "epoch: 47 [763257/888800 85.88%] train loss: 1.3769067663815804e-05 \n",
      "epoch: 47 [764368/888800 86.00%] train loss: 1.3357916941458825e-05 \n",
      "epoch: 47 [765479/888800 86.12%] train loss: 1.5050382899062242e-05 \n",
      "epoch: 47 [766590/888800 86.25%] train loss: 1.4359589840751141e-05 \n",
      "epoch: 47 [767701/888800 86.38%] train loss: 1.426454764441587e-05 \n",
      "epoch: 47 [768812/888800 86.50%] train loss: 1.4112158169155009e-05 \n",
      "epoch: 47 [769923/888800 86.62%] train loss: 1.4144875422061887e-05 \n",
      "epoch: 47 [771034/888800 86.75%] train loss: 1.3907222637499217e-05 \n",
      "epoch: 47 [772145/888800 86.88%] train loss: 1.5313096810132265e-05 \n",
      "epoch: 47 [773256/888800 87.00%] train loss: 1.3878054232918657e-05 \n",
      "epoch: 47 [774367/888800 87.12%] train loss: 1.4683284462080337e-05 \n",
      "epoch: 47 [775478/888800 87.25%] train loss: 1.4582788026018534e-05 \n",
      "epoch: 47 [776589/888800 87.38%] train loss: 1.4162803381623235e-05 \n",
      "epoch: 47 [777700/888800 87.50%] train loss: 1.4725332221132703e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 [778811/888800 87.62%] train loss: 1.4227061910787597e-05 \n",
      "epoch: 47 [779922/888800 87.75%] train loss: 1.375534793623956e-05 \n",
      "epoch: 47 [781033/888800 87.88%] train loss: 1.4578826267097611e-05 \n",
      "epoch: 47 [782144/888800 88.00%] train loss: 1.3635217328555882e-05 \n",
      "epoch: 47 [783255/888800 88.12%] train loss: 1.5500487279496156e-05 \n",
      "epoch: 47 [784366/888800 88.25%] train loss: 1.4181610822561197e-05 \n",
      "epoch: 47 [785477/888800 88.38%] train loss: 1.3055298950348515e-05 \n",
      "epoch: 47 [786588/888800 88.50%] train loss: 1.5120370335353073e-05 \n",
      "epoch: 47 [787699/888800 88.62%] train loss: 1.3999451766721904e-05 \n",
      "epoch: 47 [788810/888800 88.75%] train loss: 1.4711121366417501e-05 \n",
      "epoch: 47 [789921/888800 88.88%] train loss: 1.5298302969313227e-05 \n",
      "epoch: 47 [791032/888800 89.00%] train loss: 1.4580002243747003e-05 \n",
      "epoch: 47 [792143/888800 89.12%] train loss: 1.3798502550343983e-05 \n",
      "epoch: 47 [793254/888800 89.25%] train loss: 1.5324234482250176e-05 \n",
      "epoch: 47 [794365/888800 89.38%] train loss: 1.5411780623253435e-05 \n",
      "epoch: 47 [795476/888800 89.50%] train loss: 1.5077835996635258e-05 \n",
      "epoch: 47 [796587/888800 89.62%] train loss: 1.2971117030247115e-05 \n",
      "epoch: 47 [797698/888800 89.75%] train loss: 1.4529584404954221e-05 \n",
      "epoch: 47 [798809/888800 89.88%] train loss: 1.4948452189855743e-05 \n",
      "epoch: 47 [799920/888800 90.00%] train loss: 1.565720776852686e-05 \n",
      "epoch: 47 [801031/888800 90.12%] train loss: 1.326403707935242e-05 \n",
      "epoch: 47 [802142/888800 90.25%] train loss: 1.3773396858596243e-05 \n",
      "epoch: 47 [803253/888800 90.38%] train loss: 1.377933585899882e-05 \n",
      "epoch: 47 [804364/888800 90.50%] train loss: 1.3532851880881935e-05 \n",
      "epoch: 47 [805475/888800 90.62%] train loss: 1.554064692754764e-05 \n",
      "epoch: 47 [806586/888800 90.75%] train loss: 1.547457395645324e-05 \n",
      "epoch: 47 [807697/888800 90.88%] train loss: 1.4226397979655303e-05 \n",
      "epoch: 47 [808808/888800 91.00%] train loss: 1.4675601960334461e-05 \n",
      "epoch: 47 [809919/888800 91.12%] train loss: 1.4841065421933308e-05 \n",
      "epoch: 47 [811030/888800 91.25%] train loss: 1.4189916328177787e-05 \n",
      "epoch: 47 [812141/888800 91.38%] train loss: 1.3576529454439878e-05 \n",
      "epoch: 47 [813252/888800 91.50%] train loss: 1.452476135455072e-05 \n",
      "epoch: 47 [814363/888800 91.62%] train loss: 1.4863650903862435e-05 \n",
      "epoch: 47 [815474/888800 91.75%] train loss: 1.3768884855380747e-05 \n",
      "epoch: 47 [816585/888800 91.88%] train loss: 1.5207576325337868e-05 \n",
      "epoch: 47 [817696/888800 92.00%] train loss: 1.5821435226825997e-05 \n",
      "epoch: 47 [818807/888800 92.12%] train loss: 1.3672456589119975e-05 \n",
      "epoch: 47 [819918/888800 92.25%] train loss: 1.4232299690775108e-05 \n",
      "epoch: 47 [821029/888800 92.38%] train loss: 1.357586370431818e-05 \n",
      "epoch: 47 [822140/888800 92.50%] train loss: 1.4856173038424458e-05 \n",
      "epoch: 47 [823251/888800 92.62%] train loss: 1.363097362627741e-05 \n",
      "epoch: 47 [824362/888800 92.75%] train loss: 1.2717021490971092e-05 \n",
      "epoch: 47 [825473/888800 92.88%] train loss: 1.400439487042604e-05 \n",
      "epoch: 47 [826584/888800 93.00%] train loss: 1.4040557289263234e-05 \n",
      "epoch: 47 [827695/888800 93.12%] train loss: 1.4372938494489063e-05 \n",
      "epoch: 47 [828806/888800 93.25%] train loss: 1.3937313269707374e-05 \n",
      "epoch: 47 [829917/888800 93.38%] train loss: 1.4379966160049662e-05 \n",
      "epoch: 47 [831028/888800 93.50%] train loss: 1.335008073510835e-05 \n",
      "epoch: 47 [832139/888800 93.62%] train loss: 1.4078294952923898e-05 \n",
      "epoch: 47 [833250/888800 93.75%] train loss: 1.5179463844106067e-05 \n",
      "epoch: 47 [834361/888800 93.88%] train loss: 1.351781338598812e-05 \n",
      "epoch: 47 [835472/888800 94.00%] train loss: 1.3563388165493961e-05 \n",
      "epoch: 47 [836583/888800 94.12%] train loss: 1.3923964615969453e-05 \n",
      "epoch: 47 [837694/888800 94.25%] train loss: 1.3312103874341119e-05 \n",
      "epoch: 47 [838805/888800 94.38%] train loss: 1.37759907374857e-05 \n",
      "epoch: 47 [839916/888800 94.50%] train loss: 1.3721110008191317e-05 \n",
      "epoch: 47 [841027/888800 94.62%] train loss: 1.3391833817877341e-05 \n",
      "epoch: 47 [842138/888800 94.75%] train loss: 1.3611909707833547e-05 \n",
      "epoch: 47 [843249/888800 94.88%] train loss: 1.3707785001315642e-05 \n",
      "epoch: 47 [844360/888800 95.00%] train loss: 1.2788596905011218e-05 \n",
      "epoch: 47 [845471/888800 95.12%] train loss: 1.4400051441043615e-05 \n",
      "epoch: 47 [846582/888800 95.25%] train loss: 1.4091752746026032e-05 \n",
      "epoch: 47 [847693/888800 95.38%] train loss: 1.3784359907731414e-05 \n",
      "epoch: 47 [848804/888800 95.50%] train loss: 1.3449422112898901e-05 \n",
      "epoch: 47 [849915/888800 95.62%] train loss: 1.5785826690262184e-05 \n",
      "epoch: 47 [851026/888800 95.75%] train loss: 1.4831708540441468e-05 \n",
      "epoch: 47 [852137/888800 95.88%] train loss: 1.6439636965515092e-05 \n",
      "epoch: 47 [853248/888800 96.00%] train loss: 1.543589860375505e-05 \n",
      "epoch: 47 [854359/888800 96.12%] train loss: 1.4792930414841976e-05 \n",
      "epoch: 47 [855470/888800 96.25%] train loss: 1.5676869224989787e-05 \n",
      "epoch: 47 [856581/888800 96.38%] train loss: 1.4249289051804226e-05 \n",
      "epoch: 47 [857692/888800 96.50%] train loss: 1.566663740959484e-05 \n",
      "epoch: 47 [858803/888800 96.62%] train loss: 1.454268567613326e-05 \n",
      "epoch: 47 [859914/888800 96.75%] train loss: 1.4924871720722876e-05 \n",
      "epoch: 47 [861025/888800 96.88%] train loss: 1.2784446880687028e-05 \n",
      "epoch: 47 [862136/888800 97.00%] train loss: 1.6287234757328406e-05 \n",
      "epoch: 47 [863247/888800 97.12%] train loss: 1.4601217117160559e-05 \n",
      "epoch: 47 [864358/888800 97.25%] train loss: 1.4756287782802247e-05 \n",
      "epoch: 47 [865469/888800 97.38%] train loss: 1.3660981494467705e-05 \n",
      "epoch: 47 [866580/888800 97.50%] train loss: 1.537171920062974e-05 \n",
      "epoch: 47 [867691/888800 97.62%] train loss: 1.4348628610605374e-05 \n",
      "epoch: 47 [868802/888800 97.75%] train loss: 1.4607631783292163e-05 \n",
      "epoch: 47 [869913/888800 97.88%] train loss: 1.309197523369221e-05 \n",
      "epoch: 47 [871024/888800 98.00%] train loss: 1.3755301552009769e-05 \n",
      "epoch: 47 [872135/888800 98.12%] train loss: 1.4412839846045244e-05 \n",
      "epoch: 47 [873246/888800 98.25%] train loss: 1.6376929124817252e-05 \n",
      "epoch: 47 [874357/888800 98.38%] train loss: 1.355819586024154e-05 \n",
      "epoch: 47 [875468/888800 98.50%] train loss: 1.4837130947853439e-05 \n",
      "epoch: 47 [876579/888800 98.62%] train loss: 1.4193260540196206e-05 \n",
      "epoch: 47 [877690/888800 98.75%] train loss: 1.527990934846457e-05 \n",
      "epoch: 47 [878801/888800 98.88%] train loss: 1.395506569679128e-05 \n",
      "epoch: 47 [879912/888800 99.00%] train loss: 1.6019821487134323e-05 \n",
      "epoch: 47 [881023/888800 99.12%] train loss: 1.3219647371442989e-05 \n",
      "epoch: 47 [882134/888800 99.25%] train loss: 1.5398392861243337e-05 \n",
      "epoch: 47 [883245/888800 99.38%] train loss: 1.4718902093591169e-05 \n",
      "epoch: 47 [884356/888800 99.50%] train loss: 1.4531961824104656e-05 \n",
      "epoch: 47 [885467/888800 99.62%] train loss: 1.432995850336738e-05 \n",
      "epoch: 47 [886578/888800 99.75%] train loss: 1.3735529137193225e-05 \n",
      "epoch: 47 [887689/888800 99.88%] train loss: 1.4195977200870402e-05 \n",
      "epoch: 48 [0/888800 0.00%] train loss: 1.3828436749463435e-05 \n",
      "epoch: 48 [1111/888800 0.12%] train loss: 1.3124270481057465e-05 \n",
      "epoch: 48 [2222/888800 0.25%] train loss: 1.4734643627889454e-05 \n",
      "epoch: 48 [3333/888800 0.38%] train loss: 1.4155374628899153e-05 \n",
      "epoch: 48 [4444/888800 0.50%] train loss: 1.3372204193728976e-05 \n",
      "epoch: 48 [5555/888800 0.62%] train loss: 1.419987984263571e-05 \n",
      "epoch: 48 [6666/888800 0.75%] train loss: 1.5157404959609266e-05 \n",
      "epoch: 48 [7777/888800 0.88%] train loss: 1.353667084913468e-05 \n",
      "epoch: 48 [8888/888800 1.00%] train loss: 1.3782221685687546e-05 \n",
      "epoch: 48 [9999/888800 1.12%] train loss: 1.466035519115394e-05 \n",
      "epoch: 48 [11110/888800 1.25%] train loss: 1.478942340327194e-05 \n",
      "epoch: 48 [12221/888800 1.38%] train loss: 1.3374254194786772e-05 \n",
      "epoch: 48 [13332/888800 1.50%] train loss: 1.4993031072663143e-05 \n",
      "epoch: 48 [14443/888800 1.62%] train loss: 1.3892007700633258e-05 \n",
      "epoch: 48 [15554/888800 1.75%] train loss: 1.417458952346351e-05 \n",
      "epoch: 48 [16665/888800 1.88%] train loss: 1.5552379409200512e-05 \n",
      "epoch: 48 [17776/888800 2.00%] train loss: 1.3539142855734099e-05 \n",
      "epoch: 48 [18887/888800 2.12%] train loss: 1.4897704204486217e-05 \n",
      "epoch: 48 [19998/888800 2.25%] train loss: 1.4594706954085268e-05 \n",
      "epoch: 48 [21109/888800 2.38%] train loss: 1.4687650036648847e-05 \n",
      "epoch: 48 [22220/888800 2.50%] train loss: 1.369598521705484e-05 \n",
      "epoch: 48 [23331/888800 2.62%] train loss: 1.3910766938352026e-05 \n",
      "epoch: 48 [24442/888800 2.75%] train loss: 1.4617147826356813e-05 \n",
      "epoch: 48 [25553/888800 2.88%] train loss: 1.4087934687267989e-05 \n",
      "epoch: 48 [26664/888800 3.00%] train loss: 1.501536007708637e-05 \n",
      "epoch: 48 [27775/888800 3.12%] train loss: 1.3539277460949961e-05 \n",
      "epoch: 48 [28886/888800 3.25%] train loss: 1.535423143650405e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [29997/888800 3.38%] train loss: 1.431263990525622e-05 \n",
      "epoch: 48 [31108/888800 3.50%] train loss: 1.4191854461387265e-05 \n",
      "epoch: 48 [32219/888800 3.62%] train loss: 1.3938793017587159e-05 \n",
      "epoch: 48 [33330/888800 3.75%] train loss: 1.5055382391437888e-05 \n",
      "epoch: 48 [34441/888800 3.88%] train loss: 1.268533833354013e-05 \n",
      "epoch: 48 [35552/888800 4.00%] train loss: 1.6462277926621027e-05 \n",
      "epoch: 48 [36663/888800 4.12%] train loss: 1.613813583389856e-05 \n",
      "epoch: 48 [37774/888800 4.25%] train loss: 1.4893924344505649e-05 \n",
      "epoch: 48 [38885/888800 4.38%] train loss: 1.5723719116067514e-05 \n",
      "epoch: 48 [39996/888800 4.50%] train loss: 1.2697281817963813e-05 \n",
      "epoch: 48 [41107/888800 4.62%] train loss: 1.4841868505754974e-05 \n",
      "epoch: 48 [42218/888800 4.75%] train loss: 1.591729414940346e-05 \n",
      "epoch: 48 [43329/888800 4.88%] train loss: 1.2804472135030665e-05 \n",
      "epoch: 48 [44440/888800 5.00%] train loss: 1.561850876896642e-05 \n",
      "epoch: 48 [45551/888800 5.12%] train loss: 1.370631707686698e-05 \n",
      "epoch: 48 [46662/888800 5.25%] train loss: 1.4282921256381087e-05 \n",
      "epoch: 48 [47773/888800 5.38%] train loss: 1.4382913832378108e-05 \n",
      "epoch: 48 [48884/888800 5.50%] train loss: 1.3780221706838347e-05 \n",
      "epoch: 48 [49995/888800 5.62%] train loss: 1.4076333172852173e-05 \n",
      "epoch: 48 [51106/888800 5.75%] train loss: 1.5422958313138224e-05 \n",
      "epoch: 48 [52217/888800 5.88%] train loss: 1.2635766324819997e-05 \n",
      "epoch: 48 [53328/888800 6.00%] train loss: 1.503190924267983e-05 \n",
      "epoch: 48 [54439/888800 6.12%] train loss: 1.4346668649523053e-05 \n",
      "epoch: 48 [55550/888800 6.25%] train loss: 1.4138472579361405e-05 \n",
      "epoch: 48 [56661/888800 6.38%] train loss: 1.4978513718233444e-05 \n",
      "epoch: 48 [57772/888800 6.50%] train loss: 1.4153642041492276e-05 \n",
      "epoch: 48 [58883/888800 6.62%] train loss: 1.4065753020986449e-05 \n",
      "epoch: 48 [59994/888800 6.75%] train loss: 1.491729653935181e-05 \n",
      "epoch: 48 [61105/888800 6.88%] train loss: 1.5103068108146545e-05 \n",
      "epoch: 48 [62216/888800 7.00%] train loss: 1.3979415598441847e-05 \n",
      "epoch: 48 [63327/888800 7.12%] train loss: 1.3159939044271596e-05 \n",
      "epoch: 48 [64438/888800 7.25%] train loss: 1.461156443838263e-05 \n",
      "epoch: 48 [65549/888800 7.38%] train loss: 1.4505359104077797e-05 \n",
      "epoch: 48 [66660/888800 7.50%] train loss: 1.3983944882056676e-05 \n",
      "epoch: 48 [67771/888800 7.62%] train loss: 1.440261348761851e-05 \n",
      "epoch: 48 [68882/888800 7.75%] train loss: 1.3237552593636792e-05 \n",
      "epoch: 48 [69993/888800 7.88%] train loss: 1.512148173787864e-05 \n",
      "epoch: 48 [71104/888800 8.00%] train loss: 1.3334913091966882e-05 \n",
      "epoch: 48 [72215/888800 8.12%] train loss: 1.425151276635006e-05 \n",
      "epoch: 48 [73326/888800 8.25%] train loss: 1.4534602996718604e-05 \n",
      "epoch: 48 [74437/888800 8.38%] train loss: 1.4651607671112288e-05 \n",
      "epoch: 48 [75548/888800 8.50%] train loss: 1.37140732476837e-05 \n",
      "epoch: 48 [76659/888800 8.62%] train loss: 1.3386183127295226e-05 \n",
      "epoch: 48 [77770/888800 8.75%] train loss: 1.4253365407057572e-05 \n",
      "epoch: 48 [78881/888800 8.88%] train loss: 1.3974729881738313e-05 \n",
      "epoch: 48 [79992/888800 9.00%] train loss: 1.4897627806931268e-05 \n",
      "epoch: 48 [81103/888800 9.12%] train loss: 1.3175691492506303e-05 \n",
      "epoch: 48 [82214/888800 9.25%] train loss: 1.3448028767015785e-05 \n",
      "epoch: 48 [83325/888800 9.38%] train loss: 1.4124862900644075e-05 \n",
      "epoch: 48 [84436/888800 9.50%] train loss: 1.3829377166985068e-05 \n",
      "epoch: 48 [85547/888800 9.62%] train loss: 1.3771130397799425e-05 \n",
      "epoch: 48 [86658/888800 9.75%] train loss: 1.4206939340510871e-05 \n",
      "epoch: 48 [87769/888800 9.88%] train loss: 1.425778646080289e-05 \n",
      "epoch: 48 [88880/888800 10.00%] train loss: 1.3211769328336231e-05 \n",
      "epoch: 48 [89991/888800 10.12%] train loss: 1.4107711649558041e-05 \n",
      "epoch: 48 [91102/888800 10.25%] train loss: 1.5330306268879212e-05 \n",
      "epoch: 48 [92213/888800 10.38%] train loss: 1.493472791480599e-05 \n",
      "epoch: 48 [93324/888800 10.50%] train loss: 1.3072490219201427e-05 \n",
      "epoch: 48 [94435/888800 10.62%] train loss: 1.3809361917083152e-05 \n",
      "epoch: 48 [95546/888800 10.75%] train loss: 1.4849490071355831e-05 \n",
      "epoch: 48 [96657/888800 10.88%] train loss: 1.5561578038614243e-05 \n",
      "epoch: 48 [97768/888800 11.00%] train loss: 1.4214760994946118e-05 \n",
      "epoch: 48 [98879/888800 11.12%] train loss: 1.5140904906729702e-05 \n",
      "epoch: 48 [99990/888800 11.25%] train loss: 1.4734711839992087e-05 \n",
      "epoch: 48 [101101/888800 11.38%] train loss: 1.3273060176288709e-05 \n",
      "epoch: 48 [102212/888800 11.50%] train loss: 1.3829886484018061e-05 \n",
      "epoch: 48 [103323/888800 11.62%] train loss: 1.3428938473225571e-05 \n",
      "epoch: 48 [104434/888800 11.75%] train loss: 1.3766730262432247e-05 \n",
      "epoch: 48 [105545/888800 11.88%] train loss: 1.2902340131404344e-05 \n",
      "epoch: 48 [106656/888800 12.00%] train loss: 1.6649255485390313e-05 \n",
      "epoch: 48 [107767/888800 12.12%] train loss: 1.2865329154010396e-05 \n",
      "epoch: 48 [108878/888800 12.25%] train loss: 1.4530991393257864e-05 \n",
      "epoch: 48 [109989/888800 12.38%] train loss: 1.4247338185668923e-05 \n",
      "epoch: 48 [111100/888800 12.50%] train loss: 1.5072409041749779e-05 \n",
      "epoch: 48 [112211/888800 12.62%] train loss: 1.3964868230686989e-05 \n",
      "epoch: 48 [113322/888800 12.75%] train loss: 1.3917515389039181e-05 \n",
      "epoch: 48 [114433/888800 12.88%] train loss: 1.3793638572678901e-05 \n",
      "epoch: 48 [115544/888800 13.00%] train loss: 1.3906662388762925e-05 \n",
      "epoch: 48 [116655/888800 13.12%] train loss: 1.4353542610479053e-05 \n",
      "epoch: 48 [117766/888800 13.25%] train loss: 1.4055374776944518e-05 \n",
      "epoch: 48 [118877/888800 13.38%] train loss: 1.3825912901666015e-05 \n",
      "epoch: 48 [119988/888800 13.50%] train loss: 1.3331610716704745e-05 \n",
      "epoch: 48 [121099/888800 13.62%] train loss: 1.4432052012125496e-05 \n",
      "epoch: 48 [122210/888800 13.75%] train loss: 1.5020359569462016e-05 \n",
      "epoch: 48 [123321/888800 13.88%] train loss: 1.4865328921587206e-05 \n",
      "epoch: 48 [124432/888800 14.00%] train loss: 1.388807413604809e-05 \n",
      "epoch: 48 [125543/888800 14.12%] train loss: 1.3919841876486316e-05 \n",
      "epoch: 48 [126654/888800 14.25%] train loss: 1.5388604879262857e-05 \n",
      "epoch: 48 [127765/888800 14.38%] train loss: 1.5154172615439165e-05 \n",
      "epoch: 48 [128876/888800 14.50%] train loss: 1.3084974852972664e-05 \n",
      "epoch: 48 [129987/888800 14.62%] train loss: 1.385233463224722e-05 \n",
      "epoch: 48 [131098/888800 14.75%] train loss: 1.4102529348747339e-05 \n",
      "epoch: 48 [132209/888800 14.88%] train loss: 1.3430464605335146e-05 \n",
      "epoch: 48 [133320/888800 15.00%] train loss: 1.3880686310585588e-05 \n",
      "epoch: 48 [134431/888800 15.12%] train loss: 1.414565667801071e-05 \n",
      "epoch: 48 [135542/888800 15.25%] train loss: 1.374708881485276e-05 \n",
      "epoch: 48 [136653/888800 15.38%] train loss: 1.3766102711088024e-05 \n",
      "epoch: 48 [137764/888800 15.50%] train loss: 1.4236311471904628e-05 \n",
      "epoch: 48 [138875/888800 15.62%] train loss: 1.5201263522612862e-05 \n",
      "epoch: 48 [139986/888800 15.75%] train loss: 1.3623076483781915e-05 \n",
      "epoch: 48 [141097/888800 15.88%] train loss: 1.496208096796181e-05 \n",
      "epoch: 48 [142208/888800 16.00%] train loss: 1.4750461559742689e-05 \n",
      "epoch: 48 [143319/888800 16.12%] train loss: 1.328739836026216e-05 \n",
      "epoch: 48 [144430/888800 16.25%] train loss: 1.3792679965263233e-05 \n",
      "epoch: 48 [145541/888800 16.38%] train loss: 1.417836483597057e-05 \n",
      "epoch: 48 [146652/888800 16.50%] train loss: 1.4853018001304008e-05 \n",
      "epoch: 48 [147763/888800 16.62%] train loss: 1.4504480532195885e-05 \n",
      "epoch: 48 [148874/888800 16.75%] train loss: 1.3865190339856781e-05 \n",
      "epoch: 48 [149985/888800 16.88%] train loss: 1.3588283763965592e-05 \n",
      "epoch: 48 [151096/888800 17.00%] train loss: 1.4176285731082316e-05 \n",
      "epoch: 48 [152207/888800 17.12%] train loss: 1.5093602087290492e-05 \n",
      "epoch: 48 [153318/888800 17.25%] train loss: 1.3757522538071498e-05 \n",
      "epoch: 48 [154429/888800 17.38%] train loss: 1.42808758027968e-05 \n",
      "epoch: 48 [155540/888800 17.50%] train loss: 1.4769168956263456e-05 \n",
      "epoch: 48 [156651/888800 17.62%] train loss: 1.4241959434002638e-05 \n",
      "epoch: 48 [157762/888800 17.75%] train loss: 1.2942552530148532e-05 \n",
      "epoch: 48 [158873/888800 17.88%] train loss: 1.3708904589293525e-05 \n",
      "epoch: 48 [159984/888800 18.00%] train loss: 1.3877152014174499e-05 \n",
      "epoch: 48 [161095/888800 18.12%] train loss: 1.4390847354661673e-05 \n",
      "epoch: 48 [162206/888800 18.25%] train loss: 1.3803003639623057e-05 \n",
      "epoch: 48 [163317/888800 18.38%] train loss: 1.3624863640870899e-05 \n",
      "epoch: 48 [164428/888800 18.50%] train loss: 1.4550722880812827e-05 \n",
      "epoch: 48 [165539/888800 18.62%] train loss: 1.3690387277165428e-05 \n",
      "epoch: 48 [166650/888800 18.75%] train loss: 1.589362545928452e-05 \n",
      "epoch: 48 [167761/888800 18.88%] train loss: 1.406697447237093e-05 \n",
      "epoch: 48 [168872/888800 19.00%] train loss: 1.4236217793950345e-05 \n",
      "epoch: 48 [169983/888800 19.12%] train loss: 1.4907756849424914e-05 \n",
      "epoch: 48 [171094/888800 19.25%] train loss: 1.4301506780611817e-05 \n",
      "epoch: 48 [172205/888800 19.38%] train loss: 1.4336835192807484e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [173316/888800 19.50%] train loss: 1.4231328350433614e-05 \n",
      "epoch: 48 [174427/888800 19.62%] train loss: 1.4375023965840228e-05 \n",
      "epoch: 48 [175538/888800 19.75%] train loss: 1.4254717825679109e-05 \n",
      "epoch: 48 [176649/888800 19.88%] train loss: 1.4077458217798267e-05 \n",
      "epoch: 48 [177760/888800 20.00%] train loss: 1.431551299901912e-05 \n",
      "epoch: 48 [178871/888800 20.12%] train loss: 1.3815328202326782e-05 \n",
      "epoch: 48 [179982/888800 20.25%] train loss: 1.3660039257956669e-05 \n",
      "epoch: 48 [181093/888800 20.38%] train loss: 1.3660404874826781e-05 \n",
      "epoch: 48 [182204/888800 20.50%] train loss: 1.4196234587871004e-05 \n",
      "epoch: 48 [183315/888800 20.62%] train loss: 1.3800507986161392e-05 \n",
      "epoch: 48 [184426/888800 20.75%] train loss: 1.3514501915778965e-05 \n",
      "epoch: 48 [185537/888800 20.88%] train loss: 1.46933198266197e-05 \n",
      "epoch: 48 [186648/888800 21.00%] train loss: 1.392364993080264e-05 \n",
      "epoch: 48 [187759/888800 21.12%] train loss: 1.478715603298042e-05 \n",
      "epoch: 48 [188870/888800 21.25%] train loss: 1.4126995665719733e-05 \n",
      "epoch: 48 [189981/888800 21.38%] train loss: 1.4719195860379841e-05 \n",
      "epoch: 48 [191092/888800 21.50%] train loss: 1.4421980267798062e-05 \n",
      "epoch: 48 [192203/888800 21.62%] train loss: 1.4788000953558367e-05 \n",
      "epoch: 48 [193314/888800 21.75%] train loss: 1.3334637515072245e-05 \n",
      "epoch: 48 [194425/888800 21.88%] train loss: 1.537458592792973e-05 \n",
      "epoch: 48 [195536/888800 22.00%] train loss: 1.3254345503810328e-05 \n",
      "epoch: 48 [196647/888800 22.12%] train loss: 1.3365703125600703e-05 \n",
      "epoch: 48 [197758/888800 22.25%] train loss: 1.4288974853116088e-05 \n",
      "epoch: 48 [198869/888800 22.38%] train loss: 1.302555847360054e-05 \n",
      "epoch: 48 [199980/888800 22.50%] train loss: 1.4240981727198232e-05 \n",
      "epoch: 48 [201091/888800 22.62%] train loss: 1.4148347872833256e-05 \n",
      "epoch: 48 [202202/888800 22.75%] train loss: 1.4495617506327108e-05 \n",
      "epoch: 48 [203313/888800 22.88%] train loss: 1.4524075595545582e-05 \n",
      "epoch: 48 [204424/888800 23.00%] train loss: 1.3092319932184182e-05 \n",
      "epoch: 48 [205535/888800 23.12%] train loss: 1.4868938706058543e-05 \n",
      "epoch: 48 [206646/888800 23.25%] train loss: 1.4652720892627258e-05 \n",
      "epoch: 48 [207757/888800 23.38%] train loss: 1.4464125342783518e-05 \n",
      "epoch: 48 [208868/888800 23.50%] train loss: 1.4040568203199655e-05 \n",
      "epoch: 48 [209979/888800 23.62%] train loss: 1.3511618817574345e-05 \n",
      "epoch: 48 [211090/888800 23.75%] train loss: 1.444960344088031e-05 \n",
      "epoch: 48 [212201/888800 23.88%] train loss: 1.4662260582554154e-05 \n",
      "epoch: 48 [213312/888800 24.00%] train loss: 1.4998197002569214e-05 \n",
      "epoch: 48 [214423/888800 24.12%] train loss: 1.476735451433342e-05 \n",
      "epoch: 48 [215534/888800 24.25%] train loss: 1.5642759535694495e-05 \n",
      "epoch: 48 [216645/888800 24.38%] train loss: 1.3634743481816258e-05 \n",
      "epoch: 48 [217756/888800 24.50%] train loss: 1.5240674656524789e-05 \n",
      "epoch: 48 [218867/888800 24.62%] train loss: 1.4384989299287554e-05 \n",
      "epoch: 48 [219978/888800 24.75%] train loss: 1.4634963008575141e-05 \n",
      "epoch: 48 [221089/888800 24.88%] train loss: 1.470092774980003e-05 \n",
      "epoch: 48 [222200/888800 25.00%] train loss: 1.584356687089894e-05 \n",
      "epoch: 48 [223311/888800 25.12%] train loss: 1.6023110219975933e-05 \n",
      "epoch: 48 [224422/888800 25.25%] train loss: 1.498303117841715e-05 \n",
      "epoch: 48 [225533/888800 25.38%] train loss: 1.626549601496663e-05 \n",
      "epoch: 48 [226644/888800 25.50%] train loss: 1.5450443243025802e-05 \n",
      "epoch: 48 [227755/888800 25.62%] train loss: 1.8596132576931268e-05 \n",
      "epoch: 48 [228866/888800 25.75%] train loss: 1.3778342690784484e-05 \n",
      "epoch: 48 [229977/888800 25.88%] train loss: 1.5649988199584186e-05 \n",
      "epoch: 48 [231088/888800 26.00%] train loss: 1.401175632054219e-05 \n",
      "epoch: 48 [232199/888800 26.12%] train loss: 1.664945921220351e-05 \n",
      "epoch: 48 [233310/888800 26.25%] train loss: 1.427362258255016e-05 \n",
      "epoch: 48 [234421/888800 26.38%] train loss: 1.4391467630048282e-05 \n",
      "epoch: 48 [235532/888800 26.50%] train loss: 1.4375924365594983e-05 \n",
      "epoch: 48 [236643/888800 26.62%] train loss: 1.473923748562811e-05 \n",
      "epoch: 48 [237754/888800 26.75%] train loss: 1.50580563058611e-05 \n",
      "epoch: 48 [238865/888800 26.88%] train loss: 1.3389758350967895e-05 \n",
      "epoch: 48 [239976/888800 27.00%] train loss: 1.4765402738703415e-05 \n",
      "epoch: 48 [241087/888800 27.12%] train loss: 1.447471458959626e-05 \n",
      "epoch: 48 [242198/888800 27.25%] train loss: 1.5437939509865828e-05 \n",
      "epoch: 48 [243309/888800 27.38%] train loss: 1.337636149401078e-05 \n",
      "epoch: 48 [244420/888800 27.50%] train loss: 1.3417902664514259e-05 \n",
      "epoch: 48 [245531/888800 27.62%] train loss: 1.4865398952679243e-05 \n",
      "epoch: 48 [246642/888800 27.75%] train loss: 1.3840025530953426e-05 \n",
      "epoch: 48 [247753/888800 27.88%] train loss: 1.5033853742352221e-05 \n",
      "epoch: 48 [248864/888800 28.00%] train loss: 1.3963077435619198e-05 \n",
      "epoch: 48 [249975/888800 28.12%] train loss: 1.2931364835822023e-05 \n",
      "epoch: 48 [251086/888800 28.25%] train loss: 1.4667177310911939e-05 \n",
      "epoch: 48 [252197/888800 28.38%] train loss: 1.3649768334289547e-05 \n",
      "epoch: 48 [253308/888800 28.50%] train loss: 1.4025952623342164e-05 \n",
      "epoch: 48 [254419/888800 28.62%] train loss: 1.3902876162319444e-05 \n",
      "epoch: 48 [255530/888800 28.75%] train loss: 1.4317682143882848e-05 \n",
      "epoch: 48 [256641/888800 28.88%] train loss: 1.2890807738585863e-05 \n",
      "epoch: 48 [257752/888800 29.00%] train loss: 1.3732639672525693e-05 \n",
      "epoch: 48 [258863/888800 29.12%] train loss: 1.574706766405143e-05 \n",
      "epoch: 48 [259974/888800 29.25%] train loss: 1.4610942344006617e-05 \n",
      "epoch: 48 [261085/888800 29.38%] train loss: 1.3644706086779479e-05 \n",
      "epoch: 48 [262196/888800 29.50%] train loss: 1.3787823263555765e-05 \n",
      "epoch: 48 [263307/888800 29.62%] train loss: 1.2599611181940418e-05 \n",
      "epoch: 48 [264418/888800 29.75%] train loss: 1.3694210792891681e-05 \n",
      "epoch: 48 [265529/888800 29.88%] train loss: 1.4631931662734132e-05 \n",
      "epoch: 48 [266640/888800 30.00%] train loss: 1.3586705790658016e-05 \n",
      "epoch: 48 [267751/888800 30.12%] train loss: 1.376315594825428e-05 \n",
      "epoch: 48 [268862/888800 30.25%] train loss: 1.3590733033197466e-05 \n",
      "epoch: 48 [269973/888800 30.38%] train loss: 1.3741000657319091e-05 \n",
      "epoch: 48 [271084/888800 30.50%] train loss: 1.3967990525998175e-05 \n",
      "epoch: 48 [272195/888800 30.62%] train loss: 1.3838306585967075e-05 \n",
      "epoch: 48 [273306/888800 30.75%] train loss: 1.3442355339066125e-05 \n",
      "epoch: 48 [274417/888800 30.88%] train loss: 1.3877724086341914e-05 \n",
      "epoch: 48 [275528/888800 31.00%] train loss: 1.36007020046236e-05 \n",
      "epoch: 48 [276639/888800 31.12%] train loss: 1.3763188690063544e-05 \n",
      "epoch: 48 [277750/888800 31.25%] train loss: 1.4892829312884714e-05 \n",
      "epoch: 48 [278861/888800 31.38%] train loss: 1.4335960258904379e-05 \n",
      "epoch: 48 [279972/888800 31.50%] train loss: 1.3327542546903715e-05 \n",
      "epoch: 48 [281083/888800 31.62%] train loss: 1.3729073543800041e-05 \n",
      "epoch: 48 [282194/888800 31.75%] train loss: 1.3644189493788872e-05 \n",
      "epoch: 48 [283305/888800 31.88%] train loss: 1.354483265458839e-05 \n",
      "epoch: 48 [284416/888800 32.00%] train loss: 1.3127276361046825e-05 \n",
      "epoch: 48 [285527/888800 32.12%] train loss: 1.4394394383998588e-05 \n",
      "epoch: 48 [286638/888800 32.25%] train loss: 1.4787642612645868e-05 \n",
      "epoch: 48 [287749/888800 32.38%] train loss: 1.3863184904039372e-05 \n",
      "epoch: 48 [288860/888800 32.50%] train loss: 1.4546586498909164e-05 \n",
      "epoch: 48 [289971/888800 32.62%] train loss: 1.4086415831116028e-05 \n",
      "epoch: 48 [291082/888800 32.75%] train loss: 1.3432400010060519e-05 \n",
      "epoch: 48 [292193/888800 32.88%] train loss: 1.4916703548806254e-05 \n",
      "epoch: 48 [293304/888800 33.00%] train loss: 1.4004778677190188e-05 \n",
      "epoch: 48 [294415/888800 33.12%] train loss: 1.4407452908926643e-05 \n",
      "epoch: 48 [295526/888800 33.25%] train loss: 1.3648269487021025e-05 \n",
      "epoch: 48 [296637/888800 33.38%] train loss: 1.3251958989712875e-05 \n",
      "epoch: 48 [297748/888800 33.50%] train loss: 1.3415393368632067e-05 \n",
      "epoch: 48 [298859/888800 33.62%] train loss: 1.4750745322089642e-05 \n",
      "epoch: 48 [299970/888800 33.75%] train loss: 1.3846217370883096e-05 \n",
      "epoch: 48 [301081/888800 33.88%] train loss: 1.4239503798307851e-05 \n",
      "epoch: 48 [302192/888800 34.00%] train loss: 1.4801690667809453e-05 \n",
      "epoch: 48 [303303/888800 34.12%] train loss: 1.4218146134226117e-05 \n",
      "epoch: 48 [304414/888800 34.25%] train loss: 1.4423508218897041e-05 \n",
      "epoch: 48 [305525/888800 34.38%] train loss: 1.3106086043990217e-05 \n",
      "epoch: 48 [306636/888800 34.50%] train loss: 1.3300174032337964e-05 \n",
      "epoch: 48 [307747/888800 34.62%] train loss: 1.3780600056634285e-05 \n",
      "epoch: 48 [308858/888800 34.75%] train loss: 1.3967932318337262e-05 \n",
      "epoch: 48 [309969/888800 34.88%] train loss: 1.4740370716026518e-05 \n",
      "epoch: 48 [311080/888800 35.00%] train loss: 1.5427925973199308e-05 \n",
      "epoch: 48 [312191/888800 35.12%] train loss: 1.3869476788386237e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [313302/888800 35.25%] train loss: 1.3812334145768546e-05 \n",
      "epoch: 48 [314413/888800 35.38%] train loss: 1.4215540431905538e-05 \n",
      "epoch: 48 [315524/888800 35.50%] train loss: 1.388736654917011e-05 \n",
      "epoch: 48 [316635/888800 35.62%] train loss: 1.5755011190776713e-05 \n",
      "epoch: 48 [317746/888800 35.75%] train loss: 1.5875832104939036e-05 \n",
      "epoch: 48 [318857/888800 35.88%] train loss: 1.4057236512599047e-05 \n",
      "epoch: 48 [319968/888800 36.00%] train loss: 1.4934360478946473e-05 \n",
      "epoch: 48 [321079/888800 36.12%] train loss: 1.5175464795902371e-05 \n",
      "epoch: 48 [322190/888800 36.25%] train loss: 1.4877830835757777e-05 \n",
      "epoch: 48 [323301/888800 36.38%] train loss: 1.4668024050479289e-05 \n",
      "epoch: 48 [324412/888800 36.50%] train loss: 1.4339051631395705e-05 \n",
      "epoch: 48 [325523/888800 36.62%] train loss: 1.4517017007165123e-05 \n",
      "epoch: 48 [326634/888800 36.75%] train loss: 1.3660983313457109e-05 \n",
      "epoch: 48 [327745/888800 36.88%] train loss: 1.3467336430039722e-05 \n",
      "epoch: 48 [328856/888800 37.00%] train loss: 1.571748362039216e-05 \n",
      "epoch: 48 [329967/888800 37.12%] train loss: 1.3023392057220917e-05 \n",
      "epoch: 48 [331078/888800 37.25%] train loss: 1.3537613085645717e-05 \n",
      "epoch: 48 [332189/888800 37.38%] train loss: 1.365814205200877e-05 \n",
      "epoch: 48 [333300/888800 37.50%] train loss: 1.4776969692320563e-05 \n",
      "epoch: 48 [334411/888800 37.62%] train loss: 1.3972159649711102e-05 \n",
      "epoch: 48 [335522/888800 37.75%] train loss: 1.4188105524226557e-05 \n",
      "epoch: 48 [336633/888800 37.88%] train loss: 1.5007514775788877e-05 \n",
      "epoch: 48 [337744/888800 38.00%] train loss: 1.510464062448591e-05 \n",
      "epoch: 48 [338855/888800 38.12%] train loss: 1.3745133401243947e-05 \n",
      "epoch: 48 [339966/888800 38.25%] train loss: 1.419934142177226e-05 \n",
      "epoch: 48 [341077/888800 38.38%] train loss: 1.3734947970078792e-05 \n",
      "epoch: 48 [342188/888800 38.50%] train loss: 1.561576391395647e-05 \n",
      "epoch: 48 [343299/888800 38.62%] train loss: 1.4204165381670464e-05 \n",
      "epoch: 48 [344410/888800 38.75%] train loss: 1.4622294656874146e-05 \n",
      "epoch: 48 [345521/888800 38.88%] train loss: 1.4936807929188944e-05 \n",
      "epoch: 48 [346632/888800 39.00%] train loss: 1.353246443613898e-05 \n",
      "epoch: 48 [347743/888800 39.12%] train loss: 1.5054132745717652e-05 \n",
      "epoch: 48 [348854/888800 39.25%] train loss: 1.4721937077410985e-05 \n",
      "epoch: 48 [349965/888800 39.38%] train loss: 1.5116735085030086e-05 \n",
      "epoch: 48 [351076/888800 39.50%] train loss: 1.4266340258473065e-05 \n",
      "epoch: 48 [352187/888800 39.62%] train loss: 1.4637343156209681e-05 \n",
      "epoch: 48 [353298/888800 39.75%] train loss: 1.4498716154776048e-05 \n",
      "epoch: 48 [354409/888800 39.88%] train loss: 1.544067526992876e-05 \n",
      "epoch: 48 [355520/888800 40.00%] train loss: 1.4756240489077754e-05 \n",
      "epoch: 48 [356631/888800 40.12%] train loss: 1.3315735486685298e-05 \n",
      "epoch: 48 [357742/888800 40.25%] train loss: 1.5837280443520285e-05 \n",
      "epoch: 48 [358853/888800 40.38%] train loss: 1.4645431292592548e-05 \n",
      "epoch: 48 [359964/888800 40.50%] train loss: 1.3515536920749582e-05 \n",
      "epoch: 48 [361075/888800 40.62%] train loss: 1.5474897736567073e-05 \n",
      "epoch: 48 [362186/888800 40.75%] train loss: 1.4275024113885593e-05 \n",
      "epoch: 48 [363297/888800 40.88%] train loss: 1.4503896636597347e-05 \n",
      "epoch: 48 [364408/888800 41.00%] train loss: 1.500010330346413e-05 \n",
      "epoch: 48 [365519/888800 41.12%] train loss: 1.5206206626316998e-05 \n",
      "epoch: 48 [366630/888800 41.25%] train loss: 1.4078227650315966e-05 \n",
      "epoch: 48 [367741/888800 41.38%] train loss: 1.3956945622339845e-05 \n",
      "epoch: 48 [368852/888800 41.50%] train loss: 1.3400252100836951e-05 \n",
      "epoch: 48 [369963/888800 41.62%] train loss: 1.3500819477485493e-05 \n",
      "epoch: 48 [371074/888800 41.75%] train loss: 1.4574351553164888e-05 \n",
      "epoch: 48 [372185/888800 41.88%] train loss: 1.3332906746654771e-05 \n",
      "epoch: 48 [373296/888800 42.00%] train loss: 1.4266373000282329e-05 \n",
      "epoch: 48 [374407/888800 42.12%] train loss: 1.5287156202248298e-05 \n",
      "epoch: 48 [375518/888800 42.25%] train loss: 1.3747085176873952e-05 \n",
      "epoch: 48 [376629/888800 42.38%] train loss: 1.3784994735033251e-05 \n",
      "epoch: 48 [377740/888800 42.50%] train loss: 1.40408992592711e-05 \n",
      "epoch: 48 [378851/888800 42.62%] train loss: 1.217567205458181e-05 \n",
      "epoch: 48 [379962/888800 42.75%] train loss: 1.2978428458154667e-05 \n",
      "epoch: 48 [381073/888800 42.88%] train loss: 1.4458807527262252e-05 \n",
      "epoch: 48 [382184/888800 43.00%] train loss: 1.3218041203799658e-05 \n",
      "epoch: 48 [383295/888800 43.12%] train loss: 1.4682241271657404e-05 \n",
      "epoch: 48 [384406/888800 43.25%] train loss: 1.4498125892714597e-05 \n",
      "epoch: 48 [385517/888800 43.38%] train loss: 1.4659448424936272e-05 \n",
      "epoch: 48 [386628/888800 43.50%] train loss: 1.3583427971752826e-05 \n",
      "epoch: 48 [387739/888800 43.62%] train loss: 1.4488343367702328e-05 \n",
      "epoch: 48 [388850/888800 43.75%] train loss: 1.448020339012146e-05 \n",
      "epoch: 48 [389961/888800 43.88%] train loss: 1.5347723092418164e-05 \n",
      "epoch: 48 [391072/888800 44.00%] train loss: 1.4351127902045846e-05 \n",
      "epoch: 48 [392183/888800 44.12%] train loss: 1.437700029782718e-05 \n",
      "epoch: 48 [393294/888800 44.25%] train loss: 1.3458884495776147e-05 \n",
      "epoch: 48 [394405/888800 44.38%] train loss: 1.3305329957802314e-05 \n",
      "epoch: 48 [395516/888800 44.50%] train loss: 1.5703133612987585e-05 \n",
      "epoch: 48 [396627/888800 44.62%] train loss: 1.4839476534689311e-05 \n",
      "epoch: 48 [397738/888800 44.75%] train loss: 1.4505337276204955e-05 \n",
      "epoch: 48 [398849/888800 44.88%] train loss: 1.3573624528362416e-05 \n",
      "epoch: 48 [399960/888800 45.00%] train loss: 1.5422167052747682e-05 \n",
      "epoch: 48 [401071/888800 45.12%] train loss: 1.369835536024766e-05 \n",
      "epoch: 48 [402182/888800 45.25%] train loss: 1.482473271607887e-05 \n",
      "epoch: 48 [403293/888800 45.38%] train loss: 1.336681998509448e-05 \n",
      "epoch: 48 [404404/888800 45.50%] train loss: 1.4816472685197368e-05 \n",
      "epoch: 48 [405515/888800 45.62%] train loss: 1.3988227692607325e-05 \n",
      "epoch: 48 [406626/888800 45.75%] train loss: 1.60463314387016e-05 \n",
      "epoch: 48 [407737/888800 45.88%] train loss: 1.5140240975597408e-05 \n",
      "epoch: 48 [408848/888800 46.00%] train loss: 1.3702259821002372e-05 \n",
      "epoch: 48 [409959/888800 46.12%] train loss: 1.4766301319468766e-05 \n",
      "epoch: 48 [411070/888800 46.25%] train loss: 1.4849302715447266e-05 \n",
      "epoch: 48 [412181/888800 46.38%] train loss: 1.3474678780767135e-05 \n",
      "epoch: 48 [413292/888800 46.50%] train loss: 1.4210302651918028e-05 \n",
      "epoch: 48 [414403/888800 46.62%] train loss: 1.356580378342187e-05 \n",
      "epoch: 48 [415514/888800 46.75%] train loss: 1.4283581549534574e-05 \n",
      "epoch: 48 [416625/888800 46.88%] train loss: 1.279111165786162e-05 \n",
      "epoch: 48 [417736/888800 47.00%] train loss: 1.3518166269932408e-05 \n",
      "epoch: 48 [418847/888800 47.12%] train loss: 1.5239180356729776e-05 \n",
      "epoch: 48 [419958/888800 47.25%] train loss: 1.37259748953511e-05 \n",
      "epoch: 48 [421069/888800 47.38%] train loss: 1.4336942513182294e-05 \n",
      "epoch: 48 [422180/888800 47.50%] train loss: 1.4711778931086883e-05 \n",
      "epoch: 48 [423291/888800 47.62%] train loss: 1.302195232710801e-05 \n",
      "epoch: 48 [424402/888800 47.75%] train loss: 1.4205658771970775e-05 \n",
      "epoch: 48 [425513/888800 47.88%] train loss: 1.4746741726412438e-05 \n",
      "epoch: 48 [426624/888800 48.00%] train loss: 1.4587723853765056e-05 \n",
      "epoch: 48 [427735/888800 48.12%] train loss: 1.4096744052949362e-05 \n",
      "epoch: 48 [428846/888800 48.25%] train loss: 1.498945857747458e-05 \n",
      "epoch: 48 [429957/888800 48.38%] train loss: 1.4260454918257892e-05 \n",
      "epoch: 48 [431068/888800 48.50%] train loss: 1.407463332725456e-05 \n",
      "epoch: 48 [432179/888800 48.62%] train loss: 1.3709890481550246e-05 \n",
      "epoch: 48 [433290/888800 48.75%] train loss: 1.4192472917784471e-05 \n",
      "epoch: 48 [434401/888800 48.88%] train loss: 1.4719814316777047e-05 \n",
      "epoch: 48 [435512/888800 49.00%] train loss: 1.3745249816565774e-05 \n",
      "epoch: 48 [436623/888800 49.12%] train loss: 1.4454401934926864e-05 \n",
      "epoch: 48 [437734/888800 49.25%] train loss: 1.495093329140218e-05 \n",
      "epoch: 48 [438845/888800 49.38%] train loss: 1.3204167771618813e-05 \n",
      "epoch: 48 [439956/888800 49.50%] train loss: 1.4001300769450609e-05 \n",
      "epoch: 48 [441067/888800 49.62%] train loss: 1.3999664588482119e-05 \n",
      "epoch: 48 [442178/888800 49.75%] train loss: 1.4330402336781844e-05 \n",
      "epoch: 48 [443289/888800 49.88%] train loss: 1.444422196072992e-05 \n",
      "epoch: 48 [444400/888800 50.00%] train loss: 1.5741870811325498e-05 \n",
      "epoch: 48 [445511/888800 50.12%] train loss: 1.37054039441864e-05 \n",
      "epoch: 48 [446622/888800 50.25%] train loss: 1.564304511703085e-05 \n",
      "epoch: 48 [447733/888800 50.38%] train loss: 1.5327619621530175e-05 \n",
      "epoch: 48 [448844/888800 50.50%] train loss: 1.522705588286044e-05 \n",
      "epoch: 48 [449955/888800 50.62%] train loss: 1.433006673323689e-05 \n",
      "epoch: 48 [451066/888800 50.75%] train loss: 1.4635124898632057e-05 \n",
      "epoch: 48 [452177/888800 50.88%] train loss: 1.541034180263523e-05 \n",
      "epoch: 48 [453288/888800 51.00%] train loss: 1.3854910321242642e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [454399/888800 51.12%] train loss: 1.2693340067926329e-05 \n",
      "epoch: 48 [455510/888800 51.25%] train loss: 1.455348410672741e-05 \n",
      "epoch: 48 [456621/888800 51.38%] train loss: 1.4923449271009304e-05 \n",
      "epoch: 48 [457732/888800 51.50%] train loss: 1.4018372894497588e-05 \n",
      "epoch: 48 [458843/888800 51.62%] train loss: 1.4858629583613947e-05 \n",
      "epoch: 48 [459954/888800 51.75%] train loss: 1.433546367479721e-05 \n",
      "epoch: 48 [461065/888800 51.88%] train loss: 1.5551489923382178e-05 \n",
      "epoch: 48 [462176/888800 52.00%] train loss: 1.2698379578068852e-05 \n",
      "epoch: 48 [463287/888800 52.12%] train loss: 1.3820555977872573e-05 \n",
      "epoch: 48 [464398/888800 52.25%] train loss: 1.387696829624474e-05 \n",
      "epoch: 48 [465509/888800 52.38%] train loss: 1.446347505407175e-05 \n",
      "epoch: 48 [466620/888800 52.50%] train loss: 1.4845364603388589e-05 \n",
      "epoch: 48 [467731/888800 52.62%] train loss: 1.4206525520421565e-05 \n",
      "epoch: 48 [468842/888800 52.75%] train loss: 1.4467063010670245e-05 \n",
      "epoch: 48 [469953/888800 52.88%] train loss: 1.4382528206624556e-05 \n",
      "epoch: 48 [471064/888800 53.00%] train loss: 1.5307212379411794e-05 \n",
      "epoch: 48 [472175/888800 53.12%] train loss: 1.4116772035777103e-05 \n",
      "epoch: 48 [473286/888800 53.25%] train loss: 1.3893441064283252e-05 \n",
      "epoch: 48 [474397/888800 53.38%] train loss: 1.4135854144115001e-05 \n",
      "epoch: 48 [475508/888800 53.50%] train loss: 1.4208299035090022e-05 \n",
      "epoch: 48 [476619/888800 53.62%] train loss: 1.3739630958298221e-05 \n",
      "epoch: 48 [477730/888800 53.75%] train loss: 1.3501481589628384e-05 \n",
      "epoch: 48 [478841/888800 53.88%] train loss: 1.6163865439011715e-05 \n",
      "epoch: 48 [479952/888800 54.00%] train loss: 1.3957659575680736e-05 \n",
      "epoch: 48 [481063/888800 54.12%] train loss: 1.386735948472051e-05 \n",
      "epoch: 48 [482174/888800 54.25%] train loss: 1.4577968613593839e-05 \n",
      "epoch: 48 [483285/888800 54.38%] train loss: 1.4100312910159118e-05 \n",
      "epoch: 48 [484396/888800 54.50%] train loss: 1.4140657185635064e-05 \n",
      "epoch: 48 [485507/888800 54.62%] train loss: 1.4214329894457478e-05 \n",
      "epoch: 48 [486618/888800 54.75%] train loss: 1.4464554624282755e-05 \n",
      "epoch: 48 [487729/888800 54.88%] train loss: 1.2779933967976831e-05 \n",
      "epoch: 48 [488840/888800 55.00%] train loss: 1.330853410763666e-05 \n",
      "epoch: 48 [489951/888800 55.12%] train loss: 1.3802767171000596e-05 \n",
      "epoch: 48 [491062/888800 55.25%] train loss: 1.3895141819375567e-05 \n",
      "epoch: 48 [492173/888800 55.38%] train loss: 1.4650914636149537e-05 \n",
      "epoch: 48 [493284/888800 55.50%] train loss: 1.4352105608850252e-05 \n",
      "epoch: 48 [494395/888800 55.62%] train loss: 1.3334226423467044e-05 \n",
      "epoch: 48 [495506/888800 55.75%] train loss: 1.394817081745714e-05 \n",
      "epoch: 48 [496617/888800 55.88%] train loss: 1.4129433111520484e-05 \n",
      "epoch: 48 [497728/888800 56.00%] train loss: 1.4564151570084505e-05 \n",
      "epoch: 48 [498839/888800 56.12%] train loss: 1.459278428228572e-05 \n",
      "epoch: 48 [499950/888800 56.25%] train loss: 1.5053066817927174e-05 \n",
      "epoch: 48 [501061/888800 56.38%] train loss: 1.4401198313862551e-05 \n",
      "epoch: 48 [502172/888800 56.50%] train loss: 1.3639553799293935e-05 \n",
      "epoch: 48 [503283/888800 56.62%] train loss: 1.4411732081498485e-05 \n",
      "epoch: 48 [504394/888800 56.75%] train loss: 1.562364377605263e-05 \n",
      "epoch: 48 [505505/888800 56.88%] train loss: 1.4325056326924823e-05 \n",
      "epoch: 48 [506616/888800 57.00%] train loss: 1.368496123177465e-05 \n",
      "epoch: 48 [507727/888800 57.12%] train loss: 1.4195214134815615e-05 \n",
      "epoch: 48 [508838/888800 57.25%] train loss: 1.387397696817061e-05 \n",
      "epoch: 48 [509949/888800 57.38%] train loss: 1.4584604286937974e-05 \n",
      "epoch: 48 [511060/888800 57.50%] train loss: 1.3643050806422252e-05 \n",
      "epoch: 48 [512171/888800 57.62%] train loss: 1.5110965250642039e-05 \n",
      "epoch: 48 [513282/888800 57.75%] train loss: 1.4510871551465243e-05 \n",
      "epoch: 48 [514393/888800 57.88%] train loss: 1.4272405678639188e-05 \n",
      "epoch: 48 [515504/888800 58.00%] train loss: 1.2200780474813655e-05 \n",
      "epoch: 48 [516615/888800 58.12%] train loss: 1.4005880075274035e-05 \n",
      "epoch: 48 [517726/888800 58.25%] train loss: 1.4533442481479142e-05 \n",
      "epoch: 48 [518837/888800 58.38%] train loss: 1.3793316611554474e-05 \n",
      "epoch: 48 [519948/888800 58.50%] train loss: 1.4575744899048004e-05 \n",
      "epoch: 48 [521059/888800 58.62%] train loss: 1.4111923519521952e-05 \n",
      "epoch: 48 [522170/888800 58.75%] train loss: 1.536640957056079e-05 \n",
      "epoch: 48 [523281/888800 58.88%] train loss: 1.469246853957884e-05 \n",
      "epoch: 48 [524392/888800 59.00%] train loss: 1.3599945305031724e-05 \n",
      "epoch: 48 [525503/888800 59.12%] train loss: 1.5164731848926749e-05 \n",
      "epoch: 48 [526614/888800 59.25%] train loss: 1.436826369172195e-05 \n",
      "epoch: 48 [527725/888800 59.38%] train loss: 1.4730831026099622e-05 \n",
      "epoch: 48 [528836/888800 59.50%] train loss: 1.5915427866275422e-05 \n",
      "epoch: 48 [529947/888800 59.62%] train loss: 1.3629940440296195e-05 \n",
      "epoch: 48 [531058/888800 59.75%] train loss: 1.7092712369048968e-05 \n",
      "epoch: 48 [532169/888800 59.88%] train loss: 1.533063368697185e-05 \n",
      "epoch: 48 [533280/888800 60.00%] train loss: 1.663850162003655e-05 \n",
      "epoch: 48 [534391/888800 60.12%] train loss: 1.554049231344834e-05 \n",
      "epoch: 48 [535502/888800 60.25%] train loss: 1.3206632502260618e-05 \n",
      "epoch: 48 [536613/888800 60.38%] train loss: 1.2954992598679382e-05 \n",
      "epoch: 48 [537724/888800 60.50%] train loss: 1.4082801499171183e-05 \n",
      "epoch: 48 [538835/888800 60.62%] train loss: 1.430279098713072e-05 \n",
      "epoch: 48 [539946/888800 60.75%] train loss: 1.4656325220130384e-05 \n",
      "epoch: 48 [541057/888800 60.88%] train loss: 1.522363891126588e-05 \n",
      "epoch: 48 [542168/888800 61.00%] train loss: 1.31370106828399e-05 \n",
      "epoch: 48 [543279/888800 61.12%] train loss: 1.4457302313530818e-05 \n",
      "epoch: 48 [544390/888800 61.25%] train loss: 1.3804428817820735e-05 \n",
      "epoch: 48 [545501/888800 61.38%] train loss: 1.4060154171602335e-05 \n",
      "epoch: 48 [546612/888800 61.50%] train loss: 1.5023868400021456e-05 \n",
      "epoch: 48 [547723/888800 61.62%] train loss: 1.3345893421501387e-05 \n",
      "epoch: 48 [548834/888800 61.75%] train loss: 1.5573044947814196e-05 \n",
      "epoch: 48 [549945/888800 61.88%] train loss: 1.4198258213582449e-05 \n",
      "epoch: 48 [551056/888800 62.00%] train loss: 1.279673870158149e-05 \n",
      "epoch: 48 [552167/888800 62.12%] train loss: 1.4142374311632011e-05 \n",
      "epoch: 48 [553278/888800 62.25%] train loss: 1.5309728041756898e-05 \n",
      "epoch: 48 [554389/888800 62.38%] train loss: 1.3916108400735538e-05 \n",
      "epoch: 48 [555500/888800 62.50%] train loss: 1.4220160664990544e-05 \n",
      "epoch: 48 [556611/888800 62.62%] train loss: 1.4000534974911716e-05 \n",
      "epoch: 48 [557722/888800 62.75%] train loss: 1.4748575267731212e-05 \n",
      "epoch: 48 [558833/888800 62.88%] train loss: 1.4523220670525916e-05 \n",
      "epoch: 48 [559944/888800 63.00%] train loss: 1.3948410924058408e-05 \n",
      "epoch: 48 [561055/888800 63.12%] train loss: 1.4592965271731373e-05 \n",
      "epoch: 48 [562166/888800 63.25%] train loss: 1.3590999515145086e-05 \n",
      "epoch: 48 [563277/888800 63.38%] train loss: 1.4288961210695561e-05 \n",
      "epoch: 48 [564388/888800 63.50%] train loss: 1.4656116036348976e-05 \n",
      "epoch: 48 [565499/888800 63.62%] train loss: 1.508054538135184e-05 \n",
      "epoch: 48 [566610/888800 63.75%] train loss: 1.537905882287305e-05 \n",
      "epoch: 48 [567721/888800 63.88%] train loss: 1.414934013155289e-05 \n",
      "epoch: 48 [568832/888800 64.00%] train loss: 1.4064054084883537e-05 \n",
      "epoch: 48 [569943/888800 64.12%] train loss: 1.3725141798204277e-05 \n",
      "epoch: 48 [571054/888800 64.25%] train loss: 1.5206491298158653e-05 \n",
      "epoch: 48 [572165/888800 64.38%] train loss: 1.4572717191185802e-05 \n",
      "epoch: 48 [573276/888800 64.50%] train loss: 1.550907109049149e-05 \n",
      "epoch: 48 [574387/888800 64.62%] train loss: 1.4184631254465785e-05 \n",
      "epoch: 48 [575498/888800 64.75%] train loss: 1.418615192960715e-05 \n",
      "epoch: 48 [576609/888800 64.88%] train loss: 1.5029935639176983e-05 \n",
      "epoch: 48 [577720/888800 65.00%] train loss: 1.4787426152906846e-05 \n",
      "epoch: 48 [578831/888800 65.12%] train loss: 1.3017849596508313e-05 \n",
      "epoch: 48 [579942/888800 65.25%] train loss: 1.380462072120281e-05 \n",
      "epoch: 48 [581053/888800 65.38%] train loss: 1.4353238839248661e-05 \n",
      "epoch: 48 [582164/888800 65.50%] train loss: 1.3998610484122764e-05 \n",
      "epoch: 48 [583275/888800 65.62%] train loss: 1.5412946595461108e-05 \n",
      "epoch: 48 [584386/888800 65.75%] train loss: 1.5500168956350535e-05 \n",
      "epoch: 48 [585497/888800 65.88%] train loss: 1.4187585293257143e-05 \n",
      "epoch: 48 [586608/888800 66.00%] train loss: 1.4214516340871342e-05 \n",
      "epoch: 48 [587719/888800 66.12%] train loss: 1.4046755495655816e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [588830/888800 66.25%] train loss: 1.4125586858426686e-05 \n",
      "epoch: 48 [589941/888800 66.38%] train loss: 1.40911206472083e-05 \n",
      "epoch: 48 [591052/888800 66.50%] train loss: 1.387487463944126e-05 \n",
      "epoch: 48 [592163/888800 66.62%] train loss: 1.454775883757975e-05 \n",
      "epoch: 48 [593274/888800 66.75%] train loss: 1.2907398740935605e-05 \n",
      "epoch: 48 [594385/888800 66.88%] train loss: 1.3782359928882215e-05 \n",
      "epoch: 48 [595496/888800 67.00%] train loss: 1.4286885743786115e-05 \n",
      "epoch: 48 [596607/888800 67.12%] train loss: 1.4845516489003785e-05 \n",
      "epoch: 48 [597718/888800 67.25%] train loss: 1.3324378414836247e-05 \n",
      "epoch: 48 [598829/888800 67.38%] train loss: 1.4208801985660102e-05 \n",
      "epoch: 48 [599940/888800 67.50%] train loss: 1.2981022337044124e-05 \n",
      "epoch: 48 [601051/888800 67.62%] train loss: 1.3964420759293716e-05 \n",
      "epoch: 48 [602162/888800 67.75%] train loss: 1.5156146218942013e-05 \n",
      "epoch: 48 [603273/888800 67.88%] train loss: 1.3951856089988723e-05 \n",
      "epoch: 48 [604384/888800 68.00%] train loss: 1.4515919247060083e-05 \n",
      "epoch: 48 [605495/888800 68.12%] train loss: 1.4067389201954938e-05 \n",
      "epoch: 48 [606606/888800 68.25%] train loss: 1.36872949951794e-05 \n",
      "epoch: 48 [607717/888800 68.38%] train loss: 1.424108813807834e-05 \n",
      "epoch: 48 [608828/888800 68.50%] train loss: 1.477930709370412e-05 \n",
      "epoch: 48 [609939/888800 68.62%] train loss: 1.5644955055904575e-05 \n",
      "epoch: 48 [611050/888800 68.75%] train loss: 1.4335707419377286e-05 \n",
      "epoch: 48 [612161/888800 68.88%] train loss: 1.5286785128409974e-05 \n",
      "epoch: 48 [613272/888800 69.00%] train loss: 1.4178550372889731e-05 \n",
      "epoch: 48 [614383/888800 69.12%] train loss: 1.579205854795873e-05 \n",
      "epoch: 48 [615494/888800 69.25%] train loss: 1.4575112800230272e-05 \n",
      "epoch: 48 [616605/888800 69.38%] train loss: 1.4497264601232018e-05 \n",
      "epoch: 48 [617716/888800 69.50%] train loss: 1.447583781555295e-05 \n",
      "epoch: 48 [618827/888800 69.62%] train loss: 1.4172196642903145e-05 \n",
      "epoch: 48 [619938/888800 69.75%] train loss: 1.5403589713969268e-05 \n",
      "epoch: 48 [621049/888800 69.88%] train loss: 1.342317682428984e-05 \n",
      "epoch: 48 [622160/888800 70.00%] train loss: 1.4680973436043132e-05 \n",
      "epoch: 48 [623271/888800 70.12%] train loss: 1.450080981157953e-05 \n",
      "epoch: 48 [624382/888800 70.25%] train loss: 1.3562960702984128e-05 \n",
      "epoch: 48 [625493/888800 70.38%] train loss: 1.4315301996248309e-05 \n",
      "epoch: 48 [626604/888800 70.50%] train loss: 1.470823281124467e-05 \n",
      "epoch: 48 [627715/888800 70.62%] train loss: 1.4450210073846392e-05 \n",
      "epoch: 48 [628826/888800 70.75%] train loss: 1.4898787412676029e-05 \n",
      "epoch: 48 [629937/888800 70.88%] train loss: 1.4946196642995346e-05 \n",
      "epoch: 48 [631048/888800 71.00%] train loss: 1.3863566891814116e-05 \n",
      "epoch: 48 [632159/888800 71.12%] train loss: 1.4204884791979566e-05 \n",
      "epoch: 48 [633270/888800 71.25%] train loss: 1.3800649867334869e-05 \n",
      "epoch: 48 [634381/888800 71.38%] train loss: 1.426634844392538e-05 \n",
      "epoch: 48 [635492/888800 71.50%] train loss: 1.391264140693238e-05 \n",
      "epoch: 48 [636603/888800 71.62%] train loss: 1.3656152987095993e-05 \n",
      "epoch: 48 [637714/888800 71.75%] train loss: 1.3266118003230076e-05 \n",
      "epoch: 48 [638825/888800 71.88%] train loss: 1.415389579051407e-05 \n",
      "epoch: 48 [639936/888800 72.00%] train loss: 1.3814125850331038e-05 \n",
      "epoch: 48 [641047/888800 72.12%] train loss: 1.3118239621690009e-05 \n",
      "epoch: 48 [642158/888800 72.25%] train loss: 1.4401703992916737e-05 \n",
      "epoch: 48 [643269/888800 72.38%] train loss: 1.3511527868104167e-05 \n",
      "epoch: 48 [644380/888800 72.50%] train loss: 1.4111142263573129e-05 \n",
      "epoch: 48 [645491/888800 72.62%] train loss: 1.3803453839500435e-05 \n",
      "epoch: 48 [646602/888800 72.75%] train loss: 1.515987969469279e-05 \n",
      "epoch: 48 [647713/888800 72.88%] train loss: 1.3776881132798735e-05 \n",
      "epoch: 48 [648824/888800 73.00%] train loss: 1.332245119556319e-05 \n",
      "epoch: 48 [649935/888800 73.12%] train loss: 1.4337316315504722e-05 \n",
      "epoch: 48 [651046/888800 73.25%] train loss: 1.561913813930005e-05 \n",
      "epoch: 48 [652157/888800 73.38%] train loss: 1.5269584764610045e-05 \n",
      "epoch: 48 [653268/888800 73.50%] train loss: 1.4352835933095776e-05 \n",
      "epoch: 48 [654379/888800 73.62%] train loss: 1.4794982234889176e-05 \n",
      "epoch: 48 [655490/888800 73.75%] train loss: 1.3667762686964124e-05 \n",
      "epoch: 48 [656601/888800 73.88%] train loss: 1.3461436537909321e-05 \n",
      "epoch: 48 [657712/888800 74.00%] train loss: 1.3374736226978712e-05 \n",
      "epoch: 48 [658823/888800 74.12%] train loss: 1.3958385352452751e-05 \n",
      "epoch: 48 [659934/888800 74.25%] train loss: 1.4387104783963878e-05 \n",
      "epoch: 48 [661045/888800 74.38%] train loss: 1.5226720279315487e-05 \n",
      "epoch: 48 [662156/888800 74.50%] train loss: 1.5306295608752407e-05 \n",
      "epoch: 48 [663267/888800 74.62%] train loss: 1.4848074897599872e-05 \n",
      "epoch: 48 [664378/888800 74.75%] train loss: 1.4350807759910822e-05 \n",
      "epoch: 48 [665489/888800 74.88%] train loss: 1.4216881936590653e-05 \n",
      "epoch: 48 [666600/888800 75.00%] train loss: 1.3665535334439483e-05 \n",
      "epoch: 48 [667711/888800 75.12%] train loss: 1.4883358744555153e-05 \n",
      "epoch: 48 [668822/888800 75.25%] train loss: 1.3815664715366438e-05 \n",
      "epoch: 48 [669933/888800 75.38%] train loss: 1.3371044587984215e-05 \n",
      "epoch: 48 [671044/888800 75.50%] train loss: 1.3737464541918598e-05 \n",
      "epoch: 48 [672155/888800 75.62%] train loss: 1.3654313988809008e-05 \n",
      "epoch: 48 [673266/888800 75.75%] train loss: 1.4066870789974928e-05 \n",
      "epoch: 48 [674377/888800 75.88%] train loss: 1.4352974176290445e-05 \n",
      "epoch: 48 [675488/888800 76.00%] train loss: 1.4627501514041796e-05 \n",
      "epoch: 48 [676599/888800 76.12%] train loss: 1.3985086297907401e-05 \n",
      "epoch: 48 [677710/888800 76.25%] train loss: 1.2931235687574372e-05 \n",
      "epoch: 48 [678821/888800 76.38%] train loss: 1.3960887372377329e-05 \n",
      "epoch: 48 [679932/888800 76.50%] train loss: 1.479025468142936e-05 \n",
      "epoch: 48 [681043/888800 76.62%] train loss: 1.4625294170400593e-05 \n",
      "epoch: 48 [682154/888800 76.75%] train loss: 1.563889964018017e-05 \n",
      "epoch: 48 [683265/888800 76.88%] train loss: 1.3742279406869784e-05 \n",
      "epoch: 48 [684376/888800 77.00%] train loss: 1.4263414414017461e-05 \n",
      "epoch: 48 [685487/888800 77.12%] train loss: 1.3124845281708986e-05 \n",
      "epoch: 48 [686598/888800 77.25%] train loss: 1.4671123608422931e-05 \n",
      "epoch: 48 [687709/888800 77.38%] train loss: 1.6500176570843905e-05 \n",
      "epoch: 48 [688820/888800 77.50%] train loss: 1.4058610759093426e-05 \n",
      "epoch: 48 [689931/888800 77.62%] train loss: 1.2852704458055086e-05 \n",
      "epoch: 48 [691042/888800 77.75%] train loss: 1.5290837836801074e-05 \n",
      "epoch: 48 [692153/888800 77.88%] train loss: 1.4869261576677673e-05 \n",
      "epoch: 48 [693264/888800 78.00%] train loss: 1.6453421267215163e-05 \n",
      "epoch: 48 [694375/888800 78.12%] train loss: 1.4279510651249439e-05 \n",
      "epoch: 48 [695486/888800 78.25%] train loss: 1.5420433555846103e-05 \n",
      "epoch: 48 [696597/888800 78.38%] train loss: 1.4345245290314779e-05 \n",
      "epoch: 48 [697708/888800 78.50%] train loss: 1.531013367639389e-05 \n",
      "epoch: 48 [698819/888800 78.62%] train loss: 1.3932096408098005e-05 \n",
      "epoch: 48 [699930/888800 78.75%] train loss: 1.566572427691426e-05 \n",
      "epoch: 48 [701041/888800 78.88%] train loss: 1.4681438187835738e-05 \n",
      "epoch: 48 [702152/888800 79.00%] train loss: 1.4500188626698218e-05 \n",
      "epoch: 48 [703263/888800 79.12%] train loss: 1.5424699085997418e-05 \n",
      "epoch: 48 [704374/888800 79.25%] train loss: 1.4873404325044248e-05 \n",
      "epoch: 48 [705485/888800 79.38%] train loss: 1.4904132513038348e-05 \n",
      "epoch: 48 [706596/888800 79.50%] train loss: 1.3515013051801361e-05 \n",
      "epoch: 48 [707707/888800 79.62%] train loss: 1.4064399692870211e-05 \n",
      "epoch: 48 [708818/888800 79.75%] train loss: 1.292204160563415e-05 \n",
      "epoch: 48 [709929/888800 79.88%] train loss: 1.513055667601293e-05 \n",
      "epoch: 48 [711040/888800 80.00%] train loss: 1.3135432709532324e-05 \n",
      "epoch: 48 [712151/888800 80.12%] train loss: 1.6302061339956708e-05 \n",
      "epoch: 48 [713262/888800 80.25%] train loss: 1.4598792404285632e-05 \n",
      "epoch: 48 [714373/888800 80.38%] train loss: 1.605120996828191e-05 \n",
      "epoch: 48 [715484/888800 80.50%] train loss: 1.477361820434453e-05 \n",
      "epoch: 48 [716595/888800 80.62%] train loss: 1.7104233847931027e-05 \n",
      "epoch: 48 [717706/888800 80.75%] train loss: 1.654570769460406e-05 \n",
      "epoch: 48 [718817/888800 80.88%] train loss: 1.518352291896008e-05 \n",
      "epoch: 48 [719928/888800 81.00%] train loss: 1.8117341824108735e-05 \n",
      "epoch: 48 [721039/888800 81.12%] train loss: 1.4955445294617675e-05 \n",
      "epoch: 48 [722150/888800 81.25%] train loss: 1.6323994714184664e-05 \n",
      "epoch: 48 [723261/888800 81.38%] train loss: 1.5940498997224495e-05 \n",
      "epoch: 48 [724372/888800 81.50%] train loss: 1.6936402971623465e-05 \n",
      "epoch: 48 [725483/888800 81.62%] train loss: 1.53837027028203e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [726594/888800 81.75%] train loss: 1.489068290538853e-05 \n",
      "epoch: 48 [727705/888800 81.88%] train loss: 1.4230374290491454e-05 \n",
      "epoch: 48 [728816/888800 82.00%] train loss: 1.4869871847622562e-05 \n",
      "epoch: 48 [729927/888800 82.12%] train loss: 1.4039455891179387e-05 \n",
      "epoch: 48 [731038/888800 82.25%] train loss: 1.4135106539470144e-05 \n",
      "epoch: 48 [732149/888800 82.38%] train loss: 1.4879713489790447e-05 \n",
      "epoch: 48 [733260/888800 82.50%] train loss: 1.5689296560594812e-05 \n",
      "epoch: 48 [734371/888800 82.62%] train loss: 1.410501226928318e-05 \n",
      "epoch: 48 [735482/888800 82.75%] train loss: 1.4314606232801452e-05 \n",
      "epoch: 48 [736593/888800 82.88%] train loss: 1.3370871783990879e-05 \n",
      "epoch: 48 [737704/888800 83.00%] train loss: 1.478031299484428e-05 \n",
      "epoch: 48 [738815/888800 83.12%] train loss: 1.3601108548755292e-05 \n",
      "epoch: 48 [739926/888800 83.25%] train loss: 1.4168536836223211e-05 \n",
      "epoch: 48 [741037/888800 83.38%] train loss: 1.325253106188029e-05 \n",
      "epoch: 48 [742148/888800 83.50%] train loss: 1.3501909052138217e-05 \n",
      "epoch: 48 [743259/888800 83.62%] train loss: 1.4098430256126449e-05 \n",
      "epoch: 48 [744370/888800 83.75%] train loss: 1.4384854694071691e-05 \n",
      "epoch: 48 [745481/888800 83.88%] train loss: 1.4937427295080852e-05 \n",
      "epoch: 48 [746592/888800 84.00%] train loss: 1.4525387086905539e-05 \n",
      "epoch: 48 [747703/888800 84.12%] train loss: 1.3396776012086775e-05 \n",
      "epoch: 48 [748814/888800 84.25%] train loss: 1.4391708646144252e-05 \n",
      "epoch: 48 [749925/888800 84.38%] train loss: 1.249016622750787e-05 \n",
      "epoch: 48 [751036/888800 84.50%] train loss: 1.2356233128230087e-05 \n",
      "epoch: 48 [752147/888800 84.62%] train loss: 1.311827145400457e-05 \n",
      "epoch: 48 [753258/888800 84.75%] train loss: 1.4748797184438445e-05 \n",
      "epoch: 48 [754369/888800 84.88%] train loss: 1.4408293282031082e-05 \n",
      "epoch: 48 [755480/888800 85.00%] train loss: 1.4488635315501597e-05 \n",
      "epoch: 48 [756591/888800 85.12%] train loss: 1.4603477211494464e-05 \n",
      "epoch: 48 [757702/888800 85.25%] train loss: 1.3640978977491613e-05 \n",
      "epoch: 48 [758813/888800 85.38%] train loss: 1.4499891221930739e-05 \n",
      "epoch: 48 [759924/888800 85.50%] train loss: 1.4706589354318567e-05 \n",
      "epoch: 48 [761035/888800 85.62%] train loss: 1.4658350664831232e-05 \n",
      "epoch: 48 [762146/888800 85.75%] train loss: 1.3747784578299616e-05 \n",
      "epoch: 48 [763257/888800 85.88%] train loss: 1.4079882930673193e-05 \n",
      "epoch: 48 [764368/888800 86.00%] train loss: 1.315355439146515e-05 \n",
      "epoch: 48 [765479/888800 86.12%] train loss: 1.4670737073174678e-05 \n",
      "epoch: 48 [766590/888800 86.25%] train loss: 1.3717105503019411e-05 \n",
      "epoch: 48 [767701/888800 86.38%] train loss: 1.298037386732176e-05 \n",
      "epoch: 48 [768812/888800 86.50%] train loss: 1.3730395949096419e-05 \n",
      "epoch: 48 [769923/888800 86.62%] train loss: 1.5003397493273951e-05 \n",
      "epoch: 48 [771034/888800 86.75%] train loss: 1.4521970115310978e-05 \n",
      "epoch: 48 [772145/888800 86.88%] train loss: 1.425366190233035e-05 \n",
      "epoch: 48 [773256/888800 87.00%] train loss: 1.446825626771897e-05 \n",
      "epoch: 48 [774367/888800 87.12%] train loss: 1.4092619494476821e-05 \n",
      "epoch: 48 [775478/888800 87.25%] train loss: 1.5184055882855318e-05 \n",
      "epoch: 48 [776589/888800 87.38%] train loss: 1.4299411304818932e-05 \n",
      "epoch: 48 [777700/888800 87.50%] train loss: 1.5355120922322385e-05 \n",
      "epoch: 48 [778811/888800 87.62%] train loss: 1.558470648888033e-05 \n",
      "epoch: 48 [779922/888800 87.75%] train loss: 1.3225318070908543e-05 \n",
      "epoch: 48 [781033/888800 87.88%] train loss: 1.3591829883807804e-05 \n",
      "epoch: 48 [782144/888800 88.00%] train loss: 1.4670790733362082e-05 \n",
      "epoch: 48 [783255/888800 88.12%] train loss: 1.3717898582399357e-05 \n",
      "epoch: 48 [784366/888800 88.25%] train loss: 1.3280031453177799e-05 \n",
      "epoch: 48 [785477/888800 88.38%] train loss: 1.4713192285853438e-05 \n",
      "epoch: 48 [786588/888800 88.50%] train loss: 1.3988691534905229e-05 \n",
      "epoch: 48 [787699/888800 88.62%] train loss: 1.4949734577385243e-05 \n",
      "epoch: 48 [788810/888800 88.75%] train loss: 1.3962269804324023e-05 \n",
      "epoch: 48 [789921/888800 88.88%] train loss: 1.3970385225547943e-05 \n",
      "epoch: 48 [791032/888800 89.00%] train loss: 1.3265741472423542e-05 \n",
      "epoch: 48 [792143/888800 89.12%] train loss: 1.428968880645698e-05 \n",
      "epoch: 48 [793254/888800 89.25%] train loss: 1.3841059626429342e-05 \n",
      "epoch: 48 [794365/888800 89.38%] train loss: 1.3531446711567696e-05 \n",
      "epoch: 48 [795476/888800 89.50%] train loss: 1.324933509749826e-05 \n",
      "epoch: 48 [796587/888800 89.62%] train loss: 1.3430180842988193e-05 \n",
      "epoch: 48 [797698/888800 89.75%] train loss: 1.4420059414987918e-05 \n",
      "epoch: 48 [798809/888800 89.88%] train loss: 1.4084796930546872e-05 \n",
      "epoch: 48 [799920/888800 90.00%] train loss: 1.4806832041358575e-05 \n",
      "epoch: 48 [801031/888800 90.12%] train loss: 1.4623934475821443e-05 \n",
      "epoch: 48 [802142/888800 90.25%] train loss: 1.3931588910054415e-05 \n",
      "epoch: 48 [803253/888800 90.38%] train loss: 1.4282077245297842e-05 \n",
      "epoch: 48 [804364/888800 90.50%] train loss: 1.3641813893627841e-05 \n",
      "epoch: 48 [805475/888800 90.62%] train loss: 1.4353721780935302e-05 \n",
      "epoch: 48 [806586/888800 90.75%] train loss: 1.3834624041919596e-05 \n",
      "epoch: 48 [807697/888800 90.88%] train loss: 1.4022469258634374e-05 \n",
      "epoch: 48 [808808/888800 91.00%] train loss: 1.4882142750138883e-05 \n",
      "epoch: 48 [809919/888800 91.12%] train loss: 1.4525739061355125e-05 \n",
      "epoch: 48 [811030/888800 91.25%] train loss: 1.4941031622583978e-05 \n",
      "epoch: 48 [812141/888800 91.38%] train loss: 1.4349171578942332e-05 \n",
      "epoch: 48 [813252/888800 91.50%] train loss: 1.3368388863455039e-05 \n",
      "epoch: 48 [814363/888800 91.62%] train loss: 1.3729096281167585e-05 \n",
      "epoch: 48 [815474/888800 91.75%] train loss: 1.2770517969329376e-05 \n",
      "epoch: 48 [816585/888800 91.88%] train loss: 1.3425886209006421e-05 \n",
      "epoch: 48 [817696/888800 92.00%] train loss: 1.2538273040263448e-05 \n",
      "epoch: 48 [818807/888800 92.12%] train loss: 1.5375424482044764e-05 \n",
      "epoch: 48 [819918/888800 92.25%] train loss: 1.4391021068149712e-05 \n",
      "epoch: 48 [821029/888800 92.38%] train loss: 1.3889301044400781e-05 \n",
      "epoch: 48 [822140/888800 92.50%] train loss: 1.3444671822071541e-05 \n",
      "epoch: 48 [823251/888800 92.62%] train loss: 1.3162617506168317e-05 \n",
      "epoch: 48 [824362/888800 92.75%] train loss: 1.4612369341193698e-05 \n",
      "epoch: 48 [825473/888800 92.88%] train loss: 1.2755655006913003e-05 \n",
      "epoch: 48 [826584/888800 93.00%] train loss: 1.4123233086138498e-05 \n",
      "epoch: 48 [827695/888800 93.12%] train loss: 1.297802464250708e-05 \n",
      "epoch: 48 [828806/888800 93.25%] train loss: 1.4705079593113624e-05 \n",
      "epoch: 48 [829917/888800 93.38%] train loss: 1.3396167560131289e-05 \n",
      "epoch: 48 [831028/888800 93.50%] train loss: 1.4563846889359411e-05 \n",
      "epoch: 48 [832139/888800 93.62%] train loss: 1.3089443200442474e-05 \n",
      "epoch: 48 [833250/888800 93.75%] train loss: 1.2583922398334835e-05 \n",
      "epoch: 48 [834361/888800 93.88%] train loss: 1.3383675650402438e-05 \n",
      "epoch: 48 [835472/888800 94.00%] train loss: 1.4888402802171186e-05 \n",
      "epoch: 48 [836583/888800 94.12%] train loss: 1.4639787877968047e-05 \n",
      "epoch: 48 [837694/888800 94.25%] train loss: 1.368774610455148e-05 \n",
      "epoch: 48 [838805/888800 94.38%] train loss: 1.5207902833935805e-05 \n",
      "epoch: 48 [839916/888800 94.50%] train loss: 1.3536935512092896e-05 \n",
      "epoch: 48 [841027/888800 94.62%] train loss: 1.5690140571678057e-05 \n",
      "epoch: 48 [842138/888800 94.75%] train loss: 1.4668171388620976e-05 \n",
      "epoch: 48 [843249/888800 94.88%] train loss: 1.428796076652361e-05 \n",
      "epoch: 48 [844360/888800 95.00%] train loss: 1.4270863175624982e-05 \n",
      "epoch: 48 [845471/888800 95.12%] train loss: 1.353045900032157e-05 \n",
      "epoch: 48 [846582/888800 95.25%] train loss: 1.3965041034680326e-05 \n",
      "epoch: 48 [847693/888800 95.38%] train loss: 1.511423397460021e-05 \n",
      "epoch: 48 [848804/888800 95.50%] train loss: 1.3277609468786977e-05 \n",
      "epoch: 48 [849915/888800 95.62%] train loss: 1.5332343537011184e-05 \n",
      "epoch: 48 [851026/888800 95.75%] train loss: 1.277614228456514e-05 \n",
      "epoch: 48 [852137/888800 95.88%] train loss: 1.5497733329539187e-05 \n",
      "epoch: 48 [853248/888800 96.00%] train loss: 1.4479348465101793e-05 \n",
      "epoch: 48 [854359/888800 96.12%] train loss: 1.4513349015032873e-05 \n",
      "epoch: 48 [855470/888800 96.25%] train loss: 1.5682211596868e-05 \n",
      "epoch: 48 [856581/888800 96.38%] train loss: 1.3799290172755718e-05 \n",
      "epoch: 48 [857692/888800 96.50%] train loss: 1.535406227048952e-05 \n",
      "epoch: 48 [858803/888800 96.62%] train loss: 1.412753317708848e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 [859914/888800 96.75%] train loss: 1.4595319044019561e-05 \n",
      "epoch: 48 [861025/888800 96.88%] train loss: 1.3521257642423734e-05 \n",
      "epoch: 48 [862136/888800 97.00%] train loss: 1.3997199857840315e-05 \n",
      "epoch: 48 [863247/888800 97.12%] train loss: 1.4403206478164066e-05 \n",
      "epoch: 48 [864358/888800 97.25%] train loss: 1.4385857866727747e-05 \n",
      "epoch: 48 [865469/888800 97.38%] train loss: 1.2512778994278051e-05 \n",
      "epoch: 48 [866580/888800 97.50%] train loss: 1.4181496226228774e-05 \n",
      "epoch: 48 [867691/888800 97.62%] train loss: 1.5622450519003905e-05 \n",
      "epoch: 48 [868802/888800 97.75%] train loss: 1.3585906344815157e-05 \n",
      "epoch: 48 [869913/888800 97.88%] train loss: 1.4639897926826961e-05 \n",
      "epoch: 48 [871024/888800 98.00%] train loss: 1.4046364412934054e-05 \n",
      "epoch: 48 [872135/888800 98.12%] train loss: 1.5137105947360396e-05 \n",
      "epoch: 48 [873246/888800 98.25%] train loss: 1.323941341979662e-05 \n",
      "epoch: 48 [874357/888800 98.38%] train loss: 1.3835254321747925e-05 \n",
      "epoch: 48 [875468/888800 98.50%] train loss: 1.4150081369734835e-05 \n",
      "epoch: 48 [876579/888800 98.62%] train loss: 1.3117117305228021e-05 \n",
      "epoch: 48 [877690/888800 98.75%] train loss: 1.4998139704403002e-05 \n",
      "epoch: 48 [878801/888800 98.88%] train loss: 1.5218069165712222e-05 \n",
      "epoch: 48 [879912/888800 99.00%] train loss: 1.4037145774636883e-05 \n",
      "epoch: 48 [881023/888800 99.12%] train loss: 1.4533112334902398e-05 \n",
      "epoch: 48 [882134/888800 99.25%] train loss: 1.403336864314042e-05 \n",
      "epoch: 48 [883245/888800 99.38%] train loss: 1.51050462591229e-05 \n",
      "epoch: 48 [884356/888800 99.50%] train loss: 1.367281311104307e-05 \n",
      "epoch: 48 [885467/888800 99.62%] train loss: 1.328353573626373e-05 \n",
      "epoch: 48 [886578/888800 99.75%] train loss: 1.4498883501801174e-05 \n",
      "epoch: 48 [887689/888800 99.88%] train loss: 1.3715094610233791e-05 \n",
      "epoch: 49 [0/888800 0.00%] train loss: 1.3302356819622219e-05 \n",
      "epoch: 49 [1111/888800 0.12%] train loss: 1.3881115592084825e-05 \n",
      "epoch: 49 [2222/888800 0.25%] train loss: 1.388588407280622e-05 \n",
      "epoch: 49 [3333/888800 0.38%] train loss: 1.3325835425348487e-05 \n",
      "epoch: 49 [4444/888800 0.50%] train loss: 1.6157482605194673e-05 \n",
      "epoch: 49 [5555/888800 0.62%] train loss: 1.335593424300896e-05 \n",
      "epoch: 49 [6666/888800 0.75%] train loss: 1.550716297060717e-05 \n",
      "epoch: 49 [7777/888800 0.88%] train loss: 1.4304985597846098e-05 \n",
      "epoch: 49 [8888/888800 1.00%] train loss: 1.4290471881395206e-05 \n",
      "epoch: 49 [9999/888800 1.12%] train loss: 1.4535333320964128e-05 \n",
      "epoch: 49 [11110/888800 1.25%] train loss: 1.443518885935191e-05 \n",
      "epoch: 49 [12221/888800 1.38%] train loss: 1.4956290215195622e-05 \n",
      "epoch: 49 [13332/888800 1.50%] train loss: 1.5058230928843841e-05 \n",
      "epoch: 49 [14443/888800 1.62%] train loss: 1.6491931091877632e-05 \n",
      "epoch: 49 [15554/888800 1.75%] train loss: 1.494699881732231e-05 \n",
      "epoch: 49 [16665/888800 1.88%] train loss: 1.5240776519931387e-05 \n",
      "epoch: 49 [17776/888800 2.00%] train loss: 1.4634684703196399e-05 \n",
      "epoch: 49 [18887/888800 2.12%] train loss: 1.4086788723943755e-05 \n",
      "epoch: 49 [19998/888800 2.25%] train loss: 1.4074502360017505e-05 \n",
      "epoch: 49 [21109/888800 2.38%] train loss: 1.4574050510418601e-05 \n",
      "epoch: 49 [22220/888800 2.50%] train loss: 1.4563930562871974e-05 \n",
      "epoch: 49 [23331/888800 2.62%] train loss: 1.3970494364912156e-05 \n",
      "epoch: 49 [24442/888800 2.75%] train loss: 1.4293050298874732e-05 \n",
      "epoch: 49 [25553/888800 2.88%] train loss: 1.63336571858963e-05 \n",
      "epoch: 49 [26664/888800 3.00%] train loss: 1.5121720025490504e-05 \n",
      "epoch: 49 [27775/888800 3.12%] train loss: 1.4060877219890244e-05 \n",
      "epoch: 49 [28886/888800 3.25%] train loss: 1.5161078408709727e-05 \n",
      "epoch: 49 [29997/888800 3.38%] train loss: 1.5212888683890924e-05 \n",
      "epoch: 49 [31108/888800 3.50%] train loss: 1.3834552191838156e-05 \n",
      "epoch: 49 [32219/888800 3.62%] train loss: 1.3600484635389876e-05 \n",
      "epoch: 49 [33330/888800 3.75%] train loss: 1.3036180462222546e-05 \n",
      "epoch: 49 [34441/888800 3.88%] train loss: 1.3875755939807277e-05 \n",
      "epoch: 49 [35552/888800 4.00%] train loss: 1.4768712389923166e-05 \n",
      "epoch: 49 [36663/888800 4.12%] train loss: 1.3556516023527365e-05 \n",
      "epoch: 49 [37774/888800 4.25%] train loss: 1.4063123671803623e-05 \n",
      "epoch: 49 [38885/888800 4.38%] train loss: 1.3253929864731617e-05 \n",
      "epoch: 49 [39996/888800 4.50%] train loss: 1.3661569937539753e-05 \n",
      "epoch: 49 [41107/888800 4.62%] train loss: 1.4739624020876363e-05 \n",
      "epoch: 49 [42218/888800 4.75%] train loss: 1.5073981558089145e-05 \n",
      "epoch: 49 [43329/888800 4.88%] train loss: 1.492499177402351e-05 \n",
      "epoch: 49 [44440/888800 5.00%] train loss: 1.6006340956664644e-05 \n",
      "epoch: 49 [45551/888800 5.12%] train loss: 1.4891346836520825e-05 \n",
      "epoch: 49 [46662/888800 5.25%] train loss: 1.4566516256309114e-05 \n",
      "epoch: 49 [47773/888800 5.38%] train loss: 1.6479245459777303e-05 \n",
      "epoch: 49 [48884/888800 5.50%] train loss: 1.416610939486418e-05 \n",
      "epoch: 49 [49995/888800 5.62%] train loss: 1.4083445421420038e-05 \n",
      "epoch: 49 [51106/888800 5.75%] train loss: 1.3494050108420197e-05 \n",
      "epoch: 49 [52217/888800 5.88%] train loss: 1.487259487475967e-05 \n",
      "epoch: 49 [53328/888800 6.00%] train loss: 1.4773230759601574e-05 \n",
      "epoch: 49 [54439/888800 6.12%] train loss: 1.3866391782357823e-05 \n",
      "epoch: 49 [55550/888800 6.25%] train loss: 1.3610784662887454e-05 \n",
      "epoch: 49 [56661/888800 6.38%] train loss: 1.4375000318977982e-05 \n",
      "epoch: 49 [57772/888800 6.50%] train loss: 1.6940204659476876e-05 \n",
      "epoch: 49 [58883/888800 6.62%] train loss: 1.367445474897977e-05 \n",
      "epoch: 49 [59994/888800 6.75%] train loss: 1.5360870747826993e-05 \n",
      "epoch: 49 [61105/888800 6.88%] train loss: 1.3587387911684345e-05 \n",
      "epoch: 49 [62216/888800 7.00%] train loss: 1.520119531051023e-05 \n",
      "epoch: 49 [63327/888800 7.12%] train loss: 1.4642788300989196e-05 \n",
      "epoch: 49 [64438/888800 7.25%] train loss: 1.3507826224667951e-05 \n",
      "epoch: 49 [65549/888800 7.38%] train loss: 1.4724138054589275e-05 \n",
      "epoch: 49 [66660/888800 7.50%] train loss: 1.4554937479260843e-05 \n",
      "epoch: 49 [67771/888800 7.62%] train loss: 1.3344678336579818e-05 \n",
      "epoch: 49 [68882/888800 7.75%] train loss: 1.5012191397545394e-05 \n",
      "epoch: 49 [69993/888800 7.88%] train loss: 1.4112382814346347e-05 \n",
      "epoch: 49 [71104/888800 8.00%] train loss: 1.5252051525749266e-05 \n",
      "epoch: 49 [72215/888800 8.12%] train loss: 1.3320454854692798e-05 \n",
      "epoch: 49 [73326/888800 8.25%] train loss: 1.4767240827495698e-05 \n",
      "epoch: 49 [74437/888800 8.38%] train loss: 1.4933993043086957e-05 \n",
      "epoch: 49 [75548/888800 8.50%] train loss: 1.4243102668842766e-05 \n",
      "epoch: 49 [76659/888800 8.62%] train loss: 1.4336574167828076e-05 \n",
      "epoch: 49 [77770/888800 8.75%] train loss: 1.5005927707534283e-05 \n",
      "epoch: 49 [78881/888800 8.88%] train loss: 1.589164457982406e-05 \n",
      "epoch: 49 [79992/888800 9.00%] train loss: 1.3834376659360714e-05 \n",
      "epoch: 49 [81103/888800 9.12%] train loss: 1.4709139577462338e-05 \n",
      "epoch: 49 [82214/888800 9.25%] train loss: 1.3192857295507565e-05 \n",
      "epoch: 49 [83325/888800 9.38%] train loss: 1.4354968698171433e-05 \n",
      "epoch: 49 [84436/888800 9.50%] train loss: 1.2993295058549847e-05 \n",
      "epoch: 49 [85547/888800 9.62%] train loss: 1.3190503523219377e-05 \n",
      "epoch: 49 [86658/888800 9.75%] train loss: 1.6716652680770494e-05 \n",
      "epoch: 49 [87769/888800 9.88%] train loss: 1.3337940799829084e-05 \n",
      "epoch: 49 [88880/888800 10.00%] train loss: 1.3922904145147186e-05 \n",
      "epoch: 49 [89991/888800 10.12%] train loss: 1.4522080164169893e-05 \n",
      "epoch: 49 [91102/888800 10.25%] train loss: 1.4216296222002711e-05 \n",
      "epoch: 49 [92213/888800 10.38%] train loss: 1.2981940017198212e-05 \n",
      "epoch: 49 [93324/888800 10.50%] train loss: 1.2786704246536829e-05 \n",
      "epoch: 49 [94435/888800 10.62%] train loss: 1.506699209130602e-05 \n",
      "epoch: 49 [95546/888800 10.75%] train loss: 1.4652391655545216e-05 \n",
      "epoch: 49 [96657/888800 10.88%] train loss: 1.2844603588746395e-05 \n",
      "epoch: 49 [97768/888800 11.00%] train loss: 1.5034316675155424e-05 \n",
      "epoch: 49 [98879/888800 11.12%] train loss: 1.5198798791971058e-05 \n",
      "epoch: 49 [99990/888800 11.25%] train loss: 1.3948877494840417e-05 \n",
      "epoch: 49 [101101/888800 11.38%] train loss: 1.4909413948771544e-05 \n",
      "epoch: 49 [102212/888800 11.50%] train loss: 1.3854195458407048e-05 \n",
      "epoch: 49 [103323/888800 11.62%] train loss: 1.4066067706153262e-05 \n",
      "epoch: 49 [104434/888800 11.75%] train loss: 1.37978959173779e-05 \n",
      "epoch: 49 [105545/888800 11.88%] train loss: 1.4215272130968515e-05 \n",
      "epoch: 49 [106656/888800 12.00%] train loss: 1.4088290299696382e-05 \n",
      "epoch: 49 [107767/888800 12.12%] train loss: 1.3770623809250537e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [108878/888800 12.25%] train loss: 1.5026564142317511e-05 \n",
      "epoch: 49 [109989/888800 12.38%] train loss: 1.4752049537491985e-05 \n",
      "epoch: 49 [111100/888800 12.50%] train loss: 1.5640312994946726e-05 \n",
      "epoch: 49 [112211/888800 12.62%] train loss: 1.4266051948652603e-05 \n",
      "epoch: 49 [113322/888800 12.75%] train loss: 1.4098661267780699e-05 \n",
      "epoch: 49 [114433/888800 12.88%] train loss: 1.4185873624228407e-05 \n",
      "epoch: 49 [115544/888800 13.00%] train loss: 1.4131142961559817e-05 \n",
      "epoch: 49 [116655/888800 13.12%] train loss: 1.4313091924123e-05 \n",
      "epoch: 49 [117766/888800 13.25%] train loss: 1.3186137948650867e-05 \n",
      "epoch: 49 [118877/888800 13.38%] train loss: 1.4393982382898685e-05 \n",
      "epoch: 49 [119988/888800 13.50%] train loss: 1.3864799257135019e-05 \n",
      "epoch: 49 [121099/888800 13.62%] train loss: 1.3554378710978199e-05 \n",
      "epoch: 49 [122210/888800 13.75%] train loss: 1.422728928446304e-05 \n",
      "epoch: 49 [123321/888800 13.88%] train loss: 1.4684559573652223e-05 \n",
      "epoch: 49 [124432/888800 14.00%] train loss: 1.31871292978758e-05 \n",
      "epoch: 49 [125543/888800 14.12%] train loss: 1.374112798657734e-05 \n",
      "epoch: 49 [126654/888800 14.25%] train loss: 1.3020857295487076e-05 \n",
      "epoch: 49 [127765/888800 14.38%] train loss: 1.4038706467545126e-05 \n",
      "epoch: 49 [128876/888800 14.50%] train loss: 1.4046358046471141e-05 \n",
      "epoch: 49 [129987/888800 14.62%] train loss: 1.2605995834746864e-05 \n",
      "epoch: 49 [131098/888800 14.75%] train loss: 1.501053247920936e-05 \n",
      "epoch: 49 [132209/888800 14.88%] train loss: 1.580227217345964e-05 \n",
      "epoch: 49 [133320/888800 15.00%] train loss: 1.369312758470187e-05 \n",
      "epoch: 49 [134431/888800 15.12%] train loss: 1.4699909115734044e-05 \n",
      "epoch: 49 [135542/888800 15.25%] train loss: 1.4707326045027003e-05 \n",
      "epoch: 49 [136653/888800 15.38%] train loss: 1.3360313459997997e-05 \n",
      "epoch: 49 [137764/888800 15.50%] train loss: 1.4733439456904307e-05 \n",
      "epoch: 49 [138875/888800 15.62%] train loss: 1.6318055713782087e-05 \n",
      "epoch: 49 [139986/888800 15.75%] train loss: 1.3142948773747776e-05 \n",
      "epoch: 49 [141097/888800 15.88%] train loss: 1.3382245924731251e-05 \n",
      "epoch: 49 [142208/888800 16.00%] train loss: 1.4749527508683968e-05 \n",
      "epoch: 49 [143319/888800 16.12%] train loss: 1.3758428394794464e-05 \n",
      "epoch: 49 [144430/888800 16.25%] train loss: 1.3917703654442448e-05 \n",
      "epoch: 49 [145541/888800 16.38%] train loss: 1.329929000348784e-05 \n",
      "epoch: 49 [146652/888800 16.50%] train loss: 1.3872906492906623e-05 \n",
      "epoch: 49 [147763/888800 16.62%] train loss: 1.4575022760254797e-05 \n",
      "epoch: 49 [148874/888800 16.75%] train loss: 1.4578838090528734e-05 \n",
      "epoch: 49 [149985/888800 16.88%] train loss: 1.2729412446788047e-05 \n",
      "epoch: 49 [151096/888800 17.00%] train loss: 1.4863556316413451e-05 \n",
      "epoch: 49 [152207/888800 17.12%] train loss: 1.393497677781852e-05 \n",
      "epoch: 49 [153318/888800 17.25%] train loss: 1.4419586477742996e-05 \n",
      "epoch: 49 [154429/888800 17.38%] train loss: 1.5247495866788086e-05 \n",
      "epoch: 49 [155540/888800 17.50%] train loss: 1.6440399122075178e-05 \n",
      "epoch: 49 [156651/888800 17.62%] train loss: 1.4314572581497487e-05 \n",
      "epoch: 49 [157762/888800 17.75%] train loss: 1.6618691006442532e-05 \n",
      "epoch: 49 [158873/888800 17.88%] train loss: 1.3558054888562765e-05 \n",
      "epoch: 49 [159984/888800 18.00%] train loss: 1.4674567864858545e-05 \n",
      "epoch: 49 [161095/888800 18.12%] train loss: 1.6315283573931083e-05 \n",
      "epoch: 49 [162206/888800 18.25%] train loss: 1.3699284863832872e-05 \n",
      "epoch: 49 [163317/888800 18.38%] train loss: 1.5478659406653605e-05 \n",
      "epoch: 49 [164428/888800 18.50%] train loss: 1.3140613191353623e-05 \n",
      "epoch: 49 [165539/888800 18.62%] train loss: 1.5700828953413293e-05 \n",
      "epoch: 49 [166650/888800 18.75%] train loss: 1.5346984582720324e-05 \n",
      "epoch: 49 [167761/888800 18.88%] train loss: 1.5520990928052925e-05 \n",
      "epoch: 49 [168872/888800 19.00%] train loss: 1.3279920494824182e-05 \n",
      "epoch: 49 [169983/888800 19.12%] train loss: 1.5873893062234856e-05 \n",
      "epoch: 49 [171094/888800 19.25%] train loss: 1.4462184481089935e-05 \n",
      "epoch: 49 [172205/888800 19.38%] train loss: 1.4356602150655817e-05 \n",
      "epoch: 49 [173316/888800 19.50%] train loss: 1.396034440404037e-05 \n",
      "epoch: 49 [174427/888800 19.62%] train loss: 1.2757398508256301e-05 \n",
      "epoch: 49 [175538/888800 19.75%] train loss: 1.5333129340433516e-05 \n",
      "epoch: 49 [176649/888800 19.88%] train loss: 1.3862263585906476e-05 \n",
      "epoch: 49 [177760/888800 20.00%] train loss: 1.530187000753358e-05 \n",
      "epoch: 49 [178871/888800 20.12%] train loss: 1.4425065273826476e-05 \n",
      "epoch: 49 [179982/888800 20.25%] train loss: 1.395037725160364e-05 \n",
      "epoch: 49 [181093/888800 20.38%] train loss: 1.5754359992570244e-05 \n",
      "epoch: 49 [182204/888800 20.50%] train loss: 1.3888866305933334e-05 \n",
      "epoch: 49 [183315/888800 20.62%] train loss: 1.4890285456203856e-05 \n",
      "epoch: 49 [184426/888800 20.75%] train loss: 1.4830630789219867e-05 \n",
      "epoch: 49 [185537/888800 20.88%] train loss: 1.4117430509941187e-05 \n",
      "epoch: 49 [186648/888800 21.00%] train loss: 1.54122244566679e-05 \n",
      "epoch: 49 [187759/888800 21.12%] train loss: 1.4926242329238448e-05 \n",
      "epoch: 49 [188870/888800 21.25%] train loss: 1.45881567732431e-05 \n",
      "epoch: 49 [189981/888800 21.38%] train loss: 1.3339987162908074e-05 \n",
      "epoch: 49 [191092/888800 21.50%] train loss: 1.3099614989187103e-05 \n",
      "epoch: 49 [192203/888800 21.62%] train loss: 1.529943801870104e-05 \n",
      "epoch: 49 [193314/888800 21.75%] train loss: 1.4060658941161819e-05 \n",
      "epoch: 49 [194425/888800 21.88%] train loss: 1.5219102351693437e-05 \n",
      "epoch: 49 [195536/888800 22.00%] train loss: 1.4825785910943523e-05 \n",
      "epoch: 49 [196647/888800 22.12%] train loss: 1.3039776604273356e-05 \n",
      "epoch: 49 [197758/888800 22.25%] train loss: 1.3388592378760222e-05 \n",
      "epoch: 49 [198869/888800 22.38%] train loss: 1.4752695278730243e-05 \n",
      "epoch: 49 [199980/888800 22.50%] train loss: 1.4964095498726238e-05 \n",
      "epoch: 49 [201091/888800 22.62%] train loss: 1.476852958148811e-05 \n",
      "epoch: 49 [202202/888800 22.75%] train loss: 1.4196206393535249e-05 \n",
      "epoch: 49 [203313/888800 22.88%] train loss: 1.496062395744957e-05 \n",
      "epoch: 49 [204424/888800 23.00%] train loss: 1.3258229046186898e-05 \n",
      "epoch: 49 [205535/888800 23.12%] train loss: 1.3629000932269264e-05 \n",
      "epoch: 49 [206646/888800 23.25%] train loss: 1.4841100892226677e-05 \n",
      "epoch: 49 [207757/888800 23.38%] train loss: 1.3710007806366775e-05 \n",
      "epoch: 49 [208868/888800 23.50%] train loss: 1.4446381101151928e-05 \n",
      "epoch: 49 [209979/888800 23.62%] train loss: 1.5042682207422331e-05 \n",
      "epoch: 49 [211090/888800 23.75%] train loss: 1.4091519915382378e-05 \n",
      "epoch: 49 [212201/888800 23.88%] train loss: 1.5491994417971e-05 \n",
      "epoch: 49 [213312/888800 24.00%] train loss: 1.2962502296431921e-05 \n",
      "epoch: 49 [214423/888800 24.12%] train loss: 1.4334157640405465e-05 \n",
      "epoch: 49 [215534/888800 24.25%] train loss: 1.4566560821549501e-05 \n",
      "epoch: 49 [216645/888800 24.38%] train loss: 1.4482017832051497e-05 \n",
      "epoch: 49 [217756/888800 24.50%] train loss: 1.5501353118452244e-05 \n",
      "epoch: 49 [218867/888800 24.62%] train loss: 1.430288830306381e-05 \n",
      "epoch: 49 [219978/888800 24.75%] train loss: 1.3962939192424528e-05 \n",
      "epoch: 49 [221089/888800 24.88%] train loss: 1.5076283489179332e-05 \n",
      "epoch: 49 [222200/888800 25.00%] train loss: 1.4780303899897262e-05 \n",
      "epoch: 49 [223311/888800 25.12%] train loss: 1.4254719644668512e-05 \n",
      "epoch: 49 [224422/888800 25.25%] train loss: 1.4010788618179504e-05 \n",
      "epoch: 49 [225533/888800 25.38%] train loss: 1.5094480659172405e-05 \n",
      "epoch: 49 [226644/888800 25.50%] train loss: 1.4434368495130911e-05 \n",
      "epoch: 49 [227755/888800 25.62%] train loss: 1.401721965521574e-05 \n",
      "epoch: 49 [228866/888800 25.75%] train loss: 1.2641366993193515e-05 \n",
      "epoch: 49 [229977/888800 25.88%] train loss: 1.4109951735008508e-05 \n",
      "epoch: 49 [231088/888800 26.00%] train loss: 1.4888567420712207e-05 \n",
      "epoch: 49 [232199/888800 26.12%] train loss: 1.3387992112257052e-05 \n",
      "epoch: 49 [233310/888800 26.25%] train loss: 1.3876761840947438e-05 \n",
      "epoch: 49 [234421/888800 26.38%] train loss: 1.3983065400680061e-05 \n",
      "epoch: 49 [235532/888800 26.50%] train loss: 1.3523467714549042e-05 \n",
      "epoch: 49 [236643/888800 26.62%] train loss: 1.3665549886354711e-05 \n",
      "epoch: 49 [237754/888800 26.75%] train loss: 1.3338293683773372e-05 \n",
      "epoch: 49 [238865/888800 26.88%] train loss: 1.3809746633342002e-05 \n",
      "epoch: 49 [239976/888800 27.00%] train loss: 1.4504265891446266e-05 \n",
      "epoch: 49 [241087/888800 27.12%] train loss: 1.3353577742236666e-05 \n",
      "epoch: 49 [242198/888800 27.25%] train loss: 1.2495539522205945e-05 \n",
      "epoch: 49 [243309/888800 27.38%] train loss: 1.4645338524132967e-05 \n",
      "epoch: 49 [244420/888800 27.50%] train loss: 1.4289865248429123e-05 \n",
      "epoch: 49 [245531/888800 27.62%] train loss: 1.377092758048093e-05 \n",
      "epoch: 49 [246642/888800 27.75%] train loss: 1.3682255485036876e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [247753/888800 27.88%] train loss: 1.3996184861753136e-05 \n",
      "epoch: 49 [248864/888800 28.00%] train loss: 1.4159399142954499e-05 \n",
      "epoch: 49 [249975/888800 28.12%] train loss: 1.4456863027589861e-05 \n",
      "epoch: 49 [251086/888800 28.25%] train loss: 1.3505102288036142e-05 \n",
      "epoch: 49 [252197/888800 28.38%] train loss: 1.3687830687558744e-05 \n",
      "epoch: 49 [253308/888800 28.50%] train loss: 1.4096615814196412e-05 \n",
      "epoch: 49 [254419/888800 28.62%] train loss: 1.2876604159828275e-05 \n",
      "epoch: 49 [255530/888800 28.75%] train loss: 1.4138466212898493e-05 \n",
      "epoch: 49 [256641/888800 28.88%] train loss: 1.3169743397156708e-05 \n",
      "epoch: 49 [257752/888800 29.00%] train loss: 1.3812826182402205e-05 \n",
      "epoch: 49 [258863/888800 29.12%] train loss: 1.442223037884105e-05 \n",
      "epoch: 49 [259974/888800 29.25%] train loss: 1.3852884876541793e-05 \n",
      "epoch: 49 [261085/888800 29.38%] train loss: 1.5022184925328474e-05 \n",
      "epoch: 49 [262196/888800 29.50%] train loss: 1.397251253365539e-05 \n",
      "epoch: 49 [263307/888800 29.62%] train loss: 1.4238023140933365e-05 \n",
      "epoch: 49 [264418/888800 29.75%] train loss: 1.4011059647600632e-05 \n",
      "epoch: 49 [265529/888800 29.88%] train loss: 1.3721455616177991e-05 \n",
      "epoch: 49 [266640/888800 30.00%] train loss: 1.4225706763681956e-05 \n",
      "epoch: 49 [267751/888800 30.12%] train loss: 1.4857296264381148e-05 \n",
      "epoch: 49 [268862/888800 30.25%] train loss: 1.394793525832938e-05 \n",
      "epoch: 49 [269973/888800 30.38%] train loss: 1.4939811080694199e-05 \n",
      "epoch: 49 [271084/888800 30.50%] train loss: 1.3476349522534292e-05 \n",
      "epoch: 49 [272195/888800 30.62%] train loss: 1.6063020666479133e-05 \n",
      "epoch: 49 [273306/888800 30.75%] train loss: 1.5131552572711371e-05 \n",
      "epoch: 49 [274417/888800 30.88%] train loss: 1.5521138266194612e-05 \n",
      "epoch: 49 [275528/888800 31.00%] train loss: 1.4285794350143988e-05 \n",
      "epoch: 49 [276639/888800 31.12%] train loss: 1.5044633983052336e-05 \n",
      "epoch: 49 [277750/888800 31.25%] train loss: 1.5667394109186716e-05 \n",
      "epoch: 49 [278861/888800 31.38%] train loss: 1.3696844689548016e-05 \n",
      "epoch: 49 [279972/888800 31.50%] train loss: 1.5091520253918134e-05 \n",
      "epoch: 49 [281083/888800 31.62%] train loss: 1.4412977179745212e-05 \n",
      "epoch: 49 [282194/888800 31.75%] train loss: 1.581909782544244e-05 \n",
      "epoch: 49 [283305/888800 31.88%] train loss: 1.418883493897738e-05 \n",
      "epoch: 49 [284416/888800 32.00%] train loss: 1.3559040780819487e-05 \n",
      "epoch: 49 [285527/888800 32.12%] train loss: 1.4085178918321617e-05 \n",
      "epoch: 49 [286638/888800 32.25%] train loss: 1.4356383871927392e-05 \n",
      "epoch: 49 [287749/888800 32.38%] train loss: 1.571828943269793e-05 \n",
      "epoch: 49 [288860/888800 32.50%] train loss: 1.447891099815024e-05 \n",
      "epoch: 49 [289971/888800 32.62%] train loss: 1.561778481118381e-05 \n",
      "epoch: 49 [291082/888800 32.75%] train loss: 1.4549492334481329e-05 \n",
      "epoch: 49 [292193/888800 32.88%] train loss: 1.4401399312191643e-05 \n",
      "epoch: 49 [293304/888800 33.00%] train loss: 1.33054763864493e-05 \n",
      "epoch: 49 [294415/888800 33.12%] train loss: 1.5057372365845367e-05 \n",
      "epoch: 49 [295526/888800 33.25%] train loss: 1.40398733492475e-05 \n",
      "epoch: 49 [296637/888800 33.38%] train loss: 1.4876338354952168e-05 \n",
      "epoch: 49 [297748/888800 33.50%] train loss: 1.614150642126333e-05 \n",
      "epoch: 49 [298859/888800 33.62%] train loss: 1.4851131709292531e-05 \n",
      "epoch: 49 [299970/888800 33.75%] train loss: 1.3146276614861563e-05 \n",
      "epoch: 49 [301081/888800 33.88%] train loss: 1.3915841918787919e-05 \n",
      "epoch: 49 [302192/888800 34.00%] train loss: 1.42136741487775e-05 \n",
      "epoch: 49 [303303/888800 34.12%] train loss: 1.3230435797595419e-05 \n",
      "epoch: 49 [304414/888800 34.25%] train loss: 1.4132085198070854e-05 \n",
      "epoch: 49 [305525/888800 34.38%] train loss: 1.3932697584095877e-05 \n",
      "epoch: 49 [306636/888800 34.50%] train loss: 1.4201561498339288e-05 \n",
      "epoch: 49 [307747/888800 34.62%] train loss: 1.4126559108262882e-05 \n",
      "epoch: 49 [308858/888800 34.75%] train loss: 1.4285746146924794e-05 \n",
      "epoch: 49 [309969/888800 34.88%] train loss: 1.3056998795946129e-05 \n",
      "epoch: 49 [311080/888800 35.00%] train loss: 1.3595852578873746e-05 \n",
      "epoch: 49 [312191/888800 35.12%] train loss: 1.527752283436712e-05 \n",
      "epoch: 49 [313302/888800 35.25%] train loss: 1.4097608982410748e-05 \n",
      "epoch: 49 [314413/888800 35.38%] train loss: 1.3445699551084545e-05 \n",
      "epoch: 49 [315524/888800 35.50%] train loss: 1.379673085466493e-05 \n",
      "epoch: 49 [316635/888800 35.62%] train loss: 1.5080133380251937e-05 \n",
      "epoch: 49 [317746/888800 35.75%] train loss: 1.2669903298956342e-05 \n",
      "epoch: 49 [318857/888800 35.88%] train loss: 1.3648491403728258e-05 \n",
      "epoch: 49 [319968/888800 36.00%] train loss: 1.478929516451899e-05 \n",
      "epoch: 49 [321079/888800 36.12%] train loss: 1.4043942428543232e-05 \n",
      "epoch: 49 [322190/888800 36.25%] train loss: 1.4946917872293852e-05 \n",
      "epoch: 49 [323301/888800 36.38%] train loss: 1.4124936569714919e-05 \n",
      "epoch: 49 [324412/888800 36.50%] train loss: 1.5041936421766877e-05 \n",
      "epoch: 49 [325523/888800 36.62%] train loss: 1.3937507901573554e-05 \n",
      "epoch: 49 [326634/888800 36.75%] train loss: 1.4185443433234468e-05 \n",
      "epoch: 49 [327745/888800 36.88%] train loss: 1.289130887016654e-05 \n",
      "epoch: 49 [328856/888800 37.00%] train loss: 1.5926592823234387e-05 \n",
      "epoch: 49 [329967/888800 37.12%] train loss: 1.6161260646185838e-05 \n",
      "epoch: 49 [331078/888800 37.25%] train loss: 1.2887830052932259e-05 \n",
      "epoch: 49 [332189/888800 37.38%] train loss: 1.551087734696921e-05 \n",
      "epoch: 49 [333300/888800 37.50%] train loss: 1.4091894627199508e-05 \n",
      "epoch: 49 [334411/888800 37.62%] train loss: 1.555953895149287e-05 \n",
      "epoch: 49 [335522/888800 37.75%] train loss: 1.4639298569818493e-05 \n",
      "epoch: 49 [336633/888800 37.88%] train loss: 1.4847861166344956e-05 \n",
      "epoch: 49 [337744/888800 38.00%] train loss: 1.4380838365468662e-05 \n",
      "epoch: 49 [338855/888800 38.12%] train loss: 1.4566079698852263e-05 \n",
      "epoch: 49 [339966/888800 38.25%] train loss: 1.3688817489310168e-05 \n",
      "epoch: 49 [341077/888800 38.38%] train loss: 1.5272848031600006e-05 \n",
      "epoch: 49 [342188/888800 38.50%] train loss: 1.369535402773181e-05 \n",
      "epoch: 49 [343299/888800 38.62%] train loss: 1.464534034312237e-05 \n",
      "epoch: 49 [344410/888800 38.75%] train loss: 1.3471988495439291e-05 \n",
      "epoch: 49 [345521/888800 38.88%] train loss: 1.340013841399923e-05 \n",
      "epoch: 49 [346632/888800 39.00%] train loss: 1.3683010365639348e-05 \n",
      "epoch: 49 [347743/888800 39.12%] train loss: 1.3387439139478374e-05 \n",
      "epoch: 49 [348854/888800 39.25%] train loss: 1.4731520423083566e-05 \n",
      "epoch: 49 [349965/888800 39.38%] train loss: 1.41931550388108e-05 \n",
      "epoch: 49 [351076/888800 39.50%] train loss: 1.2676400729105808e-05 \n",
      "epoch: 49 [352187/888800 39.62%] train loss: 1.4285204088082537e-05 \n",
      "epoch: 49 [353298/888800 39.75%] train loss: 1.4369424206961412e-05 \n",
      "epoch: 49 [354409/888800 39.88%] train loss: 1.5060383702802937e-05 \n",
      "epoch: 49 [355520/888800 40.00%] train loss: 1.3676668459083885e-05 \n",
      "epoch: 49 [356631/888800 40.12%] train loss: 1.4201613339537289e-05 \n",
      "epoch: 49 [357742/888800 40.25%] train loss: 1.4488740816887002e-05 \n",
      "epoch: 49 [358853/888800 40.38%] train loss: 1.4669093616248574e-05 \n",
      "epoch: 49 [359964/888800 40.50%] train loss: 1.5520472516072914e-05 \n",
      "epoch: 49 [361075/888800 40.62%] train loss: 1.3780535482510459e-05 \n",
      "epoch: 49 [362186/888800 40.75%] train loss: 1.5831505152164027e-05 \n",
      "epoch: 49 [363297/888800 40.88%] train loss: 1.467488800699357e-05 \n",
      "epoch: 49 [364408/888800 41.00%] train loss: 1.4761567399546038e-05 \n",
      "epoch: 49 [365519/888800 41.12%] train loss: 1.284271365875611e-05 \n",
      "epoch: 49 [366630/888800 41.25%] train loss: 1.5493331375182606e-05 \n",
      "epoch: 49 [367741/888800 41.38%] train loss: 1.4049357559997588e-05 \n",
      "epoch: 49 [368852/888800 41.50%] train loss: 1.5066771084093489e-05 \n",
      "epoch: 49 [369963/888800 41.62%] train loss: 1.3495731764123775e-05 \n",
      "epoch: 49 [371074/888800 41.75%] train loss: 1.6107478586491197e-05 \n",
      "epoch: 49 [372185/888800 41.88%] train loss: 1.358447116217576e-05 \n",
      "epoch: 49 [373296/888800 42.00%] train loss: 1.6752095689298585e-05 \n",
      "epoch: 49 [374407/888800 42.12%] train loss: 1.4624747564084828e-05 \n",
      "epoch: 49 [375518/888800 42.25%] train loss: 1.6130927178892307e-05 \n",
      "epoch: 49 [376629/888800 42.38%] train loss: 1.410744971508393e-05 \n",
      "epoch: 49 [377740/888800 42.50%] train loss: 1.590154533914756e-05 \n",
      "epoch: 49 [378851/888800 42.62%] train loss: 1.5062073543958832e-05 \n",
      "epoch: 49 [379962/888800 42.75%] train loss: 1.4995095625636168e-05 \n",
      "epoch: 49 [381073/888800 42.88%] train loss: 1.75400055013597e-05 \n",
      "epoch: 49 [382184/888800 43.00%] train loss: 1.5747138604638167e-05 \n",
      "epoch: 49 [383295/888800 43.12%] train loss: 1.6647649317746982e-05 \n",
      "epoch: 49 [384406/888800 43.25%] train loss: 1.3148561265552416e-05 \n",
      "epoch: 49 [385517/888800 43.38%] train loss: 1.943415372807067e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [386628/888800 43.50%] train loss: 1.4731022019986995e-05 \n",
      "epoch: 49 [387739/888800 43.62%] train loss: 1.6339006833732128e-05 \n",
      "epoch: 49 [388850/888800 43.75%] train loss: 1.4549260413332377e-05 \n",
      "epoch: 49 [389961/888800 43.88%] train loss: 1.5016451470728498e-05 \n",
      "epoch: 49 [391072/888800 44.00%] train loss: 1.4831129192316439e-05 \n",
      "epoch: 49 [392183/888800 44.12%] train loss: 1.5003682165115606e-05 \n",
      "epoch: 49 [393294/888800 44.25%] train loss: 1.4852614185656421e-05 \n",
      "epoch: 49 [394405/888800 44.38%] train loss: 1.524448725831462e-05 \n",
      "epoch: 49 [395516/888800 44.50%] train loss: 1.4487033695331775e-05 \n",
      "epoch: 49 [396627/888800 44.62%] train loss: 1.6034662621677853e-05 \n",
      "epoch: 49 [397738/888800 44.75%] train loss: 1.3480125744536053e-05 \n",
      "epoch: 49 [398849/888800 44.88%] train loss: 1.6126336049637757e-05 \n",
      "epoch: 49 [399960/888800 45.00%] train loss: 1.3330815818335395e-05 \n",
      "epoch: 49 [401071/888800 45.12%] train loss: 1.4864388504065573e-05 \n",
      "epoch: 49 [402182/888800 45.25%] train loss: 1.5178201465460006e-05 \n",
      "epoch: 49 [403293/888800 45.38%] train loss: 1.4953268873796333e-05 \n",
      "epoch: 49 [404404/888800 45.50%] train loss: 1.578933370183222e-05 \n",
      "epoch: 49 [405515/888800 45.62%] train loss: 1.4214663679013029e-05 \n",
      "epoch: 49 [406626/888800 45.75%] train loss: 1.2762832739099395e-05 \n",
      "epoch: 49 [407737/888800 45.88%] train loss: 1.4288923011918087e-05 \n",
      "epoch: 49 [408848/888800 46.00%] train loss: 1.3596089047496207e-05 \n",
      "epoch: 49 [409959/888800 46.12%] train loss: 1.4641726011177525e-05 \n",
      "epoch: 49 [411070/888800 46.25%] train loss: 1.56960104504833e-05 \n",
      "epoch: 49 [412181/888800 46.38%] train loss: 1.5026878827484325e-05 \n",
      "epoch: 49 [413292/888800 46.50%] train loss: 1.5002019608800765e-05 \n",
      "epoch: 49 [414403/888800 46.62%] train loss: 1.4087371710047591e-05 \n",
      "epoch: 49 [415514/888800 46.75%] train loss: 1.5181374692474492e-05 \n",
      "epoch: 49 [416625/888800 46.88%] train loss: 1.4739410289621446e-05 \n",
      "epoch: 49 [417736/888800 47.00%] train loss: 1.452724427508656e-05 \n",
      "epoch: 49 [418847/888800 47.12%] train loss: 1.3861657862435095e-05 \n",
      "epoch: 49 [419958/888800 47.25%] train loss: 1.2865985809185077e-05 \n",
      "epoch: 49 [421069/888800 47.38%] train loss: 1.3422174561128486e-05 \n",
      "epoch: 49 [422180/888800 47.50%] train loss: 1.3854182725481223e-05 \n",
      "epoch: 49 [423291/888800 47.62%] train loss: 1.3999401744513307e-05 \n",
      "epoch: 49 [424402/888800 47.75%] train loss: 1.4663030924566556e-05 \n",
      "epoch: 49 [425513/888800 47.88%] train loss: 1.5637249816791154e-05 \n",
      "epoch: 49 [426624/888800 48.00%] train loss: 1.4457605175266508e-05 \n",
      "epoch: 49 [427735/888800 48.12%] train loss: 1.4628290045948233e-05 \n",
      "epoch: 49 [428846/888800 48.25%] train loss: 1.4350553101394325e-05 \n",
      "epoch: 49 [429957/888800 48.38%] train loss: 1.3894880794396158e-05 \n",
      "epoch: 49 [431068/888800 48.50%] train loss: 1.4208173524821177e-05 \n",
      "epoch: 49 [432179/888800 48.62%] train loss: 1.4161014405544847e-05 \n",
      "epoch: 49 [433290/888800 48.75%] train loss: 1.4775709132663906e-05 \n",
      "epoch: 49 [434401/888800 48.88%] train loss: 1.5432320651598275e-05 \n",
      "epoch: 49 [435512/888800 49.00%] train loss: 1.4360037312144414e-05 \n",
      "epoch: 49 [436623/888800 49.12%] train loss: 1.4359433407662436e-05 \n",
      "epoch: 49 [437734/888800 49.25%] train loss: 1.4059544810152147e-05 \n",
      "epoch: 49 [438845/888800 49.38%] train loss: 1.3843206033925526e-05 \n",
      "epoch: 49 [439956/888800 49.50%] train loss: 1.3489969205693342e-05 \n",
      "epoch: 49 [441067/888800 49.62%] train loss: 1.3759951798419934e-05 \n",
      "epoch: 49 [442178/888800 49.75%] train loss: 1.3080252756481059e-05 \n",
      "epoch: 49 [443289/888800 49.88%] train loss: 1.341733877779916e-05 \n",
      "epoch: 49 [444400/888800 50.00%] train loss: 1.3760671208729036e-05 \n",
      "epoch: 49 [445511/888800 50.12%] train loss: 1.4413039934879635e-05 \n",
      "epoch: 49 [446622/888800 50.25%] train loss: 1.4205923434928991e-05 \n",
      "epoch: 49 [447733/888800 50.38%] train loss: 1.4679976629849989e-05 \n",
      "epoch: 49 [448844/888800 50.50%] train loss: 1.511978371127043e-05 \n",
      "epoch: 49 [449955/888800 50.62%] train loss: 1.4601227121602278e-05 \n",
      "epoch: 49 [451066/888800 50.75%] train loss: 1.3827676411892753e-05 \n",
      "epoch: 49 [452177/888800 50.88%] train loss: 1.3795706763630733e-05 \n",
      "epoch: 49 [453288/888800 51.00%] train loss: 1.5251360309775919e-05 \n",
      "epoch: 49 [454399/888800 51.12%] train loss: 1.3174049854569603e-05 \n",
      "epoch: 49 [455510/888800 51.25%] train loss: 1.4270682186179329e-05 \n",
      "epoch: 49 [456621/888800 51.38%] train loss: 1.4928609743947163e-05 \n",
      "epoch: 49 [457732/888800 51.50%] train loss: 1.3507617040886544e-05 \n",
      "epoch: 49 [458843/888800 51.62%] train loss: 1.3209078133513685e-05 \n",
      "epoch: 49 [459954/888800 51.75%] train loss: 1.3733255400438793e-05 \n",
      "epoch: 49 [461065/888800 51.88%] train loss: 1.5482879462069832e-05 \n",
      "epoch: 49 [462176/888800 52.00%] train loss: 1.3498026419256348e-05 \n",
      "epoch: 49 [463287/888800 52.12%] train loss: 1.4174545867717825e-05 \n",
      "epoch: 49 [464398/888800 52.25%] train loss: 1.463548051106045e-05 \n",
      "epoch: 49 [465509/888800 52.38%] train loss: 1.5699946743552573e-05 \n",
      "epoch: 49 [466620/888800 52.50%] train loss: 1.4232047760742716e-05 \n",
      "epoch: 49 [467731/888800 52.62%] train loss: 1.4703603483212646e-05 \n",
      "epoch: 49 [468842/888800 52.75%] train loss: 1.3990130355523434e-05 \n",
      "epoch: 49 [469953/888800 52.88%] train loss: 1.3986955309519544e-05 \n",
      "epoch: 49 [471064/888800 53.00%] train loss: 1.3644262253365014e-05 \n",
      "epoch: 49 [472175/888800 53.12%] train loss: 1.4149774870020337e-05 \n",
      "epoch: 49 [473286/888800 53.25%] train loss: 1.3481215319188777e-05 \n",
      "epoch: 49 [474397/888800 53.38%] train loss: 1.560823329782579e-05 \n",
      "epoch: 49 [475508/888800 53.50%] train loss: 1.4221096535038669e-05 \n",
      "epoch: 49 [476619/888800 53.62%] train loss: 1.5218473890854511e-05 \n",
      "epoch: 49 [477730/888800 53.75%] train loss: 1.4393155652214773e-05 \n",
      "epoch: 49 [478841/888800 53.88%] train loss: 1.4863915566820651e-05 \n",
      "epoch: 49 [479952/888800 54.00%] train loss: 1.4633671526098624e-05 \n",
      "epoch: 49 [481063/888800 54.12%] train loss: 1.4740880033059511e-05 \n",
      "epoch: 49 [482174/888800 54.25%] train loss: 1.4269307030190248e-05 \n",
      "epoch: 49 [483285/888800 54.38%] train loss: 1.4998064216342755e-05 \n",
      "epoch: 49 [484396/888800 54.50%] train loss: 1.4840929907222744e-05 \n",
      "epoch: 49 [485507/888800 54.62%] train loss: 1.4281166841101367e-05 \n",
      "epoch: 49 [486618/888800 54.75%] train loss: 1.5136577530938666e-05 \n",
      "epoch: 49 [487729/888800 54.88%] train loss: 1.4734950127603952e-05 \n",
      "epoch: 49 [488840/888800 55.00%] train loss: 1.280725518881809e-05 \n",
      "epoch: 49 [489951/888800 55.12%] train loss: 1.4597506378777325e-05 \n",
      "epoch: 49 [491062/888800 55.25%] train loss: 1.3777549611404538e-05 \n",
      "epoch: 49 [492173/888800 55.38%] train loss: 1.558310577820521e-05 \n",
      "epoch: 49 [493284/888800 55.50%] train loss: 1.539010918349959e-05 \n",
      "epoch: 49 [494395/888800 55.62%] train loss: 1.531728594272863e-05 \n",
      "epoch: 49 [495506/888800 55.75%] train loss: 1.4589544662158005e-05 \n",
      "epoch: 49 [496617/888800 55.88%] train loss: 1.3677216884389054e-05 \n",
      "epoch: 49 [497728/888800 56.00%] train loss: 1.3949652384326328e-05 \n",
      "epoch: 49 [498839/888800 56.12%] train loss: 1.2625855561054777e-05 \n",
      "epoch: 49 [499950/888800 56.25%] train loss: 1.2817318747693207e-05 \n",
      "epoch: 49 [501061/888800 56.38%] train loss: 1.4398264283954632e-05 \n",
      "epoch: 49 [502172/888800 56.50%] train loss: 1.4840842595731374e-05 \n",
      "epoch: 49 [503283/888800 56.62%] train loss: 1.4107433344179299e-05 \n",
      "epoch: 49 [504394/888800 56.75%] train loss: 1.4537883544107899e-05 \n",
      "epoch: 49 [505505/888800 56.88%] train loss: 1.4353731785377022e-05 \n",
      "epoch: 49 [506616/888800 57.00%] train loss: 1.4412727978196926e-05 \n",
      "epoch: 49 [507727/888800 57.12%] train loss: 1.3982458767713979e-05 \n",
      "epoch: 49 [508838/888800 57.25%] train loss: 1.4103708053880837e-05 \n",
      "epoch: 49 [509949/888800 57.38%] train loss: 1.4664540685771499e-05 \n",
      "epoch: 49 [511060/888800 57.50%] train loss: 1.5348483429988846e-05 \n",
      "epoch: 49 [512171/888800 57.62%] train loss: 1.5824476577108726e-05 \n",
      "epoch: 49 [513282/888800 57.75%] train loss: 1.4406713489734102e-05 \n",
      "epoch: 49 [514393/888800 57.88%] train loss: 1.604237149877008e-05 \n",
      "epoch: 49 [515504/888800 58.00%] train loss: 1.3709254744753707e-05 \n",
      "epoch: 49 [516615/888800 58.12%] train loss: 1.4236745300877374e-05 \n",
      "epoch: 49 [517726/888800 58.25%] train loss: 1.4025641576154158e-05 \n",
      "epoch: 49 [518837/888800 58.38%] train loss: 1.5286001143977046e-05 \n",
      "epoch: 49 [519948/888800 58.50%] train loss: 1.2401267667883076e-05 \n",
      "epoch: 49 [521059/888800 58.62%] train loss: 1.3834312085236888e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [522170/888800 58.75%] train loss: 1.576817885506898e-05 \n",
      "epoch: 49 [523281/888800 58.88%] train loss: 1.3554038559959736e-05 \n",
      "epoch: 49 [524392/888800 59.00%] train loss: 1.3974319699627813e-05 \n",
      "epoch: 49 [525503/888800 59.12%] train loss: 1.39973972181906e-05 \n",
      "epoch: 49 [526614/888800 59.25%] train loss: 1.3615525858767796e-05 \n",
      "epoch: 49 [527725/888800 59.38%] train loss: 1.2663470442930702e-05 \n",
      "epoch: 49 [528836/888800 59.50%] train loss: 1.4252224900701549e-05 \n",
      "epoch: 49 [529947/888800 59.62%] train loss: 1.4729385839018505e-05 \n",
      "epoch: 49 [531058/888800 59.75%] train loss: 1.4875376109557692e-05 \n",
      "epoch: 49 [532169/888800 59.88%] train loss: 1.338507172476966e-05 \n",
      "epoch: 49 [533280/888800 60.00%] train loss: 1.2802483979612589e-05 \n",
      "epoch: 49 [534391/888800 60.12%] train loss: 1.3620538084069267e-05 \n",
      "epoch: 49 [535502/888800 60.25%] train loss: 1.4703598935739137e-05 \n",
      "epoch: 49 [536613/888800 60.38%] train loss: 1.3648233107232954e-05 \n",
      "epoch: 49 [537724/888800 60.50%] train loss: 1.3758418390352745e-05 \n",
      "epoch: 49 [538835/888800 60.62%] train loss: 1.461363717680797e-05 \n",
      "epoch: 49 [539946/888800 60.75%] train loss: 1.3238758583611343e-05 \n",
      "epoch: 49 [541057/888800 60.88%] train loss: 1.536437775939703e-05 \n",
      "epoch: 49 [542168/888800 61.00%] train loss: 1.3053324437350966e-05 \n",
      "epoch: 49 [543279/888800 61.12%] train loss: 1.4685278983961325e-05 \n",
      "epoch: 49 [544390/888800 61.25%] train loss: 1.3850008144800086e-05 \n",
      "epoch: 49 [545501/888800 61.38%] train loss: 1.4823086530668661e-05 \n",
      "epoch: 49 [546612/888800 61.50%] train loss: 1.374631483486155e-05 \n",
      "epoch: 49 [547723/888800 61.62%] train loss: 1.4225996892491821e-05 \n",
      "epoch: 49 [548834/888800 61.75%] train loss: 1.514884479547618e-05 \n",
      "epoch: 49 [549945/888800 61.88%] train loss: 1.4723779713676777e-05 \n",
      "epoch: 49 [551056/888800 62.00%] train loss: 1.514670566393761e-05 \n",
      "epoch: 49 [552167/888800 62.12%] train loss: 1.3804460650135297e-05 \n",
      "epoch: 49 [553278/888800 62.25%] train loss: 1.6865938960108906e-05 \n",
      "epoch: 49 [554389/888800 62.38%] train loss: 1.307644197368063e-05 \n",
      "epoch: 49 [555500/888800 62.50%] train loss: 1.4810445463808719e-05 \n",
      "epoch: 49 [556611/888800 62.62%] train loss: 1.43184270200436e-05 \n",
      "epoch: 49 [557722/888800 62.75%] train loss: 1.605128636583686e-05 \n",
      "epoch: 49 [558833/888800 62.88%] train loss: 1.3904681509302463e-05 \n",
      "epoch: 49 [559944/888800 63.00%] train loss: 1.4208589163899887e-05 \n",
      "epoch: 49 [561055/888800 63.12%] train loss: 1.4538179129885975e-05 \n",
      "epoch: 49 [562166/888800 63.25%] train loss: 1.3895771189709194e-05 \n",
      "epoch: 49 [563277/888800 63.38%] train loss: 1.6012598280212842e-05 \n",
      "epoch: 49 [564388/888800 63.50%] train loss: 1.3980638868815731e-05 \n",
      "epoch: 49 [565499/888800 63.62%] train loss: 1.600580981175881e-05 \n",
      "epoch: 49 [566610/888800 63.75%] train loss: 1.3792322533845436e-05 \n",
      "epoch: 49 [567721/888800 63.88%] train loss: 1.4535289665218443e-05 \n",
      "epoch: 49 [568832/888800 64.00%] train loss: 1.3533089258999098e-05 \n",
      "epoch: 49 [569943/888800 64.12%] train loss: 1.4415811165235937e-05 \n",
      "epoch: 49 [571054/888800 64.25%] train loss: 1.4399377505469602e-05 \n",
      "epoch: 49 [572165/888800 64.38%] train loss: 1.5079829609021544e-05 \n",
      "epoch: 49 [573276/888800 64.50%] train loss: 1.3882024177291896e-05 \n",
      "epoch: 49 [574387/888800 64.62%] train loss: 1.3160807611711789e-05 \n",
      "epoch: 49 [575498/888800 64.75%] train loss: 1.4359562555910088e-05 \n",
      "epoch: 49 [576609/888800 64.88%] train loss: 1.4385522263182793e-05 \n",
      "epoch: 49 [577720/888800 65.00%] train loss: 1.3665766346093733e-05 \n",
      "epoch: 49 [578831/888800 65.12%] train loss: 1.426645576430019e-05 \n",
      "epoch: 49 [579942/888800 65.25%] train loss: 1.303046792600071e-05 \n",
      "epoch: 49 [581053/888800 65.38%] train loss: 1.4284171811596025e-05 \n",
      "epoch: 49 [582164/888800 65.50%] train loss: 1.3775083971268032e-05 \n",
      "epoch: 49 [583275/888800 65.62%] train loss: 1.445813995815115e-05 \n",
      "epoch: 49 [584386/888800 65.75%] train loss: 1.2901514310215134e-05 \n",
      "epoch: 49 [585497/888800 65.88%] train loss: 1.3309124369698111e-05 \n",
      "epoch: 49 [586608/888800 66.00%] train loss: 1.4031117643753532e-05 \n",
      "epoch: 49 [587719/888800 66.12%] train loss: 1.3566021152655594e-05 \n",
      "epoch: 49 [588830/888800 66.25%] train loss: 1.5126541256904602e-05 \n",
      "epoch: 49 [589941/888800 66.38%] train loss: 1.395629169564927e-05 \n",
      "epoch: 49 [591052/888800 66.50%] train loss: 1.430212432751432e-05 \n",
      "epoch: 49 [592163/888800 66.62%] train loss: 1.4297654161055107e-05 \n",
      "epoch: 49 [593274/888800 66.75%] train loss: 1.3724010386795271e-05 \n",
      "epoch: 49 [594385/888800 66.88%] train loss: 1.4079912943998352e-05 \n",
      "epoch: 49 [595496/888800 67.00%] train loss: 1.3901677448302507e-05 \n",
      "epoch: 49 [596607/888800 67.12%] train loss: 1.3003163076064084e-05 \n",
      "epoch: 49 [597718/888800 67.25%] train loss: 1.397765754518332e-05 \n",
      "epoch: 49 [598829/888800 67.38%] train loss: 1.4331666534417309e-05 \n",
      "epoch: 49 [599940/888800 67.50%] train loss: 1.4028671103005763e-05 \n",
      "epoch: 49 [601051/888800 67.62%] train loss: 1.3556970770878252e-05 \n",
      "epoch: 49 [602162/888800 67.75%] train loss: 1.4533207831846084e-05 \n",
      "epoch: 49 [603273/888800 67.88%] train loss: 1.4327649296319578e-05 \n",
      "epoch: 49 [604384/888800 68.00%] train loss: 1.3911915630160365e-05 \n",
      "epoch: 49 [605495/888800 68.12%] train loss: 1.432503904652549e-05 \n",
      "epoch: 49 [606606/888800 68.25%] train loss: 1.3401614523900207e-05 \n",
      "epoch: 49 [607717/888800 68.38%] train loss: 1.4021337847225368e-05 \n",
      "epoch: 49 [608828/888800 68.50%] train loss: 1.3242582099337596e-05 \n",
      "epoch: 49 [609939/888800 68.62%] train loss: 1.4326062228064984e-05 \n",
      "epoch: 49 [611050/888800 68.75%] train loss: 1.3859986211173236e-05 \n",
      "epoch: 49 [612161/888800 68.88%] train loss: 1.475395038141869e-05 \n",
      "epoch: 49 [613272/888800 69.00%] train loss: 1.4589229976991192e-05 \n",
      "epoch: 49 [614383/888800 69.12%] train loss: 1.3997159840073436e-05 \n",
      "epoch: 49 [615494/888800 69.25%] train loss: 1.4211620509740897e-05 \n",
      "epoch: 49 [616605/888800 69.38%] train loss: 1.5997184164007194e-05 \n",
      "epoch: 49 [617716/888800 69.50%] train loss: 1.4652468962594867e-05 \n",
      "epoch: 49 [618827/888800 69.62%] train loss: 1.4278790331445634e-05 \n",
      "epoch: 49 [619938/888800 69.75%] train loss: 1.5438814443768933e-05 \n",
      "epoch: 49 [621049/888800 69.88%] train loss: 1.5444638847839087e-05 \n",
      "epoch: 49 [622160/888800 70.00%] train loss: 1.452851211070083e-05 \n",
      "epoch: 49 [623271/888800 70.12%] train loss: 1.4849973013042472e-05 \n",
      "epoch: 49 [624382/888800 70.25%] train loss: 1.4175965588947292e-05 \n",
      "epoch: 49 [625493/888800 70.38%] train loss: 1.4162425941321999e-05 \n",
      "epoch: 49 [626604/888800 70.50%] train loss: 1.4938295862521045e-05 \n",
      "epoch: 49 [627715/888800 70.62%] train loss: 1.3317733646545094e-05 \n",
      "epoch: 49 [628826/888800 70.75%] train loss: 1.4089296200836543e-05 \n",
      "epoch: 49 [629937/888800 70.88%] train loss: 1.4482097867585253e-05 \n",
      "epoch: 49 [631048/888800 71.00%] train loss: 1.5294070180971175e-05 \n",
      "epoch: 49 [632159/888800 71.12%] train loss: 1.3857494195690379e-05 \n",
      "epoch: 49 [633270/888800 71.25%] train loss: 1.5739587979624048e-05 \n",
      "epoch: 49 [634381/888800 71.38%] train loss: 1.355372751277173e-05 \n",
      "epoch: 49 [635492/888800 71.50%] train loss: 1.4397727682080586e-05 \n",
      "epoch: 49 [636603/888800 71.62%] train loss: 1.4258059309213422e-05 \n",
      "epoch: 49 [637714/888800 71.75%] train loss: 1.3801321983919479e-05 \n",
      "epoch: 49 [638825/888800 71.88%] train loss: 1.4545847079716623e-05 \n",
      "epoch: 49 [639936/888800 72.00%] train loss: 1.4683773770229891e-05 \n",
      "epoch: 49 [641047/888800 72.12%] train loss: 1.556274582981132e-05 \n",
      "epoch: 49 [642158/888800 72.25%] train loss: 1.576803879288491e-05 \n",
      "epoch: 49 [643269/888800 72.38%] train loss: 1.5238375453918707e-05 \n",
      "epoch: 49 [644380/888800 72.50%] train loss: 1.3892251445213333e-05 \n",
      "epoch: 49 [645491/888800 72.62%] train loss: 1.6042347851907834e-05 \n",
      "epoch: 49 [646602/888800 72.75%] train loss: 1.4074329556024168e-05 \n",
      "epoch: 49 [647713/888800 72.88%] train loss: 1.467546280764509e-05 \n",
      "epoch: 49 [648824/888800 73.00%] train loss: 1.5304449334507808e-05 \n",
      "epoch: 49 [649935/888800 73.12%] train loss: 1.4550669220625423e-05 \n",
      "epoch: 49 [651046/888800 73.25%] train loss: 1.3051820133114234e-05 \n",
      "epoch: 49 [652157/888800 73.38%] train loss: 1.3967784980195574e-05 \n",
      "epoch: 49 [653268/888800 73.50%] train loss: 1.3349948858376592e-05 \n",
      "epoch: 49 [654379/888800 73.62%] train loss: 1.4567112884833477e-05 \n",
      "epoch: 49 [655490/888800 73.75%] train loss: 1.389092176395934e-05 \n",
      "epoch: 49 [656601/888800 73.88%] train loss: 1.4472098882833961e-05 \n",
      "epoch: 49 [657712/888800 74.00%] train loss: 1.5649284250685014e-05 \n",
      "epoch: 49 [658823/888800 74.12%] train loss: 1.3624231542053167e-05 \n",
      "epoch: 49 [659934/888800 74.25%] train loss: 1.4999014638306107e-05 \n",
      "epoch: 49 [661045/888800 74.38%] train loss: 1.4053166523808613e-05 \n",
      "epoch: 49 [662156/888800 74.50%] train loss: 1.4256671420298517e-05 \n",
      "epoch: 49 [663267/888800 74.62%] train loss: 1.4038691006135195e-05 \n",
      "epoch: 49 [664378/888800 74.75%] train loss: 1.31940551000298e-05 \n",
      "epoch: 49 [665489/888800 74.88%] train loss: 1.4226307030185126e-05 \n",
      "epoch: 49 [666600/888800 75.00%] train loss: 1.4264730452850927e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [667711/888800 75.12%] train loss: 1.4044626368558966e-05 \n",
      "epoch: 49 [668822/888800 75.25%] train loss: 1.3257324098958634e-05 \n",
      "epoch: 49 [669933/888800 75.38%] train loss: 1.4376643775904085e-05 \n",
      "epoch: 49 [671044/888800 75.50%] train loss: 1.3342403690330684e-05 \n",
      "epoch: 49 [672155/888800 75.62%] train loss: 1.4205080333340447e-05 \n",
      "epoch: 49 [673266/888800 75.75%] train loss: 1.427762344974326e-05 \n",
      "epoch: 49 [674377/888800 75.88%] train loss: 1.4416414160223212e-05 \n",
      "epoch: 49 [675488/888800 76.00%] train loss: 1.4101068700256292e-05 \n",
      "epoch: 49 [676599/888800 76.12%] train loss: 1.4165103493724018e-05 \n",
      "epoch: 49 [677710/888800 76.25%] train loss: 1.417964722350007e-05 \n",
      "epoch: 49 [678821/888800 76.38%] train loss: 1.4400379768630955e-05 \n",
      "epoch: 49 [679932/888800 76.50%] train loss: 1.3379646588873584e-05 \n",
      "epoch: 49 [681043/888800 76.62%] train loss: 1.4479881428997032e-05 \n",
      "epoch: 49 [682154/888800 76.75%] train loss: 1.3685362318938132e-05 \n",
      "epoch: 49 [683265/888800 76.88%] train loss: 1.43635697895661e-05 \n",
      "epoch: 49 [684376/888800 77.00%] train loss: 1.437435821571853e-05 \n",
      "epoch: 49 [685487/888800 77.12%] train loss: 1.3689087609236594e-05 \n",
      "epoch: 49 [686598/888800 77.25%] train loss: 1.3592278264695778e-05 \n",
      "epoch: 49 [687709/888800 77.38%] train loss: 1.3758673958363943e-05 \n",
      "epoch: 49 [688820/888800 77.50%] train loss: 1.50474370457232e-05 \n",
      "epoch: 49 [689931/888800 77.62%] train loss: 1.397915093548363e-05 \n",
      "epoch: 49 [691042/888800 77.75%] train loss: 1.3742971532337833e-05 \n",
      "epoch: 49 [692153/888800 77.88%] train loss: 1.5735242413938977e-05 \n",
      "epoch: 49 [693264/888800 78.00%] train loss: 1.4561551324732136e-05 \n",
      "epoch: 49 [694375/888800 78.12%] train loss: 1.4210630070010666e-05 \n",
      "epoch: 49 [695486/888800 78.25%] train loss: 1.4438390280702151e-05 \n",
      "epoch: 49 [696597/888800 78.38%] train loss: 1.5784349670866504e-05 \n",
      "epoch: 49 [697708/888800 78.50%] train loss: 1.3792274330626242e-05 \n",
      "epoch: 49 [698819/888800 78.62%] train loss: 1.4746704437129665e-05 \n",
      "epoch: 49 [699930/888800 78.75%] train loss: 1.316906764259329e-05 \n",
      "epoch: 49 [701041/888800 78.88%] train loss: 1.3974273315398023e-05 \n",
      "epoch: 49 [702152/888800 79.00%] train loss: 1.555162452859804e-05 \n",
      "epoch: 49 [703263/888800 79.12%] train loss: 1.4755721167603042e-05 \n",
      "epoch: 49 [704374/888800 79.25%] train loss: 1.6668411262799054e-05 \n",
      "epoch: 49 [705485/888800 79.38%] train loss: 1.4181458027451299e-05 \n",
      "epoch: 49 [706596/888800 79.50%] train loss: 1.3467040844261646e-05 \n",
      "epoch: 49 [707707/888800 79.62%] train loss: 1.4914272469468415e-05 \n",
      "epoch: 49 [708818/888800 79.75%] train loss: 1.3111681255395524e-05 \n",
      "epoch: 49 [709929/888800 79.88%] train loss: 1.3121905794832855e-05 \n",
      "epoch: 49 [711040/888800 80.00%] train loss: 1.3034693438385148e-05 \n",
      "epoch: 49 [712151/888800 80.12%] train loss: 1.5365190847660415e-05 \n",
      "epoch: 49 [713262/888800 80.25%] train loss: 1.4383015695784707e-05 \n",
      "epoch: 49 [714373/888800 80.38%] train loss: 1.3499918168236036e-05 \n",
      "epoch: 49 [715484/888800 80.50%] train loss: 1.4282228221418336e-05 \n",
      "epoch: 49 [716595/888800 80.62%] train loss: 1.3729748388868757e-05 \n",
      "epoch: 49 [717706/888800 80.75%] train loss: 1.5165077456913423e-05 \n",
      "epoch: 49 [718817/888800 80.88%] train loss: 1.3955886970506981e-05 \n",
      "epoch: 49 [719928/888800 81.00%] train loss: 1.424088804924395e-05 \n",
      "epoch: 49 [721039/888800 81.12%] train loss: 1.310459447267931e-05 \n",
      "epoch: 49 [722150/888800 81.25%] train loss: 1.4987711438152473e-05 \n",
      "epoch: 49 [723261/888800 81.38%] train loss: 1.2955470083397813e-05 \n",
      "epoch: 49 [724372/888800 81.50%] train loss: 1.3215037142799702e-05 \n",
      "epoch: 49 [725483/888800 81.62%] train loss: 1.6639492969261482e-05 \n",
      "epoch: 49 [726594/888800 81.75%] train loss: 1.3818749721394852e-05 \n",
      "epoch: 49 [727705/888800 81.88%] train loss: 1.4886632925481535e-05 \n",
      "epoch: 49 [728816/888800 82.00%] train loss: 1.5198607798083685e-05 \n",
      "epoch: 49 [729927/888800 82.12%] train loss: 1.358933423034614e-05 \n",
      "epoch: 49 [731038/888800 82.25%] train loss: 1.531660745968111e-05 \n",
      "epoch: 49 [732149/888800 82.38%] train loss: 1.3611985195893794e-05 \n",
      "epoch: 49 [733260/888800 82.50%] train loss: 1.5282850654330105e-05 \n",
      "epoch: 49 [734371/888800 82.62%] train loss: 1.4295737855718471e-05 \n",
      "epoch: 49 [735482/888800 82.75%] train loss: 1.4592544175684452e-05 \n",
      "epoch: 49 [736593/888800 82.88%] train loss: 1.4694131095893681e-05 \n",
      "epoch: 49 [737704/888800 83.00%] train loss: 1.598617745912634e-05 \n",
      "epoch: 49 [738815/888800 83.12%] train loss: 1.6700185369700193e-05 \n",
      "epoch: 49 [739926/888800 83.25%] train loss: 1.3893015420762822e-05 \n",
      "epoch: 49 [741037/888800 83.38%] train loss: 1.7201398804900236e-05 \n",
      "epoch: 49 [742148/888800 83.50%] train loss: 1.3935890819993801e-05 \n",
      "epoch: 49 [743259/888800 83.62%] train loss: 1.5384946891572326e-05 \n",
      "epoch: 49 [744370/888800 83.75%] train loss: 1.454456287319772e-05 \n",
      "epoch: 49 [745481/888800 83.88%] train loss: 1.35304226205335e-05 \n",
      "epoch: 49 [746592/888800 84.00%] train loss: 1.4843062672298402e-05 \n",
      "epoch: 49 [747703/888800 84.12%] train loss: 1.5585874280077405e-05 \n",
      "epoch: 49 [748814/888800 84.25%] train loss: 1.49329889609362e-05 \n",
      "epoch: 49 [749925/888800 84.38%] train loss: 1.3729772035731003e-05 \n",
      "epoch: 49 [751036/888800 84.50%] train loss: 1.496405093348585e-05 \n",
      "epoch: 49 [752147/888800 84.62%] train loss: 1.5911957234493457e-05 \n",
      "epoch: 49 [753258/888800 84.75%] train loss: 1.3875437616661657e-05 \n",
      "epoch: 49 [754369/888800 84.88%] train loss: 1.3553343706007581e-05 \n",
      "epoch: 49 [755480/888800 85.00%] train loss: 1.5131317923078313e-05 \n",
      "epoch: 49 [756591/888800 85.12%] train loss: 1.2604705261765048e-05 \n",
      "epoch: 49 [757702/888800 85.25%] train loss: 1.396334573655622e-05 \n",
      "epoch: 49 [758813/888800 85.38%] train loss: 1.3783490430796519e-05 \n",
      "epoch: 49 [759924/888800 85.50%] train loss: 1.4626260963268578e-05 \n",
      "epoch: 49 [761035/888800 85.62%] train loss: 1.3975864931126125e-05 \n",
      "epoch: 49 [762146/888800 85.75%] train loss: 1.5256301594490651e-05 \n",
      "epoch: 49 [763257/888800 85.88%] train loss: 1.4100336557021365e-05 \n",
      "epoch: 49 [764368/888800 86.00%] train loss: 1.5080880984896794e-05 \n",
      "epoch: 49 [765479/888800 86.12%] train loss: 1.3326695807336364e-05 \n",
      "epoch: 49 [766590/888800 86.25%] train loss: 1.4384911992237903e-05 \n",
      "epoch: 49 [767701/888800 86.38%] train loss: 1.4334209481603466e-05 \n",
      "epoch: 49 [768812/888800 86.50%] train loss: 1.5508248907281086e-05 \n",
      "epoch: 49 [769923/888800 86.62%] train loss: 1.4836629816272762e-05 \n",
      "epoch: 49 [771034/888800 86.75%] train loss: 1.3986745216243435e-05 \n",
      "epoch: 49 [772145/888800 86.88%] train loss: 1.353512197965756e-05 \n",
      "epoch: 49 [773256/888800 87.00%] train loss: 1.4193071365298238e-05 \n",
      "epoch: 49 [774367/888800 87.12%] train loss: 1.4460395505011547e-05 \n",
      "epoch: 49 [775478/888800 87.25%] train loss: 1.3112098713463638e-05 \n",
      "epoch: 49 [776589/888800 87.38%] train loss: 1.4706155525345821e-05 \n",
      "epoch: 49 [777700/888800 87.50%] train loss: 1.5300103768822737e-05 \n",
      "epoch: 49 [778811/888800 87.62%] train loss: 1.3552526070270687e-05 \n",
      "epoch: 49 [779922/888800 87.75%] train loss: 1.37455708681955e-05 \n",
      "epoch: 49 [781033/888800 87.88%] train loss: 1.3721361938223708e-05 \n",
      "epoch: 49 [782144/888800 88.00%] train loss: 1.3584248335973825e-05 \n",
      "epoch: 49 [783255/888800 88.12%] train loss: 1.5064592844282743e-05 \n",
      "epoch: 49 [784366/888800 88.25%] train loss: 1.4742493476660457e-05 \n",
      "epoch: 49 [785477/888800 88.38%] train loss: 1.3456186024995986e-05 \n",
      "epoch: 49 [786588/888800 88.50%] train loss: 1.4509019820252433e-05 \n",
      "epoch: 49 [787699/888800 88.62%] train loss: 1.3277568541525397e-05 \n",
      "epoch: 49 [788810/888800 88.75%] train loss: 1.521155809314223e-05 \n",
      "epoch: 49 [789921/888800 88.88%] train loss: 1.4219017430150416e-05 \n",
      "epoch: 49 [791032/888800 89.00%] train loss: 1.4527267921948805e-05 \n",
      "epoch: 49 [792143/888800 89.12%] train loss: 1.5093102774699219e-05 \n",
      "epoch: 49 [793254/888800 89.25%] train loss: 1.4967747119953856e-05 \n",
      "epoch: 49 [794365/888800 89.38%] train loss: 1.4103127796261106e-05 \n",
      "epoch: 49 [795476/888800 89.50%] train loss: 1.4979637853684835e-05 \n",
      "epoch: 49 [796587/888800 89.62%] train loss: 1.3590848539024591e-05 \n",
      "epoch: 49 [797698/888800 89.75%] train loss: 1.4503110833175015e-05 \n",
      "epoch: 49 [798809/888800 89.88%] train loss: 1.499307018093532e-05 \n",
      "epoch: 49 [799920/888800 90.00%] train loss: 1.2650113603740465e-05 \n",
      "epoch: 49 [801031/888800 90.12%] train loss: 1.4408917195396498e-05 \n",
      "epoch: 49 [802142/888800 90.25%] train loss: 1.297858398174867e-05 \n",
      "epoch: 49 [803253/888800 90.38%] train loss: 1.4313632163975853e-05 \n",
      "epoch: 49 [804364/888800 90.50%] train loss: 1.4511407243844587e-05 \n",
      "epoch: 49 [805475/888800 90.62%] train loss: 1.4421626474359073e-05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 [806586/888800 90.75%] train loss: 1.515569329058053e-05 \n",
      "epoch: 49 [807697/888800 90.88%] train loss: 1.4744992768100929e-05 \n",
      "epoch: 49 [808808/888800 91.00%] train loss: 1.3852391930413432e-05 \n",
      "epoch: 49 [809919/888800 91.12%] train loss: 1.441005679225782e-05 \n",
      "epoch: 49 [811030/888800 91.25%] train loss: 1.4195979929354507e-05 \n",
      "epoch: 49 [812141/888800 91.38%] train loss: 1.3594751180789899e-05 \n",
      "epoch: 49 [813252/888800 91.50%] train loss: 1.469555172661785e-05 \n",
      "epoch: 49 [814363/888800 91.62%] train loss: 1.5008581613074057e-05 \n",
      "epoch: 49 [815474/888800 91.75%] train loss: 1.4838751667411998e-05 \n",
      "epoch: 49 [816585/888800 91.88%] train loss: 1.433380111848237e-05 \n",
      "epoch: 49 [817696/888800 92.00%] train loss: 1.4283390555647202e-05 \n",
      "epoch: 49 [818807/888800 92.12%] train loss: 1.4146171452011913e-05 \n",
      "epoch: 49 [819918/888800 92.25%] train loss: 1.3519171261577867e-05 \n",
      "epoch: 49 [821029/888800 92.38%] train loss: 1.3132610547472723e-05 \n",
      "epoch: 49 [822140/888800 92.50%] train loss: 1.4840869880572427e-05 \n",
      "epoch: 49 [823251/888800 92.62%] train loss: 1.4292901141743641e-05 \n",
      "epoch: 49 [824362/888800 92.75%] train loss: 1.4113697034190409e-05 \n",
      "epoch: 49 [825473/888800 92.88%] train loss: 1.3330133697309066e-05 \n",
      "epoch: 49 [826584/888800 93.00%] train loss: 1.2919863365823403e-05 \n",
      "epoch: 49 [827695/888800 93.12%] train loss: 1.4348814147524536e-05 \n",
      "epoch: 49 [828806/888800 93.25%] train loss: 1.2866619726992212e-05 \n",
      "epoch: 49 [829917/888800 93.38%] train loss: 1.4588468729925808e-05 \n",
      "epoch: 49 [831028/888800 93.50%] train loss: 1.4011393432156183e-05 \n",
      "epoch: 49 [832139/888800 93.62%] train loss: 1.5103950318007264e-05 \n",
      "epoch: 49 [833250/888800 93.75%] train loss: 1.3825893802277278e-05 \n",
      "epoch: 49 [834361/888800 93.88%] train loss: 1.324445656791795e-05 \n",
      "epoch: 49 [835472/888800 94.00%] train loss: 1.2826798410969786e-05 \n",
      "epoch: 49 [836583/888800 94.12%] train loss: 1.4426879715756513e-05 \n",
      "epoch: 49 [837694/888800 94.25%] train loss: 1.3184604540583678e-05 \n",
      "epoch: 49 [838805/888800 94.38%] train loss: 1.4005752746015787e-05 \n",
      "epoch: 49 [839916/888800 94.50%] train loss: 1.404984595865244e-05 \n",
      "epoch: 49 [841027/888800 94.62%] train loss: 1.3776993000647053e-05 \n",
      "epoch: 49 [842138/888800 94.75%] train loss: 1.4082680536375847e-05 \n",
      "epoch: 49 [843249/888800 94.88%] train loss: 1.4374449165188707e-05 \n",
      "epoch: 49 [844360/888800 95.00%] train loss: 1.3880970072932541e-05 \n",
      "epoch: 49 [845471/888800 95.12%] train loss: 1.3971466614748351e-05 \n",
      "epoch: 49 [846582/888800 95.25%] train loss: 1.5304518456105143e-05 \n",
      "epoch: 49 [847693/888800 95.38%] train loss: 1.4061881302041002e-05 \n",
      "epoch: 49 [848804/888800 95.50%] train loss: 1.3447379387798719e-05 \n",
      "epoch: 49 [849915/888800 95.62%] train loss: 1.4557323083863594e-05 \n",
      "epoch: 49 [851026/888800 95.75%] train loss: 1.504255851614289e-05 \n",
      "epoch: 49 [852137/888800 95.88%] train loss: 1.5273191820597276e-05 \n",
      "epoch: 49 [853248/888800 96.00%] train loss: 1.7027212379616685e-05 \n",
      "epoch: 49 [854359/888800 96.12%] train loss: 1.4029134035808966e-05 \n",
      "epoch: 49 [855470/888800 96.25%] train loss: 1.4992969227023423e-05 \n",
      "epoch: 49 [856581/888800 96.38%] train loss: 1.2867430086771492e-05 \n",
      "epoch: 49 [857692/888800 96.50%] train loss: 1.535766205051914e-05 \n",
      "epoch: 49 [858803/888800 96.62%] train loss: 1.4318172361527104e-05 \n",
      "epoch: 49 [859914/888800 96.75%] train loss: 1.4686541362607386e-05 \n",
      "epoch: 49 [861025/888800 96.88%] train loss: 1.484615040681092e-05 \n",
      "epoch: 49 [862136/888800 97.00%] train loss: 1.3360355296754278e-05 \n",
      "epoch: 49 [863247/888800 97.12%] train loss: 1.4646339877799619e-05 \n",
      "epoch: 49 [864358/888800 97.25%] train loss: 1.4872090105200186e-05 \n",
      "epoch: 49 [865469/888800 97.38%] train loss: 1.5470675862161443e-05 \n",
      "epoch: 49 [866580/888800 97.50%] train loss: 1.3897757526137866e-05 \n",
      "epoch: 49 [867691/888800 97.62%] train loss: 1.4652053323516157e-05 \n",
      "epoch: 49 [868802/888800 97.75%] train loss: 1.460343355574878e-05 \n",
      "epoch: 49 [869913/888800 97.88%] train loss: 1.491179773438489e-05 \n",
      "epoch: 49 [871024/888800 98.00%] train loss: 1.3678981304110494e-05 \n",
      "epoch: 49 [872135/888800 98.12%] train loss: 1.35777718242025e-05 \n",
      "epoch: 49 [873246/888800 98.25%] train loss: 1.4715880752191879e-05 \n",
      "epoch: 49 [874357/888800 98.38%] train loss: 1.3615524949273095e-05 \n",
      "epoch: 49 [875468/888800 98.50%] train loss: 1.4004181139171124e-05 \n",
      "epoch: 49 [876579/888800 98.62%] train loss: 1.6674151993356645e-05 \n",
      "epoch: 49 [877690/888800 98.75%] train loss: 1.6580412193434313e-05 \n",
      "epoch: 49 [878801/888800 98.88%] train loss: 1.4480139725492336e-05 \n",
      "epoch: 49 [879912/888800 99.00%] train loss: 1.6059262634371407e-05 \n",
      "epoch: 49 [881023/888800 99.12%] train loss: 1.3794856386084575e-05 \n",
      "epoch: 49 [882134/888800 99.25%] train loss: 1.5038435776659753e-05 \n",
      "epoch: 49 [883245/888800 99.38%] train loss: 1.3068303815089166e-05 \n",
      "epoch: 49 [884356/888800 99.50%] train loss: 1.6388215954066254e-05 \n",
      "epoch: 49 [885467/888800 99.62%] train loss: 1.3070087334199343e-05 \n",
      "epoch: 49 [886578/888800 99.75%] train loss: 1.5231998077069875e-05 \n",
      "epoch: 49 [887689/888800 99.88%] train loss: 1.4207342246663757e-05 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \"\"\"利用分割后的数据对neural network进行训练\"\"\"\n",
    "    \"\"\"这里发现一个问题，由于原文中使用四层隐含层，每层7个Units的简单模型，造成模型的拟合能力较差，\n",
    "    很多情况下对于训练数据并不能很好收敛，大概5六次中会有一次loss可以正常下降，在最初的尝试中，我们\n",
    "    以为是由于weights initialization造成的，在尝试了不同的weight initalization之后发现，不同的\n",
    "    权重初始化对这个简单模型的结果差异不大，即都会出现多数不收敛，少数可以收敛的情况，如果某单次训练Loss\n",
    "    没有正常收敛，不用灰心，请重新训练\"\"\"\n",
    "    \"\"\"BP模型实例\"\"\"\n",
    "    Gpu = torch.device(\"cuda\")\n",
    "    Bp_kalman = BpFilter().to(Gpu)\n",
    "    # for m in Bp_kalman.modules():\n",
    "    #     if isinstance(m, nn.Conv2d):\n",
    "    #         nn.init.xavier_normal_(m.weight.data)\n",
    "    #     elif isinstance(m, nn.Linear):\n",
    "    #         nn.init.xavier_normal_(m.weight.data)\n",
    "    # for m in Bp_kalman.modules():\n",
    "    #     if isinstance(m, nn.Conv2d):\n",
    "    #         nn.init.xavier_normal_(m.weight.data)\n",
    "    #     elif isinstance(m, nn.Linear):\n",
    "    #         nn.init.xavier_normal_(m.weight.data)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(Bp_kalman.parameters(), lr=0.001)\n",
    "    train_loss, validation_loss = Fit(Bp_kalman, train_loader, Gpu, optimizer, criterion, 50)\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADt0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjByYzMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy9h23ruAAAgAElEQVR4nOydd3gU1frHv2dmW3oooZfQkaqAiIqCYsGuqD8LNmzXrlevXRE7dsUC14LYsJdrARsIiIKIoAIKCEgvSUhPtkw5vz+mt93Zzaawzud58mR36tndmXfe81ZCKYWHh4eHR+bCNPcAPDw8PDwaF0/Qe3h4eGQ4nqD38PDwyHA8Qe/h4eGR4XiC3sPDwyPD8TX3AOxo27YtLS4ubu5heHh4eOwz/PLLL2WU0iK7dS1S0BcXF2P58uXNPQwPDw+PfQZCyBandZ7pxsPDwyPD8QS9h4eHR4bjCXoPDw+PDMcT9B4eHh4ZjifoPTw8PDIcT9B7eHh4ZDieoPfw8PDIcDxBvw+wcH0ptpXXN/cwPDw89lE8Qb8PcOHMZRj35MLmHoaHh8c+iifo9xFivNjcQ/Dw8NhH8QS9h4eHR4bjCXoPDw+PDMcT9B4eHh4ZjifoPTw8PDIcT9B7eHh4ZDieoPfw8PDIcDxB7+Hh4ZHheILew8PDI8PxBL2Hh4dHhuMJeg8PD48MxxP0Hh4eHhmOJ+g9PDw8MhxP0Ht4eHhkOJ6g9/Dw8MhwPEG/DzCeWYYeZFdzD8PDw2MfxdfcA/CID6UUMwJPy+8ubdaxeHh47Jt4Gn0Lh9LmHoGHh8e+TkYJ+j92VuNfbywHJ2RONyZPznt4eDSUjBL0/373V3y1Zg82lNQ291DSBvVUeg8PjwaSUNATQmYSQkoIIasd1hNCyDRCyAZCyO+EkGFu9003hDTFWZoWT8x7eHg0FDca/SwA4+OsPw5AH/nvcgDTk9jXIwGeQu/h4dFQEgp6SukiAOVxNjkFwOtUYimAQkJIR5f7tmhEkTa76YR6Or2Hh0cDSYeNvjOAbbr32+VlSUEIuZwQspwQsry0tDQNw2o4Pe+Yg5ve+61Zx5DKc2ZjaS0WrCtJ/2A8PDz2SdIh6O0s40mLJ0rpi5TSEZTSEUVFRQ0aUDqV8I9W7kjfwZqIcU8sxEWv/tzcw4gLpRTv/bwNUV5o7qF4eGQ86RD02wF01b3vAmBnGo7bIHhBxN9ldXG3oZRiy9742zQ3mWqjn7NqN2758Hc88+1fzT0UD4+MJx2C/lMAF8jRN6MAVFFKmz1f/7Gv1+GIxxdgW3m97foZCzeix+1zMOaxBVizs8qyvqls85+s3OE4RiBzbfTVEQ4AsLc21swj8fDIfNyEV74NYAmAfoSQ7YSQSwghVxBCrpA3mQNgE4ANAF4CcFW8fdP+CRz4aZPkAy6pidqun/XDZvW1naDlhKYRsDe8+ytOfm6x7brn5v+FL1fvbpJxNDWKvS9TH2QeHi2JhLVuKKXnJFhPAVydyr6NiRZTby9I9ALGLpGWF+Nn1woiBUMAkobg/Yp6zjo+SvH41+sBUEwINfgUaSXCCbj3szW4+dj+aJ0TSOkYmZjz4OHRUsmozFhCRRSgFhRU0xgdFEZRt1yw2SieRl9ZH0OvO+bg5e//bsBo45uHtleEAQCkBWq8n6zcgbeXbcNjX61t8LEy1Qfh4dGSyChBPzH6Dn4LXQ42XKZq2k5yRC9gRNFO0Dtr9LuqIgCAD37ZnvJYzWMw88OGMgBAx7xgwuP8vr0SP29uunQF5etqiJBO9Pt4eHikj4wS9IfGfgQA+OpLE2r0em2atxH0vAsbfUPND/HOoDxoWmUnriR98nM/4MwZSxo2mBRoyOdP9Pt4ZDartlehst5zxDcVGSXo9ZJHeelkHtEvTaTRx3ijdp8u4RTPdKOsERP4CpqKL37fpTqG0+lA9Zyx/0xOem4xzmgG5eSfSmYJehUKgkSmG50zllKU1ERQG+XVZbxIcZPvPRzMrMGDX/yR1NmrIxyG3/9NQnNKPBGnDE9M4alSiJq0d6S6evYKXPHmL6alqav0qhPbk/P/WDKpymxLJzMFPYUqg1w5Y0WKkQ/Ow3HPLFKX8YKIa32f4O3Ag/hzV43p8PGl069bK7G3LpYwGSieEFceRDQFjf6b4M34LnhT0vu5JR0zGkIFXMX+DwEx3PCDeXh4xCWjBL1e/rQVSnCH7y1Qap9i35pW4Ar2U9zlewNUkMIbt5VrQiemd8aaFFdF0ClaqSBSfLRiOwT56aGMI5ENm1IgD/VgYR0jVbfRPlU45q5cQBGptuzbGDTERt91x1zc4n8Xx5W+kr4BeXh42JJRgl7PdZWP4HLfF8gt+912/bN4BLf538GlvrnoVLLIsp7ntNh2J3mmLH972Vbc+N5veHPpFgCagCWEIBwTsHC9c5G2VaFL8YR/umU5pcAJzFL057UQxv0mf+l4HDvMroeaCBc3C7cp8YlS5FJQkEpQlFRHcP/nf6gPSw8Pj/SRsYKeobJGTu1NH+2ozn4uaN7/4tu+wNrd1RC5iLrMTnM9kKxFkErbKNEDJTXSe1XjB3DnJ6tw4cxl2FBSg+/Wlhhq6yjbncr+aDk+pSKeD0zDs9w9cT9nPMxC84zpS3DYo98BAL5cvcvgk0gGf6wSnwfuQOuoFF768crtWL3DWkYiHkqmg5IncMfHq/DK4r/x/V8to3KpR+PR0JlmOCbg3Z+3NnsJ8X2JDBX0FFSJ03awcTPQlouCMTP145U7wHNa6QRi0un9NdvxfvA+XFf/HA5/9Ds5g1UL01Rs+IQAG0slwV4T4TFp1s8Y89gCbZQOD6H1e2rw7dwPE35KhTzUIx9Wx9bXfxjLJ6zbI/kaNpTU4Io3V+CWDxKXYP7mjz2WWUD3Pd9iELMZY0reAgD8+93fcOKz9mUcnDDH0SsJat69655NpbWqctFcHHDf15g2L7nCdA39jR+c8wdu/XAVFv1VlnBbrzqqRIYJell4UO21OayjtCZqqWqpN9MoiHpBb9LomagkMIuFzdiqE4KiSPHnrmpcPGu5bjTOODljv/1zD3oRqQDoRnRJcBTgt+Bl+D10uWX5HR+tst2+Xrb1b3Vhxrns9eU49mmTaUsed120ITdRAm+5R0KOfGIhRj44r1nHUFHP4clv1ie1j0gphpINaIXqlM5ZKtevqk8wI/1jZzX63fUlvlzdPDUWKaVxEy+bkowS9BFOMddoYTfm6d0hU+fhiMcXGDR6zk7QxzTHbCtxr2Edhf2PJ4jAt3/sAQAMJJvhc9hOPY6oCcqqsDYGSpMrfcCQ5IRlTYRXz+OG+piAh3wv4x7fa8oIAQA7qxoQMUOMphuPfw4iBf4XnIwPA1NS2t8cDOHEqh2VAID5a41NeHZWhvHSok0pnTsZ3ly6BX3unIs91c076wIyTNDrRYZqujFF3SgmAr2A4bkYnvC/gInst+oyQWejv6L8cYczGi80kVJwIkVfsg1fBO/AaZWvxpWmetNNjVy296lv1mPOql3q+OwichrKpFk/y+PVlu2sDCPCOZ/rXN98TPJ9ZVpKUreTqnH0ouGtR+ajmDZ7MqlVZhVVQZ/gPA6X5sWzfsaDc/7E9orGDUz45FdpVu5m5tzYZJSg19CVNXP4tc02+tPZxXjQP1M7Aq85aOvD9Siv096rMe7yex94XMzOBRU4cIKIDkRy9HaNalNaO+2D6iRteV0MVfUcnpn3F9bsrAajCnptnMVJJkE5xfsrmb56IX3I1Pk2CVFWpBDP+OUjXKFq9B7/NFLRDaK8gPlr9xiWJbp21DBn05ZKEIIyjktfW47nv9uQ/KAS0JLKfGSUoKe6H5QqH83hW9b/9Gu2axE4xzLLACpi195Kw3EvmPmTtq+qiUtHOY/9FpP9b2BUybvgBVE9dnkdj678VjzvfxpEiMEHHkRvztE5ik9+7gcMve9r3fikcTM6rX9BkklQ9ZGYwZE6jKzHJewc7XOpxcmkFwvWJY54OfulpeodREHACSLyUYcArOav+BhvvsHhn7E5dC78kcQONo99m1SyvR+esxYXz1qOX7ZUAKBJXW9mHct8+m//3IPHvloX9xiUUqzYWuH6nPrztoTooIwS9BpU9zi1N0foTTd+aE6d/waexojd7+P9nzQbnkiJIV1brUMDgkvYL3A0I2nCIb4KnEBVYS6C4JrqJ3ECuwxZe9dgQ+gCzPA/rR1XtB9bDsK4x/8GgIaZbnqSXWo4JQB8FJyCu/1vojWqsTl0Lk6MfiF9njjX4RCy0eA0+22b/gEozQ5+D12GNwMPYeveZKaoRmf50dUfAwByy1cncYx/Nu1QgXw0byvMq9lPMIxYnbERTsAih/yRVLK9N8thyVXhGEbWzMP60IXIqd0cdx9Kk7t/jnpyoaNQfnPpFkx44Ud8t67Edr0dicqwNCUZJegLiV4YW2upXPTqMvQjWzGG+c1guskhRmdJLleKANE5R03ap3IxRDgBd/vfwqHsGgAAEQW0rl2HWYHHAAAiGETk8C5ln2PZ5brj2l8CF7DfqK/NF2oy2sEbgYdtl3ciktZ8bOwbPDf/L9U5a4ZSik+Dd+OTwGTzCgDAwcwfagbxSGYdDn/sO/MhHFGn1Q4hpqkQ4QRU2TRxyVSWha7GwuC/m3UMN/vfw0fBKZblD3zxBy6Yucy2TaeTghMPLTeFYES9FAWWWxU/2qegZj02hs7HgOrvXZ1jQ0mto9KzVO5Y53Sv2OFDDCPIWs90k266EG3ar5hu9IJxwbpSfBW8Da8FHlFt4ACQD6smGtBp+SKI6ccy2ugVCBXQv/J701ZW1NmBTrNpC+mG6E+2oiPRonxYU+ROvItmT3UEC3QaRxbs2yiOY1YCADiex+Nfr8cDDkXblHN1Z4xajPKA6sXsslT2dIv54ZkOjp/2vcH89U+gFWmZhcGUa1wfTabQ4IqsuszzeLStlMKL96v+wbD8JP5rbA6dC4a33vdOZqXdcuRM2yQ6ql1Y/SI+CN6HUFVyeQaNQUYJegVKgQivGJLtL6osojlX84l1+qu3AY5i/kSBPiFJdcYaLzQiciC6LNs8Eoady+ioJxfKh9HG1pWUoBWq8WXwNlzgc9bo49k3z5yxBBe9+rPjeoV/+6VkLOVhVxfjsTl0Lq5ntSSt3VURtYG3nhwYQyo5zqrhRDgh4cxD8+Eat6uL8inHPW8qbV4zhocNVHKkHvnEAjXrmQrGa2ZzWZ0adeYEQzkczvwm307uwm7sZswPz/kT53HvS8eslxTDy9jPcSSzAoAxEo0TRPU6rpMduAzjXkHpzkvmX1/E2bb/8Nw/cdwz7mYcDSEzBT2AWiWZRxam8UIHT2etWZ0nsJrz1U8EvMhOBaUUhzw8D9/J3n+zoGcoD0bUBP1BjHOrvZVbKzB3lSbQPg7eg5WhKyzbmTX6eEEu5jCuAlKPo5nlDltrfgpRDjlVHgAAMOrheRj3xELLPu8F7jP4N7io8ZzVEQ797/4SzyTIllRc1sQ0O3r5+0244s0VLSL22CM+bs2I28rD2FRah3v+J5k4zTb6sY8vwFn/XRr3GGdVvozXA48gv2yles0s3lCeIFpGi7tR+K8+fl5+UNzpn42ZgcfRnezGv9/9FVv21qGkJoI+d87F60uk+lUBMYwbfB8AvP0s2Z7ESYH/XbgJf+5KLXEsGTJT0FNRq/4o/+9/95cYy/zq+hgns8amCP2wFWFOwM6qiNqAYyhjTLpgqABWMF4I+zMbAVinmae98CMe/+rPhOOwCnrniybos/6cLwWedNyegYjhZB1A7e2Oe+usHYAGMlsMSrgY0wT9Q76XUCHv89GKHY7nBXSF36i9dhbl0me792gc4ikdA6O/Yl3wQrDRKvhkLVgJxRVtZtl/JBB2HbltAAB/tFK9Zn7ZWhk/WkaZ1LtM0lgYvBFfrNqJWz/8Xe3Z/NFK6Tq+KPw6bvB9hNZb5ro6lnR6q/m4uchIQQ9IjlDphXZRzQo86mpfYvPDEFA15d/xshF5sNS+PZr+xx5ANqvHTARjttHHsW92oiUYzyxLeEyFvswOfBi8F+MrZjts4TQ+bTnhNc37XJ97Z6zmhLU/RyoheC/5H8fm0LlJ7+eRGvEE2Gk1byNIOGSVrwHLEAAUW8vrcOKz34MKDUgCJNKxgMR+Hrv7OBEsRBAQMMSojfcUNgMAuGAr18fSAkKcP68PPIJo/JaKGSnoqShiHLtSfpc+zbAqHMMwsh4FNjZ9QLpIfKK9rVHUCbQ5wTvgA49ckriEgM9soxecvf5v+aZgRuBpx/VOdIlZ08HPZBdgFGM/49DfP8RmKnsmuwCtqBSGWVITwbFPLbJmITr4Tg5i1uIl/+OgYvKVNY9mVyS9j0fq2LXgNCOIInyxamwOTcSl7Bys3lFtyVa/hJ2DwSRRSQJ9+pP0uhVq0R7xu7iZ+Tl4pRq0YefM7UN2gIEAAuD/2O+QJUh1rXKp5KMTGPfOWOqii9pbgYewLnSR62OmSuLO0/sieiEiS6UpvlkNOiQBcOnMH7EgOAUxytpuw1AerIMWIYjGi+o5/7MYzyZ2nLKmOjbxQtOKkFypYAW7EMfH/C86br/07704WNnXJOjZmh14zP8iVkUXATgNH63YgXV7avD6ki244/j91O20Oj/Gz3eF7zMAwJaaHUC7gqQ/i0fToa/51PfOuVgx+WjkBo0ihRMomLAURXYe+y1eFk6wVG292/+m/Opax3Mpdw8hRHWyPhGYIS8932F8Rhv9tvJ6dCXx75Evg7fh45pzkV1+Ph71v4QltasAHKcGRThVnI0/aud94vnx0klmavSGojci5qzahYt8DQ+7q62ULtgAsRe2LOVBHKZp5pAyN0Le/jjOgl50mMpe8cYvuGa2s7ZbF0nGwQRU1WtTTdH0eZWoo9ZUizTIQRgEUnTFaz9ulhbK+zEO6o7yIPhzVzXGPPadWvPfo3HYWZl8gTq9GTEmiBh0z1eq/0qB53mIRFKMipk9+Dgw2ZXpZs3OKlO/BM1pn2QNPwDA6h1VhuRBwNlH2je2Rg2qaC0XNGSUmXUK5qDmt9BnqKA3CENKcdVbyU/pdzIdLMuOUM1B9hCI2gVhwhxSlirxbpIgsT/Hl2t24/PfnUMWeT65sXUnupojCTSc9hUrsSZ0CXpW/ojTp/+Iez5dI8Xey0KC2ERGSIeV1j/1zXps2VuPpZuMFUQ90seyv8txyNT5+Hjl9qT20wt6Jbpr0V+lEESKajl+XuQioESbAR/AbDBoxXZ2/hgv4oRpi/GvN6wRYwTEWEbEgZVbK1TlqirM2/ZLcBbABGAY+ZVcc0pWTGgSyV6UWP2EzUWGCnrti62LxnAgSX56FEaW4T0BjWvOkLZxzvSkQno00mQuNIVz2Hk4i3V2lPZntiZ1PH0VS/NU1nzftq+Wmpt0r/kF/vrdOIFZKvvT5BsHBKu2W6fTio3eFy7Dg75XkMN6DSQai7W7q9GFlMh1ZIwsWl+KWT/8bbuf3tb+UuBJ/BGchKL6DZirz4Pg6i2z2VOf1fob6M38p73wA+av3QORShVgV2/WjmN0rMbXkTeV1uK0F37EHDl8eU9NFO1Rjk3BiXH3U49OGDDyw0mpNaX4ylJx8OrHG+UFbCpt+iS3zBT0Ou35nWVb8X7wvqT2p8ROa3D3AzsL+vSk5qeSPv6w/xU84n/JcX0nkpxDS485Ckj5ljhBmn7rNfZ3/Pfj+cA0UJ5TZwK7q6M46bnFllBOZeZy3t5pmOibh46l7jtYzfrhbzybZNejfzLty5djcfAGDN1r7Uk8aeYSPPSZfScyswDPJlGMKvsIXLgOh7BStjXhoxZloDez0/YYu7ZuxE3vLAcEDl8Hb8VzjD40WL6OGJIwWq2iLorL2c/QRq7RdACzAT+FrrH0bXDK0KUGjV7aRrHR10ScFbYdlWHEeFFt4RkTrHH0t37wO458YqFtMmJjkpGCHjqh+kJgWkqHsLuYtpLOAIAdaGe/E6WO08pFa1OrvW1GTCEapTGxPtik7y2bRHH2tK91FzlBMaMkmlF1OtuVlOKzwB1ohRrDUZSbMEeQtH0Sync9ptmff4Wvv02ukXqmQCmNmxxoR2GdlOvRtX6NYXl1hMN7gfuwPnSh/blsBCWhArrt0mLNWTFiiRR7U1eDSdCtWxq6FvfSGeo1fhCxL81hJ+ffX74Nxbd9gb21UWSVrcId/rfVBMCBzBb744iiremIggFks4tWLlz6Tl/+fiPOmK7NFhRqozwOnToffe+ai153zMG8P/egWqmLo5v51P+1EG/4H0Ik2rQ+p4wU9OYesMkS5URL/DqBZqYIOMS9ElBHjb545+cNGpNKC7D36THHuys3TjtSiVWhS2Gfrk7Vi38QsxmDmc04gDFmOCoPzGxRDmvz5bge09fBW/FZ8K4kPkXm8OaSv3H05NewIwXnqp55f+zGhHtnYjjjPDOyi0BhRB6E0SJvqCjE9eOYfU5HYynGTVUeFLp8DaUPMxiYJT2lFOuXfIZfg5dh/ZadgEszKQWF4NDqT21uomj08vU6K/AYztn5ID582zhDrq+twebQufg4MBmbQ+di3cpFGMv+po5P4SHhKRzGrkasyljZs7GTqjJS0Lv9oZ3oUrLAojX4iYDukJ7iAer0IKGOzthT2B8bNCaFVEw3jYnAG7+L6rDpuzc1aQEgNVxJ4MSlooBH3/0afehm+TAt6wHXUgn++AS+D/4bJX+vSbgtpRQzF65FWM1C1n6lmp9n49vgLfH3t4mjJ1QAZfzaAlGI61cyz1CzSAxLmEulY9mdE1bTDccLOD38AQpJHbD9J9dlkKko2N5PlDDqMRQbvT5D/XR2MV4JPGHYZ9N2yRylKCwjK7S+D3rTjaJATvvvc4b9F67Ziruf+S827GmccggZKegbag/vzeyM69mPl8nGNLJASsUZ25hsnWsssdD+wwmG9yP/ni6/0m7byupKRMqNJRKi1G94L4oibvnzTPV9KjXM/4kMikplPoLh+HXT66MxvD71Slz83UFou+4dAEZHY4d6Fw2/bUKJGcqDsJpG33rt2/j+zQcdDxEvAdDOfEqIdTkXDaM+JEXJ0cptcOtP4zgOe0qt31PX+jVYs/Rrwxji1bXfsHU7Rn18iGGZEMhTX+uVFOV4j5p8ZmM/GIL7K27B9oWzXI09WTIyYSodjk+n+G4ACBHn46ezvrodom6qu3VKP2xtNw6jG/WM8TmBNZZcKDIlpCgJX3rLTdX043AENhu2s5Z6MAmAFvaAa0n89sFUFPY5BN2HHq5+j4S1T+pTWPbRs7gw+jYAyXwmkZz5wM6ZSagA6Ew3/Zjt6Mc4h23GK1msvwfjRd3wsShismmP4cOuY93DH1yJXqK1Vk5rUotTdkoKjNkZa0dsu9VZLfq0qD29cqa/ziMlfyNk2i/EJdfFyi0ZqdEjDYLeTayuBepsukkbuoumG3ZjdMlbaT187eNDQcONcLHpbr5+JiEPSKYxAyZNr6XNZFoSQ1c/jO4fnwRAUzSIEsO9aQGww9oLOBSzyUsw1LZIXAjM7jchVADDxH/IGIgTXGCOktHOYVweXvG2biVxLegH2Qh5yxjkh4ovjjzwZxfa7Kh9B4GI9l3rZyOhF/a37tdItvqEgp4QMpMQUkIIse3xRiSmEUI2EEJ+J4QM060bTwhZJ6+7LZ0Dj0c6YtbdFBwzMzTyMwI0uSzTZGlsG31u7WasW/JF2o87aufrSW0frFiPv5lu6nuDjb5qO1DSNKnj+xRTCtCDlyJoCrfPA3asAF4/BXjpSElB2KorBWwz8zRe8y4Evc0xekfWYP8frnQ9ZMF1sp7s66HWe7PD4rsMAtJcS6chKA9Op4cOALA+mwebLkls0Mop6msmoSBvJkEPYBaA8XHWHwegj/x3OYDpAEAIYQE8L68fAOAcQsiAhgzWiagQxaaqTdjm82EXy6KCq0Y5w6CKIagnBDEgaT27E3XfG1JPseAQypUmmkKzDSdZEqEx6LH0LvQQtUQugynnqYHACwc1w6haPkrDnA6/TwdeOkJdTp8eDMw8VtXuie11JAsZUUDbsH2SlGFrG7NLnphcvaX8d05OavuB312M/pw17FIR/m1q16eY1GSP2aRoQP78dqZixvywEUVA4CzHEwHEANQTghpCUCNGUBYuA5/mMOqENnpK6SJCSHGcTU4B8DqV4oOWEkIKCSEdARQD2EAp3QQAhJB35G0dgmNT5++qv3HmZ2cCXTtJCyIfAN27WLYjlMIHwEcpfBTwgYLV/fdTalhWI+aiLamBn0r7BChFUP7vp0CAUgSgvFfWQX0f0O2TRSlCIkWIUmRRESFRXkYpkpjowlexEYDNlC+NpCu5K520hJre+zKkWnJ+r9+8FX07D7c1EYys+EIyey54GL2rbKLEyjYA1TuAnmOk92lwkEvXcxymFABnzFTfMg69Ew4q/QAA0Gfnp/izz/G224gAIoQgTAjCDEGYMPJ/ggghiMl/nPofqIAPwd9fQqywAByBup4jBNxn5yJW2BUV5TsRaF+k7sOBoJIugL9zR3Uf/tVBEAjAFRdBBMATAh6w1sqnc4D35mDuhLnokmeVYamSDmdsZwDbdO+3y8vsljuqYYSQyyHNCNCtWzenzWwRXGq5lBBwADiXjQgADlst7pL045cfAllURIhS5IgUOaKIXFFEDqXIlV/nihR5i69DTlEQef485AaD0nIqIl8QkUvT04m1JQp6zxmrI1YHfHJVSrvWinKZXSfzxp7VqFi3GJaq6ztWaDOEKVVA6TqgNvmM6s+FUTiRjd9NSo8AoPqrO1DO5GNNIIAqlkE1o/3VmgR2mGFQv/5eRDq2twjzMJOiS3LlNKCVTSXVyjXSHwBkZ5lW1gABv2UXtzS5Ru8C+3BX5+W2UEpfBPAiAIwYMSIp9Y1zqAG/r8ARAo4lqHHrG//+dul/p/aGxSylKBBFtBYEFAoiWsmvWwkiWgkC2goCitT/0kPFjqz6+N2hmgMvvFLH8pnAH5+ktKvPHwQAxyqre2o5lFZGrIJeZwYCADw/Em1TOP9ftAPKWAYlLItSlkWJj0Up60Mpy6CKZQ1CXBHkktYbAWAtNJipCGn0MwDpEfTbAXTVve8CYIYLnP4AACAASURBVCeAgMPytONn/SjOLwa/9y/whCDM5oAR68GDgCfSNEkAILrW5PdNBEJQzrIoTxBap5AniGgjCGgvCOjI8+jE8+jIC+i0dSZ2+Fh04IWkzEqNSYeN7wILLwVu1flAYvWAL6TWJfmnEI5yMOuPbgkwIiDw6Fb5k+36utqGJezUE4Jtfh82+3zY5vdjt4+VhLr8v4xdiZkkfSaJTEAyJUtmZUqCCGblJdwn6XOk4RifArhGtsEfBKCKUrqLEFIKoA8hpAeAHQDOBtAofd4GthmIz077TLLnAfil64UYvu01y3YiAB6yfYwAPAgE+b/yQNAv28p2RDu6GzxgsN1FdTa8mG4ZB8XOpy1X1oUZyQ4YIYz0X2cbdNvTMt3UsAxqWAabYT/FDIgU3XgO3TkexRyHXhyHXjEOPTgeWU1sMy/a/o30okZXY+ShjkBWK+DWzU06lubmt+2VGJXivixEYPFT6FBnH7XE8olLJ1BBwDafDxsCfmz1+bDZ78dWvw9b/D6U+BKJlOb1tYREEVmUIks2lSqvQ7Ivza/+yb42GH1y6npQbG0zDvsdfDIC/7tW3cev89kFZL9fQPb9+SjAyv99sm+OgdH08XPXi3HgWU+l/XMnFPSEkLcBjAXQlhCyHcA9gCQZKKUzAMwBcDyADQDqAUyS1/GEkGsAfAWABTCTUpo4LzsN2Al5QPpSA5B+MOl6i3/R5TJAsdi4ESgUQIwAEcKoTqJ6Ik1ZaxkGdQyDWiK9rmUYrCRd0GHoIajlalG7cR5qGYIaeZqbsg3SgRhDsCEQwIaAsX0aoRSdeR79YhwGRmMYEIthSCSKvKYQ/ozpkg1XAOV/A617NP65m5OKLcCO5cCg0xsUa00FDtizynF9aOsi1JisrmUMg9XBIFYHA1gdDGDVe4ehWgl8aAJyRckHVSCKyNf/CZLvKptSZCkCXP9aEeYiRbYc+JDOO2RJ224Y1f4gkPqG1RXS42RSayhuom7OSbCeArjaYd0cSA+CfZJUYumTPwcQpECQiigAEsaBfiQMwoQxj0lvFhsdRFECVDAsKlkG5QyLCpZRX5ezDMrkKXQZy2Ivy4JPcSZBCcF2vx/b/X7My8kGIPkHBkRjGB6JYngkimHRCPJd9BRNlu17q2GZ+E/bX3IQZjLT9pdi330hjNqUWkVWAOg5/0qAq3Fc3371i4j5fJidl4vlWSGsDgawy6ylx5z3d0O+IKCd7C8q4qXXbWVfUoEswPNF6XWuKLbY9H0Kglh9DYIJtvtYOBSnsT+4OuaI7a8BSP33daKlfocthMYR9JvEDujJpFa2eAK7GNi9CugwGBxlDRmlQQp0EAR0EAQA8R3UIoBKhkGpj8VulsVOnw+7fD7s8kmvt/l9qHBp6wck/8CqUBCrQkHMgiT4h0SjGF0fwRH1YfTmuLREBIlcJA1H2QdRkpPWzY2/XQJ8NkI+Qgh+DgXxQ1YWFmeHsMWferQII8/2tkQH4HxhBTrzPNrxvCrYN3a8CGO2vdKQj9CCIIjVVycU9C3B0+UJ+jjETZZoAHwSP3wZzUdbYnKQzRgNTJGaepTTXLQmtfhD7I4BTnW3bWAAtBZFtI6J6OfwUKhiGGzxSzbYTX4fNvr92BjwY7vPD5pAaguEYGUohJWhEJ5tXYjiGIfxdfU4pbYWXfjUp6dKL89/LP7stBxGAPB9VhY+zMvBkqwQokma/XJEEftFY+jJcegm+3C68Ty6cDz8AIojT+C20DwAgEiJmlm6rQUIvXTRq2weuPrElaZE0vyf2RP0cWgs000yT/iDos/jFf/jam1rldpS+IgIv2zTK6U2cb4NpEAUMSQawxBTk4SPxYPQN7QSa4IB/BEMYGUwiE0JYoY3B/yYESjAjFYFGB6O4KTaOhxTV5+0XZ8IzZ+12yREa4E1HwEHnG+wyQu+UINEZRnL4MO8XHyQl4vdCR2nEj5K0T8Ww6BoDIOjMQyKRlHM8a7t3WEEkAPpd2tJaW/mGXGytK9Zg9JKrWDbVrEIC8WhON/3rWG7Tq3ygGa2LHqCPg6NJejd3yLSQ6ENsblKHu8NAMgjkiMonHACmT5KSSecFvsJA2MxKI2hyhgGK0JB/BIKYVlW0OLA1fNLVgi/ZIXwWJtWmFhVg/+rqUX7OE3P9Qixf4ig//I2YOUbQKsegF8Lply6NYxDkzwUBbAsFMS7+Xn4LjsroW/GRymGRaIYHQ5jRDiKfrEYnH9Ne/5zTF9Abg0bRlAV9G6KpTUWN3OXG/o+x+CDX3aKnRq9D58EJyd9zKL5N6qvz+duRwC8RdDTZIq8NRKeoI9DOmtm6GF9ASRjFRqslpF1pj5JQT9XOBDHsT8ntY+Cv6g3UGZc1lYUcUx9GMfIEQi7WBaLs0OYn52NpVkhW+FSxzB4sVUBXiosxKm1Nbi+vBJtEiRGibyD6SbTEqrq5YqHr51oWJxMZVEK4MesEJ5tVYA1wfjXB8Pl4fTwTowOR3BQOIKcJK79bWIRujLGjklXju2tCXoadFMjrdH5VDjEJOj96gOIS4NJiYIYGpQoiESa7W6nbfFf/kTc75/leIwX+ROk8gBp5p+VaZIkbksVnxlNThMQiPX5OoM/KaljKIjyHSTmtE+wpZHlYr+UzgcAApPYWddREHBmTR2m7ynFgq3bMblsL4Y4FEujhOLjvFyM79oJj7UuRE0cra/4m0vtV6z5yNXYWzxf3Snlg7D23/Hove+7OszyUBAXdWyHKzq0cxTyIVHEaTW1yN18Dqo23I7JeytwZH04KSEPACFi/F1Xir3BMtpvaFRCmlbiP8b9n/raXCAkptNzk/GbOcFARDaswQKKRr9W7Ip1YlfLej0P8RMbPA77sXk44vaSrEE2Doy8gF/EPq62F20uqqn8OdgodrQs/+4/Y+Me6x0cizu4S/B94Smuzq3QEA1GZJKbyBeIFGfW1OGtXXvw+bad+FdFFfJtTDURhsHrBfk4s3NHfJedlZzh7MNLkhpTi2WJ3GKOTc0UV8EwuKZ9ESZ1bI8VIfs6TT1iHG7dW4Fvt+3AfWXlIOHOaIgoUM0yDuyFTb32JuJ54VT1tWD6jDFdVzO9oD8x+kBK52IhYiu1KlxUdsaKYBCUmxYtEgbjU+HglM6TCp6gj4PbJiIiCEpRiJ20javt7TR6J3q0jd8Um6cMZgvjQNjkhC/fAKudmOS59HTneVxTWYWvt+3EnWXlKI5ZI352+H24rn0RrmxfhC/owJTPtS8TS+FBvCgrhFO7dMRCS4EtiSPq6jFz1x78b8cunFddgwI5z8EsAJMl26TRmx/Qk8lV+EyQcnk3tB2X1LF30dYAgPf5w9Vl1TS1yCPRpLpxRBP044dohRRX056YnuQM+0+xKx6cdCKevPhoy7oQlbT8dqQCQTnCLQq/ZYbRmHiC3oaXeKnMqVtnrHKj3M+djw+FwxJun85wK17uYu9ziKA4Mvo4buMkc8casTsWCEMBNOzmbp2fm3Cbv8TOcdfnUIqza2rx4Y5daLNnFIpsGlD8kJ2FR7vW4edQ0zmaWwq/bKt1vW2YEDzQphWu7tDOts7R6Pow3tmxG9NKynBgJGoRL1yaXHX/E6S+qebj17CtcS13HYojs1GZ0wM/CAPxuaAVcVgbx5xxbHQqiiOz8axwmrrsPWFM3HEcHX3Udvlblxo1aP3nPm6oMQ3vMf6suOdQqEcIV8Wuw3GxR9CxTQE6FGizqKOij2JEZDqGlUuNfPZnNhkEfVPiCXqZF3itAcJL/AkA3At65clcgla4iUvcXUcwCfrrYraJxa5Qxui363IDYCdtgypqnRXkhvyI0dQeOK0L4hdd+lI40KI9OREA8J/9z8Sc7bswsarG0oGn3C/ikg7t8FSrguSzGigF1s4Bti9Pds/moWyD+jIsuPv+1gb8OKtTB7ybb/1NhkSieG3nHkzfUypFSDlw5qhe+PDKhpsRnH5z1mcUahO5O3ENd536/tTYfbb7PcGdgWpISoXeyWl3lv0iWs36v2gXxCiL5WJfwzYHdDPW5NRr9IxpjKJL0TggMhNzxFHyuIwjK6WFKEMBSrN6auM8/HQsFIbgEf5si3Q5Kvoo2uamPluOhyfoZabzJ2OD2Am/ij1Vwe026ua8g3sm3kiHXqPfJhbhUzHZgDmbY/pzIdpkMYlgDBet8mA4rE+RQaPhaeJL4VvhAGnb3M74r/wwtIPC/Y0CAFlZ2QhRitvKK/D+jt04IGJ0aFFCMLOwAPe3aZUg39c8EAq8cw7wcnLmgmbjRZ2m6iIk7/usEC7o2B5/m3IYWEpxRUUVZu3ag2HRxOGo5xzcBwd0tRQmjssiYbA2DmYEAE3QZwWMM4RgwH7GMIs/BuU0FxGHiLFnhQnq63qqbTNbONKybcQUANo3+jrOiN1jWGb28XPQC/qGC1iRUkQ57YGkaO3/66GNY1T/briQuw3baHuEdFdzKS3ABtoF824a2+Bx2OEJepkaZOOo2OM4NfaAJuhdavSj+xahXZ578wK1sdG/dvFI1/vr8cu/YIc2hegZtTYK58GqN6DeJkgYBjHdhT6Nn2DZV8993Pm4nLsJh0aeQTS3C74UnMdLQVxr9ADABjWbcl+Ow8u7SnBelbVc7gf5ebi8QztUuc3iNPc0/WGa1ErvpxeBn192Pb4mI6aZa7Jo/EJZn+Tm4Nr2RZZCdl05Dq/t2oOrK6tcGwdYXwAMY/97XRS7xXb5U/wZAIA9tBAlVHlIGI8xIToFj3BnI+jTKxoaU/iLMCz6omGfMdEnbc+3B60xIToF/SKzVF/YO/xYdb21XBkBQPDNvzXbPkOcbfRsEn6na2LXYpEwGFfFrjMsFylFTBdkoNxf4ZBWuZ+X/SJtcgLolG31ARZkNY5JxxP0NohJCnrC+PD9rUfg6AH2IY7l1GjTjhHtoaCcYUzfIgRY+5tNr82Y6ds+FzPOG46zDjTaORVbvKgTulI3GOmMhLC4ibsCAHBu7A5M09lAFW7hLlNfrxD7QASDHSiCn2UsNv7Xec0JVUKTi7LwBYzOtQCAW8sr8cquPcjljd/J8qwQbmjXFq4KIZi79Hxzt9Qoe+7NwBc3JTXGpubg6i9tl1MALxbk4+6iNhBMgmtCTS0+2LEbQ6PWbyeeHZw4CHnA2fGpT9BTGtZrioT0fwXti+nCyQZBn4h6GsTFsf/glKjVnLOC9kUUAYQRQnFkNm7jE0ec92mvmbTMH1MfFKE33Sy9Pf4M8HPxYFzA3a6abBQogPb5mo1emdWKrKbIcLJPbb+O+cgjEd22jeuY/UcL+gc4+5hVxaSxmxS5Og5DGAR9rO0F/TJ/HE6OPWhYVssmV67g4OizcdePH9TBELcMAP/i/o3R0achZQNYx8WwLOaLw1AcmY0fxUGws3y+J2hdhfRmHh9DLIJePyN4mE+u7YA/YB8GODISxa0VRejEGQX28qwQrmtfhEiiLEthH6iLE64Efp0NbHZX3fCt/Dw829r4ICWU4vayctxbVo5sB3PjWbG7HY+pXDtDIi9a1jnFl+tj0EWlSbaDXnTtkVrYsd5ZaYcIBvPFYfiN9o67ncKp0ftwq04hseN27hKsEHuDmK8XnQlVb7rpUBDCoM75rs6vJy/kQ5dW1gcjq3OQK4LexxIExXp1eWNH4PyjBb2Txl6DbPwrdgNu8t/p7jjyb6R/miv8RbtgDzXaP2tZ7UbV/8B/sPZJTFVwjnLRNHTj8igC2E7bYcIBnbFfp0L1XAVZPnn75H76qO7G9rOM5eFBDdsmZ+9kg1mG2YOe7oIPb+/cjX4mLfWH7CxcnUjYp7nvZqPw1R3AJ1cCs+wbWuuZn52FJ0xCnhEJHi8pw7k19lE6ymww3jWkmDSqbbaxi856iT/e8ACYKxwIANiZN9iyLQAc2rstNj10PGZeNAJnDI/fXcr8YJk16UDMue4wfHGdVjzs0tFa74FfaW+8q1NIAKB/B6Nj+m1hHCbE7rNo9CAEHwiHY1LsZvhMzthHTh9iO76PBas/rXNhFubfNAbt8qT7/wFuIn4Ve+KKMb1wyegeWLdbqhOymvYEJ8jBEyyDZQXj1WN4gr4R0Qv6Djoh/eGVB+MrcSTKXSZ6KBfQzcf2w+NnDjWsE0HAwYcw1YRfrU/T6PU/8JOhq7BVtJ9FnBO7U51GP86dqa2Q1Siz/VFhyikDcXg/yaQU8rOa5m8j6G/lLsMHwuGW5YBJo2etGj0Fwe9iD6wWiwEgqem6zx/Ee8IRqKXabxCVk1kYiGgtinhhT6kl5n5ZVggvFMaZHSVRLqDZiNW52uy3YAA3tWtrKCXhpxRjdwxSy07YcVrsXpyUIAHIF8d0Y57pLRSG4EH+PPByxBYBsEA8AMWR2djW9ST8LvbAK7lGk4qPJWAYgiP7twchBLcf1x8PnjZIXT+2n3bNmxWIoV0KMaBTPnKD2vVnp56N6K4pU1/eYH8NmzV6AoL/cFfgO/EAMKzxvAM7Ga+rjWJHDIm8hP/I5k6F/xvRBS9eMBw9i7SH5MvCCTg19gAmHVqMu08cgMUbyjAy8jzOjN6lavQBH4P5rc6SZ92e6aZR0X+1p+yvdczpXCgJVJFSnBmdjGOij6jrVojWKaVyAYX8rEVj+U3sBQAoh6ZlCIxR87/z+P0AABwJYDW175S0RByI9VQ6tl0MriLo14jdEdFl/LGEqNq7CFaLJGKIxdzzrnAE/sNdgW1iEXabZiH6LEIfY7XRE1CcHHsAJ8YewrED2yd12frlh4JPl6B2oxymysgO1XaCgFd37UEfU5jgq4X5+DLHIYHm2WHa69UfJjGiRkQUgF9mAQIHcGGgrjThLnsZBjeahDyhFA+U7kVR2KiMPG1yqpfTPKyi8aPC/HEeyk5eKjtNn2dCODn2IDYEjDNT84PkX2N6YeJB3dX30ycO146hO+65B3VDqxxJQRJ0TWwEm4Y2sy4eiT/FbniLTyLCSvd92j3szo7dhaf5CTg08gxOid2PauRYKs8+esZQy0NBwS8/PDhBRAlaIYwQRvZoDYYAl4zuIftGtECJeTfFzw9oCP/oomZ6jX5kj9b476JN0nL5N6cAfqb9ob/cK2XHag3NUitHWmx/Mv/h/oX1tKvlXPprimUZXHa4diPGc/8qx4jZCHpRFuAnxB4yLGcZLbo3SoK6H5yVbO02N82RsScsy2IG04293T/VOiYB1irolSm8vidAW1HEy7tKcFqXjobEoDvbtkEHnsf+Nk5IlVUfpDS2tLPyTeCz66XZxto5wPZlcTfnAdzSrq2lF+uUsnIcX1ePX+TvfKtYhAXi/niaPwO7aBuIILiW/RgVcM55qKdBZJMo/DZRTHtpHj4SDrOYFKhOMCkEfQyivHOWg9P9oZAV0H5L/XX10GmaKUh/mQ7r3gqzftxsOEaAZXBcbCoAYCKA7285wnBc+4Fp52IZghtiV2EV7YF58rKl4gAsFQfEP0Yc/HJwxcsXHogLZ0q/c7u8EDY9LIUmz1z8N5Q7niEEvYoSJyKmSkZr9OZoFzP6y2/cfu0x47zheHXSgZqgp9YtlXTvy7kbsVNOz3a6jD9wyODzEWdxHs9Wpwl6n2VZ29wgHjl9MJSwMgWGELBysw7Jdi6fmxBV4wCAPN3UmIPPki3JwYfZlx6ENjkB9O+Yj2nnDke6UMbhI5qwUGrxMKYQydaiiMdKyuDTef5iDMHN7drGj7FvAaViAQDhcvl/RUIhDwDPtirAsizjDPCiympMqJVMPsqUf544DJP5SQCkmdn7wlgcHnvGUOrCXFtlVPQ5DI9Mh88m2muBuD8e5M9Dv472Tsnp52mzpdPlWWwigW5m7vWH4flzhxmWDepqX0akXb7ka7jp6L4Y3t0a8+83fYaurbPRNjd+yLN+vCwh+EQcjY00fkZ3MijX9ZDO9hp/hBOxg7bFW/w43Mjelrbz2pGxgn47bYvneC1kUG8jV/hKHGF4P35QBxzRr52a4UZtwgiU6nR1NIRZ/LHSwqzWCcejvwwZJ0FPgd9FSbsXKMFk7kLDakW7DevDLXVjPOvAbjDDMgQ+URpzjAS0cTCs4Qb/15j40/upZ43AIb3b4pe7j0Zu0AdiEpzE8JqAxHmYmbEzHSh1wmM2BdRGRqKYUlZuWLbb58PLhXEiJZJ0Pjca6oMrsVCcn52FmSYfxIhwBNdXVGqHS2IWdSdnLPxWjRzsRYGt2UJJvrv4UKMpUflVmWzJZPQ5O069BI3BlcDCm8dixnnOCsF+HfNxwhBjIb9nzx1hu21+yI/NU0/AteP6oI1szpEUG/mcKdS5/zFHM/OwDqHNdnxx3WhcOTZxNrEi6AMOprEoL4CCwZ38JdjIFLs+fyq0kKu/cXhVOFYtpjRf3N+w7uLYf7CJdsImsQN+EIyFs/SmGzPZcqW+egTxonASiiOzgUDiIkt60w3POm//knACxkenolf0LbwuHGtYpwg/Y5MRe4Gq3LsMAXyiNOYoCarbE0Jw1gjJrHT3iQNw9RFW38N1R2rL2puEKKs77/fCIPTqrj1kCHFvxJkYu92ijQFAG7l9YonPPkrjlNo6nGqKNJlRWIDljnVxWkBBdEAT9AkePDyAqW2MmivLZeGx0jLDXOt7URJ2c4SDEp5ab//uF5mlvrYTkop5kHGYCfmDOegbeQ3/Zc+BNks0btO9TQ7GD+qQcFx6WJbBvScPxIvnOz8gQn4Wm6eeYKvYuKU4MhsrczWnbXyHtJGBnQpw6/j+GN49voKn+MCcAhPCMc1U2dhXZ8YKegIKCkatu27NnAPuOmE/HBl7EhO5O037Sthp9Fmy6UavVTtlFQKSSeSZs7WHzDP8BJQX7Ke+t9pAGaylxgv4lQslLUep9xE2hC/aC/pPrxmNfx/VF4QQsIKi0QfByq0HKePDreP748/7xkuOIZub/cZjNKea329y5/ikz/8GfxTO5+7AtImaJnb2SHc3oEAJfhAHqzZ6PZ8Ih+IN/ih82vpCmz0lri+vRGtdJqJICG4raoMqu9+Dc4hMWf4qULHZ1XjTgqr+xr/1ZhXkY5fOLk8okLXzJLQVjKasofuPRHFktuxLcub5c4cZ7N92IbAvTNTMKI/IRb2IKexQuV4DPimzmoKoPV/MtV5SgRDgwkOKccxAdw+IA7oljozTX19Pcaerr/X6hTkwIZ34bK5vAIjoeic3duOtjBL0VbosPnOMvFkcUhDHBI+gX9JihnSxXkTT5eJnZdCm1PF+o9uP3w9j+7VTx/OZMArZIX1mbOJfeNx+Unik4qyMlymrMKhzAa4/SkpU2dtlHEppPj4LnaKafyjjB8OQxA4rGfONIOR2xLHRqZjCS4JYH945pq+7RDMlcsNvcyPUI4S7+YsRZpz9LG1FEQ+X7jUs2+Pz4dlWNjf/X19Zl3Fh4PMbgFed6/akHar5SJzY5PfhhVZGk01+VS+gvrtlW33mZzxOGNIxYcXS4wdrZhQlpp4vsDfp2WnA6RBWbJIHefuyUfht8jFxt/nmxsMxQ/YpPCOcLs3CYbXRNzURTl+ozQuvdM3B0edwWvReADqtXP1v/SKpgzacG/Thk6sPxfMTh1nWvSkcjeLIbINGFDdShkhTN208BNlB+4Qiu4QrPT7VdKPbzkXhNS67PQ6MzsA2Xzetxj6TXMCVWRgzhGAd7aaGm1nuE5txmYuuKWF/fpbB9InDcFz04bhjsAttPSQcwaRKY12cz3Nz3NXD2b1a+t+U8fYJTDcigCltW4PTfaGtBAFtSg+0zVJNRj65KTR3RnQy/i+qZdEyDIOekTdxtVzXhYLgjuP7Gx78h/SWHKgDHBy3yZCsZh3ysyjIjl8fRjIhWZv6EADnjOyG1y4e6fq8B/dM3HPipqP7oqdNH4lC0zjH7dfO1TnTQUYJ+nqEUGHK7rMLB1PXxZGR+3ctNCRppApDpItR0egFMMjJsm+tZvdgUbhlfD/45I71ZxyslV91U49Hr7kwqunGenOYMwr1mDU4sxx1c5uYRzopdjMAKWLiuMEdsdVv1R5F3Y80yaHA1jUVlWirmwbXMQymtXJRZuKVo6T/TeqoVT6P/Tf2cW4OVpo6Q92+twJEyDVEWykk+t5nX3qQmsTnJilnOe2PZVQzLRIiPSAiss2+dU4Alx/eyzCDO2X/zvh18tE4ZqA08xzTN3UBlopTNfVzAQ9PGIwxfYtcnffbG8fg5QvtncV6rh3XB/NNneE+veZQfG1K5Lrl2P74/NrR6lgak4wS9ICmtSQ23bhnaJf4QiPeb6TcEIo9UASDHAeNvnVOAOMdbJNXje2NbFbSBhl/CPeoETmJP4leRsfT6D+5+lD8do/9NNhOozfz2TWj40YimDVKxTyg3GQCpRgfnYpTovfh7hOl+GW9oLcTdIBUBG1idY1h2ft5uVgTcFkJsCkFfRwbPQXwnqmpy7A6ivF19eDBGDT6I6OPY2DklYQCone7XF0SXzqkiXw9mx78hdkBdGmVjaW3j8O1R7qrU6NnoTDE9riNS/xzKSHHZ43oimfO3h+92+UiJ0Xlb0iXQrQzzdhZhqhafmN/6oxLmDILekWTt05b3dWm3PTQ8ZKwuV96f2T/dpi/tsT1eA7t3dZwNhEEhHVO54534yqOVMYf1Boumw5w3qhu2FlprOeuCGUfS7S4dBuNPuRnEfKzOG5QB4Q5YwlV8w1oJ+gHd9H7LZJrMA1ISTGKI/oyOW5apMABkRkQwMTthHRBVTVezu2IuoDkdKWE4KE2rfHmrj2Jb6KmtM8q3/+ChyyrvsvOwh+mRt6TyiQhIIA1fP5NVMrkNtt2P7tmNE56brG2IE0fzXwY5Xow/8qJipY5cTF3M/wcjxUNGO9tx/VHcZvU2gza8fWNh2PL3nqMcmGuaSiNPZPJOEEvUEXQG7ETO276ijAMgb61kd3P4XSYm4/th06Fxv6dlBprtScTB61o4/r+sGaB+sCp9oWlACn6gJWPQVnnn366TeyzrFPblQAAIABJREFUOanGrHi5Eet+Er8Hr6hLf1RMRZRSVCCx7TcAYEhJXyzp8pu67PdQEPOys3BUnFowAIBIpVRzJhC/P2862FhSjV42ywUAz5icyIfWh9GJDwCMZPLrXlQAGCcu6jPKxxAM6VKAwV0KMHXCYOysDGPa/A3IDxkf6E9xp2ORaF+wy8y4/u2sD3Ri+Jc2BLAQwDrWbHLDFWPsvllnzKd69IwhGKoLwOhYkIWOBfb9d9OFy95GDSbjTDeCg+nGDidnrBn9BaGker9+8Uh0TKC92MWmi2DUrvCWg1vfGljrl8wZjD+oe0Ak/gxKs4OAj1Ft9G6dsf+K3YC7uEmWNPmG3JBO8DpBz8rnE5O4EzrUt8YRdfWGZXNyXQrv+fELf6WLqnr7Mg2f5eZgk87URCjFTeWVYHQzwb9K6233BYDzD+6Oj66SKiuePbIbbjymHzZPPQEhv9GB+4xwOlZSKRrri+tG4+3LRlmOBQAThnXGKxdpWeKpzNBSoTGuKyfMZ/q/EV3RL46fqjFQHsSKf6OxyDiNXs3cIwRnH9gVdIUyxbRWW3QrQwgheII7A8tpP3CyScOpa47jMXQ3rBBHo48XZvVEwW2o3L4eFwZyQG3aBjoRkx9OAZYxhFe64StR6iR1q0Wjj3/+hgoGRaO3q8XjfE7g0qpqfKcrcvZddhZ2+lh04uPPJhCuBBY9DvAR4Mi7UhmyS6yfJ0pgCac8qbYOfTgOG00mSDPKlN/NtTz7soNw7ks/qe+dinEB2nVo/pkbu5xuU9romyGi0kJBth/L7hyHNjnuO9SlQsZp9IrYJaAo1oU4mR0hFMDpw+LXxtbzrDABS8SBqkYf8rOqxt46x339danjk6ZlLWaNGY0DOklmisGdCzDzIqOHP0yDWEu7IehjNHHh4g5XBb1PE/QNDa+0CIA4w/hDtMZ/J0Ip55rld1+jhoBiUDSGrpxW9YYnBDMLXIT9UQGYfz+w6LGkx2ph70agvlx7/fcibYzm9oYAvs7ONiRHUZHFVZVV0vaJBH0Sw7LLC3FC0+S1+0lPnqyJnj8q+d82Hk3piz3HZWJfY9MuL9ToD7gM1Oi1C/Oyw3rizd/zgb0Aq7NJfycMxUVnT0zJcRSVNcOgn8F5o7rjPJcXunbDMhB1jbhfC5yDC3TbXTmmF0b3bouhXa03pSBL06BPE35uLg+lj2XAx6gO3WQFvflCNAv6vJD98Y6OPopeZCdmBJ62Xa/PGtZTViuZOJRmDm5hAFxWWY3JRZoD7aO8XFxaWY0OQhytXkyg8SfDs8OA3A7Af9ZppZKnVMkrrU/EhdlGO7BYOQKd+b8BGGeCsy87CHjDuG8PWZnp3S5x5UP9T7jxocSNTgC9wFeXAJAqTm6emv5Es6YKr2yMsbdkMk6j199GLEPADD0bs/kj8GmbSwFIafeTuFtB/ZIA+eG2I7HsTvc1rJVsNr2wdYMWR08wQDdlpqYwO4YhtkIeAHhBEfQMvhRHYp5wAL7qEL+NGgBwvGyjZxnVocvEccbaYY6jj8gmrJ5FOba2YD3xMjJP2d++WmDX1pLwOzxBlq2S5QhI3/GfYjecWFuHzrr2gxwheDWRVk/TKOgBoHa37WKzRr+bZTHPVE8/Vq05S0M+LQ+kg01C3RH92+F/Vx+KiQcl1k715rZEGqQ10iT+zMKjZeNK0BNCxhNC1hFCNhBCLPU0CSGtCCEfE0J+J4QsI4QM0q27nhCymhCyhhByQzoHb4f5QhTYEO7gL0Od3NXpXWGsYX3nwqyktEZFow/5U3tGvnfFoZYMObcojsmgn0E9QriEuxmV/sROnKiuq40aopmkoDdrWkoJWHN1QzucBH08WXNYnyJ8f8sRluqGiTgrdjdOiD6CS6uqDMs/zsuJ31C8xl4wp5XFT6PH3oWGRbPz8wwNRTrECPiw9p0qRrrrx/W1LRUBAEO7FrrShJNRlpXY+5BP6ySVCcy9/jBMOSn1GvP7KgmlFSGEBfA8gOMADABwDiHE/E3dAeBXSukQABcAeEbedxCAywCMBDAUwImEkD5oRCqQi8+EUbjVb3oeEQb7RWbiLl4q1ZrqDPHS0VL2Zqvs5PqiKho9w5CUIwsUx6R+NuHGCXfsgPbokB/CpEN7oIyVNGR9iGYqFGYHsHnqCY6mK81UBUtXHoVEWmXX1taY6DOjkzEhOsV2++MHd0Q1crCedsUpNXVoo3PAhhkGq4NxHF5bl8QdS1r49h4URHaob+sJwQd5RpPLMZU+6G/L2VnnAAA6d+0BliG4MHaroeNZMqRy3XUzxaXTluDBbAD7dczHRS6Uk0zDjVo6EsAGSukmSmkMwDsATjFtMwCQGrNQStcCKCaEtAewH4CllNJ6SikPYCGA09BILLtzHGZOOgjXctdhFSNV81M0HUIIwgi5qvcRj8sO75nQVDEu+hhOid5nWKbcHoQwRk02iftGE/TJfYZ2+SEsvWMcerfLxb359+Pq2HUgwcbrZqOHgmCl2AuVNAcfCqMN68yC575TjOWi7fiZ9scK2tew7B1+rHo2BT+AkRFj4tj/8lyGWn4zGVjyvLtt9VAKTHGIZLF5In+cl4ManZZeKAg4pNb4234bPArFkdkggWz4GIKF4lC1a1myuBH09548EJNPNOpxa+8fj9PGSmGYmwN97XbzaOG4kRidAWzTvd8uL9PzG4AJAEAIGQmgO4AuAFYDOJwQ0oYQkg3geAC2Vykh5HJCyHJCyPLS0sR9NO1olxdCNxstELDK08asFreRdsZv1D4NnBCSssNJccY6NTJwQxlphS/EUbZdhRqLauRi/+hLWC4aS+neZRIoFxxcHPc471xuH/NdLxd5M3+i48wx9TnZ9iWMzfzwDPDVHYm3M2MTUaMi8pZFZm3+rOpaMKKpLLD8fGCZhoceutn9wkOKcfFoo8Yb8rNguwzD+OhUzC04u0Fj8Gge3EgMN8mgUwG0IoT8CuBaACsB8JTSPwE8AuAbAF9CeiBYr3gAlNIXKaUjKKUjiorclbm1g3GIK27+GafW8EN/wyUzLKXut3424TbpSz0G1XpUNiZ2cfTmZcmG5g3sZO9QXS5KWmZ5nrEp9eH1YYDT9okwDD7NbcSZTLzInT2rDW+rGIINAc18xlCKs2tq1BaK6iF1v5fPlLSWqFWemYZGtKyl3Zq4AJxHunDzq22HUQvvAmCnfgNKaTWldBKldH9INvoiAH/L616hlA6jlB4OoBzAX2kZuQNmraX5BbwE0Qn6VDUzXpb0fpaobdSSTaFWzD/JdNRJF25OOe+mMZh7/WEO+9sfYI44CiMjz2NP6wMNy1kAfMVIw7J383Pxi5hcqrxr4kXuvDjW8PZrU6RNT45DW0E0FG4TdElxLEMM7e5+nXw0lt91VMPGmwSNnRebKMvco2G4Cb34GUAfQkgPADsAnA3gXP0GhJBCAPWyDf9SAIsopdXyunaU0hJCSDdI5p34jRYbiKrRK4JVGWNjntQFV7OTMT76NQ4J5IEQgm+E4VgoDklKy1KaC/lZRjU9JXsDaqaApv9G3HzUXkVWjfuTqw+Fn43/gCyBtWE0AEQqRyKn6DsQuc7OFr8fbwb6Yji/0d2gE7F1qfQ3+ob4phsT/zPNLA6olW5FpYXfhOgU7Kat1So/kkavff7CJIMBWjpfXHcYymqjzT2MjCWhoKeU8oSQawB8BUlJmkkpXUMIuUJePwOS0/V1It1NfwDQdyH+kBDSBgAH4GpKaaN2eXASJhaB2sRybjXpiwV8Mb5nJNPNZdxNAIBkCroKskbvY0jK41fs/M0h6JXWjJU0B5fFbsL7LvfbX84rEJMoh6CeU8gHXz0I/gKt2NnGghJgb5ydkmGm3Nd39A2uk67+9vvwm6m37bbKowAyC/5AEKxAsEI2R+XJH5lpwEzQTKsUw3sbk9Y5gaQyzD2Sw1UwNaV0DoA5pmUzdK+XALANm6SU2s/DGwlHG31TDsIGfQc5vQkimXEpZpeG3PBiE5luVrED0VXcgWqqi3SRv4QvhFEJe5zaoe/Ne1nsRpRRY4SL02OAqxxhEPQlWdUOWyZgyQuAPwsYMcl+vcukq09Nhdb4uh4o4IOAHwiFQlhyw5EY+eA8AJqNnmVIWtrdvXLhCPRPoROU8pBuKaZQj+TIuBII1rKqLePKVPsKkdTj6BVBp5+dJGujV517LgX9VWN7Ycte56qJTjyX9S88WXsUSmHN8k2Hvfcb0drpR/9dHBp5BkVESpoSwsVgKCDKH7nOH8Vulo1fEsGOr26X/jsJejGx6UaAVdBzVcOxWOgB0UfwTe4pGKD/feX/hLj/zeKh9B9OnZZxP3kkR8YJeuUesTb0MFeJTJ54rfYSQdXoCWMbvmRk/juXj8Knv+5EfsinK1KcnNhUTDduNfpbxieveQMAT/zYQN0XjUs3O1CEHVSO3qJ+dI76sS2kFTv7KicbF5q6UjUYs41+iykJq/0g/FS9ASWGAmYB8NWDsRtB9Iy+hcMCbQ0zNlWTTu9Ik6aJyqZ7NBKZJ+idllsU/eRunR9vOxL5WQ23bRKkrtH375CP/uOlaTdxeqIlQFE6Gzu8Mt5Mo7HqpdA4Jx1Qk4ttIc09NDe3MQS9aYZQb3IEdB6GrwVDwBr46kEA1ez1lBo1d/1MsCXQQobhkSQZGxSr2sTTdLxOhVkNahau1ck3CtnD+qSWM5Dq50rWdJMOlMqKTdW8wo6+NfkgugfBmmAQW3xp1HNE0eqMFUzVdSjFWlMfW67a2O2Jghps8XrfTnPSVJ2QPBqHzBP06g1B7RfLuCnrmk60G9aYMHX7camZRlJFdeg2keSYe/1h+PdRUgRJotrqjUmWEMTwiDF878vc9PUXhchbNXpTNmyVGMO6gDGyRIwYk8xFES3SdOOxb5Nxgl6NL5cFa+dWUrlbRbAzRKpF3bmwcXtBOo6PGKfhPoeKhIlQQtE6FiaXaKJp9CmdNmlYhiDFj+iKGbr+tvGUTg4+S0mEuTnZ8ecYf31rv3zurdZlVAA+vNS4jDfW2lnA7zVUqhSi7UAFo9+HghoFvfy/pZhuPPZNMk/Qm0zXR/Rrh/evONhSv6OpoWkuPTC2XxGmTxyG68clV2SqqTV6oHH9AeMHdTC8H9vP3hTGgcXRdfUgumzTjYEA/vLH8bu8dbr98p9mWJeJPLDtJ+OyT681vP02VmZ4z9cMghlKYW+6cR5lE+HNLPZlMk/Q2yw7sLi1evMc3MvcUKFpSdeNQgjBcYM7Jl3gTMk5auyEKXMDGACIQpqFKEXI0n5OCvz3/OFYcffRlnU8WLQSRXSq///2zjw6qipb3N+uypxAmEESIIBRxCAQMEGUiAqNIB2esXnOCIrYrbai7WIpPlufSv/st2yHXk6tKGrbTj+mdqCxFTtP4oANEhkEBAEhgogoYQgZquq8P2pI3UolqQpJVarY31q1Uvfcc+/dO1W17777nLO3de59YHWnFtPMYqmjInzisK4VdBwKYugJHIxtX/PX24scSnjE3aybtCS3ShMDPD2bTXj/tiJ6Rylk41+0PJp4F0y1dSjAP7bsNVyLnGPoyc8862x5Gbfrx/Qn0W7jqdKGKQwM7lz9/vn6/3HrGCY+vhKH56ve72hHvks/6Nu/NamFM6kO7rZavWYM/UdpqdT63f6y6+rYVNOwqErgzKGcruns/umYL5Hdf47MZkgYtV9bCx2MjW3iztCnJtlZ81/jyAwyFTK3Z8vnwYdDbo8Mtv5wJPjOKHtEk4eexGuf725xhaxwEakPRThI4M/OkuM6390XuVMb+xv6pASbrwB6IN6niVrj/qp3q7GmHtiQnIShBR/LYwHe+LI7muz+fkASs/FHj7EpyFUDDeoTl+fz+c6f6OkpI/g/vxoarqStSlum91bajrgL3QB0zUhu8SBna7B8dhHb5k20NrYTj+iBKXmU/3582DVvj4ezBnbl8oK+/Pb8cDL7hE5T9VK9T1DfmW4AmOpeGFe97rsTE9mR2IS/8/O3oQmxcXGju2oEylKt4apxVaGtNs5MS2T84ONdzXr8eKt95feL/NOEcvzEnUffHnB7kcE9n2jHOBPstohnPky02/h/JUN4ddWuiF4X6mv7LnWdzeHaVD50DSel6nsSMuqzZZempTKgspHFU4+fAfdVBt8XItsTEznmN82ph8NBXk3wCrbRSDYXCnlZmXz4u3Pp3y3EKl1KuyIuPfr2SDtx6CNGNPQNtjI2OcHOmzecBQgrXCMw2HAcOc3Sp9UGZBvhm4CZPafW1jX6w4tk5a9wGdA9Q6d5xihq6CPEibvwpe01vnpUP7plJHHRGQ0HN5MTbRT078LIfvX56h2HrYa+PDmZec4pzKu7IvDwVuGzgLBNbm0t7zndSdkKcrpY9gVWkVKU1kC/VUrMM6B7Bqv/azwnZTb0zL2F1P2nLF58Rh7O6vpZWS4RXk/tw0+mkfS9xsCaF1skmwtYGfDEsOnw+dxYdysAU0daE79Fo/KXEv+ooY8Qt1zgTtfvX+91dJTn9EeacDNttgZJnkF5fwM6sHtGg/ANHbbydWPZNnd8BG/f2qLrb0pK4id7/Wee7nKRXNUTp6c27PC+1spY3tDNU1fms3x2REs5KHGMGvoIccO5A9n50EUkegzP5gcu5OVrC5o5Kr7wD6FHKgWFN6bsP8gp0jB8Y9K3s97kcEfdDQ1PsvfLhm0h8lGaNWwz+lg1/nMgTu6Rwfr7fsHDU93TJr2hm0lDTmJQr/ALhChKMNTQR4mURHtUp4C2OU0478VDe7Pid+dGThbqPfr7p5yOILiqszHOeiMs9hok4bBvGqaF9+9p8XVXplpvaPYjA1just7gO6Qk+uRrz4OxSuyi0yuVNiGrcyrbfzzqi5H7k5GSYAlhtYRXry8Mq8ao3eMpZ6YmUlXrBGy4arthT63w9bElf4+zKrybr9MIdgl+Vztgs7Eh2SrjwsrrMEF+dnVObz3gOL75K1FDDb3SJjxxeT5l2370LbRpbUYPDOJ5+/HGrFFs21+/OjnBrwyj12d2Vp9kMfQJ6dtwVoW3qGs/nehF8Hr3ZWmpGP9slceyLNkq7/hFfUI678rX3J6RTZ+tnBio+6C0CZlpiQ2mO/pS7kbg+oUDunJlYT/ftj1ISMR51Jr5057+Na4wfxKBBcr9WRkwrdJx5FTLtn/RmaJTuvP6rFHMGjMgrOsrSiiooVcih4leJkavR+9yGd/1HUcHYvzSFttT9lGXEF4h9FRqGt1XnmLNq5PffbRlO/D/MGpA14hW/lJOHNTQKycEvsRqLlOfmMuVhuuYNU/O0fSKwEObZKBtb9D2ahH2+RcBN0LfDGtYqHOEU1EoJy5q6JUTAnsQjx7AERC+qQrT0DfGpoD0x6auE3axtrXV+IWiBKKDsUrEiGa+H++0xTqXNZ2x48gpJHd/37ddnf4djgMt/2HMqr0NwXC042fAHl+781g/zemuRA316JWIUV8WL/JxaK9H73QZS2IuV3UWLke9Z+2y1zaYEhkOh0njPVcBX6RZf1qOI6eooVeihhp6JeJEZzDW/VV3OAOtrQ3n0VxLS1nq8a3aFftRbCnfWdqcR3OjkgJCUUANvXKC4IvRG9PgeSIwTv+F/2wZCf8nYk/fivgvoqruiXF2UI9eiRpq6JUTAu/0SkfAYCyAM2DmzS7/ilP9zg7/WulfW7ZrAhOoKUqEUUOvRIxghUEihX+MfkiWdZGTqetsmU+/LyGBn7ypCML06A0Gu1/1KqhfmKUOvRIt1NArEWPikJPomp7EtLNyIn5tr6F3OA0jc7rwm7ED63eaBFw11lW8n3hXtdrCy8lTnfwztoT6soTGmYSzqvGatooSCdTQKxGjZ8cU1twznpN7RD6fi8+j9zxVBNY+dRyxxunLvMVCJDxDvy/NmvfGUXUy3smaGqNXooUaeuWEIMEXunHPo++Ual285AzIQ1OWmooLwvLoJ9X8gZ9Tjlja/Gf06KwbJVqEZOhF5EIR2SIi20TkziD7O4vIEhFZJyKfi0ie377bRGSjiGwQkddEJCXweEVpa7xpih2u4B6981hfS376SruNr5KSmvTot7t6Wba/MjnYkn60tLmqex6X3IrSGjRr6EXEDjwJTAQGA5eLyOCAbnOBcmPMGcA04HHPsVnALcBIY0weYAcuaz3xFSU0pp3Vj1+NyObGc935ZnJ7dmDZLf6l+uw4AubTL0ztzdIuMxo95x4TUArSdgxb8veWJldtfYZKdeiVaBGKR18AbDPGbDfG1AKvA1MC+gwGVgAYYzYDOSLidWUSgFQRSQDS8F8XrigRIj05gYenDiUzrT5kM7i3tVSfMyBO/2ZKNrP/VdvgXBfWPMQjdb/i/zutVbISMrYgUp9iwVnTw5J/Xu28Ei1CMfRZwG6/7QpPmz9fAiUAIlIA9AOyjTHfAQ8Du4C9QKUx5p/BLiIis0RktYis3r9/f3haKEorELhwypa6G+xHG/T72WTwZ2cJx7CmIU7I2GQ9X2BdWh2NVaJEKIY+2IL1wG/sQ0BnESkHfgusBRwi0hm3998f6A2ki8hVwS5ijHnWGDPSGDOye/fuwbooSptx2Zl9mD32TJzV9XF3EYM9eQ+cXmLpW+uZRVPnl/qsDrdH74+ziYVSGcmaT1CJHKEY+gqgj992NgHhF2PMIWPMDGPMMNwx+u7ADmAcsMMYs98YUwcsBqzVFxSlHXDnxEFkdU7FVW2dT29L/gGmLrC0eQ28fzWqtSnJiL3at+1ypDdYceuleGhvls8eE3SforQFoRj6fwO5ItJfRJJwD6a+5d9BRDp59gHMBD4yxhzCHbIZJSJp4k4ZeAFgfb5VlHaAeHJqumqts2QS0rc2CLnU4o7zO/x+PqVp1kRo7uma1p+X9yznDepOdmfNRa9EjmafH40xDhG5GXgP96yZF4wxG0Xk1579zwCnAS+LiBP4CrjOs2+ViCwEvgAcuEM6z7ZE0Lq6OioqKqiurm6+sxIVUlJSyM7OJjExsfnO7QyxQXbnVBxHTiW5x3Jfuz19Kx9+vYsL/PrW4Z5y6aR+6uX/Bhh6R5CwTTTTNCsnNiEFCo0xy4BlAW3P+L3/FMgNPM6z717g3uOQEYCKigo6dOhATk6OJZ+40j4wxnDgwAEqKiro379/tMUJG5sIhQO68rux5/LUtlewJR0AQGxOPt/3sc/QX1QzD+Px1I8a97z7/XYbu/xubsbYGwzsgl9xdP36KhEmZlbGVldX07VrVzXy7RQRoWvXrjH7xOX9Vg3v05m6Q3mWfR/u+sD3fqOpv4mtN/2ZW3cdWxOthUpc1SeByzojB+AUT+qHnh11zaASWWJq6F+NfPsmlj8fm0d2EcFxOI/kbv/r27e3rpwqEdIaTI8UXnVeQFr6Ykurqyb4atgbzzuZUQO7cmZOl1aVXVGaI2Y8ekVpC7w5cLzYBFzV2bjq6lMZi62Of6U1VnXKwfJ068Cq43DgwnG4Z/Jg7DZRI69EBTX0bcj06dNZuHBhyP3Hjh3L6tWrAdi5cye5ubm89957lJaWkpmZybBhwxg2bBjjxo1rK5FPOJ6+agT5fTuRnOD+KdhsAgiOQ0Mt/d7OSA9yNHToso1Ke/2grMuRhiMgQdrFw7O47pzYG7dQ4oeYCt2cKFRUVDBhwgT+9Kc/MWHCBEpLSxkzZgzvvPNOtEWLO8YP7sn4wfWhFq+DX1c5nKSuH/naP0lJp6hmToPjEzNXU+e37Th0BoE/K10Rq0SbmDT0//32Rr7ac6hVzzm4d0fu/eXpTfZ55JFHeOGFFwCYOXMms2fPZufOnUycOJFzzjmHTz75hKysLP7+97+T6ldgesWKFTzxxBMsWbIEgPfff5+nn36axYsXN7jG999/z7Rp03jwwQcpLi5uRQ2VUPCOM7hqTsJVl4ktsRIAY3PxXVoV+GVEkMQD1CVvtBxfV5nf4Jxq5pVoo6GbEFmzZg0LFixg1apVfPbZZzz33HOsXbsWgK1bt3LTTTexceNGOnXqxKJFiyzHnn/++WzatAlvDp8FCxYwY0bwrIjTpk3j5ptvZurUqZb2lStX+kI38+bNawMNFbDm+3BW5Vj2JXVZad3u/Cn4FQF3VvfGVd2HQNShV6JNTHr0zXnebUFZWRkXX3wx6enuWG1JSQkrV66kuLiY/v37M2zYMABGjBjBzp07LceKCFdffTWvvPIKM2bM4NNPP+Xll18Oep1x48bx17/+lenTp5OWVj/Ip6GbyOA/c6j259EkZn7p207I+Bpbyi5c1X0BQ0LHDZZja386G/9bRYfkBA7XONSjV6KOevQh0lScNTm5fs603W7H4XA06DNjxgxeeeUVXnvtNaZOnUpCQvB77Jw5cygsLGTq1KlBz6O0Lf4evetYPxwBXn3KSUsBFwmZq7ElHvS1G1eCJz5fz4MXu+fja4xeiTZq6EOkqKiIpUuXUlVVxdGjR1myZAljxoSemKp379707t2bBx98kOnTpzfZ99FHH6Vjx45cd911aiQiTOBSgNr94y3b9pQ9pOU8RUqvty3tjiOngbGmfvDOzddPUIk2auhDJD8/n+nTp1NQUEBhYSEzZ85k+PDhYZ3jyiuvpE+fPgwe3HCetT8iwksvvcTevXuZM6fhTA8lcjirBlJXaZ1qaU+tQGz1BUmMK4GaHyYA8OfLhzNpSC+SEmz1Nw219EqUickYfbS4/fbbuf322y1tOTk5bNhQH6u94447fO9ffPFFS9+ysjKuv/76Rs9fWlrqe5+UlMQ//1lfo2Xs2LEtE1oJi2AJx2r2TSYhYxNib1htyr2/GFPXDYBu6Uk8deUIAN5Z587mrUXBlWijHn2EGDFiBOvWreOqq4LWXVHaCcGyOBhnB6r3TsUYa6FwY4TqfROpO1gQ/Fyem4ZG35Roox59hFizZk20RVCOA8fhIVTt6EpS11LsKXtwOTpQe+A8nEGyVHrx3jTU0CvRRg29ooTKPCToAAANQElEQVSIq6Y31XuuCLn/GdnufDm/GpHdViIpSkiooVcUPwJDN4X9u7Bqx08tOld25zR2PnRRK0ilKMeHxugVpQliOPOyovhQQ68ofgTOurGppVfiADX0YZCRkeF7v2zZMnJzc9m1axf33XcfWVlZvlw0d955Z9jn9k9FfMYZZzBu3Dh++OEHwD1Ns3v37gwbNozBgwfz3HPPtZpOipVAu66GXokH1NC3gBUrVvDb3/6W5cuX07dvXwBuu+02ysvLKS8v56GHHmpwTE5OTrPnHTNmDOXl5axbt44zzzyTJ5980rfv0ksvpby8nNLSUubOncu+fftaTR+lcdTOK/FAbA7G/uNO+H59656z1xCY2NBAB7Jy5Uquv/56li1bxsCBA1tXBg/GGA4fPszJJ5/cYF+PHj0YOHAg3377LT17Bi9Zp7ScQMNut4Vn6TulJTXfSVEijHr0YVBTU8OUKVNYunQpgwYNsux79NFHfaGb9957r0Xn96Yi7tu3Lx988AHXXnttgz7bt29n+/btQW8CyvFzPDH6V68vZHDvjq0tkqIcN7Hp0YfgebcFiYmJjB49mueff57HH3/csu+2226zpD8AuOmmm/j4448B2LNnjy+V8dSpU7n77rsbnN8/FfEf//hH5syZwzPPPAPAG2+8QVlZGcnJyfzlL3+hSxetPdoW5PbI4OpR/eiWkcyjH3xNUw59WpKdqlqnb3v0wG4RkFBRwic2DX2UsNlsvPnmm4wbN44//OEPzJ07t8n+/jH2nJwcysvLQ75WcXExl1xyiW/70ksv5YknnghfaCUsbDbhgf/I8+Wpacqjz+qUytYfjkRKNEVpMRq6CZO0tDTeeecd/va3v/H888+32XXKysrabAxAaZ6iU7ozqFcHbv9F4ykOOqYmNrpPUdoT6tG3gC5durB8+XKKioro1q31Hte9MXpjDJmZmcyfP7/Vzq2ER8eURJbPLgpaD+CZq/KZs3AdF57eizXf/hwF6RQlPNTQh8GRI/WP6X369GHHjh0ATJkypdljA8sLBjJ27FgqKyuD7ps+fXqzxUqUtkGChG7ysjJZd98E/rF+bxQkUpTw0dCNooRJot39swl36qWiRAs19IrSDL06pli2EzwGXg29EiuooVeUZvhs7gWW7QSb+2ej6RGUWEENvaKESYLdbeBt6tErMYIaekUJE6+ht6tHr8QIaugVJUx8oRv99SgxQkhfVRG5UES2iMg2EWmQg1dEOovIEhFZJyKfi0iep/1UESn3ex0SkdmtrUR7Y9KkSRw8eLDJPr///e/54IMPWnT+0tJSJk+eHHL/0aNHt+g6rSlDvFAyPMs3CKsxeiVWaHYevYjYgSeB8UAF8G8RecsY85Vft7lAuTHmYhEZ5Ol/gTFmCzDM7zzfAUuOR+AhLw05nsObZf01Lc+KaYzBGMOyZcua7Xv//fe3+Drh8sknn0TsWvHOI5cO873vrJkqlRghFI++ANhmjNlujKkFXgcCVwgNBlYAGGM2AzkiEphD9wLgG2PMt8cpc9R45JFHyMvLIy8vj8ceewxwL4Q67bTTuPHGG8nPz2f37t3k5OTw448/AvDAAw8waNAgxo8fz+WXX87DDz8MuBdBLVy4EHDnwbn33nvJz89nyJAhbN68GYDPP/+c0aNHM3z4cEaPHs2WLVualG/jxo0UFBT4ipds3boVqC+Y4nK5uPHGGzn99NOZPHkykyZNanUZTiRO7dWBl68tiLYYitIsoRj6LGC333aFp82fL4ESABEpAPoB2QF9LgNea5mY0WfNmjUsWLCAVatW8dlnn/Hcc8+xdu1aALZs2cK0adNYu3Yt/fr18x2zevVqFi1axNq1a1m8eDGrV69u9PzdunXjiy++4De/+Y3vZjBo0CA++ugj1q5dy/33399sErVnnnmGW2+9lfLyclavXk12tvUjWLx4MTt37mT9+vXMnz+fTz/9tNVlONEoOqV7tEVQlGYJJQVCsEBkYAKQh4DHRaQcWA+sBRy+E4gkAcXAXY1eRGQWMAvwVW1qT5SVlXHxxReTnp4OQElJCStXrqS4uJh+/foxatSooMdMmTKF1NRUAH75y182ev6SkhIARowYweLFiwGorKzkmmuuYevWrYgIdXV1Tcp41llnMW/ePCoqKigpKSE3N7eBPFOnTsVms9GrVy/OO++8VpdBUZT2RyiGvgLo47edDezx72CMOQTMABB3cpAdnpeXicAXxphG698ZY54FngUYOXJkw0xSHo4nhn48BEtu5cVr/MM5JpDk5GQA7HY7Dof7HnnPPfdw3nnnsWTJEnbu3MnYsWObPMcVV1xBYWEh7777LhMmTGD+/Pmcf/75IcvTGjIoitL+CCV0828gV0T6ezzzy4C3/DuISCfPPoCZwEce4+/lcmI4bANQVFTE0qVLqaqq4ujRoyxZsoQxY8Y0ecw555zD22+/TXV1NUeOHOHdd98N65qVlZVkZbmjZC+++GKz/bdv386AAQO45ZZbKC4uZt26dQ3kWbRoES6Xi3379lFaWtrqMiiK0v5o1tAbYxzAzcB7wCbgTWPMRhH5tYj82tPtNGCjiGzG7b3f6j1eRNJwz9hZ3NrCR5L8/HymT59OQUEBhYWFzJw5k+HDhzd5zJlnnklxcTFDhw6lpKSEkSNHkpmZGfI158yZw1133cXZZ5+N0+lstv8bb7xBXl4ew4YNY/PmzUybNs2y/5JLLiE7O5u8vDxuuOEGCgsLm5UnXBnilVlFA3j00qHRFkNRWoSEE16IFCNHjjSBA5ebNm3itNNOi5JELefIkSNkZGRQVVVFUVERzz77LPn5+VGX58CBAxQUFPDxxx/Tq1evVjt/rH5Ox8P7X+3DZQwTTm+9/6OihIuIrDHGjAy2T/PRtzGzZs3iq6++orq6mmuuuSaqRh5g8uTJHDx4kNraWu65555WNfInKuMHB84kVpT2hRr6NubVV1+NtggWQonLK4oSX8RUto72GGZS6tHPR1HaJzFj6FNSUjhw4IAak3aKMYYDBw6QkpLSfGdFUSJKzIRusrOzqaioYP/+/dEWRWmElJSUBqtxFUWJPjFj6BMTE+nfv3+0xVAURYk5YiZ0oyiKorQMNfSKoihxjhp6RVGUOKddrowVkf1AS/PWdwN+bEVx2hPxqlu86gWqW6wSi7r1M8YEzZvdLg398SAiqxtbBhzrxKtu8aoXqG6xSrzppqEbRVGUOEcNvaIoSpwTj4b+2WgL0IbEq27xqheobrFKXOkWdzF6RVEUxUo8evSKoiiKH2roFUVR4py4MfQicqGIbBGRbSJyZ7TlCRcR6SMi/xKRTSKyUURu9bR3EZH3RWSr529nv2Pu8ui7RUQmRE/65hERu4isFZF3PNtxoRf4aiYvFJHNns/vrHjQT0Ru83wXN4jIayKSEqt6icgLIvKDiGzwawtbFxEZISLrPfv+LCISaV1ahDEm5l+AHfgGGAAkAV8Cg6MtV5g6nATke953AL4GBgP/A9zpab8T+KPn/WCPnslAf4/+9mjr0YR+twOvAu94tuNCL4/MLwEzPe+TgE6xrh+QBewAUj3bbwLTY1UvoAjIBzb4tYWtC/A5cBYgwD+AidHWLZRXvHj0BcA2Y8x2Y0wt8DowJcoyhYUxZq8x5gvP+8O4C7Fn4dbjJU+3l4D/8LyfArxujKkxxuwAtuH+P7Q7RCQbuAiY79cc83oBiEhH3EbkeQBjTK0x5iDxoV8CkCoiCUAasIcY1csY8xHwU0BzWLqIyElAR2PMp8Zt9V/2O6ZdEy+GPgvY7bdd4WmLSUQkBxgOrAJ6GmP2gvtmAPTwdIslnR8D5gAuv7Z40AvcT5H7gQWe0NR8EUknxvUzxnwHPAzsAvYClcaYfxLjegUQri5ZnveB7e2eeDH0weJkMTlvVEQygEXAbGPMoaa6BmlrdzqLyGTgB2PMmlAPCdLW7vTyIwF3SOBpY8xw4CjuMEBjxIR+nnj1FNyhi95Auohc1dQhQdranV4h0pguMatjvBj6CqCP33Y27sfMmEJEEnEb+b8ZYxZ7mvd5Hhnx/P3B0x4rOp8NFIvITtwhtfNF5BViXy8vFUCFMWaVZ3shbsMf6/qNA3YYY/YbY+qAxcBoYl8vf8LVpcLzPrC93RMvhv7fQK6I9BeRJOAy4K0oyxQWntH754FNxphH/Ha9BVzjeX8N8He/9stEJFlE+gO5uAeK2hXGmLuMMdnGmBzcn8uHxpiriHG9vBhjvgd2i8ipnqYLgK+Iff12AaNEJM3z3bwA97hRrOvlT1i6eMI7h0VklOd/Ms3vmPZNtEeDW+sFTMI9U+Ub4O5oy9MC+c/B/Ri4Dij3vCYBXYEVwFbP3y5+x9zt0XcLMTD6D4ylftZNPOk1DFjt+eyWAp3jQT/gv4HNwAbgr7hnocSkXsBruMca6nB75te1RBdgpOf/8Q3wBJ7sAu39pSkQFEVR4px4Cd0oiqIojaCGXlEUJc5RQ68oihLnqKFXFEWJc9TQK4qixDlq6BVFUeIcNfSKoihxzv8BELuwG1JRhYYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    %matplotlib inline\n",
    "    test = CH4_KF[500]  # (1111,)\n",
    "    test = array_to_tensor(test)\n",
    "    test = test.reshape(1111, 1)\n",
    "    prediction = Bp_kalman(test)\n",
    "    prediction = prediction.cpu().detach().numpy()\n",
    "    test = test.cpu().detach().numpy()\n",
    "    plt.figure()\n",
    "    plt.plot(test, alpha=1, label=\"only KF\")\n",
    "    plt.plot(prediction, alpha=1, label=\"KF+ BP\")\n",
    "    plt.plot(CH4_no_noise_spectral[500], linewidth=4, label=\"original signal\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"保存模型\"\"\"\n",
    "model_save_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\深度学习滤波器\\滤波模型\\透射谱的滤波模型\\BP_KF.pt\"\n",
    "torch.save(Bp_kalman.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
